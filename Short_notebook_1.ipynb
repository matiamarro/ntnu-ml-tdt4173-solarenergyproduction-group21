{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69005a2f-957e-4261-aa67-254008221c36",
   "metadata": {},
   "source": [
    "# Group 21 - We're Kenough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65db86b8-ec56-47fb-951d-b2f350d469f1",
   "metadata": {},
   "source": [
    "- Angelica Ricci: 105181\n",
    "- Mattia Milone: 105633\n",
    "- Michele Lamon: 105251"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d528717",
   "metadata": {},
   "source": [
    "Estimated time running:\n",
    "+ intel 11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz 16GB ram: 3 hours "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81529b37-5564-443a-97cc-7f694533acba",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Short notebook - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ad68ad-f583-4072-9317-2027ae342fa0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Importing all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8511b1db-5171-44e7-bc6e-344d1a1c0018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "import catboost\n",
    "from catboost import CatBoostRegressor\n",
    "from catboost import Pool\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, mean_squared_error\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "import re\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef6f2a9-dbbf-404e-9dd0-f0a229eb1872",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Uploading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d2baff-5faf-4fba-8102-2ff29be4308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a = pd.read_parquet('A/train_targets.parquet')\n",
    "train_b = pd.read_parquet('B/train_targets.parquet')\n",
    "train_c = pd.read_parquet('C/train_targets.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96e79d5b-35ca-4a35-b815-c3c5a9cef89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_estimated_a = pd.read_parquet('A/X_train_estimated.parquet')\n",
    "X_train_estimated_b = pd.read_parquet('B/X_train_estimated.parquet')\n",
    "X_train_estimated_c = pd.read_parquet('C/X_train_estimated.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82bea7c5-242e-4b7f-8610-f8932903356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_observed_a = pd.read_parquet('A/X_train_observed.parquet')\n",
    "X_train_observed_b = pd.read_parquet('B/X_train_observed.parquet')\n",
    "X_train_observed_c = pd.read_parquet('C/X_train_observed.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c30e9df5-1e22-41e9-8a52-54635f616aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_observed_a = pd.read_parquet('A/X_train_observed.parquet')\n",
    "X_train_observed_b = pd.read_parquet('B/X_train_observed.parquet')\n",
    "X_train_observed_c = pd.read_parquet('C/X_train_observed.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d6785ac-d984-4e15-b94c-5698f1069510",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_estimated_a = pd.read_parquet('A/X_test_estimated.parquet')\n",
    "X_test_estimated_b = pd.read_parquet('B/X_test_estimated.parquet')\n",
    "X_test_estimated_c = pd.read_parquet('C/X_test_estimated.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39fcba64-57d0-47d7-92fc-4cb0fa8bda39",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = pd.read_csv('test.csv')\n",
    "test2['time'] = pd.to_datetime(test2['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be92d7f-64f4-4a14-8a7a-a568e4ab26a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Preparation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99c7ffd6-6c14-4928-940d-cbfcf4de1a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a['time'] = pd.to_datetime(train_a['time'])\n",
    "train_b['time'] = pd.to_datetime(train_b['time'])\n",
    "train_c['time'] = pd.to_datetime(train_c['time'])\n",
    "\n",
    "X_train_estimated_a['date_forecast'] = pd.to_datetime(X_train_estimated_a['date_forecast'])\n",
    "X_train_estimated_b['date_forecast'] = pd.to_datetime(X_train_estimated_b['date_forecast'])\n",
    "X_train_estimated_c['date_forecast'] = pd.to_datetime(X_train_estimated_c['date_forecast'])\n",
    "\n",
    "X_train_observed_a['date_forecast'] = pd.to_datetime(X_train_observed_a['date_forecast'])\n",
    "X_train_observed_b['date_forecast'] = pd.to_datetime(X_train_observed_b['date_forecast'])\n",
    "X_train_observed_c['date_forecast'] = pd.to_datetime(X_train_observed_c['date_forecast'])\n",
    "\n",
    "X_test_estimated_a['date_forecast'] = pd.to_datetime(X_test_estimated_a['date_forecast'])\n",
    "X_test_estimated_b['date_forecast'] = pd.to_datetime(X_test_estimated_b['date_forecast'])\n",
    "X_test_estimated_c['date_forecast'] = pd.to_datetime(X_test_estimated_c['date_forecast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4f0a646-ed34-436e-8323-bbadef184f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_estimated_a['forecast_age'] = (X_train_estimated_a['date_forecast']-X_train_estimated_a['date_calc']).dt.seconds/3600\n",
    "del X_train_estimated_a['date_calc']\n",
    "X_test_estimated_a['forecast_age'] = (X_test_estimated_a['date_forecast']-X_test_estimated_a['date_calc']).dt.seconds/3600\n",
    "del X_test_estimated_a['date_calc']\n",
    "\n",
    "X_train_estimated_b['forecast_age'] = (X_train_estimated_b['date_forecast']-X_train_estimated_b['date_calc']).dt.seconds/3600\n",
    "del X_train_estimated_b['date_calc']\n",
    "X_test_estimated_b['forecast_age'] = (X_test_estimated_b['date_forecast']-X_test_estimated_b['date_calc']).dt.seconds/3600\n",
    "del X_test_estimated_b['date_calc']\n",
    "\n",
    "X_train_estimated_c['forecast_age'] = (X_train_estimated_c['date_forecast']-X_train_estimated_c['date_calc']).dt.seconds/3600\n",
    "del X_train_estimated_c['date_calc']\n",
    "X_test_estimated_c['forecast_age'] = (X_test_estimated_c['date_forecast']-X_test_estimated_c['date_calc']).dt.seconds/3600\n",
    "del X_test_estimated_c['date_calc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b738d32b-2e77-4117-91bb-6028f60f805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_observed_a.set_index('date_forecast', inplace=True)\n",
    "X_train_observed_b.set_index('date_forecast', inplace=True)\n",
    "X_train_observed_c.set_index('date_forecast', inplace=True)\n",
    "\n",
    "X_train_estimated_a.set_index('date_forecast', inplace=True)\n",
    "X_train_estimated_b.set_index('date_forecast', inplace=True)\n",
    "X_train_estimated_c.set_index('date_forecast', inplace=True)\n",
    "\n",
    "X_test_estimated_a.set_index('date_forecast', inplace=True)\n",
    "X_test_estimated_b.set_index('date_forecast', inplace=True)\n",
    "X_test_estimated_c.set_index('date_forecast', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84cb6967-cc9e-42fa-bf3c-92137f4962e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_observed_a['sensor_A'] = 1\n",
    "X_train_observed_a['sensor_B'] = 0\n",
    "X_train_observed_a['sensor_C'] = 0\n",
    "X_train_observed_a['month'] = X_train_observed_a.index.strftime('%m')\n",
    "X_train_observed_a['hour'] = X_train_observed_a.index.strftime('%H')\n",
    "X_train_observed_a['forecast_age'] = 0\n",
    "X_train_observed_a['is_obv'] = 1\n",
    "\n",
    "X_train_observed_b['sensor_A'] = 0\n",
    "X_train_observed_b['sensor_B'] = 1\n",
    "X_train_observed_b['sensor_C'] = 0\n",
    "X_train_observed_b['month'] = X_train_observed_b.index.strftime('%m')\n",
    "X_train_observed_b['hour'] = X_train_observed_b.index.strftime('%H')\n",
    "X_train_observed_b['forecast_age'] = 0\n",
    "X_train_observed_b['is_obv'] = 1\n",
    "\n",
    "X_train_observed_c['sensor_A'] = 0\n",
    "X_train_observed_c['sensor_B'] = 0\n",
    "X_train_observed_c['sensor_C'] = 1\n",
    "X_train_observed_c['month'] = X_train_observed_c.index.strftime('%m')\n",
    "X_train_observed_c['hour'] = X_train_observed_c.index.strftime('%H')\n",
    "X_train_observed_c['forecast_age'] = 0\n",
    "X_train_observed_c['is_obv'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29f24f82-c3fe-4584-a6c4-e32624c7ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_estimated_a['sensor_A'] = 1\n",
    "X_train_estimated_a['sensor_B'] = 0\n",
    "X_train_estimated_a['sensor_C'] = 0\n",
    "X_train_estimated_a['month'] = X_train_estimated_a.index.strftime('%m')\n",
    "X_train_estimated_a['hour'] = X_train_estimated_a.index.strftime('%H')\n",
    "X_train_estimated_a['is_obv'] = 0\n",
    "\n",
    "X_train_estimated_b['sensor_A'] = 0\n",
    "X_train_estimated_b['sensor_B'] = 1\n",
    "X_train_estimated_b['sensor_C'] = 0\n",
    "X_train_estimated_b['month'] = X_train_estimated_b.index.strftime('%m')\n",
    "X_train_estimated_b['hour'] = X_train_estimated_b.index.strftime('%H')\n",
    "X_train_estimated_b['is_obv'] = 0\n",
    "\n",
    "X_train_estimated_c['sensor_A'] = 0\n",
    "X_train_estimated_c['sensor_B'] = 0\n",
    "X_train_estimated_c['sensor_C'] = 1\n",
    "X_train_estimated_c['month'] = X_train_estimated_c.index.strftime('%m')\n",
    "X_train_estimated_c['hour'] = X_train_estimated_c.index.strftime('%H')\n",
    "X_train_estimated_c['is_obv'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c6aec02-c58a-4388-b352-009e493fcb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_estimated_a['sensor_A'] = 1\n",
    "X_test_estimated_a['sensor_B'] = 0\n",
    "X_test_estimated_a['sensor_C'] = 0\n",
    "X_test_estimated_a['month'] = X_test_estimated_a.index.strftime('%m')\n",
    "X_test_estimated_a['hour'] = X_test_estimated_a.index.strftime('%H')\n",
    "X_test_estimated_a['is_obv'] = 0\n",
    "\n",
    "X_test_estimated_b['sensor_A'] = 0\n",
    "X_test_estimated_b['sensor_B'] = 1\n",
    "X_test_estimated_b['sensor_C'] = 0\n",
    "X_test_estimated_b['month'] = X_test_estimated_b.index.strftime('%m')\n",
    "X_test_estimated_b['hour'] = X_test_estimated_b.index.strftime('%H')\n",
    "X_test_estimated_b['is_obv'] = 0\n",
    "\n",
    "X_test_estimated_c['sensor_A'] = 0\n",
    "X_test_estimated_c['sensor_B'] = 0\n",
    "X_test_estimated_c['sensor_C'] = 1\n",
    "X_test_estimated_c['month'] = X_test_estimated_c.index.strftime('%m')\n",
    "X_test_estimated_c['hour'] = X_test_estimated_c.index.strftime('%H')\n",
    "X_test_estimated_c['is_obv'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faff4640-e5ad-4a7b-b3a2-2bfd8d8dbb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_observed_a[[\"month\", \"hour\"]] = X_train_observed_a[[\"month\", \"hour\"]].apply(pd.to_numeric)\n",
    "X_train_estimated_a[[\"month\", \"hour\"]] = X_train_estimated_a[[\"month\", \"hour\"]].apply(pd.to_numeric)\n",
    "X_test_estimated_a[[\"month\", \"hour\"]] = X_test_estimated_a[[\"month\", \"hour\"]].apply(pd.to_numeric)\n",
    "\n",
    "X_train_observed_b[[\"month\", \"hour\"]] = X_train_observed_b[[\"month\", \"hour\"]].apply(pd.to_numeric)\n",
    "X_train_estimated_b[[\"month\", \"hour\"]] = X_train_estimated_b[[\"month\", \"hour\"]].apply(pd.to_numeric)\n",
    "X_test_estimated_b[[\"month\", \"hour\"]] = X_test_estimated_b[[\"month\", \"hour\"]].apply(pd.to_numeric)\n",
    "\n",
    "X_train_observed_c[[\"month\", \"hour\"]] = X_train_observed_c[[\"month\", \"hour\"]].apply(pd.to_numeric)\n",
    "X_train_estimated_c[[\"month\", \"hour\"]] = X_train_estimated_c[[\"month\", \"hour\"]].apply(pd.to_numeric)\n",
    "X_test_estimated_c[[\"month\", \"hour\"]] = X_test_estimated_c[[\"month\", \"hour\"]].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46651db6-359d-41c3-8bc4-bb758d0bcd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_observed_a = X_train_observed_a.resample('H').median()\n",
    "X_train_observed_b = X_train_observed_b.resample('H').median()\n",
    "X_train_observed_c = X_train_observed_c.resample('H').median()\n",
    "X_train_estimated_a = X_train_estimated_a.resample('H').median()\n",
    "X_train_estimated_b = X_train_estimated_b.resample('H').median()\n",
    "X_train_estimated_c = X_train_estimated_c.resample('H').median()\n",
    "X_test_estimated_a = X_test_estimated_a.resample('H').median()\n",
    "X_test_estimated_b = X_test_estimated_b.resample('H').median()\n",
    "X_test_estimated_c = X_test_estimated_c.resample('H').median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e23fc49-fbde-45c3-914e-748374f18890",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_b_new = train_b.copy()\n",
    "\n",
    "train_b_new['diff1'] = train_b_new['pv_measurement'] - train_b_new['pv_measurement'].shift(1)\n",
    "train_b_new['diff3'] = train_b_new['pv_measurement'] - train_b_new['pv_measurement'].shift(3)\n",
    "train_b_new['diff5'] = train_b_new['pv_measurement'] - train_b_new['pv_measurement'].shift(5)\n",
    "train_b_new['diff7'] = train_b_new['pv_measurement'] - train_b_new['pv_measurement'].shift(7)\n",
    "train_b_new['diff10'] = train_b_new['pv_measurement'] - train_b_new['pv_measurement'].shift(10)\n",
    "train_b_new['diff15'] = train_b_new['pv_measurement'] - train_b_new['pv_measurement'].shift(15)\n",
    "\n",
    "train_b_new['toDrop'] = ((train_b_new['diff1'] + train_b_new[\n",
    "    'diff3'] + train_b_new['diff5'] + train_b_new['diff7'] + train_b_new['diff10'] + train_b_new['diff15']) == 0)\n",
    "\n",
    "train_b_new = train_b_new[train_b_new['toDrop'] != True]\n",
    "train_b_new = train_b_new.drop(columns=['diff1', 'diff3', 'diff5', 'diff7', 'diff10', 'diff15', 'toDrop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4991e355-0deb-4e48-8095-75b25e1f4653",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_c_new = train_c.copy()\n",
    "\n",
    "train_c_new['diff1'] = train_c_new['pv_measurement'] - train_c_new['pv_measurement'].shift(1)\n",
    "train_c_new['diff3'] = train_c_new['pv_measurement'] - train_c_new['pv_measurement'].shift(3)\n",
    "train_c_new['diff5'] = train_c_new['pv_measurement'] - train_c_new['pv_measurement'].shift(5)\n",
    "train_c_new['diff7'] = train_c_new['pv_measurement'] - train_c_new['pv_measurement'].shift(7)\n",
    "train_c_new['diff10'] = train_c_new['pv_measurement'] - train_c_new['pv_measurement'].shift(10)\n",
    "train_c_new['diff15'] = train_c_new['pv_measurement'] - train_c_new['pv_measurement'].shift(15)\n",
    "\n",
    "train_c_new['toDrop'] = ((train_c_new['diff1'] + train_c_new[\n",
    "    'diff3'] + train_c_new['diff5'] + train_c_new['diff7'] + train_c_new['diff10'] + train_c_new['diff15']) == 0)\n",
    "\n",
    "train_c_new = train_c_new[train_c_new['toDrop'] != True]\n",
    "train_c_new = train_c_new.drop(columns=['diff1', 'diff3', 'diff5', 'diff7', 'diff10', 'diff15', 'toDrop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ce9b66b-4bd5-4ac4-bbd5-9bddf4debb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_observed_a = train_a.merge(X_train_observed_a, left_on='time', right_on='date_forecast', how='right')\n",
    "y_train_observed_b = train_b_new.merge(X_train_observed_b, left_on='time', right_on='date_forecast', how='right')\n",
    "y_train_observed_c = train_c_new.merge(X_train_observed_c, left_on='time', right_on='date_forecast', how='right')\n",
    "\n",
    "y_train_obv = pd.concat([y_train_observed_a,y_train_observed_b,y_train_observed_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2c74946-c917-4aa9-8106-3f68ceb434ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_estimated_a = train_a.merge(X_train_estimated_a, left_on='time', right_on='date_forecast', how='right')\n",
    "y_train_estimated_b = train_b_new.merge(X_train_estimated_b, left_on='time', right_on='date_forecast', how='right')\n",
    "y_train_estimated_c = train_c_new.merge(X_train_estimated_c, left_on='time', right_on='date_forecast', how='right')\n",
    "\n",
    "y_train_est = pd.concat([y_train_estimated_a,y_train_estimated_b,y_train_estimated_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9351b4b2-579f-4e2c-9a20-6848d0ecd2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([X_test_estimated_a,X_test_estimated_b,X_test_estimated_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577af3a6-bde4-4b8f-93e5-a9ed80e7d499",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## NaN Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57caf83b-09ed-4637-b48d-57e2671df98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_with_nan_obv = [features for features in y_train_obv.columns if y_train_obv[features].isnull().sum()>1]\n",
    "feature_with_nan_est =[features for features in y_train_est.columns if y_train_est[features].isnull().sum()>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c9a7a1b-e654-49cd-a59a-3c32f1578a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "del y_train_obv['snow_density:kgm3']\n",
    "del y_train_est['snow_density:kgm3']\n",
    "del test['snow_density:kgm3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f0d411f-dd7d-4245-a0cf-0d50b1724230",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_delete=['ceiling_height_agl:m','snow_drift:idx','elevation:m','cloud_base_agl:m']\n",
    "y_train_obv.drop(columns=columns_to_delete, inplace=True)\n",
    "y_train_est.drop(columns=columns_to_delete, inplace=True)\n",
    "test.drop(columns=columns_to_delete, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8342c60e-701e-4b3d-a152-b2dcbb09f575",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_obv = y_train_obv.dropna()\n",
    "y_train_est = y_train_est.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c588e9aa-75a8-463d-b38c-fb1252377bce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1c344e4-ddcb-4ce5-a6d7-0f8e42661bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.concat([y_train_obv,y_train_est])\n",
    "train=train.set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34c00070-54ba-403f-acf8-544b72861092",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = test.pop('forecast_age')\n",
    "test.insert(45, col.name, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4508e06-a06a-49d9-bf0c-495974934955",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['day_of_week'] = train.index.dayofweek\n",
    "test['day_of_week'] = test.index.dayofweek\n",
    "train['day_of_year'] = train.index.dayofyear\n",
    "test['day_of_year'] = test.index.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56808dd5-28c9-4759-b732-6fbf37d9a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_mapping = {\n",
    "    1: 1,\n",
    "    2: 1,\n",
    "    3: 2,\n",
    "    4: 2,\n",
    "    5: 2,\n",
    "    6: 3,\n",
    "    7: 3,\n",
    "    8: 3,\n",
    "    9: 4,\n",
    "    10: 4,\n",
    "    11: 4,\n",
    "    12: 1,\n",
    "}\n",
    "\n",
    "# Create a new column 'Season' based on the mapping\n",
    "train['season'] = train['month'].map(season_mapping)\n",
    "test['season'] = test['month'].map(season_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8769eeb3-797c-4860-a266-930d7720fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns=['is_day:idx'])\n",
    "test = pd.get_dummies(test, columns=['is_day:idx'])\n",
    "train = pd.get_dummies(train, columns=['is_in_shadow:idx'])\n",
    "test = pd.get_dummies(test, columns=['is_in_shadow:idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "079335bd-d101-48d2-88cc-85a1c9b869ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(0, inplace=True)\n",
    "test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce622bde-c7fa-44a7-87db-4ea48ee37537",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.loc[:, train.columns != \"pv_measurement\"]\n",
    "y_train = train['pv_measurement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6dffc576-3d37-422e-8058-52b53c867ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cyclical features for day of the week\n",
    "X_train['day_of_week_sin'] = np.sin(2 * np.pi * X_train['day_of_week'] / 7)\n",
    "X_train['day_of_week_cos'] = np.cos(2 * np.pi * X_train['day_of_week'] / 7)\n",
    "\n",
    "# Create cyclical features for month\n",
    "X_train['month_sin'] = np.sin(2 * np.pi * X_train['month'] / 12)\n",
    "X_train['month_cos'] = np.cos(2 * np.pi * X_train['month'] / 12)\n",
    "\n",
    "# Create cyclical features for day of the week\n",
    "test['day_of_week_sin'] = np.sin(2 * np.pi * test['day_of_week'] / 7)\n",
    "test['day_of_week_cos'] = np.cos(2 * np.pi * test['day_of_week'] / 7)\n",
    "\n",
    "# Create cyclical features for month\n",
    "test['month_sin'] = np.sin(2 * np.pi * test['month'] / 12)\n",
    "test['month_cos'] = np.cos(2 * np.pi * test['month'] / 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bafbbcea-36c9-4bef-ad9f-ed9689463d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_transformed = np.sqrt(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d4516-cf26-489d-b01f-168eb3e5b161",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Preparation of the test set and the submission file base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ebe9b281-0165-4f83-bc0f-c7ae6f05a514",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test2.merge(test, left_on='time', right_on='date_forecast', how='left')\n",
    "X_test = pd.get_dummies(X_test, columns=['location'], prefix='sensor2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "750f0307-1909-4289-8273-d32e8183462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[(X_test['sensor_A'] == X_test['sensor2_A']) &\n",
    "                 (X_test['sensor_B'] == X_test['sensor2_B']) &\n",
    "                 (X_test['sensor_C'] == X_test['sensor2_C'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bccd81db-8caa-4418-b14d-ef0aa25635ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_test['sensor2_A']\n",
    "del X_test['sensor2_B']\n",
    "del X_test['sensor2_C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff4cc5da-4853-4239-8e87-1d68f5c05780",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.sort_values(by='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7fd97e05-c125-49d0-900a-de27ada4eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_test['id']\n",
    "del X_test['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "712833ff-a7df-4cf7-aa75-a1bbca73e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X_test.set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f71a780-fbf7-461c-b1b3-de52275aab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.rename_axis('time')\n",
    "X_test = X_test.rename_axis('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "552e59ee-2db3-4409-8246-3f0bce066d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns = [re.sub(r'[^a-zA-Z0-9_]', '_', col) for col in X_train.columns]\n",
    "X_test.columns = [re.sub(r'[^a-zA-Z0-9_]', '_', col) for col in X_test.columns]\n",
    "test.columns = [re.sub(r'[^a-zA-Z0-9_]', '_', col) for col in test.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea53aa58-f28b-4087-9429-74b5dd15c7ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Generic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "098150cc-c9af-404a-b73d-b574a5817afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_to_df(array_pred, squared=False):\n",
    "    if squared==True:\n",
    "        array_pred = array_pred**2\n",
    "\n",
    "    df_predicitons = pd.DataFrame(array_pred)\n",
    "    df_predicitons = df_predicitons.applymap(lambda x: max(0, x))\n",
    "    df_predicitons.iloc[:,0] = df_predicitons.iloc[:,0].apply(lambda x: 0 if 0 <= x <= 1 else x)\n",
    "    df_predicitons.rename(columns={df_predicitons.columns[0]: 'values'}, inplace=True)\n",
    "    df_predicitons = df_predicitons.rename_axis('id')\n",
    "    return df_predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f197a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred(pred_list, name_list, a1=0, a2=2160):\n",
    "    \"\"\"\n",
    "    Plots the given prediction dataframes from a1 to a2 with the given labels\n",
    "\n",
    "    Parameters:\n",
    "    - pred_list (list of df): list of prediction dataframes.\n",
    "    - name_list (list of str): list of labels (same order as pred_list).\n",
    "    - a1 (int, optional): beginning of viewing window (0).\n",
    "    - a2 (int, optional): end of viewing window (2160).\n",
    "\n",
    "    Returns:\n",
    "    - nothing\n",
    "\n",
    "    Example:\n",
    "    \n",
    "    plot_pred([best_of_best, pazzo, xgb_sum_pred], ['best_of_best', 'pazzo', 'xgb_sum_pred'], 100, 300)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    new_dataframe = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(pred_list)):\n",
    "        new_dataframe[name_list[i]] = pred_list[i]['values']\n",
    "\n",
    "    plt.figure(figsize=(20,9))\n",
    "\n",
    "    for i in range(len(pred_list)):\n",
    "        new_dataframe[name_list[i]][a1:a2].plot(label=name_list[i])\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0d2161-befc-4459-b3c5-d0ee0cf2e9e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preparation of the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6687929-a320-4a85-bba4-ae58d0dbb99c",
   "metadata": {},
   "source": [
    "Hyperparameters for the models used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2789260-f8f6-46a0-b44b-91b8a71ff6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_model_param = {\n",
    "    'lgbm': {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'mae',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.01,\n",
    "        'feature_fraction': 0.7,\n",
    "        'feature_pre_filter': True,\n",
    "        'bagging_freq': 5,\n",
    "        'bagging_fraction': 0.75\n",
    "    },\n",
    "    'lgbm_reg': {\n",
    "        'learning_rate': 0.07019571273972466,\n",
    "        'n_estimators': 350,\n",
    "        'max_depth': 10,\n",
    "        'min_child_samples': 29,\n",
    "        'feature_fraction': 0.8244973703390805,\n",
    "        'bagging_fraction': 0.753170749901516,\n",
    "        'reg_alpha': 0.9719949744352129,\n",
    "        'reg_lambda': 0.8504246860234232,\n",
    "        'min_split_gain': 0.36086476058243666,\n",
    "        'max_bin': 62,\n",
    "        'min_child_weight': 0.256068322761324,\n",
    "        'subsample_for_bin': 30\n",
    "    },\n",
    "    'catboost': { #MIGLIORI\n",
    "        'iterations': 1000, \n",
    "        'depth': 6, \n",
    "        'learning_rate': 0.1, \n",
    "        'loss_function': 'MAE'\n",
    "    },\n",
    "    'catboost_opt': {\n",
    "        'depth': 6,\n",
    "        'iterations': 4598,\n",
    "        'learning_rate': 0.11381056696717655\n",
    "    },\n",
    "    'xgboost' : {\n",
    "        'colsample_bytree': 0.8,\n",
    "        'learning_rate': 0.01,\n",
    "        'max_depth': 5,\n",
    "        'n_estimators': 1000,\n",
    "        'subsample': 0.8\n",
    "    },\n",
    "    'xgboost2' : { #MIGLIORI\n",
    "        'colsample_bytree': 0.70468596253168,\n",
    "        'learning_rate': 0.00931602383319447,\n",
    "        'max_depth': 7,\n",
    "        'n_estimators': 56,\n",
    "        'subsample': 0.9610097364456339\n",
    "    },\n",
    "    'xgboost3':{\n",
    "        'colsample_bytree': 0.7224776657906091,\n",
    "        'learning_rate': 0.044779531399174476,\n",
    "        'max_depth': 10,\n",
    "        'n_estimators': 906,\n",
    "        'subsample': 0.706461320142151\n",
    "    },\n",
    "    'randomforest_opt' :{\n",
    "        'max_depth': 26,\n",
    "        'max_features': 0.4942262677968311,\n",
    "        'min_samples_leaf': 6,\n",
    "        'min_samples_split': 8,\n",
    "        'n_estimators': 1809\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224a5d3a-55f9-4fc2-a149-8ffaaa1f60f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Models Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ff2260e-4f9a-4cd1-a118-df83d0594a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_lgbm(X_train, y_train, test=None, params=None, weights=None):\n",
    "    # Create a LightGBM dataset for the training set\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "    # Define LightGBM parameters\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'mae',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.01,\n",
    "        'feature_fraction': 0.7,\n",
    "        'feature_pre_filter':True,\n",
    "        'bagging_freq': 5,\n",
    "        'bagging_fraction': 0.75\n",
    "    }\n",
    "\n",
    "    # Train the LightGBM model\n",
    "    num_round = 1000\n",
    "    model = lgb.train(params, train_data, num_round)   \n",
    "\n",
    "    if test is not None:\n",
    "        # Make predictions on the test set\n",
    "        predictions = model.predict(test, num_iteration=model.best_iteration)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        return model, model.predict(test, num_iteration=model.best_iteration)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab86deb8-18a6-4434-aed4-f6fbb1d09d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_lgbm_reg(X_train, y_train, test=None, params=0, weights=None):\n",
    "    if params is None:\n",
    "        params = dict_model_param['lgbm_reg']\n",
    "\n",
    "    # Split your data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = LGBMRegressor(**params)\n",
    "\n",
    "    # Specify the validation set using eval_set\n",
    "    eval_set = [(X_val, y_val)]\n",
    "\n",
    "    model.fit(X_train, y_train, eval_set=eval_set)\n",
    "\n",
    "    if test is not None:\n",
    "        # Make predictions on the test set\n",
    "        predictions = model.predict(test)\n",
    "\n",
    "        return model, predictions\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d8487842-7520-4e26-aa4f-d3440cab2f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_catboost(X_train, y_train, test=None, params=0):\n",
    "\n",
    "    if params ==0:\n",
    "        params = dict_model_param['catboost']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    train_dataset = Pool(data=X_train, label=y_train)\n",
    "    test_dataset = Pool(data=X_test, label=y_test)\n",
    "\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(train_dataset, eval_set=test_dataset, verbose=100)\n",
    "\n",
    "    if test is not None:\n",
    "        test_pool = Pool(data=test)\n",
    "        predictions = model.predict(test_pool)\n",
    "\n",
    "        return model, predictions\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b023467-2a89-4719-80fe-24756ec541f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_xgboost(X_train, y_train, test=None, params=0):\n",
    "    \n",
    "    if params ==0:\n",
    "        params = dict_model_param['xgboost']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42) \n",
    "    \n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    if test is not None:\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        return model, predictions\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f3e89ac8-b7f2-4257-9548-3c4294095ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_randomforest(X_train, y_train, test=None, params=0):\n",
    "    \n",
    "    if params ==0:\n",
    "        params = dict_model_param['randomforest']\n",
    "    \n",
    "    model = RandomForestRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    if test is not None:\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        return model, predictions\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6be00f48-cc36-4f45-bba2-f4b6bcaa52b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_models(X_train, y_train, test=None, model='lgbm', params=None, weights=None):#, cat_features=0):\n",
    "    if weights is None:\n",
    "        weights = [1]*len(X_train)\n",
    "    if model=='lgbm':\n",
    "        return pred_lgbm(X_train, y_train, test, params, weights)\n",
    "    if model=='catboost':\n",
    "        return pred_catboost(X_train, y_train, test, params)\n",
    "    if model=='xgboost':\n",
    "        return pred_xgboost(X_train, y_train, test, params)\n",
    "    if model=='randomforest':\n",
    "        return pred_randomforest(X_train, y_train, test, params)\n",
    "    if model=='lgbm_reg':\n",
    "        return pred_lgbm_reg(X_train, y_train, test, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74040200-7f68-4e58-b848-731c31b951c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Y_slided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57e40fb8-ec7d-4a22-b3a9-ff5226e0075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_slided_prediction(X_train, y_train, test=test, model='lgbm', params=0, squared=False):\n",
    "    if params==0:\n",
    "        params = dict_model_param[model]\n",
    "\n",
    "    Xy_train = X_train.copy()\n",
    "    Xy_train['pv_measurement'] = y_train\n",
    "\n",
    "    Xy_train_A = Xy_train[Xy_train['sensor_A'] == 1]\n",
    "    Xy_train_B = Xy_train[Xy_train['sensor_B'] == 1]\n",
    "    Xy_train_C = Xy_train[Xy_train['sensor_C'] == 1]\n",
    "\n",
    "    Xy_train_A['previous_pv_measurement'] = Xy_train_A['pv_measurement'].shift(1, freq='H')\n",
    "    Xy_train_B['previous_pv_measurement'] = Xy_train_B['pv_measurement'].shift(1, freq='H')\n",
    "    Xy_train_C['previous_pv_measurement'] = Xy_train_C['pv_measurement'].shift(1, freq='H')\n",
    "\n",
    "    X_train_y_slided = pd.concat([Xy_train_A, Xy_train_B, Xy_train_C])\n",
    "    X_train_y_slided.dropna()\n",
    "    y_train_y_slided = X_train_y_slided['pv_measurement']\n",
    "    X_train_y_slided.drop(columns=['pv_measurement'], inplace=True)\n",
    "\n",
    "    y_train_transformed = np.sqrt(y_train_y_slided) if squared else y_train_y_slided\n",
    "\n",
    "    _,y_pred = prediction_models(X_train, y_train_transformed, test=test, model=model) #predizione non slided\n",
    "    \n",
    "    pred = pred_to_df(y_pred, squared)\n",
    "    \n",
    "    model2 = prediction_models(X_train_y_slided, y_train_y_slided, model=model)\n",
    "    \n",
    "    test_slide_A = test[test['sensor_A'] == 1]\n",
    "    test_slide_B = test[test['sensor_B'] == 1]\n",
    "    test_slide_C = test[test['sensor_C'] == 1]\n",
    "    \n",
    "    range2 = len(pred)\n",
    "    range3 = range2 * 2\n",
    "    \n",
    "    pred_A = pred[:len(test_slide_A)-1]\n",
    "    pred_B = pred[len(test_slide_A):len(test_slide_B)+len(test_slide_A)-1]\n",
    "    pred_C = pred[len(test_slide_B)+len(test_slide_A):]\n",
    "    \n",
    "    '''\n",
    "    pred_A = pred[0:1535]\n",
    "    pred_B = pred[1536:3071]\n",
    "    pred_C = pred[3072:]\n",
    "    '''\n",
    "    \n",
    "    datasets = [test_slide_A, test_slide_B, test_slide_C]\n",
    "    preds = [pred_A, pred_B, pred_C]\n",
    "\n",
    "    result_all = []\n",
    "\n",
    "    for i in [0, 1, 2]:\n",
    "\n",
    "        dataset = datasets[i]\n",
    "        pred_set = preds[i]\n",
    "\n",
    "        result = []\n",
    "        previous_pv_measurement = pred.values[0][0]\n",
    "\n",
    "        result.append(previous_pv_measurement)\n",
    "        max_time_diff = pd.Timedelta(hours=1)\n",
    "\n",
    "        test_copy = dataset.copy()\n",
    "        test_copy['previous_pv_measurement'] = 0\n",
    "\n",
    "        for index in range(1, len(dataset)):\n",
    "            if test_copy.index[index] - test_copy.index[index-1] > max_time_diff:\n",
    "                previous_pv_measurement = pred_set.values[index][0]\n",
    "            else:\n",
    "                test_copy.loc[test_copy.index[index], 'previous_pv_measurement'] = previous_pv_measurement\n",
    "                if model=='lgbm':\n",
    "                    previous_pv_measurement = model2.predict(test_copy.iloc[index], num_iteration=model2.best_iteration)[0]\n",
    "                else:\n",
    "                    previous_pv_measurement = model2.predict(np.array(test_copy.iloc[index]).reshape(1, 59))[0]\n",
    "                    \n",
    "            result.append(previous_pv_measurement)\n",
    "\n",
    "        result_all.append(result)\n",
    "        \n",
    "    flattened_list = [item for sublist in result_all for item in sublist]\n",
    "    return pred_to_df(pd.DataFrame(flattened_list), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "284a3280-76e9-43ca-8899-7c992b78ea14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004731 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7758\n",
      "[LightGBM] [Info] Number of data points in the train set: 79218, number of used features: 58\n",
      "[LightGBM] [Info] Start training from score 9.924039\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8013\n",
      "[LightGBM] [Info] Number of data points in the train set: 79218, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 9.924039\n"
     ]
    }
   ],
   "source": [
    "result_lgbm_slided = y_slided_prediction(X_train, y_train_transformed, test=test, model='lgbm', params=dict_model_param['lgbm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ebb55df",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lgbm_slided = pred_to_df(result_lgbm_slided, squared= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d45cac9b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 329\n",
      "[LightGBM] [Info] Number of data points in the train set: 63374, number of used features: 50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Start training from score 331.773985\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 339\n",
      "[LightGBM] [Info] Number of data points in the train set: 63374, number of used features: 51\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Start training from score 331.773985\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "result_lgbm_r_slided = y_slided_prediction(X_train, y_train, test=test, model='lgbm_reg', squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c27d357a-b163-4a44-8fed-85689a07a520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7758\n",
      "[LightGBM] [Info] Number of data points in the train set: 79218, number of used features: 58\n",
      "[LightGBM] [Info] Start training from score 9.924039\n"
     ]
    }
   ],
   "source": [
    "lgbm,result_lgbm = prediction_models(X_train, y_train_transformed, test=X_test, model='lgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7d5faad1-b83a-4ff1-8600-cc0be8f90cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lgbm = pred_to_df(result_lgbm, squared=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17f3c6c-f2f3-471f-9264-bc9746c4d2bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "32b764fa-ee14-4b7e-a19b-8ffa8267bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking_models(base_models, X_train, y_train, test=None, final_regressor='linear', final_params={}):\n",
    "    if final_regressor=='linear':\n",
    "        final_model = LinearRegression()\n",
    "    elif final_regressor == 'SVR':\n",
    "        final_model = SVR(**final_params)\n",
    "        \n",
    "    stacking_regressor = StackingRegressor(\n",
    "        estimators=base_models,\n",
    "        final_estimator=final_model)\n",
    "    \n",
    "    stacking_regressor.fit(X_train, y_train)\n",
    "\n",
    "    if X_test is not None:\n",
    "        y_pred = stacking_regressor.predict(X_test)\n",
    "        return stacking_regressor, y_pred\n",
    "    else:\n",
    "        return stacking_regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9d0a41-8ee3-4388-9ce9-bc7287fc9fef",
   "metadata": {},
   "source": [
    "### Stacking 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c2c97f64-988a-4342-99c9-95bd90ace2d1",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 329\n",
      "[LightGBM] [Info] Number of data points in the train set: 63374, number of used features: 50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Start training from score 9.927074\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "lgbm, lgb_pred = prediction_models(X_train, y_train_transformed, test=X_test, model='lgbm_reg', params=None)\n",
    "lgb_pred = pred_to_df(lgb_pred, squared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c7ec5ce3-4573-42a8-8b05-9d63a82a52bf",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 9.0652210\ttest: 9.0565245\tbest: 9.0565245 (0)\ttotal: 155ms\tremaining: 2m 35s\n",
      "100:\tlearn: 2.0733148\ttest: 2.0567362\tbest: 2.0567362 (100)\ttotal: 1.47s\tremaining: 13.1s\n",
      "200:\tlearn: 1.8829095\ttest: 1.8841427\tbest: 1.8841427 (200)\ttotal: 2.71s\tremaining: 10.8s\n",
      "300:\tlearn: 1.8074775\ttest: 1.8289070\tbest: 1.8289070 (300)\ttotal: 4.04s\tremaining: 9.38s\n",
      "400:\tlearn: 1.7689026\ttest: 1.8052966\tbest: 1.8052966 (400)\ttotal: 5.26s\tremaining: 7.86s\n",
      "500:\tlearn: 1.7531543\ttest: 1.7968189\tbest: 1.7968066 (498)\ttotal: 6.38s\tremaining: 6.35s\n",
      "600:\tlearn: 1.7364629\ttest: 1.7864132\tbest: 1.7864132 (597)\ttotal: 7.49s\tremaining: 4.97s\n",
      "700:\tlearn: 1.7227136\ttest: 1.7781776\tbest: 1.7781776 (700)\ttotal: 8.76s\tremaining: 3.73s\n",
      "800:\tlearn: 1.7090281\ttest: 1.7699329\tbest: 1.7699329 (800)\ttotal: 9.96s\tremaining: 2.47s\n",
      "900:\tlearn: 1.6921185\ttest: 1.7613328\tbest: 1.7613328 (900)\ttotal: 11.3s\tremaining: 1.25s\n",
      "999:\tlearn: 1.6786105\ttest: 1.7549962\tbest: 1.7549690 (995)\ttotal: 12.7s\tremaining: 0us\n",
      "\n",
      "bestTest = 1.754968993\n",
      "bestIteration = 995\n",
      "\n",
      "Shrink model to first 996 iterations.\n"
     ]
    }
   ],
   "source": [
    "catboostm, catboost_pred = prediction_models(X_train, y_train_transformed, test=X_test, model='catboost', params=dict_model_param['catboost'])\n",
    "catboost_pred = pred_to_df(catboost_pred, squared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "97e79149-4a5b-48f3-9310-eece3f775c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost, xgboost_pred = prediction_models(X_train, y_train_transformed, test=X_test, model='xgboost', params=dict_model_param['xgboost2'])\n",
    "xgboost_pred = pred_to_df(xgboost_pred, squared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "969f767f-515d-4d13-9231-280f5a37722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest, randomforest_pred = prediction_models(X_train, y_train_transformed, test=X_test, model='randomforest', params=dict_model_param['randomforest_opt'])\n",
    "randomforest_pred = pred_to_df(randomforest_pred, squared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "318dbd46-4a5b-4a96-9ec0-953e36cf3d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = [\n",
    "    ('lgbm', lgbm),\n",
    "    ('catboost', catboostm),\n",
    "    ('randomforest', randomforest)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bd0290ae-3bb2-4a02-bbda-13f7ffb16745",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 339\n",
      "[LightGBM] [Info] Number of data points in the train set: 79218, number of used features: 54\n",
      "[LightGBM] [Info] Start training from score 9.924039\n",
      "0:\tlearn: 9.0625740\ttotal: 20.2ms\tremaining: 20.2s\n",
      "1:\tlearn: 8.4133972\ttotal: 38ms\tremaining: 19s\n",
      "2:\tlearn: 7.8099768\ttotal: 56ms\tremaining: 18.6s\n",
      "3:\tlearn: 7.1189953\ttotal: 73.7ms\tremaining: 18.3s\n",
      "4:\tlearn: 6.5480038\ttotal: 90.6ms\tremaining: 18s\n",
      "5:\tlearn: 6.1447702\ttotal: 108ms\tremaining: 17.8s\n",
      "6:\tlearn: 5.6831695\ttotal: 126ms\tremaining: 17.9s\n",
      "7:\tlearn: 5.2592029\ttotal: 143ms\tremaining: 17.8s\n",
      "8:\tlearn: 4.8578495\ttotal: 161ms\tremaining: 17.8s\n",
      "9:\tlearn: 4.5101983\ttotal: 179ms\tremaining: 17.7s\n",
      "10:\tlearn: 4.2214233\ttotal: 196ms\tremaining: 17.6s\n",
      "11:\tlearn: 4.0145113\ttotal: 212ms\tremaining: 17.5s\n",
      "12:\tlearn: 3.7663852\ttotal: 229ms\tremaining: 17.4s\n",
      "13:\tlearn: 3.5508344\ttotal: 247ms\tremaining: 17.4s\n",
      "14:\tlearn: 3.3660768\ttotal: 265ms\tremaining: 17.4s\n",
      "15:\tlearn: 3.2461008\ttotal: 283ms\tremaining: 17.4s\n",
      "16:\tlearn: 3.1503877\ttotal: 300ms\tremaining: 17.4s\n",
      "17:\tlearn: 3.0181972\ttotal: 317ms\tremaining: 17.3s\n",
      "18:\tlearn: 2.9418795\ttotal: 333ms\tremaining: 17.2s\n",
      "19:\tlearn: 2.8248909\ttotal: 350ms\tremaining: 17.2s\n",
      "20:\tlearn: 2.7679296\ttotal: 369ms\tremaining: 17.2s\n",
      "21:\tlearn: 2.7168477\ttotal: 386ms\tremaining: 17.2s\n",
      "22:\tlearn: 2.6735806\ttotal: 403ms\tremaining: 17.1s\n",
      "23:\tlearn: 2.6248225\ttotal: 419ms\tremaining: 17s\n",
      "24:\tlearn: 2.5607037\ttotal: 436ms\tremaining: 17s\n",
      "25:\tlearn: 2.5115372\ttotal: 458ms\tremaining: 17.1s\n",
      "26:\tlearn: 2.4882104\ttotal: 474ms\tremaining: 17.1s\n",
      "27:\tlearn: 2.4611594\ttotal: 490ms\tremaining: 17s\n",
      "28:\tlearn: 2.4410608\ttotal: 506ms\tremaining: 16.9s\n",
      "29:\tlearn: 2.3899064\ttotal: 523ms\tremaining: 16.9s\n",
      "30:\tlearn: 2.3623715\ttotal: 539ms\tremaining: 16.8s\n",
      "31:\tlearn: 2.3473465\ttotal: 555ms\tremaining: 16.8s\n",
      "32:\tlearn: 2.3210701\ttotal: 572ms\tremaining: 16.8s\n",
      "33:\tlearn: 2.2891452\ttotal: 589ms\tremaining: 16.7s\n",
      "34:\tlearn: 2.2796365\ttotal: 606ms\tremaining: 16.7s\n",
      "35:\tlearn: 2.2697524\ttotal: 622ms\tremaining: 16.7s\n",
      "36:\tlearn: 2.2449804\ttotal: 639ms\tremaining: 16.6s\n",
      "37:\tlearn: 2.2316725\ttotal: 657ms\tremaining: 16.6s\n",
      "38:\tlearn: 2.2148337\ttotal: 677ms\tremaining: 16.7s\n",
      "39:\tlearn: 2.2098784\ttotal: 692ms\tremaining: 16.6s\n",
      "40:\tlearn: 2.2021916\ttotal: 708ms\tremaining: 16.6s\n",
      "41:\tlearn: 2.1972459\ttotal: 724ms\tremaining: 16.5s\n",
      "42:\tlearn: 2.1922020\ttotal: 739ms\tremaining: 16.5s\n",
      "43:\tlearn: 2.1901579\ttotal: 756ms\tremaining: 16.4s\n",
      "44:\tlearn: 2.1885948\ttotal: 772ms\tremaining: 16.4s\n",
      "45:\tlearn: 2.1863853\ttotal: 788ms\tremaining: 16.3s\n",
      "46:\tlearn: 2.1687848\ttotal: 805ms\tremaining: 16.3s\n",
      "47:\tlearn: 2.1661821\ttotal: 822ms\tremaining: 16.3s\n",
      "48:\tlearn: 2.1630093\ttotal: 837ms\tremaining: 16.3s\n",
      "49:\tlearn: 2.1609104\ttotal: 853ms\tremaining: 16.2s\n",
      "50:\tlearn: 2.1588285\ttotal: 869ms\tremaining: 16.2s\n",
      "51:\tlearn: 2.1564277\ttotal: 890ms\tremaining: 16.2s\n",
      "52:\tlearn: 2.1527741\ttotal: 905ms\tremaining: 16.2s\n",
      "53:\tlearn: 2.1520782\ttotal: 920ms\tremaining: 16.1s\n",
      "54:\tlearn: 2.1502300\ttotal: 937ms\tremaining: 16.1s\n",
      "55:\tlearn: 2.1322229\ttotal: 954ms\tremaining: 16.1s\n",
      "56:\tlearn: 2.1294096\ttotal: 970ms\tremaining: 16s\n",
      "57:\tlearn: 2.1261664\ttotal: 986ms\tremaining: 16s\n",
      "58:\tlearn: 2.1259865\ttotal: 1s\tremaining: 16s\n",
      "59:\tlearn: 2.1253059\ttotal: 1.02s\tremaining: 15.9s\n",
      "60:\tlearn: 2.1251454\ttotal: 1.03s\tremaining: 15.9s\n",
      "61:\tlearn: 2.1246183\ttotal: 1.05s\tremaining: 15.9s\n",
      "62:\tlearn: 2.1170591\ttotal: 1.07s\tremaining: 15.9s\n",
      "63:\tlearn: 2.1151568\ttotal: 1.08s\tremaining: 15.9s\n",
      "64:\tlearn: 2.1147531\ttotal: 1.1s\tremaining: 15.9s\n",
      "65:\tlearn: 2.1045100\ttotal: 1.12s\tremaining: 15.8s\n",
      "66:\tlearn: 2.1039708\ttotal: 1.14s\tremaining: 15.8s\n",
      "67:\tlearn: 2.1007006\ttotal: 1.15s\tremaining: 15.8s\n",
      "68:\tlearn: 2.0971870\ttotal: 1.17s\tremaining: 15.8s\n",
      "69:\tlearn: 2.0958785\ttotal: 1.18s\tremaining: 15.7s\n",
      "70:\tlearn: 2.0956003\ttotal: 1.2s\tremaining: 15.7s\n",
      "71:\tlearn: 2.0955235\ttotal: 1.21s\tremaining: 15.6s\n",
      "72:\tlearn: 2.0950717\ttotal: 1.23s\tremaining: 15.6s\n",
      "73:\tlearn: 2.0929360\ttotal: 1.24s\tremaining: 15.6s\n",
      "74:\tlearn: 2.0923191\ttotal: 1.26s\tremaining: 15.5s\n",
      "75:\tlearn: 2.0911181\ttotal: 1.27s\tremaining: 15.5s\n",
      "76:\tlearn: 2.0896094\ttotal: 1.29s\tremaining: 15.5s\n",
      "77:\tlearn: 2.0892318\ttotal: 1.31s\tremaining: 15.4s\n",
      "78:\tlearn: 2.0885337\ttotal: 1.32s\tremaining: 15.4s\n",
      "79:\tlearn: 2.0879237\ttotal: 1.34s\tremaining: 15.4s\n",
      "80:\tlearn: 2.0859293\ttotal: 1.35s\tremaining: 15.4s\n",
      "81:\tlearn: 2.0787234\ttotal: 1.37s\tremaining: 15.3s\n",
      "82:\tlearn: 2.0782299\ttotal: 1.39s\tremaining: 15.3s\n",
      "83:\tlearn: 2.0779779\ttotal: 1.4s\tremaining: 15.3s\n",
      "84:\tlearn: 2.0745414\ttotal: 1.42s\tremaining: 15.3s\n",
      "85:\tlearn: 2.0742712\ttotal: 1.43s\tremaining: 15.2s\n",
      "86:\tlearn: 2.0739254\ttotal: 1.45s\tremaining: 15.2s\n",
      "87:\tlearn: 2.0728982\ttotal: 1.47s\tremaining: 15.2s\n",
      "88:\tlearn: 2.0721155\ttotal: 1.48s\tremaining: 15.1s\n",
      "89:\tlearn: 2.0708139\ttotal: 1.5s\tremaining: 15.1s\n",
      "90:\tlearn: 2.0706068\ttotal: 1.51s\tremaining: 15.1s\n",
      "91:\tlearn: 2.0698130\ttotal: 1.52s\tremaining: 15.1s\n",
      "92:\tlearn: 2.0698078\ttotal: 1.54s\tremaining: 15s\n",
      "93:\tlearn: 2.0691319\ttotal: 1.56s\tremaining: 15s\n",
      "94:\tlearn: 2.0683299\ttotal: 1.57s\tremaining: 15s\n",
      "95:\tlearn: 2.0682265\ttotal: 1.59s\tremaining: 15s\n",
      "96:\tlearn: 2.0681748\ttotal: 1.6s\tremaining: 14.9s\n",
      "97:\tlearn: 2.0677758\ttotal: 1.62s\tremaining: 14.9s\n",
      "98:\tlearn: 2.0604453\ttotal: 1.63s\tremaining: 14.8s\n",
      "99:\tlearn: 2.0601571\ttotal: 1.65s\tremaining: 14.8s\n",
      "100:\tlearn: 2.0599629\ttotal: 1.66s\tremaining: 14.8s\n",
      "101:\tlearn: 2.0581087\ttotal: 1.67s\tremaining: 14.7s\n",
      "102:\tlearn: 2.0574210\ttotal: 1.69s\tremaining: 14.7s\n",
      "103:\tlearn: 2.0495505\ttotal: 1.7s\tremaining: 14.7s\n",
      "104:\tlearn: 2.0491661\ttotal: 1.72s\tremaining: 14.6s\n",
      "105:\tlearn: 2.0488888\ttotal: 1.73s\tremaining: 14.6s\n",
      "106:\tlearn: 2.0488297\ttotal: 1.75s\tremaining: 14.6s\n",
      "107:\tlearn: 2.0457459\ttotal: 1.76s\tremaining: 14.5s\n",
      "108:\tlearn: 2.0451842\ttotal: 1.77s\tremaining: 14.5s\n",
      "109:\tlearn: 2.0449781\ttotal: 1.79s\tremaining: 14.5s\n",
      "110:\tlearn: 2.0446407\ttotal: 1.8s\tremaining: 14.4s\n",
      "111:\tlearn: 2.0443334\ttotal: 1.82s\tremaining: 14.4s\n",
      "112:\tlearn: 2.0441884\ttotal: 1.83s\tremaining: 14.4s\n",
      "113:\tlearn: 2.0441142\ttotal: 1.84s\tremaining: 14.3s\n",
      "114:\tlearn: 2.0440816\ttotal: 1.86s\tremaining: 14.3s\n",
      "115:\tlearn: 2.0427003\ttotal: 1.87s\tremaining: 14.3s\n",
      "116:\tlearn: 2.0420012\ttotal: 1.88s\tremaining: 14.2s\n",
      "117:\tlearn: 2.0416852\ttotal: 1.9s\tremaining: 14.2s\n",
      "118:\tlearn: 2.0415388\ttotal: 1.91s\tremaining: 14.1s\n",
      "119:\tlearn: 2.0321863\ttotal: 1.92s\tremaining: 14.1s\n",
      "120:\tlearn: 2.0288617\ttotal: 1.94s\tremaining: 14.1s\n",
      "121:\tlearn: 2.0276089\ttotal: 1.95s\tremaining: 14.1s\n",
      "122:\tlearn: 2.0240351\ttotal: 1.97s\tremaining: 14.1s\n",
      "123:\tlearn: 2.0236964\ttotal: 1.98s\tremaining: 14s\n",
      "124:\tlearn: 2.0190659\ttotal: 2s\tremaining: 14s\n",
      "125:\tlearn: 2.0180172\ttotal: 2.01s\tremaining: 14s\n",
      "126:\tlearn: 2.0172872\ttotal: 2.02s\tremaining: 13.9s\n",
      "127:\tlearn: 2.0140679\ttotal: 2.04s\tremaining: 13.9s\n",
      "128:\tlearn: 2.0081441\ttotal: 2.05s\tremaining: 13.9s\n",
      "129:\tlearn: 2.0063871\ttotal: 2.07s\tremaining: 13.8s\n",
      "130:\tlearn: 2.0048432\ttotal: 2.08s\tremaining: 13.8s\n",
      "131:\tlearn: 1.9997133\ttotal: 2.1s\tremaining: 13.8s\n",
      "132:\tlearn: 1.9987263\ttotal: 2.11s\tremaining: 13.8s\n",
      "133:\tlearn: 1.9972355\ttotal: 2.12s\tremaining: 13.7s\n",
      "134:\tlearn: 1.9967367\ttotal: 2.14s\tremaining: 13.7s\n",
      "135:\tlearn: 1.9940983\ttotal: 2.15s\tremaining: 13.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136:\tlearn: 1.9917453\ttotal: 2.17s\tremaining: 13.6s\n",
      "137:\tlearn: 1.9899005\ttotal: 2.18s\tremaining: 13.6s\n",
      "138:\tlearn: 1.9891141\ttotal: 2.2s\tremaining: 13.6s\n",
      "139:\tlearn: 1.9872972\ttotal: 2.21s\tremaining: 13.6s\n",
      "140:\tlearn: 1.9856725\ttotal: 2.23s\tremaining: 13.6s\n",
      "141:\tlearn: 1.9829191\ttotal: 2.24s\tremaining: 13.5s\n",
      "142:\tlearn: 1.9779575\ttotal: 2.25s\tremaining: 13.5s\n",
      "143:\tlearn: 1.9751523\ttotal: 2.27s\tremaining: 13.5s\n",
      "144:\tlearn: 1.9706630\ttotal: 2.28s\tremaining: 13.5s\n",
      "145:\tlearn: 1.9671126\ttotal: 2.29s\tremaining: 13.4s\n",
      "146:\tlearn: 1.9652524\ttotal: 2.31s\tremaining: 13.4s\n",
      "147:\tlearn: 1.9619327\ttotal: 2.32s\tremaining: 13.4s\n",
      "148:\tlearn: 1.9601310\ttotal: 2.33s\tremaining: 13.3s\n",
      "149:\tlearn: 1.9589545\ttotal: 2.35s\tremaining: 13.3s\n",
      "150:\tlearn: 1.9551591\ttotal: 2.36s\tremaining: 13.3s\n",
      "151:\tlearn: 1.9506114\ttotal: 2.38s\tremaining: 13.3s\n",
      "152:\tlearn: 1.9483762\ttotal: 2.39s\tremaining: 13.2s\n",
      "153:\tlearn: 1.9446391\ttotal: 2.41s\tremaining: 13.2s\n",
      "154:\tlearn: 1.9417674\ttotal: 2.42s\tremaining: 13.2s\n",
      "155:\tlearn: 1.9389325\ttotal: 2.44s\tremaining: 13.2s\n",
      "156:\tlearn: 1.9388090\ttotal: 2.45s\tremaining: 13.2s\n",
      "157:\tlearn: 1.9388017\ttotal: 2.46s\tremaining: 13.1s\n",
      "158:\tlearn: 1.9373594\ttotal: 2.48s\tremaining: 13.1s\n",
      "159:\tlearn: 1.9359200\ttotal: 2.49s\tremaining: 13.1s\n",
      "160:\tlearn: 1.9345239\ttotal: 2.5s\tremaining: 13s\n",
      "161:\tlearn: 1.9341969\ttotal: 2.52s\tremaining: 13s\n",
      "162:\tlearn: 1.9327716\ttotal: 2.53s\tremaining: 13s\n",
      "163:\tlearn: 1.9301553\ttotal: 2.54s\tremaining: 13s\n",
      "164:\tlearn: 1.9283528\ttotal: 2.56s\tremaining: 13s\n",
      "165:\tlearn: 1.9280087\ttotal: 2.57s\tremaining: 12.9s\n",
      "166:\tlearn: 1.9258202\ttotal: 2.59s\tremaining: 12.9s\n",
      "167:\tlearn: 1.9249009\ttotal: 2.6s\tremaining: 12.9s\n",
      "168:\tlearn: 1.9233442\ttotal: 2.62s\tremaining: 12.9s\n",
      "169:\tlearn: 1.9214365\ttotal: 2.63s\tremaining: 12.9s\n",
      "170:\tlearn: 1.9195310\ttotal: 2.65s\tremaining: 12.8s\n",
      "171:\tlearn: 1.9149621\ttotal: 2.66s\tremaining: 12.8s\n",
      "172:\tlearn: 1.9141947\ttotal: 2.67s\tremaining: 12.8s\n",
      "173:\tlearn: 1.9137737\ttotal: 2.69s\tremaining: 12.8s\n",
      "174:\tlearn: 1.9114799\ttotal: 2.7s\tremaining: 12.7s\n",
      "175:\tlearn: 1.9103112\ttotal: 2.71s\tremaining: 12.7s\n",
      "176:\tlearn: 1.9091528\ttotal: 2.73s\tremaining: 12.7s\n",
      "177:\tlearn: 1.9057268\ttotal: 2.74s\tremaining: 12.7s\n",
      "178:\tlearn: 1.9053700\ttotal: 2.76s\tremaining: 12.6s\n",
      "179:\tlearn: 1.9045469\ttotal: 2.77s\tremaining: 12.6s\n",
      "180:\tlearn: 1.9025230\ttotal: 2.78s\tremaining: 12.6s\n",
      "181:\tlearn: 1.9015473\ttotal: 2.8s\tremaining: 12.6s\n",
      "182:\tlearn: 1.9007332\ttotal: 2.81s\tremaining: 12.6s\n",
      "183:\tlearn: 1.8995969\ttotal: 2.83s\tremaining: 12.5s\n",
      "184:\tlearn: 1.8994565\ttotal: 2.84s\tremaining: 12.5s\n",
      "185:\tlearn: 1.8989545\ttotal: 2.85s\tremaining: 12.5s\n",
      "186:\tlearn: 1.8987218\ttotal: 2.87s\tremaining: 12.5s\n",
      "187:\tlearn: 1.8971754\ttotal: 2.88s\tremaining: 12.4s\n",
      "188:\tlearn: 1.8963783\ttotal: 2.89s\tremaining: 12.4s\n",
      "189:\tlearn: 1.8944328\ttotal: 2.91s\tremaining: 12.4s\n",
      "190:\tlearn: 1.8932171\ttotal: 2.92s\tremaining: 12.4s\n",
      "191:\tlearn: 1.8930453\ttotal: 2.93s\tremaining: 12.3s\n",
      "192:\tlearn: 1.8929188\ttotal: 2.95s\tremaining: 12.3s\n",
      "193:\tlearn: 1.8921292\ttotal: 2.96s\tremaining: 12.3s\n",
      "194:\tlearn: 1.8914647\ttotal: 2.98s\tremaining: 12.3s\n",
      "195:\tlearn: 1.8910278\ttotal: 2.99s\tremaining: 12.3s\n",
      "196:\tlearn: 1.8900427\ttotal: 3s\tremaining: 12.2s\n",
      "197:\tlearn: 1.8895467\ttotal: 3.02s\tremaining: 12.2s\n",
      "198:\tlearn: 1.8888445\ttotal: 3.04s\tremaining: 12.2s\n",
      "199:\tlearn: 1.8880036\ttotal: 3.05s\tremaining: 12.2s\n",
      "200:\tlearn: 1.8877507\ttotal: 3.06s\tremaining: 12.2s\n",
      "201:\tlearn: 1.8867576\ttotal: 3.08s\tremaining: 12.2s\n",
      "202:\tlearn: 1.8863023\ttotal: 3.09s\tremaining: 12.1s\n",
      "203:\tlearn: 1.8835915\ttotal: 3.11s\tremaining: 12.1s\n",
      "204:\tlearn: 1.8820079\ttotal: 3.12s\tremaining: 12.1s\n",
      "205:\tlearn: 1.8809665\ttotal: 3.13s\tremaining: 12.1s\n",
      "206:\tlearn: 1.8801201\ttotal: 3.15s\tremaining: 12.1s\n",
      "207:\tlearn: 1.8790738\ttotal: 3.16s\tremaining: 12s\n",
      "208:\tlearn: 1.8777644\ttotal: 3.18s\tremaining: 12s\n",
      "209:\tlearn: 1.8752109\ttotal: 3.19s\tremaining: 12s\n",
      "210:\tlearn: 1.8732623\ttotal: 3.2s\tremaining: 12s\n",
      "211:\tlearn: 1.8716975\ttotal: 3.22s\tremaining: 12s\n",
      "212:\tlearn: 1.8703801\ttotal: 3.23s\tremaining: 11.9s\n",
      "213:\tlearn: 1.8693834\ttotal: 3.25s\tremaining: 11.9s\n",
      "214:\tlearn: 1.8685898\ttotal: 3.28s\tremaining: 12s\n",
      "215:\tlearn: 1.8672259\ttotal: 3.29s\tremaining: 11.9s\n",
      "216:\tlearn: 1.8672080\ttotal: 3.3s\tremaining: 11.9s\n",
      "217:\tlearn: 1.8671844\ttotal: 3.32s\tremaining: 11.9s\n",
      "218:\tlearn: 1.8668864\ttotal: 3.33s\tremaining: 11.9s\n",
      "219:\tlearn: 1.8663534\ttotal: 3.34s\tremaining: 11.9s\n",
      "220:\tlearn: 1.8658230\ttotal: 3.36s\tremaining: 11.8s\n",
      "221:\tlearn: 1.8649730\ttotal: 3.37s\tremaining: 11.8s\n",
      "222:\tlearn: 1.8626805\ttotal: 3.39s\tremaining: 11.8s\n",
      "223:\tlearn: 1.8616880\ttotal: 3.4s\tremaining: 11.8s\n",
      "224:\tlearn: 1.8610799\ttotal: 3.41s\tremaining: 11.8s\n",
      "225:\tlearn: 1.8591019\ttotal: 3.43s\tremaining: 11.7s\n",
      "226:\tlearn: 1.8581987\ttotal: 3.44s\tremaining: 11.7s\n",
      "227:\tlearn: 1.8578647\ttotal: 3.46s\tremaining: 11.7s\n",
      "228:\tlearn: 1.8573248\ttotal: 3.47s\tremaining: 11.7s\n",
      "229:\tlearn: 1.8571350\ttotal: 3.49s\tremaining: 11.7s\n",
      "230:\tlearn: 1.8566375\ttotal: 3.5s\tremaining: 11.7s\n",
      "231:\tlearn: 1.8559832\ttotal: 3.52s\tremaining: 11.6s\n",
      "232:\tlearn: 1.8554336\ttotal: 3.53s\tremaining: 11.6s\n",
      "233:\tlearn: 1.8537901\ttotal: 3.54s\tremaining: 11.6s\n",
      "234:\tlearn: 1.8535463\ttotal: 3.56s\tremaining: 11.6s\n",
      "235:\tlearn: 1.8534159\ttotal: 3.57s\tremaining: 11.6s\n",
      "236:\tlearn: 1.8522909\ttotal: 3.58s\tremaining: 11.5s\n",
      "237:\tlearn: 1.8516133\ttotal: 3.6s\tremaining: 11.5s\n",
      "238:\tlearn: 1.8512367\ttotal: 3.61s\tremaining: 11.5s\n",
      "239:\tlearn: 1.8509131\ttotal: 3.63s\tremaining: 11.5s\n",
      "240:\tlearn: 1.8502461\ttotal: 3.64s\tremaining: 11.5s\n",
      "241:\tlearn: 1.8495338\ttotal: 3.65s\tremaining: 11.4s\n",
      "242:\tlearn: 1.8479457\ttotal: 3.67s\tremaining: 11.4s\n",
      "243:\tlearn: 1.8472134\ttotal: 3.68s\tremaining: 11.4s\n",
      "244:\tlearn: 1.8470181\ttotal: 3.7s\tremaining: 11.4s\n",
      "245:\tlearn: 1.8462283\ttotal: 3.71s\tremaining: 11.4s\n",
      "246:\tlearn: 1.8452517\ttotal: 3.72s\tremaining: 11.4s\n",
      "247:\tlearn: 1.8443376\ttotal: 3.74s\tremaining: 11.3s\n",
      "248:\tlearn: 1.8435179\ttotal: 3.75s\tremaining: 11.3s\n",
      "249:\tlearn: 1.8434509\ttotal: 3.77s\tremaining: 11.3s\n",
      "250:\tlearn: 1.8425094\ttotal: 3.78s\tremaining: 11.3s\n",
      "251:\tlearn: 1.8419361\ttotal: 3.79s\tremaining: 11.3s\n",
      "252:\tlearn: 1.8414748\ttotal: 3.81s\tremaining: 11.2s\n",
      "253:\tlearn: 1.8400368\ttotal: 3.82s\tremaining: 11.2s\n",
      "254:\tlearn: 1.8398776\ttotal: 3.84s\tremaining: 11.2s\n",
      "255:\tlearn: 1.8397375\ttotal: 3.85s\tremaining: 11.2s\n",
      "256:\tlearn: 1.8395893\ttotal: 3.86s\tremaining: 11.2s\n",
      "257:\tlearn: 1.8393136\ttotal: 3.88s\tremaining: 11.2s\n",
      "258:\tlearn: 1.8392001\ttotal: 3.9s\tremaining: 11.1s\n",
      "259:\tlearn: 1.8381785\ttotal: 3.91s\tremaining: 11.1s\n",
      "260:\tlearn: 1.8371989\ttotal: 3.92s\tremaining: 11.1s\n",
      "261:\tlearn: 1.8365953\ttotal: 3.94s\tremaining: 11.1s\n",
      "262:\tlearn: 1.8357134\ttotal: 3.95s\tremaining: 11.1s\n",
      "263:\tlearn: 1.8352408\ttotal: 3.97s\tremaining: 11.1s\n",
      "264:\tlearn: 1.8340000\ttotal: 3.98s\tremaining: 11s\n",
      "265:\tlearn: 1.8330499\ttotal: 4s\tremaining: 11s\n",
      "266:\tlearn: 1.8327918\ttotal: 4.01s\tremaining: 11s\n",
      "267:\tlearn: 1.8327817\ttotal: 4.03s\tremaining: 11s\n",
      "268:\tlearn: 1.8313451\ttotal: 4.04s\tremaining: 11s\n",
      "269:\tlearn: 1.8305117\ttotal: 4.05s\tremaining: 11s\n",
      "270:\tlearn: 1.8295019\ttotal: 4.07s\tremaining: 10.9s\n",
      "271:\tlearn: 1.8287796\ttotal: 4.08s\tremaining: 10.9s\n",
      "272:\tlearn: 1.8281713\ttotal: 4.09s\tremaining: 10.9s\n",
      "273:\tlearn: 1.8268401\ttotal: 4.11s\tremaining: 10.9s\n",
      "274:\tlearn: 1.8245490\ttotal: 4.13s\tremaining: 10.9s\n",
      "275:\tlearn: 1.8233848\ttotal: 4.14s\tremaining: 10.9s\n",
      "276:\tlearn: 1.8229835\ttotal: 4.16s\tremaining: 10.8s\n",
      "277:\tlearn: 1.8227998\ttotal: 4.17s\tremaining: 10.8s\n",
      "278:\tlearn: 1.8225979\ttotal: 4.18s\tremaining: 10.8s\n",
      "279:\tlearn: 1.8220904\ttotal: 4.2s\tremaining: 10.8s\n",
      "280:\tlearn: 1.8220166\ttotal: 4.21s\tremaining: 10.8s\n",
      "281:\tlearn: 1.8215671\ttotal: 4.22s\tremaining: 10.8s\n",
      "282:\tlearn: 1.8207528\ttotal: 4.24s\tremaining: 10.7s\n",
      "283:\tlearn: 1.8204759\ttotal: 4.25s\tremaining: 10.7s\n",
      "284:\tlearn: 1.8203249\ttotal: 4.26s\tremaining: 10.7s\n",
      "285:\tlearn: 1.8196582\ttotal: 4.28s\tremaining: 10.7s\n",
      "286:\tlearn: 1.8188473\ttotal: 4.29s\tremaining: 10.7s\n",
      "287:\tlearn: 1.8188291\ttotal: 4.31s\tremaining: 10.6s\n",
      "288:\tlearn: 1.8186903\ttotal: 4.32s\tremaining: 10.6s\n",
      "289:\tlearn: 1.8183928\ttotal: 4.34s\tremaining: 10.6s\n",
      "290:\tlearn: 1.8177073\ttotal: 4.35s\tremaining: 10.6s\n",
      "291:\tlearn: 1.8176749\ttotal: 4.37s\tremaining: 10.6s\n",
      "292:\tlearn: 1.8176591\ttotal: 4.38s\tremaining: 10.6s\n",
      "293:\tlearn: 1.8170325\ttotal: 4.39s\tremaining: 10.5s\n",
      "294:\tlearn: 1.8168994\ttotal: 4.41s\tremaining: 10.5s\n",
      "295:\tlearn: 1.8168742\ttotal: 4.42s\tremaining: 10.5s\n",
      "296:\tlearn: 1.8168717\ttotal: 4.43s\tremaining: 10.5s\n",
      "297:\tlearn: 1.8168413\ttotal: 4.45s\tremaining: 10.5s\n",
      "298:\tlearn: 1.8157356\ttotal: 4.46s\tremaining: 10.5s\n",
      "299:\tlearn: 1.8155865\ttotal: 4.48s\tremaining: 10.4s\n",
      "300:\tlearn: 1.8154606\ttotal: 4.49s\tremaining: 10.4s\n",
      "301:\tlearn: 1.8154045\ttotal: 4.51s\tremaining: 10.4s\n",
      "302:\tlearn: 1.8152173\ttotal: 4.52s\tremaining: 10.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303:\tlearn: 1.8149142\ttotal: 4.54s\tremaining: 10.4s\n",
      "304:\tlearn: 1.8142967\ttotal: 4.55s\tremaining: 10.4s\n",
      "305:\tlearn: 1.8142815\ttotal: 4.57s\tremaining: 10.4s\n",
      "306:\tlearn: 1.8136887\ttotal: 4.58s\tremaining: 10.3s\n",
      "307:\tlearn: 1.8128219\ttotal: 4.59s\tremaining: 10.3s\n",
      "308:\tlearn: 1.8113340\ttotal: 4.61s\tremaining: 10.3s\n",
      "309:\tlearn: 1.8107824\ttotal: 4.62s\tremaining: 10.3s\n",
      "310:\tlearn: 1.8100839\ttotal: 4.63s\tremaining: 10.3s\n",
      "311:\tlearn: 1.8093794\ttotal: 4.65s\tremaining: 10.3s\n",
      "312:\tlearn: 1.8084826\ttotal: 4.66s\tremaining: 10.2s\n",
      "313:\tlearn: 1.8082373\ttotal: 4.67s\tremaining: 10.2s\n",
      "314:\tlearn: 1.8077990\ttotal: 4.69s\tremaining: 10.2s\n",
      "315:\tlearn: 1.8077766\ttotal: 4.7s\tremaining: 10.2s\n",
      "316:\tlearn: 1.8069710\ttotal: 4.72s\tremaining: 10.2s\n",
      "317:\tlearn: 1.8059846\ttotal: 4.73s\tremaining: 10.1s\n",
      "318:\tlearn: 1.8049258\ttotal: 4.75s\tremaining: 10.1s\n",
      "319:\tlearn: 1.8043324\ttotal: 4.76s\tremaining: 10.1s\n",
      "320:\tlearn: 1.8034837\ttotal: 4.78s\tremaining: 10.1s\n",
      "321:\tlearn: 1.8029842\ttotal: 4.79s\tremaining: 10.1s\n",
      "322:\tlearn: 1.8024648\ttotal: 4.8s\tremaining: 10.1s\n",
      "323:\tlearn: 1.8021273\ttotal: 4.82s\tremaining: 10.1s\n",
      "324:\tlearn: 1.8021262\ttotal: 4.83s\tremaining: 10s\n",
      "325:\tlearn: 1.8021194\ttotal: 4.85s\tremaining: 10s\n",
      "326:\tlearn: 1.8021106\ttotal: 4.86s\tremaining: 10s\n",
      "327:\tlearn: 1.8016701\ttotal: 4.87s\tremaining: 9.98s\n",
      "328:\tlearn: 1.8007070\ttotal: 4.89s\tremaining: 9.97s\n",
      "329:\tlearn: 1.7993552\ttotal: 4.9s\tremaining: 9.95s\n",
      "330:\tlearn: 1.7984531\ttotal: 4.92s\tremaining: 9.94s\n",
      "331:\tlearn: 1.7980068\ttotal: 4.93s\tremaining: 9.92s\n",
      "332:\tlearn: 1.7966227\ttotal: 4.94s\tremaining: 9.9s\n",
      "333:\tlearn: 1.7965378\ttotal: 4.96s\tremaining: 9.89s\n",
      "334:\tlearn: 1.7954117\ttotal: 4.97s\tremaining: 9.87s\n",
      "335:\tlearn: 1.7949064\ttotal: 4.99s\tremaining: 9.86s\n",
      "336:\tlearn: 1.7943672\ttotal: 5s\tremaining: 9.84s\n",
      "337:\tlearn: 1.7933856\ttotal: 5.01s\tremaining: 9.82s\n",
      "338:\tlearn: 1.7930651\ttotal: 5.03s\tremaining: 9.81s\n",
      "339:\tlearn: 1.7929690\ttotal: 5.04s\tremaining: 9.79s\n",
      "340:\tlearn: 1.7927526\ttotal: 5.06s\tremaining: 9.78s\n",
      "341:\tlearn: 1.7925562\ttotal: 5.07s\tremaining: 9.76s\n",
      "342:\tlearn: 1.7923408\ttotal: 5.09s\tremaining: 9.74s\n",
      "343:\tlearn: 1.7920615\ttotal: 5.1s\tremaining: 9.73s\n",
      "344:\tlearn: 1.7909520\ttotal: 5.12s\tremaining: 9.71s\n",
      "345:\tlearn: 1.7901912\ttotal: 5.13s\tremaining: 9.7s\n",
      "346:\tlearn: 1.7892391\ttotal: 5.14s\tremaining: 9.68s\n",
      "347:\tlearn: 1.7885900\ttotal: 5.16s\tremaining: 9.66s\n",
      "348:\tlearn: 1.7881704\ttotal: 5.17s\tremaining: 9.65s\n",
      "349:\tlearn: 1.7873722\ttotal: 5.19s\tremaining: 9.64s\n",
      "350:\tlearn: 1.7872712\ttotal: 5.2s\tremaining: 9.62s\n",
      "351:\tlearn: 1.7872091\ttotal: 5.22s\tremaining: 9.61s\n",
      "352:\tlearn: 1.7872072\ttotal: 5.23s\tremaining: 9.59s\n",
      "353:\tlearn: 1.7872041\ttotal: 5.25s\tremaining: 9.57s\n",
      "354:\tlearn: 1.7871028\ttotal: 5.26s\tremaining: 9.56s\n",
      "355:\tlearn: 1.7871004\ttotal: 5.27s\tremaining: 9.54s\n",
      "356:\tlearn: 1.7870983\ttotal: 5.29s\tremaining: 9.52s\n",
      "357:\tlearn: 1.7859547\ttotal: 5.3s\tremaining: 9.51s\n",
      "358:\tlearn: 1.7852089\ttotal: 5.32s\tremaining: 9.49s\n",
      "359:\tlearn: 1.7848231\ttotal: 5.33s\tremaining: 9.47s\n",
      "360:\tlearn: 1.7846729\ttotal: 5.34s\tremaining: 9.46s\n",
      "361:\tlearn: 1.7842862\ttotal: 5.36s\tremaining: 9.44s\n",
      "362:\tlearn: 1.7842848\ttotal: 5.37s\tremaining: 9.42s\n",
      "363:\tlearn: 1.7842840\ttotal: 5.38s\tremaining: 9.41s\n",
      "364:\tlearn: 1.7842831\ttotal: 5.4s\tremaining: 9.39s\n",
      "365:\tlearn: 1.7842827\ttotal: 5.41s\tremaining: 9.38s\n",
      "366:\tlearn: 1.7842823\ttotal: 5.43s\tremaining: 9.36s\n",
      "367:\tlearn: 1.7841609\ttotal: 5.44s\tremaining: 9.35s\n",
      "368:\tlearn: 1.7841602\ttotal: 5.46s\tremaining: 9.33s\n",
      "369:\tlearn: 1.7841600\ttotal: 5.47s\tremaining: 9.31s\n",
      "370:\tlearn: 1.7841593\ttotal: 5.48s\tremaining: 9.3s\n",
      "371:\tlearn: 1.7841592\ttotal: 5.5s\tremaining: 9.28s\n",
      "372:\tlearn: 1.7841550\ttotal: 5.51s\tremaining: 9.26s\n",
      "373:\tlearn: 1.7840570\ttotal: 5.52s\tremaining: 9.25s\n",
      "374:\tlearn: 1.7840477\ttotal: 5.54s\tremaining: 9.23s\n",
      "375:\tlearn: 1.7840472\ttotal: 5.55s\tremaining: 9.21s\n",
      "376:\tlearn: 1.7840469\ttotal: 5.57s\tremaining: 9.2s\n",
      "377:\tlearn: 1.7831453\ttotal: 5.58s\tremaining: 9.18s\n",
      "378:\tlearn: 1.7831424\ttotal: 5.59s\tremaining: 9.17s\n",
      "379:\tlearn: 1.7830564\ttotal: 5.61s\tremaining: 9.15s\n",
      "380:\tlearn: 1.7829583\ttotal: 5.63s\tremaining: 9.14s\n",
      "381:\tlearn: 1.7811121\ttotal: 5.64s\tremaining: 9.13s\n",
      "382:\tlearn: 1.7809592\ttotal: 5.65s\tremaining: 9.11s\n",
      "383:\tlearn: 1.7803724\ttotal: 5.67s\tremaining: 9.09s\n",
      "384:\tlearn: 1.7799479\ttotal: 5.68s\tremaining: 9.08s\n",
      "385:\tlearn: 1.7797670\ttotal: 5.7s\tremaining: 9.06s\n",
      "386:\tlearn: 1.7791005\ttotal: 5.71s\tremaining: 9.04s\n",
      "387:\tlearn: 1.7790908\ttotal: 5.72s\tremaining: 9.03s\n",
      "388:\tlearn: 1.7790545\ttotal: 5.74s\tremaining: 9.01s\n",
      "389:\tlearn: 1.7789998\ttotal: 5.75s\tremaining: 8.99s\n",
      "390:\tlearn: 1.7770243\ttotal: 5.76s\tremaining: 8.98s\n",
      "391:\tlearn: 1.7770032\ttotal: 5.78s\tremaining: 8.96s\n",
      "392:\tlearn: 1.7762745\ttotal: 5.79s\tremaining: 8.94s\n",
      "393:\tlearn: 1.7762009\ttotal: 5.8s\tremaining: 8.93s\n",
      "394:\tlearn: 1.7749342\ttotal: 5.82s\tremaining: 8.92s\n",
      "395:\tlearn: 1.7740262\ttotal: 5.83s\tremaining: 8.9s\n",
      "396:\tlearn: 1.7725883\ttotal: 5.85s\tremaining: 8.88s\n",
      "397:\tlearn: 1.7717568\ttotal: 5.86s\tremaining: 8.87s\n",
      "398:\tlearn: 1.7716379\ttotal: 5.88s\tremaining: 8.85s\n",
      "399:\tlearn: 1.7715810\ttotal: 5.89s\tremaining: 8.83s\n",
      "400:\tlearn: 1.7712219\ttotal: 5.9s\tremaining: 8.82s\n",
      "401:\tlearn: 1.7711951\ttotal: 5.92s\tremaining: 8.8s\n",
      "402:\tlearn: 1.7699618\ttotal: 5.93s\tremaining: 8.78s\n",
      "403:\tlearn: 1.7697984\ttotal: 5.94s\tremaining: 8.77s\n",
      "404:\tlearn: 1.7697416\ttotal: 5.96s\tremaining: 8.75s\n",
      "405:\tlearn: 1.7697218\ttotal: 5.97s\tremaining: 8.74s\n",
      "406:\tlearn: 1.7697144\ttotal: 5.99s\tremaining: 8.72s\n",
      "407:\tlearn: 1.7696973\ttotal: 6s\tremaining: 8.71s\n",
      "408:\tlearn: 1.7693903\ttotal: 6.01s\tremaining: 8.69s\n",
      "409:\tlearn: 1.7687719\ttotal: 6.03s\tremaining: 8.68s\n",
      "410:\tlearn: 1.7687326\ttotal: 6.05s\tremaining: 8.66s\n",
      "411:\tlearn: 1.7685306\ttotal: 6.06s\tremaining: 8.65s\n",
      "412:\tlearn: 1.7676306\ttotal: 6.07s\tremaining: 8.63s\n",
      "413:\tlearn: 1.7670521\ttotal: 6.09s\tremaining: 8.62s\n",
      "414:\tlearn: 1.7663850\ttotal: 6.1s\tremaining: 8.6s\n",
      "415:\tlearn: 1.7663844\ttotal: 6.12s\tremaining: 8.59s\n",
      "416:\tlearn: 1.7663181\ttotal: 6.13s\tremaining: 8.57s\n",
      "417:\tlearn: 1.7662542\ttotal: 6.15s\tremaining: 8.56s\n",
      "418:\tlearn: 1.7657844\ttotal: 6.16s\tremaining: 8.54s\n",
      "419:\tlearn: 1.7651466\ttotal: 6.17s\tremaining: 8.53s\n",
      "420:\tlearn: 1.7651386\ttotal: 6.19s\tremaining: 8.51s\n",
      "421:\tlearn: 1.7651364\ttotal: 6.2s\tremaining: 8.49s\n",
      "422:\tlearn: 1.7651262\ttotal: 6.21s\tremaining: 8.48s\n",
      "423:\tlearn: 1.7643020\ttotal: 6.23s\tremaining: 8.46s\n",
      "424:\tlearn: 1.7642272\ttotal: 6.25s\tremaining: 8.45s\n",
      "425:\tlearn: 1.7641283\ttotal: 6.26s\tremaining: 8.44s\n",
      "426:\tlearn: 1.7639365\ttotal: 6.28s\tremaining: 8.42s\n",
      "427:\tlearn: 1.7638456\ttotal: 6.29s\tremaining: 8.4s\n",
      "428:\tlearn: 1.7637623\ttotal: 6.3s\tremaining: 8.39s\n",
      "429:\tlearn: 1.7635623\ttotal: 6.32s\tremaining: 8.37s\n",
      "430:\tlearn: 1.7634931\ttotal: 6.33s\tremaining: 8.36s\n",
      "431:\tlearn: 1.7633909\ttotal: 6.34s\tremaining: 8.34s\n",
      "432:\tlearn: 1.7631527\ttotal: 6.36s\tremaining: 8.32s\n",
      "433:\tlearn: 1.7628176\ttotal: 6.37s\tremaining: 8.31s\n",
      "434:\tlearn: 1.7625110\ttotal: 6.38s\tremaining: 8.29s\n",
      "435:\tlearn: 1.7624420\ttotal: 6.4s\tremaining: 8.28s\n",
      "436:\tlearn: 1.7624337\ttotal: 6.41s\tremaining: 8.26s\n",
      "437:\tlearn: 1.7624204\ttotal: 6.42s\tremaining: 8.24s\n",
      "438:\tlearn: 1.7623884\ttotal: 6.44s\tremaining: 8.23s\n",
      "439:\tlearn: 1.7623440\ttotal: 6.45s\tremaining: 8.21s\n",
      "440:\tlearn: 1.7623387\ttotal: 6.47s\tremaining: 8.2s\n",
      "441:\tlearn: 1.7623383\ttotal: 6.48s\tremaining: 8.18s\n",
      "442:\tlearn: 1.7622978\ttotal: 6.49s\tremaining: 8.16s\n",
      "443:\tlearn: 1.7618399\ttotal: 6.51s\tremaining: 8.15s\n",
      "444:\tlearn: 1.7617677\ttotal: 6.52s\tremaining: 8.13s\n",
      "445:\tlearn: 1.7616022\ttotal: 6.54s\tremaining: 8.12s\n",
      "446:\tlearn: 1.7615812\ttotal: 6.55s\tremaining: 8.1s\n",
      "447:\tlearn: 1.7615664\ttotal: 6.56s\tremaining: 8.09s\n",
      "448:\tlearn: 1.7615603\ttotal: 6.58s\tremaining: 8.07s\n",
      "449:\tlearn: 1.7603757\ttotal: 6.59s\tremaining: 8.05s\n",
      "450:\tlearn: 1.7601563\ttotal: 6.61s\tremaining: 8.04s\n",
      "451:\tlearn: 1.7599345\ttotal: 6.62s\tremaining: 8.02s\n",
      "452:\tlearn: 1.7596989\ttotal: 6.63s\tremaining: 8.01s\n",
      "453:\tlearn: 1.7595450\ttotal: 6.65s\tremaining: 7.99s\n",
      "454:\tlearn: 1.7592870\ttotal: 6.66s\tremaining: 7.98s\n",
      "455:\tlearn: 1.7589760\ttotal: 6.68s\tremaining: 7.97s\n",
      "456:\tlearn: 1.7586233\ttotal: 6.69s\tremaining: 7.95s\n",
      "457:\tlearn: 1.7584268\ttotal: 6.71s\tremaining: 7.93s\n",
      "458:\tlearn: 1.7584197\ttotal: 6.72s\tremaining: 7.92s\n",
      "459:\tlearn: 1.7584104\ttotal: 6.73s\tremaining: 7.9s\n",
      "460:\tlearn: 1.7584028\ttotal: 6.74s\tremaining: 7.89s\n",
      "461:\tlearn: 1.7582991\ttotal: 6.76s\tremaining: 7.87s\n",
      "462:\tlearn: 1.7575445\ttotal: 6.77s\tremaining: 7.86s\n",
      "463:\tlearn: 1.7569663\ttotal: 6.79s\tremaining: 7.84s\n",
      "464:\tlearn: 1.7569583\ttotal: 6.8s\tremaining: 7.82s\n",
      "465:\tlearn: 1.7568902\ttotal: 6.82s\tremaining: 7.81s\n",
      "466:\tlearn: 1.7565124\ttotal: 6.83s\tremaining: 7.79s\n",
      "467:\tlearn: 1.7564843\ttotal: 6.84s\tremaining: 7.78s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468:\tlearn: 1.7564034\ttotal: 6.86s\tremaining: 7.76s\n",
      "469:\tlearn: 1.7560449\ttotal: 6.87s\tremaining: 7.75s\n",
      "470:\tlearn: 1.7560442\ttotal: 6.89s\tremaining: 7.74s\n",
      "471:\tlearn: 1.7560136\ttotal: 6.9s\tremaining: 7.72s\n",
      "472:\tlearn: 1.7557695\ttotal: 6.92s\tremaining: 7.7s\n",
      "473:\tlearn: 1.7553185\ttotal: 6.93s\tremaining: 7.69s\n",
      "474:\tlearn: 1.7551719\ttotal: 6.94s\tremaining: 7.67s\n",
      "475:\tlearn: 1.7549059\ttotal: 6.96s\tremaining: 7.66s\n",
      "476:\tlearn: 1.7544021\ttotal: 6.97s\tremaining: 7.64s\n",
      "477:\tlearn: 1.7543940\ttotal: 6.99s\tremaining: 7.63s\n",
      "478:\tlearn: 1.7543767\ttotal: 7s\tremaining: 7.61s\n",
      "479:\tlearn: 1.7543757\ttotal: 7.01s\tremaining: 7.6s\n",
      "480:\tlearn: 1.7543752\ttotal: 7.03s\tremaining: 7.58s\n",
      "481:\tlearn: 1.7543742\ttotal: 7.04s\tremaining: 7.57s\n",
      "482:\tlearn: 1.7543295\ttotal: 7.06s\tremaining: 7.55s\n",
      "483:\tlearn: 1.7543187\ttotal: 7.07s\tremaining: 7.54s\n",
      "484:\tlearn: 1.7542598\ttotal: 7.08s\tremaining: 7.52s\n",
      "485:\tlearn: 1.7533241\ttotal: 7.1s\tremaining: 7.51s\n",
      "486:\tlearn: 1.7532856\ttotal: 7.11s\tremaining: 7.49s\n",
      "487:\tlearn: 1.7532782\ttotal: 7.13s\tremaining: 7.48s\n",
      "488:\tlearn: 1.7532523\ttotal: 7.14s\tremaining: 7.46s\n",
      "489:\tlearn: 1.7531935\ttotal: 7.16s\tremaining: 7.45s\n",
      "490:\tlearn: 1.7531780\ttotal: 7.17s\tremaining: 7.43s\n",
      "491:\tlearn: 1.7531712\ttotal: 7.18s\tremaining: 7.42s\n",
      "492:\tlearn: 1.7530885\ttotal: 7.2s\tremaining: 7.4s\n",
      "493:\tlearn: 1.7530527\ttotal: 7.21s\tremaining: 7.38s\n",
      "494:\tlearn: 1.7530367\ttotal: 7.22s\tremaining: 7.37s\n",
      "495:\tlearn: 1.7530244\ttotal: 7.24s\tremaining: 7.35s\n",
      "496:\tlearn: 1.7530172\ttotal: 7.25s\tremaining: 7.34s\n",
      "497:\tlearn: 1.7529024\ttotal: 7.26s\tremaining: 7.32s\n",
      "498:\tlearn: 1.7528579\ttotal: 7.28s\tremaining: 7.31s\n",
      "499:\tlearn: 1.7527873\ttotal: 7.29s\tremaining: 7.29s\n",
      "500:\tlearn: 1.7527537\ttotal: 7.31s\tremaining: 7.28s\n",
      "501:\tlearn: 1.7527166\ttotal: 7.32s\tremaining: 7.26s\n",
      "502:\tlearn: 1.7526143\ttotal: 7.34s\tremaining: 7.25s\n",
      "503:\tlearn: 1.7525823\ttotal: 7.35s\tremaining: 7.23s\n",
      "504:\tlearn: 1.7525746\ttotal: 7.36s\tremaining: 7.22s\n",
      "505:\tlearn: 1.7525700\ttotal: 7.38s\tremaining: 7.2s\n",
      "506:\tlearn: 1.7525700\ttotal: 7.39s\tremaining: 7.19s\n",
      "507:\tlearn: 1.7520058\ttotal: 7.4s\tremaining: 7.17s\n",
      "508:\tlearn: 1.7514377\ttotal: 7.42s\tremaining: 7.16s\n",
      "509:\tlearn: 1.7511650\ttotal: 7.43s\tremaining: 7.14s\n",
      "510:\tlearn: 1.7511319\ttotal: 7.45s\tremaining: 7.13s\n",
      "511:\tlearn: 1.7511302\ttotal: 7.46s\tremaining: 7.11s\n",
      "512:\tlearn: 1.7511299\ttotal: 7.47s\tremaining: 7.09s\n",
      "513:\tlearn: 1.7511205\ttotal: 7.49s\tremaining: 7.08s\n",
      "514:\tlearn: 1.7510868\ttotal: 7.5s\tremaining: 7.06s\n",
      "515:\tlearn: 1.7510460\ttotal: 7.51s\tremaining: 7.05s\n",
      "516:\tlearn: 1.7509688\ttotal: 7.53s\tremaining: 7.03s\n",
      "517:\tlearn: 1.7509606\ttotal: 7.54s\tremaining: 7.02s\n",
      "518:\tlearn: 1.7509489\ttotal: 7.56s\tremaining: 7s\n",
      "519:\tlearn: 1.7509256\ttotal: 7.57s\tremaining: 6.99s\n",
      "520:\tlearn: 1.7496631\ttotal: 7.58s\tremaining: 6.97s\n",
      "521:\tlearn: 1.7494850\ttotal: 7.6s\tremaining: 6.96s\n",
      "522:\tlearn: 1.7494476\ttotal: 7.61s\tremaining: 6.94s\n",
      "523:\tlearn: 1.7494276\ttotal: 7.63s\tremaining: 6.93s\n",
      "524:\tlearn: 1.7493859\ttotal: 7.64s\tremaining: 6.91s\n",
      "525:\tlearn: 1.7493858\ttotal: 7.65s\tremaining: 6.9s\n",
      "526:\tlearn: 1.7493857\ttotal: 7.67s\tremaining: 6.88s\n",
      "527:\tlearn: 1.7493642\ttotal: 7.68s\tremaining: 6.87s\n",
      "528:\tlearn: 1.7493115\ttotal: 7.69s\tremaining: 6.85s\n",
      "529:\tlearn: 1.7492974\ttotal: 7.71s\tremaining: 6.84s\n",
      "530:\tlearn: 1.7492841\ttotal: 7.73s\tremaining: 6.82s\n",
      "531:\tlearn: 1.7490318\ttotal: 7.74s\tremaining: 6.81s\n",
      "532:\tlearn: 1.7489594\ttotal: 7.75s\tremaining: 6.79s\n",
      "533:\tlearn: 1.7489339\ttotal: 7.77s\tremaining: 6.78s\n",
      "534:\tlearn: 1.7489287\ttotal: 7.78s\tremaining: 6.76s\n",
      "535:\tlearn: 1.7489287\ttotal: 7.79s\tremaining: 6.75s\n",
      "536:\tlearn: 1.7489287\ttotal: 7.81s\tremaining: 6.73s\n",
      "537:\tlearn: 1.7489284\ttotal: 7.82s\tremaining: 6.72s\n",
      "538:\tlearn: 1.7489283\ttotal: 7.83s\tremaining: 6.7s\n",
      "539:\tlearn: 1.7489283\ttotal: 7.85s\tremaining: 6.68s\n",
      "540:\tlearn: 1.7489280\ttotal: 7.86s\tremaining: 6.67s\n",
      "541:\tlearn: 1.7489280\ttotal: 7.87s\tremaining: 6.65s\n",
      "542:\tlearn: 1.7489279\ttotal: 7.89s\tremaining: 6.64s\n",
      "543:\tlearn: 1.7489277\ttotal: 7.9s\tremaining: 6.62s\n",
      "544:\tlearn: 1.7489274\ttotal: 7.91s\tremaining: 6.61s\n",
      "545:\tlearn: 1.7489273\ttotal: 7.93s\tremaining: 6.59s\n",
      "546:\tlearn: 1.7489253\ttotal: 7.94s\tremaining: 6.58s\n",
      "547:\tlearn: 1.7489251\ttotal: 7.96s\tremaining: 6.56s\n",
      "548:\tlearn: 1.7489246\ttotal: 7.97s\tremaining: 6.55s\n",
      "549:\tlearn: 1.7489242\ttotal: 7.98s\tremaining: 6.53s\n",
      "550:\tlearn: 1.7489225\ttotal: 8s\tremaining: 6.52s\n",
      "551:\tlearn: 1.7489213\ttotal: 8.01s\tremaining: 6.5s\n",
      "552:\tlearn: 1.7489195\ttotal: 8.03s\tremaining: 6.49s\n",
      "553:\tlearn: 1.7489143\ttotal: 8.04s\tremaining: 6.47s\n",
      "554:\tlearn: 1.7489136\ttotal: 8.05s\tremaining: 6.46s\n",
      "555:\tlearn: 1.7488953\ttotal: 8.07s\tremaining: 6.44s\n",
      "556:\tlearn: 1.7487514\ttotal: 8.08s\tremaining: 6.43s\n",
      "557:\tlearn: 1.7487288\ttotal: 8.1s\tremaining: 6.41s\n",
      "558:\tlearn: 1.7487208\ttotal: 8.11s\tremaining: 6.4s\n",
      "559:\tlearn: 1.7482841\ttotal: 8.12s\tremaining: 6.38s\n",
      "560:\tlearn: 1.7482839\ttotal: 8.14s\tremaining: 6.37s\n",
      "561:\tlearn: 1.7482422\ttotal: 8.15s\tremaining: 6.35s\n",
      "562:\tlearn: 1.7482393\ttotal: 8.16s\tremaining: 6.34s\n",
      "563:\tlearn: 1.7482272\ttotal: 8.18s\tremaining: 6.32s\n",
      "564:\tlearn: 1.7482021\ttotal: 8.19s\tremaining: 6.31s\n",
      "565:\tlearn: 1.7476693\ttotal: 8.21s\tremaining: 6.29s\n",
      "566:\tlearn: 1.7476685\ttotal: 8.22s\tremaining: 6.28s\n",
      "567:\tlearn: 1.7472011\ttotal: 8.23s\tremaining: 6.26s\n",
      "568:\tlearn: 1.7471765\ttotal: 8.25s\tremaining: 6.25s\n",
      "569:\tlearn: 1.7471765\ttotal: 8.26s\tremaining: 6.23s\n",
      "570:\tlearn: 1.7471701\ttotal: 8.27s\tremaining: 6.22s\n",
      "571:\tlearn: 1.7471701\ttotal: 8.29s\tremaining: 6.2s\n",
      "572:\tlearn: 1.7471700\ttotal: 8.3s\tremaining: 6.18s\n",
      "573:\tlearn: 1.7471700\ttotal: 8.31s\tremaining: 6.17s\n",
      "574:\tlearn: 1.7471517\ttotal: 8.33s\tremaining: 6.16s\n",
      "575:\tlearn: 1.7471517\ttotal: 8.36s\tremaining: 6.16s\n",
      "576:\tlearn: 1.7471019\ttotal: 8.38s\tremaining: 6.14s\n",
      "577:\tlearn: 1.7469869\ttotal: 8.39s\tremaining: 6.13s\n",
      "578:\tlearn: 1.7467625\ttotal: 8.4s\tremaining: 6.11s\n",
      "579:\tlearn: 1.7467536\ttotal: 8.42s\tremaining: 6.1s\n",
      "580:\tlearn: 1.7467536\ttotal: 8.43s\tremaining: 6.08s\n",
      "581:\tlearn: 1.7467490\ttotal: 8.45s\tremaining: 6.07s\n",
      "582:\tlearn: 1.7460683\ttotal: 8.46s\tremaining: 6.05s\n",
      "583:\tlearn: 1.7455147\ttotal: 8.48s\tremaining: 6.04s\n",
      "584:\tlearn: 1.7455144\ttotal: 8.49s\tremaining: 6.02s\n",
      "585:\tlearn: 1.7448250\ttotal: 8.5s\tremaining: 6.01s\n",
      "586:\tlearn: 1.7444366\ttotal: 8.52s\tremaining: 5.99s\n",
      "587:\tlearn: 1.7444231\ttotal: 8.53s\tremaining: 5.98s\n",
      "588:\tlearn: 1.7444217\ttotal: 8.55s\tremaining: 5.96s\n",
      "589:\tlearn: 1.7444216\ttotal: 8.56s\tremaining: 5.95s\n",
      "590:\tlearn: 1.7442924\ttotal: 8.58s\tremaining: 5.94s\n",
      "591:\tlearn: 1.7442258\ttotal: 8.59s\tremaining: 5.92s\n",
      "592:\tlearn: 1.7442078\ttotal: 8.61s\tremaining: 5.91s\n",
      "593:\tlearn: 1.7440969\ttotal: 8.62s\tremaining: 5.89s\n",
      "594:\tlearn: 1.7440523\ttotal: 8.63s\tremaining: 5.88s\n",
      "595:\tlearn: 1.7440350\ttotal: 8.65s\tremaining: 5.86s\n",
      "596:\tlearn: 1.7440107\ttotal: 8.66s\tremaining: 5.85s\n",
      "597:\tlearn: 1.7440104\ttotal: 8.68s\tremaining: 5.83s\n",
      "598:\tlearn: 1.7440104\ttotal: 8.69s\tremaining: 5.82s\n",
      "599:\tlearn: 1.7440014\ttotal: 8.71s\tremaining: 5.8s\n",
      "600:\tlearn: 1.7440009\ttotal: 8.72s\tremaining: 5.79s\n",
      "601:\tlearn: 1.7439974\ttotal: 8.73s\tremaining: 5.77s\n",
      "602:\tlearn: 1.7439619\ttotal: 8.75s\tremaining: 5.76s\n",
      "603:\tlearn: 1.7439617\ttotal: 8.76s\tremaining: 5.75s\n",
      "604:\tlearn: 1.7439617\ttotal: 8.78s\tremaining: 5.73s\n",
      "605:\tlearn: 1.7439616\ttotal: 8.79s\tremaining: 5.72s\n",
      "606:\tlearn: 1.7439615\ttotal: 8.81s\tremaining: 5.7s\n",
      "607:\tlearn: 1.7439614\ttotal: 8.82s\tremaining: 5.69s\n",
      "608:\tlearn: 1.7439612\ttotal: 8.84s\tremaining: 5.67s\n",
      "609:\tlearn: 1.7439378\ttotal: 8.85s\tremaining: 5.66s\n",
      "610:\tlearn: 1.7433648\ttotal: 8.86s\tremaining: 5.64s\n",
      "611:\tlearn: 1.7428155\ttotal: 8.88s\tremaining: 5.63s\n",
      "612:\tlearn: 1.7424188\ttotal: 8.89s\tremaining: 5.61s\n",
      "613:\tlearn: 1.7423658\ttotal: 8.9s\tremaining: 5.6s\n",
      "614:\tlearn: 1.7423579\ttotal: 8.92s\tremaining: 5.58s\n",
      "615:\tlearn: 1.7423572\ttotal: 8.93s\tremaining: 5.57s\n",
      "616:\tlearn: 1.7423572\ttotal: 8.95s\tremaining: 5.55s\n",
      "617:\tlearn: 1.7423572\ttotal: 8.96s\tremaining: 5.54s\n",
      "618:\tlearn: 1.7423572\ttotal: 8.97s\tremaining: 5.52s\n",
      "619:\tlearn: 1.7423567\ttotal: 8.99s\tremaining: 5.51s\n",
      "620:\tlearn: 1.7423489\ttotal: 9s\tremaining: 5.49s\n",
      "621:\tlearn: 1.7421100\ttotal: 9.02s\tremaining: 5.48s\n",
      "622:\tlearn: 1.7420363\ttotal: 9.03s\tremaining: 5.46s\n",
      "623:\tlearn: 1.7410083\ttotal: 9.05s\tremaining: 5.45s\n",
      "624:\tlearn: 1.7407440\ttotal: 9.06s\tremaining: 5.44s\n",
      "625:\tlearn: 1.7407283\ttotal: 9.07s\tremaining: 5.42s\n",
      "626:\tlearn: 1.7407281\ttotal: 9.09s\tremaining: 5.41s\n",
      "627:\tlearn: 1.7401204\ttotal: 9.1s\tremaining: 5.39s\n",
      "628:\tlearn: 1.7395555\ttotal: 9.12s\tremaining: 5.38s\n",
      "629:\tlearn: 1.7395150\ttotal: 9.13s\tremaining: 5.36s\n",
      "630:\tlearn: 1.7395088\ttotal: 9.14s\tremaining: 5.35s\n",
      "631:\tlearn: 1.7395069\ttotal: 9.15s\tremaining: 5.33s\n",
      "632:\tlearn: 1.7395068\ttotal: 9.17s\tremaining: 5.32s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633:\tlearn: 1.7395058\ttotal: 9.19s\tremaining: 5.3s\n",
      "634:\tlearn: 1.7394743\ttotal: 9.2s\tremaining: 5.29s\n",
      "635:\tlearn: 1.7394593\ttotal: 9.21s\tremaining: 5.27s\n",
      "636:\tlearn: 1.7393909\ttotal: 9.23s\tremaining: 5.26s\n",
      "637:\tlearn: 1.7390701\ttotal: 9.24s\tremaining: 5.24s\n",
      "638:\tlearn: 1.7381592\ttotal: 9.26s\tremaining: 5.23s\n",
      "639:\tlearn: 1.7373696\ttotal: 9.27s\tremaining: 5.21s\n",
      "640:\tlearn: 1.7373310\ttotal: 9.28s\tremaining: 5.2s\n",
      "641:\tlearn: 1.7373293\ttotal: 9.3s\tremaining: 5.18s\n",
      "642:\tlearn: 1.7369252\ttotal: 9.31s\tremaining: 5.17s\n",
      "643:\tlearn: 1.7360217\ttotal: 9.32s\tremaining: 5.16s\n",
      "644:\tlearn: 1.7356947\ttotal: 9.34s\tremaining: 5.14s\n",
      "645:\tlearn: 1.7356944\ttotal: 9.35s\tremaining: 5.13s\n",
      "646:\tlearn: 1.7356934\ttotal: 9.37s\tremaining: 5.11s\n",
      "647:\tlearn: 1.7356769\ttotal: 9.38s\tremaining: 5.09s\n",
      "648:\tlearn: 1.7353705\ttotal: 9.39s\tremaining: 5.08s\n",
      "649:\tlearn: 1.7353702\ttotal: 9.41s\tremaining: 5.07s\n",
      "650:\tlearn: 1.7353602\ttotal: 9.42s\tremaining: 5.05s\n",
      "651:\tlearn: 1.7353596\ttotal: 9.44s\tremaining: 5.04s\n",
      "652:\tlearn: 1.7353594\ttotal: 9.45s\tremaining: 5.02s\n",
      "653:\tlearn: 1.7353591\ttotal: 9.46s\tremaining: 5.01s\n",
      "654:\tlearn: 1.7353587\ttotal: 9.48s\tremaining: 4.99s\n",
      "655:\tlearn: 1.7353587\ttotal: 9.49s\tremaining: 4.98s\n",
      "656:\tlearn: 1.7353587\ttotal: 9.51s\tremaining: 4.96s\n",
      "657:\tlearn: 1.7353587\ttotal: 9.52s\tremaining: 4.95s\n",
      "658:\tlearn: 1.7353587\ttotal: 9.53s\tremaining: 4.93s\n",
      "659:\tlearn: 1.7353586\ttotal: 9.55s\tremaining: 4.92s\n",
      "660:\tlearn: 1.7353576\ttotal: 9.56s\tremaining: 4.9s\n",
      "661:\tlearn: 1.7353576\ttotal: 9.58s\tremaining: 4.89s\n",
      "662:\tlearn: 1.7353576\ttotal: 9.59s\tremaining: 4.88s\n",
      "663:\tlearn: 1.7353576\ttotal: 9.6s\tremaining: 4.86s\n",
      "664:\tlearn: 1.7353432\ttotal: 9.62s\tremaining: 4.85s\n",
      "665:\tlearn: 1.7353249\ttotal: 9.63s\tremaining: 4.83s\n",
      "666:\tlearn: 1.7351599\ttotal: 9.65s\tremaining: 4.82s\n",
      "667:\tlearn: 1.7351539\ttotal: 9.66s\tremaining: 4.8s\n",
      "668:\tlearn: 1.7351066\ttotal: 9.68s\tremaining: 4.79s\n",
      "669:\tlearn: 1.7346863\ttotal: 9.69s\tremaining: 4.77s\n",
      "670:\tlearn: 1.7345987\ttotal: 9.7s\tremaining: 4.76s\n",
      "671:\tlearn: 1.7340104\ttotal: 9.72s\tremaining: 4.74s\n",
      "672:\tlearn: 1.7337174\ttotal: 9.73s\tremaining: 4.73s\n",
      "673:\tlearn: 1.7329657\ttotal: 9.74s\tremaining: 4.71s\n",
      "674:\tlearn: 1.7328504\ttotal: 9.76s\tremaining: 4.7s\n",
      "675:\tlearn: 1.7328470\ttotal: 9.77s\tremaining: 4.68s\n",
      "676:\tlearn: 1.7328020\ttotal: 9.79s\tremaining: 4.67s\n",
      "677:\tlearn: 1.7327546\ttotal: 9.8s\tremaining: 4.65s\n",
      "678:\tlearn: 1.7325035\ttotal: 9.81s\tremaining: 4.64s\n",
      "679:\tlearn: 1.7324801\ttotal: 9.83s\tremaining: 4.63s\n",
      "680:\tlearn: 1.7324800\ttotal: 9.84s\tremaining: 4.61s\n",
      "681:\tlearn: 1.7324797\ttotal: 9.86s\tremaining: 4.6s\n",
      "682:\tlearn: 1.7324793\ttotal: 9.87s\tremaining: 4.58s\n",
      "683:\tlearn: 1.7324787\ttotal: 9.89s\tremaining: 4.57s\n",
      "684:\tlearn: 1.7324782\ttotal: 9.9s\tremaining: 4.55s\n",
      "685:\tlearn: 1.7324776\ttotal: 9.92s\tremaining: 4.54s\n",
      "686:\tlearn: 1.7324772\ttotal: 9.93s\tremaining: 4.52s\n",
      "687:\tlearn: 1.7324772\ttotal: 9.94s\tremaining: 4.51s\n",
      "688:\tlearn: 1.7324032\ttotal: 9.96s\tremaining: 4.49s\n",
      "689:\tlearn: 1.7322466\ttotal: 9.97s\tremaining: 4.48s\n",
      "690:\tlearn: 1.7315667\ttotal: 9.98s\tremaining: 4.46s\n",
      "691:\tlearn: 1.7315665\ttotal: 10s\tremaining: 4.45s\n",
      "692:\tlearn: 1.7315620\ttotal: 10s\tremaining: 4.44s\n",
      "693:\tlearn: 1.7315612\ttotal: 10s\tremaining: 4.42s\n",
      "694:\tlearn: 1.7315612\ttotal: 10s\tremaining: 4.41s\n",
      "695:\tlearn: 1.7315234\ttotal: 10.1s\tremaining: 4.39s\n",
      "696:\tlearn: 1.7315234\ttotal: 10.1s\tremaining: 4.38s\n",
      "697:\tlearn: 1.7315233\ttotal: 10.1s\tremaining: 4.36s\n",
      "698:\tlearn: 1.7313127\ttotal: 10.1s\tremaining: 4.35s\n",
      "699:\tlearn: 1.7313127\ttotal: 10.1s\tremaining: 4.33s\n",
      "700:\tlearn: 1.7313127\ttotal: 10.1s\tremaining: 4.32s\n",
      "701:\tlearn: 1.7312426\ttotal: 10.1s\tremaining: 4.3s\n",
      "702:\tlearn: 1.7304471\ttotal: 10.2s\tremaining: 4.29s\n",
      "703:\tlearn: 1.7295921\ttotal: 10.2s\tremaining: 4.27s\n",
      "704:\tlearn: 1.7295522\ttotal: 10.2s\tremaining: 4.26s\n",
      "705:\tlearn: 1.7295517\ttotal: 10.2s\tremaining: 4.25s\n",
      "706:\tlearn: 1.7295517\ttotal: 10.2s\tremaining: 4.23s\n",
      "707:\tlearn: 1.7295517\ttotal: 10.2s\tremaining: 4.21s\n",
      "708:\tlearn: 1.7294731\ttotal: 10.2s\tremaining: 4.2s\n",
      "709:\tlearn: 1.7294577\ttotal: 10.3s\tremaining: 4.19s\n",
      "710:\tlearn: 1.7294292\ttotal: 10.3s\tremaining: 4.17s\n",
      "711:\tlearn: 1.7291354\ttotal: 10.3s\tremaining: 4.16s\n",
      "712:\tlearn: 1.7283150\ttotal: 10.3s\tremaining: 4.14s\n",
      "713:\tlearn: 1.7283115\ttotal: 10.3s\tremaining: 4.13s\n",
      "714:\tlearn: 1.7275320\ttotal: 10.3s\tremaining: 4.11s\n",
      "715:\tlearn: 1.7274830\ttotal: 10.3s\tremaining: 4.1s\n",
      "716:\tlearn: 1.7270898\ttotal: 10.3s\tremaining: 4.08s\n",
      "717:\tlearn: 1.7270719\ttotal: 10.4s\tremaining: 4.07s\n",
      "718:\tlearn: 1.7270718\ttotal: 10.4s\tremaining: 4.05s\n",
      "719:\tlearn: 1.7270693\ttotal: 10.4s\tremaining: 4.04s\n",
      "720:\tlearn: 1.7270693\ttotal: 10.4s\tremaining: 4.02s\n",
      "721:\tlearn: 1.7270528\ttotal: 10.4s\tremaining: 4.01s\n",
      "722:\tlearn: 1.7269988\ttotal: 10.4s\tremaining: 3.99s\n",
      "723:\tlearn: 1.7269860\ttotal: 10.4s\tremaining: 3.98s\n",
      "724:\tlearn: 1.7266809\ttotal: 10.4s\tremaining: 3.96s\n",
      "725:\tlearn: 1.7266429\ttotal: 10.5s\tremaining: 3.95s\n",
      "726:\tlearn: 1.7265255\ttotal: 10.5s\tremaining: 3.93s\n",
      "727:\tlearn: 1.7265254\ttotal: 10.5s\tremaining: 3.92s\n",
      "728:\tlearn: 1.7264860\ttotal: 10.5s\tremaining: 3.91s\n",
      "729:\tlearn: 1.7264668\ttotal: 10.5s\tremaining: 3.89s\n",
      "730:\tlearn: 1.7264062\ttotal: 10.5s\tremaining: 3.88s\n",
      "731:\tlearn: 1.7263994\ttotal: 10.5s\tremaining: 3.86s\n",
      "732:\tlearn: 1.7263991\ttotal: 10.6s\tremaining: 3.85s\n",
      "733:\tlearn: 1.7263842\ttotal: 10.6s\tremaining: 3.83s\n",
      "734:\tlearn: 1.7263839\ttotal: 10.6s\tremaining: 3.82s\n",
      "735:\tlearn: 1.7263824\ttotal: 10.6s\tremaining: 3.8s\n",
      "736:\tlearn: 1.7263198\ttotal: 10.6s\tremaining: 3.79s\n",
      "737:\tlearn: 1.7259420\ttotal: 10.6s\tremaining: 3.77s\n",
      "738:\tlearn: 1.7259199\ttotal: 10.6s\tremaining: 3.76s\n",
      "739:\tlearn: 1.7258819\ttotal: 10.7s\tremaining: 3.75s\n",
      "740:\tlearn: 1.7258812\ttotal: 10.7s\tremaining: 3.73s\n",
      "741:\tlearn: 1.7258811\ttotal: 10.7s\tremaining: 3.72s\n",
      "742:\tlearn: 1.7258308\ttotal: 10.7s\tremaining: 3.7s\n",
      "743:\tlearn: 1.7257512\ttotal: 10.7s\tremaining: 3.69s\n",
      "744:\tlearn: 1.7256227\ttotal: 10.7s\tremaining: 3.67s\n",
      "745:\tlearn: 1.7255443\ttotal: 10.7s\tremaining: 3.66s\n",
      "746:\tlearn: 1.7255229\ttotal: 10.8s\tremaining: 3.65s\n",
      "747:\tlearn: 1.7254917\ttotal: 10.8s\tremaining: 3.63s\n",
      "748:\tlearn: 1.7253209\ttotal: 10.8s\tremaining: 3.62s\n",
      "749:\tlearn: 1.7253175\ttotal: 10.8s\tremaining: 3.6s\n",
      "750:\tlearn: 1.7253174\ttotal: 10.8s\tremaining: 3.59s\n",
      "751:\tlearn: 1.7252893\ttotal: 10.8s\tremaining: 3.57s\n",
      "752:\tlearn: 1.7252771\ttotal: 10.8s\tremaining: 3.56s\n",
      "753:\tlearn: 1.7252740\ttotal: 10.9s\tremaining: 3.54s\n",
      "754:\tlearn: 1.7252720\ttotal: 10.9s\tremaining: 3.53s\n",
      "755:\tlearn: 1.7252716\ttotal: 10.9s\tremaining: 3.51s\n",
      "756:\tlearn: 1.7250257\ttotal: 10.9s\tremaining: 3.5s\n",
      "757:\tlearn: 1.7238413\ttotal: 10.9s\tremaining: 3.48s\n",
      "758:\tlearn: 1.7238042\ttotal: 10.9s\tremaining: 3.47s\n",
      "759:\tlearn: 1.7237703\ttotal: 10.9s\tremaining: 3.46s\n",
      "760:\tlearn: 1.7235749\ttotal: 11s\tremaining: 3.44s\n",
      "761:\tlearn: 1.7235652\ttotal: 11s\tremaining: 3.43s\n",
      "762:\tlearn: 1.7231896\ttotal: 11s\tremaining: 3.41s\n",
      "763:\tlearn: 1.7231753\ttotal: 11s\tremaining: 3.4s\n",
      "764:\tlearn: 1.7231624\ttotal: 11s\tremaining: 3.38s\n",
      "765:\tlearn: 1.7231063\ttotal: 11s\tremaining: 3.37s\n",
      "766:\tlearn: 1.7231047\ttotal: 11s\tremaining: 3.35s\n",
      "767:\tlearn: 1.7227991\ttotal: 11.1s\tremaining: 3.34s\n",
      "768:\tlearn: 1.7226929\ttotal: 11.1s\tremaining: 3.32s\n",
      "769:\tlearn: 1.7223178\ttotal: 11.1s\tremaining: 3.31s\n",
      "770:\tlearn: 1.7223172\ttotal: 11.1s\tremaining: 3.29s\n",
      "771:\tlearn: 1.7218181\ttotal: 11.1s\tremaining: 3.28s\n",
      "772:\tlearn: 1.7218174\ttotal: 11.1s\tremaining: 3.27s\n",
      "773:\tlearn: 1.7218087\ttotal: 11.1s\tremaining: 3.25s\n",
      "774:\tlearn: 1.7218087\ttotal: 11.2s\tremaining: 3.24s\n",
      "775:\tlearn: 1.7218076\ttotal: 11.2s\tremaining: 3.22s\n",
      "776:\tlearn: 1.7218076\ttotal: 11.2s\tremaining: 3.21s\n",
      "777:\tlearn: 1.7218058\ttotal: 11.2s\tremaining: 3.19s\n",
      "778:\tlearn: 1.7218055\ttotal: 11.2s\tremaining: 3.18s\n",
      "779:\tlearn: 1.7217909\ttotal: 11.2s\tremaining: 3.16s\n",
      "780:\tlearn: 1.7217909\ttotal: 11.2s\tremaining: 3.15s\n",
      "781:\tlearn: 1.7213589\ttotal: 11.2s\tremaining: 3.13s\n",
      "782:\tlearn: 1.7213568\ttotal: 11.3s\tremaining: 3.12s\n",
      "783:\tlearn: 1.7198187\ttotal: 11.3s\tremaining: 3.1s\n",
      "784:\tlearn: 1.7195736\ttotal: 11.3s\tremaining: 3.09s\n",
      "785:\tlearn: 1.7191727\ttotal: 11.3s\tremaining: 3.08s\n",
      "786:\tlearn: 1.7189381\ttotal: 11.3s\tremaining: 3.06s\n",
      "787:\tlearn: 1.7189259\ttotal: 11.3s\tremaining: 3.05s\n",
      "788:\tlearn: 1.7183368\ttotal: 11.3s\tremaining: 3.03s\n",
      "789:\tlearn: 1.7179197\ttotal: 11.4s\tremaining: 3.02s\n",
      "790:\tlearn: 1.7177393\ttotal: 11.4s\tremaining: 3s\n",
      "791:\tlearn: 1.7169027\ttotal: 11.4s\tremaining: 2.99s\n",
      "792:\tlearn: 1.7169025\ttotal: 11.4s\tremaining: 2.98s\n",
      "793:\tlearn: 1.7169025\ttotal: 11.4s\tremaining: 2.96s\n",
      "794:\tlearn: 1.7169025\ttotal: 11.4s\tremaining: 2.95s\n",
      "795:\tlearn: 1.7168869\ttotal: 11.4s\tremaining: 2.93s\n",
      "796:\tlearn: 1.7168865\ttotal: 11.5s\tremaining: 2.92s\n",
      "797:\tlearn: 1.7168718\ttotal: 11.5s\tremaining: 2.9s\n",
      "798:\tlearn: 1.7168070\ttotal: 11.5s\tremaining: 2.89s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799:\tlearn: 1.7163368\ttotal: 11.5s\tremaining: 2.87s\n",
      "800:\tlearn: 1.7159492\ttotal: 11.5s\tremaining: 2.86s\n",
      "801:\tlearn: 1.7159414\ttotal: 11.5s\tremaining: 2.85s\n",
      "802:\tlearn: 1.7159414\ttotal: 11.5s\tremaining: 2.83s\n",
      "803:\tlearn: 1.7159403\ttotal: 11.6s\tremaining: 2.82s\n",
      "804:\tlearn: 1.7159403\ttotal: 11.6s\tremaining: 2.8s\n",
      "805:\tlearn: 1.7159385\ttotal: 11.6s\tremaining: 2.79s\n",
      "806:\tlearn: 1.7158688\ttotal: 11.6s\tremaining: 2.77s\n",
      "807:\tlearn: 1.7150822\ttotal: 11.6s\tremaining: 2.76s\n",
      "808:\tlearn: 1.7147902\ttotal: 11.6s\tremaining: 2.74s\n",
      "809:\tlearn: 1.7147901\ttotal: 11.6s\tremaining: 2.73s\n",
      "810:\tlearn: 1.7147898\ttotal: 11.6s\tremaining: 2.71s\n",
      "811:\tlearn: 1.7147897\ttotal: 11.7s\tremaining: 2.7s\n",
      "812:\tlearn: 1.7147740\ttotal: 11.7s\tremaining: 2.69s\n",
      "813:\tlearn: 1.7147696\ttotal: 11.7s\tremaining: 2.67s\n",
      "814:\tlearn: 1.7147097\ttotal: 11.7s\tremaining: 2.66s\n",
      "815:\tlearn: 1.7147064\ttotal: 11.7s\tremaining: 2.64s\n",
      "816:\tlearn: 1.7146727\ttotal: 11.7s\tremaining: 2.63s\n",
      "817:\tlearn: 1.7146725\ttotal: 11.7s\tremaining: 2.61s\n",
      "818:\tlearn: 1.7146606\ttotal: 11.8s\tremaining: 2.6s\n",
      "819:\tlearn: 1.7146367\ttotal: 11.8s\tremaining: 2.58s\n",
      "820:\tlearn: 1.7142682\ttotal: 11.8s\tremaining: 2.57s\n",
      "821:\tlearn: 1.7141721\ttotal: 11.8s\tremaining: 2.56s\n",
      "822:\tlearn: 1.7141570\ttotal: 11.8s\tremaining: 2.54s\n",
      "823:\tlearn: 1.7141565\ttotal: 11.8s\tremaining: 2.53s\n",
      "824:\tlearn: 1.7141564\ttotal: 11.8s\tremaining: 2.51s\n",
      "825:\tlearn: 1.7140566\ttotal: 11.9s\tremaining: 2.5s\n",
      "826:\tlearn: 1.7137803\ttotal: 11.9s\tremaining: 2.48s\n",
      "827:\tlearn: 1.7137543\ttotal: 11.9s\tremaining: 2.47s\n",
      "828:\tlearn: 1.7136933\ttotal: 11.9s\tremaining: 2.45s\n",
      "829:\tlearn: 1.7136705\ttotal: 11.9s\tremaining: 2.44s\n",
      "830:\tlearn: 1.7136703\ttotal: 11.9s\tremaining: 2.43s\n",
      "831:\tlearn: 1.7136703\ttotal: 11.9s\tremaining: 2.41s\n",
      "832:\tlearn: 1.7136673\ttotal: 12s\tremaining: 2.4s\n",
      "833:\tlearn: 1.7136673\ttotal: 12s\tremaining: 2.38s\n",
      "834:\tlearn: 1.7136662\ttotal: 12s\tremaining: 2.37s\n",
      "835:\tlearn: 1.7136661\ttotal: 12s\tremaining: 2.35s\n",
      "836:\tlearn: 1.7136661\ttotal: 12s\tremaining: 2.34s\n",
      "837:\tlearn: 1.7136621\ttotal: 12s\tremaining: 2.32s\n",
      "838:\tlearn: 1.7136621\ttotal: 12s\tremaining: 2.31s\n",
      "839:\tlearn: 1.7136540\ttotal: 12.1s\tremaining: 2.29s\n",
      "840:\tlearn: 1.7136379\ttotal: 12.1s\tremaining: 2.28s\n",
      "841:\tlearn: 1.7136379\ttotal: 12.1s\tremaining: 2.27s\n",
      "842:\tlearn: 1.7136379\ttotal: 12.1s\tremaining: 2.25s\n",
      "843:\tlearn: 1.7136365\ttotal: 12.1s\tremaining: 2.24s\n",
      "844:\tlearn: 1.7136364\ttotal: 12.1s\tremaining: 2.22s\n",
      "845:\tlearn: 1.7136249\ttotal: 12.1s\tremaining: 2.21s\n",
      "846:\tlearn: 1.7136240\ttotal: 12.2s\tremaining: 2.19s\n",
      "847:\tlearn: 1.7136239\ttotal: 12.2s\tremaining: 2.18s\n",
      "848:\tlearn: 1.7136067\ttotal: 12.2s\tremaining: 2.17s\n",
      "849:\tlearn: 1.7136067\ttotal: 12.2s\tremaining: 2.15s\n",
      "850:\tlearn: 1.7136067\ttotal: 12.2s\tremaining: 2.14s\n",
      "851:\tlearn: 1.7136067\ttotal: 12.2s\tremaining: 2.12s\n",
      "852:\tlearn: 1.7121789\ttotal: 12.2s\tremaining: 2.11s\n",
      "853:\tlearn: 1.7115736\ttotal: 12.2s\tremaining: 2.09s\n",
      "854:\tlearn: 1.7115529\ttotal: 12.3s\tremaining: 2.08s\n",
      "855:\tlearn: 1.7115527\ttotal: 12.3s\tremaining: 2.06s\n",
      "856:\tlearn: 1.7115527\ttotal: 12.3s\tremaining: 2.05s\n",
      "857:\tlearn: 1.7115527\ttotal: 12.3s\tremaining: 2.04s\n",
      "858:\tlearn: 1.7115527\ttotal: 12.3s\tremaining: 2.02s\n",
      "859:\tlearn: 1.7115519\ttotal: 12.3s\tremaining: 2.01s\n",
      "860:\tlearn: 1.7115506\ttotal: 12.3s\tremaining: 1.99s\n",
      "861:\tlearn: 1.7115502\ttotal: 12.4s\tremaining: 1.98s\n",
      "862:\tlearn: 1.7115500\ttotal: 12.4s\tremaining: 1.96s\n",
      "863:\tlearn: 1.7115500\ttotal: 12.4s\tremaining: 1.95s\n",
      "864:\tlearn: 1.7115500\ttotal: 12.4s\tremaining: 1.94s\n",
      "865:\tlearn: 1.7110812\ttotal: 12.4s\tremaining: 1.92s\n",
      "866:\tlearn: 1.7110524\ttotal: 12.4s\tremaining: 1.91s\n",
      "867:\tlearn: 1.7106690\ttotal: 12.4s\tremaining: 1.89s\n",
      "868:\tlearn: 1.7106505\ttotal: 12.5s\tremaining: 1.88s\n",
      "869:\tlearn: 1.7105965\ttotal: 12.5s\tremaining: 1.86s\n",
      "870:\tlearn: 1.7105871\ttotal: 12.5s\tremaining: 1.85s\n",
      "871:\tlearn: 1.7105871\ttotal: 12.5s\tremaining: 1.83s\n",
      "872:\tlearn: 1.7105597\ttotal: 12.5s\tremaining: 1.82s\n",
      "873:\tlearn: 1.7102593\ttotal: 12.5s\tremaining: 1.8s\n",
      "874:\tlearn: 1.7102322\ttotal: 12.5s\tremaining: 1.79s\n",
      "875:\tlearn: 1.7102220\ttotal: 12.6s\tremaining: 1.78s\n",
      "876:\tlearn: 1.7102220\ttotal: 12.6s\tremaining: 1.76s\n",
      "877:\tlearn: 1.7102219\ttotal: 12.6s\tremaining: 1.75s\n",
      "878:\tlearn: 1.7102214\ttotal: 12.6s\tremaining: 1.73s\n",
      "879:\tlearn: 1.7102207\ttotal: 12.6s\tremaining: 1.72s\n",
      "880:\tlearn: 1.7102207\ttotal: 12.6s\tremaining: 1.71s\n",
      "881:\tlearn: 1.7102206\ttotal: 12.6s\tremaining: 1.69s\n",
      "882:\tlearn: 1.7102206\ttotal: 12.7s\tremaining: 1.68s\n",
      "883:\tlearn: 1.7100929\ttotal: 12.7s\tremaining: 1.66s\n",
      "884:\tlearn: 1.7100262\ttotal: 12.7s\tremaining: 1.65s\n",
      "885:\tlearn: 1.7100240\ttotal: 12.7s\tremaining: 1.63s\n",
      "886:\tlearn: 1.7100109\ttotal: 12.7s\tremaining: 1.62s\n",
      "887:\tlearn: 1.7100108\ttotal: 12.7s\tremaining: 1.6s\n",
      "888:\tlearn: 1.7099986\ttotal: 12.7s\tremaining: 1.59s\n",
      "889:\tlearn: 1.7098744\ttotal: 12.8s\tremaining: 1.58s\n",
      "890:\tlearn: 1.7098504\ttotal: 12.8s\tremaining: 1.56s\n",
      "891:\tlearn: 1.7090856\ttotal: 12.8s\tremaining: 1.55s\n",
      "892:\tlearn: 1.7089761\ttotal: 12.8s\tremaining: 1.53s\n",
      "893:\tlearn: 1.7089419\ttotal: 12.8s\tremaining: 1.52s\n",
      "894:\tlearn: 1.7086559\ttotal: 12.8s\tremaining: 1.5s\n",
      "895:\tlearn: 1.7085835\ttotal: 12.8s\tremaining: 1.49s\n",
      "896:\tlearn: 1.7084305\ttotal: 12.8s\tremaining: 1.47s\n",
      "897:\tlearn: 1.7082241\ttotal: 12.9s\tremaining: 1.46s\n",
      "898:\tlearn: 1.7081738\ttotal: 12.9s\tremaining: 1.45s\n",
      "899:\tlearn: 1.7081392\ttotal: 12.9s\tremaining: 1.43s\n",
      "900:\tlearn: 1.7081177\ttotal: 12.9s\tremaining: 1.42s\n",
      "901:\tlearn: 1.7080764\ttotal: 12.9s\tremaining: 1.4s\n",
      "902:\tlearn: 1.7080323\ttotal: 12.9s\tremaining: 1.39s\n",
      "903:\tlearn: 1.7080036\ttotal: 12.9s\tremaining: 1.37s\n",
      "904:\tlearn: 1.7079944\ttotal: 13s\tremaining: 1.36s\n",
      "905:\tlearn: 1.7079939\ttotal: 13s\tremaining: 1.34s\n",
      "906:\tlearn: 1.7079904\ttotal: 13s\tremaining: 1.33s\n",
      "907:\tlearn: 1.7079843\ttotal: 13s\tremaining: 1.32s\n",
      "908:\tlearn: 1.7079251\ttotal: 13s\tremaining: 1.3s\n",
      "909:\tlearn: 1.7077511\ttotal: 13s\tremaining: 1.29s\n",
      "910:\tlearn: 1.7074548\ttotal: 13s\tremaining: 1.27s\n",
      "911:\tlearn: 1.7074536\ttotal: 13s\tremaining: 1.26s\n",
      "912:\tlearn: 1.7074235\ttotal: 13.1s\tremaining: 1.24s\n",
      "913:\tlearn: 1.7071550\ttotal: 13.1s\tremaining: 1.23s\n",
      "914:\tlearn: 1.7071473\ttotal: 13.1s\tremaining: 1.22s\n",
      "915:\tlearn: 1.7071425\ttotal: 13.1s\tremaining: 1.2s\n",
      "916:\tlearn: 1.7068653\ttotal: 13.1s\tremaining: 1.19s\n",
      "917:\tlearn: 1.7064951\ttotal: 13.1s\tremaining: 1.17s\n",
      "918:\tlearn: 1.7064818\ttotal: 13.1s\tremaining: 1.16s\n",
      "919:\tlearn: 1.7064604\ttotal: 13.2s\tremaining: 1.14s\n",
      "920:\tlearn: 1.7064472\ttotal: 13.2s\tremaining: 1.13s\n",
      "921:\tlearn: 1.7064455\ttotal: 13.2s\tremaining: 1.11s\n",
      "922:\tlearn: 1.7064005\ttotal: 13.2s\tremaining: 1.1s\n",
      "923:\tlearn: 1.7063896\ttotal: 13.2s\tremaining: 1.09s\n",
      "924:\tlearn: 1.7058838\ttotal: 13.2s\tremaining: 1.07s\n",
      "925:\tlearn: 1.7058601\ttotal: 13.2s\tremaining: 1.06s\n",
      "926:\tlearn: 1.7048198\ttotal: 13.3s\tremaining: 1.04s\n",
      "927:\tlearn: 1.7045481\ttotal: 13.3s\tremaining: 1.03s\n",
      "928:\tlearn: 1.7044466\ttotal: 13.3s\tremaining: 1.01s\n",
      "929:\tlearn: 1.7044453\ttotal: 13.3s\tremaining: 1s\n",
      "930:\tlearn: 1.7044452\ttotal: 13.3s\tremaining: 986ms\n",
      "931:\tlearn: 1.7044362\ttotal: 13.3s\tremaining: 972ms\n",
      "932:\tlearn: 1.7043916\ttotal: 13.3s\tremaining: 958ms\n",
      "933:\tlearn: 1.7043873\ttotal: 13.4s\tremaining: 944ms\n",
      "934:\tlearn: 1.7043873\ttotal: 13.4s\tremaining: 929ms\n",
      "935:\tlearn: 1.7043872\ttotal: 13.4s\tremaining: 915ms\n",
      "936:\tlearn: 1.7043869\ttotal: 13.4s\tremaining: 901ms\n",
      "937:\tlearn: 1.7043816\ttotal: 13.4s\tremaining: 886ms\n",
      "938:\tlearn: 1.7042279\ttotal: 13.4s\tremaining: 872ms\n",
      "939:\tlearn: 1.7042098\ttotal: 13.4s\tremaining: 858ms\n",
      "940:\tlearn: 1.7041801\ttotal: 13.5s\tremaining: 843ms\n",
      "941:\tlearn: 1.7041514\ttotal: 13.5s\tremaining: 829ms\n",
      "942:\tlearn: 1.7041493\ttotal: 13.5s\tremaining: 815ms\n",
      "943:\tlearn: 1.7041491\ttotal: 13.5s\tremaining: 800ms\n",
      "944:\tlearn: 1.7040723\ttotal: 13.5s\tremaining: 786ms\n",
      "945:\tlearn: 1.7040629\ttotal: 13.5s\tremaining: 772ms\n",
      "946:\tlearn: 1.7038990\ttotal: 13.5s\tremaining: 757ms\n",
      "947:\tlearn: 1.7038681\ttotal: 13.5s\tremaining: 743ms\n",
      "948:\tlearn: 1.7038473\ttotal: 13.6s\tremaining: 729ms\n",
      "949:\tlearn: 1.7036391\ttotal: 13.6s\tremaining: 714ms\n",
      "950:\tlearn: 1.7036317\ttotal: 13.6s\tremaining: 700ms\n",
      "951:\tlearn: 1.7035953\ttotal: 13.6s\tremaining: 686ms\n",
      "952:\tlearn: 1.7035841\ttotal: 13.6s\tremaining: 672ms\n",
      "953:\tlearn: 1.7035792\ttotal: 13.6s\tremaining: 657ms\n",
      "954:\tlearn: 1.7033889\ttotal: 13.6s\tremaining: 643ms\n",
      "955:\tlearn: 1.7032461\ttotal: 13.7s\tremaining: 629ms\n",
      "956:\tlearn: 1.7032171\ttotal: 13.7s\tremaining: 614ms\n",
      "957:\tlearn: 1.7031892\ttotal: 13.7s\tremaining: 600ms\n",
      "958:\tlearn: 1.7031727\ttotal: 13.7s\tremaining: 586ms\n",
      "959:\tlearn: 1.7031264\ttotal: 13.7s\tremaining: 571ms\n",
      "960:\tlearn: 1.7031119\ttotal: 13.7s\tremaining: 557ms\n",
      "961:\tlearn: 1.7031119\ttotal: 13.7s\tremaining: 543ms\n",
      "962:\tlearn: 1.7031112\ttotal: 13.8s\tremaining: 528ms\n",
      "963:\tlearn: 1.7030886\ttotal: 13.8s\tremaining: 514ms\n",
      "964:\tlearn: 1.7030847\ttotal: 13.8s\tremaining: 500ms\n",
      "965:\tlearn: 1.7030829\ttotal: 13.8s\tremaining: 486ms\n",
      "966:\tlearn: 1.7030829\ttotal: 13.8s\tremaining: 471ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "967:\tlearn: 1.7030829\ttotal: 13.8s\tremaining: 457ms\n",
      "968:\tlearn: 1.7030817\ttotal: 13.8s\tremaining: 443ms\n",
      "969:\tlearn: 1.7030817\ttotal: 13.9s\tremaining: 428ms\n",
      "970:\tlearn: 1.7030817\ttotal: 13.9s\tremaining: 414ms\n",
      "971:\tlearn: 1.7030817\ttotal: 13.9s\tremaining: 400ms\n",
      "972:\tlearn: 1.7030817\ttotal: 13.9s\tremaining: 386ms\n",
      "973:\tlearn: 1.7030817\ttotal: 13.9s\tremaining: 371ms\n",
      "974:\tlearn: 1.7030740\ttotal: 13.9s\tremaining: 357ms\n",
      "975:\tlearn: 1.7029180\ttotal: 13.9s\tremaining: 343ms\n",
      "976:\tlearn: 1.7029104\ttotal: 13.9s\tremaining: 328ms\n",
      "977:\tlearn: 1.7028819\ttotal: 14s\tremaining: 314ms\n",
      "978:\tlearn: 1.7028817\ttotal: 14s\tremaining: 300ms\n",
      "979:\tlearn: 1.7028469\ttotal: 14s\tremaining: 285ms\n",
      "980:\tlearn: 1.7028469\ttotal: 14s\tremaining: 271ms\n",
      "981:\tlearn: 1.7028462\ttotal: 14s\tremaining: 257ms\n",
      "982:\tlearn: 1.7028310\ttotal: 14s\tremaining: 243ms\n",
      "983:\tlearn: 1.7028127\ttotal: 14s\tremaining: 228ms\n",
      "984:\tlearn: 1.7028113\ttotal: 14.1s\tremaining: 214ms\n",
      "985:\tlearn: 1.7027115\ttotal: 14.1s\tremaining: 200ms\n",
      "986:\tlearn: 1.7020938\ttotal: 14.1s\tremaining: 185ms\n",
      "987:\tlearn: 1.7017415\ttotal: 14.1s\tremaining: 171ms\n",
      "988:\tlearn: 1.7017369\ttotal: 14.1s\tremaining: 157ms\n",
      "989:\tlearn: 1.7017311\ttotal: 14.1s\tremaining: 143ms\n",
      "990:\tlearn: 1.7017280\ttotal: 14.1s\tremaining: 128ms\n",
      "991:\tlearn: 1.7004403\ttotal: 14.2s\tremaining: 114ms\n",
      "992:\tlearn: 1.7004376\ttotal: 14.2s\tremaining: 99.8ms\n",
      "993:\tlearn: 1.6997987\ttotal: 14.2s\tremaining: 85.6ms\n",
      "994:\tlearn: 1.6997655\ttotal: 14.2s\tremaining: 71.3ms\n",
      "995:\tlearn: 1.6997203\ttotal: 14.2s\tremaining: 57ms\n",
      "996:\tlearn: 1.6997203\ttotal: 14.2s\tremaining: 42.8ms\n",
      "997:\tlearn: 1.6997202\ttotal: 14.2s\tremaining: 28.5ms\n",
      "998:\tlearn: 1.6997202\ttotal: 14.2s\tremaining: 14.3ms\n",
      "999:\tlearn: 1.6996980\ttotal: 14.3s\tremaining: 0us\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 337\n",
      "[LightGBM] [Info] Number of data points in the train set: 63374, number of used features: 54\n",
      "[LightGBM] [Info] Start training from score 8.848466\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 63374, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 8.409162\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 346\n",
      "[LightGBM] [Info] Number of data points in the train set: 63374, number of used features: 54\n",
      "[LightGBM] [Info] Start training from score 10.510467\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 329\n",
      "[LightGBM] [Info] Number of data points in the train set: 63375, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 10.969636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 321\n",
      "[LightGBM] [Info] Number of data points in the train set: 63375, number of used features: 45\n",
      "[LightGBM] [Info] Start training from score 10.882431\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0:\tlearn: 8.1763373\ttotal: 17.2ms\tremaining: 17.2s\n",
      "1:\tlearn: 7.5836425\ttotal: 33.2ms\tremaining: 16.6s\n",
      "2:\tlearn: 7.0461478\ttotal: 50ms\tremaining: 16.6s\n",
      "3:\tlearn: 6.5649757\ttotal: 66.5ms\tremaining: 16.6s\n",
      "4:\tlearn: 6.0332550\ttotal: 85.7ms\tremaining: 17.1s\n",
      "5:\tlearn: 5.6687886\ttotal: 102ms\tremaining: 16.9s\n",
      "6:\tlearn: 5.2329079\ttotal: 118ms\tremaining: 16.8s\n",
      "7:\tlearn: 4.8376908\ttotal: 135ms\tremaining: 16.7s\n",
      "8:\tlearn: 4.4638830\ttotal: 152ms\tremaining: 16.8s\n",
      "9:\tlearn: 4.1391092\ttotal: 170ms\tremaining: 16.8s\n",
      "10:\tlearn: 3.8550104\ttotal: 187ms\tremaining: 16.8s\n",
      "11:\tlearn: 3.6660284\ttotal: 204ms\tremaining: 16.8s\n",
      "12:\tlearn: 3.4243658\ttotal: 219ms\tremaining: 16.7s\n",
      "13:\tlearn: 3.2266809\ttotal: 235ms\tremaining: 16.6s\n",
      "14:\tlearn: 3.0466553\ttotal: 252ms\tremaining: 16.5s\n",
      "15:\tlearn: 2.9363339\ttotal: 268ms\tremaining: 16.5s\n",
      "16:\tlearn: 2.8463279\ttotal: 283ms\tremaining: 16.3s\n",
      "17:\tlearn: 2.7227787\ttotal: 300ms\tremaining: 16.4s\n",
      "18:\tlearn: 2.6508875\ttotal: 317ms\tremaining: 16.3s\n",
      "19:\tlearn: 2.5392880\ttotal: 332ms\tremaining: 16.3s\n",
      "20:\tlearn: 2.4889679\ttotal: 348ms\tremaining: 16.2s\n",
      "21:\tlearn: 2.4422827\ttotal: 364ms\tremaining: 16.2s\n",
      "22:\tlearn: 2.4000894\ttotal: 380ms\tremaining: 16.1s\n",
      "23:\tlearn: 2.3319366\ttotal: 396ms\tremaining: 16.1s\n",
      "24:\tlearn: 2.2711496\ttotal: 411ms\tremaining: 16s\n",
      "25:\tlearn: 2.2164356\ttotal: 427ms\tremaining: 16s\n",
      "26:\tlearn: 2.1930910\ttotal: 442ms\tremaining: 15.9s\n",
      "27:\tlearn: 2.1665237\ttotal: 458ms\tremaining: 15.9s\n",
      "28:\tlearn: 2.1475267\ttotal: 473ms\tremaining: 15.8s\n",
      "29:\tlearn: 2.1130382\ttotal: 489ms\tremaining: 15.8s\n",
      "30:\tlearn: 2.0712086\ttotal: 506ms\tremaining: 15.8s\n",
      "31:\tlearn: 2.0572371\ttotal: 520ms\tremaining: 15.7s\n",
      "32:\tlearn: 2.0264774\ttotal: 536ms\tremaining: 15.7s\n",
      "33:\tlearn: 1.9984197\ttotal: 551ms\tremaining: 15.6s\n",
      "34:\tlearn: 1.9878476\ttotal: 566ms\tremaining: 15.6s\n",
      "35:\tlearn: 1.9791812\ttotal: 584ms\tremaining: 15.6s\n",
      "36:\tlearn: 1.9635189\ttotal: 598ms\tremaining: 15.6s\n",
      "37:\tlearn: 1.9517677\ttotal: 613ms\tremaining: 15.5s\n",
      "38:\tlearn: 1.9421914\ttotal: 628ms\tremaining: 15.5s\n",
      "39:\tlearn: 1.9405267\ttotal: 643ms\tremaining: 15.4s\n",
      "40:\tlearn: 1.9322093\ttotal: 658ms\tremaining: 15.4s\n",
      "41:\tlearn: 1.9194211\ttotal: 672ms\tremaining: 15.3s\n",
      "42:\tlearn: 1.9136387\ttotal: 686ms\tremaining: 15.3s\n",
      "43:\tlearn: 1.9101871\ttotal: 701ms\tremaining: 15.2s\n",
      "44:\tlearn: 1.9079664\ttotal: 715ms\tremaining: 15.2s\n",
      "45:\tlearn: 1.9051864\ttotal: 731ms\tremaining: 15.2s\n",
      "46:\tlearn: 1.8986454\ttotal: 746ms\tremaining: 15.1s\n",
      "47:\tlearn: 1.8948776\ttotal: 762ms\tremaining: 15.1s\n",
      "48:\tlearn: 1.8910938\ttotal: 776ms\tremaining: 15.1s\n",
      "49:\tlearn: 1.8888906\ttotal: 791ms\tremaining: 15s\n",
      "50:\tlearn: 1.8871133\ttotal: 806ms\tremaining: 15s\n",
      "51:\tlearn: 1.8846107\ttotal: 820ms\tremaining: 15s\n",
      "52:\tlearn: 1.8817426\ttotal: 834ms\tremaining: 14.9s\n",
      "53:\tlearn: 1.8804745\ttotal: 849ms\tremaining: 14.9s\n",
      "54:\tlearn: 1.8729157\ttotal: 863ms\tremaining: 14.8s\n",
      "55:\tlearn: 1.8613128\ttotal: 878ms\tremaining: 14.8s\n",
      "56:\tlearn: 1.8580366\ttotal: 892ms\tremaining: 14.8s\n",
      "57:\tlearn: 1.8572932\ttotal: 907ms\tremaining: 14.7s\n",
      "58:\tlearn: 1.8570772\ttotal: 922ms\tremaining: 14.7s\n",
      "59:\tlearn: 1.8559343\ttotal: 936ms\tremaining: 14.7s\n",
      "60:\tlearn: 1.8557464\ttotal: 952ms\tremaining: 14.7s\n",
      "61:\tlearn: 1.8550094\ttotal: 967ms\tremaining: 14.6s\n",
      "62:\tlearn: 1.8453168\ttotal: 985ms\tremaining: 14.6s\n",
      "63:\tlearn: 1.8436991\ttotal: 1s\tremaining: 14.7s\n",
      "64:\tlearn: 1.8432293\ttotal: 1.02s\tremaining: 14.6s\n",
      "65:\tlearn: 1.8424969\ttotal: 1.03s\tremaining: 14.6s\n",
      "66:\tlearn: 1.8418318\ttotal: 1.05s\tremaining: 14.6s\n",
      "67:\tlearn: 1.8389614\ttotal: 1.07s\tremaining: 14.7s\n",
      "68:\tlearn: 1.8383194\ttotal: 1.09s\tremaining: 14.7s\n",
      "69:\tlearn: 1.8369019\ttotal: 1.11s\tremaining: 14.7s\n",
      "70:\tlearn: 1.8365826\ttotal: 1.13s\tremaining: 14.7s\n",
      "71:\tlearn: 1.8364750\ttotal: 1.14s\tremaining: 14.7s\n",
      "72:\tlearn: 1.8358158\ttotal: 1.16s\tremaining: 14.7s\n",
      "73:\tlearn: 1.8353055\ttotal: 1.17s\tremaining: 14.7s\n",
      "74:\tlearn: 1.8348008\ttotal: 1.19s\tremaining: 14.6s\n",
      "75:\tlearn: 1.8333896\ttotal: 1.2s\tremaining: 14.6s\n",
      "76:\tlearn: 1.8322245\ttotal: 1.22s\tremaining: 14.6s\n",
      "77:\tlearn: 1.8319302\ttotal: 1.23s\tremaining: 14.6s\n",
      "78:\tlearn: 1.8310917\ttotal: 1.25s\tremaining: 14.5s\n",
      "79:\tlearn: 1.8303461\ttotal: 1.26s\tremaining: 14.5s\n",
      "80:\tlearn: 1.8277953\ttotal: 1.28s\tremaining: 14.5s\n",
      "81:\tlearn: 1.8268455\ttotal: 1.29s\tremaining: 14.5s\n",
      "82:\tlearn: 1.8263264\ttotal: 1.31s\tremaining: 14.4s\n",
      "83:\tlearn: 1.8260386\ttotal: 1.32s\tremaining: 14.4s\n",
      "84:\tlearn: 1.8213846\ttotal: 1.34s\tremaining: 14.4s\n",
      "85:\tlearn: 1.8211084\ttotal: 1.36s\tremaining: 14.4s\n",
      "86:\tlearn: 1.8208848\ttotal: 1.37s\tremaining: 14.4s\n",
      "87:\tlearn: 1.8198992\ttotal: 1.39s\tremaining: 14.4s\n",
      "88:\tlearn: 1.8188455\ttotal: 1.4s\tremaining: 14.3s\n",
      "89:\tlearn: 1.8175407\ttotal: 1.41s\tremaining: 14.3s\n",
      "90:\tlearn: 1.8173503\ttotal: 1.43s\tremaining: 14.2s\n",
      "91:\tlearn: 1.8167180\ttotal: 1.44s\tremaining: 14.2s\n",
      "92:\tlearn: 1.8167146\ttotal: 1.45s\tremaining: 14.1s\n",
      "93:\tlearn: 1.8159614\ttotal: 1.46s\tremaining: 14.1s\n",
      "94:\tlearn: 1.8156456\ttotal: 1.47s\tremaining: 14s\n",
      "95:\tlearn: 1.8156305\ttotal: 1.49s\tremaining: 14s\n",
      "96:\tlearn: 1.8144875\ttotal: 1.5s\tremaining: 14s\n",
      "97:\tlearn: 1.8138491\ttotal: 1.51s\tremaining: 13.9s\n",
      "98:\tlearn: 1.8079010\ttotal: 1.52s\tremaining: 13.9s\n",
      "99:\tlearn: 1.8077337\ttotal: 1.54s\tremaining: 13.8s\n",
      "100:\tlearn: 1.8072877\ttotal: 1.55s\tremaining: 13.8s\n",
      "101:\tlearn: 1.8056487\ttotal: 1.57s\tremaining: 13.8s\n",
      "102:\tlearn: 1.8031277\ttotal: 1.58s\tremaining: 13.8s\n",
      "103:\tlearn: 1.7951203\ttotal: 1.6s\tremaining: 13.8s\n",
      "104:\tlearn: 1.7945629\ttotal: 1.62s\tremaining: 13.8s\n",
      "105:\tlearn: 1.7937082\ttotal: 1.64s\tremaining: 13.8s\n",
      "106:\tlearn: 1.7936835\ttotal: 1.65s\tremaining: 13.8s\n",
      "107:\tlearn: 1.7934366\ttotal: 1.67s\tremaining: 13.8s\n",
      "108:\tlearn: 1.7913378\ttotal: 1.68s\tremaining: 13.8s\n",
      "109:\tlearn: 1.7911889\ttotal: 1.7s\tremaining: 13.8s\n",
      "110:\tlearn: 1.7854528\ttotal: 1.72s\tremaining: 13.8s\n",
      "111:\tlearn: 1.7850924\ttotal: 1.74s\tremaining: 13.8s\n",
      "112:\tlearn: 1.7845209\ttotal: 1.75s\tremaining: 13.8s\n",
      "113:\tlearn: 1.7844059\ttotal: 1.77s\tremaining: 13.8s\n",
      "114:\tlearn: 1.7839212\ttotal: 1.79s\tremaining: 13.7s\n",
      "115:\tlearn: 1.7836821\ttotal: 1.8s\tremaining: 13.8s\n",
      "116:\tlearn: 1.7827405\ttotal: 1.82s\tremaining: 13.8s\n",
      "117:\tlearn: 1.7795088\ttotal: 1.84s\tremaining: 13.7s\n",
      "118:\tlearn: 1.7793252\ttotal: 1.85s\tremaining: 13.7s\n",
      "119:\tlearn: 1.7750614\ttotal: 1.87s\tremaining: 13.7s\n",
      "120:\tlearn: 1.7709862\ttotal: 1.89s\tremaining: 13.7s\n",
      "121:\tlearn: 1.7687356\ttotal: 1.91s\tremaining: 13.7s\n",
      "122:\tlearn: 1.7684121\ttotal: 1.92s\tremaining: 13.7s\n",
      "123:\tlearn: 1.7675211\ttotal: 1.94s\tremaining: 13.7s\n",
      "124:\tlearn: 1.7671757\ttotal: 1.96s\tremaining: 13.7s\n",
      "125:\tlearn: 1.7670719\ttotal: 1.98s\tremaining: 13.7s\n",
      "126:\tlearn: 1.7623185\ttotal: 2s\tremaining: 13.7s\n",
      "127:\tlearn: 1.7605378\ttotal: 2.01s\tremaining: 13.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128:\tlearn: 1.7591164\ttotal: 2.03s\tremaining: 13.7s\n",
      "129:\tlearn: 1.7528406\ttotal: 2.05s\tremaining: 13.7s\n",
      "130:\tlearn: 1.7450706\ttotal: 2.07s\tremaining: 13.7s\n",
      "131:\tlearn: 1.7385758\ttotal: 2.08s\tremaining: 13.7s\n",
      "132:\tlearn: 1.7352597\ttotal: 2.1s\tremaining: 13.7s\n",
      "133:\tlearn: 1.7308696\ttotal: 2.12s\tremaining: 13.7s\n",
      "134:\tlearn: 1.7293376\ttotal: 2.14s\tremaining: 13.7s\n",
      "135:\tlearn: 1.7250837\ttotal: 2.16s\tremaining: 13.7s\n",
      "136:\tlearn: 1.7240466\ttotal: 2.17s\tremaining: 13.7s\n",
      "137:\tlearn: 1.7230000\ttotal: 2.19s\tremaining: 13.7s\n",
      "138:\tlearn: 1.7211632\ttotal: 2.21s\tremaining: 13.7s\n",
      "139:\tlearn: 1.7184667\ttotal: 2.23s\tremaining: 13.7s\n",
      "140:\tlearn: 1.7178159\ttotal: 2.25s\tremaining: 13.7s\n",
      "141:\tlearn: 1.7134568\ttotal: 2.26s\tremaining: 13.7s\n",
      "142:\tlearn: 1.7126048\ttotal: 2.28s\tremaining: 13.7s\n",
      "143:\tlearn: 1.7115020\ttotal: 2.3s\tremaining: 13.6s\n",
      "144:\tlearn: 1.7079821\ttotal: 2.31s\tremaining: 13.6s\n",
      "145:\tlearn: 1.7068888\ttotal: 2.33s\tremaining: 13.6s\n",
      "146:\tlearn: 1.7034214\ttotal: 2.34s\tremaining: 13.6s\n",
      "147:\tlearn: 1.7018542\ttotal: 2.35s\tremaining: 13.6s\n",
      "148:\tlearn: 1.7007268\ttotal: 2.37s\tremaining: 13.5s\n",
      "149:\tlearn: 1.6987356\ttotal: 2.38s\tremaining: 13.5s\n",
      "150:\tlearn: 1.6974425\ttotal: 2.4s\tremaining: 13.5s\n",
      "151:\tlearn: 1.6952371\ttotal: 2.42s\tremaining: 13.5s\n",
      "152:\tlearn: 1.6938276\ttotal: 2.43s\tremaining: 13.5s\n",
      "153:\tlearn: 1.6914177\ttotal: 2.45s\tremaining: 13.4s\n",
      "154:\tlearn: 1.6892812\ttotal: 2.46s\tremaining: 13.4s\n",
      "155:\tlearn: 1.6868363\ttotal: 2.48s\tremaining: 13.4s\n",
      "156:\tlearn: 1.6853062\ttotal: 2.49s\tremaining: 13.4s\n",
      "157:\tlearn: 1.6824092\ttotal: 2.51s\tremaining: 13.4s\n",
      "158:\tlearn: 1.6809796\ttotal: 2.53s\tremaining: 13.4s\n",
      "159:\tlearn: 1.6791178\ttotal: 2.54s\tremaining: 13.3s\n",
      "160:\tlearn: 1.6760844\ttotal: 2.56s\tremaining: 13.3s\n",
      "161:\tlearn: 1.6731492\ttotal: 2.58s\tremaining: 13.3s\n",
      "162:\tlearn: 1.6711923\ttotal: 2.59s\tremaining: 13.3s\n",
      "163:\tlearn: 1.6696355\ttotal: 2.6s\tremaining: 13.3s\n",
      "164:\tlearn: 1.6688697\ttotal: 2.62s\tremaining: 13.3s\n",
      "165:\tlearn: 1.6659371\ttotal: 2.63s\tremaining: 13.2s\n",
      "166:\tlearn: 1.6637987\ttotal: 2.65s\tremaining: 13.2s\n",
      "167:\tlearn: 1.6625144\ttotal: 2.67s\tremaining: 13.2s\n",
      "168:\tlearn: 1.6603173\ttotal: 2.68s\tremaining: 13.2s\n",
      "169:\tlearn: 1.6584921\ttotal: 2.69s\tremaining: 13.2s\n",
      "170:\tlearn: 1.6562649\ttotal: 2.71s\tremaining: 13.1s\n",
      "171:\tlearn: 1.6529374\ttotal: 2.72s\tremaining: 13.1s\n",
      "172:\tlearn: 1.6503792\ttotal: 2.73s\tremaining: 13.1s\n",
      "173:\tlearn: 1.6478162\ttotal: 2.75s\tremaining: 13.1s\n",
      "174:\tlearn: 1.6449929\ttotal: 2.76s\tremaining: 13s\n",
      "175:\tlearn: 1.6443501\ttotal: 2.77s\tremaining: 13s\n",
      "176:\tlearn: 1.6431198\ttotal: 2.79s\tremaining: 13s\n",
      "177:\tlearn: 1.6424072\ttotal: 2.8s\tremaining: 12.9s\n",
      "178:\tlearn: 1.6415602\ttotal: 2.81s\tremaining: 12.9s\n",
      "179:\tlearn: 1.6394865\ttotal: 2.83s\tremaining: 12.9s\n",
      "180:\tlearn: 1.6368252\ttotal: 2.84s\tremaining: 12.9s\n",
      "181:\tlearn: 1.6348797\ttotal: 2.86s\tremaining: 12.8s\n",
      "182:\tlearn: 1.6324605\ttotal: 2.87s\tremaining: 12.8s\n",
      "183:\tlearn: 1.6302138\ttotal: 2.89s\tremaining: 12.8s\n",
      "184:\tlearn: 1.6269914\ttotal: 2.9s\tremaining: 12.8s\n",
      "185:\tlearn: 1.6241723\ttotal: 2.92s\tremaining: 12.8s\n",
      "186:\tlearn: 1.6233533\ttotal: 2.93s\tremaining: 12.8s\n",
      "187:\tlearn: 1.6218388\ttotal: 2.95s\tremaining: 12.7s\n",
      "188:\tlearn: 1.6204021\ttotal: 2.96s\tremaining: 12.7s\n",
      "189:\tlearn: 1.6191340\ttotal: 2.98s\tremaining: 12.7s\n",
      "190:\tlearn: 1.6179553\ttotal: 2.99s\tremaining: 12.7s\n",
      "191:\tlearn: 1.6172073\ttotal: 3s\tremaining: 12.6s\n",
      "192:\tlearn: 1.6158925\ttotal: 3.02s\tremaining: 12.6s\n",
      "193:\tlearn: 1.6149754\ttotal: 3.03s\tremaining: 12.6s\n",
      "194:\tlearn: 1.6140257\ttotal: 3.04s\tremaining: 12.6s\n",
      "195:\tlearn: 1.6124861\ttotal: 3.06s\tremaining: 12.5s\n",
      "196:\tlearn: 1.6109190\ttotal: 3.07s\tremaining: 12.5s\n",
      "197:\tlearn: 1.6070461\ttotal: 3.09s\tremaining: 12.5s\n",
      "198:\tlearn: 1.6038052\ttotal: 3.1s\tremaining: 12.5s\n",
      "199:\tlearn: 1.6018530\ttotal: 3.12s\tremaining: 12.5s\n",
      "200:\tlearn: 1.6004375\ttotal: 3.13s\tremaining: 12.4s\n",
      "201:\tlearn: 1.5999729\ttotal: 3.14s\tremaining: 12.4s\n",
      "202:\tlearn: 1.5997432\ttotal: 3.15s\tremaining: 12.4s\n",
      "203:\tlearn: 1.5996256\ttotal: 3.17s\tremaining: 12.4s\n",
      "204:\tlearn: 1.5989147\ttotal: 3.18s\tremaining: 12.3s\n",
      "205:\tlearn: 1.5976191\ttotal: 3.19s\tremaining: 12.3s\n",
      "206:\tlearn: 1.5972481\ttotal: 3.21s\tremaining: 12.3s\n",
      "207:\tlearn: 1.5964177\ttotal: 3.22s\tremaining: 12.3s\n",
      "208:\tlearn: 1.5961189\ttotal: 3.23s\tremaining: 12.2s\n",
      "209:\tlearn: 1.5959369\ttotal: 3.25s\tremaining: 12.2s\n",
      "210:\tlearn: 1.5956003\ttotal: 3.26s\tremaining: 12.2s\n",
      "211:\tlearn: 1.5951996\ttotal: 3.28s\tremaining: 12.2s\n",
      "212:\tlearn: 1.5945183\ttotal: 3.29s\tremaining: 12.2s\n",
      "213:\tlearn: 1.5938457\ttotal: 3.31s\tremaining: 12.1s\n",
      "214:\tlearn: 1.5933852\ttotal: 3.32s\tremaining: 12.1s\n",
      "215:\tlearn: 1.5929999\ttotal: 3.33s\tremaining: 12.1s\n",
      "216:\tlearn: 1.5918201\ttotal: 3.35s\tremaining: 12.1s\n",
      "217:\tlearn: 1.5914721\ttotal: 3.36s\tremaining: 12.1s\n",
      "218:\tlearn: 1.5908009\ttotal: 3.37s\tremaining: 12s\n",
      "219:\tlearn: 1.5891050\ttotal: 3.39s\tremaining: 12s\n",
      "220:\tlearn: 1.5885104\ttotal: 3.4s\tremaining: 12s\n",
      "221:\tlearn: 1.5876437\ttotal: 3.42s\tremaining: 12s\n",
      "222:\tlearn: 1.5870378\ttotal: 3.43s\tremaining: 11.9s\n",
      "223:\tlearn: 1.5864685\ttotal: 3.44s\tremaining: 11.9s\n",
      "224:\tlearn: 1.5857589\ttotal: 3.46s\tremaining: 11.9s\n",
      "225:\tlearn: 1.5856873\ttotal: 3.47s\tremaining: 11.9s\n",
      "226:\tlearn: 1.5851825\ttotal: 3.49s\tremaining: 11.9s\n",
      "227:\tlearn: 1.5843215\ttotal: 3.5s\tremaining: 11.9s\n",
      "228:\tlearn: 1.5839228\ttotal: 3.52s\tremaining: 11.8s\n",
      "229:\tlearn: 1.5833166\ttotal: 3.53s\tremaining: 11.8s\n",
      "230:\tlearn: 1.5818010\ttotal: 3.55s\tremaining: 11.8s\n",
      "231:\tlearn: 1.5815155\ttotal: 3.56s\tremaining: 11.8s\n",
      "232:\tlearn: 1.5796869\ttotal: 3.58s\tremaining: 11.8s\n",
      "233:\tlearn: 1.5783846\ttotal: 3.59s\tremaining: 11.8s\n",
      "234:\tlearn: 1.5779102\ttotal: 3.6s\tremaining: 11.7s\n",
      "235:\tlearn: 1.5776733\ttotal: 3.62s\tremaining: 11.7s\n",
      "236:\tlearn: 1.5762271\ttotal: 3.63s\tremaining: 11.7s\n",
      "237:\tlearn: 1.5749107\ttotal: 3.65s\tremaining: 11.7s\n",
      "238:\tlearn: 1.5737889\ttotal: 3.66s\tremaining: 11.7s\n",
      "239:\tlearn: 1.5728778\ttotal: 3.67s\tremaining: 11.6s\n",
      "240:\tlearn: 1.5719234\ttotal: 3.69s\tremaining: 11.6s\n",
      "241:\tlearn: 1.5703926\ttotal: 3.7s\tremaining: 11.6s\n",
      "242:\tlearn: 1.5701946\ttotal: 3.71s\tremaining: 11.6s\n",
      "243:\tlearn: 1.5698532\ttotal: 3.73s\tremaining: 11.6s\n",
      "244:\tlearn: 1.5685232\ttotal: 3.75s\tremaining: 11.5s\n",
      "245:\tlearn: 1.5677963\ttotal: 3.76s\tremaining: 11.5s\n",
      "246:\tlearn: 1.5672988\ttotal: 3.77s\tremaining: 11.5s\n",
      "247:\tlearn: 1.5668694\ttotal: 3.79s\tremaining: 11.5s\n",
      "248:\tlearn: 1.5662055\ttotal: 3.8s\tremaining: 11.5s\n",
      "249:\tlearn: 1.5656877\ttotal: 3.82s\tremaining: 11.5s\n",
      "250:\tlearn: 1.5649897\ttotal: 3.85s\tremaining: 11.5s\n",
      "251:\tlearn: 1.5643692\ttotal: 3.86s\tremaining: 11.5s\n",
      "252:\tlearn: 1.5635783\ttotal: 3.89s\tremaining: 11.5s\n",
      "253:\tlearn: 1.5627030\ttotal: 3.91s\tremaining: 11.5s\n",
      "254:\tlearn: 1.5617559\ttotal: 3.92s\tremaining: 11.5s\n",
      "255:\tlearn: 1.5608268\ttotal: 3.94s\tremaining: 11.5s\n",
      "256:\tlearn: 1.5598695\ttotal: 3.96s\tremaining: 11.4s\n",
      "257:\tlearn: 1.5590959\ttotal: 3.97s\tremaining: 11.4s\n",
      "258:\tlearn: 1.5583781\ttotal: 3.99s\tremaining: 11.4s\n",
      "259:\tlearn: 1.5572363\ttotal: 4s\tremaining: 11.4s\n",
      "260:\tlearn: 1.5567106\ttotal: 4.02s\tremaining: 11.4s\n",
      "261:\tlearn: 1.5559436\ttotal: 4.03s\tremaining: 11.4s\n",
      "262:\tlearn: 1.5541705\ttotal: 4.05s\tremaining: 11.3s\n",
      "263:\tlearn: 1.5537578\ttotal: 4.06s\tremaining: 11.3s\n",
      "264:\tlearn: 1.5527337\ttotal: 4.07s\tremaining: 11.3s\n",
      "265:\tlearn: 1.5520995\ttotal: 4.09s\tremaining: 11.3s\n",
      "266:\tlearn: 1.5512756\ttotal: 4.1s\tremaining: 11.3s\n",
      "267:\tlearn: 1.5509337\ttotal: 4.11s\tremaining: 11.2s\n",
      "268:\tlearn: 1.5501138\ttotal: 4.13s\tremaining: 11.2s\n",
      "269:\tlearn: 1.5492543\ttotal: 4.14s\tremaining: 11.2s\n",
      "270:\tlearn: 1.5487994\ttotal: 4.16s\tremaining: 11.2s\n",
      "271:\tlearn: 1.5482421\ttotal: 4.17s\tremaining: 11.2s\n",
      "272:\tlearn: 1.5475466\ttotal: 4.19s\tremaining: 11.2s\n",
      "273:\tlearn: 1.5470727\ttotal: 4.2s\tremaining: 11.1s\n",
      "274:\tlearn: 1.5465523\ttotal: 4.21s\tremaining: 11.1s\n",
      "275:\tlearn: 1.5463340\ttotal: 4.23s\tremaining: 11.1s\n",
      "276:\tlearn: 1.5457169\ttotal: 4.24s\tremaining: 11.1s\n",
      "277:\tlearn: 1.5449559\ttotal: 4.26s\tremaining: 11.1s\n",
      "278:\tlearn: 1.5433079\ttotal: 4.28s\tremaining: 11.1s\n",
      "279:\tlearn: 1.5430110\ttotal: 4.3s\tremaining: 11.1s\n",
      "280:\tlearn: 1.5424301\ttotal: 4.31s\tremaining: 11s\n",
      "281:\tlearn: 1.5419417\ttotal: 4.33s\tremaining: 11s\n",
      "282:\tlearn: 1.5416862\ttotal: 4.34s\tremaining: 11s\n",
      "283:\tlearn: 1.5416064\ttotal: 4.36s\tremaining: 11s\n",
      "284:\tlearn: 1.5415430\ttotal: 4.38s\tremaining: 11s\n",
      "285:\tlearn: 1.5414203\ttotal: 4.39s\tremaining: 11s\n",
      "286:\tlearn: 1.5413171\ttotal: 4.41s\tremaining: 11s\n",
      "287:\tlearn: 1.5412187\ttotal: 4.42s\tremaining: 10.9s\n",
      "288:\tlearn: 1.5411693\ttotal: 4.44s\tremaining: 10.9s\n",
      "289:\tlearn: 1.5411387\ttotal: 4.46s\tremaining: 10.9s\n",
      "290:\tlearn: 1.5407092\ttotal: 4.47s\tremaining: 10.9s\n",
      "291:\tlearn: 1.5399421\ttotal: 4.49s\tremaining: 10.9s\n",
      "292:\tlearn: 1.5381884\ttotal: 4.5s\tremaining: 10.9s\n",
      "293:\tlearn: 1.5381146\ttotal: 4.52s\tremaining: 10.8s\n",
      "294:\tlearn: 1.5380438\ttotal: 4.53s\tremaining: 10.8s\n",
      "295:\tlearn: 1.5379483\ttotal: 4.55s\tremaining: 10.8s\n",
      "296:\tlearn: 1.5376386\ttotal: 4.57s\tremaining: 10.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297:\tlearn: 1.5375852\ttotal: 4.59s\tremaining: 10.8s\n",
      "298:\tlearn: 1.5374718\ttotal: 4.61s\tremaining: 10.8s\n",
      "299:\tlearn: 1.5373476\ttotal: 4.62s\tremaining: 10.8s\n",
      "300:\tlearn: 1.5371831\ttotal: 4.64s\tremaining: 10.8s\n",
      "301:\tlearn: 1.5371338\ttotal: 4.65s\tremaining: 10.8s\n",
      "302:\tlearn: 1.5369618\ttotal: 4.67s\tremaining: 10.7s\n",
      "303:\tlearn: 1.5368951\ttotal: 4.69s\tremaining: 10.7s\n",
      "304:\tlearn: 1.5364842\ttotal: 4.7s\tremaining: 10.7s\n",
      "305:\tlearn: 1.5362516\ttotal: 4.72s\tremaining: 10.7s\n",
      "306:\tlearn: 1.5355378\ttotal: 4.73s\tremaining: 10.7s\n",
      "307:\tlearn: 1.5354317\ttotal: 4.75s\tremaining: 10.7s\n",
      "308:\tlearn: 1.5352278\ttotal: 4.76s\tremaining: 10.7s\n",
      "309:\tlearn: 1.5345836\ttotal: 4.78s\tremaining: 10.6s\n",
      "310:\tlearn: 1.5341874\ttotal: 4.79s\tremaining: 10.6s\n",
      "311:\tlearn: 1.5334098\ttotal: 4.81s\tremaining: 10.6s\n",
      "312:\tlearn: 1.5329232\ttotal: 4.83s\tremaining: 10.6s\n",
      "313:\tlearn: 1.5323769\ttotal: 4.84s\tremaining: 10.6s\n",
      "314:\tlearn: 1.5315849\ttotal: 4.86s\tremaining: 10.6s\n",
      "315:\tlearn: 1.5313965\ttotal: 4.87s\tremaining: 10.5s\n",
      "316:\tlearn: 1.5305884\ttotal: 4.89s\tremaining: 10.5s\n",
      "317:\tlearn: 1.5303916\ttotal: 4.9s\tremaining: 10.5s\n",
      "318:\tlearn: 1.5298247\ttotal: 4.92s\tremaining: 10.5s\n",
      "319:\tlearn: 1.5289499\ttotal: 4.94s\tremaining: 10.5s\n",
      "320:\tlearn: 1.5282328\ttotal: 4.95s\tremaining: 10.5s\n",
      "321:\tlearn: 1.5275583\ttotal: 4.97s\tremaining: 10.5s\n",
      "322:\tlearn: 1.5274035\ttotal: 4.99s\tremaining: 10.5s\n",
      "323:\tlearn: 1.5260096\ttotal: 5s\tremaining: 10.4s\n",
      "324:\tlearn: 1.5258131\ttotal: 5.02s\tremaining: 10.4s\n",
      "325:\tlearn: 1.5243445\ttotal: 5.04s\tremaining: 10.4s\n",
      "326:\tlearn: 1.5238732\ttotal: 5.05s\tremaining: 10.4s\n",
      "327:\tlearn: 1.5236722\ttotal: 5.07s\tremaining: 10.4s\n",
      "328:\tlearn: 1.5231755\ttotal: 5.08s\tremaining: 10.4s\n",
      "329:\tlearn: 1.5220118\ttotal: 5.09s\tremaining: 10.3s\n",
      "330:\tlearn: 1.5216382\ttotal: 5.11s\tremaining: 10.3s\n",
      "331:\tlearn: 1.5209461\ttotal: 5.13s\tremaining: 10.3s\n",
      "332:\tlearn: 1.5203683\ttotal: 5.14s\tremaining: 10.3s\n",
      "333:\tlearn: 1.5195060\ttotal: 5.15s\tremaining: 10.3s\n",
      "334:\tlearn: 1.5190031\ttotal: 5.17s\tremaining: 10.3s\n",
      "335:\tlearn: 1.5189880\ttotal: 5.18s\tremaining: 10.2s\n",
      "336:\tlearn: 1.5183818\ttotal: 5.2s\tremaining: 10.2s\n",
      "337:\tlearn: 1.5179702\ttotal: 5.21s\tremaining: 10.2s\n",
      "338:\tlearn: 1.5170726\ttotal: 5.23s\tremaining: 10.2s\n",
      "339:\tlearn: 1.5160070\ttotal: 5.25s\tremaining: 10.2s\n",
      "340:\tlearn: 1.5157808\ttotal: 5.26s\tremaining: 10.2s\n",
      "341:\tlearn: 1.5149018\ttotal: 5.28s\tremaining: 10.2s\n",
      "342:\tlearn: 1.5137647\ttotal: 5.29s\tremaining: 10.1s\n",
      "343:\tlearn: 1.5124624\ttotal: 5.3s\tremaining: 10.1s\n",
      "344:\tlearn: 1.5118194\ttotal: 5.32s\tremaining: 10.1s\n",
      "345:\tlearn: 1.5112158\ttotal: 5.33s\tremaining: 10.1s\n",
      "346:\tlearn: 1.5108921\ttotal: 5.34s\tremaining: 10.1s\n",
      "347:\tlearn: 1.5108311\ttotal: 5.36s\tremaining: 10s\n",
      "348:\tlearn: 1.5108018\ttotal: 5.37s\tremaining: 10s\n",
      "349:\tlearn: 1.5107021\ttotal: 5.38s\tremaining: 10s\n",
      "350:\tlearn: 1.5098887\ttotal: 5.4s\tremaining: 9.98s\n",
      "351:\tlearn: 1.5098822\ttotal: 5.41s\tremaining: 9.96s\n",
      "352:\tlearn: 1.5088624\ttotal: 5.42s\tremaining: 9.94s\n",
      "353:\tlearn: 1.5086970\ttotal: 5.44s\tremaining: 9.92s\n",
      "354:\tlearn: 1.5086760\ttotal: 5.45s\tremaining: 9.9s\n",
      "355:\tlearn: 1.5077326\ttotal: 5.46s\tremaining: 9.89s\n",
      "356:\tlearn: 1.5071664\ttotal: 5.48s\tremaining: 9.87s\n",
      "357:\tlearn: 1.5070086\ttotal: 5.49s\tremaining: 9.85s\n",
      "358:\tlearn: 1.5069406\ttotal: 5.51s\tremaining: 9.84s\n",
      "359:\tlearn: 1.5066379\ttotal: 5.52s\tremaining: 9.82s\n",
      "360:\tlearn: 1.5065757\ttotal: 5.54s\tremaining: 9.8s\n",
      "361:\tlearn: 1.5058066\ttotal: 5.55s\tremaining: 9.79s\n",
      "362:\tlearn: 1.5055984\ttotal: 5.57s\tremaining: 9.78s\n",
      "363:\tlearn: 1.5053852\ttotal: 5.59s\tremaining: 9.76s\n",
      "364:\tlearn: 1.5050624\ttotal: 5.6s\tremaining: 9.75s\n",
      "365:\tlearn: 1.5050262\ttotal: 5.62s\tremaining: 9.73s\n",
      "366:\tlearn: 1.5049984\ttotal: 5.63s\tremaining: 9.72s\n",
      "367:\tlearn: 1.5045369\ttotal: 5.65s\tremaining: 9.71s\n",
      "368:\tlearn: 1.5040369\ttotal: 5.67s\tremaining: 9.69s\n",
      "369:\tlearn: 1.5035792\ttotal: 5.68s\tremaining: 9.68s\n",
      "370:\tlearn: 1.5032889\ttotal: 5.7s\tremaining: 9.67s\n",
      "371:\tlearn: 1.5027985\ttotal: 5.72s\tremaining: 9.65s\n",
      "372:\tlearn: 1.5026781\ttotal: 5.73s\tremaining: 9.64s\n",
      "373:\tlearn: 1.5022860\ttotal: 5.75s\tremaining: 9.63s\n",
      "374:\tlearn: 1.5020118\ttotal: 5.76s\tremaining: 9.61s\n",
      "375:\tlearn: 1.5017083\ttotal: 5.78s\tremaining: 9.59s\n",
      "376:\tlearn: 1.5013169\ttotal: 5.8s\tremaining: 9.58s\n",
      "377:\tlearn: 1.5012476\ttotal: 5.81s\tremaining: 9.56s\n",
      "378:\tlearn: 1.5012217\ttotal: 5.82s\tremaining: 9.54s\n",
      "379:\tlearn: 1.5011776\ttotal: 5.83s\tremaining: 9.52s\n",
      "380:\tlearn: 1.5011266\ttotal: 5.85s\tremaining: 9.5s\n",
      "381:\tlearn: 1.5011070\ttotal: 5.86s\tremaining: 9.48s\n",
      "382:\tlearn: 1.5004861\ttotal: 5.87s\tremaining: 9.46s\n",
      "383:\tlearn: 1.5004709\ttotal: 5.89s\tremaining: 9.44s\n",
      "384:\tlearn: 1.5004187\ttotal: 5.9s\tremaining: 9.43s\n",
      "385:\tlearn: 1.5002249\ttotal: 5.92s\tremaining: 9.41s\n",
      "386:\tlearn: 1.5001056\ttotal: 5.93s\tremaining: 9.39s\n",
      "387:\tlearn: 1.4996947\ttotal: 5.94s\tremaining: 9.37s\n",
      "388:\tlearn: 1.4990839\ttotal: 5.96s\tremaining: 9.35s\n",
      "389:\tlearn: 1.4981609\ttotal: 5.97s\tremaining: 9.34s\n",
      "390:\tlearn: 1.4981260\ttotal: 5.98s\tremaining: 9.32s\n",
      "391:\tlearn: 1.4976501\ttotal: 6s\tremaining: 9.3s\n",
      "392:\tlearn: 1.4975115\ttotal: 6.01s\tremaining: 9.28s\n",
      "393:\tlearn: 1.4967254\ttotal: 6.02s\tremaining: 9.26s\n",
      "394:\tlearn: 1.4966392\ttotal: 6.03s\tremaining: 9.24s\n",
      "395:\tlearn: 1.4963277\ttotal: 6.05s\tremaining: 9.23s\n",
      "396:\tlearn: 1.4960352\ttotal: 6.06s\tremaining: 9.21s\n",
      "397:\tlearn: 1.4957988\ttotal: 6.08s\tremaining: 9.19s\n",
      "398:\tlearn: 1.4955784\ttotal: 6.09s\tremaining: 9.17s\n",
      "399:\tlearn: 1.4954688\ttotal: 6.11s\tremaining: 9.16s\n",
      "400:\tlearn: 1.4952996\ttotal: 6.12s\tremaining: 9.14s\n",
      "401:\tlearn: 1.4952976\ttotal: 6.14s\tremaining: 9.14s\n",
      "402:\tlearn: 1.4952737\ttotal: 6.16s\tremaining: 9.13s\n",
      "403:\tlearn: 1.4952736\ttotal: 6.18s\tremaining: 9.12s\n",
      "404:\tlearn: 1.4952585\ttotal: 6.19s\tremaining: 9.1s\n",
      "405:\tlearn: 1.4951405\ttotal: 6.21s\tremaining: 9.08s\n",
      "406:\tlearn: 1.4949773\ttotal: 6.22s\tremaining: 9.07s\n",
      "407:\tlearn: 1.4949176\ttotal: 6.24s\tremaining: 9.05s\n",
      "408:\tlearn: 1.4948551\ttotal: 6.25s\tremaining: 9.03s\n",
      "409:\tlearn: 1.4938350\ttotal: 6.26s\tremaining: 9.02s\n",
      "410:\tlearn: 1.4938245\ttotal: 6.28s\tremaining: 9s\n",
      "411:\tlearn: 1.4938091\ttotal: 6.29s\tremaining: 8.98s\n",
      "412:\tlearn: 1.4937174\ttotal: 6.31s\tremaining: 8.97s\n",
      "413:\tlearn: 1.4935556\ttotal: 6.32s\tremaining: 8.95s\n",
      "414:\tlearn: 1.4935536\ttotal: 6.33s\tremaining: 8.93s\n",
      "415:\tlearn: 1.4935239\ttotal: 6.35s\tremaining: 8.91s\n",
      "416:\tlearn: 1.4934881\ttotal: 6.36s\tremaining: 8.9s\n",
      "417:\tlearn: 1.4933175\ttotal: 6.38s\tremaining: 8.88s\n",
      "418:\tlearn: 1.4924547\ttotal: 6.39s\tremaining: 8.86s\n",
      "419:\tlearn: 1.4922634\ttotal: 6.4s\tremaining: 8.84s\n",
      "420:\tlearn: 1.4921891\ttotal: 6.42s\tremaining: 8.83s\n",
      "421:\tlearn: 1.4919197\ttotal: 6.43s\tremaining: 8.81s\n",
      "422:\tlearn: 1.4917750\ttotal: 6.44s\tremaining: 8.79s\n",
      "423:\tlearn: 1.4915383\ttotal: 6.46s\tremaining: 8.77s\n",
      "424:\tlearn: 1.4909495\ttotal: 6.47s\tremaining: 8.76s\n",
      "425:\tlearn: 1.4899926\ttotal: 6.49s\tremaining: 8.74s\n",
      "426:\tlearn: 1.4889454\ttotal: 6.5s\tremaining: 8.72s\n",
      "427:\tlearn: 1.4889433\ttotal: 6.51s\tremaining: 8.71s\n",
      "428:\tlearn: 1.4889431\ttotal: 6.53s\tremaining: 8.69s\n",
      "429:\tlearn: 1.4889392\ttotal: 6.54s\tremaining: 8.67s\n",
      "430:\tlearn: 1.4889331\ttotal: 6.55s\tremaining: 8.65s\n",
      "431:\tlearn: 1.4889165\ttotal: 6.57s\tremaining: 8.64s\n",
      "432:\tlearn: 1.4888885\ttotal: 6.58s\tremaining: 8.62s\n",
      "433:\tlearn: 1.4888885\ttotal: 6.59s\tremaining: 8.6s\n",
      "434:\tlearn: 1.4888854\ttotal: 6.61s\tremaining: 8.58s\n",
      "435:\tlearn: 1.4887555\ttotal: 6.62s\tremaining: 8.56s\n",
      "436:\tlearn: 1.4886218\ttotal: 6.63s\tremaining: 8.55s\n",
      "437:\tlearn: 1.4886173\ttotal: 6.65s\tremaining: 8.53s\n",
      "438:\tlearn: 1.4884410\ttotal: 6.66s\tremaining: 8.51s\n",
      "439:\tlearn: 1.4884403\ttotal: 6.67s\tremaining: 8.49s\n",
      "440:\tlearn: 1.4884392\ttotal: 6.69s\tremaining: 8.47s\n",
      "441:\tlearn: 1.4884385\ttotal: 6.7s\tremaining: 8.46s\n",
      "442:\tlearn: 1.4884385\ttotal: 6.71s\tremaining: 8.44s\n",
      "443:\tlearn: 1.4884383\ttotal: 6.72s\tremaining: 8.42s\n",
      "444:\tlearn: 1.4884383\ttotal: 6.74s\tremaining: 8.41s\n",
      "445:\tlearn: 1.4880122\ttotal: 6.75s\tremaining: 8.39s\n",
      "446:\tlearn: 1.4877770\ttotal: 6.77s\tremaining: 8.37s\n",
      "447:\tlearn: 1.4877767\ttotal: 6.78s\tremaining: 8.35s\n",
      "448:\tlearn: 1.4877759\ttotal: 6.79s\tremaining: 8.33s\n",
      "449:\tlearn: 1.4877759\ttotal: 6.8s\tremaining: 8.32s\n",
      "450:\tlearn: 1.4877759\ttotal: 6.82s\tremaining: 8.3s\n",
      "451:\tlearn: 1.4873725\ttotal: 6.83s\tremaining: 8.28s\n",
      "452:\tlearn: 1.4873502\ttotal: 6.84s\tremaining: 8.27s\n",
      "453:\tlearn: 1.4872974\ttotal: 6.86s\tremaining: 8.25s\n",
      "454:\tlearn: 1.4869525\ttotal: 6.87s\tremaining: 8.23s\n",
      "455:\tlearn: 1.4869388\ttotal: 6.88s\tremaining: 8.21s\n",
      "456:\tlearn: 1.4869369\ttotal: 6.9s\tremaining: 8.2s\n",
      "457:\tlearn: 1.4869361\ttotal: 6.91s\tremaining: 8.18s\n",
      "458:\tlearn: 1.4868832\ttotal: 6.92s\tremaining: 8.16s\n",
      "459:\tlearn: 1.4866894\ttotal: 6.94s\tremaining: 8.14s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460:\tlearn: 1.4863588\ttotal: 6.95s\tremaining: 8.13s\n",
      "461:\tlearn: 1.4863577\ttotal: 6.96s\tremaining: 8.11s\n",
      "462:\tlearn: 1.4863442\ttotal: 6.98s\tremaining: 8.09s\n",
      "463:\tlearn: 1.4855112\ttotal: 6.99s\tremaining: 8.08s\n",
      "464:\tlearn: 1.4854143\ttotal: 7.01s\tremaining: 8.06s\n",
      "465:\tlearn: 1.4848842\ttotal: 7.02s\tremaining: 8.04s\n",
      "466:\tlearn: 1.4843068\ttotal: 7.03s\tremaining: 8.03s\n",
      "467:\tlearn: 1.4842841\ttotal: 7.05s\tremaining: 8.01s\n",
      "468:\tlearn: 1.4842623\ttotal: 7.06s\tremaining: 7.99s\n",
      "469:\tlearn: 1.4841399\ttotal: 7.07s\tremaining: 7.98s\n",
      "470:\tlearn: 1.4841269\ttotal: 7.09s\tremaining: 7.96s\n",
      "471:\tlearn: 1.4841198\ttotal: 7.1s\tremaining: 7.94s\n",
      "472:\tlearn: 1.4841198\ttotal: 7.11s\tremaining: 7.92s\n",
      "473:\tlearn: 1.4841168\ttotal: 7.13s\tremaining: 7.91s\n",
      "474:\tlearn: 1.4835782\ttotal: 7.14s\tremaining: 7.89s\n",
      "475:\tlearn: 1.4835453\ttotal: 7.15s\tremaining: 7.88s\n",
      "476:\tlearn: 1.4835452\ttotal: 7.17s\tremaining: 7.86s\n",
      "477:\tlearn: 1.4835449\ttotal: 7.18s\tremaining: 7.84s\n",
      "478:\tlearn: 1.4835438\ttotal: 7.19s\tremaining: 7.82s\n",
      "479:\tlearn: 1.4834110\ttotal: 7.21s\tremaining: 7.81s\n",
      "480:\tlearn: 1.4833984\ttotal: 7.22s\tremaining: 7.79s\n",
      "481:\tlearn: 1.4829857\ttotal: 7.23s\tremaining: 7.77s\n",
      "482:\tlearn: 1.4828977\ttotal: 7.25s\tremaining: 7.76s\n",
      "483:\tlearn: 1.4828660\ttotal: 7.26s\tremaining: 7.74s\n",
      "484:\tlearn: 1.4825660\ttotal: 7.27s\tremaining: 7.72s\n",
      "485:\tlearn: 1.4825660\ttotal: 7.29s\tremaining: 7.71s\n",
      "486:\tlearn: 1.4824019\ttotal: 7.3s\tremaining: 7.69s\n",
      "487:\tlearn: 1.4823738\ttotal: 7.31s\tremaining: 7.67s\n",
      "488:\tlearn: 1.4817460\ttotal: 7.33s\tremaining: 7.66s\n",
      "489:\tlearn: 1.4815538\ttotal: 7.34s\tremaining: 7.64s\n",
      "490:\tlearn: 1.4814506\ttotal: 7.36s\tremaining: 7.63s\n",
      "491:\tlearn: 1.4807131\ttotal: 7.37s\tremaining: 7.61s\n",
      "492:\tlearn: 1.4804409\ttotal: 7.38s\tremaining: 7.59s\n",
      "493:\tlearn: 1.4803697\ttotal: 7.39s\tremaining: 7.58s\n",
      "494:\tlearn: 1.4796862\ttotal: 7.41s\tremaining: 7.56s\n",
      "495:\tlearn: 1.4796408\ttotal: 7.42s\tremaining: 7.54s\n",
      "496:\tlearn: 1.4796311\ttotal: 7.43s\tremaining: 7.52s\n",
      "497:\tlearn: 1.4796280\ttotal: 7.45s\tremaining: 7.5s\n",
      "498:\tlearn: 1.4796274\ttotal: 7.46s\tremaining: 7.49s\n",
      "499:\tlearn: 1.4795605\ttotal: 7.47s\tremaining: 7.47s\n",
      "500:\tlearn: 1.4795009\ttotal: 7.49s\tremaining: 7.46s\n",
      "501:\tlearn: 1.4790174\ttotal: 7.5s\tremaining: 7.44s\n",
      "502:\tlearn: 1.4790139\ttotal: 7.51s\tremaining: 7.42s\n",
      "503:\tlearn: 1.4790056\ttotal: 7.53s\tremaining: 7.41s\n",
      "504:\tlearn: 1.4790034\ttotal: 7.54s\tremaining: 7.39s\n",
      "505:\tlearn: 1.4789552\ttotal: 7.55s\tremaining: 7.37s\n",
      "506:\tlearn: 1.4786028\ttotal: 7.57s\tremaining: 7.36s\n",
      "507:\tlearn: 1.4782537\ttotal: 7.58s\tremaining: 7.34s\n",
      "508:\tlearn: 1.4781899\ttotal: 7.59s\tremaining: 7.33s\n",
      "509:\tlearn: 1.4780595\ttotal: 7.61s\tremaining: 7.31s\n",
      "510:\tlearn: 1.4773102\ttotal: 7.62s\tremaining: 7.29s\n",
      "511:\tlearn: 1.4772248\ttotal: 7.63s\tremaining: 7.27s\n",
      "512:\tlearn: 1.4771460\ttotal: 7.64s\tremaining: 7.26s\n",
      "513:\tlearn: 1.4771460\ttotal: 7.66s\tremaining: 7.24s\n",
      "514:\tlearn: 1.4771178\ttotal: 7.67s\tremaining: 7.22s\n",
      "515:\tlearn: 1.4770515\ttotal: 7.68s\tremaining: 7.21s\n",
      "516:\tlearn: 1.4766385\ttotal: 7.7s\tremaining: 7.19s\n",
      "517:\tlearn: 1.4766337\ttotal: 7.71s\tremaining: 7.17s\n",
      "518:\tlearn: 1.4766315\ttotal: 7.72s\tremaining: 7.16s\n",
      "519:\tlearn: 1.4766303\ttotal: 7.74s\tremaining: 7.14s\n",
      "520:\tlearn: 1.4765580\ttotal: 7.75s\tremaining: 7.13s\n",
      "521:\tlearn: 1.4759996\ttotal: 7.76s\tremaining: 7.11s\n",
      "522:\tlearn: 1.4759976\ttotal: 7.78s\tremaining: 7.09s\n",
      "523:\tlearn: 1.4759959\ttotal: 7.79s\tremaining: 7.08s\n",
      "524:\tlearn: 1.4759914\ttotal: 7.8s\tremaining: 7.06s\n",
      "525:\tlearn: 1.4759748\ttotal: 7.82s\tremaining: 7.05s\n",
      "526:\tlearn: 1.4759156\ttotal: 7.83s\tremaining: 7.03s\n",
      "527:\tlearn: 1.4758809\ttotal: 7.85s\tremaining: 7.01s\n",
      "528:\tlearn: 1.4758152\ttotal: 7.86s\tremaining: 7s\n",
      "529:\tlearn: 1.4757748\ttotal: 7.87s\tremaining: 6.98s\n",
      "530:\tlearn: 1.4756576\ttotal: 7.89s\tremaining: 6.97s\n",
      "531:\tlearn: 1.4756002\ttotal: 7.9s\tremaining: 6.95s\n",
      "532:\tlearn: 1.4752511\ttotal: 7.91s\tremaining: 6.93s\n",
      "533:\tlearn: 1.4748930\ttotal: 7.93s\tremaining: 6.92s\n",
      "534:\tlearn: 1.4741704\ttotal: 7.94s\tremaining: 6.9s\n",
      "535:\tlearn: 1.4741704\ttotal: 7.95s\tremaining: 6.88s\n",
      "536:\tlearn: 1.4739407\ttotal: 7.97s\tremaining: 6.87s\n",
      "537:\tlearn: 1.4737176\ttotal: 7.98s\tremaining: 6.85s\n",
      "538:\tlearn: 1.4733190\ttotal: 7.99s\tremaining: 6.84s\n",
      "539:\tlearn: 1.4728761\ttotal: 8.01s\tremaining: 6.82s\n",
      "540:\tlearn: 1.4725020\ttotal: 8.02s\tremaining: 6.81s\n",
      "541:\tlearn: 1.4724098\ttotal: 8.04s\tremaining: 6.79s\n",
      "542:\tlearn: 1.4720202\ttotal: 8.05s\tremaining: 6.78s\n",
      "543:\tlearn: 1.4709819\ttotal: 8.06s\tremaining: 6.76s\n",
      "544:\tlearn: 1.4709785\ttotal: 8.08s\tremaining: 6.74s\n",
      "545:\tlearn: 1.4709729\ttotal: 8.09s\tremaining: 6.73s\n",
      "546:\tlearn: 1.4709717\ttotal: 8.1s\tremaining: 6.71s\n",
      "547:\tlearn: 1.4709715\ttotal: 8.12s\tremaining: 6.69s\n",
      "548:\tlearn: 1.4708996\ttotal: 8.13s\tremaining: 6.68s\n",
      "549:\tlearn: 1.4708959\ttotal: 8.14s\tremaining: 6.66s\n",
      "550:\tlearn: 1.4708482\ttotal: 8.15s\tremaining: 6.64s\n",
      "551:\tlearn: 1.4708357\ttotal: 8.17s\tremaining: 6.63s\n",
      "552:\tlearn: 1.4708252\ttotal: 8.18s\tremaining: 6.61s\n",
      "553:\tlearn: 1.4708252\ttotal: 8.19s\tremaining: 6.6s\n",
      "554:\tlearn: 1.4708228\ttotal: 8.21s\tremaining: 6.58s\n",
      "555:\tlearn: 1.4708227\ttotal: 8.22s\tremaining: 6.56s\n",
      "556:\tlearn: 1.4708227\ttotal: 8.23s\tremaining: 6.55s\n",
      "557:\tlearn: 1.4708227\ttotal: 8.25s\tremaining: 6.53s\n",
      "558:\tlearn: 1.4708113\ttotal: 8.26s\tremaining: 6.52s\n",
      "559:\tlearn: 1.4701607\ttotal: 8.27s\tremaining: 6.5s\n",
      "560:\tlearn: 1.4700397\ttotal: 8.29s\tremaining: 6.49s\n",
      "561:\tlearn: 1.4697762\ttotal: 8.3s\tremaining: 6.47s\n",
      "562:\tlearn: 1.4697520\ttotal: 8.31s\tremaining: 6.45s\n",
      "563:\tlearn: 1.4691684\ttotal: 8.33s\tremaining: 6.44s\n",
      "564:\tlearn: 1.4691278\ttotal: 8.34s\tremaining: 6.42s\n",
      "565:\tlearn: 1.4691277\ttotal: 8.36s\tremaining: 6.41s\n",
      "566:\tlearn: 1.4691277\ttotal: 8.37s\tremaining: 6.39s\n",
      "567:\tlearn: 1.4691277\ttotal: 8.38s\tremaining: 6.38s\n",
      "568:\tlearn: 1.4691272\ttotal: 8.4s\tremaining: 6.36s\n",
      "569:\tlearn: 1.4691213\ttotal: 8.41s\tremaining: 6.34s\n",
      "570:\tlearn: 1.4688062\ttotal: 8.43s\tremaining: 6.33s\n",
      "571:\tlearn: 1.4688062\ttotal: 8.44s\tremaining: 6.31s\n",
      "572:\tlearn: 1.4688062\ttotal: 8.45s\tremaining: 6.3s\n",
      "573:\tlearn: 1.4688056\ttotal: 8.46s\tremaining: 6.28s\n",
      "574:\tlearn: 1.4688023\ttotal: 8.48s\tremaining: 6.27s\n",
      "575:\tlearn: 1.4688009\ttotal: 8.49s\tremaining: 6.25s\n",
      "576:\tlearn: 1.4687997\ttotal: 8.51s\tremaining: 6.24s\n",
      "577:\tlearn: 1.4687995\ttotal: 8.52s\tremaining: 6.22s\n",
      "578:\tlearn: 1.4687981\ttotal: 8.53s\tremaining: 6.2s\n",
      "579:\tlearn: 1.4687959\ttotal: 8.54s\tremaining: 6.19s\n",
      "580:\tlearn: 1.4687959\ttotal: 8.56s\tremaining: 6.17s\n",
      "581:\tlearn: 1.4687959\ttotal: 8.57s\tremaining: 6.16s\n",
      "582:\tlearn: 1.4687958\ttotal: 8.59s\tremaining: 6.14s\n",
      "583:\tlearn: 1.4687956\ttotal: 8.6s\tremaining: 6.13s\n",
      "584:\tlearn: 1.4687866\ttotal: 8.61s\tremaining: 6.11s\n",
      "585:\tlearn: 1.4687665\ttotal: 8.63s\tremaining: 6.1s\n",
      "586:\tlearn: 1.4680634\ttotal: 8.65s\tremaining: 6.09s\n",
      "587:\tlearn: 1.4680293\ttotal: 8.66s\tremaining: 6.07s\n",
      "588:\tlearn: 1.4668948\ttotal: 8.68s\tremaining: 6.06s\n",
      "589:\tlearn: 1.4668635\ttotal: 8.69s\tremaining: 6.04s\n",
      "590:\tlearn: 1.4668451\ttotal: 8.71s\tremaining: 6.02s\n",
      "591:\tlearn: 1.4664821\ttotal: 8.72s\tremaining: 6.01s\n",
      "592:\tlearn: 1.4652572\ttotal: 8.73s\tremaining: 5.99s\n",
      "593:\tlearn: 1.4645411\ttotal: 8.74s\tremaining: 5.98s\n",
      "594:\tlearn: 1.4645410\ttotal: 8.76s\tremaining: 5.96s\n",
      "595:\tlearn: 1.4645410\ttotal: 8.77s\tremaining: 5.95s\n",
      "596:\tlearn: 1.4645339\ttotal: 8.79s\tremaining: 5.93s\n",
      "597:\tlearn: 1.4645338\ttotal: 8.8s\tremaining: 5.91s\n",
      "598:\tlearn: 1.4645070\ttotal: 8.81s\tremaining: 5.9s\n",
      "599:\tlearn: 1.4645070\ttotal: 8.82s\tremaining: 5.88s\n",
      "600:\tlearn: 1.4645068\ttotal: 8.84s\tremaining: 5.87s\n",
      "601:\tlearn: 1.4645062\ttotal: 8.85s\tremaining: 5.85s\n",
      "602:\tlearn: 1.4645015\ttotal: 8.86s\tremaining: 5.83s\n",
      "603:\tlearn: 1.4645005\ttotal: 8.88s\tremaining: 5.82s\n",
      "604:\tlearn: 1.4638636\ttotal: 8.89s\tremaining: 5.8s\n",
      "605:\tlearn: 1.4634216\ttotal: 8.9s\tremaining: 5.79s\n",
      "606:\tlearn: 1.4634206\ttotal: 8.92s\tremaining: 5.77s\n",
      "607:\tlearn: 1.4634194\ttotal: 8.93s\tremaining: 5.76s\n",
      "608:\tlearn: 1.4634120\ttotal: 8.95s\tremaining: 5.74s\n",
      "609:\tlearn: 1.4634120\ttotal: 8.96s\tremaining: 5.73s\n",
      "610:\tlearn: 1.4634116\ttotal: 8.97s\tremaining: 5.71s\n",
      "611:\tlearn: 1.4634116\ttotal: 8.99s\tremaining: 5.7s\n",
      "612:\tlearn: 1.4634068\ttotal: 9s\tremaining: 5.68s\n",
      "613:\tlearn: 1.4634066\ttotal: 9.01s\tremaining: 5.67s\n",
      "614:\tlearn: 1.4634065\ttotal: 9.03s\tremaining: 5.65s\n",
      "615:\tlearn: 1.4633822\ttotal: 9.04s\tremaining: 5.63s\n",
      "616:\tlearn: 1.4625633\ttotal: 9.05s\tremaining: 5.62s\n",
      "617:\tlearn: 1.4624329\ttotal: 9.07s\tremaining: 5.61s\n",
      "618:\tlearn: 1.4619026\ttotal: 9.08s\tremaining: 5.59s\n",
      "619:\tlearn: 1.4618168\ttotal: 9.1s\tremaining: 5.57s\n",
      "620:\tlearn: 1.4613791\ttotal: 9.11s\tremaining: 5.56s\n",
      "621:\tlearn: 1.4613334\ttotal: 9.12s\tremaining: 5.54s\n",
      "622:\tlearn: 1.4611900\ttotal: 9.14s\tremaining: 5.53s\n",
      "623:\tlearn: 1.4611899\ttotal: 9.15s\tremaining: 5.51s\n",
      "624:\tlearn: 1.4611899\ttotal: 9.16s\tremaining: 5.5s\n",
      "625:\tlearn: 1.4611899\ttotal: 9.18s\tremaining: 5.48s\n",
      "626:\tlearn: 1.4611899\ttotal: 9.19s\tremaining: 5.47s\n",
      "627:\tlearn: 1.4611848\ttotal: 9.2s\tremaining: 5.45s\n",
      "628:\tlearn: 1.4611832\ttotal: 9.21s\tremaining: 5.43s\n",
      "629:\tlearn: 1.4611832\ttotal: 9.23s\tremaining: 5.42s\n",
      "630:\tlearn: 1.4611794\ttotal: 9.24s\tremaining: 5.4s\n",
      "631:\tlearn: 1.4610298\ttotal: 9.25s\tremaining: 5.39s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632:\tlearn: 1.4610294\ttotal: 9.27s\tremaining: 5.37s\n",
      "633:\tlearn: 1.4610294\ttotal: 9.28s\tremaining: 5.36s\n",
      "634:\tlearn: 1.4610291\ttotal: 9.29s\tremaining: 5.34s\n",
      "635:\tlearn: 1.4610291\ttotal: 9.31s\tremaining: 5.33s\n",
      "636:\tlearn: 1.4610291\ttotal: 9.32s\tremaining: 5.31s\n",
      "637:\tlearn: 1.4610291\ttotal: 9.33s\tremaining: 5.3s\n",
      "638:\tlearn: 1.4609602\ttotal: 9.35s\tremaining: 5.28s\n",
      "639:\tlearn: 1.4609150\ttotal: 9.36s\tremaining: 5.26s\n",
      "640:\tlearn: 1.4609043\ttotal: 9.37s\tremaining: 5.25s\n",
      "641:\tlearn: 1.4609042\ttotal: 9.39s\tremaining: 5.23s\n",
      "642:\tlearn: 1.4609042\ttotal: 9.4s\tremaining: 5.22s\n",
      "643:\tlearn: 1.4609042\ttotal: 9.41s\tremaining: 5.2s\n",
      "644:\tlearn: 1.4609037\ttotal: 9.43s\tremaining: 5.19s\n",
      "645:\tlearn: 1.4609037\ttotal: 9.44s\tremaining: 5.17s\n",
      "646:\tlearn: 1.4609036\ttotal: 9.45s\tremaining: 5.16s\n",
      "647:\tlearn: 1.4609025\ttotal: 9.47s\tremaining: 5.14s\n",
      "648:\tlearn: 1.4609016\ttotal: 9.48s\tremaining: 5.13s\n",
      "649:\tlearn: 1.4609016\ttotal: 9.5s\tremaining: 5.11s\n",
      "650:\tlearn: 1.4609016\ttotal: 9.52s\tremaining: 5.1s\n",
      "651:\tlearn: 1.4609016\ttotal: 9.53s\tremaining: 5.09s\n",
      "652:\tlearn: 1.4608972\ttotal: 9.54s\tremaining: 5.07s\n",
      "653:\tlearn: 1.4608959\ttotal: 9.55s\tremaining: 5.05s\n",
      "654:\tlearn: 1.4608782\ttotal: 9.57s\tremaining: 5.04s\n",
      "655:\tlearn: 1.4603318\ttotal: 9.58s\tremaining: 5.02s\n",
      "656:\tlearn: 1.4601447\ttotal: 9.6s\tremaining: 5.01s\n",
      "657:\tlearn: 1.4595365\ttotal: 9.61s\tremaining: 4.99s\n",
      "658:\tlearn: 1.4594656\ttotal: 9.62s\tremaining: 4.98s\n",
      "659:\tlearn: 1.4594371\ttotal: 9.64s\tremaining: 4.96s\n",
      "660:\tlearn: 1.4594326\ttotal: 9.65s\tremaining: 4.95s\n",
      "661:\tlearn: 1.4594326\ttotal: 9.66s\tremaining: 4.93s\n",
      "662:\tlearn: 1.4594324\ttotal: 9.68s\tremaining: 4.92s\n",
      "663:\tlearn: 1.4594236\ttotal: 9.69s\tremaining: 4.9s\n",
      "664:\tlearn: 1.4594236\ttotal: 9.7s\tremaining: 4.89s\n",
      "665:\tlearn: 1.4594214\ttotal: 9.72s\tremaining: 4.87s\n",
      "666:\tlearn: 1.4593516\ttotal: 9.73s\tremaining: 4.86s\n",
      "667:\tlearn: 1.4593485\ttotal: 9.75s\tremaining: 4.84s\n",
      "668:\tlearn: 1.4593475\ttotal: 9.76s\tremaining: 4.83s\n",
      "669:\tlearn: 1.4593472\ttotal: 9.77s\tremaining: 4.81s\n",
      "670:\tlearn: 1.4593371\ttotal: 9.79s\tremaining: 4.8s\n",
      "671:\tlearn: 1.4593370\ttotal: 9.8s\tremaining: 4.78s\n",
      "672:\tlearn: 1.4593370\ttotal: 9.81s\tremaining: 4.77s\n",
      "673:\tlearn: 1.4593369\ttotal: 9.83s\tremaining: 4.75s\n",
      "674:\tlearn: 1.4593368\ttotal: 9.84s\tremaining: 4.74s\n",
      "675:\tlearn: 1.4593368\ttotal: 9.85s\tremaining: 4.72s\n",
      "676:\tlearn: 1.4593368\ttotal: 9.87s\tremaining: 4.71s\n",
      "677:\tlearn: 1.4593179\ttotal: 9.88s\tremaining: 4.69s\n",
      "678:\tlearn: 1.4593155\ttotal: 9.89s\tremaining: 4.68s\n",
      "679:\tlearn: 1.4593155\ttotal: 9.91s\tremaining: 4.66s\n",
      "680:\tlearn: 1.4593155\ttotal: 9.92s\tremaining: 4.65s\n",
      "681:\tlearn: 1.4593045\ttotal: 9.94s\tremaining: 4.63s\n",
      "682:\tlearn: 1.4585345\ttotal: 9.95s\tremaining: 4.62s\n",
      "683:\tlearn: 1.4583442\ttotal: 9.96s\tremaining: 4.6s\n",
      "684:\tlearn: 1.4578776\ttotal: 9.97s\tremaining: 4.59s\n",
      "685:\tlearn: 1.4574901\ttotal: 9.99s\tremaining: 4.57s\n",
      "686:\tlearn: 1.4566765\ttotal: 10s\tremaining: 4.56s\n",
      "687:\tlearn: 1.4566260\ttotal: 10s\tremaining: 4.54s\n",
      "688:\tlearn: 1.4566065\ttotal: 10s\tremaining: 4.53s\n",
      "689:\tlearn: 1.4565567\ttotal: 10s\tremaining: 4.51s\n",
      "690:\tlearn: 1.4564414\ttotal: 10.1s\tremaining: 4.5s\n",
      "691:\tlearn: 1.4558637\ttotal: 10.1s\tremaining: 4.48s\n",
      "692:\tlearn: 1.4555156\ttotal: 10.1s\tremaining: 4.46s\n",
      "693:\tlearn: 1.4554740\ttotal: 10.1s\tremaining: 4.45s\n",
      "694:\tlearn: 1.4550351\ttotal: 10.1s\tremaining: 4.44s\n",
      "695:\tlearn: 1.4549769\ttotal: 10.1s\tremaining: 4.42s\n",
      "696:\tlearn: 1.4548294\ttotal: 10.1s\tremaining: 4.41s\n",
      "697:\tlearn: 1.4547859\ttotal: 10.1s\tremaining: 4.39s\n",
      "698:\tlearn: 1.4547859\ttotal: 10.2s\tremaining: 4.38s\n",
      "699:\tlearn: 1.4547603\ttotal: 10.2s\tremaining: 4.36s\n",
      "700:\tlearn: 1.4545174\ttotal: 10.2s\tremaining: 4.35s\n",
      "701:\tlearn: 1.4540000\ttotal: 10.2s\tremaining: 4.33s\n",
      "702:\tlearn: 1.4539205\ttotal: 10.2s\tremaining: 4.32s\n",
      "703:\tlearn: 1.4536718\ttotal: 10.2s\tremaining: 4.3s\n",
      "704:\tlearn: 1.4536435\ttotal: 10.2s\tremaining: 4.29s\n",
      "705:\tlearn: 1.4536422\ttotal: 10.3s\tremaining: 4.27s\n",
      "706:\tlearn: 1.4536418\ttotal: 10.3s\tremaining: 4.26s\n",
      "707:\tlearn: 1.4536342\ttotal: 10.3s\tremaining: 4.24s\n",
      "708:\tlearn: 1.4534393\ttotal: 10.3s\tremaining: 4.23s\n",
      "709:\tlearn: 1.4531478\ttotal: 10.3s\tremaining: 4.21s\n",
      "710:\tlearn: 1.4531478\ttotal: 10.3s\tremaining: 4.2s\n",
      "711:\tlearn: 1.4531251\ttotal: 10.3s\tremaining: 4.18s\n",
      "712:\tlearn: 1.4531251\ttotal: 10.4s\tremaining: 4.17s\n",
      "713:\tlearn: 1.4531251\ttotal: 10.4s\tremaining: 4.15s\n",
      "714:\tlearn: 1.4531052\ttotal: 10.4s\tremaining: 4.14s\n",
      "715:\tlearn: 1.4531052\ttotal: 10.4s\tremaining: 4.12s\n",
      "716:\tlearn: 1.4531052\ttotal: 10.4s\tremaining: 4.11s\n",
      "717:\tlearn: 1.4531052\ttotal: 10.4s\tremaining: 4.09s\n",
      "718:\tlearn: 1.4530617\ttotal: 10.4s\tremaining: 4.08s\n",
      "719:\tlearn: 1.4530519\ttotal: 10.4s\tremaining: 4.06s\n",
      "720:\tlearn: 1.4530257\ttotal: 10.5s\tremaining: 4.05s\n",
      "721:\tlearn: 1.4529893\ttotal: 10.5s\tremaining: 4.03s\n",
      "722:\tlearn: 1.4529876\ttotal: 10.5s\tremaining: 4.02s\n",
      "723:\tlearn: 1.4529874\ttotal: 10.5s\tremaining: 4s\n",
      "724:\tlearn: 1.4529874\ttotal: 10.5s\tremaining: 3.99s\n",
      "725:\tlearn: 1.4529749\ttotal: 10.5s\tremaining: 3.97s\n",
      "726:\tlearn: 1.4529110\ttotal: 10.5s\tremaining: 3.96s\n",
      "727:\tlearn: 1.4528942\ttotal: 10.6s\tremaining: 3.94s\n",
      "728:\tlearn: 1.4525220\ttotal: 10.6s\tremaining: 3.93s\n",
      "729:\tlearn: 1.4524240\ttotal: 10.6s\tremaining: 3.91s\n",
      "730:\tlearn: 1.4516351\ttotal: 10.6s\tremaining: 3.9s\n",
      "731:\tlearn: 1.4508472\ttotal: 10.6s\tremaining: 3.88s\n",
      "732:\tlearn: 1.4506879\ttotal: 10.6s\tremaining: 3.87s\n",
      "733:\tlearn: 1.4502022\ttotal: 10.6s\tremaining: 3.85s\n",
      "734:\tlearn: 1.4501881\ttotal: 10.6s\tremaining: 3.84s\n",
      "735:\tlearn: 1.4499951\ttotal: 10.7s\tremaining: 3.82s\n",
      "736:\tlearn: 1.4499895\ttotal: 10.7s\tremaining: 3.81s\n",
      "737:\tlearn: 1.4499702\ttotal: 10.7s\tremaining: 3.79s\n",
      "738:\tlearn: 1.4497924\ttotal: 10.7s\tremaining: 3.78s\n",
      "739:\tlearn: 1.4497916\ttotal: 10.7s\tremaining: 3.76s\n",
      "740:\tlearn: 1.4497908\ttotal: 10.7s\tremaining: 3.75s\n",
      "741:\tlearn: 1.4497908\ttotal: 10.7s\tremaining: 3.73s\n",
      "742:\tlearn: 1.4497778\ttotal: 10.8s\tremaining: 3.72s\n",
      "743:\tlearn: 1.4497774\ttotal: 10.8s\tremaining: 3.7s\n",
      "744:\tlearn: 1.4497771\ttotal: 10.8s\tremaining: 3.69s\n",
      "745:\tlearn: 1.4497770\ttotal: 10.8s\tremaining: 3.67s\n",
      "746:\tlearn: 1.4497759\ttotal: 10.8s\tremaining: 3.66s\n",
      "747:\tlearn: 1.4497759\ttotal: 10.8s\tremaining: 3.65s\n",
      "748:\tlearn: 1.4497758\ttotal: 10.8s\tremaining: 3.63s\n",
      "749:\tlearn: 1.4493852\ttotal: 10.8s\tremaining: 3.62s\n",
      "750:\tlearn: 1.4491248\ttotal: 10.9s\tremaining: 3.6s\n",
      "751:\tlearn: 1.4490754\ttotal: 10.9s\tremaining: 3.58s\n",
      "752:\tlearn: 1.4490678\ttotal: 10.9s\tremaining: 3.57s\n",
      "753:\tlearn: 1.4486374\ttotal: 10.9s\tremaining: 3.56s\n",
      "754:\tlearn: 1.4483058\ttotal: 10.9s\tremaining: 3.54s\n",
      "755:\tlearn: 1.4480609\ttotal: 10.9s\tremaining: 3.53s\n",
      "756:\tlearn: 1.4480414\ttotal: 10.9s\tremaining: 3.51s\n",
      "757:\tlearn: 1.4480414\ttotal: 11s\tremaining: 3.5s\n",
      "758:\tlearn: 1.4480413\ttotal: 11s\tremaining: 3.48s\n",
      "759:\tlearn: 1.4480413\ttotal: 11s\tremaining: 3.47s\n",
      "760:\tlearn: 1.4480413\ttotal: 11s\tremaining: 3.45s\n",
      "761:\tlearn: 1.4474131\ttotal: 11s\tremaining: 3.44s\n",
      "762:\tlearn: 1.4473831\ttotal: 11s\tremaining: 3.42s\n",
      "763:\tlearn: 1.4473064\ttotal: 11s\tremaining: 3.41s\n",
      "764:\tlearn: 1.4471731\ttotal: 11.1s\tremaining: 3.39s\n",
      "765:\tlearn: 1.4469585\ttotal: 11.1s\tremaining: 3.38s\n",
      "766:\tlearn: 1.4469564\ttotal: 11.1s\tremaining: 3.37s\n",
      "767:\tlearn: 1.4468896\ttotal: 11.1s\tremaining: 3.35s\n",
      "768:\tlearn: 1.4468716\ttotal: 11.1s\tremaining: 3.34s\n",
      "769:\tlearn: 1.4468714\ttotal: 11.1s\tremaining: 3.32s\n",
      "770:\tlearn: 1.4468453\ttotal: 11.1s\tremaining: 3.31s\n",
      "771:\tlearn: 1.4468147\ttotal: 11.1s\tremaining: 3.29s\n",
      "772:\tlearn: 1.4468127\ttotal: 11.2s\tremaining: 3.28s\n",
      "773:\tlearn: 1.4468110\ttotal: 11.2s\tremaining: 3.26s\n",
      "774:\tlearn: 1.4468110\ttotal: 11.2s\tremaining: 3.25s\n",
      "775:\tlearn: 1.4468109\ttotal: 11.2s\tremaining: 3.23s\n",
      "776:\tlearn: 1.4468106\ttotal: 11.2s\tremaining: 3.22s\n",
      "777:\tlearn: 1.4468084\ttotal: 11.2s\tremaining: 3.2s\n",
      "778:\tlearn: 1.4468080\ttotal: 11.2s\tremaining: 3.19s\n",
      "779:\tlearn: 1.4468077\ttotal: 11.3s\tremaining: 3.17s\n",
      "780:\tlearn: 1.4463569\ttotal: 11.3s\tremaining: 3.16s\n",
      "781:\tlearn: 1.4463466\ttotal: 11.3s\tremaining: 3.15s\n",
      "782:\tlearn: 1.4463466\ttotal: 11.3s\tremaining: 3.13s\n",
      "783:\tlearn: 1.4463466\ttotal: 11.3s\tremaining: 3.12s\n",
      "784:\tlearn: 1.4463381\ttotal: 11.3s\tremaining: 3.1s\n",
      "785:\tlearn: 1.4463381\ttotal: 11.3s\tremaining: 3.09s\n",
      "786:\tlearn: 1.4463381\ttotal: 11.4s\tremaining: 3.07s\n",
      "787:\tlearn: 1.4461222\ttotal: 11.4s\tremaining: 3.06s\n",
      "788:\tlearn: 1.4458278\ttotal: 11.4s\tremaining: 3.04s\n",
      "789:\tlearn: 1.4457122\ttotal: 11.4s\tremaining: 3.03s\n",
      "790:\tlearn: 1.4456809\ttotal: 11.4s\tremaining: 3.01s\n",
      "791:\tlearn: 1.4456129\ttotal: 11.4s\tremaining: 3s\n",
      "792:\tlearn: 1.4456129\ttotal: 11.4s\tremaining: 2.98s\n",
      "793:\tlearn: 1.4456083\ttotal: 11.4s\tremaining: 2.97s\n",
      "794:\tlearn: 1.4455503\ttotal: 11.5s\tremaining: 2.96s\n",
      "795:\tlearn: 1.4449112\ttotal: 11.5s\tremaining: 2.94s\n",
      "796:\tlearn: 1.4447315\ttotal: 11.5s\tremaining: 2.93s\n",
      "797:\tlearn: 1.4436842\ttotal: 11.5s\tremaining: 2.91s\n",
      "798:\tlearn: 1.4433208\ttotal: 11.5s\tremaining: 2.9s\n",
      "799:\tlearn: 1.4428558\ttotal: 11.5s\tremaining: 2.88s\n",
      "800:\tlearn: 1.4428558\ttotal: 11.5s\tremaining: 2.87s\n",
      "801:\tlearn: 1.4428558\ttotal: 11.6s\tremaining: 2.85s\n",
      "802:\tlearn: 1.4427753\ttotal: 11.6s\tremaining: 2.84s\n",
      "803:\tlearn: 1.4427370\ttotal: 11.6s\tremaining: 2.82s\n",
      "804:\tlearn: 1.4427243\ttotal: 11.6s\tremaining: 2.81s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "805:\tlearn: 1.4421201\ttotal: 11.6s\tremaining: 2.79s\n",
      "806:\tlearn: 1.4419534\ttotal: 11.6s\tremaining: 2.78s\n",
      "807:\tlearn: 1.4418546\ttotal: 11.6s\tremaining: 2.77s\n",
      "808:\tlearn: 1.4412153\ttotal: 11.7s\tremaining: 2.75s\n",
      "809:\tlearn: 1.4412057\ttotal: 11.7s\tremaining: 2.73s\n",
      "810:\tlearn: 1.4412054\ttotal: 11.7s\tremaining: 2.72s\n",
      "811:\tlearn: 1.4411570\ttotal: 11.7s\tremaining: 2.71s\n",
      "812:\tlearn: 1.4411528\ttotal: 11.7s\tremaining: 2.69s\n",
      "813:\tlearn: 1.4411340\ttotal: 11.7s\tremaining: 2.68s\n",
      "814:\tlearn: 1.4409021\ttotal: 11.7s\tremaining: 2.66s\n",
      "815:\tlearn: 1.4407006\ttotal: 11.7s\tremaining: 2.65s\n",
      "816:\tlearn: 1.4406937\ttotal: 11.8s\tremaining: 2.63s\n",
      "817:\tlearn: 1.4406888\ttotal: 11.8s\tremaining: 2.62s\n",
      "818:\tlearn: 1.4406614\ttotal: 11.8s\tremaining: 2.6s\n",
      "819:\tlearn: 1.4406416\ttotal: 11.8s\tremaining: 2.59s\n",
      "820:\tlearn: 1.4406180\ttotal: 11.8s\tremaining: 2.58s\n",
      "821:\tlearn: 1.4403724\ttotal: 11.8s\tremaining: 2.56s\n",
      "822:\tlearn: 1.4403718\ttotal: 11.8s\tremaining: 2.55s\n",
      "823:\tlearn: 1.4403718\ttotal: 11.9s\tremaining: 2.53s\n",
      "824:\tlearn: 1.4403716\ttotal: 11.9s\tremaining: 2.52s\n",
      "825:\tlearn: 1.4402761\ttotal: 11.9s\tremaining: 2.5s\n",
      "826:\tlearn: 1.4400590\ttotal: 11.9s\tremaining: 2.49s\n",
      "827:\tlearn: 1.4400133\ttotal: 11.9s\tremaining: 2.47s\n",
      "828:\tlearn: 1.4399948\ttotal: 11.9s\tremaining: 2.46s\n",
      "829:\tlearn: 1.4399195\ttotal: 11.9s\tremaining: 2.44s\n",
      "830:\tlearn: 1.4399121\ttotal: 11.9s\tremaining: 2.43s\n",
      "831:\tlearn: 1.4399115\ttotal: 12s\tremaining: 2.41s\n",
      "832:\tlearn: 1.4399114\ttotal: 12s\tremaining: 2.4s\n",
      "833:\tlearn: 1.4398950\ttotal: 12s\tremaining: 2.38s\n",
      "834:\tlearn: 1.4398805\ttotal: 12s\tremaining: 2.37s\n",
      "835:\tlearn: 1.4397176\ttotal: 12s\tremaining: 2.36s\n",
      "836:\tlearn: 1.4394311\ttotal: 12s\tremaining: 2.34s\n",
      "837:\tlearn: 1.4391105\ttotal: 12s\tremaining: 2.33s\n",
      "838:\tlearn: 1.4386626\ttotal: 12.1s\tremaining: 2.31s\n",
      "839:\tlearn: 1.4385998\ttotal: 12.1s\tremaining: 2.3s\n",
      "840:\tlearn: 1.4384960\ttotal: 12.1s\tremaining: 2.28s\n",
      "841:\tlearn: 1.4384930\ttotal: 12.1s\tremaining: 2.27s\n",
      "842:\tlearn: 1.4384429\ttotal: 12.1s\tremaining: 2.25s\n",
      "843:\tlearn: 1.4383800\ttotal: 12.1s\tremaining: 2.24s\n",
      "844:\tlearn: 1.4383373\ttotal: 12.1s\tremaining: 2.23s\n",
      "845:\tlearn: 1.4380541\ttotal: 12.1s\tremaining: 2.21s\n",
      "846:\tlearn: 1.4379657\ttotal: 12.2s\tremaining: 2.2s\n",
      "847:\tlearn: 1.4372534\ttotal: 12.2s\tremaining: 2.18s\n",
      "848:\tlearn: 1.4372156\ttotal: 12.2s\tremaining: 2.17s\n",
      "849:\tlearn: 1.4370824\ttotal: 12.2s\tremaining: 2.15s\n",
      "850:\tlearn: 1.4370760\ttotal: 12.2s\tremaining: 2.14s\n",
      "851:\tlearn: 1.4370711\ttotal: 12.2s\tremaining: 2.12s\n",
      "852:\tlearn: 1.4370708\ttotal: 12.3s\tremaining: 2.11s\n",
      "853:\tlearn: 1.4370704\ttotal: 12.3s\tremaining: 2.1s\n",
      "854:\tlearn: 1.4369730\ttotal: 12.3s\tremaining: 2.08s\n",
      "855:\tlearn: 1.4369163\ttotal: 12.3s\tremaining: 2.07s\n",
      "856:\tlearn: 1.4369135\ttotal: 12.3s\tremaining: 2.06s\n",
      "857:\tlearn: 1.4368519\ttotal: 12.3s\tremaining: 2.04s\n",
      "858:\tlearn: 1.4368490\ttotal: 12.3s\tremaining: 2.03s\n",
      "859:\tlearn: 1.4368485\ttotal: 12.4s\tremaining: 2.01s\n",
      "860:\tlearn: 1.4364874\ttotal: 12.4s\tremaining: 2s\n",
      "861:\tlearn: 1.4364868\ttotal: 12.4s\tremaining: 1.98s\n",
      "862:\tlearn: 1.4364712\ttotal: 12.4s\tremaining: 1.97s\n",
      "863:\tlearn: 1.4362021\ttotal: 12.4s\tremaining: 1.95s\n",
      "864:\tlearn: 1.4360409\ttotal: 12.4s\tremaining: 1.94s\n",
      "865:\tlearn: 1.4359395\ttotal: 12.4s\tremaining: 1.93s\n",
      "866:\tlearn: 1.4358441\ttotal: 12.5s\tremaining: 1.91s\n",
      "867:\tlearn: 1.4358245\ttotal: 12.5s\tremaining: 1.9s\n",
      "868:\tlearn: 1.4358245\ttotal: 12.5s\tremaining: 1.88s\n",
      "869:\tlearn: 1.4357902\ttotal: 12.5s\tremaining: 1.87s\n",
      "870:\tlearn: 1.4357464\ttotal: 12.5s\tremaining: 1.85s\n",
      "871:\tlearn: 1.4357464\ttotal: 12.5s\tremaining: 1.84s\n",
      "872:\tlearn: 1.4357429\ttotal: 12.5s\tremaining: 1.82s\n",
      "873:\tlearn: 1.4356273\ttotal: 12.6s\tremaining: 1.81s\n",
      "874:\tlearn: 1.4356246\ttotal: 12.6s\tremaining: 1.79s\n",
      "875:\tlearn: 1.4354741\ttotal: 12.6s\tremaining: 1.78s\n",
      "876:\tlearn: 1.4352950\ttotal: 12.6s\tremaining: 1.77s\n",
      "877:\tlearn: 1.4349662\ttotal: 12.6s\tremaining: 1.75s\n",
      "878:\tlearn: 1.4346433\ttotal: 12.6s\tremaining: 1.74s\n",
      "879:\tlearn: 1.4342259\ttotal: 12.7s\tremaining: 1.73s\n",
      "880:\tlearn: 1.4342218\ttotal: 12.7s\tremaining: 1.71s\n",
      "881:\tlearn: 1.4342218\ttotal: 12.7s\tremaining: 1.7s\n",
      "882:\tlearn: 1.4341899\ttotal: 12.7s\tremaining: 1.68s\n",
      "883:\tlearn: 1.4341689\ttotal: 12.7s\tremaining: 1.67s\n",
      "884:\tlearn: 1.4340885\ttotal: 12.7s\tremaining: 1.65s\n",
      "885:\tlearn: 1.4340387\ttotal: 12.7s\tremaining: 1.64s\n",
      "886:\tlearn: 1.4340370\ttotal: 12.7s\tremaining: 1.62s\n",
      "887:\tlearn: 1.4339503\ttotal: 12.8s\tremaining: 1.61s\n",
      "888:\tlearn: 1.4338503\ttotal: 12.8s\tremaining: 1.59s\n",
      "889:\tlearn: 1.4337319\ttotal: 12.8s\tremaining: 1.58s\n",
      "890:\tlearn: 1.4332970\ttotal: 12.8s\tremaining: 1.56s\n",
      "891:\tlearn: 1.4332932\ttotal: 12.8s\tremaining: 1.55s\n",
      "892:\tlearn: 1.4332777\ttotal: 12.8s\tremaining: 1.54s\n",
      "893:\tlearn: 1.4332496\ttotal: 12.8s\tremaining: 1.52s\n",
      "894:\tlearn: 1.4332344\ttotal: 12.9s\tremaining: 1.51s\n",
      "895:\tlearn: 1.4331687\ttotal: 12.9s\tremaining: 1.49s\n",
      "896:\tlearn: 1.4331644\ttotal: 12.9s\tremaining: 1.48s\n",
      "897:\tlearn: 1.4330821\ttotal: 12.9s\tremaining: 1.47s\n",
      "898:\tlearn: 1.4330177\ttotal: 12.9s\tremaining: 1.45s\n",
      "899:\tlearn: 1.4328060\ttotal: 12.9s\tremaining: 1.44s\n",
      "900:\tlearn: 1.4328055\ttotal: 12.9s\tremaining: 1.42s\n",
      "901:\tlearn: 1.4321329\ttotal: 13s\tremaining: 1.41s\n",
      "902:\tlearn: 1.4321302\ttotal: 13s\tremaining: 1.39s\n",
      "903:\tlearn: 1.4320916\ttotal: 13s\tremaining: 1.38s\n",
      "904:\tlearn: 1.4320673\ttotal: 13s\tremaining: 1.36s\n",
      "905:\tlearn: 1.4315894\ttotal: 13s\tremaining: 1.35s\n",
      "906:\tlearn: 1.4311671\ttotal: 13s\tremaining: 1.33s\n",
      "907:\tlearn: 1.4308636\ttotal: 13s\tremaining: 1.32s\n",
      "908:\tlearn: 1.4304676\ttotal: 13.1s\tremaining: 1.31s\n",
      "909:\tlearn: 1.4304268\ttotal: 13.1s\tremaining: 1.29s\n",
      "910:\tlearn: 1.4301427\ttotal: 13.1s\tremaining: 1.28s\n",
      "911:\tlearn: 1.4301183\ttotal: 13.1s\tremaining: 1.26s\n",
      "912:\tlearn: 1.4301181\ttotal: 13.1s\tremaining: 1.25s\n",
      "913:\tlearn: 1.4301181\ttotal: 13.1s\tremaining: 1.23s\n",
      "914:\tlearn: 1.4301160\ttotal: 13.1s\tremaining: 1.22s\n",
      "915:\tlearn: 1.4295567\ttotal: 13.1s\tremaining: 1.21s\n",
      "916:\tlearn: 1.4295511\ttotal: 13.2s\tremaining: 1.19s\n",
      "917:\tlearn: 1.4289237\ttotal: 13.2s\tremaining: 1.18s\n",
      "918:\tlearn: 1.4289119\ttotal: 13.2s\tremaining: 1.16s\n",
      "919:\tlearn: 1.4288900\ttotal: 13.2s\tremaining: 1.15s\n",
      "920:\tlearn: 1.4286618\ttotal: 13.2s\tremaining: 1.13s\n",
      "921:\tlearn: 1.4286458\ttotal: 13.2s\tremaining: 1.12s\n",
      "922:\tlearn: 1.4286386\ttotal: 13.2s\tremaining: 1.1s\n",
      "923:\tlearn: 1.4286345\ttotal: 13.3s\tremaining: 1.09s\n",
      "924:\tlearn: 1.4283614\ttotal: 13.3s\tremaining: 1.07s\n",
      "925:\tlearn: 1.4283431\ttotal: 13.3s\tremaining: 1.06s\n",
      "926:\tlearn: 1.4278354\ttotal: 13.3s\tremaining: 1.05s\n",
      "927:\tlearn: 1.4275659\ttotal: 13.3s\tremaining: 1.03s\n",
      "928:\tlearn: 1.4275379\ttotal: 13.3s\tremaining: 1.02s\n",
      "929:\tlearn: 1.4274746\ttotal: 13.3s\tremaining: 1s\n",
      "930:\tlearn: 1.4269330\ttotal: 13.3s\tremaining: 989ms\n",
      "931:\tlearn: 1.4265290\ttotal: 13.4s\tremaining: 975ms\n",
      "932:\tlearn: 1.4263380\ttotal: 13.4s\tremaining: 960ms\n",
      "933:\tlearn: 1.4260744\ttotal: 13.4s\tremaining: 946ms\n",
      "934:\tlearn: 1.4260638\ttotal: 13.4s\tremaining: 932ms\n",
      "935:\tlearn: 1.4260469\ttotal: 13.4s\tremaining: 917ms\n",
      "936:\tlearn: 1.4258804\ttotal: 13.4s\tremaining: 903ms\n",
      "937:\tlearn: 1.4258753\ttotal: 13.4s\tremaining: 888ms\n",
      "938:\tlearn: 1.4249645\ttotal: 13.5s\tremaining: 874ms\n",
      "939:\tlearn: 1.4249553\ttotal: 13.5s\tremaining: 860ms\n",
      "940:\tlearn: 1.4249433\ttotal: 13.5s\tremaining: 845ms\n",
      "941:\tlearn: 1.4249431\ttotal: 13.5s\tremaining: 831ms\n",
      "942:\tlearn: 1.4249333\ttotal: 13.5s\tremaining: 817ms\n",
      "943:\tlearn: 1.4249077\ttotal: 13.5s\tremaining: 802ms\n",
      "944:\tlearn: 1.4249009\ttotal: 13.5s\tremaining: 788ms\n",
      "945:\tlearn: 1.4249009\ttotal: 13.6s\tremaining: 774ms\n",
      "946:\tlearn: 1.4246198\ttotal: 13.6s\tremaining: 759ms\n",
      "947:\tlearn: 1.4245548\ttotal: 13.6s\tremaining: 745ms\n",
      "948:\tlearn: 1.4245509\ttotal: 13.6s\tremaining: 730ms\n",
      "949:\tlearn: 1.4245502\ttotal: 13.6s\tremaining: 716ms\n",
      "950:\tlearn: 1.4245500\ttotal: 13.6s\tremaining: 702ms\n",
      "951:\tlearn: 1.4245333\ttotal: 13.6s\tremaining: 687ms\n",
      "952:\tlearn: 1.4245219\ttotal: 13.6s\tremaining: 673ms\n",
      "953:\tlearn: 1.4245217\ttotal: 13.7s\tremaining: 659ms\n",
      "954:\tlearn: 1.4243353\ttotal: 13.7s\tremaining: 644ms\n",
      "955:\tlearn: 1.4243314\ttotal: 13.7s\tremaining: 630ms\n",
      "956:\tlearn: 1.4243314\ttotal: 13.7s\tremaining: 616ms\n",
      "957:\tlearn: 1.4243272\ttotal: 13.7s\tremaining: 601ms\n",
      "958:\tlearn: 1.4243270\ttotal: 13.7s\tremaining: 587ms\n",
      "959:\tlearn: 1.4243149\ttotal: 13.7s\tremaining: 573ms\n",
      "960:\tlearn: 1.4242213\ttotal: 13.8s\tremaining: 558ms\n",
      "961:\tlearn: 1.4242078\ttotal: 13.8s\tremaining: 544ms\n",
      "962:\tlearn: 1.4239123\ttotal: 13.8s\tremaining: 529ms\n",
      "963:\tlearn: 1.4238812\ttotal: 13.8s\tremaining: 515ms\n",
      "964:\tlearn: 1.4238800\ttotal: 13.8s\tremaining: 501ms\n",
      "965:\tlearn: 1.4235928\ttotal: 13.8s\tremaining: 486ms\n",
      "966:\tlearn: 1.4235034\ttotal: 13.8s\tremaining: 472ms\n",
      "967:\tlearn: 1.4234932\ttotal: 13.8s\tremaining: 458ms\n",
      "968:\tlearn: 1.4234903\ttotal: 13.9s\tremaining: 443ms\n",
      "969:\tlearn: 1.4233046\ttotal: 13.9s\tremaining: 429ms\n",
      "970:\tlearn: 1.4232976\ttotal: 13.9s\tremaining: 415ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "971:\tlearn: 1.4231757\ttotal: 13.9s\tremaining: 400ms\n",
      "972:\tlearn: 1.4231693\ttotal: 13.9s\tremaining: 386ms\n",
      "973:\tlearn: 1.4229106\ttotal: 13.9s\tremaining: 372ms\n",
      "974:\tlearn: 1.4227480\ttotal: 13.9s\tremaining: 358ms\n",
      "975:\tlearn: 1.4227449\ttotal: 14s\tremaining: 343ms\n",
      "976:\tlearn: 1.4224691\ttotal: 14s\tremaining: 329ms\n",
      "977:\tlearn: 1.4224454\ttotal: 14s\tremaining: 315ms\n",
      "978:\tlearn: 1.4221296\ttotal: 14s\tremaining: 300ms\n",
      "979:\tlearn: 1.4218117\ttotal: 14s\tremaining: 286ms\n",
      "980:\tlearn: 1.4217741\ttotal: 14s\tremaining: 272ms\n",
      "981:\tlearn: 1.4217529\ttotal: 14s\tremaining: 257ms\n",
      "982:\tlearn: 1.4217301\ttotal: 14s\tremaining: 243ms\n",
      "983:\tlearn: 1.4215865\ttotal: 14.1s\tremaining: 229ms\n",
      "984:\tlearn: 1.4215490\ttotal: 14.1s\tremaining: 214ms\n",
      "985:\tlearn: 1.4213931\ttotal: 14.1s\tremaining: 200ms\n",
      "986:\tlearn: 1.4213665\ttotal: 14.1s\tremaining: 186ms\n",
      "987:\tlearn: 1.4209686\ttotal: 14.1s\tremaining: 171ms\n",
      "988:\tlearn: 1.4208440\ttotal: 14.1s\tremaining: 157ms\n",
      "989:\tlearn: 1.4208390\ttotal: 14.1s\tremaining: 143ms\n",
      "990:\tlearn: 1.4208389\ttotal: 14.2s\tremaining: 129ms\n",
      "991:\tlearn: 1.4203988\ttotal: 14.2s\tremaining: 114ms\n",
      "992:\tlearn: 1.4203920\ttotal: 14.2s\tremaining: 100ms\n",
      "993:\tlearn: 1.4203802\ttotal: 14.2s\tremaining: 85.7ms\n",
      "994:\tlearn: 1.4200669\ttotal: 14.2s\tremaining: 71.4ms\n",
      "995:\tlearn: 1.4200557\ttotal: 14.2s\tremaining: 57.1ms\n",
      "996:\tlearn: 1.4196327\ttotal: 14.2s\tremaining: 42.8ms\n",
      "997:\tlearn: 1.4196324\ttotal: 14.2s\tremaining: 28.6ms\n",
      "998:\tlearn: 1.4196311\ttotal: 14.3s\tremaining: 14.3ms\n",
      "999:\tlearn: 1.4195533\ttotal: 14.3s\tremaining: 0us\n",
      "0:\tlearn: 7.7363396\ttotal: 16.8ms\tremaining: 16.8s\n",
      "1:\tlearn: 7.1942445\ttotal: 33.9ms\tremaining: 16.9s\n",
      "2:\tlearn: 6.6802956\ttotal: 51.4ms\tremaining: 17.1s\n",
      "3:\tlearn: 6.2028020\ttotal: 69.3ms\tremaining: 17.3s\n",
      "4:\tlearn: 5.7018303\ttotal: 87.4ms\tremaining: 17.4s\n",
      "5:\tlearn: 5.3417593\ttotal: 105ms\tremaining: 17.4s\n",
      "6:\tlearn: 4.9361376\ttotal: 122ms\tremaining: 17.3s\n",
      "7:\tlearn: 4.5860986\ttotal: 139ms\tremaining: 17.3s\n",
      "8:\tlearn: 4.2543175\ttotal: 157ms\tremaining: 17.3s\n",
      "9:\tlearn: 3.9421313\ttotal: 174ms\tremaining: 17.2s\n",
      "10:\tlearn: 3.6916733\ttotal: 191ms\tremaining: 17.2s\n",
      "11:\tlearn: 3.5131462\ttotal: 209ms\tremaining: 17.2s\n",
      "12:\tlearn: 3.3557144\ttotal: 226ms\tremaining: 17.1s\n",
      "13:\tlearn: 3.1571921\ttotal: 242ms\tremaining: 17s\n",
      "14:\tlearn: 3.0417049\ttotal: 258ms\tremaining: 16.9s\n",
      "15:\tlearn: 2.9387032\ttotal: 277ms\tremaining: 17s\n",
      "16:\tlearn: 2.8037035\ttotal: 295ms\tremaining: 17.1s\n",
      "17:\tlearn: 2.6825430\ttotal: 311ms\tremaining: 17s\n",
      "18:\tlearn: 2.6131815\ttotal: 327ms\tremaining: 16.9s\n",
      "19:\tlearn: 2.5164971\ttotal: 344ms\tremaining: 16.9s\n",
      "20:\tlearn: 2.4673435\ttotal: 361ms\tremaining: 16.9s\n",
      "21:\tlearn: 2.4188497\ttotal: 379ms\tremaining: 16.8s\n",
      "22:\tlearn: 2.3798825\ttotal: 395ms\tremaining: 16.8s\n",
      "23:\tlearn: 2.3121073\ttotal: 412ms\tremaining: 16.8s\n",
      "24:\tlearn: 2.2592076\ttotal: 429ms\tremaining: 16.7s\n",
      "25:\tlearn: 2.2327586\ttotal: 446ms\tremaining: 16.7s\n",
      "26:\tlearn: 2.2094816\ttotal: 461ms\tremaining: 16.6s\n",
      "27:\tlearn: 2.1692380\ttotal: 478ms\tremaining: 16.6s\n",
      "28:\tlearn: 2.1513174\ttotal: 494ms\tremaining: 16.6s\n",
      "29:\tlearn: 2.1126676\ttotal: 511ms\tremaining: 16.5s\n",
      "30:\tlearn: 2.0980670\ttotal: 526ms\tremaining: 16.4s\n",
      "31:\tlearn: 2.0844858\ttotal: 540ms\tremaining: 16.3s\n",
      "32:\tlearn: 2.0575448\ttotal: 556ms\tremaining: 16.3s\n",
      "33:\tlearn: 2.0332401\ttotal: 572ms\tremaining: 16.3s\n",
      "34:\tlearn: 2.0251430\ttotal: 588ms\tremaining: 16.2s\n",
      "35:\tlearn: 2.0158696\ttotal: 604ms\tremaining: 16.2s\n",
      "36:\tlearn: 1.9997434\ttotal: 621ms\tremaining: 16.2s\n",
      "37:\tlearn: 1.9798144\ttotal: 637ms\tremaining: 16.1s\n",
      "38:\tlearn: 1.9750801\ttotal: 654ms\tremaining: 16.1s\n",
      "39:\tlearn: 1.9709956\ttotal: 668ms\tremaining: 16s\n",
      "40:\tlearn: 1.9643633\ttotal: 683ms\tremaining: 16s\n",
      "41:\tlearn: 1.9594847\ttotal: 698ms\tremaining: 15.9s\n",
      "42:\tlearn: 1.9559500\ttotal: 713ms\tremaining: 15.9s\n",
      "43:\tlearn: 1.9546472\ttotal: 729ms\tremaining: 15.8s\n",
      "44:\tlearn: 1.9527022\ttotal: 745ms\tremaining: 15.8s\n",
      "45:\tlearn: 1.9503985\ttotal: 761ms\tremaining: 15.8s\n",
      "46:\tlearn: 1.9437658\ttotal: 777ms\tremaining: 15.8s\n",
      "47:\tlearn: 1.9408190\ttotal: 794ms\tremaining: 15.7s\n",
      "48:\tlearn: 1.9370822\ttotal: 809ms\tremaining: 15.7s\n",
      "49:\tlearn: 1.9350379\ttotal: 825ms\tremaining: 15.7s\n",
      "50:\tlearn: 1.9344470\ttotal: 841ms\tremaining: 15.6s\n",
      "51:\tlearn: 1.9320180\ttotal: 857ms\tremaining: 15.6s\n",
      "52:\tlearn: 1.9318358\ttotal: 873ms\tremaining: 15.6s\n",
      "53:\tlearn: 1.9308543\ttotal: 889ms\tremaining: 15.6s\n",
      "54:\tlearn: 1.9237713\ttotal: 905ms\tremaining: 15.5s\n",
      "55:\tlearn: 1.9085301\ttotal: 922ms\tremaining: 15.5s\n",
      "56:\tlearn: 1.9055188\ttotal: 938ms\tremaining: 15.5s\n",
      "57:\tlearn: 1.9044848\ttotal: 954ms\tremaining: 15.5s\n",
      "58:\tlearn: 1.9043663\ttotal: 971ms\tremaining: 15.5s\n",
      "59:\tlearn: 1.9035879\ttotal: 987ms\tremaining: 15.5s\n",
      "60:\tlearn: 1.9032118\ttotal: 1s\tremaining: 15.4s\n",
      "61:\tlearn: 1.9026836\ttotal: 1.02s\tremaining: 15.4s\n",
      "62:\tlearn: 1.9015586\ttotal: 1.03s\tremaining: 15.4s\n",
      "63:\tlearn: 1.8999190\ttotal: 1.05s\tremaining: 15.4s\n",
      "64:\tlearn: 1.8995865\ttotal: 1.07s\tremaining: 15.4s\n",
      "65:\tlearn: 1.8993495\ttotal: 1.08s\tremaining: 15.3s\n",
      "66:\tlearn: 1.8985254\ttotal: 1.1s\tremaining: 15.3s\n",
      "67:\tlearn: 1.8952995\ttotal: 1.11s\tremaining: 15.3s\n",
      "68:\tlearn: 1.8908065\ttotal: 1.13s\tremaining: 15.3s\n",
      "69:\tlearn: 1.8893996\ttotal: 1.15s\tremaining: 15.3s\n",
      "70:\tlearn: 1.8892314\ttotal: 1.16s\tremaining: 15.2s\n",
      "71:\tlearn: 1.8890631\ttotal: 1.18s\tremaining: 15.2s\n",
      "72:\tlearn: 1.8887791\ttotal: 1.19s\tremaining: 15.2s\n",
      "73:\tlearn: 1.8885602\ttotal: 1.21s\tremaining: 15.1s\n",
      "74:\tlearn: 1.8881951\ttotal: 1.22s\tremaining: 15.1s\n",
      "75:\tlearn: 1.8873591\ttotal: 1.24s\tremaining: 15.1s\n",
      "76:\tlearn: 1.8859059\ttotal: 1.26s\tremaining: 15.1s\n",
      "77:\tlearn: 1.8858177\ttotal: 1.27s\tremaining: 15s\n",
      "78:\tlearn: 1.8850594\ttotal: 1.29s\tremaining: 15s\n",
      "79:\tlearn: 1.8747827\ttotal: 1.3s\tremaining: 15s\n",
      "80:\tlearn: 1.8729075\ttotal: 1.32s\tremaining: 15s\n",
      "81:\tlearn: 1.8640891\ttotal: 1.33s\tremaining: 14.9s\n",
      "82:\tlearn: 1.8637815\ttotal: 1.35s\tremaining: 14.9s\n",
      "83:\tlearn: 1.8634911\ttotal: 1.37s\tremaining: 14.9s\n",
      "84:\tlearn: 1.8599992\ttotal: 1.38s\tremaining: 14.9s\n",
      "85:\tlearn: 1.8597412\ttotal: 1.4s\tremaining: 14.9s\n",
      "86:\tlearn: 1.8595355\ttotal: 1.41s\tremaining: 14.8s\n",
      "87:\tlearn: 1.8587448\ttotal: 1.43s\tremaining: 14.8s\n",
      "88:\tlearn: 1.8575030\ttotal: 1.45s\tremaining: 14.8s\n",
      "89:\tlearn: 1.8562056\ttotal: 1.46s\tremaining: 14.8s\n",
      "90:\tlearn: 1.8559219\ttotal: 1.48s\tremaining: 14.8s\n",
      "91:\tlearn: 1.8545473\ttotal: 1.49s\tremaining: 14.7s\n",
      "92:\tlearn: 1.8545450\ttotal: 1.5s\tremaining: 14.7s\n",
      "93:\tlearn: 1.8538355\ttotal: 1.52s\tremaining: 14.6s\n",
      "94:\tlearn: 1.8534858\ttotal: 1.54s\tremaining: 14.6s\n",
      "95:\tlearn: 1.8533704\ttotal: 1.55s\tremaining: 14.6s\n",
      "96:\tlearn: 1.8533137\ttotal: 1.56s\tremaining: 14.6s\n",
      "97:\tlearn: 1.8524898\ttotal: 1.58s\tremaining: 14.5s\n",
      "98:\tlearn: 1.8432344\ttotal: 1.59s\tremaining: 14.5s\n",
      "99:\tlearn: 1.8429704\ttotal: 1.61s\tremaining: 14.5s\n",
      "100:\tlearn: 1.8427771\ttotal: 1.63s\tremaining: 14.5s\n",
      "101:\tlearn: 1.8405458\ttotal: 1.64s\tremaining: 14.5s\n",
      "102:\tlearn: 1.8404499\ttotal: 1.66s\tremaining: 14.4s\n",
      "103:\tlearn: 1.8312030\ttotal: 1.67s\tremaining: 14.4s\n",
      "104:\tlearn: 1.8303361\ttotal: 1.69s\tremaining: 14.4s\n",
      "105:\tlearn: 1.8299903\ttotal: 1.71s\tremaining: 14.4s\n",
      "106:\tlearn: 1.8298594\ttotal: 1.72s\tremaining: 14.4s\n",
      "107:\tlearn: 1.8275312\ttotal: 1.74s\tremaining: 14.3s\n",
      "108:\tlearn: 1.8269531\ttotal: 1.75s\tremaining: 14.3s\n",
      "109:\tlearn: 1.8268448\ttotal: 1.77s\tremaining: 14.3s\n",
      "110:\tlearn: 1.8264581\ttotal: 1.79s\tremaining: 14.3s\n",
      "111:\tlearn: 1.8259661\ttotal: 1.8s\tremaining: 14.3s\n",
      "112:\tlearn: 1.8251750\ttotal: 1.82s\tremaining: 14.3s\n",
      "113:\tlearn: 1.8250206\ttotal: 1.83s\tremaining: 14.3s\n",
      "114:\tlearn: 1.8249795\ttotal: 1.85s\tremaining: 14.2s\n",
      "115:\tlearn: 1.8234450\ttotal: 1.86s\tremaining: 14.2s\n",
      "116:\tlearn: 1.8205446\ttotal: 1.88s\tremaining: 14.2s\n",
      "117:\tlearn: 1.8201721\ttotal: 1.89s\tremaining: 14.2s\n",
      "118:\tlearn: 1.8198680\ttotal: 1.91s\tremaining: 14.1s\n",
      "119:\tlearn: 1.8099870\ttotal: 1.93s\tremaining: 14.1s\n",
      "120:\tlearn: 1.8066177\ttotal: 1.94s\tremaining: 14.1s\n",
      "121:\tlearn: 1.8005126\ttotal: 1.96s\tremaining: 14.1s\n",
      "122:\tlearn: 1.7961012\ttotal: 1.98s\tremaining: 14.1s\n",
      "123:\tlearn: 1.7956833\ttotal: 1.99s\tremaining: 14.1s\n",
      "124:\tlearn: 1.7905448\ttotal: 2.01s\tremaining: 14.1s\n",
      "125:\tlearn: 1.7891939\ttotal: 2.02s\tremaining: 14s\n",
      "126:\tlearn: 1.7886773\ttotal: 2.04s\tremaining: 14s\n",
      "127:\tlearn: 1.7873164\ttotal: 2.05s\tremaining: 14s\n",
      "128:\tlearn: 1.7848580\ttotal: 2.07s\tremaining: 14s\n",
      "129:\tlearn: 1.7763639\ttotal: 2.08s\tremaining: 13.9s\n",
      "130:\tlearn: 1.7757335\ttotal: 2.1s\tremaining: 13.9s\n",
      "131:\tlearn: 1.7756962\ttotal: 2.11s\tremaining: 13.9s\n",
      "132:\tlearn: 1.7753400\ttotal: 2.13s\tremaining: 13.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133:\tlearn: 1.7751805\ttotal: 2.15s\tremaining: 13.9s\n",
      "134:\tlearn: 1.7751060\ttotal: 2.16s\tremaining: 13.8s\n",
      "135:\tlearn: 1.7747315\ttotal: 2.17s\tremaining: 13.8s\n",
      "136:\tlearn: 1.7746075\ttotal: 2.19s\tremaining: 13.8s\n",
      "137:\tlearn: 1.7745441\ttotal: 2.2s\tremaining: 13.8s\n",
      "138:\tlearn: 1.7744534\ttotal: 2.22s\tremaining: 13.8s\n",
      "139:\tlearn: 1.7742810\ttotal: 2.23s\tremaining: 13.7s\n",
      "140:\tlearn: 1.7741720\ttotal: 2.25s\tremaining: 13.7s\n",
      "141:\tlearn: 1.7706893\ttotal: 2.26s\tremaining: 13.7s\n",
      "142:\tlearn: 1.7704892\ttotal: 2.28s\tremaining: 13.7s\n",
      "143:\tlearn: 1.7692384\ttotal: 2.29s\tremaining: 13.6s\n",
      "144:\tlearn: 1.7691759\ttotal: 2.31s\tremaining: 13.6s\n",
      "145:\tlearn: 1.7691084\ttotal: 2.32s\tremaining: 13.6s\n",
      "146:\tlearn: 1.7689502\ttotal: 2.34s\tremaining: 13.6s\n",
      "147:\tlearn: 1.7687881\ttotal: 2.35s\tremaining: 13.5s\n",
      "148:\tlearn: 1.7686982\ttotal: 2.37s\tremaining: 13.5s\n",
      "149:\tlearn: 1.7686444\ttotal: 2.38s\tremaining: 13.5s\n",
      "150:\tlearn: 1.7684003\ttotal: 2.4s\tremaining: 13.5s\n",
      "151:\tlearn: 1.7683098\ttotal: 2.41s\tremaining: 13.5s\n",
      "152:\tlearn: 1.7682178\ttotal: 2.43s\tremaining: 13.4s\n",
      "153:\tlearn: 1.7680332\ttotal: 2.44s\tremaining: 13.4s\n",
      "154:\tlearn: 1.7665096\ttotal: 2.46s\tremaining: 13.4s\n",
      "155:\tlearn: 1.7626502\ttotal: 2.47s\tremaining: 13.4s\n",
      "156:\tlearn: 1.7621092\ttotal: 2.48s\tremaining: 13.3s\n",
      "157:\tlearn: 1.7562211\ttotal: 2.5s\tremaining: 13.3s\n",
      "158:\tlearn: 1.7494947\ttotal: 2.52s\tremaining: 13.3s\n",
      "159:\tlearn: 1.7464626\ttotal: 2.53s\tremaining: 13.3s\n",
      "160:\tlearn: 1.7431066\ttotal: 2.55s\tremaining: 13.3s\n",
      "161:\tlearn: 1.7403949\ttotal: 2.56s\tremaining: 13.2s\n",
      "162:\tlearn: 1.7402739\ttotal: 2.58s\tremaining: 13.2s\n",
      "163:\tlearn: 1.7401199\ttotal: 2.59s\tremaining: 13.2s\n",
      "164:\tlearn: 1.7398089\ttotal: 2.61s\tremaining: 13.2s\n",
      "165:\tlearn: 1.7397384\ttotal: 2.62s\tremaining: 13.2s\n",
      "166:\tlearn: 1.7395108\ttotal: 2.64s\tremaining: 13.2s\n",
      "167:\tlearn: 1.7392830\ttotal: 2.65s\tremaining: 13.1s\n",
      "168:\tlearn: 1.7389589\ttotal: 2.67s\tremaining: 13.1s\n",
      "169:\tlearn: 1.7387353\ttotal: 2.68s\tremaining: 13.1s\n",
      "170:\tlearn: 1.7362343\ttotal: 2.7s\tremaining: 13.1s\n",
      "171:\tlearn: 1.7354000\ttotal: 2.71s\tremaining: 13.1s\n",
      "172:\tlearn: 1.7351245\ttotal: 2.73s\tremaining: 13.1s\n",
      "173:\tlearn: 1.7349294\ttotal: 2.75s\tremaining: 13s\n",
      "174:\tlearn: 1.7347011\ttotal: 2.76s\tremaining: 13s\n",
      "175:\tlearn: 1.7345231\ttotal: 2.78s\tremaining: 13s\n",
      "176:\tlearn: 1.7333666\ttotal: 2.79s\tremaining: 13s\n",
      "177:\tlearn: 1.7328974\ttotal: 2.81s\tremaining: 13s\n",
      "178:\tlearn: 1.7327566\ttotal: 2.82s\tremaining: 13s\n",
      "179:\tlearn: 1.7319477\ttotal: 2.84s\tremaining: 12.9s\n",
      "180:\tlearn: 1.7317614\ttotal: 2.85s\tremaining: 12.9s\n",
      "181:\tlearn: 1.7316414\ttotal: 2.87s\tremaining: 12.9s\n",
      "182:\tlearn: 1.7300208\ttotal: 2.89s\tremaining: 12.9s\n",
      "183:\tlearn: 1.7293949\ttotal: 2.9s\tremaining: 12.9s\n",
      "184:\tlearn: 1.7289575\ttotal: 2.92s\tremaining: 12.9s\n",
      "185:\tlearn: 1.7286798\ttotal: 2.94s\tremaining: 12.8s\n",
      "186:\tlearn: 1.7285692\ttotal: 2.95s\tremaining: 12.8s\n",
      "187:\tlearn: 1.7283644\ttotal: 2.97s\tremaining: 12.8s\n",
      "188:\tlearn: 1.7282955\ttotal: 2.98s\tremaining: 12.8s\n",
      "189:\tlearn: 1.7262435\ttotal: 3s\tremaining: 12.8s\n",
      "190:\tlearn: 1.7257990\ttotal: 3.02s\tremaining: 12.8s\n",
      "191:\tlearn: 1.7256955\ttotal: 3.03s\tremaining: 12.8s\n",
      "192:\tlearn: 1.7256360\ttotal: 3.05s\tremaining: 12.8s\n",
      "193:\tlearn: 1.7254522\ttotal: 3.07s\tremaining: 12.7s\n",
      "194:\tlearn: 1.7252552\ttotal: 3.08s\tremaining: 12.7s\n",
      "195:\tlearn: 1.7248529\ttotal: 3.1s\tremaining: 12.7s\n",
      "196:\tlearn: 1.7246878\ttotal: 3.11s\tremaining: 12.7s\n",
      "197:\tlearn: 1.7245564\ttotal: 3.13s\tremaining: 12.7s\n",
      "198:\tlearn: 1.7225241\ttotal: 3.15s\tremaining: 12.7s\n",
      "199:\tlearn: 1.7214963\ttotal: 3.16s\tremaining: 12.7s\n",
      "200:\tlearn: 1.7203967\ttotal: 3.18s\tremaining: 12.6s\n",
      "201:\tlearn: 1.7190301\ttotal: 3.19s\tremaining: 12.6s\n",
      "202:\tlearn: 1.7187863\ttotal: 3.21s\tremaining: 12.6s\n",
      "203:\tlearn: 1.7185968\ttotal: 3.23s\tremaining: 12.6s\n",
      "204:\tlearn: 1.7184402\ttotal: 3.24s\tremaining: 12.6s\n",
      "205:\tlearn: 1.7183114\ttotal: 3.26s\tremaining: 12.6s\n",
      "206:\tlearn: 1.7160941\ttotal: 3.27s\tremaining: 12.5s\n",
      "207:\tlearn: 1.7150344\ttotal: 3.29s\tremaining: 12.5s\n",
      "208:\tlearn: 1.7133233\ttotal: 3.31s\tremaining: 12.5s\n",
      "209:\tlearn: 1.7121517\ttotal: 3.32s\tremaining: 12.5s\n",
      "210:\tlearn: 1.7121011\ttotal: 3.33s\tremaining: 12.5s\n",
      "211:\tlearn: 1.7112844\ttotal: 3.35s\tremaining: 12.4s\n",
      "212:\tlearn: 1.7100094\ttotal: 3.36s\tremaining: 12.4s\n",
      "213:\tlearn: 1.7086073\ttotal: 3.38s\tremaining: 12.4s\n",
      "214:\tlearn: 1.7069367\ttotal: 3.39s\tremaining: 12.4s\n",
      "215:\tlearn: 1.7055621\ttotal: 3.41s\tremaining: 12.4s\n",
      "216:\tlearn: 1.7040617\ttotal: 3.42s\tremaining: 12.4s\n",
      "217:\tlearn: 1.7039301\ttotal: 3.44s\tremaining: 12.3s\n",
      "218:\tlearn: 1.7037744\ttotal: 3.46s\tremaining: 12.3s\n",
      "219:\tlearn: 1.7036581\ttotal: 3.47s\tremaining: 12.3s\n",
      "220:\tlearn: 1.7024160\ttotal: 3.48s\tremaining: 12.3s\n",
      "221:\tlearn: 1.7008400\ttotal: 3.5s\tremaining: 12.3s\n",
      "222:\tlearn: 1.6972906\ttotal: 3.52s\tremaining: 12.2s\n",
      "223:\tlearn: 1.6962417\ttotal: 3.53s\tremaining: 12.2s\n",
      "224:\tlearn: 1.6961630\ttotal: 3.54s\tremaining: 12.2s\n",
      "225:\tlearn: 1.6956694\ttotal: 3.56s\tremaining: 12.2s\n",
      "226:\tlearn: 1.6956426\ttotal: 3.57s\tremaining: 12.2s\n",
      "227:\tlearn: 1.6939881\ttotal: 3.59s\tremaining: 12.2s\n",
      "228:\tlearn: 1.6933633\ttotal: 3.6s\tremaining: 12.1s\n",
      "229:\tlearn: 1.6920588\ttotal: 3.62s\tremaining: 12.1s\n",
      "230:\tlearn: 1.6903785\ttotal: 3.63s\tremaining: 12.1s\n",
      "231:\tlearn: 1.6892742\ttotal: 3.65s\tremaining: 12.1s\n",
      "232:\tlearn: 1.6891824\ttotal: 3.67s\tremaining: 12.1s\n",
      "233:\tlearn: 1.6887645\ttotal: 3.68s\tremaining: 12.1s\n",
      "234:\tlearn: 1.6879766\ttotal: 3.69s\tremaining: 12s\n",
      "235:\tlearn: 1.6872770\ttotal: 3.71s\tremaining: 12s\n",
      "236:\tlearn: 1.6871899\ttotal: 3.73s\tremaining: 12s\n",
      "237:\tlearn: 1.6866706\ttotal: 3.74s\tremaining: 12s\n",
      "238:\tlearn: 1.6839648\ttotal: 3.75s\tremaining: 12s\n",
      "239:\tlearn: 1.6829916\ttotal: 3.77s\tremaining: 11.9s\n",
      "240:\tlearn: 1.6821867\ttotal: 3.79s\tremaining: 11.9s\n",
      "241:\tlearn: 1.6812095\ttotal: 3.8s\tremaining: 11.9s\n",
      "242:\tlearn: 1.6798521\ttotal: 3.81s\tremaining: 11.9s\n",
      "243:\tlearn: 1.6782639\ttotal: 3.83s\tremaining: 11.9s\n",
      "244:\tlearn: 1.6748362\ttotal: 3.85s\tremaining: 11.9s\n",
      "245:\tlearn: 1.6738944\ttotal: 3.86s\tremaining: 11.8s\n",
      "246:\tlearn: 1.6703935\ttotal: 3.88s\tremaining: 11.8s\n",
      "247:\tlearn: 1.6692043\ttotal: 3.89s\tremaining: 11.8s\n",
      "248:\tlearn: 1.6683941\ttotal: 3.9s\tremaining: 11.8s\n",
      "249:\tlearn: 1.6660075\ttotal: 3.92s\tremaining: 11.8s\n",
      "250:\tlearn: 1.6639736\ttotal: 3.94s\tremaining: 11.7s\n",
      "251:\tlearn: 1.6625610\ttotal: 3.95s\tremaining: 11.7s\n",
      "252:\tlearn: 1.6616889\ttotal: 3.97s\tremaining: 11.7s\n",
      "253:\tlearn: 1.6609611\ttotal: 3.98s\tremaining: 11.7s\n",
      "254:\tlearn: 1.6594255\ttotal: 4s\tremaining: 11.7s\n",
      "255:\tlearn: 1.6583120\ttotal: 4.01s\tremaining: 11.7s\n",
      "256:\tlearn: 1.6569459\ttotal: 4.03s\tremaining: 11.6s\n",
      "257:\tlearn: 1.6566082\ttotal: 4.04s\tremaining: 11.6s\n",
      "258:\tlearn: 1.6555884\ttotal: 4.06s\tremaining: 11.6s\n",
      "259:\tlearn: 1.6548625\ttotal: 4.07s\tremaining: 11.6s\n",
      "260:\tlearn: 1.6536203\ttotal: 4.09s\tremaining: 11.6s\n",
      "261:\tlearn: 1.6514329\ttotal: 4.1s\tremaining: 11.6s\n",
      "262:\tlearn: 1.6503350\ttotal: 4.12s\tremaining: 11.5s\n",
      "263:\tlearn: 1.6483387\ttotal: 4.13s\tremaining: 11.5s\n",
      "264:\tlearn: 1.6470432\ttotal: 4.15s\tremaining: 11.5s\n",
      "265:\tlearn: 1.6452637\ttotal: 4.16s\tremaining: 11.5s\n",
      "266:\tlearn: 1.6425874\ttotal: 4.18s\tremaining: 11.5s\n",
      "267:\tlearn: 1.6397011\ttotal: 4.19s\tremaining: 11.5s\n",
      "268:\tlearn: 1.6381097\ttotal: 4.21s\tremaining: 11.4s\n",
      "269:\tlearn: 1.6367478\ttotal: 4.22s\tremaining: 11.4s\n",
      "270:\tlearn: 1.6348818\ttotal: 4.24s\tremaining: 11.4s\n",
      "271:\tlearn: 1.6324368\ttotal: 4.25s\tremaining: 11.4s\n",
      "272:\tlearn: 1.6320320\ttotal: 4.27s\tremaining: 11.4s\n",
      "273:\tlearn: 1.6309347\ttotal: 4.28s\tremaining: 11.4s\n",
      "274:\tlearn: 1.6304683\ttotal: 4.3s\tremaining: 11.3s\n",
      "275:\tlearn: 1.6298638\ttotal: 4.31s\tremaining: 11.3s\n",
      "276:\tlearn: 1.6281336\ttotal: 4.33s\tremaining: 11.3s\n",
      "277:\tlearn: 1.6277494\ttotal: 4.34s\tremaining: 11.3s\n",
      "278:\tlearn: 1.6271590\ttotal: 4.36s\tremaining: 11.3s\n",
      "279:\tlearn: 1.6267622\ttotal: 4.37s\tremaining: 11.2s\n",
      "280:\tlearn: 1.6259869\ttotal: 4.39s\tremaining: 11.2s\n",
      "281:\tlearn: 1.6250290\ttotal: 4.4s\tremaining: 11.2s\n",
      "282:\tlearn: 1.6239931\ttotal: 4.42s\tremaining: 11.2s\n",
      "283:\tlearn: 1.6232555\ttotal: 4.43s\tremaining: 11.2s\n",
      "284:\tlearn: 1.6217816\ttotal: 4.45s\tremaining: 11.2s\n",
      "285:\tlearn: 1.6210478\ttotal: 4.46s\tremaining: 11.1s\n",
      "286:\tlearn: 1.6204529\ttotal: 4.48s\tremaining: 11.1s\n",
      "287:\tlearn: 1.6194852\ttotal: 4.49s\tremaining: 11.1s\n",
      "288:\tlearn: 1.6191593\ttotal: 4.51s\tremaining: 11.1s\n",
      "289:\tlearn: 1.6181430\ttotal: 4.53s\tremaining: 11.1s\n",
      "290:\tlearn: 1.6180592\ttotal: 4.54s\tremaining: 11.1s\n",
      "291:\tlearn: 1.6177624\ttotal: 4.55s\tremaining: 11s\n",
      "292:\tlearn: 1.6163465\ttotal: 4.57s\tremaining: 11s\n",
      "293:\tlearn: 1.6159138\ttotal: 4.58s\tremaining: 11s\n",
      "294:\tlearn: 1.6157192\ttotal: 4.6s\tremaining: 11s\n",
      "295:\tlearn: 1.6152061\ttotal: 4.62s\tremaining: 11s\n",
      "296:\tlearn: 1.6138052\ttotal: 4.63s\tremaining: 11s\n",
      "297:\tlearn: 1.6134898\ttotal: 4.64s\tremaining: 10.9s\n",
      "298:\tlearn: 1.6128712\ttotal: 4.66s\tremaining: 10.9s\n",
      "299:\tlearn: 1.6115185\ttotal: 4.67s\tremaining: 10.9s\n",
      "300:\tlearn: 1.6104840\ttotal: 4.69s\tremaining: 10.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301:\tlearn: 1.6096169\ttotal: 4.7s\tremaining: 10.9s\n",
      "302:\tlearn: 1.6092525\ttotal: 4.72s\tremaining: 10.9s\n",
      "303:\tlearn: 1.6087087\ttotal: 4.73s\tremaining: 10.8s\n",
      "304:\tlearn: 1.6078291\ttotal: 4.75s\tremaining: 10.8s\n",
      "305:\tlearn: 1.6068162\ttotal: 4.76s\tremaining: 10.8s\n",
      "306:\tlearn: 1.6067851\ttotal: 4.78s\tremaining: 10.8s\n",
      "307:\tlearn: 1.6065135\ttotal: 4.79s\tremaining: 10.8s\n",
      "308:\tlearn: 1.6057928\ttotal: 4.81s\tremaining: 10.8s\n",
      "309:\tlearn: 1.6052397\ttotal: 4.82s\tremaining: 10.7s\n",
      "310:\tlearn: 1.6048470\ttotal: 4.84s\tremaining: 10.7s\n",
      "311:\tlearn: 1.6046256\ttotal: 4.85s\tremaining: 10.7s\n",
      "312:\tlearn: 1.6045139\ttotal: 4.87s\tremaining: 10.7s\n",
      "313:\tlearn: 1.6038671\ttotal: 4.88s\tremaining: 10.7s\n",
      "314:\tlearn: 1.6038102\ttotal: 4.9s\tremaining: 10.7s\n",
      "315:\tlearn: 1.6029231\ttotal: 4.91s\tremaining: 10.6s\n",
      "316:\tlearn: 1.6015926\ttotal: 4.93s\tremaining: 10.6s\n",
      "317:\tlearn: 1.6003352\ttotal: 4.94s\tremaining: 10.6s\n",
      "318:\tlearn: 1.5996876\ttotal: 4.96s\tremaining: 10.6s\n",
      "319:\tlearn: 1.5994645\ttotal: 4.97s\tremaining: 10.6s\n",
      "320:\tlearn: 1.5973280\ttotal: 4.99s\tremaining: 10.6s\n",
      "321:\tlearn: 1.5968049\ttotal: 5s\tremaining: 10.5s\n",
      "322:\tlearn: 1.5962074\ttotal: 5.02s\tremaining: 10.5s\n",
      "323:\tlearn: 1.5960068\ttotal: 5.03s\tremaining: 10.5s\n",
      "324:\tlearn: 1.5952134\ttotal: 5.05s\tremaining: 10.5s\n",
      "325:\tlearn: 1.5946446\ttotal: 5.06s\tremaining: 10.5s\n",
      "326:\tlearn: 1.5939656\ttotal: 5.08s\tremaining: 10.5s\n",
      "327:\tlearn: 1.5932261\ttotal: 5.09s\tremaining: 10.4s\n",
      "328:\tlearn: 1.5930466\ttotal: 5.11s\tremaining: 10.4s\n",
      "329:\tlearn: 1.5926600\ttotal: 5.12s\tremaining: 10.4s\n",
      "330:\tlearn: 1.5913129\ttotal: 5.14s\tremaining: 10.4s\n",
      "331:\tlearn: 1.5895883\ttotal: 5.15s\tremaining: 10.4s\n",
      "332:\tlearn: 1.5891647\ttotal: 5.17s\tremaining: 10.4s\n",
      "333:\tlearn: 1.5889231\ttotal: 5.18s\tremaining: 10.3s\n",
      "334:\tlearn: 1.5884747\ttotal: 5.21s\tremaining: 10.3s\n",
      "335:\tlearn: 1.5882528\ttotal: 5.23s\tremaining: 10.3s\n",
      "336:\tlearn: 1.5879965\ttotal: 5.24s\tremaining: 10.3s\n",
      "337:\tlearn: 1.5867352\ttotal: 5.26s\tremaining: 10.3s\n",
      "338:\tlearn: 1.5857146\ttotal: 5.27s\tremaining: 10.3s\n",
      "339:\tlearn: 1.5852800\ttotal: 5.29s\tremaining: 10.3s\n",
      "340:\tlearn: 1.5852282\ttotal: 5.3s\tremaining: 10.2s\n",
      "341:\tlearn: 1.5850328\ttotal: 5.32s\tremaining: 10.2s\n",
      "342:\tlearn: 1.5850082\ttotal: 5.33s\tremaining: 10.2s\n",
      "343:\tlearn: 1.5848312\ttotal: 5.35s\tremaining: 10.2s\n",
      "344:\tlearn: 1.5839536\ttotal: 5.37s\tremaining: 10.2s\n",
      "345:\tlearn: 1.5838518\ttotal: 5.38s\tremaining: 10.2s\n",
      "346:\tlearn: 1.5838066\ttotal: 5.39s\tremaining: 10.2s\n",
      "347:\tlearn: 1.5830093\ttotal: 5.41s\tremaining: 10.1s\n",
      "348:\tlearn: 1.5816938\ttotal: 5.42s\tremaining: 10.1s\n",
      "349:\tlearn: 1.5814388\ttotal: 5.44s\tremaining: 10.1s\n",
      "350:\tlearn: 1.5809796\ttotal: 5.45s\tremaining: 10.1s\n",
      "351:\tlearn: 1.5804125\ttotal: 5.47s\tremaining: 10.1s\n",
      "352:\tlearn: 1.5799096\ttotal: 5.48s\tremaining: 10s\n",
      "353:\tlearn: 1.5798133\ttotal: 5.5s\tremaining: 10s\n",
      "354:\tlearn: 1.5795396\ttotal: 5.51s\tremaining: 10s\n",
      "355:\tlearn: 1.5793784\ttotal: 5.53s\tremaining: 10s\n",
      "356:\tlearn: 1.5790382\ttotal: 5.54s\tremaining: 9.98s\n",
      "357:\tlearn: 1.5784357\ttotal: 5.56s\tremaining: 9.96s\n",
      "358:\tlearn: 1.5780293\ttotal: 5.57s\tremaining: 9.95s\n",
      "359:\tlearn: 1.5779960\ttotal: 5.58s\tremaining: 9.93s\n",
      "360:\tlearn: 1.5756293\ttotal: 5.6s\tremaining: 9.91s\n",
      "361:\tlearn: 1.5745952\ttotal: 5.62s\tremaining: 9.9s\n",
      "362:\tlearn: 1.5744652\ttotal: 5.63s\tremaining: 9.88s\n",
      "363:\tlearn: 1.5742917\ttotal: 5.65s\tremaining: 9.87s\n",
      "364:\tlearn: 1.5738079\ttotal: 5.66s\tremaining: 9.85s\n",
      "365:\tlearn: 1.5733362\ttotal: 5.68s\tremaining: 9.84s\n",
      "366:\tlearn: 1.5725957\ttotal: 5.69s\tremaining: 9.82s\n",
      "367:\tlearn: 1.5715996\ttotal: 5.71s\tremaining: 9.8s\n",
      "368:\tlearn: 1.5710672\ttotal: 5.72s\tremaining: 9.78s\n",
      "369:\tlearn: 1.5706153\ttotal: 5.74s\tremaining: 9.77s\n",
      "370:\tlearn: 1.5704758\ttotal: 5.75s\tremaining: 9.75s\n",
      "371:\tlearn: 1.5701093\ttotal: 5.77s\tremaining: 9.73s\n",
      "372:\tlearn: 1.5694900\ttotal: 5.78s\tremaining: 9.72s\n",
      "373:\tlearn: 1.5693359\ttotal: 5.79s\tremaining: 9.7s\n",
      "374:\tlearn: 1.5687365\ttotal: 5.81s\tremaining: 9.69s\n",
      "375:\tlearn: 1.5683198\ttotal: 5.83s\tremaining: 9.67s\n",
      "376:\tlearn: 1.5682739\ttotal: 5.84s\tremaining: 9.65s\n",
      "377:\tlearn: 1.5678739\ttotal: 5.86s\tremaining: 9.64s\n",
      "378:\tlearn: 1.5664779\ttotal: 5.88s\tremaining: 9.64s\n",
      "379:\tlearn: 1.5654513\ttotal: 5.9s\tremaining: 9.63s\n",
      "380:\tlearn: 1.5652513\ttotal: 5.91s\tremaining: 9.61s\n",
      "381:\tlearn: 1.5643083\ttotal: 5.93s\tremaining: 9.59s\n",
      "382:\tlearn: 1.5638145\ttotal: 5.95s\tremaining: 9.58s\n",
      "383:\tlearn: 1.5634543\ttotal: 5.96s\tremaining: 9.56s\n",
      "384:\tlearn: 1.5631703\ttotal: 5.98s\tremaining: 9.55s\n",
      "385:\tlearn: 1.5629326\ttotal: 5.99s\tremaining: 9.53s\n",
      "386:\tlearn: 1.5624193\ttotal: 6.01s\tremaining: 9.52s\n",
      "387:\tlearn: 1.5623219\ttotal: 6.02s\tremaining: 9.5s\n",
      "388:\tlearn: 1.5622943\ttotal: 6.04s\tremaining: 9.48s\n",
      "389:\tlearn: 1.5619354\ttotal: 6.05s\tremaining: 9.47s\n",
      "390:\tlearn: 1.5611340\ttotal: 6.07s\tremaining: 9.45s\n",
      "391:\tlearn: 1.5610204\ttotal: 6.08s\tremaining: 9.43s\n",
      "392:\tlearn: 1.5602416\ttotal: 6.1s\tremaining: 9.42s\n",
      "393:\tlearn: 1.5582628\ttotal: 6.11s\tremaining: 9.4s\n",
      "394:\tlearn: 1.5565356\ttotal: 6.13s\tremaining: 9.39s\n",
      "395:\tlearn: 1.5563947\ttotal: 6.14s\tremaining: 9.37s\n",
      "396:\tlearn: 1.5556704\ttotal: 6.16s\tremaining: 9.35s\n",
      "397:\tlearn: 1.5551905\ttotal: 6.17s\tremaining: 9.34s\n",
      "398:\tlearn: 1.5538841\ttotal: 6.19s\tremaining: 9.32s\n",
      "399:\tlearn: 1.5537898\ttotal: 6.2s\tremaining: 9.31s\n",
      "400:\tlearn: 1.5534803\ttotal: 6.22s\tremaining: 9.29s\n",
      "401:\tlearn: 1.5531765\ttotal: 6.23s\tremaining: 9.27s\n",
      "402:\tlearn: 1.5531542\ttotal: 6.25s\tremaining: 9.26s\n",
      "403:\tlearn: 1.5530990\ttotal: 6.26s\tremaining: 9.24s\n",
      "404:\tlearn: 1.5520232\ttotal: 6.28s\tremaining: 9.22s\n",
      "405:\tlearn: 1.5518949\ttotal: 6.29s\tremaining: 9.21s\n",
      "406:\tlearn: 1.5518706\ttotal: 6.3s\tremaining: 9.19s\n",
      "407:\tlearn: 1.5518638\ttotal: 6.32s\tremaining: 9.17s\n",
      "408:\tlearn: 1.5514093\ttotal: 6.33s\tremaining: 9.15s\n",
      "409:\tlearn: 1.5512142\ttotal: 6.35s\tremaining: 9.14s\n",
      "410:\tlearn: 1.5509918\ttotal: 6.36s\tremaining: 9.12s\n",
      "411:\tlearn: 1.5509802\ttotal: 6.38s\tremaining: 9.1s\n",
      "412:\tlearn: 1.5509692\ttotal: 6.39s\tremaining: 9.08s\n",
      "413:\tlearn: 1.5508825\ttotal: 6.41s\tremaining: 9.07s\n",
      "414:\tlearn: 1.5505676\ttotal: 6.42s\tremaining: 9.05s\n",
      "415:\tlearn: 1.5501816\ttotal: 6.43s\tremaining: 9.03s\n",
      "416:\tlearn: 1.5500671\ttotal: 6.45s\tremaining: 9.02s\n",
      "417:\tlearn: 1.5500484\ttotal: 6.46s\tremaining: 9s\n",
      "418:\tlearn: 1.5497986\ttotal: 6.48s\tremaining: 8.98s\n",
      "419:\tlearn: 1.5493038\ttotal: 6.49s\tremaining: 8.97s\n",
      "420:\tlearn: 1.5493008\ttotal: 6.51s\tremaining: 8.95s\n",
      "421:\tlearn: 1.5492872\ttotal: 6.52s\tremaining: 8.93s\n",
      "422:\tlearn: 1.5492808\ttotal: 6.54s\tremaining: 8.92s\n",
      "423:\tlearn: 1.5481693\ttotal: 6.55s\tremaining: 8.9s\n",
      "424:\tlearn: 1.5477946\ttotal: 6.57s\tremaining: 8.88s\n",
      "425:\tlearn: 1.5477574\ttotal: 6.58s\tremaining: 8.87s\n",
      "426:\tlearn: 1.5477405\ttotal: 6.6s\tremaining: 8.85s\n",
      "427:\tlearn: 1.5475363\ttotal: 6.61s\tremaining: 8.84s\n",
      "428:\tlearn: 1.5474994\ttotal: 6.63s\tremaining: 8.82s\n",
      "429:\tlearn: 1.5474594\ttotal: 6.64s\tremaining: 8.8s\n",
      "430:\tlearn: 1.5474188\ttotal: 6.66s\tremaining: 8.79s\n",
      "431:\tlearn: 1.5465060\ttotal: 6.67s\tremaining: 8.77s\n",
      "432:\tlearn: 1.5459521\ttotal: 6.69s\tremaining: 8.76s\n",
      "433:\tlearn: 1.5459321\ttotal: 6.7s\tremaining: 8.74s\n",
      "434:\tlearn: 1.5455897\ttotal: 6.71s\tremaining: 8.72s\n",
      "435:\tlearn: 1.5455254\ttotal: 6.73s\tremaining: 8.71s\n",
      "436:\tlearn: 1.5455061\ttotal: 6.75s\tremaining: 8.69s\n",
      "437:\tlearn: 1.5453524\ttotal: 6.76s\tremaining: 8.67s\n",
      "438:\tlearn: 1.5451211\ttotal: 6.78s\tremaining: 8.66s\n",
      "439:\tlearn: 1.5449877\ttotal: 6.79s\tremaining: 8.64s\n",
      "440:\tlearn: 1.5448787\ttotal: 6.8s\tremaining: 8.63s\n",
      "441:\tlearn: 1.5448787\ttotal: 6.82s\tremaining: 8.61s\n",
      "442:\tlearn: 1.5448787\ttotal: 6.83s\tremaining: 8.59s\n",
      "443:\tlearn: 1.5448787\ttotal: 6.85s\tremaining: 8.58s\n",
      "444:\tlearn: 1.5448787\ttotal: 6.86s\tremaining: 8.56s\n",
      "445:\tlearn: 1.5448713\ttotal: 6.88s\tremaining: 8.54s\n",
      "446:\tlearn: 1.5448713\ttotal: 6.89s\tremaining: 8.53s\n",
      "447:\tlearn: 1.5448713\ttotal: 6.91s\tremaining: 8.51s\n",
      "448:\tlearn: 1.5448689\ttotal: 6.92s\tremaining: 8.49s\n",
      "449:\tlearn: 1.5448632\ttotal: 6.93s\tremaining: 8.48s\n",
      "450:\tlearn: 1.5447948\ttotal: 6.95s\tremaining: 8.46s\n",
      "451:\tlearn: 1.5447073\ttotal: 6.96s\tremaining: 8.44s\n",
      "452:\tlearn: 1.5446371\ttotal: 6.98s\tremaining: 8.43s\n",
      "453:\tlearn: 1.5446322\ttotal: 7s\tremaining: 8.41s\n",
      "454:\tlearn: 1.5445755\ttotal: 7.01s\tremaining: 8.4s\n",
      "455:\tlearn: 1.5445711\ttotal: 7.03s\tremaining: 8.38s\n",
      "456:\tlearn: 1.5445310\ttotal: 7.04s\tremaining: 8.36s\n",
      "457:\tlearn: 1.5443607\ttotal: 7.05s\tremaining: 8.35s\n",
      "458:\tlearn: 1.5443595\ttotal: 7.07s\tremaining: 8.33s\n",
      "459:\tlearn: 1.5442546\ttotal: 7.08s\tremaining: 8.32s\n",
      "460:\tlearn: 1.5442508\ttotal: 7.1s\tremaining: 8.3s\n",
      "461:\tlearn: 1.5442499\ttotal: 7.11s\tremaining: 8.28s\n",
      "462:\tlearn: 1.5442383\ttotal: 7.13s\tremaining: 8.27s\n",
      "463:\tlearn: 1.5442382\ttotal: 7.14s\tremaining: 8.25s\n",
      "464:\tlearn: 1.5442343\ttotal: 7.16s\tremaining: 8.23s\n",
      "465:\tlearn: 1.5441843\ttotal: 7.17s\tremaining: 8.22s\n",
      "466:\tlearn: 1.5441508\ttotal: 7.19s\tremaining: 8.2s\n",
      "467:\tlearn: 1.5441220\ttotal: 7.2s\tremaining: 8.19s\n",
      "468:\tlearn: 1.5441095\ttotal: 7.22s\tremaining: 8.17s\n",
      "469:\tlearn: 1.5441085\ttotal: 7.23s\tremaining: 8.15s\n",
      "470:\tlearn: 1.5440508\ttotal: 7.25s\tremaining: 8.14s\n",
      "471:\tlearn: 1.5440469\ttotal: 7.26s\tremaining: 8.12s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472:\tlearn: 1.5440467\ttotal: 7.28s\tremaining: 8.11s\n",
      "473:\tlearn: 1.5440155\ttotal: 7.29s\tremaining: 8.09s\n",
      "474:\tlearn: 1.5439752\ttotal: 7.31s\tremaining: 8.08s\n",
      "475:\tlearn: 1.5439416\ttotal: 7.32s\tremaining: 8.06s\n",
      "476:\tlearn: 1.5439002\ttotal: 7.34s\tremaining: 8.04s\n",
      "477:\tlearn: 1.5438353\ttotal: 7.35s\tremaining: 8.03s\n",
      "478:\tlearn: 1.5437107\ttotal: 7.37s\tremaining: 8.01s\n",
      "479:\tlearn: 1.5437107\ttotal: 7.38s\tremaining: 8s\n",
      "480:\tlearn: 1.5437097\ttotal: 7.4s\tremaining: 7.98s\n",
      "481:\tlearn: 1.5433672\ttotal: 7.41s\tremaining: 7.96s\n",
      "482:\tlearn: 1.5433569\ttotal: 7.42s\tremaining: 7.95s\n",
      "483:\tlearn: 1.5433568\ttotal: 7.44s\tremaining: 7.93s\n",
      "484:\tlearn: 1.5430096\ttotal: 7.46s\tremaining: 7.92s\n",
      "485:\tlearn: 1.5430063\ttotal: 7.47s\tremaining: 7.9s\n",
      "486:\tlearn: 1.5429992\ttotal: 7.49s\tremaining: 7.88s\n",
      "487:\tlearn: 1.5429991\ttotal: 7.5s\tremaining: 7.87s\n",
      "488:\tlearn: 1.5429991\ttotal: 7.51s\tremaining: 7.85s\n",
      "489:\tlearn: 1.5429931\ttotal: 7.53s\tremaining: 7.84s\n",
      "490:\tlearn: 1.5429930\ttotal: 7.54s\tremaining: 7.82s\n",
      "491:\tlearn: 1.5429929\ttotal: 7.56s\tremaining: 7.8s\n",
      "492:\tlearn: 1.5429929\ttotal: 7.57s\tremaining: 7.79s\n",
      "493:\tlearn: 1.5429929\ttotal: 7.59s\tremaining: 7.77s\n",
      "494:\tlearn: 1.5429929\ttotal: 7.61s\tremaining: 7.76s\n",
      "495:\tlearn: 1.5429926\ttotal: 7.62s\tremaining: 7.74s\n",
      "496:\tlearn: 1.5429912\ttotal: 7.63s\tremaining: 7.73s\n",
      "497:\tlearn: 1.5429912\ttotal: 7.65s\tremaining: 7.71s\n",
      "498:\tlearn: 1.5429912\ttotal: 7.66s\tremaining: 7.7s\n",
      "499:\tlearn: 1.5429912\ttotal: 7.68s\tremaining: 7.68s\n",
      "500:\tlearn: 1.5429911\ttotal: 7.69s\tremaining: 7.66s\n",
      "501:\tlearn: 1.5429876\ttotal: 7.71s\tremaining: 7.65s\n",
      "502:\tlearn: 1.5429808\ttotal: 7.72s\tremaining: 7.63s\n",
      "503:\tlearn: 1.5429685\ttotal: 7.74s\tremaining: 7.62s\n",
      "504:\tlearn: 1.5424994\ttotal: 7.75s\tremaining: 7.6s\n",
      "505:\tlearn: 1.5420812\ttotal: 7.77s\tremaining: 7.58s\n",
      "506:\tlearn: 1.5414663\ttotal: 7.78s\tremaining: 7.57s\n",
      "507:\tlearn: 1.5408453\ttotal: 7.8s\tremaining: 7.55s\n",
      "508:\tlearn: 1.5401167\ttotal: 7.81s\tremaining: 7.54s\n",
      "509:\tlearn: 1.5401129\ttotal: 7.83s\tremaining: 7.52s\n",
      "510:\tlearn: 1.5401110\ttotal: 7.84s\tremaining: 7.5s\n",
      "511:\tlearn: 1.5401036\ttotal: 7.85s\tremaining: 7.49s\n",
      "512:\tlearn: 1.5400730\ttotal: 7.87s\tremaining: 7.47s\n",
      "513:\tlearn: 1.5400725\ttotal: 7.88s\tremaining: 7.46s\n",
      "514:\tlearn: 1.5400723\ttotal: 7.9s\tremaining: 7.44s\n",
      "515:\tlearn: 1.5400721\ttotal: 7.91s\tremaining: 7.42s\n",
      "516:\tlearn: 1.5394398\ttotal: 7.93s\tremaining: 7.41s\n",
      "517:\tlearn: 1.5394245\ttotal: 7.95s\tremaining: 7.39s\n",
      "518:\tlearn: 1.5394212\ttotal: 7.96s\tremaining: 7.38s\n",
      "519:\tlearn: 1.5387925\ttotal: 7.97s\tremaining: 7.36s\n",
      "520:\tlearn: 1.5387584\ttotal: 7.99s\tremaining: 7.34s\n",
      "521:\tlearn: 1.5385251\ttotal: 8s\tremaining: 7.33s\n",
      "522:\tlearn: 1.5378081\ttotal: 8.02s\tremaining: 7.31s\n",
      "523:\tlearn: 1.5372623\ttotal: 8.03s\tremaining: 7.3s\n",
      "524:\tlearn: 1.5366433\ttotal: 8.05s\tremaining: 7.28s\n",
      "525:\tlearn: 1.5363805\ttotal: 8.06s\tremaining: 7.27s\n",
      "526:\tlearn: 1.5363792\ttotal: 8.08s\tremaining: 7.25s\n",
      "527:\tlearn: 1.5363791\ttotal: 8.09s\tremaining: 7.23s\n",
      "528:\tlearn: 1.5363791\ttotal: 8.11s\tremaining: 7.22s\n",
      "529:\tlearn: 1.5363748\ttotal: 8.12s\tremaining: 7.2s\n",
      "530:\tlearn: 1.5363747\ttotal: 8.13s\tremaining: 7.18s\n",
      "531:\tlearn: 1.5363747\ttotal: 8.15s\tremaining: 7.17s\n",
      "532:\tlearn: 1.5363744\ttotal: 8.16s\tremaining: 7.15s\n",
      "533:\tlearn: 1.5363742\ttotal: 8.18s\tremaining: 7.14s\n",
      "534:\tlearn: 1.5363647\ttotal: 8.2s\tremaining: 7.12s\n",
      "535:\tlearn: 1.5363644\ttotal: 8.21s\tremaining: 7.11s\n",
      "536:\tlearn: 1.5363643\ttotal: 8.22s\tremaining: 7.09s\n",
      "537:\tlearn: 1.5363640\ttotal: 8.24s\tremaining: 7.07s\n",
      "538:\tlearn: 1.5363640\ttotal: 8.25s\tremaining: 7.06s\n",
      "539:\tlearn: 1.5363601\ttotal: 8.27s\tremaining: 7.04s\n",
      "540:\tlearn: 1.5357572\ttotal: 8.28s\tremaining: 7.03s\n",
      "541:\tlearn: 1.5357571\ttotal: 8.3s\tremaining: 7.01s\n",
      "542:\tlearn: 1.5357571\ttotal: 8.31s\tremaining: 6.99s\n",
      "543:\tlearn: 1.5357571\ttotal: 8.32s\tremaining: 6.98s\n",
      "544:\tlearn: 1.5357570\ttotal: 8.34s\tremaining: 6.96s\n",
      "545:\tlearn: 1.5357494\ttotal: 8.35s\tremaining: 6.95s\n",
      "546:\tlearn: 1.5357493\ttotal: 8.37s\tremaining: 6.93s\n",
      "547:\tlearn: 1.5357465\ttotal: 8.38s\tremaining: 6.91s\n",
      "548:\tlearn: 1.5357442\ttotal: 8.4s\tremaining: 6.9s\n",
      "549:\tlearn: 1.5357429\ttotal: 8.41s\tremaining: 6.88s\n",
      "550:\tlearn: 1.5357388\ttotal: 8.43s\tremaining: 6.87s\n",
      "551:\tlearn: 1.5357388\ttotal: 8.44s\tremaining: 6.85s\n",
      "552:\tlearn: 1.5357386\ttotal: 8.46s\tremaining: 6.83s\n",
      "553:\tlearn: 1.5357191\ttotal: 8.47s\tremaining: 6.82s\n",
      "554:\tlearn: 1.5357162\ttotal: 8.48s\tremaining: 6.8s\n",
      "555:\tlearn: 1.5357081\ttotal: 8.5s\tremaining: 6.78s\n",
      "556:\tlearn: 1.5356971\ttotal: 8.51s\tremaining: 6.77s\n",
      "557:\tlearn: 1.5351905\ttotal: 8.53s\tremaining: 6.75s\n",
      "558:\tlearn: 1.5349994\ttotal: 8.54s\tremaining: 6.74s\n",
      "559:\tlearn: 1.5348443\ttotal: 8.55s\tremaining: 6.72s\n",
      "560:\tlearn: 1.5341384\ttotal: 8.57s\tremaining: 6.71s\n",
      "561:\tlearn: 1.5329122\ttotal: 8.58s\tremaining: 6.69s\n",
      "562:\tlearn: 1.5320938\ttotal: 8.6s\tremaining: 6.67s\n",
      "563:\tlearn: 1.5320237\ttotal: 8.61s\tremaining: 6.66s\n",
      "564:\tlearn: 1.5319948\ttotal: 8.63s\tremaining: 6.64s\n",
      "565:\tlearn: 1.5319656\ttotal: 8.64s\tremaining: 6.63s\n",
      "566:\tlearn: 1.5319636\ttotal: 8.65s\tremaining: 6.61s\n",
      "567:\tlearn: 1.5319449\ttotal: 8.67s\tremaining: 6.59s\n",
      "568:\tlearn: 1.5315814\ttotal: 8.68s\tremaining: 6.58s\n",
      "569:\tlearn: 1.5315063\ttotal: 8.7s\tremaining: 6.56s\n",
      "570:\tlearn: 1.5315062\ttotal: 8.71s\tremaining: 6.55s\n",
      "571:\tlearn: 1.5315061\ttotal: 8.73s\tremaining: 6.53s\n",
      "572:\tlearn: 1.5314830\ttotal: 8.74s\tremaining: 6.51s\n",
      "573:\tlearn: 1.5314625\ttotal: 8.76s\tremaining: 6.5s\n",
      "574:\tlearn: 1.5314350\ttotal: 8.77s\tremaining: 6.48s\n",
      "575:\tlearn: 1.5314094\ttotal: 8.79s\tremaining: 6.47s\n",
      "576:\tlearn: 1.5314092\ttotal: 8.8s\tremaining: 6.45s\n",
      "577:\tlearn: 1.5314084\ttotal: 8.82s\tremaining: 6.44s\n",
      "578:\tlearn: 1.5314039\ttotal: 8.83s\tremaining: 6.42s\n",
      "579:\tlearn: 1.5314038\ttotal: 8.85s\tremaining: 6.41s\n",
      "580:\tlearn: 1.5314035\ttotal: 8.86s\tremaining: 6.39s\n",
      "581:\tlearn: 1.5313974\ttotal: 8.88s\tremaining: 6.38s\n",
      "582:\tlearn: 1.5313947\ttotal: 8.89s\tremaining: 6.36s\n",
      "583:\tlearn: 1.5310009\ttotal: 8.91s\tremaining: 6.34s\n",
      "584:\tlearn: 1.5295867\ttotal: 8.92s\tremaining: 6.33s\n",
      "585:\tlearn: 1.5295364\ttotal: 8.94s\tremaining: 6.31s\n",
      "586:\tlearn: 1.5294870\ttotal: 8.95s\tremaining: 6.3s\n",
      "587:\tlearn: 1.5294839\ttotal: 8.97s\tremaining: 6.28s\n",
      "588:\tlearn: 1.5294833\ttotal: 8.98s\tremaining: 6.27s\n",
      "589:\tlearn: 1.5294833\ttotal: 9s\tremaining: 6.25s\n",
      "590:\tlearn: 1.5294830\ttotal: 9.01s\tremaining: 6.24s\n",
      "591:\tlearn: 1.5294828\ttotal: 9.03s\tremaining: 6.22s\n",
      "592:\tlearn: 1.5294827\ttotal: 9.04s\tremaining: 6.21s\n",
      "593:\tlearn: 1.5294763\ttotal: 9.06s\tremaining: 6.19s\n",
      "594:\tlearn: 1.5294763\ttotal: 9.07s\tremaining: 6.18s\n",
      "595:\tlearn: 1.5294762\ttotal: 9.09s\tremaining: 6.16s\n",
      "596:\tlearn: 1.5294760\ttotal: 9.1s\tremaining: 6.14s\n",
      "597:\tlearn: 1.5294760\ttotal: 9.12s\tremaining: 6.13s\n",
      "598:\tlearn: 1.5289923\ttotal: 9.13s\tremaining: 6.11s\n",
      "599:\tlearn: 1.5283432\ttotal: 9.15s\tremaining: 6.1s\n",
      "600:\tlearn: 1.5277612\ttotal: 9.16s\tremaining: 6.08s\n",
      "601:\tlearn: 1.5274303\ttotal: 9.18s\tremaining: 6.07s\n",
      "602:\tlearn: 1.5274134\ttotal: 9.2s\tremaining: 6.05s\n",
      "603:\tlearn: 1.5274134\ttotal: 9.21s\tremaining: 6.04s\n",
      "604:\tlearn: 1.5273980\ttotal: 9.22s\tremaining: 6.02s\n",
      "605:\tlearn: 1.5273853\ttotal: 9.24s\tremaining: 6.01s\n",
      "606:\tlearn: 1.5273594\ttotal: 9.25s\tremaining: 5.99s\n",
      "607:\tlearn: 1.5272742\ttotal: 9.27s\tremaining: 5.97s\n",
      "608:\tlearn: 1.5259527\ttotal: 9.28s\tremaining: 5.96s\n",
      "609:\tlearn: 1.5257654\ttotal: 9.29s\tremaining: 5.94s\n",
      "610:\tlearn: 1.5251962\ttotal: 9.31s\tremaining: 5.93s\n",
      "611:\tlearn: 1.5251958\ttotal: 9.32s\tremaining: 5.91s\n",
      "612:\tlearn: 1.5251958\ttotal: 9.34s\tremaining: 5.89s\n",
      "613:\tlearn: 1.5251957\ttotal: 9.35s\tremaining: 5.88s\n",
      "614:\tlearn: 1.5251956\ttotal: 9.37s\tremaining: 5.87s\n",
      "615:\tlearn: 1.5251955\ttotal: 9.38s\tremaining: 5.85s\n",
      "616:\tlearn: 1.5251954\ttotal: 9.4s\tremaining: 5.83s\n",
      "617:\tlearn: 1.5251705\ttotal: 9.41s\tremaining: 5.82s\n",
      "618:\tlearn: 1.5251206\ttotal: 9.43s\tremaining: 5.8s\n",
      "619:\tlearn: 1.5250940\ttotal: 9.44s\tremaining: 5.79s\n",
      "620:\tlearn: 1.5241937\ttotal: 9.45s\tremaining: 5.77s\n",
      "621:\tlearn: 1.5236388\ttotal: 9.47s\tremaining: 5.75s\n",
      "622:\tlearn: 1.5234787\ttotal: 9.48s\tremaining: 5.74s\n",
      "623:\tlearn: 1.5230967\ttotal: 9.5s\tremaining: 5.72s\n",
      "624:\tlearn: 1.5228696\ttotal: 9.51s\tremaining: 5.71s\n",
      "625:\tlearn: 1.5224319\ttotal: 9.53s\tremaining: 5.69s\n",
      "626:\tlearn: 1.5223158\ttotal: 9.54s\tremaining: 5.68s\n",
      "627:\tlearn: 1.5223157\ttotal: 9.56s\tremaining: 5.66s\n",
      "628:\tlearn: 1.5223157\ttotal: 9.57s\tremaining: 5.64s\n",
      "629:\tlearn: 1.5222846\ttotal: 9.58s\tremaining: 5.63s\n",
      "630:\tlearn: 1.5213164\ttotal: 9.6s\tremaining: 5.61s\n",
      "631:\tlearn: 1.5212722\ttotal: 9.61s\tremaining: 5.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632:\tlearn: 1.5205576\ttotal: 9.63s\tremaining: 5.58s\n",
      "633:\tlearn: 1.5202249\ttotal: 9.64s\tremaining: 5.57s\n",
      "634:\tlearn: 1.5202201\ttotal: 9.66s\tremaining: 5.55s\n",
      "635:\tlearn: 1.5202201\ttotal: 9.67s\tremaining: 5.54s\n",
      "636:\tlearn: 1.5202201\ttotal: 9.69s\tremaining: 5.52s\n",
      "637:\tlearn: 1.5202201\ttotal: 9.7s\tremaining: 5.5s\n",
      "638:\tlearn: 1.5202201\ttotal: 9.71s\tremaining: 5.49s\n",
      "639:\tlearn: 1.5202201\ttotal: 9.73s\tremaining: 5.47s\n",
      "640:\tlearn: 1.5202201\ttotal: 9.74s\tremaining: 5.46s\n",
      "641:\tlearn: 1.5202200\ttotal: 9.76s\tremaining: 5.44s\n",
      "642:\tlearn: 1.5202197\ttotal: 9.77s\tremaining: 5.43s\n",
      "643:\tlearn: 1.5202159\ttotal: 9.79s\tremaining: 5.41s\n",
      "644:\tlearn: 1.5202159\ttotal: 9.8s\tremaining: 5.39s\n",
      "645:\tlearn: 1.5202159\ttotal: 9.81s\tremaining: 5.38s\n",
      "646:\tlearn: 1.5201887\ttotal: 9.83s\tremaining: 5.36s\n",
      "647:\tlearn: 1.5201885\ttotal: 9.84s\tremaining: 5.35s\n",
      "648:\tlearn: 1.5201885\ttotal: 9.86s\tremaining: 5.33s\n",
      "649:\tlearn: 1.5201404\ttotal: 9.87s\tremaining: 5.32s\n",
      "650:\tlearn: 1.5191821\ttotal: 9.89s\tremaining: 5.3s\n",
      "651:\tlearn: 1.5186780\ttotal: 9.9s\tremaining: 5.28s\n",
      "652:\tlearn: 1.5185718\ttotal: 9.91s\tremaining: 5.27s\n",
      "653:\tlearn: 1.5185718\ttotal: 9.93s\tremaining: 5.25s\n",
      "654:\tlearn: 1.5185718\ttotal: 9.94s\tremaining: 5.24s\n",
      "655:\tlearn: 1.5185681\ttotal: 9.96s\tremaining: 5.22s\n",
      "656:\tlearn: 1.5185681\ttotal: 9.97s\tremaining: 5.21s\n",
      "657:\tlearn: 1.5185681\ttotal: 9.98s\tremaining: 5.19s\n",
      "658:\tlearn: 1.5185681\ttotal: 10s\tremaining: 5.17s\n",
      "659:\tlearn: 1.5185681\ttotal: 10s\tremaining: 5.16s\n",
      "660:\tlearn: 1.5185492\ttotal: 10s\tremaining: 5.14s\n",
      "661:\tlearn: 1.5184802\ttotal: 10s\tremaining: 5.13s\n",
      "662:\tlearn: 1.5166409\ttotal: 10.1s\tremaining: 5.11s\n",
      "663:\tlearn: 1.5166112\ttotal: 10.1s\tremaining: 5.1s\n",
      "664:\tlearn: 1.5166103\ttotal: 10.1s\tremaining: 5.08s\n",
      "665:\tlearn: 1.5166103\ttotal: 10.1s\tremaining: 5.07s\n",
      "666:\tlearn: 1.5166103\ttotal: 10.1s\tremaining: 5.05s\n",
      "667:\tlearn: 1.5166102\ttotal: 10.1s\tremaining: 5.04s\n",
      "668:\tlearn: 1.5166101\ttotal: 10.1s\tremaining: 5.02s\n",
      "669:\tlearn: 1.5166082\ttotal: 10.2s\tremaining: 5s\n",
      "670:\tlearn: 1.5166082\ttotal: 10.2s\tremaining: 4.99s\n",
      "671:\tlearn: 1.5166082\ttotal: 10.2s\tremaining: 4.97s\n",
      "672:\tlearn: 1.5161872\ttotal: 10.2s\tremaining: 4.96s\n",
      "673:\tlearn: 1.5160915\ttotal: 10.2s\tremaining: 4.94s\n",
      "674:\tlearn: 1.5157313\ttotal: 10.2s\tremaining: 4.93s\n",
      "675:\tlearn: 1.5156119\ttotal: 10.3s\tremaining: 4.91s\n",
      "676:\tlearn: 1.5155747\ttotal: 10.3s\tremaining: 4.9s\n",
      "677:\tlearn: 1.5155298\ttotal: 10.3s\tremaining: 4.88s\n",
      "678:\tlearn: 1.5155226\ttotal: 10.3s\tremaining: 4.87s\n",
      "679:\tlearn: 1.5154731\ttotal: 10.3s\tremaining: 4.85s\n",
      "680:\tlearn: 1.5150201\ttotal: 10.3s\tremaining: 4.84s\n",
      "681:\tlearn: 1.5148913\ttotal: 10.3s\tremaining: 4.82s\n",
      "682:\tlearn: 1.5148612\ttotal: 10.4s\tremaining: 4.8s\n",
      "683:\tlearn: 1.5142350\ttotal: 10.4s\tremaining: 4.79s\n",
      "684:\tlearn: 1.5142314\ttotal: 10.4s\tremaining: 4.77s\n",
      "685:\tlearn: 1.5142309\ttotal: 10.4s\tremaining: 4.76s\n",
      "686:\tlearn: 1.5140847\ttotal: 10.4s\tremaining: 4.74s\n",
      "687:\tlearn: 1.5139039\ttotal: 10.4s\tremaining: 4.73s\n",
      "688:\tlearn: 1.5136312\ttotal: 10.4s\tremaining: 4.71s\n",
      "689:\tlearn: 1.5131728\ttotal: 10.5s\tremaining: 4.7s\n",
      "690:\tlearn: 1.5131728\ttotal: 10.5s\tremaining: 4.68s\n",
      "691:\tlearn: 1.5131727\ttotal: 10.5s\tremaining: 4.67s\n",
      "692:\tlearn: 1.5131717\ttotal: 10.5s\tremaining: 4.65s\n",
      "693:\tlearn: 1.5131717\ttotal: 10.5s\tremaining: 4.63s\n",
      "694:\tlearn: 1.5130827\ttotal: 10.5s\tremaining: 4.62s\n",
      "695:\tlearn: 1.5129282\ttotal: 10.5s\tremaining: 4.6s\n",
      "696:\tlearn: 1.5129255\ttotal: 10.6s\tremaining: 4.59s\n",
      "697:\tlearn: 1.5128331\ttotal: 10.6s\tremaining: 4.57s\n",
      "698:\tlearn: 1.5125650\ttotal: 10.6s\tremaining: 4.56s\n",
      "699:\tlearn: 1.5124992\ttotal: 10.6s\tremaining: 4.54s\n",
      "700:\tlearn: 1.5124705\ttotal: 10.6s\tremaining: 4.53s\n",
      "701:\tlearn: 1.5124611\ttotal: 10.6s\tremaining: 4.51s\n",
      "702:\tlearn: 1.5124159\ttotal: 10.6s\tremaining: 4.5s\n",
      "703:\tlearn: 1.5124158\ttotal: 10.7s\tremaining: 4.48s\n",
      "704:\tlearn: 1.5124151\ttotal: 10.7s\tremaining: 4.47s\n",
      "705:\tlearn: 1.5124148\ttotal: 10.7s\tremaining: 4.45s\n",
      "706:\tlearn: 1.5124086\ttotal: 10.7s\tremaining: 4.44s\n",
      "707:\tlearn: 1.5118713\ttotal: 10.7s\tremaining: 4.42s\n",
      "708:\tlearn: 1.5117959\ttotal: 10.7s\tremaining: 4.41s\n",
      "709:\tlearn: 1.5113072\ttotal: 10.7s\tremaining: 4.39s\n",
      "710:\tlearn: 1.5111945\ttotal: 10.8s\tremaining: 4.38s\n",
      "711:\tlearn: 1.5111696\ttotal: 10.8s\tremaining: 4.36s\n",
      "712:\tlearn: 1.5111696\ttotal: 10.8s\tremaining: 4.34s\n",
      "713:\tlearn: 1.5111696\ttotal: 10.8s\tremaining: 4.33s\n",
      "714:\tlearn: 1.5111690\ttotal: 10.8s\tremaining: 4.31s\n",
      "715:\tlearn: 1.5111690\ttotal: 10.8s\tremaining: 4.3s\n",
      "716:\tlearn: 1.5111687\ttotal: 10.8s\tremaining: 4.28s\n",
      "717:\tlearn: 1.5111683\ttotal: 10.9s\tremaining: 4.27s\n",
      "718:\tlearn: 1.5111506\ttotal: 10.9s\tremaining: 4.25s\n",
      "719:\tlearn: 1.5108910\ttotal: 10.9s\tremaining: 4.24s\n",
      "720:\tlearn: 1.5108565\ttotal: 10.9s\tremaining: 4.22s\n",
      "721:\tlearn: 1.5099811\ttotal: 10.9s\tremaining: 4.21s\n",
      "722:\tlearn: 1.5099811\ttotal: 10.9s\tremaining: 4.19s\n",
      "723:\tlearn: 1.5099811\ttotal: 10.9s\tremaining: 4.17s\n",
      "724:\tlearn: 1.5099811\ttotal: 11s\tremaining: 4.16s\n",
      "725:\tlearn: 1.5099811\ttotal: 11s\tremaining: 4.14s\n",
      "726:\tlearn: 1.5099810\ttotal: 11s\tremaining: 4.13s\n",
      "727:\tlearn: 1.5099810\ttotal: 11s\tremaining: 4.11s\n",
      "728:\tlearn: 1.5099780\ttotal: 11s\tremaining: 4.1s\n",
      "729:\tlearn: 1.5099780\ttotal: 11s\tremaining: 4.08s\n",
      "730:\tlearn: 1.5099780\ttotal: 11s\tremaining: 4.07s\n",
      "731:\tlearn: 1.5099780\ttotal: 11.1s\tremaining: 4.05s\n",
      "732:\tlearn: 1.5099780\ttotal: 11.1s\tremaining: 4.03s\n",
      "733:\tlearn: 1.5099780\ttotal: 11.1s\tremaining: 4.02s\n",
      "734:\tlearn: 1.5099780\ttotal: 11.1s\tremaining: 4s\n",
      "735:\tlearn: 1.5099780\ttotal: 11.1s\tremaining: 3.99s\n",
      "736:\tlearn: 1.5099780\ttotal: 11.1s\tremaining: 3.97s\n",
      "737:\tlearn: 1.5099780\ttotal: 11.1s\tremaining: 3.96s\n",
      "738:\tlearn: 1.5088844\ttotal: 11.2s\tremaining: 3.94s\n",
      "739:\tlearn: 1.5083191\ttotal: 11.2s\tremaining: 3.93s\n",
      "740:\tlearn: 1.5082389\ttotal: 11.2s\tremaining: 3.91s\n",
      "741:\tlearn: 1.5071352\ttotal: 11.2s\tremaining: 3.9s\n",
      "742:\tlearn: 1.5070658\ttotal: 11.2s\tremaining: 3.88s\n",
      "743:\tlearn: 1.5069824\ttotal: 11.2s\tremaining: 3.86s\n",
      "744:\tlearn: 1.5069696\ttotal: 11.2s\tremaining: 3.85s\n",
      "745:\tlearn: 1.5069507\ttotal: 11.3s\tremaining: 3.83s\n",
      "746:\tlearn: 1.5069506\ttotal: 11.3s\tremaining: 3.82s\n",
      "747:\tlearn: 1.5069505\ttotal: 11.3s\tremaining: 3.8s\n",
      "748:\tlearn: 1.5068238\ttotal: 11.3s\tremaining: 3.79s\n",
      "749:\tlearn: 1.5068004\ttotal: 11.3s\tremaining: 3.77s\n",
      "750:\tlearn: 1.5066000\ttotal: 11.3s\tremaining: 3.76s\n",
      "751:\tlearn: 1.5063285\ttotal: 11.4s\tremaining: 3.74s\n",
      "752:\tlearn: 1.5063228\ttotal: 11.4s\tremaining: 3.73s\n",
      "753:\tlearn: 1.5063137\ttotal: 11.4s\tremaining: 3.71s\n",
      "754:\tlearn: 1.5062842\ttotal: 11.4s\tremaining: 3.7s\n",
      "755:\tlearn: 1.5062838\ttotal: 11.4s\tremaining: 3.68s\n",
      "756:\tlearn: 1.5062837\ttotal: 11.4s\tremaining: 3.67s\n",
      "757:\tlearn: 1.5062743\ttotal: 11.4s\tremaining: 3.65s\n",
      "758:\tlearn: 1.5062742\ttotal: 11.5s\tremaining: 3.64s\n",
      "759:\tlearn: 1.5062732\ttotal: 11.5s\tremaining: 3.62s\n",
      "760:\tlearn: 1.5062720\ttotal: 11.5s\tremaining: 3.61s\n",
      "761:\tlearn: 1.5062719\ttotal: 11.5s\tremaining: 3.59s\n",
      "762:\tlearn: 1.5062718\ttotal: 11.5s\tremaining: 3.58s\n",
      "763:\tlearn: 1.5062696\ttotal: 11.5s\tremaining: 3.56s\n",
      "764:\tlearn: 1.5062696\ttotal: 11.5s\tremaining: 3.54s\n",
      "765:\tlearn: 1.5062696\ttotal: 11.6s\tremaining: 3.53s\n",
      "766:\tlearn: 1.5062314\ttotal: 11.6s\tremaining: 3.51s\n",
      "767:\tlearn: 1.5055427\ttotal: 11.6s\tremaining: 3.5s\n",
      "768:\tlearn: 1.5055349\ttotal: 11.6s\tremaining: 3.48s\n",
      "769:\tlearn: 1.5055349\ttotal: 11.6s\tremaining: 3.47s\n",
      "770:\tlearn: 1.5055348\ttotal: 11.6s\tremaining: 3.45s\n",
      "771:\tlearn: 1.5055322\ttotal: 11.6s\tremaining: 3.44s\n",
      "772:\tlearn: 1.5055096\ttotal: 11.7s\tremaining: 3.42s\n",
      "773:\tlearn: 1.5052162\ttotal: 11.7s\tremaining: 3.41s\n",
      "774:\tlearn: 1.5048025\ttotal: 11.7s\tremaining: 3.39s\n",
      "775:\tlearn: 1.5047980\ttotal: 11.7s\tremaining: 3.38s\n",
      "776:\tlearn: 1.5039046\ttotal: 11.7s\tremaining: 3.36s\n",
      "777:\tlearn: 1.5039023\ttotal: 11.7s\tremaining: 3.35s\n",
      "778:\tlearn: 1.5039023\ttotal: 11.7s\tremaining: 3.33s\n",
      "779:\tlearn: 1.5039022\ttotal: 11.8s\tremaining: 3.32s\n",
      "780:\tlearn: 1.5039018\ttotal: 11.8s\tremaining: 3.3s\n",
      "781:\tlearn: 1.5039016\ttotal: 11.8s\tremaining: 3.29s\n",
      "782:\tlearn: 1.5038991\ttotal: 11.8s\tremaining: 3.27s\n",
      "783:\tlearn: 1.5038866\ttotal: 11.8s\tremaining: 3.26s\n",
      "784:\tlearn: 1.5038644\ttotal: 11.8s\tremaining: 3.24s\n",
      "785:\tlearn: 1.5038643\ttotal: 11.9s\tremaining: 3.23s\n",
      "786:\tlearn: 1.5038093\ttotal: 11.9s\tremaining: 3.21s\n",
      "787:\tlearn: 1.5037999\ttotal: 11.9s\tremaining: 3.2s\n",
      "788:\tlearn: 1.5037999\ttotal: 11.9s\tremaining: 3.18s\n",
      "789:\tlearn: 1.5037999\ttotal: 11.9s\tremaining: 3.17s\n",
      "790:\tlearn: 1.5037737\ttotal: 11.9s\tremaining: 3.15s\n",
      "791:\tlearn: 1.5028499\ttotal: 11.9s\tremaining: 3.14s\n",
      "792:\tlearn: 1.5027831\ttotal: 12s\tremaining: 3.12s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793:\tlearn: 1.5022912\ttotal: 12s\tremaining: 3.1s\n",
      "794:\tlearn: 1.5020212\ttotal: 12s\tremaining: 3.09s\n",
      "795:\tlearn: 1.5019888\ttotal: 12s\tremaining: 3.08s\n",
      "796:\tlearn: 1.5019808\ttotal: 12s\tremaining: 3.06s\n",
      "797:\tlearn: 1.5019782\ttotal: 12s\tremaining: 3.04s\n",
      "798:\tlearn: 1.5019763\ttotal: 12s\tremaining: 3.03s\n",
      "799:\tlearn: 1.5019762\ttotal: 12.1s\tremaining: 3.01s\n",
      "800:\tlearn: 1.5019760\ttotal: 12.1s\tremaining: 3s\n",
      "801:\tlearn: 1.5019441\ttotal: 12.1s\tremaining: 2.98s\n",
      "802:\tlearn: 1.5019268\ttotal: 12.1s\tremaining: 2.97s\n",
      "803:\tlearn: 1.5019063\ttotal: 12.1s\tremaining: 2.95s\n",
      "804:\tlearn: 1.5019040\ttotal: 12.1s\tremaining: 2.94s\n",
      "805:\tlearn: 1.5019017\ttotal: 12.1s\tremaining: 2.92s\n",
      "806:\tlearn: 1.5019017\ttotal: 12.2s\tremaining: 2.91s\n",
      "807:\tlearn: 1.5019017\ttotal: 12.2s\tremaining: 2.89s\n",
      "808:\tlearn: 1.5019017\ttotal: 12.2s\tremaining: 2.88s\n",
      "809:\tlearn: 1.5019017\ttotal: 12.2s\tremaining: 2.86s\n",
      "810:\tlearn: 1.5019017\ttotal: 12.2s\tremaining: 2.85s\n",
      "811:\tlearn: 1.5019016\ttotal: 12.2s\tremaining: 2.83s\n",
      "812:\tlearn: 1.5018846\ttotal: 12.3s\tremaining: 2.82s\n",
      "813:\tlearn: 1.5018759\ttotal: 12.3s\tremaining: 2.8s\n",
      "814:\tlearn: 1.5018721\ttotal: 12.3s\tremaining: 2.79s\n",
      "815:\tlearn: 1.5018581\ttotal: 12.3s\tremaining: 2.77s\n",
      "816:\tlearn: 1.5012763\ttotal: 12.3s\tremaining: 2.76s\n",
      "817:\tlearn: 1.5008195\ttotal: 12.3s\tremaining: 2.74s\n",
      "818:\tlearn: 1.5007431\ttotal: 12.3s\tremaining: 2.73s\n",
      "819:\tlearn: 1.4997973\ttotal: 12.4s\tremaining: 2.71s\n",
      "820:\tlearn: 1.4997843\ttotal: 12.4s\tremaining: 2.7s\n",
      "821:\tlearn: 1.4997838\ttotal: 12.4s\tremaining: 2.68s\n",
      "822:\tlearn: 1.4997631\ttotal: 12.4s\tremaining: 2.67s\n",
      "823:\tlearn: 1.4997520\ttotal: 12.4s\tremaining: 2.65s\n",
      "824:\tlearn: 1.4997520\ttotal: 12.4s\tremaining: 2.64s\n",
      "825:\tlearn: 1.4997519\ttotal: 12.4s\tremaining: 2.62s\n",
      "826:\tlearn: 1.4997121\ttotal: 12.5s\tremaining: 2.61s\n",
      "827:\tlearn: 1.4995328\ttotal: 12.5s\tremaining: 2.59s\n",
      "828:\tlearn: 1.4994745\ttotal: 12.5s\tremaining: 2.58s\n",
      "829:\tlearn: 1.4994304\ttotal: 12.5s\tremaining: 2.56s\n",
      "830:\tlearn: 1.4994303\ttotal: 12.5s\tremaining: 2.54s\n",
      "831:\tlearn: 1.4993903\ttotal: 12.5s\tremaining: 2.53s\n",
      "832:\tlearn: 1.4993744\ttotal: 12.5s\tremaining: 2.52s\n",
      "833:\tlearn: 1.4988933\ttotal: 12.6s\tremaining: 2.5s\n",
      "834:\tlearn: 1.4988929\ttotal: 12.6s\tremaining: 2.48s\n",
      "835:\tlearn: 1.4985129\ttotal: 12.6s\tremaining: 2.47s\n",
      "836:\tlearn: 1.4984195\ttotal: 12.6s\tremaining: 2.45s\n",
      "837:\tlearn: 1.4983495\ttotal: 12.6s\tremaining: 2.44s\n",
      "838:\tlearn: 1.4983361\ttotal: 12.6s\tremaining: 2.42s\n",
      "839:\tlearn: 1.4983342\ttotal: 12.6s\tremaining: 2.41s\n",
      "840:\tlearn: 1.4983342\ttotal: 12.7s\tremaining: 2.39s\n",
      "841:\tlearn: 1.4983342\ttotal: 12.7s\tremaining: 2.38s\n",
      "842:\tlearn: 1.4983243\ttotal: 12.7s\tremaining: 2.36s\n",
      "843:\tlearn: 1.4983242\ttotal: 12.7s\tremaining: 2.35s\n",
      "844:\tlearn: 1.4983160\ttotal: 12.7s\tremaining: 2.33s\n",
      "845:\tlearn: 1.4982885\ttotal: 12.7s\tremaining: 2.32s\n",
      "846:\tlearn: 1.4982605\ttotal: 12.7s\tremaining: 2.3s\n",
      "847:\tlearn: 1.4973609\ttotal: 12.8s\tremaining: 2.29s\n",
      "848:\tlearn: 1.4973018\ttotal: 12.8s\tremaining: 2.27s\n",
      "849:\tlearn: 1.4972935\ttotal: 12.8s\tremaining: 2.26s\n",
      "850:\tlearn: 1.4972935\ttotal: 12.8s\tremaining: 2.24s\n",
      "851:\tlearn: 1.4972929\ttotal: 12.8s\tremaining: 2.23s\n",
      "852:\tlearn: 1.4972928\ttotal: 12.8s\tremaining: 2.21s\n",
      "853:\tlearn: 1.4972909\ttotal: 12.8s\tremaining: 2.2s\n",
      "854:\tlearn: 1.4972909\ttotal: 12.9s\tremaining: 2.18s\n",
      "855:\tlearn: 1.4972908\ttotal: 12.9s\tremaining: 2.17s\n",
      "856:\tlearn: 1.4972907\ttotal: 12.9s\tremaining: 2.15s\n",
      "857:\tlearn: 1.4972906\ttotal: 12.9s\tremaining: 2.13s\n",
      "858:\tlearn: 1.4972906\ttotal: 12.9s\tremaining: 2.12s\n",
      "859:\tlearn: 1.4972906\ttotal: 12.9s\tremaining: 2.1s\n",
      "860:\tlearn: 1.4972905\ttotal: 12.9s\tremaining: 2.09s\n",
      "861:\tlearn: 1.4972905\ttotal: 13s\tremaining: 2.08s\n",
      "862:\tlearn: 1.4972752\ttotal: 13s\tremaining: 2.06s\n",
      "863:\tlearn: 1.4968775\ttotal: 13s\tremaining: 2.05s\n",
      "864:\tlearn: 1.4960898\ttotal: 13s\tremaining: 2.03s\n",
      "865:\tlearn: 1.4960347\ttotal: 13s\tremaining: 2.02s\n",
      "866:\tlearn: 1.4959551\ttotal: 13s\tremaining: 2s\n",
      "867:\tlearn: 1.4954676\ttotal: 13.1s\tremaining: 1.99s\n",
      "868:\tlearn: 1.4954668\ttotal: 13.1s\tremaining: 1.97s\n",
      "869:\tlearn: 1.4954664\ttotal: 13.1s\tremaining: 1.96s\n",
      "870:\tlearn: 1.4954426\ttotal: 13.1s\tremaining: 1.94s\n",
      "871:\tlearn: 1.4950414\ttotal: 13.1s\tremaining: 1.93s\n",
      "872:\tlearn: 1.4946248\ttotal: 13.1s\tremaining: 1.91s\n",
      "873:\tlearn: 1.4941983\ttotal: 13.1s\tremaining: 1.9s\n",
      "874:\tlearn: 1.4934778\ttotal: 13.2s\tremaining: 1.88s\n",
      "875:\tlearn: 1.4933435\ttotal: 13.2s\tremaining: 1.86s\n",
      "876:\tlearn: 1.4933435\ttotal: 13.2s\tremaining: 1.85s\n",
      "877:\tlearn: 1.4933435\ttotal: 13.2s\tremaining: 1.83s\n",
      "878:\tlearn: 1.4933434\ttotal: 13.2s\tremaining: 1.82s\n",
      "879:\tlearn: 1.4933428\ttotal: 13.2s\tremaining: 1.8s\n",
      "880:\tlearn: 1.4933428\ttotal: 13.2s\tremaining: 1.79s\n",
      "881:\tlearn: 1.4933386\ttotal: 13.3s\tremaining: 1.77s\n",
      "882:\tlearn: 1.4931682\ttotal: 13.3s\tremaining: 1.76s\n",
      "883:\tlearn: 1.4928696\ttotal: 13.3s\tremaining: 1.74s\n",
      "884:\tlearn: 1.4928496\ttotal: 13.3s\tremaining: 1.73s\n",
      "885:\tlearn: 1.4927052\ttotal: 13.3s\tremaining: 1.71s\n",
      "886:\tlearn: 1.4926600\ttotal: 13.3s\tremaining: 1.7s\n",
      "887:\tlearn: 1.4925042\ttotal: 13.3s\tremaining: 1.68s\n",
      "888:\tlearn: 1.4924890\ttotal: 13.4s\tremaining: 1.67s\n",
      "889:\tlearn: 1.4924746\ttotal: 13.4s\tremaining: 1.65s\n",
      "890:\tlearn: 1.4924627\ttotal: 13.4s\tremaining: 1.64s\n",
      "891:\tlearn: 1.4917518\ttotal: 13.4s\tremaining: 1.62s\n",
      "892:\tlearn: 1.4917272\ttotal: 13.4s\tremaining: 1.61s\n",
      "893:\tlearn: 1.4917271\ttotal: 13.4s\tremaining: 1.59s\n",
      "894:\tlearn: 1.4916967\ttotal: 13.4s\tremaining: 1.58s\n",
      "895:\tlearn: 1.4907102\ttotal: 13.5s\tremaining: 1.56s\n",
      "896:\tlearn: 1.4906270\ttotal: 13.5s\tremaining: 1.55s\n",
      "897:\tlearn: 1.4905491\ttotal: 13.5s\tremaining: 1.53s\n",
      "898:\tlearn: 1.4901771\ttotal: 13.5s\tremaining: 1.52s\n",
      "899:\tlearn: 1.4900683\ttotal: 13.5s\tremaining: 1.5s\n",
      "900:\tlearn: 1.4895031\ttotal: 13.5s\tremaining: 1.49s\n",
      "901:\tlearn: 1.4893575\ttotal: 13.6s\tremaining: 1.47s\n",
      "902:\tlearn: 1.4892816\ttotal: 13.6s\tremaining: 1.46s\n",
      "903:\tlearn: 1.4880887\ttotal: 13.6s\tremaining: 1.44s\n",
      "904:\tlearn: 1.4880878\ttotal: 13.6s\tremaining: 1.43s\n",
      "905:\tlearn: 1.4880550\ttotal: 13.6s\tremaining: 1.41s\n",
      "906:\tlearn: 1.4877048\ttotal: 13.6s\tremaining: 1.4s\n",
      "907:\tlearn: 1.4870677\ttotal: 13.7s\tremaining: 1.38s\n",
      "908:\tlearn: 1.4870573\ttotal: 13.7s\tremaining: 1.37s\n",
      "909:\tlearn: 1.4870572\ttotal: 13.7s\tremaining: 1.35s\n",
      "910:\tlearn: 1.4870186\ttotal: 13.7s\tremaining: 1.34s\n",
      "911:\tlearn: 1.4870138\ttotal: 13.7s\tremaining: 1.32s\n",
      "912:\tlearn: 1.4869704\ttotal: 13.7s\tremaining: 1.31s\n",
      "913:\tlearn: 1.4869085\ttotal: 13.7s\tremaining: 1.29s\n",
      "914:\tlearn: 1.4865395\ttotal: 13.8s\tremaining: 1.28s\n",
      "915:\tlearn: 1.4865240\ttotal: 13.8s\tremaining: 1.26s\n",
      "916:\tlearn: 1.4861200\ttotal: 13.8s\tremaining: 1.25s\n",
      "917:\tlearn: 1.4857432\ttotal: 13.8s\tremaining: 1.23s\n",
      "918:\tlearn: 1.4851467\ttotal: 13.8s\tremaining: 1.22s\n",
      "919:\tlearn: 1.4851021\ttotal: 13.8s\tremaining: 1.2s\n",
      "920:\tlearn: 1.4847504\ttotal: 13.8s\tremaining: 1.19s\n",
      "921:\tlearn: 1.4846541\ttotal: 13.9s\tremaining: 1.17s\n",
      "922:\tlearn: 1.4838874\ttotal: 13.9s\tremaining: 1.16s\n",
      "923:\tlearn: 1.4833080\ttotal: 13.9s\tremaining: 1.14s\n",
      "924:\tlearn: 1.4830148\ttotal: 13.9s\tremaining: 1.13s\n",
      "925:\tlearn: 1.4827041\ttotal: 13.9s\tremaining: 1.11s\n",
      "926:\tlearn: 1.4823896\ttotal: 13.9s\tremaining: 1.1s\n",
      "927:\tlearn: 1.4818184\ttotal: 13.9s\tremaining: 1.08s\n",
      "928:\tlearn: 1.4815443\ttotal: 14s\tremaining: 1.07s\n",
      "929:\tlearn: 1.4815235\ttotal: 14s\tremaining: 1.05s\n",
      "930:\tlearn: 1.4812847\ttotal: 14s\tremaining: 1.04s\n",
      "931:\tlearn: 1.4812846\ttotal: 14s\tremaining: 1.02s\n",
      "932:\tlearn: 1.4812846\ttotal: 14s\tremaining: 1.01s\n",
      "933:\tlearn: 1.4812846\ttotal: 14s\tremaining: 991ms\n",
      "934:\tlearn: 1.4812839\ttotal: 14s\tremaining: 976ms\n",
      "935:\tlearn: 1.4812838\ttotal: 14.1s\tremaining: 961ms\n",
      "936:\tlearn: 1.4812838\ttotal: 14.1s\tremaining: 946ms\n",
      "937:\tlearn: 1.4812838\ttotal: 14.1s\tremaining: 931ms\n",
      "938:\tlearn: 1.4812838\ttotal: 14.1s\tremaining: 916ms\n",
      "939:\tlearn: 1.4812816\ttotal: 14.1s\tremaining: 901ms\n",
      "940:\tlearn: 1.4811673\ttotal: 14.1s\tremaining: 886ms\n",
      "941:\tlearn: 1.4811355\ttotal: 14.1s\tremaining: 871ms\n",
      "942:\tlearn: 1.4811283\ttotal: 14.2s\tremaining: 856ms\n",
      "943:\tlearn: 1.4811246\ttotal: 14.2s\tremaining: 841ms\n",
      "944:\tlearn: 1.4811154\ttotal: 14.2s\tremaining: 826ms\n",
      "945:\tlearn: 1.4811147\ttotal: 14.2s\tremaining: 811ms\n",
      "946:\tlearn: 1.4810736\ttotal: 14.2s\tremaining: 796ms\n",
      "947:\tlearn: 1.4808076\ttotal: 14.2s\tremaining: 781ms\n",
      "948:\tlearn: 1.4807571\ttotal: 14.2s\tremaining: 766ms\n",
      "949:\tlearn: 1.4805109\ttotal: 14.3s\tremaining: 751ms\n",
      "950:\tlearn: 1.4804920\ttotal: 14.3s\tremaining: 736ms\n",
      "951:\tlearn: 1.4802712\ttotal: 14.3s\tremaining: 721ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952:\tlearn: 1.4802358\ttotal: 14.3s\tremaining: 706ms\n",
      "953:\tlearn: 1.4802330\ttotal: 14.3s\tremaining: 691ms\n",
      "954:\tlearn: 1.4801965\ttotal: 14.3s\tremaining: 676ms\n",
      "955:\tlearn: 1.4800870\ttotal: 14.4s\tremaining: 661ms\n",
      "956:\tlearn: 1.4800200\ttotal: 14.4s\tremaining: 645ms\n",
      "957:\tlearn: 1.4800188\ttotal: 14.4s\tremaining: 630ms\n",
      "958:\tlearn: 1.4798095\ttotal: 14.4s\tremaining: 615ms\n",
      "959:\tlearn: 1.4798095\ttotal: 14.4s\tremaining: 600ms\n",
      "960:\tlearn: 1.4798091\ttotal: 14.4s\tremaining: 585ms\n",
      "961:\tlearn: 1.4797032\ttotal: 14.4s\tremaining: 570ms\n",
      "962:\tlearn: 1.4796236\ttotal: 14.4s\tremaining: 555ms\n",
      "963:\tlearn: 1.4796061\ttotal: 14.5s\tremaining: 540ms\n",
      "964:\tlearn: 1.4796032\ttotal: 14.5s\tremaining: 525ms\n",
      "965:\tlearn: 1.4791307\ttotal: 14.5s\tremaining: 510ms\n",
      "966:\tlearn: 1.4781691\ttotal: 14.5s\tremaining: 495ms\n",
      "967:\tlearn: 1.4781448\ttotal: 14.5s\tremaining: 480ms\n",
      "968:\tlearn: 1.4780484\ttotal: 14.5s\tremaining: 465ms\n",
      "969:\tlearn: 1.4780445\ttotal: 14.6s\tremaining: 450ms\n",
      "970:\tlearn: 1.4780219\ttotal: 14.6s\tremaining: 435ms\n",
      "971:\tlearn: 1.4778873\ttotal: 14.6s\tremaining: 420ms\n",
      "972:\tlearn: 1.4778768\ttotal: 14.6s\tremaining: 405ms\n",
      "973:\tlearn: 1.4777993\ttotal: 14.6s\tremaining: 390ms\n",
      "974:\tlearn: 1.4777990\ttotal: 14.6s\tremaining: 375ms\n",
      "975:\tlearn: 1.4774150\ttotal: 14.6s\tremaining: 360ms\n",
      "976:\tlearn: 1.4774091\ttotal: 14.7s\tremaining: 345ms\n",
      "977:\tlearn: 1.4773973\ttotal: 14.7s\tremaining: 330ms\n",
      "978:\tlearn: 1.4771906\ttotal: 14.7s\tremaining: 315ms\n",
      "979:\tlearn: 1.4771872\ttotal: 14.7s\tremaining: 300ms\n",
      "980:\tlearn: 1.4770337\ttotal: 14.7s\tremaining: 285ms\n",
      "981:\tlearn: 1.4770336\ttotal: 14.7s\tremaining: 270ms\n",
      "982:\tlearn: 1.4770304\ttotal: 14.7s\tremaining: 255ms\n",
      "983:\tlearn: 1.4770302\ttotal: 14.8s\tremaining: 240ms\n",
      "984:\tlearn: 1.4770302\ttotal: 14.8s\tremaining: 225ms\n",
      "985:\tlearn: 1.4770216\ttotal: 14.8s\tremaining: 210ms\n",
      "986:\tlearn: 1.4770214\ttotal: 14.8s\tremaining: 195ms\n",
      "987:\tlearn: 1.4769946\ttotal: 14.8s\tremaining: 180ms\n",
      "988:\tlearn: 1.4769938\ttotal: 14.8s\tremaining: 165ms\n",
      "989:\tlearn: 1.4768920\ttotal: 14.8s\tremaining: 150ms\n",
      "990:\tlearn: 1.4768919\ttotal: 14.8s\tremaining: 135ms\n",
      "991:\tlearn: 1.4768907\ttotal: 14.9s\tremaining: 120ms\n",
      "992:\tlearn: 1.4768066\ttotal: 14.9s\tremaining: 105ms\n",
      "993:\tlearn: 1.4761112\ttotal: 14.9s\tremaining: 89.9ms\n",
      "994:\tlearn: 1.4754762\ttotal: 14.9s\tremaining: 74.9ms\n",
      "995:\tlearn: 1.4754315\ttotal: 14.9s\tremaining: 59.9ms\n",
      "996:\tlearn: 1.4750733\ttotal: 14.9s\tremaining: 44.9ms\n",
      "997:\tlearn: 1.4748903\ttotal: 15s\tremaining: 30ms\n",
      "998:\tlearn: 1.4746443\ttotal: 15s\tremaining: 15ms\n",
      "999:\tlearn: 1.4746353\ttotal: 15s\tremaining: 0us\n",
      "0:\tlearn: 9.6049396\ttotal: 17.1ms\tremaining: 17.1s\n",
      "1:\tlearn: 8.9116760\ttotal: 35.2ms\tremaining: 17.6s\n",
      "2:\tlearn: 8.2376176\ttotal: 53.9ms\tremaining: 17.9s\n",
      "3:\tlearn: 7.6454094\ttotal: 72.2ms\tremaining: 18s\n",
      "4:\tlearn: 7.0283600\ttotal: 90.3ms\tremaining: 18s\n",
      "5:\tlearn: 6.5677190\ttotal: 108ms\tremaining: 17.9s\n",
      "6:\tlearn: 6.0512962\ttotal: 126ms\tremaining: 17.8s\n",
      "7:\tlearn: 5.6969473\ttotal: 143ms\tremaining: 17.8s\n",
      "8:\tlearn: 5.2491109\ttotal: 161ms\tremaining: 17.7s\n",
      "9:\tlearn: 4.8620231\ttotal: 179ms\tremaining: 17.7s\n",
      "10:\tlearn: 4.5486492\ttotal: 197ms\tremaining: 17.7s\n",
      "11:\tlearn: 4.3428171\ttotal: 214ms\tremaining: 17.6s\n",
      "12:\tlearn: 4.0683896\ttotal: 231ms\tremaining: 17.5s\n",
      "13:\tlearn: 3.8349811\ttotal: 248ms\tremaining: 17.5s\n",
      "14:\tlearn: 3.6284363\ttotal: 266ms\tremaining: 17.5s\n",
      "15:\tlearn: 3.4457690\ttotal: 284ms\tremaining: 17.4s\n",
      "16:\tlearn: 3.3525010\ttotal: 301ms\tremaining: 17.4s\n",
      "17:\tlearn: 3.2136442\ttotal: 319ms\tremaining: 17.4s\n",
      "18:\tlearn: 3.0920471\ttotal: 336ms\tremaining: 17.3s\n",
      "19:\tlearn: 2.9724254\ttotal: 353ms\tremaining: 17.3s\n",
      "20:\tlearn: 2.9146224\ttotal: 368ms\tremaining: 17.2s\n",
      "21:\tlearn: 2.8642378\ttotal: 384ms\tremaining: 17.1s\n",
      "22:\tlearn: 2.8225494\ttotal: 399ms\tremaining: 16.9s\n",
      "23:\tlearn: 2.7663312\ttotal: 414ms\tremaining: 16.8s\n",
      "24:\tlearn: 2.7057133\ttotal: 429ms\tremaining: 16.7s\n",
      "25:\tlearn: 2.6805568\ttotal: 444ms\tremaining: 16.6s\n",
      "26:\tlearn: 2.6574582\ttotal: 458ms\tremaining: 16.5s\n",
      "27:\tlearn: 2.6124078\ttotal: 473ms\tremaining: 16.4s\n",
      "28:\tlearn: 2.5919888\ttotal: 489ms\tremaining: 16.4s\n",
      "29:\tlearn: 2.5478758\ttotal: 504ms\tremaining: 16.3s\n",
      "30:\tlearn: 2.5237616\ttotal: 520ms\tremaining: 16.2s\n",
      "31:\tlearn: 2.5088120\ttotal: 534ms\tremaining: 16.2s\n",
      "32:\tlearn: 2.4824120\ttotal: 549ms\tremaining: 16.1s\n",
      "33:\tlearn: 2.4487691\ttotal: 564ms\tremaining: 16s\n",
      "34:\tlearn: 2.4364287\ttotal: 580ms\tremaining: 16s\n",
      "35:\tlearn: 2.4268359\ttotal: 594ms\tremaining: 15.9s\n",
      "36:\tlearn: 2.4018124\ttotal: 609ms\tremaining: 15.9s\n",
      "37:\tlearn: 2.3844473\ttotal: 624ms\tremaining: 15.8s\n",
      "38:\tlearn: 2.3604134\ttotal: 640ms\tremaining: 15.8s\n",
      "39:\tlearn: 2.3554887\ttotal: 655ms\tremaining: 15.7s\n",
      "40:\tlearn: 2.3478867\ttotal: 670ms\tremaining: 15.7s\n",
      "41:\tlearn: 2.3444673\ttotal: 685ms\tremaining: 15.6s\n",
      "42:\tlearn: 2.3389402\ttotal: 700ms\tremaining: 15.6s\n",
      "43:\tlearn: 2.3371329\ttotal: 715ms\tremaining: 15.5s\n",
      "44:\tlearn: 2.3355670\ttotal: 730ms\tremaining: 15.5s\n",
      "45:\tlearn: 2.3336859\ttotal: 745ms\tremaining: 15.5s\n",
      "46:\tlearn: 2.3184872\ttotal: 761ms\tremaining: 15.4s\n",
      "47:\tlearn: 2.3139723\ttotal: 775ms\tremaining: 15.4s\n",
      "48:\tlearn: 2.3097543\ttotal: 790ms\tremaining: 15.3s\n",
      "49:\tlearn: 2.3077576\ttotal: 805ms\tremaining: 15.3s\n",
      "50:\tlearn: 2.3068511\ttotal: 820ms\tremaining: 15.3s\n",
      "51:\tlearn: 2.3038821\ttotal: 835ms\tremaining: 15.2s\n",
      "52:\tlearn: 2.3023571\ttotal: 850ms\tremaining: 15.2s\n",
      "53:\tlearn: 2.2999125\ttotal: 865ms\tremaining: 15.2s\n",
      "54:\tlearn: 2.2986210\ttotal: 880ms\tremaining: 15.1s\n",
      "55:\tlearn: 2.2864308\ttotal: 897ms\tremaining: 15.1s\n",
      "56:\tlearn: 2.2827103\ttotal: 912ms\tremaining: 15.1s\n",
      "57:\tlearn: 2.2820972\ttotal: 928ms\tremaining: 15.1s\n",
      "58:\tlearn: 2.2819695\ttotal: 942ms\tremaining: 15s\n",
      "59:\tlearn: 2.2813955\ttotal: 957ms\tremaining: 15s\n",
      "60:\tlearn: 2.2812602\ttotal: 972ms\tremaining: 15s\n",
      "61:\tlearn: 2.2807935\ttotal: 988ms\tremaining: 14.9s\n",
      "62:\tlearn: 2.2701476\ttotal: 1s\tremaining: 14.9s\n",
      "63:\tlearn: 2.2679000\ttotal: 1.02s\tremaining: 14.9s\n",
      "64:\tlearn: 2.2673523\ttotal: 1.03s\tremaining: 14.8s\n",
      "65:\tlearn: 2.2654044\ttotal: 1.04s\tremaining: 14.8s\n",
      "66:\tlearn: 2.2648472\ttotal: 1.06s\tremaining: 14.8s\n",
      "67:\tlearn: 2.2593992\ttotal: 1.07s\tremaining: 14.7s\n",
      "68:\tlearn: 2.2518622\ttotal: 1.09s\tremaining: 14.7s\n",
      "69:\tlearn: 2.2506867\ttotal: 1.1s\tremaining: 14.7s\n",
      "70:\tlearn: 2.2504264\ttotal: 1.12s\tremaining: 14.7s\n",
      "71:\tlearn: 2.2502052\ttotal: 1.13s\tremaining: 14.6s\n",
      "72:\tlearn: 2.2497791\ttotal: 1.15s\tremaining: 14.6s\n",
      "73:\tlearn: 2.2495807\ttotal: 1.16s\tremaining: 14.6s\n",
      "74:\tlearn: 2.2491108\ttotal: 1.18s\tremaining: 14.5s\n",
      "75:\tlearn: 2.2476759\ttotal: 1.19s\tremaining: 14.5s\n",
      "76:\tlearn: 2.2461550\ttotal: 1.21s\tremaining: 14.5s\n",
      "77:\tlearn: 2.2459961\ttotal: 1.22s\tremaining: 14.5s\n",
      "78:\tlearn: 2.2449357\ttotal: 1.24s\tremaining: 14.4s\n",
      "79:\tlearn: 2.2448112\ttotal: 1.25s\tremaining: 14.4s\n",
      "80:\tlearn: 2.2431860\ttotal: 1.27s\tremaining: 14.4s\n",
      "81:\tlearn: 2.2348982\ttotal: 1.28s\tremaining: 14.4s\n",
      "82:\tlearn: 2.2343212\ttotal: 1.3s\tremaining: 14.3s\n",
      "83:\tlearn: 2.2340269\ttotal: 1.31s\tremaining: 14.3s\n",
      "84:\tlearn: 2.2282926\ttotal: 1.33s\tremaining: 14.3s\n",
      "85:\tlearn: 2.2280050\ttotal: 1.34s\tremaining: 14.3s\n",
      "86:\tlearn: 2.2274732\ttotal: 1.36s\tremaining: 14.3s\n",
      "87:\tlearn: 2.2263613\ttotal: 1.38s\tremaining: 14.3s\n",
      "88:\tlearn: 2.2260777\ttotal: 1.39s\tremaining: 14.2s\n",
      "89:\tlearn: 2.2244637\ttotal: 1.41s\tremaining: 14.2s\n",
      "90:\tlearn: 2.2242780\ttotal: 1.42s\tremaining: 14.2s\n",
      "91:\tlearn: 2.2235494\ttotal: 1.44s\tremaining: 14.2s\n",
      "92:\tlearn: 2.2235459\ttotal: 1.45s\tremaining: 14.1s\n",
      "93:\tlearn: 2.2227520\ttotal: 1.46s\tremaining: 14.1s\n",
      "94:\tlearn: 2.2217401\ttotal: 1.48s\tremaining: 14.1s\n",
      "95:\tlearn: 2.2217316\ttotal: 1.49s\tremaining: 14s\n",
      "96:\tlearn: 2.2210667\ttotal: 1.5s\tremaining: 14s\n",
      "97:\tlearn: 2.2204366\ttotal: 1.52s\tremaining: 14s\n",
      "98:\tlearn: 2.2197398\ttotal: 1.53s\tremaining: 14s\n",
      "99:\tlearn: 2.2196209\ttotal: 1.55s\tremaining: 13.9s\n",
      "100:\tlearn: 2.2194746\ttotal: 1.56s\tremaining: 13.9s\n",
      "101:\tlearn: 2.2130109\ttotal: 1.58s\tremaining: 13.9s\n",
      "102:\tlearn: 2.2097834\ttotal: 1.59s\tremaining: 13.9s\n",
      "103:\tlearn: 2.2037826\ttotal: 1.61s\tremaining: 13.8s\n",
      "104:\tlearn: 2.2029397\ttotal: 1.62s\tremaining: 13.8s\n",
      "105:\tlearn: 2.2022152\ttotal: 1.64s\tremaining: 13.8s\n",
      "106:\tlearn: 2.2018472\ttotal: 1.65s\tremaining: 13.8s\n",
      "107:\tlearn: 2.2009874\ttotal: 1.67s\tremaining: 13.8s\n",
      "108:\tlearn: 2.2000644\ttotal: 1.68s\tremaining: 13.7s\n",
      "109:\tlearn: 2.1998986\ttotal: 1.7s\tremaining: 13.7s\n",
      "110:\tlearn: 2.1991565\ttotal: 1.71s\tremaining: 13.7s\n",
      "111:\tlearn: 2.1987893\ttotal: 1.73s\tremaining: 13.7s\n",
      "112:\tlearn: 2.1980590\ttotal: 1.74s\tremaining: 13.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113:\tlearn: 2.1978090\ttotal: 1.75s\tremaining: 13.6s\n",
      "114:\tlearn: 2.1970882\ttotal: 1.77s\tremaining: 13.6s\n",
      "115:\tlearn: 2.1968980\ttotal: 1.78s\tremaining: 13.6s\n",
      "116:\tlearn: 2.1964123\ttotal: 1.8s\tremaining: 13.6s\n",
      "117:\tlearn: 2.1961334\ttotal: 1.81s\tremaining: 13.6s\n",
      "118:\tlearn: 2.1960140\ttotal: 1.83s\tremaining: 13.5s\n",
      "119:\tlearn: 2.1902546\ttotal: 1.84s\tremaining: 13.5s\n",
      "120:\tlearn: 2.1848395\ttotal: 1.86s\tremaining: 13.5s\n",
      "121:\tlearn: 2.1795578\ttotal: 1.87s\tremaining: 13.5s\n",
      "122:\tlearn: 2.1790154\ttotal: 1.89s\tremaining: 13.5s\n",
      "123:\tlearn: 2.1787580\ttotal: 1.9s\tremaining: 13.4s\n",
      "124:\tlearn: 2.1786069\ttotal: 1.92s\tremaining: 13.4s\n",
      "125:\tlearn: 2.1768968\ttotal: 1.93s\tremaining: 13.4s\n",
      "126:\tlearn: 2.1766373\ttotal: 1.95s\tremaining: 13.4s\n",
      "127:\tlearn: 2.1763821\ttotal: 1.96s\tremaining: 13.4s\n",
      "128:\tlearn: 2.1760164\ttotal: 1.98s\tremaining: 13.4s\n",
      "129:\tlearn: 2.1751134\ttotal: 1.99s\tremaining: 13.3s\n",
      "130:\tlearn: 2.1743129\ttotal: 2.01s\tremaining: 13.3s\n",
      "131:\tlearn: 2.1721180\ttotal: 2.02s\tremaining: 13.3s\n",
      "132:\tlearn: 2.1702613\ttotal: 2.04s\tremaining: 13.3s\n",
      "133:\tlearn: 2.1682752\ttotal: 2.05s\tremaining: 13.3s\n",
      "134:\tlearn: 2.1624280\ttotal: 2.07s\tremaining: 13.3s\n",
      "135:\tlearn: 2.1564164\ttotal: 2.08s\tremaining: 13.2s\n",
      "136:\tlearn: 2.1502690\ttotal: 2.1s\tremaining: 13.2s\n",
      "137:\tlearn: 2.1486667\ttotal: 2.11s\tremaining: 13.2s\n",
      "138:\tlearn: 2.1465760\ttotal: 2.13s\tremaining: 13.2s\n",
      "139:\tlearn: 2.1436612\ttotal: 2.14s\tremaining: 13.2s\n",
      "140:\tlearn: 2.1364742\ttotal: 2.16s\tremaining: 13.1s\n",
      "141:\tlearn: 2.1319237\ttotal: 2.17s\tremaining: 13.1s\n",
      "142:\tlearn: 2.1264773\ttotal: 2.19s\tremaining: 13.1s\n",
      "143:\tlearn: 2.1213840\ttotal: 2.21s\tremaining: 13.1s\n",
      "144:\tlearn: 2.1158080\ttotal: 2.22s\tremaining: 13.1s\n",
      "145:\tlearn: 2.1112029\ttotal: 2.23s\tremaining: 13.1s\n",
      "146:\tlearn: 2.1060747\ttotal: 2.25s\tremaining: 13.1s\n",
      "147:\tlearn: 2.1032107\ttotal: 2.27s\tremaining: 13s\n",
      "148:\tlearn: 2.1016861\ttotal: 2.28s\tremaining: 13s\n",
      "149:\tlearn: 2.1000204\ttotal: 2.3s\tremaining: 13s\n",
      "150:\tlearn: 2.0986949\ttotal: 2.31s\tremaining: 13s\n",
      "151:\tlearn: 2.0977709\ttotal: 2.32s\tremaining: 13s\n",
      "152:\tlearn: 2.0930140\ttotal: 2.34s\tremaining: 13s\n",
      "153:\tlearn: 2.0898845\ttotal: 2.35s\tremaining: 12.9s\n",
      "154:\tlearn: 2.0886588\ttotal: 2.37s\tremaining: 12.9s\n",
      "155:\tlearn: 2.0881616\ttotal: 2.38s\tremaining: 12.9s\n",
      "156:\tlearn: 2.0864799\ttotal: 2.4s\tremaining: 12.9s\n",
      "157:\tlearn: 2.0840874\ttotal: 2.41s\tremaining: 12.9s\n",
      "158:\tlearn: 2.0805638\ttotal: 2.43s\tremaining: 12.8s\n",
      "159:\tlearn: 2.0773430\ttotal: 2.44s\tremaining: 12.8s\n",
      "160:\tlearn: 2.0742732\ttotal: 2.46s\tremaining: 12.8s\n",
      "161:\tlearn: 2.0717802\ttotal: 2.47s\tremaining: 12.8s\n",
      "162:\tlearn: 2.0712830\ttotal: 2.49s\tremaining: 12.8s\n",
      "163:\tlearn: 2.0702127\ttotal: 2.5s\tremaining: 12.8s\n",
      "164:\tlearn: 2.0684909\ttotal: 2.52s\tremaining: 12.7s\n",
      "165:\tlearn: 2.0667112\ttotal: 2.53s\tremaining: 12.7s\n",
      "166:\tlearn: 2.0655845\ttotal: 2.55s\tremaining: 12.7s\n",
      "167:\tlearn: 2.0650625\ttotal: 2.56s\tremaining: 12.7s\n",
      "168:\tlearn: 2.0647434\ttotal: 2.58s\tremaining: 12.7s\n",
      "169:\tlearn: 2.0635666\ttotal: 2.59s\tremaining: 12.7s\n",
      "170:\tlearn: 2.0622215\ttotal: 2.61s\tremaining: 12.6s\n",
      "171:\tlearn: 2.0601583\ttotal: 2.62s\tremaining: 12.6s\n",
      "172:\tlearn: 2.0564468\ttotal: 2.64s\tremaining: 12.6s\n",
      "173:\tlearn: 2.0560797\ttotal: 2.65s\tremaining: 12.6s\n",
      "174:\tlearn: 2.0558376\ttotal: 2.67s\tremaining: 12.6s\n",
      "175:\tlearn: 2.0535703\ttotal: 2.68s\tremaining: 12.5s\n",
      "176:\tlearn: 2.0512174\ttotal: 2.69s\tremaining: 12.5s\n",
      "177:\tlearn: 2.0480872\ttotal: 2.71s\tremaining: 12.5s\n",
      "178:\tlearn: 2.0471504\ttotal: 2.73s\tremaining: 12.5s\n",
      "179:\tlearn: 2.0470166\ttotal: 2.74s\tremaining: 12.5s\n",
      "180:\tlearn: 2.0454864\ttotal: 2.75s\tremaining: 12.5s\n",
      "181:\tlearn: 2.0440369\ttotal: 2.77s\tremaining: 12.4s\n",
      "182:\tlearn: 2.0426625\ttotal: 2.79s\tremaining: 12.4s\n",
      "183:\tlearn: 2.0400811\ttotal: 2.8s\tremaining: 12.4s\n",
      "184:\tlearn: 2.0390683\ttotal: 2.82s\tremaining: 12.4s\n",
      "185:\tlearn: 2.0369104\ttotal: 2.83s\tremaining: 12.4s\n",
      "186:\tlearn: 2.0348825\ttotal: 2.85s\tremaining: 12.4s\n",
      "187:\tlearn: 2.0330133\ttotal: 2.86s\tremaining: 12.4s\n",
      "188:\tlearn: 2.0318392\ttotal: 2.88s\tremaining: 12.3s\n",
      "189:\tlearn: 2.0309067\ttotal: 2.89s\tremaining: 12.3s\n",
      "190:\tlearn: 2.0299596\ttotal: 2.91s\tremaining: 12.3s\n",
      "191:\tlearn: 2.0276006\ttotal: 2.92s\tremaining: 12.3s\n",
      "192:\tlearn: 2.0271681\ttotal: 2.94s\tremaining: 12.3s\n",
      "193:\tlearn: 2.0269239\ttotal: 2.95s\tremaining: 12.3s\n",
      "194:\tlearn: 2.0265508\ttotal: 2.96s\tremaining: 12.2s\n",
      "195:\tlearn: 2.0256552\ttotal: 2.98s\tremaining: 12.2s\n",
      "196:\tlearn: 2.0229729\ttotal: 3s\tremaining: 12.2s\n",
      "197:\tlearn: 2.0211700\ttotal: 3.01s\tremaining: 12.2s\n",
      "198:\tlearn: 2.0191903\ttotal: 3.02s\tremaining: 12.2s\n",
      "199:\tlearn: 2.0163230\ttotal: 3.04s\tremaining: 12.2s\n",
      "200:\tlearn: 2.0146641\ttotal: 3.05s\tremaining: 12.1s\n",
      "201:\tlearn: 2.0137518\ttotal: 3.07s\tremaining: 12.1s\n",
      "202:\tlearn: 2.0125353\ttotal: 3.08s\tremaining: 12.1s\n",
      "203:\tlearn: 2.0103851\ttotal: 3.1s\tremaining: 12.1s\n",
      "204:\tlearn: 2.0096387\ttotal: 3.12s\tremaining: 12.1s\n",
      "205:\tlearn: 2.0076615\ttotal: 3.13s\tremaining: 12.1s\n",
      "206:\tlearn: 2.0056126\ttotal: 3.15s\tremaining: 12.1s\n",
      "207:\tlearn: 2.0032602\ttotal: 3.16s\tremaining: 12s\n",
      "208:\tlearn: 2.0015561\ttotal: 3.17s\tremaining: 12s\n",
      "209:\tlearn: 2.0003324\ttotal: 3.19s\tremaining: 12s\n",
      "210:\tlearn: 1.9992689\ttotal: 3.21s\tremaining: 12s\n",
      "211:\tlearn: 1.9980273\ttotal: 3.22s\tremaining: 12s\n",
      "212:\tlearn: 1.9974848\ttotal: 3.23s\tremaining: 12s\n",
      "213:\tlearn: 1.9970303\ttotal: 3.25s\tremaining: 11.9s\n",
      "214:\tlearn: 1.9970034\ttotal: 3.27s\tremaining: 11.9s\n",
      "215:\tlearn: 1.9957171\ttotal: 3.28s\tremaining: 11.9s\n",
      "216:\tlearn: 1.9945738\ttotal: 3.3s\tremaining: 11.9s\n",
      "217:\tlearn: 1.9940814\ttotal: 3.31s\tremaining: 11.9s\n",
      "218:\tlearn: 1.9939976\ttotal: 3.32s\tremaining: 11.9s\n",
      "219:\tlearn: 1.9929841\ttotal: 3.34s\tremaining: 11.8s\n",
      "220:\tlearn: 1.9912511\ttotal: 3.35s\tremaining: 11.8s\n",
      "221:\tlearn: 1.9897066\ttotal: 3.37s\tremaining: 11.8s\n",
      "222:\tlearn: 1.9890495\ttotal: 3.38s\tremaining: 11.8s\n",
      "223:\tlearn: 1.9885374\ttotal: 3.4s\tremaining: 11.8s\n",
      "224:\tlearn: 1.9874016\ttotal: 3.42s\tremaining: 11.8s\n",
      "225:\tlearn: 1.9869895\ttotal: 3.43s\tremaining: 11.8s\n",
      "226:\tlearn: 1.9858260\ttotal: 3.45s\tremaining: 11.7s\n",
      "227:\tlearn: 1.9849210\ttotal: 3.46s\tremaining: 11.7s\n",
      "228:\tlearn: 1.9840927\ttotal: 3.48s\tremaining: 11.7s\n",
      "229:\tlearn: 1.9835932\ttotal: 3.49s\tremaining: 11.7s\n",
      "230:\tlearn: 1.9827729\ttotal: 3.51s\tremaining: 11.7s\n",
      "231:\tlearn: 1.9819852\ttotal: 3.52s\tremaining: 11.7s\n",
      "232:\tlearn: 1.9818877\ttotal: 3.54s\tremaining: 11.6s\n",
      "233:\tlearn: 1.9809038\ttotal: 3.55s\tremaining: 11.6s\n",
      "234:\tlearn: 1.9804311\ttotal: 3.57s\tremaining: 11.6s\n",
      "235:\tlearn: 1.9802249\ttotal: 3.58s\tremaining: 11.6s\n",
      "236:\tlearn: 1.9775817\ttotal: 3.6s\tremaining: 11.6s\n",
      "237:\tlearn: 1.9761737\ttotal: 3.61s\tremaining: 11.6s\n",
      "238:\tlearn: 1.9753967\ttotal: 3.63s\tremaining: 11.5s\n",
      "239:\tlearn: 1.9750175\ttotal: 3.64s\tremaining: 11.5s\n",
      "240:\tlearn: 1.9733647\ttotal: 3.65s\tremaining: 11.5s\n",
      "241:\tlearn: 1.9722355\ttotal: 3.67s\tremaining: 11.5s\n",
      "242:\tlearn: 1.9711546\ttotal: 3.69s\tremaining: 11.5s\n",
      "243:\tlearn: 1.9698251\ttotal: 3.7s\tremaining: 11.5s\n",
      "244:\tlearn: 1.9686682\ttotal: 3.72s\tremaining: 11.5s\n",
      "245:\tlearn: 1.9684641\ttotal: 3.73s\tremaining: 11.4s\n",
      "246:\tlearn: 1.9672386\ttotal: 3.75s\tremaining: 11.4s\n",
      "247:\tlearn: 1.9658963\ttotal: 3.76s\tremaining: 11.4s\n",
      "248:\tlearn: 1.9657743\ttotal: 3.78s\tremaining: 11.4s\n",
      "249:\tlearn: 1.9648214\ttotal: 3.79s\tremaining: 11.4s\n",
      "250:\tlearn: 1.9637963\ttotal: 3.81s\tremaining: 11.4s\n",
      "251:\tlearn: 1.9625454\ttotal: 3.82s\tremaining: 11.3s\n",
      "252:\tlearn: 1.9615672\ttotal: 3.84s\tremaining: 11.3s\n",
      "253:\tlearn: 1.9614789\ttotal: 3.85s\tremaining: 11.3s\n",
      "254:\tlearn: 1.9602897\ttotal: 3.87s\tremaining: 11.3s\n",
      "255:\tlearn: 1.9589398\ttotal: 3.88s\tremaining: 11.3s\n",
      "256:\tlearn: 1.9581220\ttotal: 3.9s\tremaining: 11.3s\n",
      "257:\tlearn: 1.9564180\ttotal: 3.91s\tremaining: 11.3s\n",
      "258:\tlearn: 1.9553336\ttotal: 3.93s\tremaining: 11.2s\n",
      "259:\tlearn: 1.9553329\ttotal: 3.94s\tremaining: 11.2s\n",
      "260:\tlearn: 1.9550966\ttotal: 3.96s\tremaining: 11.2s\n",
      "261:\tlearn: 1.9547998\ttotal: 3.97s\tremaining: 11.2s\n",
      "262:\tlearn: 1.9542645\ttotal: 3.99s\tremaining: 11.2s\n",
      "263:\tlearn: 1.9539936\ttotal: 4s\tremaining: 11.2s\n",
      "264:\tlearn: 1.9531046\ttotal: 4.02s\tremaining: 11.2s\n",
      "265:\tlearn: 1.9529814\ttotal: 4.03s\tremaining: 11.1s\n",
      "266:\tlearn: 1.9528462\ttotal: 4.05s\tremaining: 11.1s\n",
      "267:\tlearn: 1.9527350\ttotal: 4.06s\tremaining: 11.1s\n",
      "268:\tlearn: 1.9522945\ttotal: 4.08s\tremaining: 11.1s\n",
      "269:\tlearn: 1.9519443\ttotal: 4.09s\tremaining: 11.1s\n",
      "270:\tlearn: 1.9514554\ttotal: 4.11s\tremaining: 11.1s\n",
      "271:\tlearn: 1.9508866\ttotal: 4.12s\tremaining: 11s\n",
      "272:\tlearn: 1.9507800\ttotal: 4.14s\tremaining: 11s\n",
      "273:\tlearn: 1.9506689\ttotal: 4.15s\tremaining: 11s\n",
      "274:\tlearn: 1.9503176\ttotal: 4.17s\tremaining: 11s\n",
      "275:\tlearn: 1.9497070\ttotal: 4.18s\tremaining: 11s\n",
      "276:\tlearn: 1.9494565\ttotal: 4.2s\tremaining: 11s\n",
      "277:\tlearn: 1.9490790\ttotal: 4.21s\tremaining: 10.9s\n",
      "278:\tlearn: 1.9489295\ttotal: 4.23s\tremaining: 10.9s\n",
      "279:\tlearn: 1.9486812\ttotal: 4.24s\tremaining: 10.9s\n",
      "280:\tlearn: 1.9484974\ttotal: 4.26s\tremaining: 10.9s\n",
      "281:\tlearn: 1.9481347\ttotal: 4.27s\tremaining: 10.9s\n",
      "282:\tlearn: 1.9471716\ttotal: 4.29s\tremaining: 10.9s\n",
      "283:\tlearn: 1.9469446\ttotal: 4.3s\tremaining: 10.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284:\tlearn: 1.9465498\ttotal: 4.32s\tremaining: 10.8s\n",
      "285:\tlearn: 1.9458678\ttotal: 4.34s\tremaining: 10.8s\n",
      "286:\tlearn: 1.9456455\ttotal: 4.35s\tremaining: 10.8s\n",
      "287:\tlearn: 1.9454104\ttotal: 4.37s\tremaining: 10.8s\n",
      "288:\tlearn: 1.9443738\ttotal: 4.38s\tremaining: 10.8s\n",
      "289:\tlearn: 1.9442462\ttotal: 4.4s\tremaining: 10.8s\n",
      "290:\tlearn: 1.9432362\ttotal: 4.41s\tremaining: 10.7s\n",
      "291:\tlearn: 1.9423554\ttotal: 4.42s\tremaining: 10.7s\n",
      "292:\tlearn: 1.9423553\ttotal: 4.44s\tremaining: 10.7s\n",
      "293:\tlearn: 1.9411283\ttotal: 4.46s\tremaining: 10.7s\n",
      "294:\tlearn: 1.9410134\ttotal: 4.47s\tremaining: 10.7s\n",
      "295:\tlearn: 1.9397150\ttotal: 4.49s\tremaining: 10.7s\n",
      "296:\tlearn: 1.9393369\ttotal: 4.5s\tremaining: 10.7s\n",
      "297:\tlearn: 1.9387948\ttotal: 4.52s\tremaining: 10.6s\n",
      "298:\tlearn: 1.9384441\ttotal: 4.53s\tremaining: 10.6s\n",
      "299:\tlearn: 1.9375455\ttotal: 4.55s\tremaining: 10.6s\n",
      "300:\tlearn: 1.9372397\ttotal: 4.56s\tremaining: 10.6s\n",
      "301:\tlearn: 1.9369717\ttotal: 4.58s\tremaining: 10.6s\n",
      "302:\tlearn: 1.9367968\ttotal: 4.59s\tremaining: 10.6s\n",
      "303:\tlearn: 1.9366660\ttotal: 4.61s\tremaining: 10.5s\n",
      "304:\tlearn: 1.9363429\ttotal: 4.62s\tremaining: 10.5s\n",
      "305:\tlearn: 1.9354432\ttotal: 4.63s\tremaining: 10.5s\n",
      "306:\tlearn: 1.9353051\ttotal: 4.65s\tremaining: 10.5s\n",
      "307:\tlearn: 1.9351223\ttotal: 4.67s\tremaining: 10.5s\n",
      "308:\tlearn: 1.9347503\ttotal: 4.68s\tremaining: 10.5s\n",
      "309:\tlearn: 1.9347426\ttotal: 4.7s\tremaining: 10.5s\n",
      "310:\tlearn: 1.9345554\ttotal: 4.71s\tremaining: 10.4s\n",
      "311:\tlearn: 1.9340175\ttotal: 4.72s\tremaining: 10.4s\n",
      "312:\tlearn: 1.9340016\ttotal: 4.74s\tremaining: 10.4s\n",
      "313:\tlearn: 1.9338654\ttotal: 4.75s\tremaining: 10.4s\n",
      "314:\tlearn: 1.9333482\ttotal: 4.77s\tremaining: 10.4s\n",
      "315:\tlearn: 1.9329538\ttotal: 4.78s\tremaining: 10.4s\n",
      "316:\tlearn: 1.9317600\ttotal: 4.8s\tremaining: 10.3s\n",
      "317:\tlearn: 1.9309595\ttotal: 4.81s\tremaining: 10.3s\n",
      "318:\tlearn: 1.9307103\ttotal: 4.83s\tremaining: 10.3s\n",
      "319:\tlearn: 1.9302420\ttotal: 4.84s\tremaining: 10.3s\n",
      "320:\tlearn: 1.9295808\ttotal: 4.86s\tremaining: 10.3s\n",
      "321:\tlearn: 1.9294279\ttotal: 4.87s\tremaining: 10.3s\n",
      "322:\tlearn: 1.9282252\ttotal: 4.89s\tremaining: 10.2s\n",
      "323:\tlearn: 1.9277603\ttotal: 4.91s\tremaining: 10.2s\n",
      "324:\tlearn: 1.9271840\ttotal: 4.92s\tremaining: 10.2s\n",
      "325:\tlearn: 1.9265885\ttotal: 4.94s\tremaining: 10.2s\n",
      "326:\tlearn: 1.9260825\ttotal: 4.95s\tremaining: 10.2s\n",
      "327:\tlearn: 1.9257886\ttotal: 4.97s\tremaining: 10.2s\n",
      "328:\tlearn: 1.9251808\ttotal: 4.98s\tremaining: 10.2s\n",
      "329:\tlearn: 1.9250280\ttotal: 5s\tremaining: 10.1s\n",
      "330:\tlearn: 1.9240686\ttotal: 5.01s\tremaining: 10.1s\n",
      "331:\tlearn: 1.9235913\ttotal: 5.03s\tremaining: 10.1s\n",
      "332:\tlearn: 1.9229719\ttotal: 5.04s\tremaining: 10.1s\n",
      "333:\tlearn: 1.9224365\ttotal: 5.06s\tremaining: 10.1s\n",
      "334:\tlearn: 1.9220503\ttotal: 5.07s\tremaining: 10.1s\n",
      "335:\tlearn: 1.9219232\ttotal: 5.08s\tremaining: 10.1s\n",
      "336:\tlearn: 1.9217776\ttotal: 5.1s\tremaining: 10s\n",
      "337:\tlearn: 1.9216082\ttotal: 5.12s\tremaining: 10s\n",
      "338:\tlearn: 1.9201674\ttotal: 5.13s\tremaining: 10s\n",
      "339:\tlearn: 1.9197662\ttotal: 5.14s\tremaining: 9.99s\n",
      "340:\tlearn: 1.9185247\ttotal: 5.16s\tremaining: 9.97s\n",
      "341:\tlearn: 1.9176121\ttotal: 5.18s\tremaining: 9.96s\n",
      "342:\tlearn: 1.9167662\ttotal: 5.19s\tremaining: 9.94s\n",
      "343:\tlearn: 1.9167586\ttotal: 5.2s\tremaining: 9.92s\n",
      "344:\tlearn: 1.9167586\ttotal: 5.22s\tremaining: 9.91s\n",
      "345:\tlearn: 1.9165789\ttotal: 5.23s\tremaining: 9.89s\n",
      "346:\tlearn: 1.9163188\ttotal: 5.25s\tremaining: 9.87s\n",
      "347:\tlearn: 1.9162682\ttotal: 5.26s\tremaining: 9.86s\n",
      "348:\tlearn: 1.9162599\ttotal: 5.28s\tremaining: 9.84s\n",
      "349:\tlearn: 1.9162544\ttotal: 5.29s\tremaining: 9.83s\n",
      "350:\tlearn: 1.9162541\ttotal: 5.3s\tremaining: 9.81s\n",
      "351:\tlearn: 1.9161160\ttotal: 5.32s\tremaining: 9.79s\n",
      "352:\tlearn: 1.9161145\ttotal: 5.33s\tremaining: 9.78s\n",
      "353:\tlearn: 1.9161145\ttotal: 5.35s\tremaining: 9.76s\n",
      "354:\tlearn: 1.9157027\ttotal: 5.36s\tremaining: 9.74s\n",
      "355:\tlearn: 1.9157027\ttotal: 5.38s\tremaining: 9.73s\n",
      "356:\tlearn: 1.9156481\ttotal: 5.39s\tremaining: 9.71s\n",
      "357:\tlearn: 1.9156476\ttotal: 5.41s\tremaining: 9.7s\n",
      "358:\tlearn: 1.9156073\ttotal: 5.42s\tremaining: 9.68s\n",
      "359:\tlearn: 1.9154852\ttotal: 5.44s\tremaining: 9.66s\n",
      "360:\tlearn: 1.9154829\ttotal: 5.45s\tremaining: 9.65s\n",
      "361:\tlearn: 1.9154749\ttotal: 5.46s\tremaining: 9.63s\n",
      "362:\tlearn: 1.9152641\ttotal: 5.48s\tremaining: 9.62s\n",
      "363:\tlearn: 1.9152633\ttotal: 5.5s\tremaining: 9.6s\n",
      "364:\tlearn: 1.9151813\ttotal: 5.51s\tremaining: 9.59s\n",
      "365:\tlearn: 1.9148631\ttotal: 5.52s\tremaining: 9.57s\n",
      "366:\tlearn: 1.9145344\ttotal: 5.54s\tremaining: 9.55s\n",
      "367:\tlearn: 1.9140711\ttotal: 5.55s\tremaining: 9.54s\n",
      "368:\tlearn: 1.9140427\ttotal: 5.57s\tremaining: 9.52s\n",
      "369:\tlearn: 1.9138718\ttotal: 5.58s\tremaining: 9.5s\n",
      "370:\tlearn: 1.9137920\ttotal: 5.6s\tremaining: 9.49s\n",
      "371:\tlearn: 1.9136253\ttotal: 5.61s\tremaining: 9.47s\n",
      "372:\tlearn: 1.9129964\ttotal: 5.63s\tremaining: 9.46s\n",
      "373:\tlearn: 1.9129095\ttotal: 5.64s\tremaining: 9.44s\n",
      "374:\tlearn: 1.9128609\ttotal: 5.66s\tremaining: 9.43s\n",
      "375:\tlearn: 1.9128069\ttotal: 5.67s\tremaining: 9.41s\n",
      "376:\tlearn: 1.9126778\ttotal: 5.68s\tremaining: 9.39s\n",
      "377:\tlearn: 1.9126694\ttotal: 5.7s\tremaining: 9.38s\n",
      "378:\tlearn: 1.9117549\ttotal: 5.71s\tremaining: 9.36s\n",
      "379:\tlearn: 1.9107705\ttotal: 5.73s\tremaining: 9.35s\n",
      "380:\tlearn: 1.9099694\ttotal: 5.74s\tremaining: 9.33s\n",
      "381:\tlearn: 1.9098985\ttotal: 5.76s\tremaining: 9.31s\n",
      "382:\tlearn: 1.9093115\ttotal: 5.77s\tremaining: 9.3s\n",
      "383:\tlearn: 1.9090216\ttotal: 5.79s\tremaining: 9.28s\n",
      "384:\tlearn: 1.9088247\ttotal: 5.8s\tremaining: 9.27s\n",
      "385:\tlearn: 1.9087433\ttotal: 5.82s\tremaining: 9.26s\n",
      "386:\tlearn: 1.9081894\ttotal: 5.83s\tremaining: 9.24s\n",
      "387:\tlearn: 1.9080855\ttotal: 5.85s\tremaining: 9.23s\n",
      "388:\tlearn: 1.9080086\ttotal: 5.87s\tremaining: 9.21s\n",
      "389:\tlearn: 1.9074836\ttotal: 5.88s\tremaining: 9.2s\n",
      "390:\tlearn: 1.9074037\ttotal: 5.89s\tremaining: 9.18s\n",
      "391:\tlearn: 1.9073170\ttotal: 5.91s\tremaining: 9.17s\n",
      "392:\tlearn: 1.9070765\ttotal: 5.92s\tremaining: 9.15s\n",
      "393:\tlearn: 1.9068273\ttotal: 5.94s\tremaining: 9.13s\n",
      "394:\tlearn: 1.9067389\ttotal: 5.97s\tremaining: 9.15s\n",
      "395:\tlearn: 1.9066744\ttotal: 5.99s\tremaining: 9.13s\n",
      "396:\tlearn: 1.9066313\ttotal: 6s\tremaining: 9.12s\n",
      "397:\tlearn: 1.9063382\ttotal: 6.02s\tremaining: 9.1s\n",
      "398:\tlearn: 1.9063025\ttotal: 6.03s\tremaining: 9.09s\n",
      "399:\tlearn: 1.9057087\ttotal: 6.05s\tremaining: 9.07s\n",
      "400:\tlearn: 1.9057032\ttotal: 6.06s\tremaining: 9.05s\n",
      "401:\tlearn: 1.9052706\ttotal: 6.08s\tremaining: 9.04s\n",
      "402:\tlearn: 1.9047944\ttotal: 6.09s\tremaining: 9.02s\n",
      "403:\tlearn: 1.9040911\ttotal: 6.11s\tremaining: 9.01s\n",
      "404:\tlearn: 1.9033589\ttotal: 6.12s\tremaining: 8.99s\n",
      "405:\tlearn: 1.9028327\ttotal: 6.14s\tremaining: 8.98s\n",
      "406:\tlearn: 1.9026106\ttotal: 6.15s\tremaining: 8.96s\n",
      "407:\tlearn: 1.9024230\ttotal: 6.17s\tremaining: 8.95s\n",
      "408:\tlearn: 1.9020985\ttotal: 6.18s\tremaining: 8.93s\n",
      "409:\tlearn: 1.9020844\ttotal: 6.2s\tremaining: 8.91s\n",
      "410:\tlearn: 1.9020843\ttotal: 6.21s\tremaining: 8.9s\n",
      "411:\tlearn: 1.9015452\ttotal: 6.23s\tremaining: 8.89s\n",
      "412:\tlearn: 1.9009006\ttotal: 6.24s\tremaining: 8.87s\n",
      "413:\tlearn: 1.9008356\ttotal: 6.26s\tremaining: 8.86s\n",
      "414:\tlearn: 1.9008225\ttotal: 6.28s\tremaining: 8.85s\n",
      "415:\tlearn: 1.9007065\ttotal: 6.29s\tremaining: 8.83s\n",
      "416:\tlearn: 1.9007008\ttotal: 6.31s\tremaining: 8.82s\n",
      "417:\tlearn: 1.9006920\ttotal: 6.32s\tremaining: 8.8s\n",
      "418:\tlearn: 1.9006470\ttotal: 6.34s\tremaining: 8.79s\n",
      "419:\tlearn: 1.9000929\ttotal: 6.36s\tremaining: 8.78s\n",
      "420:\tlearn: 1.9000811\ttotal: 6.37s\tremaining: 8.76s\n",
      "421:\tlearn: 1.9000723\ttotal: 6.39s\tremaining: 8.75s\n",
      "422:\tlearn: 1.9000691\ttotal: 6.4s\tremaining: 8.73s\n",
      "423:\tlearn: 1.9000365\ttotal: 6.42s\tremaining: 8.72s\n",
      "424:\tlearn: 1.8999912\ttotal: 6.43s\tremaining: 8.7s\n",
      "425:\tlearn: 1.8996341\ttotal: 6.45s\tremaining: 8.69s\n",
      "426:\tlearn: 1.8994754\ttotal: 6.46s\tremaining: 8.67s\n",
      "427:\tlearn: 1.8992874\ttotal: 6.48s\tremaining: 8.66s\n",
      "428:\tlearn: 1.8992512\ttotal: 6.49s\tremaining: 8.64s\n",
      "429:\tlearn: 1.8992502\ttotal: 6.51s\tremaining: 8.63s\n",
      "430:\tlearn: 1.8991371\ttotal: 6.52s\tremaining: 8.61s\n",
      "431:\tlearn: 1.8991266\ttotal: 6.54s\tremaining: 8.6s\n",
      "432:\tlearn: 1.8982703\ttotal: 6.55s\tremaining: 8.58s\n",
      "433:\tlearn: 1.8980751\ttotal: 6.57s\tremaining: 8.56s\n",
      "434:\tlearn: 1.8980742\ttotal: 6.58s\tremaining: 8.55s\n",
      "435:\tlearn: 1.8980742\ttotal: 6.6s\tremaining: 8.53s\n",
      "436:\tlearn: 1.8980546\ttotal: 6.61s\tremaining: 8.52s\n",
      "437:\tlearn: 1.8980400\ttotal: 6.63s\tremaining: 8.5s\n",
      "438:\tlearn: 1.8978102\ttotal: 6.64s\tremaining: 8.49s\n",
      "439:\tlearn: 1.8978008\ttotal: 6.66s\tremaining: 8.47s\n",
      "440:\tlearn: 1.8977662\ttotal: 6.67s\tremaining: 8.46s\n",
      "441:\tlearn: 1.8974479\ttotal: 6.68s\tremaining: 8.44s\n",
      "442:\tlearn: 1.8971609\ttotal: 6.7s\tremaining: 8.42s\n",
      "443:\tlearn: 1.8967988\ttotal: 6.71s\tremaining: 8.41s\n",
      "444:\tlearn: 1.8966781\ttotal: 6.73s\tremaining: 8.39s\n",
      "445:\tlearn: 1.8965240\ttotal: 6.74s\tremaining: 8.38s\n",
      "446:\tlearn: 1.8963247\ttotal: 6.76s\tremaining: 8.36s\n",
      "447:\tlearn: 1.8963247\ttotal: 6.77s\tremaining: 8.35s\n",
      "448:\tlearn: 1.8963247\ttotal: 6.79s\tremaining: 8.33s\n",
      "449:\tlearn: 1.8963176\ttotal: 6.8s\tremaining: 8.31s\n",
      "450:\tlearn: 1.8962572\ttotal: 6.82s\tremaining: 8.3s\n",
      "451:\tlearn: 1.8962560\ttotal: 6.83s\tremaining: 8.28s\n",
      "452:\tlearn: 1.8962550\ttotal: 6.84s\tremaining: 8.27s\n",
      "453:\tlearn: 1.8962485\ttotal: 6.86s\tremaining: 8.25s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454:\tlearn: 1.8948011\ttotal: 6.87s\tremaining: 8.23s\n",
      "455:\tlearn: 1.8947359\ttotal: 6.89s\tremaining: 8.22s\n",
      "456:\tlearn: 1.8940133\ttotal: 6.9s\tremaining: 8.2s\n",
      "457:\tlearn: 1.8940006\ttotal: 6.92s\tremaining: 8.19s\n",
      "458:\tlearn: 1.8938153\ttotal: 6.93s\tremaining: 8.17s\n",
      "459:\tlearn: 1.8938057\ttotal: 6.95s\tremaining: 8.15s\n",
      "460:\tlearn: 1.8937293\ttotal: 6.96s\tremaining: 8.14s\n",
      "461:\tlearn: 1.8934980\ttotal: 6.97s\tremaining: 8.12s\n",
      "462:\tlearn: 1.8932476\ttotal: 6.99s\tremaining: 8.11s\n",
      "463:\tlearn: 1.8932352\ttotal: 7s\tremaining: 8.09s\n",
      "464:\tlearn: 1.8927360\ttotal: 7.02s\tremaining: 8.08s\n",
      "465:\tlearn: 1.8923963\ttotal: 7.04s\tremaining: 8.06s\n",
      "466:\tlearn: 1.8921766\ttotal: 7.05s\tremaining: 8.04s\n",
      "467:\tlearn: 1.8918958\ttotal: 7.06s\tremaining: 8.03s\n",
      "468:\tlearn: 1.8915571\ttotal: 7.08s\tremaining: 8.01s\n",
      "469:\tlearn: 1.8899703\ttotal: 7.09s\tremaining: 8s\n",
      "470:\tlearn: 1.8899532\ttotal: 7.11s\tremaining: 7.98s\n",
      "471:\tlearn: 1.8899524\ttotal: 7.12s\tremaining: 7.97s\n",
      "472:\tlearn: 1.8899258\ttotal: 7.14s\tremaining: 7.95s\n",
      "473:\tlearn: 1.8895929\ttotal: 7.15s\tremaining: 7.94s\n",
      "474:\tlearn: 1.8895817\ttotal: 7.17s\tremaining: 7.92s\n",
      "475:\tlearn: 1.8895059\ttotal: 7.18s\tremaining: 7.91s\n",
      "476:\tlearn: 1.8894949\ttotal: 7.2s\tremaining: 7.89s\n",
      "477:\tlearn: 1.8894825\ttotal: 7.21s\tremaining: 7.87s\n",
      "478:\tlearn: 1.8880903\ttotal: 7.22s\tremaining: 7.86s\n",
      "479:\tlearn: 1.8880888\ttotal: 7.24s\tremaining: 7.84s\n",
      "480:\tlearn: 1.8880884\ttotal: 7.25s\tremaining: 7.83s\n",
      "481:\tlearn: 1.8880884\ttotal: 7.27s\tremaining: 7.81s\n",
      "482:\tlearn: 1.8880539\ttotal: 7.28s\tremaining: 7.8s\n",
      "483:\tlearn: 1.8880538\ttotal: 7.3s\tremaining: 7.78s\n",
      "484:\tlearn: 1.8880533\ttotal: 7.31s\tremaining: 7.77s\n",
      "485:\tlearn: 1.8880533\ttotal: 7.33s\tremaining: 7.75s\n",
      "486:\tlearn: 1.8880533\ttotal: 7.34s\tremaining: 7.74s\n",
      "487:\tlearn: 1.8875367\ttotal: 7.36s\tremaining: 7.72s\n",
      "488:\tlearn: 1.8874995\ttotal: 7.37s\tremaining: 7.7s\n",
      "489:\tlearn: 1.8867278\ttotal: 7.39s\tremaining: 7.69s\n",
      "490:\tlearn: 1.8861812\ttotal: 7.4s\tremaining: 7.67s\n",
      "491:\tlearn: 1.8852356\ttotal: 7.42s\tremaining: 7.66s\n",
      "492:\tlearn: 1.8850084\ttotal: 7.43s\tremaining: 7.64s\n",
      "493:\tlearn: 1.8846975\ttotal: 7.44s\tremaining: 7.62s\n",
      "494:\tlearn: 1.8842947\ttotal: 7.46s\tremaining: 7.61s\n",
      "495:\tlearn: 1.8842011\ttotal: 7.47s\tremaining: 7.59s\n",
      "496:\tlearn: 1.8840452\ttotal: 7.49s\tremaining: 7.58s\n",
      "497:\tlearn: 1.8837506\ttotal: 7.5s\tremaining: 7.56s\n",
      "498:\tlearn: 1.8837506\ttotal: 7.52s\tremaining: 7.55s\n",
      "499:\tlearn: 1.8837446\ttotal: 7.53s\tremaining: 7.53s\n",
      "500:\tlearn: 1.8837406\ttotal: 7.55s\tremaining: 7.52s\n",
      "501:\tlearn: 1.8837391\ttotal: 7.56s\tremaining: 7.5s\n",
      "502:\tlearn: 1.8836668\ttotal: 7.58s\tremaining: 7.49s\n",
      "503:\tlearn: 1.8832978\ttotal: 7.59s\tremaining: 7.47s\n",
      "504:\tlearn: 1.8832971\ttotal: 7.61s\tremaining: 7.46s\n",
      "505:\tlearn: 1.8832971\ttotal: 7.62s\tremaining: 7.44s\n",
      "506:\tlearn: 1.8832970\ttotal: 7.63s\tremaining: 7.42s\n",
      "507:\tlearn: 1.8832968\ttotal: 7.65s\tremaining: 7.41s\n",
      "508:\tlearn: 1.8832968\ttotal: 7.66s\tremaining: 7.39s\n",
      "509:\tlearn: 1.8832951\ttotal: 7.68s\tremaining: 7.38s\n",
      "510:\tlearn: 1.8832950\ttotal: 7.69s\tremaining: 7.36s\n",
      "511:\tlearn: 1.8832950\ttotal: 7.71s\tremaining: 7.35s\n",
      "512:\tlearn: 1.8832946\ttotal: 7.72s\tremaining: 7.33s\n",
      "513:\tlearn: 1.8819735\ttotal: 7.74s\tremaining: 7.32s\n",
      "514:\tlearn: 1.8819732\ttotal: 7.75s\tremaining: 7.3s\n",
      "515:\tlearn: 1.8819607\ttotal: 7.77s\tremaining: 7.28s\n",
      "516:\tlearn: 1.8819578\ttotal: 7.78s\tremaining: 7.27s\n",
      "517:\tlearn: 1.8819492\ttotal: 7.79s\tremaining: 7.25s\n",
      "518:\tlearn: 1.8813581\ttotal: 7.81s\tremaining: 7.24s\n",
      "519:\tlearn: 1.8812663\ttotal: 7.82s\tremaining: 7.22s\n",
      "520:\tlearn: 1.8812662\ttotal: 7.84s\tremaining: 7.21s\n",
      "521:\tlearn: 1.8812328\ttotal: 7.85s\tremaining: 7.19s\n",
      "522:\tlearn: 1.8811524\ttotal: 7.87s\tremaining: 7.17s\n",
      "523:\tlearn: 1.8811294\ttotal: 7.88s\tremaining: 7.16s\n",
      "524:\tlearn: 1.8811234\ttotal: 7.89s\tremaining: 7.14s\n",
      "525:\tlearn: 1.8809222\ttotal: 7.91s\tremaining: 7.13s\n",
      "526:\tlearn: 1.8809181\ttotal: 7.92s\tremaining: 7.11s\n",
      "527:\tlearn: 1.8809149\ttotal: 7.94s\tremaining: 7.1s\n",
      "528:\tlearn: 1.8809042\ttotal: 7.95s\tremaining: 7.08s\n",
      "529:\tlearn: 1.8809012\ttotal: 7.97s\tremaining: 7.07s\n",
      "530:\tlearn: 1.8802271\ttotal: 7.98s\tremaining: 7.05s\n",
      "531:\tlearn: 1.8799640\ttotal: 8s\tremaining: 7.04s\n",
      "532:\tlearn: 1.8798562\ttotal: 8.01s\tremaining: 7.02s\n",
      "533:\tlearn: 1.8789972\ttotal: 8.03s\tremaining: 7s\n",
      "534:\tlearn: 1.8789780\ttotal: 8.04s\tremaining: 6.99s\n",
      "535:\tlearn: 1.8789732\ttotal: 8.05s\tremaining: 6.97s\n",
      "536:\tlearn: 1.8789702\ttotal: 8.07s\tremaining: 6.96s\n",
      "537:\tlearn: 1.8789275\ttotal: 8.08s\tremaining: 6.94s\n",
      "538:\tlearn: 1.8789175\ttotal: 8.1s\tremaining: 6.93s\n",
      "539:\tlearn: 1.8789112\ttotal: 8.11s\tremaining: 6.91s\n",
      "540:\tlearn: 1.8789096\ttotal: 8.13s\tremaining: 6.89s\n",
      "541:\tlearn: 1.8789093\ttotal: 8.14s\tremaining: 6.88s\n",
      "542:\tlearn: 1.8789025\ttotal: 8.16s\tremaining: 6.86s\n",
      "543:\tlearn: 1.8788688\ttotal: 8.17s\tremaining: 6.85s\n",
      "544:\tlearn: 1.8788684\ttotal: 8.19s\tremaining: 6.83s\n",
      "545:\tlearn: 1.8788682\ttotal: 8.2s\tremaining: 6.82s\n",
      "546:\tlearn: 1.8788682\ttotal: 8.21s\tremaining: 6.8s\n",
      "547:\tlearn: 1.8788674\ttotal: 8.23s\tremaining: 6.79s\n",
      "548:\tlearn: 1.8788670\ttotal: 8.24s\tremaining: 6.77s\n",
      "549:\tlearn: 1.8788668\ttotal: 8.26s\tremaining: 6.76s\n",
      "550:\tlearn: 1.8788667\ttotal: 8.27s\tremaining: 6.74s\n",
      "551:\tlearn: 1.8788654\ttotal: 8.29s\tremaining: 6.72s\n",
      "552:\tlearn: 1.8788652\ttotal: 8.3s\tremaining: 6.71s\n",
      "553:\tlearn: 1.8788646\ttotal: 8.32s\tremaining: 6.7s\n",
      "554:\tlearn: 1.8788643\ttotal: 8.34s\tremaining: 6.68s\n",
      "555:\tlearn: 1.8788643\ttotal: 8.35s\tremaining: 6.67s\n",
      "556:\tlearn: 1.8788524\ttotal: 8.36s\tremaining: 6.65s\n",
      "557:\tlearn: 1.8788289\ttotal: 8.38s\tremaining: 6.64s\n",
      "558:\tlearn: 1.8788254\ttotal: 8.39s\tremaining: 6.62s\n",
      "559:\tlearn: 1.8779120\ttotal: 8.41s\tremaining: 6.61s\n",
      "560:\tlearn: 1.8777609\ttotal: 8.42s\tremaining: 6.59s\n",
      "561:\tlearn: 1.8777540\ttotal: 8.44s\tremaining: 6.58s\n",
      "562:\tlearn: 1.8777301\ttotal: 8.45s\tremaining: 6.56s\n",
      "563:\tlearn: 1.8777285\ttotal: 8.46s\tremaining: 6.54s\n",
      "564:\tlearn: 1.8777143\ttotal: 8.48s\tremaining: 6.53s\n",
      "565:\tlearn: 1.8773861\ttotal: 8.49s\tremaining: 6.51s\n",
      "566:\tlearn: 1.8769436\ttotal: 8.51s\tremaining: 6.5s\n",
      "567:\tlearn: 1.8758169\ttotal: 8.52s\tremaining: 6.48s\n",
      "568:\tlearn: 1.8754516\ttotal: 8.54s\tremaining: 6.47s\n",
      "569:\tlearn: 1.8741639\ttotal: 8.56s\tremaining: 6.46s\n",
      "570:\tlearn: 1.8738286\ttotal: 8.57s\tremaining: 6.44s\n",
      "571:\tlearn: 1.8732457\ttotal: 8.59s\tremaining: 6.42s\n",
      "572:\tlearn: 1.8731652\ttotal: 8.6s\tremaining: 6.41s\n",
      "573:\tlearn: 1.8728711\ttotal: 8.62s\tremaining: 6.39s\n",
      "574:\tlearn: 1.8728261\ttotal: 8.63s\tremaining: 6.38s\n",
      "575:\tlearn: 1.8726782\ttotal: 8.64s\tremaining: 6.36s\n",
      "576:\tlearn: 1.8726566\ttotal: 8.66s\tremaining: 6.35s\n",
      "577:\tlearn: 1.8726461\ttotal: 8.67s\tremaining: 6.33s\n",
      "578:\tlearn: 1.8726279\ttotal: 8.69s\tremaining: 6.32s\n",
      "579:\tlearn: 1.8724835\ttotal: 8.7s\tremaining: 6.3s\n",
      "580:\tlearn: 1.8724790\ttotal: 8.73s\tremaining: 6.29s\n",
      "581:\tlearn: 1.8721857\ttotal: 8.74s\tremaining: 6.28s\n",
      "582:\tlearn: 1.8717622\ttotal: 8.76s\tremaining: 6.26s\n",
      "583:\tlearn: 1.8715119\ttotal: 8.77s\tremaining: 6.25s\n",
      "584:\tlearn: 1.8711951\ttotal: 8.79s\tremaining: 6.23s\n",
      "585:\tlearn: 1.8708007\ttotal: 8.8s\tremaining: 6.22s\n",
      "586:\tlearn: 1.8708007\ttotal: 8.82s\tremaining: 6.2s\n",
      "587:\tlearn: 1.8707782\ttotal: 8.83s\tremaining: 6.19s\n",
      "588:\tlearn: 1.8703411\ttotal: 8.85s\tremaining: 6.17s\n",
      "589:\tlearn: 1.8703116\ttotal: 8.86s\tremaining: 6.16s\n",
      "590:\tlearn: 1.8703084\ttotal: 8.88s\tremaining: 6.14s\n",
      "591:\tlearn: 1.8702964\ttotal: 8.89s\tremaining: 6.13s\n",
      "592:\tlearn: 1.8702919\ttotal: 8.91s\tremaining: 6.11s\n",
      "593:\tlearn: 1.8701118\ttotal: 8.92s\tremaining: 6.1s\n",
      "594:\tlearn: 1.8693464\ttotal: 8.94s\tremaining: 6.08s\n",
      "595:\tlearn: 1.8686662\ttotal: 8.95s\tremaining: 6.07s\n",
      "596:\tlearn: 1.8683865\ttotal: 8.97s\tremaining: 6.05s\n",
      "597:\tlearn: 1.8683689\ttotal: 8.98s\tremaining: 6.04s\n",
      "598:\tlearn: 1.8683181\ttotal: 9s\tremaining: 6.02s\n",
      "599:\tlearn: 1.8683119\ttotal: 9.01s\tremaining: 6.01s\n",
      "600:\tlearn: 1.8672872\ttotal: 9.03s\tremaining: 5.99s\n",
      "601:\tlearn: 1.8670129\ttotal: 9.04s\tremaining: 5.98s\n",
      "602:\tlearn: 1.8669899\ttotal: 9.06s\tremaining: 5.96s\n",
      "603:\tlearn: 1.8669877\ttotal: 9.07s\tremaining: 5.95s\n",
      "604:\tlearn: 1.8669877\ttotal: 9.09s\tremaining: 5.93s\n",
      "605:\tlearn: 1.8669877\ttotal: 9.1s\tremaining: 5.92s\n",
      "606:\tlearn: 1.8669841\ttotal: 9.11s\tremaining: 5.9s\n",
      "607:\tlearn: 1.8669020\ttotal: 9.13s\tremaining: 5.89s\n",
      "608:\tlearn: 1.8664443\ttotal: 9.14s\tremaining: 5.87s\n",
      "609:\tlearn: 1.8659604\ttotal: 9.16s\tremaining: 5.86s\n",
      "610:\tlearn: 1.8656119\ttotal: 9.17s\tremaining: 5.84s\n",
      "611:\tlearn: 1.8648010\ttotal: 9.19s\tremaining: 5.83s\n",
      "612:\tlearn: 1.8646028\ttotal: 9.2s\tremaining: 5.81s\n",
      "613:\tlearn: 1.8646016\ttotal: 9.22s\tremaining: 5.79s\n",
      "614:\tlearn: 1.8641004\ttotal: 9.23s\tremaining: 5.78s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "615:\tlearn: 1.8632583\ttotal: 9.25s\tremaining: 5.76s\n",
      "616:\tlearn: 1.8631671\ttotal: 9.26s\tremaining: 5.75s\n",
      "617:\tlearn: 1.8631671\ttotal: 9.28s\tremaining: 5.73s\n",
      "618:\tlearn: 1.8631670\ttotal: 9.29s\tremaining: 5.72s\n",
      "619:\tlearn: 1.8631645\ttotal: 9.3s\tremaining: 5.7s\n",
      "620:\tlearn: 1.8631613\ttotal: 9.32s\tremaining: 5.69s\n",
      "621:\tlearn: 1.8631588\ttotal: 9.34s\tremaining: 5.67s\n",
      "622:\tlearn: 1.8631277\ttotal: 9.35s\tremaining: 5.66s\n",
      "623:\tlearn: 1.8630963\ttotal: 9.36s\tremaining: 5.64s\n",
      "624:\tlearn: 1.8630689\ttotal: 9.38s\tremaining: 5.63s\n",
      "625:\tlearn: 1.8630632\ttotal: 9.39s\tremaining: 5.61s\n",
      "626:\tlearn: 1.8630631\ttotal: 9.4s\tremaining: 5.59s\n",
      "627:\tlearn: 1.8630623\ttotal: 9.42s\tremaining: 5.58s\n",
      "628:\tlearn: 1.8630623\ttotal: 9.43s\tremaining: 5.56s\n",
      "629:\tlearn: 1.8630605\ttotal: 9.45s\tremaining: 5.55s\n",
      "630:\tlearn: 1.8630605\ttotal: 9.46s\tremaining: 5.53s\n",
      "631:\tlearn: 1.8630605\ttotal: 9.48s\tremaining: 5.52s\n",
      "632:\tlearn: 1.8630605\ttotal: 9.49s\tremaining: 5.5s\n",
      "633:\tlearn: 1.8630597\ttotal: 9.5s\tremaining: 5.49s\n",
      "634:\tlearn: 1.8630597\ttotal: 9.52s\tremaining: 5.47s\n",
      "635:\tlearn: 1.8630589\ttotal: 9.53s\tremaining: 5.46s\n",
      "636:\tlearn: 1.8630575\ttotal: 9.55s\tremaining: 5.44s\n",
      "637:\tlearn: 1.8630575\ttotal: 9.56s\tremaining: 5.42s\n",
      "638:\tlearn: 1.8630548\ttotal: 9.57s\tremaining: 5.41s\n",
      "639:\tlearn: 1.8630548\ttotal: 9.59s\tremaining: 5.39s\n",
      "640:\tlearn: 1.8627193\ttotal: 9.6s\tremaining: 5.38s\n",
      "641:\tlearn: 1.8625599\ttotal: 9.62s\tremaining: 5.36s\n",
      "642:\tlearn: 1.8622199\ttotal: 9.63s\tremaining: 5.35s\n",
      "643:\tlearn: 1.8621465\ttotal: 9.65s\tremaining: 5.33s\n",
      "644:\tlearn: 1.8621462\ttotal: 9.66s\tremaining: 5.32s\n",
      "645:\tlearn: 1.8617087\ttotal: 9.68s\tremaining: 5.3s\n",
      "646:\tlearn: 1.8610698\ttotal: 9.69s\tremaining: 5.29s\n",
      "647:\tlearn: 1.8609985\ttotal: 9.71s\tremaining: 5.27s\n",
      "648:\tlearn: 1.8609339\ttotal: 9.72s\tremaining: 5.26s\n",
      "649:\tlearn: 1.8608708\ttotal: 9.73s\tremaining: 5.24s\n",
      "650:\tlearn: 1.8606772\ttotal: 9.75s\tremaining: 5.23s\n",
      "651:\tlearn: 1.8605546\ttotal: 9.76s\tremaining: 5.21s\n",
      "652:\tlearn: 1.8605498\ttotal: 9.78s\tremaining: 5.2s\n",
      "653:\tlearn: 1.8596469\ttotal: 9.79s\tremaining: 5.18s\n",
      "654:\tlearn: 1.8591638\ttotal: 9.81s\tremaining: 5.17s\n",
      "655:\tlearn: 1.8583676\ttotal: 9.82s\tremaining: 5.15s\n",
      "656:\tlearn: 1.8579702\ttotal: 9.84s\tremaining: 5.14s\n",
      "657:\tlearn: 1.8579697\ttotal: 9.85s\tremaining: 5.12s\n",
      "658:\tlearn: 1.8579694\ttotal: 9.87s\tremaining: 5.11s\n",
      "659:\tlearn: 1.8578635\ttotal: 9.88s\tremaining: 5.09s\n",
      "660:\tlearn: 1.8565911\ttotal: 9.9s\tremaining: 5.08s\n",
      "661:\tlearn: 1.8560489\ttotal: 9.91s\tremaining: 5.06s\n",
      "662:\tlearn: 1.8560488\ttotal: 9.93s\tremaining: 5.05s\n",
      "663:\tlearn: 1.8560488\ttotal: 9.94s\tremaining: 5.03s\n",
      "664:\tlearn: 1.8560207\ttotal: 9.96s\tremaining: 5.01s\n",
      "665:\tlearn: 1.8560200\ttotal: 9.97s\tremaining: 5s\n",
      "666:\tlearn: 1.8559907\ttotal: 9.98s\tremaining: 4.99s\n",
      "667:\tlearn: 1.8557211\ttotal: 10s\tremaining: 4.97s\n",
      "668:\tlearn: 1.8544035\ttotal: 10s\tremaining: 4.96s\n",
      "669:\tlearn: 1.8543929\ttotal: 10s\tremaining: 4.94s\n",
      "670:\tlearn: 1.8543928\ttotal: 10s\tremaining: 4.93s\n",
      "671:\tlearn: 1.8543928\ttotal: 10.1s\tremaining: 4.91s\n",
      "672:\tlearn: 1.8543928\ttotal: 10.1s\tremaining: 4.9s\n",
      "673:\tlearn: 1.8543924\ttotal: 10.1s\tremaining: 4.88s\n",
      "674:\tlearn: 1.8539009\ttotal: 10.1s\tremaining: 4.87s\n",
      "675:\tlearn: 1.8527457\ttotal: 10.1s\tremaining: 4.85s\n",
      "676:\tlearn: 1.8526679\ttotal: 10.1s\tremaining: 4.83s\n",
      "677:\tlearn: 1.8526678\ttotal: 10.1s\tremaining: 4.82s\n",
      "678:\tlearn: 1.8521213\ttotal: 10.2s\tremaining: 4.8s\n",
      "679:\tlearn: 1.8518585\ttotal: 10.2s\tremaining: 4.79s\n",
      "680:\tlearn: 1.8516926\ttotal: 10.2s\tremaining: 4.77s\n",
      "681:\tlearn: 1.8516874\ttotal: 10.2s\tremaining: 4.76s\n",
      "682:\tlearn: 1.8516871\ttotal: 10.2s\tremaining: 4.74s\n",
      "683:\tlearn: 1.8516868\ttotal: 10.2s\tremaining: 4.73s\n",
      "684:\tlearn: 1.8516868\ttotal: 10.3s\tremaining: 4.71s\n",
      "685:\tlearn: 1.8516868\ttotal: 10.3s\tremaining: 4.7s\n",
      "686:\tlearn: 1.8516868\ttotal: 10.3s\tremaining: 4.68s\n",
      "687:\tlearn: 1.8516868\ttotal: 10.3s\tremaining: 4.67s\n",
      "688:\tlearn: 1.8515722\ttotal: 10.3s\tremaining: 4.65s\n",
      "689:\tlearn: 1.8509618\ttotal: 10.3s\tremaining: 4.64s\n",
      "690:\tlearn: 1.8509611\ttotal: 10.3s\tremaining: 4.62s\n",
      "691:\tlearn: 1.8509611\ttotal: 10.4s\tremaining: 4.61s\n",
      "692:\tlearn: 1.8509611\ttotal: 10.4s\tremaining: 4.59s\n",
      "693:\tlearn: 1.8508994\ttotal: 10.4s\tremaining: 4.58s\n",
      "694:\tlearn: 1.8502485\ttotal: 10.4s\tremaining: 4.56s\n",
      "695:\tlearn: 1.8502460\ttotal: 10.4s\tremaining: 4.55s\n",
      "696:\tlearn: 1.8502460\ttotal: 10.4s\tremaining: 4.53s\n",
      "697:\tlearn: 1.8502460\ttotal: 10.4s\tremaining: 4.51s\n",
      "698:\tlearn: 1.8502460\ttotal: 10.5s\tremaining: 4.5s\n",
      "699:\tlearn: 1.8502460\ttotal: 10.5s\tremaining: 4.49s\n",
      "700:\tlearn: 1.8502345\ttotal: 10.5s\tremaining: 4.47s\n",
      "701:\tlearn: 1.8493174\ttotal: 10.5s\tremaining: 4.46s\n",
      "702:\tlearn: 1.8487231\ttotal: 10.5s\tremaining: 4.44s\n",
      "703:\tlearn: 1.8484878\ttotal: 10.5s\tremaining: 4.42s\n",
      "704:\tlearn: 1.8484874\ttotal: 10.5s\tremaining: 4.41s\n",
      "705:\tlearn: 1.8481827\ttotal: 10.6s\tremaining: 4.39s\n",
      "706:\tlearn: 1.8481823\ttotal: 10.6s\tremaining: 4.38s\n",
      "707:\tlearn: 1.8481823\ttotal: 10.6s\tremaining: 4.36s\n",
      "708:\tlearn: 1.8481823\ttotal: 10.6s\tremaining: 4.35s\n",
      "709:\tlearn: 1.8481823\ttotal: 10.6s\tremaining: 4.33s\n",
      "710:\tlearn: 1.8481802\ttotal: 10.6s\tremaining: 4.32s\n",
      "711:\tlearn: 1.8481720\ttotal: 10.6s\tremaining: 4.3s\n",
      "712:\tlearn: 1.8477527\ttotal: 10.7s\tremaining: 4.29s\n",
      "713:\tlearn: 1.8476958\ttotal: 10.7s\tremaining: 4.27s\n",
      "714:\tlearn: 1.8476384\ttotal: 10.7s\tremaining: 4.26s\n",
      "715:\tlearn: 1.8473438\ttotal: 10.7s\tremaining: 4.24s\n",
      "716:\tlearn: 1.8470873\ttotal: 10.7s\tremaining: 4.23s\n",
      "717:\tlearn: 1.8463838\ttotal: 10.7s\tremaining: 4.21s\n",
      "718:\tlearn: 1.8463265\ttotal: 10.7s\tremaining: 4.2s\n",
      "719:\tlearn: 1.8461056\ttotal: 10.8s\tremaining: 4.19s\n",
      "720:\tlearn: 1.8459594\ttotal: 10.8s\tremaining: 4.17s\n",
      "721:\tlearn: 1.8456096\ttotal: 10.8s\tremaining: 4.16s\n",
      "722:\tlearn: 1.8453675\ttotal: 10.8s\tremaining: 4.14s\n",
      "723:\tlearn: 1.8451009\ttotal: 10.8s\tremaining: 4.13s\n",
      "724:\tlearn: 1.8450893\ttotal: 10.8s\tremaining: 4.11s\n",
      "725:\tlearn: 1.8442261\ttotal: 10.9s\tremaining: 4.1s\n",
      "726:\tlearn: 1.8440266\ttotal: 10.9s\tremaining: 4.08s\n",
      "727:\tlearn: 1.8440240\ttotal: 10.9s\tremaining: 4.07s\n",
      "728:\tlearn: 1.8440093\ttotal: 10.9s\tremaining: 4.05s\n",
      "729:\tlearn: 1.8439957\ttotal: 10.9s\tremaining: 4.04s\n",
      "730:\tlearn: 1.8437035\ttotal: 10.9s\tremaining: 4.02s\n",
      "731:\tlearn: 1.8434909\ttotal: 10.9s\tremaining: 4.01s\n",
      "732:\tlearn: 1.8433798\ttotal: 11s\tremaining: 3.99s\n",
      "733:\tlearn: 1.8433750\ttotal: 11s\tremaining: 3.98s\n",
      "734:\tlearn: 1.8433743\ttotal: 11s\tremaining: 3.96s\n",
      "735:\tlearn: 1.8429387\ttotal: 11s\tremaining: 3.95s\n",
      "736:\tlearn: 1.8429311\ttotal: 11s\tremaining: 3.93s\n",
      "737:\tlearn: 1.8420612\ttotal: 11s\tremaining: 3.92s\n",
      "738:\tlearn: 1.8420582\ttotal: 11s\tremaining: 3.9s\n",
      "739:\tlearn: 1.8417483\ttotal: 11.1s\tremaining: 3.89s\n",
      "740:\tlearn: 1.8417436\ttotal: 11.1s\tremaining: 3.87s\n",
      "741:\tlearn: 1.8417377\ttotal: 11.1s\tremaining: 3.86s\n",
      "742:\tlearn: 1.8417341\ttotal: 11.1s\tremaining: 3.84s\n",
      "743:\tlearn: 1.8417303\ttotal: 11.1s\tremaining: 3.83s\n",
      "744:\tlearn: 1.8417298\ttotal: 11.1s\tremaining: 3.81s\n",
      "745:\tlearn: 1.8417286\ttotal: 11.1s\tremaining: 3.79s\n",
      "746:\tlearn: 1.8417283\ttotal: 11.2s\tremaining: 3.78s\n",
      "747:\tlearn: 1.8417150\ttotal: 11.2s\tremaining: 3.76s\n",
      "748:\tlearn: 1.8417150\ttotal: 11.2s\tremaining: 3.75s\n",
      "749:\tlearn: 1.8417148\ttotal: 11.2s\tremaining: 3.73s\n",
      "750:\tlearn: 1.8417128\ttotal: 11.2s\tremaining: 3.72s\n",
      "751:\tlearn: 1.8417126\ttotal: 11.2s\tremaining: 3.7s\n",
      "752:\tlearn: 1.8417122\ttotal: 11.2s\tremaining: 3.69s\n",
      "753:\tlearn: 1.8417004\ttotal: 11.3s\tremaining: 3.67s\n",
      "754:\tlearn: 1.8416990\ttotal: 11.3s\tremaining: 3.66s\n",
      "755:\tlearn: 1.8416971\ttotal: 11.3s\tremaining: 3.65s\n",
      "756:\tlearn: 1.8416968\ttotal: 11.3s\tremaining: 3.63s\n",
      "757:\tlearn: 1.8416643\ttotal: 11.3s\tremaining: 3.62s\n",
      "758:\tlearn: 1.8416479\ttotal: 11.3s\tremaining: 3.6s\n",
      "759:\tlearn: 1.8414299\ttotal: 11.4s\tremaining: 3.58s\n",
      "760:\tlearn: 1.8414292\ttotal: 11.4s\tremaining: 3.57s\n",
      "761:\tlearn: 1.8414292\ttotal: 11.4s\tremaining: 3.56s\n",
      "762:\tlearn: 1.8414264\ttotal: 11.4s\tremaining: 3.54s\n",
      "763:\tlearn: 1.8414236\ttotal: 11.4s\tremaining: 3.53s\n",
      "764:\tlearn: 1.8413767\ttotal: 11.4s\tremaining: 3.51s\n",
      "765:\tlearn: 1.8407871\ttotal: 11.4s\tremaining: 3.5s\n",
      "766:\tlearn: 1.8404982\ttotal: 11.5s\tremaining: 3.48s\n",
      "767:\tlearn: 1.8404180\ttotal: 11.5s\tremaining: 3.47s\n",
      "768:\tlearn: 1.8402645\ttotal: 11.5s\tremaining: 3.45s\n",
      "769:\tlearn: 1.8397991\ttotal: 11.5s\tremaining: 3.44s\n",
      "770:\tlearn: 1.8395091\ttotal: 11.5s\tremaining: 3.42s\n",
      "771:\tlearn: 1.8393025\ttotal: 11.5s\tremaining: 3.41s\n",
      "772:\tlearn: 1.8392950\ttotal: 11.5s\tremaining: 3.39s\n",
      "773:\tlearn: 1.8392870\ttotal: 11.6s\tremaining: 3.38s\n",
      "774:\tlearn: 1.8383878\ttotal: 11.6s\tremaining: 3.36s\n",
      "775:\tlearn: 1.8383579\ttotal: 11.6s\tremaining: 3.35s\n",
      "776:\tlearn: 1.8380700\ttotal: 11.6s\tremaining: 3.33s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777:\tlearn: 1.8375560\ttotal: 11.6s\tremaining: 3.31s\n",
      "778:\tlearn: 1.8373476\ttotal: 11.6s\tremaining: 3.3s\n",
      "779:\tlearn: 1.8373468\ttotal: 11.6s\tremaining: 3.29s\n",
      "780:\tlearn: 1.8372318\ttotal: 11.7s\tremaining: 3.27s\n",
      "781:\tlearn: 1.8370685\ttotal: 11.7s\tremaining: 3.25s\n",
      "782:\tlearn: 1.8365654\ttotal: 11.7s\tremaining: 3.24s\n",
      "783:\tlearn: 1.8360606\ttotal: 11.7s\tremaining: 3.23s\n",
      "784:\tlearn: 1.8356195\ttotal: 11.7s\tremaining: 3.21s\n",
      "785:\tlearn: 1.8354195\ttotal: 11.7s\tremaining: 3.19s\n",
      "786:\tlearn: 1.8354163\ttotal: 11.7s\tremaining: 3.18s\n",
      "787:\tlearn: 1.8349310\ttotal: 11.8s\tremaining: 3.16s\n",
      "788:\tlearn: 1.8346821\ttotal: 11.8s\tremaining: 3.15s\n",
      "789:\tlearn: 1.8345875\ttotal: 11.8s\tremaining: 3.13s\n",
      "790:\tlearn: 1.8345379\ttotal: 11.8s\tremaining: 3.12s\n",
      "791:\tlearn: 1.8345378\ttotal: 11.8s\tremaining: 3.1s\n",
      "792:\tlearn: 1.8344010\ttotal: 11.8s\tremaining: 3.09s\n",
      "793:\tlearn: 1.8343217\ttotal: 11.9s\tremaining: 3.07s\n",
      "794:\tlearn: 1.8337258\ttotal: 11.9s\tremaining: 3.06s\n",
      "795:\tlearn: 1.8336526\ttotal: 11.9s\tremaining: 3.04s\n",
      "796:\tlearn: 1.8328546\ttotal: 11.9s\tremaining: 3.03s\n",
      "797:\tlearn: 1.8325521\ttotal: 11.9s\tremaining: 3.01s\n",
      "798:\tlearn: 1.8320225\ttotal: 11.9s\tremaining: 3s\n",
      "799:\tlearn: 1.8313607\ttotal: 11.9s\tremaining: 2.98s\n",
      "800:\tlearn: 1.8313606\ttotal: 12s\tremaining: 2.97s\n",
      "801:\tlearn: 1.8313537\ttotal: 12s\tremaining: 2.95s\n",
      "802:\tlearn: 1.8310992\ttotal: 12s\tremaining: 2.94s\n",
      "803:\tlearn: 1.8310981\ttotal: 12s\tremaining: 2.92s\n",
      "804:\tlearn: 1.8310640\ttotal: 12s\tremaining: 2.91s\n",
      "805:\tlearn: 1.8310201\ttotal: 12s\tremaining: 2.89s\n",
      "806:\tlearn: 1.8310200\ttotal: 12s\tremaining: 2.88s\n",
      "807:\tlearn: 1.8310200\ttotal: 12.1s\tremaining: 2.87s\n",
      "808:\tlearn: 1.8310197\ttotal: 12.1s\tremaining: 2.85s\n",
      "809:\tlearn: 1.8310175\ttotal: 12.1s\tremaining: 2.84s\n",
      "810:\tlearn: 1.8309455\ttotal: 12.1s\tremaining: 2.82s\n",
      "811:\tlearn: 1.8306037\ttotal: 12.1s\tremaining: 2.81s\n",
      "812:\tlearn: 1.8300666\ttotal: 12.1s\tremaining: 2.79s\n",
      "813:\tlearn: 1.8300532\ttotal: 12.1s\tremaining: 2.78s\n",
      "814:\tlearn: 1.8300098\ttotal: 12.2s\tremaining: 2.76s\n",
      "815:\tlearn: 1.8299462\ttotal: 12.2s\tremaining: 2.75s\n",
      "816:\tlearn: 1.8298852\ttotal: 12.2s\tremaining: 2.73s\n",
      "817:\tlearn: 1.8298423\ttotal: 12.2s\tremaining: 2.72s\n",
      "818:\tlearn: 1.8297688\ttotal: 12.2s\tremaining: 2.7s\n",
      "819:\tlearn: 1.8296833\ttotal: 12.2s\tremaining: 2.69s\n",
      "820:\tlearn: 1.8296583\ttotal: 12.3s\tremaining: 2.67s\n",
      "821:\tlearn: 1.8296486\ttotal: 12.3s\tremaining: 2.65s\n",
      "822:\tlearn: 1.8296485\ttotal: 12.3s\tremaining: 2.64s\n",
      "823:\tlearn: 1.8296397\ttotal: 12.3s\tremaining: 2.63s\n",
      "824:\tlearn: 1.8296397\ttotal: 12.3s\tremaining: 2.61s\n",
      "825:\tlearn: 1.8296397\ttotal: 12.3s\tremaining: 2.6s\n",
      "826:\tlearn: 1.8296397\ttotal: 12.3s\tremaining: 2.58s\n",
      "827:\tlearn: 1.8292601\ttotal: 12.4s\tremaining: 2.56s\n",
      "828:\tlearn: 1.8292480\ttotal: 12.4s\tremaining: 2.55s\n",
      "829:\tlearn: 1.8292476\ttotal: 12.4s\tremaining: 2.54s\n",
      "830:\tlearn: 1.8290406\ttotal: 12.4s\tremaining: 2.52s\n",
      "831:\tlearn: 1.8289947\ttotal: 12.4s\tremaining: 2.5s\n",
      "832:\tlearn: 1.8288540\ttotal: 12.4s\tremaining: 2.49s\n",
      "833:\tlearn: 1.8287775\ttotal: 12.4s\tremaining: 2.48s\n",
      "834:\tlearn: 1.8287729\ttotal: 12.4s\tremaining: 2.46s\n",
      "835:\tlearn: 1.8287726\ttotal: 12.5s\tremaining: 2.44s\n",
      "836:\tlearn: 1.8287722\ttotal: 12.5s\tremaining: 2.43s\n",
      "837:\tlearn: 1.8287722\ttotal: 12.5s\tremaining: 2.42s\n",
      "838:\tlearn: 1.8287722\ttotal: 12.5s\tremaining: 2.4s\n",
      "839:\tlearn: 1.8287721\ttotal: 12.5s\tremaining: 2.38s\n",
      "840:\tlearn: 1.8287721\ttotal: 12.5s\tremaining: 2.37s\n",
      "841:\tlearn: 1.8287720\ttotal: 12.6s\tremaining: 2.35s\n",
      "842:\tlearn: 1.8287544\ttotal: 12.6s\tremaining: 2.34s\n",
      "843:\tlearn: 1.8287519\ttotal: 12.6s\tremaining: 2.33s\n",
      "844:\tlearn: 1.8287516\ttotal: 12.6s\tremaining: 2.31s\n",
      "845:\tlearn: 1.8287453\ttotal: 12.6s\tremaining: 2.29s\n",
      "846:\tlearn: 1.8287452\ttotal: 12.6s\tremaining: 2.28s\n",
      "847:\tlearn: 1.8287262\ttotal: 12.6s\tremaining: 2.27s\n",
      "848:\tlearn: 1.8283315\ttotal: 12.7s\tremaining: 2.25s\n",
      "849:\tlearn: 1.8282715\ttotal: 12.7s\tremaining: 2.23s\n",
      "850:\tlearn: 1.8282700\ttotal: 12.7s\tremaining: 2.22s\n",
      "851:\tlearn: 1.8282545\ttotal: 12.7s\tremaining: 2.21s\n",
      "852:\tlearn: 1.8281549\ttotal: 12.7s\tremaining: 2.19s\n",
      "853:\tlearn: 1.8274822\ttotal: 12.7s\tremaining: 2.17s\n",
      "854:\tlearn: 1.8274107\ttotal: 12.7s\tremaining: 2.16s\n",
      "855:\tlearn: 1.8271072\ttotal: 12.8s\tremaining: 2.15s\n",
      "856:\tlearn: 1.8270843\ttotal: 12.8s\tremaining: 2.13s\n",
      "857:\tlearn: 1.8270784\ttotal: 12.8s\tremaining: 2.12s\n",
      "858:\tlearn: 1.8270563\ttotal: 12.8s\tremaining: 2.1s\n",
      "859:\tlearn: 1.8270526\ttotal: 12.8s\tremaining: 2.08s\n",
      "860:\tlearn: 1.8270526\ttotal: 12.8s\tremaining: 2.07s\n",
      "861:\tlearn: 1.8270526\ttotal: 12.8s\tremaining: 2.06s\n",
      "862:\tlearn: 1.8270420\ttotal: 12.9s\tremaining: 2.04s\n",
      "863:\tlearn: 1.8265905\ttotal: 12.9s\tremaining: 2.02s\n",
      "864:\tlearn: 1.8251921\ttotal: 12.9s\tremaining: 2.01s\n",
      "865:\tlearn: 1.8246052\ttotal: 12.9s\tremaining: 2s\n",
      "866:\tlearn: 1.8245022\ttotal: 12.9s\tremaining: 1.98s\n",
      "867:\tlearn: 1.8244579\ttotal: 12.9s\tremaining: 1.97s\n",
      "868:\tlearn: 1.8243656\ttotal: 12.9s\tremaining: 1.95s\n",
      "869:\tlearn: 1.8240823\ttotal: 13s\tremaining: 1.94s\n",
      "870:\tlearn: 1.8240783\ttotal: 13s\tremaining: 1.92s\n",
      "871:\tlearn: 1.8240563\ttotal: 13s\tremaining: 1.91s\n",
      "872:\tlearn: 1.8234171\ttotal: 13s\tremaining: 1.89s\n",
      "873:\tlearn: 1.8233897\ttotal: 13s\tremaining: 1.88s\n",
      "874:\tlearn: 1.8233897\ttotal: 13s\tremaining: 1.86s\n",
      "875:\tlearn: 1.8233896\ttotal: 13s\tremaining: 1.85s\n",
      "876:\tlearn: 1.8233893\ttotal: 13.1s\tremaining: 1.83s\n",
      "877:\tlearn: 1.8233893\ttotal: 13.1s\tremaining: 1.82s\n",
      "878:\tlearn: 1.8233615\ttotal: 13.1s\tremaining: 1.8s\n",
      "879:\tlearn: 1.8233615\ttotal: 13.1s\tremaining: 1.79s\n",
      "880:\tlearn: 1.8233614\ttotal: 13.1s\tremaining: 1.77s\n",
      "881:\tlearn: 1.8230306\ttotal: 13.1s\tremaining: 1.76s\n",
      "882:\tlearn: 1.8230297\ttotal: 13.1s\tremaining: 1.74s\n",
      "883:\tlearn: 1.8230296\ttotal: 13.2s\tremaining: 1.73s\n",
      "884:\tlearn: 1.8230285\ttotal: 13.2s\tremaining: 1.71s\n",
      "885:\tlearn: 1.8230167\ttotal: 13.2s\tremaining: 1.7s\n",
      "886:\tlearn: 1.8230128\ttotal: 13.2s\tremaining: 1.68s\n",
      "887:\tlearn: 1.8230126\ttotal: 13.2s\tremaining: 1.67s\n",
      "888:\tlearn: 1.8224882\ttotal: 13.2s\tremaining: 1.65s\n",
      "889:\tlearn: 1.8224711\ttotal: 13.2s\tremaining: 1.64s\n",
      "890:\tlearn: 1.8219128\ttotal: 13.3s\tremaining: 1.62s\n",
      "891:\tlearn: 1.8211014\ttotal: 13.3s\tremaining: 1.61s\n",
      "892:\tlearn: 1.8209656\ttotal: 13.3s\tremaining: 1.59s\n",
      "893:\tlearn: 1.8209618\ttotal: 13.3s\tremaining: 1.58s\n",
      "894:\tlearn: 1.8209616\ttotal: 13.3s\tremaining: 1.56s\n",
      "895:\tlearn: 1.8209374\ttotal: 13.3s\tremaining: 1.55s\n",
      "896:\tlearn: 1.8200515\ttotal: 13.3s\tremaining: 1.53s\n",
      "897:\tlearn: 1.8200122\ttotal: 13.4s\tremaining: 1.52s\n",
      "898:\tlearn: 1.8196193\ttotal: 13.4s\tremaining: 1.5s\n",
      "899:\tlearn: 1.8191309\ttotal: 13.4s\tremaining: 1.49s\n",
      "900:\tlearn: 1.8190990\ttotal: 13.4s\tremaining: 1.47s\n",
      "901:\tlearn: 1.8190871\ttotal: 13.4s\tremaining: 1.46s\n",
      "902:\tlearn: 1.8189510\ttotal: 13.4s\tremaining: 1.44s\n",
      "903:\tlearn: 1.8189295\ttotal: 13.4s\tremaining: 1.43s\n",
      "904:\tlearn: 1.8188693\ttotal: 13.5s\tremaining: 1.41s\n",
      "905:\tlearn: 1.8177426\ttotal: 13.5s\tremaining: 1.4s\n",
      "906:\tlearn: 1.8168981\ttotal: 13.5s\tremaining: 1.38s\n",
      "907:\tlearn: 1.8164470\ttotal: 13.5s\tremaining: 1.37s\n",
      "908:\tlearn: 1.8156587\ttotal: 13.5s\tremaining: 1.35s\n",
      "909:\tlearn: 1.8156523\ttotal: 13.5s\tremaining: 1.34s\n",
      "910:\tlearn: 1.8154275\ttotal: 13.5s\tremaining: 1.32s\n",
      "911:\tlearn: 1.8152148\ttotal: 13.6s\tremaining: 1.31s\n",
      "912:\tlearn: 1.8146928\ttotal: 13.6s\tremaining: 1.29s\n",
      "913:\tlearn: 1.8146920\ttotal: 13.6s\tremaining: 1.28s\n",
      "914:\tlearn: 1.8146167\ttotal: 13.6s\tremaining: 1.26s\n",
      "915:\tlearn: 1.8138917\ttotal: 13.6s\tremaining: 1.25s\n",
      "916:\tlearn: 1.8138354\ttotal: 13.6s\tremaining: 1.24s\n",
      "917:\tlearn: 1.8138119\ttotal: 13.7s\tremaining: 1.22s\n",
      "918:\tlearn: 1.8133213\ttotal: 13.7s\tremaining: 1.21s\n",
      "919:\tlearn: 1.8130985\ttotal: 13.7s\tremaining: 1.19s\n",
      "920:\tlearn: 1.8130965\ttotal: 13.7s\tremaining: 1.18s\n",
      "921:\tlearn: 1.8130929\ttotal: 13.7s\tremaining: 1.16s\n",
      "922:\tlearn: 1.8130185\ttotal: 13.7s\tremaining: 1.15s\n",
      "923:\tlearn: 1.8130080\ttotal: 13.8s\tremaining: 1.13s\n",
      "924:\tlearn: 1.8128869\ttotal: 13.8s\tremaining: 1.12s\n",
      "925:\tlearn: 1.8128220\ttotal: 13.8s\tremaining: 1.1s\n",
      "926:\tlearn: 1.8126470\ttotal: 13.8s\tremaining: 1.09s\n",
      "927:\tlearn: 1.8126169\ttotal: 13.8s\tremaining: 1.07s\n",
      "928:\tlearn: 1.8125362\ttotal: 13.8s\tremaining: 1.06s\n",
      "929:\tlearn: 1.8123833\ttotal: 13.8s\tremaining: 1.04s\n",
      "930:\tlearn: 1.8123822\ttotal: 13.9s\tremaining: 1.03s\n",
      "931:\tlearn: 1.8123820\ttotal: 13.9s\tremaining: 1.01s\n",
      "932:\tlearn: 1.8122768\ttotal: 13.9s\tremaining: 997ms\n",
      "933:\tlearn: 1.8122668\ttotal: 13.9s\tremaining: 982ms\n",
      "934:\tlearn: 1.8121951\ttotal: 13.9s\tremaining: 967ms\n",
      "935:\tlearn: 1.8121944\ttotal: 13.9s\tremaining: 952ms\n",
      "936:\tlearn: 1.8121381\ttotal: 13.9s\tremaining: 937ms\n",
      "937:\tlearn: 1.8120496\ttotal: 14s\tremaining: 922ms\n",
      "938:\tlearn: 1.8118470\ttotal: 14s\tremaining: 907ms\n",
      "939:\tlearn: 1.8113695\ttotal: 14s\tremaining: 892ms\n",
      "940:\tlearn: 1.8112479\ttotal: 14s\tremaining: 878ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941:\tlearn: 1.8112430\ttotal: 14s\tremaining: 863ms\n",
      "942:\tlearn: 1.8112256\ttotal: 14s\tremaining: 848ms\n",
      "943:\tlearn: 1.8112091\ttotal: 14s\tremaining: 833ms\n",
      "944:\tlearn: 1.8111972\ttotal: 14.1s\tremaining: 818ms\n",
      "945:\tlearn: 1.8102817\ttotal: 14.1s\tremaining: 803ms\n",
      "946:\tlearn: 1.8100811\ttotal: 14.1s\tremaining: 788ms\n",
      "947:\tlearn: 1.8095434\ttotal: 14.1s\tremaining: 773ms\n",
      "948:\tlearn: 1.8094669\ttotal: 14.1s\tremaining: 758ms\n",
      "949:\tlearn: 1.8087611\ttotal: 14.1s\tremaining: 744ms\n",
      "950:\tlearn: 1.8083185\ttotal: 14.1s\tremaining: 729ms\n",
      "951:\tlearn: 1.8083180\ttotal: 14.2s\tremaining: 714ms\n",
      "952:\tlearn: 1.8083080\ttotal: 14.2s\tremaining: 699ms\n",
      "953:\tlearn: 1.8083079\ttotal: 14.2s\tremaining: 684ms\n",
      "954:\tlearn: 1.8083023\ttotal: 14.2s\tremaining: 669ms\n",
      "955:\tlearn: 1.8082965\ttotal: 14.2s\tremaining: 654ms\n",
      "956:\tlearn: 1.8082720\ttotal: 14.2s\tremaining: 639ms\n",
      "957:\tlearn: 1.8082197\ttotal: 14.2s\tremaining: 624ms\n",
      "958:\tlearn: 1.8081342\ttotal: 14.3s\tremaining: 609ms\n",
      "959:\tlearn: 1.8081332\ttotal: 14.3s\tremaining: 594ms\n",
      "960:\tlearn: 1.8080333\ttotal: 14.3s\tremaining: 580ms\n",
      "961:\tlearn: 1.8080219\ttotal: 14.3s\tremaining: 565ms\n",
      "962:\tlearn: 1.8080213\ttotal: 14.3s\tremaining: 550ms\n",
      "963:\tlearn: 1.8080074\ttotal: 14.3s\tremaining: 535ms\n",
      "964:\tlearn: 1.8080059\ttotal: 14.3s\tremaining: 520ms\n",
      "965:\tlearn: 1.8079920\ttotal: 14.4s\tremaining: 505ms\n",
      "966:\tlearn: 1.8074702\ttotal: 14.4s\tremaining: 490ms\n",
      "967:\tlearn: 1.8067497\ttotal: 14.4s\tremaining: 475ms\n",
      "968:\tlearn: 1.8067468\ttotal: 14.4s\tremaining: 461ms\n",
      "969:\tlearn: 1.8067449\ttotal: 14.4s\tremaining: 446ms\n",
      "970:\tlearn: 1.8067411\ttotal: 14.4s\tremaining: 431ms\n",
      "971:\tlearn: 1.8067402\ttotal: 14.4s\tremaining: 416ms\n",
      "972:\tlearn: 1.8066277\ttotal: 14.5s\tremaining: 401ms\n",
      "973:\tlearn: 1.8064740\ttotal: 14.5s\tremaining: 386ms\n",
      "974:\tlearn: 1.8064686\ttotal: 14.5s\tremaining: 371ms\n",
      "975:\tlearn: 1.8064682\ttotal: 14.5s\tremaining: 357ms\n",
      "976:\tlearn: 1.8064383\ttotal: 14.5s\tremaining: 342ms\n",
      "977:\tlearn: 1.8064383\ttotal: 14.5s\tremaining: 327ms\n",
      "978:\tlearn: 1.8064171\ttotal: 14.5s\tremaining: 312ms\n",
      "979:\tlearn: 1.8064170\ttotal: 14.6s\tremaining: 297ms\n",
      "980:\tlearn: 1.8064139\ttotal: 14.6s\tremaining: 282ms\n",
      "981:\tlearn: 1.8063991\ttotal: 14.6s\tremaining: 267ms\n",
      "982:\tlearn: 1.8055813\ttotal: 14.6s\tremaining: 253ms\n",
      "983:\tlearn: 1.8048597\ttotal: 14.6s\tremaining: 238ms\n",
      "984:\tlearn: 1.8047513\ttotal: 14.6s\tremaining: 223ms\n",
      "985:\tlearn: 1.8045777\ttotal: 14.6s\tremaining: 208ms\n",
      "986:\tlearn: 1.8038675\ttotal: 14.7s\tremaining: 193ms\n",
      "987:\tlearn: 1.8035382\ttotal: 14.7s\tremaining: 178ms\n",
      "988:\tlearn: 1.8028694\ttotal: 14.7s\tremaining: 163ms\n",
      "989:\tlearn: 1.8026760\ttotal: 14.7s\tremaining: 149ms\n",
      "990:\tlearn: 1.8023660\ttotal: 14.7s\tremaining: 134ms\n",
      "991:\tlearn: 1.8022051\ttotal: 14.7s\tremaining: 119ms\n",
      "992:\tlearn: 1.8014745\ttotal: 14.7s\tremaining: 104ms\n",
      "993:\tlearn: 1.8012603\ttotal: 14.8s\tremaining: 89.1ms\n",
      "994:\tlearn: 1.8012601\ttotal: 14.8s\tremaining: 74.3ms\n",
      "995:\tlearn: 1.8012580\ttotal: 14.8s\tremaining: 59.4ms\n",
      "996:\tlearn: 1.8012347\ttotal: 14.8s\tremaining: 44.5ms\n",
      "997:\tlearn: 1.8012102\ttotal: 14.8s\tremaining: 29.7ms\n",
      "998:\tlearn: 1.8009059\ttotal: 14.8s\tremaining: 14.8ms\n",
      "999:\tlearn: 1.8008232\ttotal: 14.8s\tremaining: 0us\n",
      "0:\tlearn: 10.0031048\ttotal: 17.6ms\tremaining: 17.6s\n",
      "1:\tlearn: 9.2579120\ttotal: 35.5ms\tremaining: 17.7s\n",
      "2:\tlearn: 8.5579824\ttotal: 54.4ms\tremaining: 18.1s\n",
      "3:\tlearn: 7.7973883\ttotal: 72.7ms\tremaining: 18.1s\n",
      "4:\tlearn: 7.1465675\ttotal: 91.2ms\tremaining: 18.2s\n",
      "5:\tlearn: 6.6822942\ttotal: 109ms\tremaining: 18s\n",
      "6:\tlearn: 6.1654339\ttotal: 126ms\tremaining: 17.9s\n",
      "7:\tlearn: 5.7092116\ttotal: 145ms\tremaining: 17.9s\n",
      "8:\tlearn: 5.2695716\ttotal: 162ms\tremaining: 17.8s\n",
      "9:\tlearn: 4.8902153\ttotal: 179ms\tremaining: 17.8s\n",
      "10:\tlearn: 4.5998959\ttotal: 197ms\tremaining: 17.7s\n",
      "11:\tlearn: 4.3767025\ttotal: 215ms\tremaining: 17.7s\n",
      "12:\tlearn: 4.1100601\ttotal: 233ms\tremaining: 17.7s\n",
      "13:\tlearn: 3.8974456\ttotal: 250ms\tremaining: 17.6s\n",
      "14:\tlearn: 3.6927632\ttotal: 267ms\tremaining: 17.5s\n",
      "15:\tlearn: 3.5671854\ttotal: 285ms\tremaining: 17.5s\n",
      "16:\tlearn: 3.4608092\ttotal: 303ms\tremaining: 17.5s\n",
      "17:\tlearn: 3.3115412\ttotal: 320ms\tremaining: 17.5s\n",
      "18:\tlearn: 3.2276489\ttotal: 338ms\tremaining: 17.4s\n",
      "19:\tlearn: 3.1025997\ttotal: 355ms\tremaining: 17.4s\n",
      "20:\tlearn: 3.0455977\ttotal: 372ms\tremaining: 17.3s\n",
      "21:\tlearn: 2.9910043\ttotal: 389ms\tremaining: 17.3s\n",
      "22:\tlearn: 2.9325953\ttotal: 407ms\tremaining: 17.3s\n",
      "23:\tlearn: 2.8847060\ttotal: 424ms\tremaining: 17.2s\n",
      "24:\tlearn: 2.8135043\ttotal: 442ms\tremaining: 17.2s\n",
      "25:\tlearn: 2.7529540\ttotal: 459ms\tremaining: 17.2s\n",
      "26:\tlearn: 2.7265103\ttotal: 476ms\tremaining: 17.1s\n",
      "27:\tlearn: 2.6974741\ttotal: 493ms\tremaining: 17.1s\n",
      "28:\tlearn: 2.6517812\ttotal: 509ms\tremaining: 17s\n",
      "29:\tlearn: 2.6038499\ttotal: 526ms\tremaining: 17s\n",
      "30:\tlearn: 2.5652697\ttotal: 544ms\tremaining: 17s\n",
      "31:\tlearn: 2.5509696\ttotal: 560ms\tremaining: 17s\n",
      "32:\tlearn: 2.5251295\ttotal: 577ms\tremaining: 16.9s\n",
      "33:\tlearn: 2.4939697\ttotal: 593ms\tremaining: 16.9s\n",
      "34:\tlearn: 2.4826367\ttotal: 610ms\tremaining: 16.8s\n",
      "35:\tlearn: 2.4663961\ttotal: 628ms\tremaining: 16.8s\n",
      "36:\tlearn: 2.4460968\ttotal: 645ms\tremaining: 16.8s\n",
      "37:\tlearn: 2.4342356\ttotal: 662ms\tremaining: 16.8s\n",
      "38:\tlearn: 2.4123594\ttotal: 679ms\tremaining: 16.7s\n",
      "39:\tlearn: 2.4059848\ttotal: 695ms\tremaining: 16.7s\n",
      "40:\tlearn: 2.3853628\ttotal: 712ms\tremaining: 16.7s\n",
      "41:\tlearn: 2.3786275\ttotal: 729ms\tremaining: 16.6s\n",
      "42:\tlearn: 2.3742441\ttotal: 745ms\tremaining: 16.6s\n",
      "43:\tlearn: 2.3706696\ttotal: 762ms\tremaining: 16.5s\n",
      "44:\tlearn: 2.3681586\ttotal: 778ms\tremaining: 16.5s\n",
      "45:\tlearn: 2.3653708\ttotal: 795ms\tremaining: 16.5s\n",
      "46:\tlearn: 2.3510739\ttotal: 811ms\tremaining: 16.5s\n",
      "47:\tlearn: 2.3490245\ttotal: 828ms\tremaining: 16.4s\n",
      "48:\tlearn: 2.3443773\ttotal: 845ms\tremaining: 16.4s\n",
      "49:\tlearn: 2.3416225\ttotal: 861ms\tremaining: 16.4s\n",
      "50:\tlearn: 2.3402084\ttotal: 878ms\tremaining: 16.3s\n",
      "51:\tlearn: 2.3367238\ttotal: 894ms\tremaining: 16.3s\n",
      "52:\tlearn: 2.3362767\ttotal: 910ms\tremaining: 16.3s\n",
      "53:\tlearn: 2.3347297\ttotal: 926ms\tremaining: 16.2s\n",
      "54:\tlearn: 2.3293298\ttotal: 943ms\tremaining: 16.2s\n",
      "55:\tlearn: 2.3125877\ttotal: 960ms\tremaining: 16.2s\n",
      "56:\tlearn: 2.3092081\ttotal: 977ms\tremaining: 16.2s\n",
      "57:\tlearn: 2.3079260\ttotal: 994ms\tremaining: 16.1s\n",
      "58:\tlearn: 2.3070280\ttotal: 1.01s\tremaining: 16.1s\n",
      "59:\tlearn: 2.3055902\ttotal: 1.02s\tremaining: 16.1s\n",
      "60:\tlearn: 2.3053519\ttotal: 1.04s\tremaining: 16s\n",
      "61:\tlearn: 2.3045030\ttotal: 1.06s\tremaining: 16s\n",
      "62:\tlearn: 2.2994339\ttotal: 1.07s\tremaining: 16s\n",
      "63:\tlearn: 2.2976378\ttotal: 1.09s\tremaining: 16s\n",
      "64:\tlearn: 2.2973013\ttotal: 1.11s\tremaining: 15.9s\n",
      "65:\tlearn: 2.2960546\ttotal: 1.12s\tremaining: 15.9s\n",
      "66:\tlearn: 2.2952996\ttotal: 1.14s\tremaining: 15.9s\n",
      "67:\tlearn: 2.2899753\ttotal: 1.15s\tremaining: 15.8s\n",
      "68:\tlearn: 2.2891351\ttotal: 1.17s\tremaining: 15.8s\n",
      "69:\tlearn: 2.2878145\ttotal: 1.19s\tremaining: 15.8s\n",
      "70:\tlearn: 2.2874240\ttotal: 1.2s\tremaining: 15.7s\n",
      "71:\tlearn: 2.2873157\ttotal: 1.22s\tremaining: 15.7s\n",
      "72:\tlearn: 2.2866132\ttotal: 1.23s\tremaining: 15.7s\n",
      "73:\tlearn: 2.2839591\ttotal: 1.25s\tremaining: 15.6s\n",
      "74:\tlearn: 2.2834071\ttotal: 1.27s\tremaining: 15.6s\n",
      "75:\tlearn: 2.2824198\ttotal: 1.28s\tremaining: 15.6s\n",
      "76:\tlearn: 2.2807992\ttotal: 1.3s\tremaining: 15.6s\n",
      "77:\tlearn: 2.2802602\ttotal: 1.32s\tremaining: 15.6s\n",
      "78:\tlearn: 2.2796089\ttotal: 1.33s\tremaining: 15.5s\n",
      "79:\tlearn: 2.2794207\ttotal: 1.35s\tremaining: 15.5s\n",
      "80:\tlearn: 2.2709881\ttotal: 1.36s\tremaining: 15.5s\n",
      "81:\tlearn: 2.2700574\ttotal: 1.38s\tremaining: 15.5s\n",
      "82:\tlearn: 2.2695059\ttotal: 1.4s\tremaining: 15.4s\n",
      "83:\tlearn: 2.2691392\ttotal: 1.41s\tremaining: 15.4s\n",
      "84:\tlearn: 2.2655326\ttotal: 1.43s\tremaining: 15.4s\n",
      "85:\tlearn: 2.2651670\ttotal: 1.44s\tremaining: 15.3s\n",
      "86:\tlearn: 2.2648784\ttotal: 1.46s\tremaining: 15.3s\n",
      "87:\tlearn: 2.2637748\ttotal: 1.48s\tremaining: 15.3s\n",
      "88:\tlearn: 2.2627500\ttotal: 1.49s\tremaining: 15.3s\n",
      "89:\tlearn: 2.2611788\ttotal: 1.51s\tremaining: 15.2s\n",
      "90:\tlearn: 2.2610666\ttotal: 1.52s\tremaining: 15.2s\n",
      "91:\tlearn: 2.2551351\ttotal: 1.54s\tremaining: 15.2s\n",
      "92:\tlearn: 2.2548086\ttotal: 1.56s\tremaining: 15.2s\n",
      "93:\tlearn: 2.2547611\ttotal: 1.57s\tremaining: 15.1s\n",
      "94:\tlearn: 2.2529804\ttotal: 1.59s\tremaining: 15.1s\n",
      "95:\tlearn: 2.2519643\ttotal: 1.6s\tremaining: 15.1s\n",
      "96:\tlearn: 2.2517909\ttotal: 1.62s\tremaining: 15.1s\n",
      "97:\tlearn: 2.2499806\ttotal: 1.63s\tremaining: 15s\n",
      "98:\tlearn: 2.2497949\ttotal: 1.65s\tremaining: 15s\n",
      "99:\tlearn: 2.2492172\ttotal: 1.66s\tremaining: 15s\n",
      "100:\tlearn: 2.2491359\ttotal: 1.67s\tremaining: 14.9s\n",
      "101:\tlearn: 2.2490506\ttotal: 1.69s\tremaining: 14.9s\n",
      "102:\tlearn: 2.2478261\ttotal: 1.7s\tremaining: 14.8s\n",
      "103:\tlearn: 2.2467951\ttotal: 1.72s\tremaining: 14.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104:\tlearn: 2.2463983\ttotal: 1.74s\tremaining: 14.8s\n",
      "105:\tlearn: 2.2454108\ttotal: 1.75s\tremaining: 14.8s\n",
      "106:\tlearn: 2.2436141\ttotal: 1.77s\tremaining: 14.7s\n",
      "107:\tlearn: 2.2427107\ttotal: 1.78s\tremaining: 14.7s\n",
      "108:\tlearn: 2.2424464\ttotal: 1.79s\tremaining: 14.7s\n",
      "109:\tlearn: 2.2413955\ttotal: 1.81s\tremaining: 14.6s\n",
      "110:\tlearn: 2.2407716\ttotal: 1.82s\tremaining: 14.6s\n",
      "111:\tlearn: 2.2406448\ttotal: 1.84s\tremaining: 14.6s\n",
      "112:\tlearn: 2.2386700\ttotal: 1.85s\tremaining: 14.6s\n",
      "113:\tlearn: 2.2334367\ttotal: 1.87s\tremaining: 14.5s\n",
      "114:\tlearn: 2.2295623\ttotal: 1.89s\tremaining: 14.5s\n",
      "115:\tlearn: 2.2294650\ttotal: 1.9s\tremaining: 14.5s\n",
      "116:\tlearn: 2.2287042\ttotal: 1.92s\tremaining: 14.5s\n",
      "117:\tlearn: 2.2252738\ttotal: 1.93s\tremaining: 14.4s\n",
      "118:\tlearn: 2.2212250\ttotal: 1.95s\tremaining: 14.4s\n",
      "119:\tlearn: 2.2185070\ttotal: 1.96s\tremaining: 14.4s\n",
      "120:\tlearn: 2.2179863\ttotal: 1.98s\tremaining: 14.4s\n",
      "121:\tlearn: 2.2152700\ttotal: 1.99s\tremaining: 14.3s\n",
      "122:\tlearn: 2.2146909\ttotal: 2.01s\tremaining: 14.3s\n",
      "123:\tlearn: 2.2138721\ttotal: 2.02s\tremaining: 14.3s\n",
      "124:\tlearn: 2.2133639\ttotal: 2.03s\tremaining: 14.2s\n",
      "125:\tlearn: 2.2132498\ttotal: 2.05s\tremaining: 14.2s\n",
      "126:\tlearn: 2.2106645\ttotal: 2.06s\tremaining: 14.2s\n",
      "127:\tlearn: 2.2100561\ttotal: 2.08s\tremaining: 14.2s\n",
      "128:\tlearn: 2.2096831\ttotal: 2.09s\tremaining: 14.1s\n",
      "129:\tlearn: 2.2082605\ttotal: 2.11s\tremaining: 14.1s\n",
      "130:\tlearn: 2.2073188\ttotal: 2.12s\tremaining: 14.1s\n",
      "131:\tlearn: 2.2031188\ttotal: 2.14s\tremaining: 14.1s\n",
      "132:\tlearn: 2.1984407\ttotal: 2.15s\tremaining: 14s\n",
      "133:\tlearn: 2.1929272\ttotal: 2.17s\tremaining: 14s\n",
      "134:\tlearn: 2.1894852\ttotal: 2.19s\tremaining: 14s\n",
      "135:\tlearn: 2.1871495\ttotal: 2.2s\tremaining: 14s\n",
      "136:\tlearn: 2.1866185\ttotal: 2.22s\tremaining: 14s\n",
      "137:\tlearn: 2.1861257\ttotal: 2.23s\tremaining: 13.9s\n",
      "138:\tlearn: 2.1832371\ttotal: 2.25s\tremaining: 13.9s\n",
      "139:\tlearn: 2.1827582\ttotal: 2.26s\tremaining: 13.9s\n",
      "140:\tlearn: 2.1804017\ttotal: 2.28s\tremaining: 13.9s\n",
      "141:\tlearn: 2.1798179\ttotal: 2.3s\tremaining: 13.9s\n",
      "142:\tlearn: 2.1791606\ttotal: 2.31s\tremaining: 13.9s\n",
      "143:\tlearn: 2.1786897\ttotal: 2.33s\tremaining: 13.8s\n",
      "144:\tlearn: 2.1771216\ttotal: 2.34s\tremaining: 13.8s\n",
      "145:\tlearn: 2.1766458\ttotal: 2.36s\tremaining: 13.8s\n",
      "146:\tlearn: 2.1730486\ttotal: 2.37s\tremaining: 13.8s\n",
      "147:\tlearn: 2.1720036\ttotal: 2.39s\tremaining: 13.8s\n",
      "148:\tlearn: 2.1706125\ttotal: 2.4s\tremaining: 13.7s\n",
      "149:\tlearn: 2.1665456\ttotal: 2.42s\tremaining: 13.7s\n",
      "150:\tlearn: 2.1640280\ttotal: 2.43s\tremaining: 13.7s\n",
      "151:\tlearn: 2.1614209\ttotal: 2.45s\tremaining: 13.7s\n",
      "152:\tlearn: 2.1588057\ttotal: 2.46s\tremaining: 13.6s\n",
      "153:\tlearn: 2.1543540\ttotal: 2.47s\tremaining: 13.6s\n",
      "154:\tlearn: 2.1519770\ttotal: 2.49s\tremaining: 13.6s\n",
      "155:\tlearn: 2.1499534\ttotal: 2.5s\tremaining: 13.6s\n",
      "156:\tlearn: 2.1466910\ttotal: 2.52s\tremaining: 13.5s\n",
      "157:\tlearn: 2.1429309\ttotal: 2.53s\tremaining: 13.5s\n",
      "158:\tlearn: 2.1411978\ttotal: 2.55s\tremaining: 13.5s\n",
      "159:\tlearn: 2.1403012\ttotal: 2.56s\tremaining: 13.5s\n",
      "160:\tlearn: 2.1383890\ttotal: 2.58s\tremaining: 13.4s\n",
      "161:\tlearn: 2.1371412\ttotal: 2.59s\tremaining: 13.4s\n",
      "162:\tlearn: 2.1349387\ttotal: 2.61s\tremaining: 13.4s\n",
      "163:\tlearn: 2.1315089\ttotal: 2.63s\tremaining: 13.4s\n",
      "164:\tlearn: 2.1281642\ttotal: 2.64s\tremaining: 13.4s\n",
      "165:\tlearn: 2.1239776\ttotal: 2.66s\tremaining: 13.3s\n",
      "166:\tlearn: 2.1204323\ttotal: 2.67s\tremaining: 13.3s\n",
      "167:\tlearn: 2.1170089\ttotal: 2.69s\tremaining: 13.3s\n",
      "168:\tlearn: 2.1122890\ttotal: 2.7s\tremaining: 13.3s\n",
      "169:\tlearn: 2.1104240\ttotal: 2.71s\tremaining: 13.3s\n",
      "170:\tlearn: 2.1082935\ttotal: 2.73s\tremaining: 13.2s\n",
      "171:\tlearn: 2.1062743\ttotal: 2.75s\tremaining: 13.2s\n",
      "172:\tlearn: 2.1044071\ttotal: 2.76s\tremaining: 13.2s\n",
      "173:\tlearn: 2.1022314\ttotal: 2.78s\tremaining: 13.2s\n",
      "174:\tlearn: 2.0979042\ttotal: 2.79s\tremaining: 13.2s\n",
      "175:\tlearn: 2.0968087\ttotal: 2.81s\tremaining: 13.1s\n",
      "176:\tlearn: 2.0957238\ttotal: 2.82s\tremaining: 13.1s\n",
      "177:\tlearn: 2.0952297\ttotal: 2.84s\tremaining: 13.1s\n",
      "178:\tlearn: 2.0945908\ttotal: 2.85s\tremaining: 13.1s\n",
      "179:\tlearn: 2.0935040\ttotal: 2.87s\tremaining: 13.1s\n",
      "180:\tlearn: 2.0913661\ttotal: 2.88s\tremaining: 13s\n",
      "181:\tlearn: 2.0900289\ttotal: 2.9s\tremaining: 13s\n",
      "182:\tlearn: 2.0888955\ttotal: 2.91s\tremaining: 13s\n",
      "183:\tlearn: 2.0881790\ttotal: 2.93s\tremaining: 13s\n",
      "184:\tlearn: 2.0862909\ttotal: 2.94s\tremaining: 13s\n",
      "185:\tlearn: 2.0837377\ttotal: 2.96s\tremaining: 12.9s\n",
      "186:\tlearn: 2.0815106\ttotal: 2.97s\tremaining: 12.9s\n",
      "187:\tlearn: 2.0797962\ttotal: 2.99s\tremaining: 12.9s\n",
      "188:\tlearn: 2.0782097\ttotal: 3s\tremaining: 12.9s\n",
      "189:\tlearn: 2.0770009\ttotal: 3.02s\tremaining: 12.9s\n",
      "190:\tlearn: 2.0754481\ttotal: 3.04s\tremaining: 12.9s\n",
      "191:\tlearn: 2.0748472\ttotal: 3.05s\tremaining: 12.8s\n",
      "192:\tlearn: 2.0727394\ttotal: 3.06s\tremaining: 12.8s\n",
      "193:\tlearn: 2.0718567\ttotal: 3.08s\tremaining: 12.8s\n",
      "194:\tlearn: 2.0705184\ttotal: 3.09s\tremaining: 12.8s\n",
      "195:\tlearn: 2.0703062\ttotal: 3.11s\tremaining: 12.8s\n",
      "196:\tlearn: 2.0690025\ttotal: 3.13s\tremaining: 12.7s\n",
      "197:\tlearn: 2.0687180\ttotal: 3.14s\tremaining: 12.7s\n",
      "198:\tlearn: 2.0676511\ttotal: 3.15s\tremaining: 12.7s\n",
      "199:\tlearn: 2.0655948\ttotal: 3.17s\tremaining: 12.7s\n",
      "200:\tlearn: 2.0629082\ttotal: 3.18s\tremaining: 12.7s\n",
      "201:\tlearn: 2.0604110\ttotal: 3.2s\tremaining: 12.6s\n",
      "202:\tlearn: 2.0578015\ttotal: 3.21s\tremaining: 12.6s\n",
      "203:\tlearn: 2.0549372\ttotal: 3.23s\tremaining: 12.6s\n",
      "204:\tlearn: 2.0531809\ttotal: 3.25s\tremaining: 12.6s\n",
      "205:\tlearn: 2.0513905\ttotal: 3.26s\tremaining: 12.6s\n",
      "206:\tlearn: 2.0505609\ttotal: 3.27s\tremaining: 12.5s\n",
      "207:\tlearn: 2.0497593\ttotal: 3.29s\tremaining: 12.5s\n",
      "208:\tlearn: 2.0486367\ttotal: 3.3s\tremaining: 12.5s\n",
      "209:\tlearn: 2.0470014\ttotal: 3.32s\tremaining: 12.5s\n",
      "210:\tlearn: 2.0452643\ttotal: 3.33s\tremaining: 12.5s\n",
      "211:\tlearn: 2.0436783\ttotal: 3.35s\tremaining: 12.5s\n",
      "212:\tlearn: 2.0425269\ttotal: 3.37s\tremaining: 12.4s\n",
      "213:\tlearn: 2.0419615\ttotal: 3.38s\tremaining: 12.4s\n",
      "214:\tlearn: 2.0415392\ttotal: 3.4s\tremaining: 12.4s\n",
      "215:\tlearn: 2.0412156\ttotal: 3.41s\tremaining: 12.4s\n",
      "216:\tlearn: 2.0398884\ttotal: 3.42s\tremaining: 12.4s\n",
      "217:\tlearn: 2.0390148\ttotal: 3.44s\tremaining: 12.3s\n",
      "218:\tlearn: 2.0385559\ttotal: 3.45s\tremaining: 12.3s\n",
      "219:\tlearn: 2.0375774\ttotal: 3.47s\tremaining: 12.3s\n",
      "220:\tlearn: 2.0364218\ttotal: 3.48s\tremaining: 12.3s\n",
      "221:\tlearn: 2.0351347\ttotal: 3.5s\tremaining: 12.3s\n",
      "222:\tlearn: 2.0349622\ttotal: 3.51s\tremaining: 12.2s\n",
      "223:\tlearn: 2.0341101\ttotal: 3.53s\tremaining: 12.2s\n",
      "224:\tlearn: 2.0334369\ttotal: 3.54s\tremaining: 12.2s\n",
      "225:\tlearn: 2.0330842\ttotal: 3.56s\tremaining: 12.2s\n",
      "226:\tlearn: 2.0326596\ttotal: 3.57s\tremaining: 12.2s\n",
      "227:\tlearn: 2.0319656\ttotal: 3.59s\tremaining: 12.1s\n",
      "228:\tlearn: 2.0314821\ttotal: 3.6s\tremaining: 12.1s\n",
      "229:\tlearn: 2.0306395\ttotal: 3.62s\tremaining: 12.1s\n",
      "230:\tlearn: 2.0298926\ttotal: 3.63s\tremaining: 12.1s\n",
      "231:\tlearn: 2.0278186\ttotal: 3.65s\tremaining: 12.1s\n",
      "232:\tlearn: 2.0259225\ttotal: 3.66s\tremaining: 12.1s\n",
      "233:\tlearn: 2.0248487\ttotal: 3.68s\tremaining: 12s\n",
      "234:\tlearn: 2.0240073\ttotal: 3.69s\tremaining: 12s\n",
      "235:\tlearn: 2.0214269\ttotal: 3.71s\tremaining: 12s\n",
      "236:\tlearn: 2.0191038\ttotal: 3.72s\tremaining: 12s\n",
      "237:\tlearn: 2.0171745\ttotal: 3.74s\tremaining: 12s\n",
      "238:\tlearn: 2.0149268\ttotal: 3.75s\tremaining: 11.9s\n",
      "239:\tlearn: 2.0139310\ttotal: 3.77s\tremaining: 11.9s\n",
      "240:\tlearn: 2.0127110\ttotal: 3.78s\tremaining: 11.9s\n",
      "241:\tlearn: 2.0114389\ttotal: 3.8s\tremaining: 11.9s\n",
      "242:\tlearn: 2.0110192\ttotal: 3.81s\tremaining: 11.9s\n",
      "243:\tlearn: 2.0104708\ttotal: 3.83s\tremaining: 11.9s\n",
      "244:\tlearn: 2.0100075\ttotal: 3.84s\tremaining: 11.8s\n",
      "245:\tlearn: 2.0094155\ttotal: 3.85s\tremaining: 11.8s\n",
      "246:\tlearn: 2.0092348\ttotal: 3.87s\tremaining: 11.8s\n",
      "247:\tlearn: 2.0090892\ttotal: 3.88s\tremaining: 11.8s\n",
      "248:\tlearn: 2.0088939\ttotal: 3.9s\tremaining: 11.8s\n",
      "249:\tlearn: 2.0084144\ttotal: 3.92s\tremaining: 11.7s\n",
      "250:\tlearn: 2.0081099\ttotal: 3.93s\tremaining: 11.7s\n",
      "251:\tlearn: 2.0067067\ttotal: 3.95s\tremaining: 11.7s\n",
      "252:\tlearn: 2.0059706\ttotal: 3.96s\tremaining: 11.7s\n",
      "253:\tlearn: 2.0049933\ttotal: 3.98s\tremaining: 11.7s\n",
      "254:\tlearn: 2.0041927\ttotal: 3.99s\tremaining: 11.7s\n",
      "255:\tlearn: 2.0036071\ttotal: 4.01s\tremaining: 11.6s\n",
      "256:\tlearn: 2.0033045\ttotal: 4.02s\tremaining: 11.6s\n",
      "257:\tlearn: 2.0030127\ttotal: 4.04s\tremaining: 11.6s\n",
      "258:\tlearn: 2.0023393\ttotal: 4.05s\tremaining: 11.6s\n",
      "259:\tlearn: 2.0017260\ttotal: 4.06s\tremaining: 11.6s\n",
      "260:\tlearn: 2.0014946\ttotal: 4.08s\tremaining: 11.5s\n",
      "261:\tlearn: 2.0012260\ttotal: 4.09s\tremaining: 11.5s\n",
      "262:\tlearn: 1.9996862\ttotal: 4.11s\tremaining: 11.5s\n",
      "263:\tlearn: 1.9996074\ttotal: 4.12s\tremaining: 11.5s\n",
      "264:\tlearn: 1.9990841\ttotal: 4.14s\tremaining: 11.5s\n",
      "265:\tlearn: 1.9980825\ttotal: 4.15s\tremaining: 11.5s\n",
      "266:\tlearn: 1.9976241\ttotal: 4.17s\tremaining: 11.4s\n",
      "267:\tlearn: 1.9973521\ttotal: 4.18s\tremaining: 11.4s\n",
      "268:\tlearn: 1.9971134\ttotal: 4.2s\tremaining: 11.4s\n",
      "269:\tlearn: 1.9966480\ttotal: 4.21s\tremaining: 11.4s\n",
      "270:\tlearn: 1.9963880\ttotal: 4.22s\tremaining: 11.4s\n",
      "271:\tlearn: 1.9960225\ttotal: 4.24s\tremaining: 11.3s\n",
      "272:\tlearn: 1.9960179\ttotal: 4.25s\tremaining: 11.3s\n",
      "273:\tlearn: 1.9959575\ttotal: 4.27s\tremaining: 11.3s\n",
      "274:\tlearn: 1.9959010\ttotal: 4.28s\tremaining: 11.3s\n",
      "275:\tlearn: 1.9958508\ttotal: 4.3s\tremaining: 11.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276:\tlearn: 1.9956780\ttotal: 4.31s\tremaining: 11.3s\n",
      "277:\tlearn: 1.9954662\ttotal: 4.33s\tremaining: 11.2s\n",
      "278:\tlearn: 1.9951334\ttotal: 4.34s\tremaining: 11.2s\n",
      "279:\tlearn: 1.9950337\ttotal: 4.36s\tremaining: 11.2s\n",
      "280:\tlearn: 1.9949466\ttotal: 4.37s\tremaining: 11.2s\n",
      "281:\tlearn: 1.9944749\ttotal: 4.39s\tremaining: 11.2s\n",
      "282:\tlearn: 1.9943120\ttotal: 4.4s\tremaining: 11.2s\n",
      "283:\tlearn: 1.9942869\ttotal: 4.42s\tremaining: 11.1s\n",
      "284:\tlearn: 1.9942312\ttotal: 4.43s\tremaining: 11.1s\n",
      "285:\tlearn: 1.9942005\ttotal: 4.45s\tremaining: 11.1s\n",
      "286:\tlearn: 1.9941182\ttotal: 4.46s\tremaining: 11.1s\n",
      "287:\tlearn: 1.9940599\ttotal: 4.48s\tremaining: 11.1s\n",
      "288:\tlearn: 1.9940205\ttotal: 4.49s\tremaining: 11.1s\n",
      "289:\tlearn: 1.9938073\ttotal: 4.51s\tremaining: 11s\n",
      "290:\tlearn: 1.9937161\ttotal: 4.52s\tremaining: 11s\n",
      "291:\tlearn: 1.9935541\ttotal: 4.54s\tremaining: 11s\n",
      "292:\tlearn: 1.9934987\ttotal: 4.55s\tremaining: 11s\n",
      "293:\tlearn: 1.9923725\ttotal: 4.57s\tremaining: 11s\n",
      "294:\tlearn: 1.9922155\ttotal: 4.58s\tremaining: 10.9s\n",
      "295:\tlearn: 1.9914884\ttotal: 4.6s\tremaining: 10.9s\n",
      "296:\tlearn: 1.9912536\ttotal: 4.61s\tremaining: 10.9s\n",
      "297:\tlearn: 1.9887652\ttotal: 4.63s\tremaining: 10.9s\n",
      "298:\tlearn: 1.9878122\ttotal: 4.64s\tremaining: 10.9s\n",
      "299:\tlearn: 1.9876883\ttotal: 4.66s\tremaining: 10.9s\n",
      "300:\tlearn: 1.9874751\ttotal: 4.67s\tremaining: 10.8s\n",
      "301:\tlearn: 1.9863446\ttotal: 4.68s\tremaining: 10.8s\n",
      "302:\tlearn: 1.9848154\ttotal: 4.7s\tremaining: 10.8s\n",
      "303:\tlearn: 1.9841600\ttotal: 4.72s\tremaining: 10.8s\n",
      "304:\tlearn: 1.9830413\ttotal: 4.74s\tremaining: 10.8s\n",
      "305:\tlearn: 1.9828839\ttotal: 4.75s\tremaining: 10.8s\n",
      "306:\tlearn: 1.9821305\ttotal: 4.77s\tremaining: 10.8s\n",
      "307:\tlearn: 1.9821305\ttotal: 4.79s\tremaining: 10.8s\n",
      "308:\tlearn: 1.9821157\ttotal: 4.8s\tremaining: 10.7s\n",
      "309:\tlearn: 1.9811686\ttotal: 4.82s\tremaining: 10.7s\n",
      "310:\tlearn: 1.9803885\ttotal: 4.83s\tremaining: 10.7s\n",
      "311:\tlearn: 1.9800488\ttotal: 4.84s\tremaining: 10.7s\n",
      "312:\tlearn: 1.9787334\ttotal: 4.86s\tremaining: 10.7s\n",
      "313:\tlearn: 1.9774994\ttotal: 4.87s\tremaining: 10.6s\n",
      "314:\tlearn: 1.9770739\ttotal: 4.89s\tremaining: 10.6s\n",
      "315:\tlearn: 1.9770419\ttotal: 4.9s\tremaining: 10.6s\n",
      "316:\tlearn: 1.9761067\ttotal: 4.92s\tremaining: 10.6s\n",
      "317:\tlearn: 1.9759958\ttotal: 4.93s\tremaining: 10.6s\n",
      "318:\tlearn: 1.9755496\ttotal: 4.95s\tremaining: 10.6s\n",
      "319:\tlearn: 1.9752008\ttotal: 4.97s\tremaining: 10.6s\n",
      "320:\tlearn: 1.9737748\ttotal: 4.98s\tremaining: 10.5s\n",
      "321:\tlearn: 1.9711813\ttotal: 5s\tremaining: 10.5s\n",
      "322:\tlearn: 1.9706481\ttotal: 5.01s\tremaining: 10.5s\n",
      "323:\tlearn: 1.9706448\ttotal: 5.03s\tremaining: 10.5s\n",
      "324:\tlearn: 1.9706424\ttotal: 5.04s\tremaining: 10.5s\n",
      "325:\tlearn: 1.9706404\ttotal: 5.05s\tremaining: 10.4s\n",
      "326:\tlearn: 1.9704994\ttotal: 5.07s\tremaining: 10.4s\n",
      "327:\tlearn: 1.9704896\ttotal: 5.08s\tremaining: 10.4s\n",
      "328:\tlearn: 1.9703655\ttotal: 5.1s\tremaining: 10.4s\n",
      "329:\tlearn: 1.9682389\ttotal: 5.11s\tremaining: 10.4s\n",
      "330:\tlearn: 1.9682349\ttotal: 5.13s\tremaining: 10.4s\n",
      "331:\tlearn: 1.9682095\ttotal: 5.14s\tremaining: 10.3s\n",
      "332:\tlearn: 1.9681169\ttotal: 5.16s\tremaining: 10.3s\n",
      "333:\tlearn: 1.9681089\ttotal: 5.17s\tremaining: 10.3s\n",
      "334:\tlearn: 1.9671917\ttotal: 5.19s\tremaining: 10.3s\n",
      "335:\tlearn: 1.9671432\ttotal: 5.2s\tremaining: 10.3s\n",
      "336:\tlearn: 1.9659360\ttotal: 5.22s\tremaining: 10.3s\n",
      "337:\tlearn: 1.9658878\ttotal: 5.23s\tremaining: 10.2s\n",
      "338:\tlearn: 1.9655605\ttotal: 5.25s\tremaining: 10.2s\n",
      "339:\tlearn: 1.9650493\ttotal: 5.26s\tremaining: 10.2s\n",
      "340:\tlearn: 1.9649398\ttotal: 5.28s\tremaining: 10.2s\n",
      "341:\tlearn: 1.9649221\ttotal: 5.29s\tremaining: 10.2s\n",
      "342:\tlearn: 1.9648740\ttotal: 5.3s\tremaining: 10.2s\n",
      "343:\tlearn: 1.9643429\ttotal: 5.32s\tremaining: 10.1s\n",
      "344:\tlearn: 1.9641934\ttotal: 5.33s\tremaining: 10.1s\n",
      "345:\tlearn: 1.9639176\ttotal: 5.35s\tremaining: 10.1s\n",
      "346:\tlearn: 1.9638158\ttotal: 5.36s\tremaining: 10.1s\n",
      "347:\tlearn: 1.9636613\ttotal: 5.38s\tremaining: 10.1s\n",
      "348:\tlearn: 1.9635104\ttotal: 5.39s\tremaining: 10.1s\n",
      "349:\tlearn: 1.9634292\ttotal: 5.4s\tremaining: 10s\n",
      "350:\tlearn: 1.9634220\ttotal: 5.42s\tremaining: 10s\n",
      "351:\tlearn: 1.9633508\ttotal: 5.43s\tremaining: 10s\n",
      "352:\tlearn: 1.9631598\ttotal: 5.45s\tremaining: 9.99s\n",
      "353:\tlearn: 1.9629245\ttotal: 5.46s\tremaining: 9.97s\n",
      "354:\tlearn: 1.9628695\ttotal: 5.48s\tremaining: 9.95s\n",
      "355:\tlearn: 1.9628361\ttotal: 5.49s\tremaining: 9.93s\n",
      "356:\tlearn: 1.9626932\ttotal: 5.5s\tremaining: 9.92s\n",
      "357:\tlearn: 1.9626537\ttotal: 5.52s\tremaining: 9.9s\n",
      "358:\tlearn: 1.9625369\ttotal: 5.54s\tremaining: 9.88s\n",
      "359:\tlearn: 1.9625024\ttotal: 5.55s\tremaining: 9.87s\n",
      "360:\tlearn: 1.9624750\ttotal: 5.57s\tremaining: 9.85s\n",
      "361:\tlearn: 1.9618190\ttotal: 5.58s\tremaining: 9.84s\n",
      "362:\tlearn: 1.9615015\ttotal: 5.6s\tremaining: 9.82s\n",
      "363:\tlearn: 1.9614432\ttotal: 5.61s\tremaining: 9.8s\n",
      "364:\tlearn: 1.9613641\ttotal: 5.63s\tremaining: 9.79s\n",
      "365:\tlearn: 1.9612697\ttotal: 5.64s\tremaining: 9.77s\n",
      "366:\tlearn: 1.9610069\ttotal: 5.66s\tremaining: 9.76s\n",
      "367:\tlearn: 1.9610040\ttotal: 5.67s\tremaining: 9.74s\n",
      "368:\tlearn: 1.9609822\ttotal: 5.68s\tremaining: 9.72s\n",
      "369:\tlearn: 1.9608549\ttotal: 5.7s\tremaining: 9.71s\n",
      "370:\tlearn: 1.9608452\ttotal: 5.71s\tremaining: 9.69s\n",
      "371:\tlearn: 1.9606477\ttotal: 5.73s\tremaining: 9.67s\n",
      "372:\tlearn: 1.9606388\ttotal: 5.74s\tremaining: 9.65s\n",
      "373:\tlearn: 1.9606246\ttotal: 5.76s\tremaining: 9.64s\n",
      "374:\tlearn: 1.9604559\ttotal: 5.77s\tremaining: 9.62s\n",
      "375:\tlearn: 1.9604548\ttotal: 5.79s\tremaining: 9.61s\n",
      "376:\tlearn: 1.9604295\ttotal: 5.82s\tremaining: 9.61s\n",
      "377:\tlearn: 1.9602071\ttotal: 5.83s\tremaining: 9.59s\n",
      "378:\tlearn: 1.9598609\ttotal: 5.84s\tremaining: 9.57s\n",
      "379:\tlearn: 1.9595224\ttotal: 5.86s\tremaining: 9.56s\n",
      "380:\tlearn: 1.9594521\ttotal: 5.87s\tremaining: 9.54s\n",
      "381:\tlearn: 1.9594459\ttotal: 5.88s\tremaining: 9.52s\n",
      "382:\tlearn: 1.9593734\ttotal: 5.9s\tremaining: 9.5s\n",
      "383:\tlearn: 1.9587036\ttotal: 5.91s\tremaining: 9.49s\n",
      "384:\tlearn: 1.9581371\ttotal: 5.93s\tremaining: 9.47s\n",
      "385:\tlearn: 1.9573841\ttotal: 5.94s\tremaining: 9.45s\n",
      "386:\tlearn: 1.9573793\ttotal: 5.96s\tremaining: 9.44s\n",
      "387:\tlearn: 1.9573782\ttotal: 5.97s\tremaining: 9.42s\n",
      "388:\tlearn: 1.9573592\ttotal: 5.99s\tremaining: 9.4s\n",
      "389:\tlearn: 1.9572232\ttotal: 6s\tremaining: 9.39s\n",
      "390:\tlearn: 1.9572048\ttotal: 6.02s\tremaining: 9.37s\n",
      "391:\tlearn: 1.9570465\ttotal: 6.03s\tremaining: 9.36s\n",
      "392:\tlearn: 1.9557910\ttotal: 6.05s\tremaining: 9.34s\n",
      "393:\tlearn: 1.9544236\ttotal: 6.06s\tremaining: 9.32s\n",
      "394:\tlearn: 1.9531159\ttotal: 6.08s\tremaining: 9.3s\n",
      "395:\tlearn: 1.9530402\ttotal: 6.09s\tremaining: 9.29s\n",
      "396:\tlearn: 1.9527545\ttotal: 6.11s\tremaining: 9.27s\n",
      "397:\tlearn: 1.9524924\ttotal: 6.12s\tremaining: 9.26s\n",
      "398:\tlearn: 1.9523530\ttotal: 6.13s\tremaining: 9.24s\n",
      "399:\tlearn: 1.9523351\ttotal: 6.15s\tremaining: 9.22s\n",
      "400:\tlearn: 1.9521186\ttotal: 6.16s\tremaining: 9.21s\n",
      "401:\tlearn: 1.9521073\ttotal: 6.18s\tremaining: 9.19s\n",
      "402:\tlearn: 1.9521032\ttotal: 6.19s\tremaining: 9.17s\n",
      "403:\tlearn: 1.9513733\ttotal: 6.21s\tremaining: 9.16s\n",
      "404:\tlearn: 1.9511739\ttotal: 6.22s\tremaining: 9.14s\n",
      "405:\tlearn: 1.9511739\ttotal: 6.24s\tremaining: 9.12s\n",
      "406:\tlearn: 1.9509908\ttotal: 6.25s\tremaining: 9.11s\n",
      "407:\tlearn: 1.9501718\ttotal: 6.26s\tremaining: 9.09s\n",
      "408:\tlearn: 1.9496270\ttotal: 6.29s\tremaining: 9.09s\n",
      "409:\tlearn: 1.9495355\ttotal: 6.31s\tremaining: 9.08s\n",
      "410:\tlearn: 1.9493529\ttotal: 6.33s\tremaining: 9.07s\n",
      "411:\tlearn: 1.9492652\ttotal: 6.34s\tremaining: 9.05s\n",
      "412:\tlearn: 1.9489619\ttotal: 6.36s\tremaining: 9.03s\n",
      "413:\tlearn: 1.9486969\ttotal: 6.37s\tremaining: 9.02s\n",
      "414:\tlearn: 1.9483041\ttotal: 6.38s\tremaining: 9s\n",
      "415:\tlearn: 1.9482567\ttotal: 6.4s\tremaining: 8.98s\n",
      "416:\tlearn: 1.9482171\ttotal: 6.41s\tremaining: 8.97s\n",
      "417:\tlearn: 1.9479196\ttotal: 6.43s\tremaining: 8.95s\n",
      "418:\tlearn: 1.9467878\ttotal: 6.44s\tremaining: 8.93s\n",
      "419:\tlearn: 1.9458068\ttotal: 6.46s\tremaining: 8.92s\n",
      "420:\tlearn: 1.9447856\ttotal: 6.47s\tremaining: 8.9s\n",
      "421:\tlearn: 1.9447797\ttotal: 6.49s\tremaining: 8.88s\n",
      "422:\tlearn: 1.9445520\ttotal: 6.5s\tremaining: 8.87s\n",
      "423:\tlearn: 1.9438945\ttotal: 6.52s\tremaining: 8.85s\n",
      "424:\tlearn: 1.9435956\ttotal: 6.53s\tremaining: 8.84s\n",
      "425:\tlearn: 1.9421264\ttotal: 6.55s\tremaining: 8.82s\n",
      "426:\tlearn: 1.9419220\ttotal: 6.56s\tremaining: 8.81s\n",
      "427:\tlearn: 1.9406926\ttotal: 6.58s\tremaining: 8.79s\n",
      "428:\tlearn: 1.9406615\ttotal: 6.59s\tremaining: 8.77s\n",
      "429:\tlearn: 1.9398441\ttotal: 6.61s\tremaining: 8.76s\n",
      "430:\tlearn: 1.9398228\ttotal: 6.62s\tremaining: 8.74s\n",
      "431:\tlearn: 1.9398228\ttotal: 6.63s\tremaining: 8.72s\n",
      "432:\tlearn: 1.9398226\ttotal: 6.65s\tremaining: 8.71s\n",
      "433:\tlearn: 1.9397670\ttotal: 6.66s\tremaining: 8.69s\n",
      "434:\tlearn: 1.9392192\ttotal: 6.68s\tremaining: 8.67s\n",
      "435:\tlearn: 1.9384905\ttotal: 6.69s\tremaining: 8.65s\n",
      "436:\tlearn: 1.9384884\ttotal: 6.71s\tremaining: 8.64s\n",
      "437:\tlearn: 1.9383991\ttotal: 6.72s\tremaining: 8.62s\n",
      "438:\tlearn: 1.9381790\ttotal: 6.73s\tremaining: 8.61s\n",
      "439:\tlearn: 1.9370367\ttotal: 6.75s\tremaining: 8.59s\n",
      "440:\tlearn: 1.9368629\ttotal: 6.76s\tremaining: 8.57s\n",
      "441:\tlearn: 1.9362413\ttotal: 6.78s\tremaining: 8.56s\n",
      "442:\tlearn: 1.9358123\ttotal: 6.79s\tremaining: 8.54s\n",
      "443:\tlearn: 1.9354810\ttotal: 6.81s\tremaining: 8.53s\n",
      "444:\tlearn: 1.9354120\ttotal: 6.82s\tremaining: 8.51s\n",
      "445:\tlearn: 1.9352595\ttotal: 6.84s\tremaining: 8.49s\n",
      "446:\tlearn: 1.9352450\ttotal: 6.85s\tremaining: 8.48s\n",
      "447:\tlearn: 1.9352179\ttotal: 6.87s\tremaining: 8.46s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448:\tlearn: 1.9347397\ttotal: 6.88s\tremaining: 8.45s\n",
      "449:\tlearn: 1.9347264\ttotal: 6.9s\tremaining: 8.43s\n",
      "450:\tlearn: 1.9344903\ttotal: 6.91s\tremaining: 8.41s\n",
      "451:\tlearn: 1.9344415\ttotal: 6.93s\tremaining: 8.4s\n",
      "452:\tlearn: 1.9343979\ttotal: 6.94s\tremaining: 8.38s\n",
      "453:\tlearn: 1.9338109\ttotal: 6.95s\tremaining: 8.36s\n",
      "454:\tlearn: 1.9337341\ttotal: 6.97s\tremaining: 8.35s\n",
      "455:\tlearn: 1.9337199\ttotal: 6.98s\tremaining: 8.33s\n",
      "456:\tlearn: 1.9336854\ttotal: 7s\tremaining: 8.31s\n",
      "457:\tlearn: 1.9335780\ttotal: 7.01s\tremaining: 8.3s\n",
      "458:\tlearn: 1.9335680\ttotal: 7.03s\tremaining: 8.28s\n",
      "459:\tlearn: 1.9334480\ttotal: 7.04s\tremaining: 8.27s\n",
      "460:\tlearn: 1.9334154\ttotal: 7.06s\tremaining: 8.25s\n",
      "461:\tlearn: 1.9333851\ttotal: 7.07s\tremaining: 8.23s\n",
      "462:\tlearn: 1.9322455\ttotal: 7.08s\tremaining: 8.22s\n",
      "463:\tlearn: 1.9322179\ttotal: 7.1s\tremaining: 8.2s\n",
      "464:\tlearn: 1.9321854\ttotal: 7.11s\tremaining: 8.19s\n",
      "465:\tlearn: 1.9317638\ttotal: 7.13s\tremaining: 8.17s\n",
      "466:\tlearn: 1.9301921\ttotal: 7.14s\tremaining: 8.15s\n",
      "467:\tlearn: 1.9297033\ttotal: 7.16s\tremaining: 8.14s\n",
      "468:\tlearn: 1.9284294\ttotal: 7.17s\tremaining: 8.12s\n",
      "469:\tlearn: 1.9280251\ttotal: 7.19s\tremaining: 8.11s\n",
      "470:\tlearn: 1.9279206\ttotal: 7.2s\tremaining: 8.09s\n",
      "471:\tlearn: 1.9278767\ttotal: 7.22s\tremaining: 8.07s\n",
      "472:\tlearn: 1.9278456\ttotal: 7.23s\tremaining: 8.06s\n",
      "473:\tlearn: 1.9276473\ttotal: 7.25s\tremaining: 8.04s\n",
      "474:\tlearn: 1.9273727\ttotal: 7.26s\tremaining: 8.02s\n",
      "475:\tlearn: 1.9272140\ttotal: 7.27s\tremaining: 8.01s\n",
      "476:\tlearn: 1.9271212\ttotal: 7.29s\tremaining: 7.99s\n",
      "477:\tlearn: 1.9270947\ttotal: 7.3s\tremaining: 7.97s\n",
      "478:\tlearn: 1.9267089\ttotal: 7.32s\tremaining: 7.96s\n",
      "479:\tlearn: 1.9265311\ttotal: 7.33s\tremaining: 7.94s\n",
      "480:\tlearn: 1.9265218\ttotal: 7.34s\tremaining: 7.93s\n",
      "481:\tlearn: 1.9265217\ttotal: 7.36s\tremaining: 7.91s\n",
      "482:\tlearn: 1.9259937\ttotal: 7.37s\tremaining: 7.89s\n",
      "483:\tlearn: 1.9253510\ttotal: 7.39s\tremaining: 7.88s\n",
      "484:\tlearn: 1.9248148\ttotal: 7.4s\tremaining: 7.86s\n",
      "485:\tlearn: 1.9246010\ttotal: 7.42s\tremaining: 7.84s\n",
      "486:\tlearn: 1.9246005\ttotal: 7.43s\tremaining: 7.83s\n",
      "487:\tlearn: 1.9244803\ttotal: 7.45s\tremaining: 7.81s\n",
      "488:\tlearn: 1.9242492\ttotal: 7.46s\tremaining: 7.8s\n",
      "489:\tlearn: 1.9239975\ttotal: 7.47s\tremaining: 7.78s\n",
      "490:\tlearn: 1.9233824\ttotal: 7.49s\tremaining: 7.76s\n",
      "491:\tlearn: 1.9229514\ttotal: 7.5s\tremaining: 7.75s\n",
      "492:\tlearn: 1.9217283\ttotal: 7.52s\tremaining: 7.73s\n",
      "493:\tlearn: 1.9214319\ttotal: 7.54s\tremaining: 7.72s\n",
      "494:\tlearn: 1.9210963\ttotal: 7.55s\tremaining: 7.7s\n",
      "495:\tlearn: 1.9205960\ttotal: 7.57s\tremaining: 7.69s\n",
      "496:\tlearn: 1.9201069\ttotal: 7.58s\tremaining: 7.67s\n",
      "497:\tlearn: 1.9200709\ttotal: 7.59s\tremaining: 7.66s\n",
      "498:\tlearn: 1.9195449\ttotal: 7.61s\tremaining: 7.64s\n",
      "499:\tlearn: 1.9195037\ttotal: 7.62s\tremaining: 7.62s\n",
      "500:\tlearn: 1.9191850\ttotal: 7.64s\tremaining: 7.61s\n",
      "501:\tlearn: 1.9189959\ttotal: 7.65s\tremaining: 7.59s\n",
      "502:\tlearn: 1.9189855\ttotal: 7.67s\tremaining: 7.58s\n",
      "503:\tlearn: 1.9187205\ttotal: 7.68s\tremaining: 7.56s\n",
      "504:\tlearn: 1.9186302\ttotal: 7.7s\tremaining: 7.54s\n",
      "505:\tlearn: 1.9184002\ttotal: 7.71s\tremaining: 7.53s\n",
      "506:\tlearn: 1.9181398\ttotal: 7.72s\tremaining: 7.51s\n",
      "507:\tlearn: 1.9180663\ttotal: 7.74s\tremaining: 7.5s\n",
      "508:\tlearn: 1.9180352\ttotal: 7.75s\tremaining: 7.48s\n",
      "509:\tlearn: 1.9178977\ttotal: 7.77s\tremaining: 7.46s\n",
      "510:\tlearn: 1.9178018\ttotal: 7.78s\tremaining: 7.45s\n",
      "511:\tlearn: 1.9177975\ttotal: 7.8s\tremaining: 7.43s\n",
      "512:\tlearn: 1.9177925\ttotal: 7.81s\tremaining: 7.42s\n",
      "513:\tlearn: 1.9177713\ttotal: 7.83s\tremaining: 7.4s\n",
      "514:\tlearn: 1.9177400\ttotal: 7.84s\tremaining: 7.39s\n",
      "515:\tlearn: 1.9177374\ttotal: 7.86s\tremaining: 7.37s\n",
      "516:\tlearn: 1.9177160\ttotal: 7.87s\tremaining: 7.36s\n",
      "517:\tlearn: 1.9177073\ttotal: 7.89s\tremaining: 7.34s\n",
      "518:\tlearn: 1.9176416\ttotal: 7.9s\tremaining: 7.32s\n",
      "519:\tlearn: 1.9174625\ttotal: 7.92s\tremaining: 7.31s\n",
      "520:\tlearn: 1.9174195\ttotal: 7.93s\tremaining: 7.29s\n",
      "521:\tlearn: 1.9170965\ttotal: 7.95s\tremaining: 7.28s\n",
      "522:\tlearn: 1.9170962\ttotal: 7.96s\tremaining: 7.26s\n",
      "523:\tlearn: 1.9170441\ttotal: 7.98s\tremaining: 7.25s\n",
      "524:\tlearn: 1.9170433\ttotal: 7.99s\tremaining: 7.23s\n",
      "525:\tlearn: 1.9170298\ttotal: 8.01s\tremaining: 7.21s\n",
      "526:\tlearn: 1.9170259\ttotal: 8.02s\tremaining: 7.2s\n",
      "527:\tlearn: 1.9170130\ttotal: 8.04s\tremaining: 7.18s\n",
      "528:\tlearn: 1.9170120\ttotal: 8.05s\tremaining: 7.17s\n",
      "529:\tlearn: 1.9170109\ttotal: 8.06s\tremaining: 7.15s\n",
      "530:\tlearn: 1.9170109\ttotal: 8.08s\tremaining: 7.14s\n",
      "531:\tlearn: 1.9170102\ttotal: 8.09s\tremaining: 7.12s\n",
      "532:\tlearn: 1.9170032\ttotal: 8.11s\tremaining: 7.1s\n",
      "533:\tlearn: 1.9170028\ttotal: 8.12s\tremaining: 7.09s\n",
      "534:\tlearn: 1.9170025\ttotal: 8.14s\tremaining: 7.07s\n",
      "535:\tlearn: 1.9169982\ttotal: 8.15s\tremaining: 7.05s\n",
      "536:\tlearn: 1.9169939\ttotal: 8.16s\tremaining: 7.04s\n",
      "537:\tlearn: 1.9169123\ttotal: 8.18s\tremaining: 7.02s\n",
      "538:\tlearn: 1.9168738\ttotal: 8.19s\tremaining: 7.01s\n",
      "539:\tlearn: 1.9168579\ttotal: 8.21s\tremaining: 6.99s\n",
      "540:\tlearn: 1.9168559\ttotal: 8.22s\tremaining: 6.98s\n",
      "541:\tlearn: 1.9168559\ttotal: 8.24s\tremaining: 6.96s\n",
      "542:\tlearn: 1.9168529\ttotal: 8.25s\tremaining: 6.94s\n",
      "543:\tlearn: 1.9168529\ttotal: 8.26s\tremaining: 6.93s\n",
      "544:\tlearn: 1.9168529\ttotal: 8.28s\tremaining: 6.91s\n",
      "545:\tlearn: 1.9168529\ttotal: 8.29s\tremaining: 6.89s\n",
      "546:\tlearn: 1.9168529\ttotal: 8.31s\tremaining: 6.88s\n",
      "547:\tlearn: 1.9168529\ttotal: 8.32s\tremaining: 6.86s\n",
      "548:\tlearn: 1.9168503\ttotal: 8.34s\tremaining: 6.85s\n",
      "549:\tlearn: 1.9168503\ttotal: 8.35s\tremaining: 6.83s\n",
      "550:\tlearn: 1.9168503\ttotal: 8.36s\tremaining: 6.82s\n",
      "551:\tlearn: 1.9168503\ttotal: 8.38s\tremaining: 6.8s\n",
      "552:\tlearn: 1.9168503\ttotal: 8.39s\tremaining: 6.79s\n",
      "553:\tlearn: 1.9168481\ttotal: 8.41s\tremaining: 6.77s\n",
      "554:\tlearn: 1.9160582\ttotal: 8.42s\tremaining: 6.75s\n",
      "555:\tlearn: 1.9160509\ttotal: 8.44s\tremaining: 6.74s\n",
      "556:\tlearn: 1.9160442\ttotal: 8.45s\tremaining: 6.72s\n",
      "557:\tlearn: 1.9159845\ttotal: 8.46s\tremaining: 6.7s\n",
      "558:\tlearn: 1.9159835\ttotal: 8.47s\tremaining: 6.69s\n",
      "559:\tlearn: 1.9159802\ttotal: 8.49s\tremaining: 6.67s\n",
      "560:\tlearn: 1.9159789\ttotal: 8.51s\tremaining: 6.66s\n",
      "561:\tlearn: 1.9157418\ttotal: 8.52s\tremaining: 6.64s\n",
      "562:\tlearn: 1.9153896\ttotal: 8.53s\tremaining: 6.62s\n",
      "563:\tlearn: 1.9153665\ttotal: 8.55s\tremaining: 6.61s\n",
      "564:\tlearn: 1.9151775\ttotal: 8.56s\tremaining: 6.59s\n",
      "565:\tlearn: 1.9147579\ttotal: 8.58s\tremaining: 6.58s\n",
      "566:\tlearn: 1.9146924\ttotal: 8.59s\tremaining: 6.56s\n",
      "567:\tlearn: 1.9146557\ttotal: 8.61s\tremaining: 6.54s\n",
      "568:\tlearn: 1.9146543\ttotal: 8.62s\tremaining: 6.53s\n",
      "569:\tlearn: 1.9146407\ttotal: 8.63s\tremaining: 6.51s\n",
      "570:\tlearn: 1.9146407\ttotal: 8.65s\tremaining: 6.5s\n",
      "571:\tlearn: 1.9146194\ttotal: 8.66s\tremaining: 6.48s\n",
      "572:\tlearn: 1.9145901\ttotal: 8.68s\tremaining: 6.46s\n",
      "573:\tlearn: 1.9138274\ttotal: 8.69s\tremaining: 6.45s\n",
      "574:\tlearn: 1.9136699\ttotal: 8.7s\tremaining: 6.43s\n",
      "575:\tlearn: 1.9136374\ttotal: 8.72s\tremaining: 6.42s\n",
      "576:\tlearn: 1.9136135\ttotal: 8.73s\tremaining: 6.4s\n",
      "577:\tlearn: 1.9136032\ttotal: 8.75s\tremaining: 6.39s\n",
      "578:\tlearn: 1.9135948\ttotal: 8.76s\tremaining: 6.37s\n",
      "579:\tlearn: 1.9135500\ttotal: 8.78s\tremaining: 6.36s\n",
      "580:\tlearn: 1.9135385\ttotal: 8.79s\tremaining: 6.34s\n",
      "581:\tlearn: 1.9134274\ttotal: 8.81s\tremaining: 6.33s\n",
      "582:\tlearn: 1.9133233\ttotal: 8.82s\tremaining: 6.31s\n",
      "583:\tlearn: 1.9131443\ttotal: 8.84s\tremaining: 6.29s\n",
      "584:\tlearn: 1.9131392\ttotal: 8.85s\tremaining: 6.28s\n",
      "585:\tlearn: 1.9128507\ttotal: 8.87s\tremaining: 6.26s\n",
      "586:\tlearn: 1.9123483\ttotal: 8.88s\tremaining: 6.25s\n",
      "587:\tlearn: 1.9118336\ttotal: 8.89s\tremaining: 6.23s\n",
      "588:\tlearn: 1.9112312\ttotal: 8.91s\tremaining: 6.22s\n",
      "589:\tlearn: 1.9110256\ttotal: 8.92s\tremaining: 6.2s\n",
      "590:\tlearn: 1.9103866\ttotal: 8.94s\tremaining: 6.18s\n",
      "591:\tlearn: 1.9103422\ttotal: 8.95s\tremaining: 6.17s\n",
      "592:\tlearn: 1.9103238\ttotal: 8.97s\tremaining: 6.15s\n",
      "593:\tlearn: 1.9103238\ttotal: 8.98s\tremaining: 6.14s\n",
      "594:\tlearn: 1.9101527\ttotal: 9s\tremaining: 6.12s\n",
      "595:\tlearn: 1.9097637\ttotal: 9.01s\tremaining: 6.11s\n",
      "596:\tlearn: 1.9093095\ttotal: 9.03s\tremaining: 6.09s\n",
      "597:\tlearn: 1.9090233\ttotal: 9.04s\tremaining: 6.08s\n",
      "598:\tlearn: 1.9089907\ttotal: 9.05s\tremaining: 6.06s\n",
      "599:\tlearn: 1.9089393\ttotal: 9.07s\tremaining: 6.05s\n",
      "600:\tlearn: 1.9089179\ttotal: 9.09s\tremaining: 6.03s\n",
      "601:\tlearn: 1.9089118\ttotal: 9.1s\tremaining: 6.02s\n",
      "602:\tlearn: 1.9089084\ttotal: 9.11s\tremaining: 6s\n",
      "603:\tlearn: 1.9089019\ttotal: 9.13s\tremaining: 5.99s\n",
      "604:\tlearn: 1.9088712\ttotal: 9.14s\tremaining: 5.97s\n",
      "605:\tlearn: 1.9088501\ttotal: 9.16s\tremaining: 5.95s\n",
      "606:\tlearn: 1.9088208\ttotal: 9.17s\tremaining: 5.94s\n",
      "607:\tlearn: 1.9087424\ttotal: 9.19s\tremaining: 5.92s\n",
      "608:\tlearn: 1.9087368\ttotal: 9.2s\tremaining: 5.91s\n",
      "609:\tlearn: 1.9087364\ttotal: 9.22s\tremaining: 5.89s\n",
      "610:\tlearn: 1.9087332\ttotal: 9.23s\tremaining: 5.88s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611:\tlearn: 1.9087332\ttotal: 9.24s\tremaining: 5.86s\n",
      "612:\tlearn: 1.9087331\ttotal: 9.26s\tremaining: 5.85s\n",
      "613:\tlearn: 1.9087330\ttotal: 9.27s\tremaining: 5.83s\n",
      "614:\tlearn: 1.9087330\ttotal: 9.29s\tremaining: 5.81s\n",
      "615:\tlearn: 1.9087330\ttotal: 9.3s\tremaining: 5.8s\n",
      "616:\tlearn: 1.9087330\ttotal: 9.32s\tremaining: 5.78s\n",
      "617:\tlearn: 1.9087330\ttotal: 9.33s\tremaining: 5.77s\n",
      "618:\tlearn: 1.9087320\ttotal: 9.34s\tremaining: 5.75s\n",
      "619:\tlearn: 1.9087315\ttotal: 9.36s\tremaining: 5.74s\n",
      "620:\tlearn: 1.9087315\ttotal: 9.37s\tremaining: 5.72s\n",
      "621:\tlearn: 1.9087294\ttotal: 9.39s\tremaining: 5.7s\n",
      "622:\tlearn: 1.9083482\ttotal: 9.4s\tremaining: 5.69s\n",
      "623:\tlearn: 1.9078049\ttotal: 9.41s\tremaining: 5.67s\n",
      "624:\tlearn: 1.9075050\ttotal: 9.43s\tremaining: 5.66s\n",
      "625:\tlearn: 1.9074567\ttotal: 9.44s\tremaining: 5.64s\n",
      "626:\tlearn: 1.9073261\ttotal: 9.46s\tremaining: 5.63s\n",
      "627:\tlearn: 1.9070726\ttotal: 9.47s\tremaining: 5.61s\n",
      "628:\tlearn: 1.9070304\ttotal: 9.49s\tremaining: 5.6s\n",
      "629:\tlearn: 1.9070288\ttotal: 9.5s\tremaining: 5.58s\n",
      "630:\tlearn: 1.9068286\ttotal: 9.52s\tremaining: 5.57s\n",
      "631:\tlearn: 1.9062809\ttotal: 9.53s\tremaining: 5.55s\n",
      "632:\tlearn: 1.9062006\ttotal: 9.55s\tremaining: 5.54s\n",
      "633:\tlearn: 1.9061975\ttotal: 9.56s\tremaining: 5.52s\n",
      "634:\tlearn: 1.9060879\ttotal: 9.58s\tremaining: 5.5s\n",
      "635:\tlearn: 1.9059691\ttotal: 9.59s\tremaining: 5.49s\n",
      "636:\tlearn: 1.9059691\ttotal: 9.61s\tremaining: 5.47s\n",
      "637:\tlearn: 1.9059691\ttotal: 9.62s\tremaining: 5.46s\n",
      "638:\tlearn: 1.9059688\ttotal: 9.63s\tremaining: 5.44s\n",
      "639:\tlearn: 1.9059684\ttotal: 9.65s\tremaining: 5.43s\n",
      "640:\tlearn: 1.9059458\ttotal: 9.66s\tremaining: 5.41s\n",
      "641:\tlearn: 1.9059458\ttotal: 9.68s\tremaining: 5.4s\n",
      "642:\tlearn: 1.9059456\ttotal: 9.69s\tremaining: 5.38s\n",
      "643:\tlearn: 1.9059140\ttotal: 9.71s\tremaining: 5.37s\n",
      "644:\tlearn: 1.9058767\ttotal: 9.72s\tremaining: 5.35s\n",
      "645:\tlearn: 1.9058766\ttotal: 9.74s\tremaining: 5.33s\n",
      "646:\tlearn: 1.9058273\ttotal: 9.75s\tremaining: 5.32s\n",
      "647:\tlearn: 1.9058252\ttotal: 9.77s\tremaining: 5.3s\n",
      "648:\tlearn: 1.9058252\ttotal: 9.78s\tremaining: 5.29s\n",
      "649:\tlearn: 1.9058174\ttotal: 9.79s\tremaining: 5.27s\n",
      "650:\tlearn: 1.9057869\ttotal: 9.81s\tremaining: 5.26s\n",
      "651:\tlearn: 1.9057821\ttotal: 9.82s\tremaining: 5.24s\n",
      "652:\tlearn: 1.9057681\ttotal: 9.84s\tremaining: 5.23s\n",
      "653:\tlearn: 1.9057063\ttotal: 9.85s\tremaining: 5.21s\n",
      "654:\tlearn: 1.9051373\ttotal: 9.87s\tremaining: 5.2s\n",
      "655:\tlearn: 1.9051217\ttotal: 9.88s\tremaining: 5.18s\n",
      "656:\tlearn: 1.9049460\ttotal: 9.89s\tremaining: 5.17s\n",
      "657:\tlearn: 1.9048926\ttotal: 9.91s\tremaining: 5.15s\n",
      "658:\tlearn: 1.9045378\ttotal: 9.92s\tremaining: 5.13s\n",
      "659:\tlearn: 1.9038912\ttotal: 9.94s\tremaining: 5.12s\n",
      "660:\tlearn: 1.9038421\ttotal: 9.95s\tremaining: 5.1s\n",
      "661:\tlearn: 1.9033908\ttotal: 9.97s\tremaining: 5.09s\n",
      "662:\tlearn: 1.9033189\ttotal: 9.98s\tremaining: 5.07s\n",
      "663:\tlearn: 1.9027343\ttotal: 9.99s\tremaining: 5.06s\n",
      "664:\tlearn: 1.9022044\ttotal: 10s\tremaining: 5.04s\n",
      "665:\tlearn: 1.9020411\ttotal: 10s\tremaining: 5.03s\n",
      "666:\tlearn: 1.9020406\ttotal: 10s\tremaining: 5.01s\n",
      "667:\tlearn: 1.9020208\ttotal: 10.1s\tremaining: 5s\n",
      "668:\tlearn: 1.9019996\ttotal: 10.1s\tremaining: 4.98s\n",
      "669:\tlearn: 1.9018000\ttotal: 10.1s\tremaining: 4.96s\n",
      "670:\tlearn: 1.9017486\ttotal: 10.1s\tremaining: 4.95s\n",
      "671:\tlearn: 1.9016861\ttotal: 10.1s\tremaining: 4.93s\n",
      "672:\tlearn: 1.9016818\ttotal: 10.1s\tremaining: 4.92s\n",
      "673:\tlearn: 1.9016816\ttotal: 10.1s\tremaining: 4.9s\n",
      "674:\tlearn: 1.9016816\ttotal: 10.2s\tremaining: 4.89s\n",
      "675:\tlearn: 1.9016816\ttotal: 10.2s\tremaining: 4.87s\n",
      "676:\tlearn: 1.9016816\ttotal: 10.2s\tremaining: 4.86s\n",
      "677:\tlearn: 1.9016813\ttotal: 10.2s\tremaining: 4.84s\n",
      "678:\tlearn: 1.9016813\ttotal: 10.2s\tremaining: 4.83s\n",
      "679:\tlearn: 1.9016808\ttotal: 10.2s\tremaining: 4.81s\n",
      "680:\tlearn: 1.9016532\ttotal: 10.2s\tremaining: 4.79s\n",
      "681:\tlearn: 1.9010086\ttotal: 10.3s\tremaining: 4.78s\n",
      "682:\tlearn: 1.9009176\ttotal: 10.3s\tremaining: 4.76s\n",
      "683:\tlearn: 1.9006726\ttotal: 10.3s\tremaining: 4.75s\n",
      "684:\tlearn: 1.9006274\ttotal: 10.3s\tremaining: 4.73s\n",
      "685:\tlearn: 1.8996254\ttotal: 10.3s\tremaining: 4.72s\n",
      "686:\tlearn: 1.8995527\ttotal: 10.3s\tremaining: 4.7s\n",
      "687:\tlearn: 1.8995520\ttotal: 10.3s\tremaining: 4.69s\n",
      "688:\tlearn: 1.8995490\ttotal: 10.4s\tremaining: 4.67s\n",
      "689:\tlearn: 1.8995487\ttotal: 10.4s\tremaining: 4.66s\n",
      "690:\tlearn: 1.8994626\ttotal: 10.4s\tremaining: 4.64s\n",
      "691:\tlearn: 1.8993114\ttotal: 10.4s\tremaining: 4.63s\n",
      "692:\tlearn: 1.8993083\ttotal: 10.4s\tremaining: 4.61s\n",
      "693:\tlearn: 1.8993069\ttotal: 10.4s\tremaining: 4.6s\n",
      "694:\tlearn: 1.8993027\ttotal: 10.4s\tremaining: 4.58s\n",
      "695:\tlearn: 1.8993024\ttotal: 10.5s\tremaining: 4.57s\n",
      "696:\tlearn: 1.8993023\ttotal: 10.5s\tremaining: 4.55s\n",
      "697:\tlearn: 1.8992966\ttotal: 10.5s\tremaining: 4.53s\n",
      "698:\tlearn: 1.8992955\ttotal: 10.5s\tremaining: 4.52s\n",
      "699:\tlearn: 1.8992390\ttotal: 10.5s\tremaining: 4.5s\n",
      "700:\tlearn: 1.8991508\ttotal: 10.5s\tremaining: 4.49s\n",
      "701:\tlearn: 1.8991461\ttotal: 10.5s\tremaining: 4.47s\n",
      "702:\tlearn: 1.8977043\ttotal: 10.6s\tremaining: 4.46s\n",
      "703:\tlearn: 1.8976581\ttotal: 10.6s\tremaining: 4.44s\n",
      "704:\tlearn: 1.8976158\ttotal: 10.6s\tremaining: 4.43s\n",
      "705:\tlearn: 1.8969096\ttotal: 10.6s\tremaining: 4.41s\n",
      "706:\tlearn: 1.8969096\ttotal: 10.6s\tremaining: 4.4s\n",
      "707:\tlearn: 1.8969010\ttotal: 10.6s\tremaining: 4.38s\n",
      "708:\tlearn: 1.8967732\ttotal: 10.6s\tremaining: 4.37s\n",
      "709:\tlearn: 1.8963005\ttotal: 10.7s\tremaining: 4.35s\n",
      "710:\tlearn: 1.8962756\ttotal: 10.7s\tremaining: 4.34s\n",
      "711:\tlearn: 1.8962755\ttotal: 10.7s\tremaining: 4.32s\n",
      "712:\tlearn: 1.8962285\ttotal: 10.7s\tremaining: 4.3s\n",
      "713:\tlearn: 1.8962044\ttotal: 10.7s\tremaining: 4.29s\n",
      "714:\tlearn: 1.8962042\ttotal: 10.7s\tremaining: 4.28s\n",
      "715:\tlearn: 1.8957607\ttotal: 10.7s\tremaining: 4.26s\n",
      "716:\tlearn: 1.8957607\ttotal: 10.8s\tremaining: 4.24s\n",
      "717:\tlearn: 1.8957607\ttotal: 10.8s\tremaining: 4.23s\n",
      "718:\tlearn: 1.8953817\ttotal: 10.8s\tremaining: 4.21s\n",
      "719:\tlearn: 1.8948188\ttotal: 10.8s\tremaining: 4.2s\n",
      "720:\tlearn: 1.8938850\ttotal: 10.8s\tremaining: 4.18s\n",
      "721:\tlearn: 1.8934554\ttotal: 10.8s\tremaining: 4.17s\n",
      "722:\tlearn: 1.8934553\ttotal: 10.8s\tremaining: 4.15s\n",
      "723:\tlearn: 1.8934553\ttotal: 10.9s\tremaining: 4.14s\n",
      "724:\tlearn: 1.8934552\ttotal: 10.9s\tremaining: 4.12s\n",
      "725:\tlearn: 1.8934515\ttotal: 10.9s\tremaining: 4.11s\n",
      "726:\tlearn: 1.8934515\ttotal: 10.9s\tremaining: 4.09s\n",
      "727:\tlearn: 1.8934281\ttotal: 10.9s\tremaining: 4.08s\n",
      "728:\tlearn: 1.8934029\ttotal: 10.9s\tremaining: 4.06s\n",
      "729:\tlearn: 1.8934027\ttotal: 10.9s\tremaining: 4.04s\n",
      "730:\tlearn: 1.8933954\ttotal: 11s\tremaining: 4.03s\n",
      "731:\tlearn: 1.8933945\ttotal: 11s\tremaining: 4.01s\n",
      "732:\tlearn: 1.8933903\ttotal: 11s\tremaining: 4s\n",
      "733:\tlearn: 1.8933903\ttotal: 11s\tremaining: 3.98s\n",
      "734:\tlearn: 1.8933903\ttotal: 11s\tremaining: 3.97s\n",
      "735:\tlearn: 1.8933357\ttotal: 11s\tremaining: 3.96s\n",
      "736:\tlearn: 1.8931330\ttotal: 11s\tremaining: 3.94s\n",
      "737:\tlearn: 1.8930943\ttotal: 11.1s\tremaining: 3.92s\n",
      "738:\tlearn: 1.8930508\ttotal: 11.1s\tremaining: 3.91s\n",
      "739:\tlearn: 1.8929482\ttotal: 11.1s\tremaining: 3.9s\n",
      "740:\tlearn: 1.8929053\ttotal: 11.1s\tremaining: 3.88s\n",
      "741:\tlearn: 1.8921241\ttotal: 11.1s\tremaining: 3.87s\n",
      "742:\tlearn: 1.8920927\ttotal: 11.1s\tremaining: 3.85s\n",
      "743:\tlearn: 1.8915280\ttotal: 11.1s\tremaining: 3.83s\n",
      "744:\tlearn: 1.8915178\ttotal: 11.2s\tremaining: 3.82s\n",
      "745:\tlearn: 1.8912320\ttotal: 11.2s\tremaining: 3.81s\n",
      "746:\tlearn: 1.8903774\ttotal: 11.2s\tremaining: 3.79s\n",
      "747:\tlearn: 1.8903650\ttotal: 11.2s\tremaining: 3.77s\n",
      "748:\tlearn: 1.8896170\ttotal: 11.2s\tremaining: 3.76s\n",
      "749:\tlearn: 1.8886624\ttotal: 11.2s\tremaining: 3.75s\n",
      "750:\tlearn: 1.8877696\ttotal: 11.3s\tremaining: 3.73s\n",
      "751:\tlearn: 1.8874428\ttotal: 11.3s\tremaining: 3.71s\n",
      "752:\tlearn: 1.8869622\ttotal: 11.3s\tremaining: 3.7s\n",
      "753:\tlearn: 1.8869205\ttotal: 11.3s\tremaining: 3.69s\n",
      "754:\tlearn: 1.8869177\ttotal: 11.3s\tremaining: 3.67s\n",
      "755:\tlearn: 1.8864469\ttotal: 11.3s\tremaining: 3.65s\n",
      "756:\tlearn: 1.8860462\ttotal: 11.3s\tremaining: 3.64s\n",
      "757:\tlearn: 1.8860370\ttotal: 11.4s\tremaining: 3.63s\n",
      "758:\tlearn: 1.8860351\ttotal: 11.4s\tremaining: 3.61s\n",
      "759:\tlearn: 1.8860343\ttotal: 11.4s\tremaining: 3.59s\n",
      "760:\tlearn: 1.8860324\ttotal: 11.4s\tremaining: 3.58s\n",
      "761:\tlearn: 1.8855008\ttotal: 11.4s\tremaining: 3.56s\n",
      "762:\tlearn: 1.8854952\ttotal: 11.4s\tremaining: 3.55s\n",
      "763:\tlearn: 1.8854897\ttotal: 11.4s\tremaining: 3.53s\n",
      "764:\tlearn: 1.8854897\ttotal: 11.5s\tremaining: 3.52s\n",
      "765:\tlearn: 1.8854301\ttotal: 11.5s\tremaining: 3.5s\n",
      "766:\tlearn: 1.8854268\ttotal: 11.5s\tremaining: 3.49s\n",
      "767:\tlearn: 1.8854167\ttotal: 11.5s\tremaining: 3.47s\n",
      "768:\tlearn: 1.8854123\ttotal: 11.5s\tremaining: 3.46s\n",
      "769:\tlearn: 1.8854028\ttotal: 11.5s\tremaining: 3.44s\n",
      "770:\tlearn: 1.8852698\ttotal: 11.5s\tremaining: 3.43s\n",
      "771:\tlearn: 1.8852304\ttotal: 11.6s\tremaining: 3.41s\n",
      "772:\tlearn: 1.8852282\ttotal: 11.6s\tremaining: 3.4s\n",
      "773:\tlearn: 1.8852271\ttotal: 11.6s\tremaining: 3.38s\n",
      "774:\tlearn: 1.8850229\ttotal: 11.6s\tremaining: 3.37s\n",
      "775:\tlearn: 1.8846822\ttotal: 11.6s\tremaining: 3.35s\n",
      "776:\tlearn: 1.8846819\ttotal: 11.6s\tremaining: 3.34s\n",
      "777:\tlearn: 1.8846818\ttotal: 11.6s\tremaining: 3.32s\n",
      "778:\tlearn: 1.8846818\ttotal: 11.7s\tremaining: 3.31s\n",
      "779:\tlearn: 1.8846817\ttotal: 11.7s\tremaining: 3.29s\n",
      "780:\tlearn: 1.8846817\ttotal: 11.7s\tremaining: 3.28s\n",
      "781:\tlearn: 1.8846816\ttotal: 11.7s\tremaining: 3.26s\n",
      "782:\tlearn: 1.8846369\ttotal: 11.7s\tremaining: 3.25s\n",
      "783:\tlearn: 1.8846312\ttotal: 11.7s\tremaining: 3.23s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784:\tlearn: 1.8846312\ttotal: 11.7s\tremaining: 3.22s\n",
      "785:\tlearn: 1.8846310\ttotal: 11.8s\tremaining: 3.2s\n",
      "786:\tlearn: 1.8846305\ttotal: 11.8s\tremaining: 3.19s\n",
      "787:\tlearn: 1.8845644\ttotal: 11.8s\tremaining: 3.17s\n",
      "788:\tlearn: 1.8845478\ttotal: 11.8s\tremaining: 3.16s\n",
      "789:\tlearn: 1.8844754\ttotal: 11.8s\tremaining: 3.14s\n",
      "790:\tlearn: 1.8843757\ttotal: 11.8s\tremaining: 3.13s\n",
      "791:\tlearn: 1.8843735\ttotal: 11.8s\tremaining: 3.11s\n",
      "792:\tlearn: 1.8841907\ttotal: 11.9s\tremaining: 3.1s\n",
      "793:\tlearn: 1.8840547\ttotal: 11.9s\tremaining: 3.08s\n",
      "794:\tlearn: 1.8839708\ttotal: 11.9s\tremaining: 3.07s\n",
      "795:\tlearn: 1.8839540\ttotal: 11.9s\tremaining: 3.05s\n",
      "796:\tlearn: 1.8837057\ttotal: 11.9s\tremaining: 3.04s\n",
      "797:\tlearn: 1.8835141\ttotal: 11.9s\tremaining: 3.02s\n",
      "798:\tlearn: 1.8835016\ttotal: 11.9s\tremaining: 3s\n",
      "799:\tlearn: 1.8834843\ttotal: 12s\tremaining: 2.99s\n",
      "800:\tlearn: 1.8834176\ttotal: 12s\tremaining: 2.98s\n",
      "801:\tlearn: 1.8834176\ttotal: 12s\tremaining: 2.96s\n",
      "802:\tlearn: 1.8834175\ttotal: 12s\tremaining: 2.94s\n",
      "803:\tlearn: 1.8834169\ttotal: 12s\tremaining: 2.93s\n",
      "804:\tlearn: 1.8827212\ttotal: 12s\tremaining: 2.92s\n",
      "805:\tlearn: 1.8819911\ttotal: 12s\tremaining: 2.9s\n",
      "806:\tlearn: 1.8819895\ttotal: 12.1s\tremaining: 2.88s\n",
      "807:\tlearn: 1.8819861\ttotal: 12.1s\tremaining: 2.87s\n",
      "808:\tlearn: 1.8817751\ttotal: 12.1s\tremaining: 2.85s\n",
      "809:\tlearn: 1.8817630\ttotal: 12.1s\tremaining: 2.84s\n",
      "810:\tlearn: 1.8815591\ttotal: 12.1s\tremaining: 2.83s\n",
      "811:\tlearn: 1.8811345\ttotal: 12.1s\tremaining: 2.81s\n",
      "812:\tlearn: 1.8808013\ttotal: 12.2s\tremaining: 2.79s\n",
      "813:\tlearn: 1.8807308\ttotal: 12.2s\tremaining: 2.78s\n",
      "814:\tlearn: 1.8807295\ttotal: 12.2s\tremaining: 2.76s\n",
      "815:\tlearn: 1.8806883\ttotal: 12.2s\tremaining: 2.75s\n",
      "816:\tlearn: 1.8806269\ttotal: 12.2s\tremaining: 2.73s\n",
      "817:\tlearn: 1.8789344\ttotal: 12.2s\tremaining: 2.72s\n",
      "818:\tlearn: 1.8785105\ttotal: 12.2s\tremaining: 2.7s\n",
      "819:\tlearn: 1.8785086\ttotal: 12.3s\tremaining: 2.69s\n",
      "820:\tlearn: 1.8784563\ttotal: 12.3s\tremaining: 2.67s\n",
      "821:\tlearn: 1.8784457\ttotal: 12.3s\tremaining: 2.66s\n",
      "822:\tlearn: 1.8784448\ttotal: 12.3s\tremaining: 2.64s\n",
      "823:\tlearn: 1.8784395\ttotal: 12.3s\tremaining: 2.63s\n",
      "824:\tlearn: 1.8784369\ttotal: 12.3s\tremaining: 2.61s\n",
      "825:\tlearn: 1.8783913\ttotal: 12.3s\tremaining: 2.6s\n",
      "826:\tlearn: 1.8774781\ttotal: 12.4s\tremaining: 2.58s\n",
      "827:\tlearn: 1.8774153\ttotal: 12.4s\tremaining: 2.57s\n",
      "828:\tlearn: 1.8774014\ttotal: 12.4s\tremaining: 2.55s\n",
      "829:\tlearn: 1.8773685\ttotal: 12.4s\tremaining: 2.54s\n",
      "830:\tlearn: 1.8773629\ttotal: 12.4s\tremaining: 2.52s\n",
      "831:\tlearn: 1.8767375\ttotal: 12.4s\tremaining: 2.51s\n",
      "832:\tlearn: 1.8767024\ttotal: 12.4s\tremaining: 2.49s\n",
      "833:\tlearn: 1.8765791\ttotal: 12.5s\tremaining: 2.48s\n",
      "834:\tlearn: 1.8762683\ttotal: 12.5s\tremaining: 2.46s\n",
      "835:\tlearn: 1.8761942\ttotal: 12.5s\tremaining: 2.45s\n",
      "836:\tlearn: 1.8761849\ttotal: 12.5s\tremaining: 2.43s\n",
      "837:\tlearn: 1.8761797\ttotal: 12.5s\tremaining: 2.42s\n",
      "838:\tlearn: 1.8761330\ttotal: 12.5s\tremaining: 2.4s\n",
      "839:\tlearn: 1.8760916\ttotal: 12.5s\tremaining: 2.39s\n",
      "840:\tlearn: 1.8760735\ttotal: 12.6s\tremaining: 2.37s\n",
      "841:\tlearn: 1.8757093\ttotal: 12.6s\tremaining: 2.36s\n",
      "842:\tlearn: 1.8756927\ttotal: 12.6s\tremaining: 2.34s\n",
      "843:\tlearn: 1.8753171\ttotal: 12.6s\tremaining: 2.33s\n",
      "844:\tlearn: 1.8752572\ttotal: 12.6s\tremaining: 2.31s\n",
      "845:\tlearn: 1.8744615\ttotal: 12.6s\tremaining: 2.3s\n",
      "846:\tlearn: 1.8740483\ttotal: 12.6s\tremaining: 2.28s\n",
      "847:\tlearn: 1.8738398\ttotal: 12.7s\tremaining: 2.27s\n",
      "848:\tlearn: 1.8738397\ttotal: 12.7s\tremaining: 2.25s\n",
      "849:\tlearn: 1.8738396\ttotal: 12.7s\tremaining: 2.24s\n",
      "850:\tlearn: 1.8738395\ttotal: 12.7s\tremaining: 2.22s\n",
      "851:\tlearn: 1.8738394\ttotal: 12.7s\tremaining: 2.21s\n",
      "852:\tlearn: 1.8738283\ttotal: 12.7s\tremaining: 2.19s\n",
      "853:\tlearn: 1.8738275\ttotal: 12.7s\tremaining: 2.18s\n",
      "854:\tlearn: 1.8738275\ttotal: 12.8s\tremaining: 2.16s\n",
      "855:\tlearn: 1.8738275\ttotal: 12.8s\tremaining: 2.15s\n",
      "856:\tlearn: 1.8738161\ttotal: 12.8s\tremaining: 2.13s\n",
      "857:\tlearn: 1.8738054\ttotal: 12.8s\tremaining: 2.12s\n",
      "858:\tlearn: 1.8738051\ttotal: 12.8s\tremaining: 2.1s\n",
      "859:\tlearn: 1.8738050\ttotal: 12.8s\tremaining: 2.09s\n",
      "860:\tlearn: 1.8738047\ttotal: 12.8s\tremaining: 2.07s\n",
      "861:\tlearn: 1.8738006\ttotal: 12.9s\tremaining: 2.06s\n",
      "862:\tlearn: 1.8735519\ttotal: 12.9s\tremaining: 2.04s\n",
      "863:\tlearn: 1.8735127\ttotal: 12.9s\tremaining: 2.03s\n",
      "864:\tlearn: 1.8734863\ttotal: 12.9s\tremaining: 2.01s\n",
      "865:\tlearn: 1.8734641\ttotal: 12.9s\tremaining: 2s\n",
      "866:\tlearn: 1.8733628\ttotal: 12.9s\tremaining: 1.98s\n",
      "867:\tlearn: 1.8733163\ttotal: 12.9s\tremaining: 1.97s\n",
      "868:\tlearn: 1.8732879\ttotal: 13s\tremaining: 1.95s\n",
      "869:\tlearn: 1.8732611\ttotal: 13s\tremaining: 1.94s\n",
      "870:\tlearn: 1.8732534\ttotal: 13s\tremaining: 1.92s\n",
      "871:\tlearn: 1.8731841\ttotal: 13s\tremaining: 1.91s\n",
      "872:\tlearn: 1.8731523\ttotal: 13s\tremaining: 1.89s\n",
      "873:\tlearn: 1.8731407\ttotal: 13s\tremaining: 1.88s\n",
      "874:\tlearn: 1.8731379\ttotal: 13s\tremaining: 1.86s\n",
      "875:\tlearn: 1.8731357\ttotal: 13.1s\tremaining: 1.85s\n",
      "876:\tlearn: 1.8730954\ttotal: 13.1s\tremaining: 1.83s\n",
      "877:\tlearn: 1.8730919\ttotal: 13.1s\tremaining: 1.82s\n",
      "878:\tlearn: 1.8730909\ttotal: 13.1s\tremaining: 1.8s\n",
      "879:\tlearn: 1.8730909\ttotal: 13.1s\tremaining: 1.79s\n",
      "880:\tlearn: 1.8730744\ttotal: 13.1s\tremaining: 1.77s\n",
      "881:\tlearn: 1.8730744\ttotal: 13.1s\tremaining: 1.76s\n",
      "882:\tlearn: 1.8730743\ttotal: 13.2s\tremaining: 1.74s\n",
      "883:\tlearn: 1.8730712\ttotal: 13.2s\tremaining: 1.73s\n",
      "884:\tlearn: 1.8730712\ttotal: 13.2s\tremaining: 1.71s\n",
      "885:\tlearn: 1.8730702\ttotal: 13.2s\tremaining: 1.7s\n",
      "886:\tlearn: 1.8730692\ttotal: 13.2s\tremaining: 1.68s\n",
      "887:\tlearn: 1.8730692\ttotal: 13.2s\tremaining: 1.67s\n",
      "888:\tlearn: 1.8730473\ttotal: 13.2s\tremaining: 1.65s\n",
      "889:\tlearn: 1.8730442\ttotal: 13.3s\tremaining: 1.64s\n",
      "890:\tlearn: 1.8730435\ttotal: 13.3s\tremaining: 1.62s\n",
      "891:\tlearn: 1.8730434\ttotal: 13.3s\tremaining: 1.61s\n",
      "892:\tlearn: 1.8730434\ttotal: 13.3s\tremaining: 1.59s\n",
      "893:\tlearn: 1.8729931\ttotal: 13.3s\tremaining: 1.58s\n",
      "894:\tlearn: 1.8729297\ttotal: 13.3s\tremaining: 1.56s\n",
      "895:\tlearn: 1.8729176\ttotal: 13.3s\tremaining: 1.55s\n",
      "896:\tlearn: 1.8719418\ttotal: 13.4s\tremaining: 1.53s\n",
      "897:\tlearn: 1.8717096\ttotal: 13.4s\tremaining: 1.52s\n",
      "898:\tlearn: 1.8707970\ttotal: 13.4s\tremaining: 1.5s\n",
      "899:\tlearn: 1.8707927\ttotal: 13.4s\tremaining: 1.49s\n",
      "900:\tlearn: 1.8707915\ttotal: 13.4s\tremaining: 1.47s\n",
      "901:\tlearn: 1.8707914\ttotal: 13.4s\tremaining: 1.46s\n",
      "902:\tlearn: 1.8707146\ttotal: 13.4s\tremaining: 1.44s\n",
      "903:\tlearn: 1.8703433\ttotal: 13.5s\tremaining: 1.43s\n",
      "904:\tlearn: 1.8692230\ttotal: 13.5s\tremaining: 1.41s\n",
      "905:\tlearn: 1.8692141\ttotal: 13.5s\tremaining: 1.4s\n",
      "906:\tlearn: 1.8689767\ttotal: 13.5s\tremaining: 1.38s\n",
      "907:\tlearn: 1.8689577\ttotal: 13.5s\tremaining: 1.37s\n",
      "908:\tlearn: 1.8689563\ttotal: 13.5s\tremaining: 1.35s\n",
      "909:\tlearn: 1.8681733\ttotal: 13.5s\tremaining: 1.34s\n",
      "910:\tlearn: 1.8681721\ttotal: 13.6s\tremaining: 1.32s\n",
      "911:\tlearn: 1.8681719\ttotal: 13.6s\tremaining: 1.31s\n",
      "912:\tlearn: 1.8681718\ttotal: 13.6s\tremaining: 1.29s\n",
      "913:\tlearn: 1.8681623\ttotal: 13.6s\tremaining: 1.28s\n",
      "914:\tlearn: 1.8681623\ttotal: 13.6s\tremaining: 1.26s\n",
      "915:\tlearn: 1.8681612\ttotal: 13.6s\tremaining: 1.25s\n",
      "916:\tlearn: 1.8681610\ttotal: 13.6s\tremaining: 1.23s\n",
      "917:\tlearn: 1.8681608\ttotal: 13.7s\tremaining: 1.22s\n",
      "918:\tlearn: 1.8681603\ttotal: 13.7s\tremaining: 1.21s\n",
      "919:\tlearn: 1.8681592\ttotal: 13.7s\tremaining: 1.19s\n",
      "920:\tlearn: 1.8680451\ttotal: 13.7s\tremaining: 1.18s\n",
      "921:\tlearn: 1.8677307\ttotal: 13.7s\tremaining: 1.16s\n",
      "922:\tlearn: 1.8677211\ttotal: 13.7s\tremaining: 1.15s\n",
      "923:\tlearn: 1.8677109\ttotal: 13.7s\tremaining: 1.13s\n",
      "924:\tlearn: 1.8676900\ttotal: 13.8s\tremaining: 1.11s\n",
      "925:\tlearn: 1.8675320\ttotal: 13.8s\tremaining: 1.1s\n",
      "926:\tlearn: 1.8668477\ttotal: 13.8s\tremaining: 1.08s\n",
      "927:\tlearn: 1.8666185\ttotal: 13.8s\tremaining: 1.07s\n",
      "928:\tlearn: 1.8666114\ttotal: 13.8s\tremaining: 1.06s\n",
      "929:\tlearn: 1.8664356\ttotal: 13.8s\tremaining: 1.04s\n",
      "930:\tlearn: 1.8664347\ttotal: 13.8s\tremaining: 1.03s\n",
      "931:\tlearn: 1.8664327\ttotal: 13.9s\tremaining: 1.01s\n",
      "932:\tlearn: 1.8663880\ttotal: 13.9s\tremaining: 997ms\n",
      "933:\tlearn: 1.8663832\ttotal: 13.9s\tremaining: 982ms\n",
      "934:\tlearn: 1.8663750\ttotal: 13.9s\tremaining: 967ms\n",
      "935:\tlearn: 1.8663646\ttotal: 13.9s\tremaining: 952ms\n",
      "936:\tlearn: 1.8663525\ttotal: 13.9s\tremaining: 937ms\n",
      "937:\tlearn: 1.8658604\ttotal: 14s\tremaining: 923ms\n",
      "938:\tlearn: 1.8648721\ttotal: 14s\tremaining: 908ms\n",
      "939:\tlearn: 1.8648719\ttotal: 14s\tremaining: 893ms\n",
      "940:\tlearn: 1.8648218\ttotal: 14s\tremaining: 879ms\n",
      "941:\tlearn: 1.8647500\ttotal: 14s\tremaining: 864ms\n",
      "942:\tlearn: 1.8647309\ttotal: 14s\tremaining: 849ms\n",
      "943:\tlearn: 1.8640914\ttotal: 14.1s\tremaining: 834ms\n",
      "944:\tlearn: 1.8640873\ttotal: 14.1s\tremaining: 819ms\n",
      "945:\tlearn: 1.8638255\ttotal: 14.1s\tremaining: 804ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "946:\tlearn: 1.8636525\ttotal: 14.1s\tremaining: 789ms\n",
      "947:\tlearn: 1.8633845\ttotal: 14.1s\tremaining: 774ms\n",
      "948:\tlearn: 1.8629846\ttotal: 14.1s\tremaining: 759ms\n",
      "949:\tlearn: 1.8625363\ttotal: 14.1s\tremaining: 744ms\n",
      "950:\tlearn: 1.8616865\ttotal: 14.2s\tremaining: 729ms\n",
      "951:\tlearn: 1.8612540\ttotal: 14.2s\tremaining: 715ms\n",
      "952:\tlearn: 1.8605289\ttotal: 14.2s\tremaining: 700ms\n",
      "953:\tlearn: 1.8605281\ttotal: 14.2s\tremaining: 685ms\n",
      "954:\tlearn: 1.8605184\ttotal: 14.2s\tremaining: 670ms\n",
      "955:\tlearn: 1.8604793\ttotal: 14.2s\tremaining: 655ms\n",
      "956:\tlearn: 1.8602602\ttotal: 14.2s\tremaining: 640ms\n",
      "957:\tlearn: 1.8598645\ttotal: 14.3s\tremaining: 625ms\n",
      "958:\tlearn: 1.8596595\ttotal: 14.3s\tremaining: 610ms\n",
      "959:\tlearn: 1.8595855\ttotal: 14.3s\tremaining: 595ms\n",
      "960:\tlearn: 1.8595453\ttotal: 14.3s\tremaining: 580ms\n",
      "961:\tlearn: 1.8594948\ttotal: 14.3s\tremaining: 565ms\n",
      "962:\tlearn: 1.8590421\ttotal: 14.3s\tremaining: 551ms\n",
      "963:\tlearn: 1.8588653\ttotal: 14.3s\tremaining: 536ms\n",
      "964:\tlearn: 1.8588529\ttotal: 14.4s\tremaining: 521ms\n",
      "965:\tlearn: 1.8584025\ttotal: 14.4s\tremaining: 506ms\n",
      "966:\tlearn: 1.8583491\ttotal: 14.4s\tremaining: 491ms\n",
      "967:\tlearn: 1.8576168\ttotal: 14.4s\tremaining: 476ms\n",
      "968:\tlearn: 1.8571341\ttotal: 14.4s\tremaining: 461ms\n",
      "969:\tlearn: 1.8571318\ttotal: 14.4s\tremaining: 446ms\n",
      "970:\tlearn: 1.8571245\ttotal: 14.4s\tremaining: 431ms\n",
      "971:\tlearn: 1.8571245\ttotal: 14.5s\tremaining: 417ms\n",
      "972:\tlearn: 1.8570315\ttotal: 14.5s\tremaining: 402ms\n",
      "973:\tlearn: 1.8568794\ttotal: 14.5s\tremaining: 387ms\n",
      "974:\tlearn: 1.8568671\ttotal: 14.5s\tremaining: 372ms\n",
      "975:\tlearn: 1.8564506\ttotal: 14.5s\tremaining: 357ms\n",
      "976:\tlearn: 1.8561293\ttotal: 14.5s\tremaining: 342ms\n",
      "977:\tlearn: 1.8559376\ttotal: 14.5s\tremaining: 327ms\n",
      "978:\tlearn: 1.8557933\ttotal: 14.6s\tremaining: 312ms\n",
      "979:\tlearn: 1.8557928\ttotal: 14.6s\tremaining: 297ms\n",
      "980:\tlearn: 1.8557455\ttotal: 14.6s\tremaining: 283ms\n",
      "981:\tlearn: 1.8548422\ttotal: 14.6s\tremaining: 268ms\n",
      "982:\tlearn: 1.8547953\ttotal: 14.6s\tremaining: 253ms\n",
      "983:\tlearn: 1.8547950\ttotal: 14.6s\tremaining: 238ms\n",
      "984:\tlearn: 1.8547941\ttotal: 14.6s\tremaining: 223ms\n",
      "985:\tlearn: 1.8543491\ttotal: 14.7s\tremaining: 208ms\n",
      "986:\tlearn: 1.8543491\ttotal: 14.7s\tremaining: 193ms\n",
      "987:\tlearn: 1.8543204\ttotal: 14.7s\tremaining: 178ms\n",
      "988:\tlearn: 1.8543200\ttotal: 14.7s\tremaining: 164ms\n",
      "989:\tlearn: 1.8542414\ttotal: 14.7s\tremaining: 149ms\n",
      "990:\tlearn: 1.8542204\ttotal: 14.7s\tremaining: 134ms\n",
      "991:\tlearn: 1.8541740\ttotal: 14.7s\tremaining: 119ms\n",
      "992:\tlearn: 1.8539764\ttotal: 14.8s\tremaining: 104ms\n",
      "993:\tlearn: 1.8539587\ttotal: 14.8s\tremaining: 89.2ms\n",
      "994:\tlearn: 1.8538541\ttotal: 14.8s\tremaining: 74.3ms\n",
      "995:\tlearn: 1.8538086\ttotal: 14.8s\tremaining: 59.4ms\n",
      "996:\tlearn: 1.8538065\ttotal: 14.8s\tremaining: 44.6ms\n",
      "997:\tlearn: 1.8537588\ttotal: 14.8s\tremaining: 29.7ms\n",
      "998:\tlearn: 1.8531897\ttotal: 14.8s\tremaining: 14.9ms\n",
      "999:\tlearn: 1.8516498\ttotal: 14.9s\tremaining: 0us\n",
      "0:\tlearn: 9.9489420\ttotal: 18.5ms\tremaining: 18.5s\n",
      "1:\tlearn: 9.0684927\ttotal: 35ms\tremaining: 17.5s\n",
      "2:\tlearn: 8.4538210\ttotal: 49.8ms\tremaining: 16.6s\n",
      "3:\tlearn: 7.7298420\ttotal: 66.2ms\tremaining: 16.5s\n",
      "4:\tlearn: 7.0895111\ttotal: 82.2ms\tremaining: 16.4s\n",
      "5:\tlearn: 6.6595027\ttotal: 97.8ms\tremaining: 16.2s\n",
      "6:\tlearn: 6.1174334\ttotal: 112ms\tremaining: 16s\n",
      "7:\tlearn: 5.7238521\ttotal: 128ms\tremaining: 15.9s\n",
      "8:\tlearn: 5.2933390\ttotal: 143ms\tremaining: 15.7s\n",
      "9:\tlearn: 4.9035462\ttotal: 158ms\tremaining: 15.6s\n",
      "10:\tlearn: 4.5628077\ttotal: 173ms\tremaining: 15.5s\n",
      "11:\tlearn: 4.2520875\ttotal: 187ms\tremaining: 15.4s\n",
      "12:\tlearn: 3.9881473\ttotal: 202ms\tremaining: 15.3s\n",
      "13:\tlearn: 3.7826559\ttotal: 216ms\tremaining: 15.2s\n",
      "14:\tlearn: 3.6349228\ttotal: 231ms\tremaining: 15.1s\n",
      "15:\tlearn: 3.4491583\ttotal: 244ms\tremaining: 15s\n",
      "16:\tlearn: 3.3037024\ttotal: 258ms\tremaining: 14.9s\n",
      "17:\tlearn: 3.1729983\ttotal: 271ms\tremaining: 14.8s\n",
      "18:\tlearn: 3.0885419\ttotal: 284ms\tremaining: 14.7s\n",
      "19:\tlearn: 2.9864971\ttotal: 298ms\tremaining: 14.6s\n",
      "20:\tlearn: 2.9121070\ttotal: 312ms\tremaining: 14.5s\n",
      "21:\tlearn: 2.8526739\ttotal: 325ms\tremaining: 14.5s\n",
      "22:\tlearn: 2.8007504\ttotal: 338ms\tremaining: 14.4s\n",
      "23:\tlearn: 2.7330946\ttotal: 352ms\tremaining: 14.3s\n",
      "24:\tlearn: 2.6747480\ttotal: 365ms\tremaining: 14.3s\n",
      "25:\tlearn: 2.6443929\ttotal: 379ms\tremaining: 14.2s\n",
      "26:\tlearn: 2.6121574\ttotal: 392ms\tremaining: 14.1s\n",
      "27:\tlearn: 2.5860594\ttotal: 405ms\tremaining: 14s\n",
      "28:\tlearn: 2.5445919\ttotal: 418ms\tremaining: 14s\n",
      "29:\tlearn: 2.5159992\ttotal: 431ms\tremaining: 13.9s\n",
      "30:\tlearn: 2.4925562\ttotal: 445ms\tremaining: 13.9s\n",
      "31:\tlearn: 2.4633116\ttotal: 458ms\tremaining: 13.9s\n",
      "32:\tlearn: 2.4499699\ttotal: 471ms\tremaining: 13.8s\n",
      "33:\tlearn: 2.4250337\ttotal: 484ms\tremaining: 13.7s\n",
      "34:\tlearn: 2.4144455\ttotal: 497ms\tremaining: 13.7s\n",
      "35:\tlearn: 2.3851942\ttotal: 511ms\tremaining: 13.7s\n",
      "36:\tlearn: 2.3753973\ttotal: 524ms\tremaining: 13.6s\n",
      "37:\tlearn: 2.3616695\ttotal: 537ms\tremaining: 13.6s\n",
      "38:\tlearn: 2.3544580\ttotal: 550ms\tremaining: 13.5s\n",
      "39:\tlearn: 2.3450926\ttotal: 564ms\tremaining: 13.5s\n",
      "40:\tlearn: 2.3391744\ttotal: 577ms\tremaining: 13.5s\n",
      "41:\tlearn: 2.3360188\ttotal: 591ms\tremaining: 13.5s\n",
      "42:\tlearn: 2.3160274\ttotal: 605ms\tremaining: 13.5s\n",
      "43:\tlearn: 2.3126130\ttotal: 618ms\tremaining: 13.4s\n",
      "44:\tlearn: 2.3098847\ttotal: 631ms\tremaining: 13.4s\n",
      "45:\tlearn: 2.2951448\ttotal: 645ms\tremaining: 13.4s\n",
      "46:\tlearn: 2.2925367\ttotal: 659ms\tremaining: 13.4s\n",
      "47:\tlearn: 2.2897962\ttotal: 672ms\tremaining: 13.3s\n",
      "48:\tlearn: 2.2877997\ttotal: 686ms\tremaining: 13.3s\n",
      "49:\tlearn: 2.2829495\ttotal: 698ms\tremaining: 13.3s\n",
      "50:\tlearn: 2.2817160\ttotal: 712ms\tremaining: 13.2s\n",
      "51:\tlearn: 2.2742446\ttotal: 725ms\tremaining: 13.2s\n",
      "52:\tlearn: 2.2726287\ttotal: 738ms\tremaining: 13.2s\n",
      "53:\tlearn: 2.2706099\ttotal: 751ms\tremaining: 13.2s\n",
      "54:\tlearn: 2.2695289\ttotal: 765ms\tremaining: 13.1s\n",
      "55:\tlearn: 2.2646228\ttotal: 778ms\tremaining: 13.1s\n",
      "56:\tlearn: 2.2636979\ttotal: 791ms\tremaining: 13.1s\n",
      "57:\tlearn: 2.2586956\ttotal: 803ms\tremaining: 13s\n",
      "58:\tlearn: 2.2579083\ttotal: 816ms\tremaining: 13s\n",
      "59:\tlearn: 2.2573681\ttotal: 829ms\tremaining: 13s\n",
      "60:\tlearn: 2.2569212\ttotal: 842ms\tremaining: 13s\n",
      "61:\tlearn: 2.2557164\ttotal: 855ms\tremaining: 12.9s\n",
      "62:\tlearn: 2.2551887\ttotal: 869ms\tremaining: 12.9s\n",
      "63:\tlearn: 2.2546493\ttotal: 883ms\tremaining: 12.9s\n",
      "64:\tlearn: 2.2537964\ttotal: 896ms\tremaining: 12.9s\n",
      "65:\tlearn: 2.2520912\ttotal: 909ms\tremaining: 12.9s\n",
      "66:\tlearn: 2.2517816\ttotal: 922ms\tremaining: 12.8s\n",
      "67:\tlearn: 2.2505599\ttotal: 936ms\tremaining: 12.8s\n",
      "68:\tlearn: 2.2493545\ttotal: 949ms\tremaining: 12.8s\n",
      "69:\tlearn: 2.2431102\ttotal: 962ms\tremaining: 12.8s\n",
      "70:\tlearn: 2.2423481\ttotal: 976ms\tremaining: 12.8s\n",
      "71:\tlearn: 2.2417701\ttotal: 990ms\tremaining: 12.8s\n",
      "72:\tlearn: 2.2404211\ttotal: 1s\tremaining: 12.7s\n",
      "73:\tlearn: 2.2394677\ttotal: 1.02s\tremaining: 12.7s\n",
      "74:\tlearn: 2.2356088\ttotal: 1.03s\tremaining: 12.7s\n",
      "75:\tlearn: 2.2274752\ttotal: 1.04s\tremaining: 12.7s\n",
      "76:\tlearn: 2.2262584\ttotal: 1.06s\tremaining: 12.7s\n",
      "77:\tlearn: 2.2256307\ttotal: 1.07s\tremaining: 12.7s\n",
      "78:\tlearn: 2.2244745\ttotal: 1.08s\tremaining: 12.7s\n",
      "79:\tlearn: 2.2179540\ttotal: 1.1s\tremaining: 12.6s\n",
      "80:\tlearn: 2.2168237\ttotal: 1.11s\tremaining: 12.6s\n",
      "81:\tlearn: 2.2164597\ttotal: 1.13s\tremaining: 12.6s\n",
      "82:\tlearn: 2.2164160\ttotal: 1.14s\tremaining: 12.6s\n",
      "83:\tlearn: 2.2153599\ttotal: 1.15s\tremaining: 12.6s\n",
      "84:\tlearn: 2.2145063\ttotal: 1.17s\tremaining: 12.5s\n",
      "85:\tlearn: 2.2120130\ttotal: 1.18s\tremaining: 12.5s\n",
      "86:\tlearn: 2.2100084\ttotal: 1.19s\tremaining: 12.5s\n",
      "87:\tlearn: 2.2098672\ttotal: 1.21s\tremaining: 12.5s\n",
      "88:\tlearn: 2.2094062\ttotal: 1.22s\tremaining: 12.5s\n",
      "89:\tlearn: 2.2092143\ttotal: 1.23s\tremaining: 12.5s\n",
      "90:\tlearn: 2.2078157\ttotal: 1.25s\tremaining: 12.5s\n",
      "91:\tlearn: 2.2075374\ttotal: 1.26s\tremaining: 12.4s\n",
      "92:\tlearn: 2.2036895\ttotal: 1.27s\tremaining: 12.4s\n",
      "93:\tlearn: 2.2033529\ttotal: 1.29s\tremaining: 12.4s\n",
      "94:\tlearn: 2.2025153\ttotal: 1.3s\tremaining: 12.4s\n",
      "95:\tlearn: 2.2020064\ttotal: 1.31s\tremaining: 12.4s\n",
      "96:\tlearn: 2.2018231\ttotal: 1.33s\tremaining: 12.4s\n",
      "97:\tlearn: 2.2013540\ttotal: 1.34s\tremaining: 12.4s\n",
      "98:\tlearn: 2.2007341\ttotal: 1.35s\tremaining: 12.3s\n",
      "99:\tlearn: 2.2005548\ttotal: 1.37s\tremaining: 12.3s\n",
      "100:\tlearn: 2.1998081\ttotal: 1.38s\tremaining: 12.3s\n",
      "101:\tlearn: 2.1987063\ttotal: 1.4s\tremaining: 12.3s\n",
      "102:\tlearn: 2.1978357\ttotal: 1.41s\tremaining: 12.3s\n",
      "103:\tlearn: 2.1968051\ttotal: 1.42s\tremaining: 12.3s\n",
      "104:\tlearn: 2.1965387\ttotal: 1.44s\tremaining: 12.2s\n",
      "105:\tlearn: 2.1961991\ttotal: 1.45s\tremaining: 12.2s\n",
      "106:\tlearn: 2.1943158\ttotal: 1.46s\tremaining: 12.2s\n",
      "107:\tlearn: 2.1913405\ttotal: 1.48s\tremaining: 12.2s\n",
      "108:\tlearn: 2.1910104\ttotal: 1.49s\tremaining: 12.2s\n",
      "109:\tlearn: 2.1860230\ttotal: 1.5s\tremaining: 12.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110:\tlearn: 2.1857919\ttotal: 1.52s\tremaining: 12.2s\n",
      "111:\tlearn: 2.1853734\ttotal: 1.53s\tremaining: 12.1s\n",
      "112:\tlearn: 2.1851944\ttotal: 1.54s\tremaining: 12.1s\n",
      "113:\tlearn: 2.1850655\ttotal: 1.56s\tremaining: 12.1s\n",
      "114:\tlearn: 2.1843197\ttotal: 1.57s\tremaining: 12.1s\n",
      "115:\tlearn: 2.1824809\ttotal: 1.58s\tremaining: 12.1s\n",
      "116:\tlearn: 2.1819529\ttotal: 1.59s\tremaining: 12s\n",
      "117:\tlearn: 2.1783790\ttotal: 1.61s\tremaining: 12s\n",
      "118:\tlearn: 2.1780321\ttotal: 1.62s\tremaining: 12s\n",
      "119:\tlearn: 2.1776712\ttotal: 1.64s\tremaining: 12s\n",
      "120:\tlearn: 2.1772480\ttotal: 1.65s\tremaining: 12s\n",
      "121:\tlearn: 2.1763268\ttotal: 1.66s\tremaining: 12s\n",
      "122:\tlearn: 2.1762790\ttotal: 1.68s\tremaining: 12s\n",
      "123:\tlearn: 2.1758880\ttotal: 1.69s\tremaining: 11.9s\n",
      "124:\tlearn: 2.1752959\ttotal: 1.71s\tremaining: 11.9s\n",
      "125:\tlearn: 2.1748227\ttotal: 1.72s\tremaining: 11.9s\n",
      "126:\tlearn: 2.1671480\ttotal: 1.73s\tremaining: 11.9s\n",
      "127:\tlearn: 2.1654029\ttotal: 1.75s\tremaining: 11.9s\n",
      "128:\tlearn: 2.1615356\ttotal: 1.76s\tremaining: 11.9s\n",
      "129:\tlearn: 2.1555891\ttotal: 1.77s\tremaining: 11.9s\n",
      "130:\tlearn: 2.1541481\ttotal: 1.79s\tremaining: 11.9s\n",
      "131:\tlearn: 2.1524332\ttotal: 1.8s\tremaining: 11.8s\n",
      "132:\tlearn: 2.1486197\ttotal: 1.81s\tremaining: 11.8s\n",
      "133:\tlearn: 2.1474773\ttotal: 1.83s\tremaining: 11.8s\n",
      "134:\tlearn: 2.1466256\ttotal: 1.84s\tremaining: 11.8s\n",
      "135:\tlearn: 2.1396066\ttotal: 1.85s\tremaining: 11.8s\n",
      "136:\tlearn: 2.1392323\ttotal: 1.87s\tremaining: 11.8s\n",
      "137:\tlearn: 2.1366423\ttotal: 1.88s\tremaining: 11.8s\n",
      "138:\tlearn: 2.1351954\ttotal: 1.9s\tremaining: 11.7s\n",
      "139:\tlearn: 2.1344097\ttotal: 1.91s\tremaining: 11.7s\n",
      "140:\tlearn: 2.1337646\ttotal: 1.92s\tremaining: 11.7s\n",
      "141:\tlearn: 2.1311008\ttotal: 1.94s\tremaining: 11.7s\n",
      "142:\tlearn: 2.1304175\ttotal: 1.95s\tremaining: 11.7s\n",
      "143:\tlearn: 2.1293129\ttotal: 1.96s\tremaining: 11.7s\n",
      "144:\tlearn: 2.1258478\ttotal: 1.98s\tremaining: 11.7s\n",
      "145:\tlearn: 2.1215646\ttotal: 1.99s\tremaining: 11.7s\n",
      "146:\tlearn: 2.1204691\ttotal: 2s\tremaining: 11.6s\n",
      "147:\tlearn: 2.1187660\ttotal: 2.02s\tremaining: 11.6s\n",
      "148:\tlearn: 2.1145984\ttotal: 2.03s\tremaining: 11.6s\n",
      "149:\tlearn: 2.1129493\ttotal: 2.05s\tremaining: 11.6s\n",
      "150:\tlearn: 2.1112084\ttotal: 2.06s\tremaining: 11.6s\n",
      "151:\tlearn: 2.1094279\ttotal: 2.07s\tremaining: 11.6s\n",
      "152:\tlearn: 2.1025698\ttotal: 2.09s\tremaining: 11.6s\n",
      "153:\tlearn: 2.0995698\ttotal: 2.1s\tremaining: 11.5s\n",
      "154:\tlearn: 2.0977850\ttotal: 2.11s\tremaining: 11.5s\n",
      "155:\tlearn: 2.0928826\ttotal: 2.13s\tremaining: 11.5s\n",
      "156:\tlearn: 2.0900366\ttotal: 2.14s\tremaining: 11.5s\n",
      "157:\tlearn: 2.0883629\ttotal: 2.15s\tremaining: 11.5s\n",
      "158:\tlearn: 2.0833555\ttotal: 2.17s\tremaining: 11.5s\n",
      "159:\tlearn: 2.0802134\ttotal: 2.18s\tremaining: 11.4s\n",
      "160:\tlearn: 2.0769116\ttotal: 2.19s\tremaining: 11.4s\n",
      "161:\tlearn: 2.0753476\ttotal: 2.21s\tremaining: 11.4s\n",
      "162:\tlearn: 2.0734989\ttotal: 2.22s\tremaining: 11.4s\n",
      "163:\tlearn: 2.0710493\ttotal: 2.23s\tremaining: 11.4s\n",
      "164:\tlearn: 2.0688431\ttotal: 2.25s\tremaining: 11.4s\n",
      "165:\tlearn: 2.0647663\ttotal: 2.26s\tremaining: 11.4s\n",
      "166:\tlearn: 2.0641377\ttotal: 2.27s\tremaining: 11.3s\n",
      "167:\tlearn: 2.0629509\ttotal: 2.29s\tremaining: 11.3s\n",
      "168:\tlearn: 2.0600935\ttotal: 2.3s\tremaining: 11.3s\n",
      "169:\tlearn: 2.0571909\ttotal: 2.31s\tremaining: 11.3s\n",
      "170:\tlearn: 2.0559116\ttotal: 2.33s\tremaining: 11.3s\n",
      "171:\tlearn: 2.0532117\ttotal: 2.34s\tremaining: 11.3s\n",
      "172:\tlearn: 2.0503505\ttotal: 2.35s\tremaining: 11.3s\n",
      "173:\tlearn: 2.0495864\ttotal: 2.37s\tremaining: 11.2s\n",
      "174:\tlearn: 2.0472109\ttotal: 2.38s\tremaining: 11.2s\n",
      "175:\tlearn: 2.0452108\ttotal: 2.4s\tremaining: 11.2s\n",
      "176:\tlearn: 2.0435819\ttotal: 2.41s\tremaining: 11.2s\n",
      "177:\tlearn: 2.0424246\ttotal: 2.42s\tremaining: 11.2s\n",
      "178:\tlearn: 2.0416596\ttotal: 2.44s\tremaining: 11.2s\n",
      "179:\tlearn: 2.0402792\ttotal: 2.45s\tremaining: 11.2s\n",
      "180:\tlearn: 2.0394453\ttotal: 2.46s\tremaining: 11.2s\n",
      "181:\tlearn: 2.0387053\ttotal: 2.48s\tremaining: 11.1s\n",
      "182:\tlearn: 2.0379647\ttotal: 2.49s\tremaining: 11.1s\n",
      "183:\tlearn: 2.0363919\ttotal: 2.5s\tremaining: 11.1s\n",
      "184:\tlearn: 2.0361922\ttotal: 2.52s\tremaining: 11.1s\n",
      "185:\tlearn: 2.0355055\ttotal: 2.53s\tremaining: 11.1s\n",
      "186:\tlearn: 2.0324068\ttotal: 2.54s\tremaining: 11.1s\n",
      "187:\tlearn: 2.0316721\ttotal: 2.56s\tremaining: 11.1s\n",
      "188:\tlearn: 2.0296420\ttotal: 2.57s\tremaining: 11s\n",
      "189:\tlearn: 2.0279105\ttotal: 2.59s\tremaining: 11s\n",
      "190:\tlearn: 2.0274978\ttotal: 2.6s\tremaining: 11s\n",
      "191:\tlearn: 2.0253354\ttotal: 2.61s\tremaining: 11s\n",
      "192:\tlearn: 2.0246406\ttotal: 2.63s\tremaining: 11s\n",
      "193:\tlearn: 2.0238478\ttotal: 2.64s\tremaining: 11s\n",
      "194:\tlearn: 2.0220239\ttotal: 2.65s\tremaining: 11s\n",
      "195:\tlearn: 2.0216887\ttotal: 2.67s\tremaining: 10.9s\n",
      "196:\tlearn: 2.0196953\ttotal: 2.68s\tremaining: 10.9s\n",
      "197:\tlearn: 2.0192223\ttotal: 2.69s\tremaining: 10.9s\n",
      "198:\tlearn: 2.0184822\ttotal: 2.71s\tremaining: 10.9s\n",
      "199:\tlearn: 2.0180001\ttotal: 2.72s\tremaining: 10.9s\n",
      "200:\tlearn: 2.0166391\ttotal: 2.73s\tremaining: 10.9s\n",
      "201:\tlearn: 2.0150757\ttotal: 2.75s\tremaining: 10.9s\n",
      "202:\tlearn: 2.0142112\ttotal: 2.76s\tremaining: 10.8s\n",
      "203:\tlearn: 2.0131769\ttotal: 2.77s\tremaining: 10.8s\n",
      "204:\tlearn: 2.0120863\ttotal: 2.79s\tremaining: 10.8s\n",
      "205:\tlearn: 2.0116554\ttotal: 2.8s\tremaining: 10.8s\n",
      "206:\tlearn: 2.0101821\ttotal: 2.82s\tremaining: 10.8s\n",
      "207:\tlearn: 2.0101617\ttotal: 2.83s\tremaining: 10.8s\n",
      "208:\tlearn: 2.0097744\ttotal: 2.84s\tremaining: 10.8s\n",
      "209:\tlearn: 2.0096951\ttotal: 2.85s\tremaining: 10.7s\n",
      "210:\tlearn: 2.0096595\ttotal: 2.87s\tremaining: 10.7s\n",
      "211:\tlearn: 2.0084010\ttotal: 2.88s\tremaining: 10.7s\n",
      "212:\tlearn: 2.0059713\ttotal: 2.89s\tremaining: 10.7s\n",
      "213:\tlearn: 2.0056016\ttotal: 2.91s\tremaining: 10.7s\n",
      "214:\tlearn: 2.0044115\ttotal: 2.92s\tremaining: 10.7s\n",
      "215:\tlearn: 2.0044109\ttotal: 2.93s\tremaining: 10.6s\n",
      "216:\tlearn: 2.0037241\ttotal: 2.95s\tremaining: 10.6s\n",
      "217:\tlearn: 2.0032575\ttotal: 2.96s\tremaining: 10.6s\n",
      "218:\tlearn: 2.0030333\ttotal: 2.97s\tremaining: 10.6s\n",
      "219:\tlearn: 2.0029642\ttotal: 2.99s\tremaining: 10.6s\n",
      "220:\tlearn: 2.0007694\ttotal: 3s\tremaining: 10.6s\n",
      "221:\tlearn: 1.9982693\ttotal: 3.02s\tremaining: 10.6s\n",
      "222:\tlearn: 1.9982466\ttotal: 3.03s\tremaining: 10.6s\n",
      "223:\tlearn: 1.9980699\ttotal: 3.04s\tremaining: 10.5s\n",
      "224:\tlearn: 1.9979367\ttotal: 3.05s\tremaining: 10.5s\n",
      "225:\tlearn: 1.9978438\ttotal: 3.07s\tremaining: 10.5s\n",
      "226:\tlearn: 1.9978288\ttotal: 3.08s\tremaining: 10.5s\n",
      "227:\tlearn: 1.9977816\ttotal: 3.09s\tremaining: 10.5s\n",
      "228:\tlearn: 1.9968901\ttotal: 3.11s\tremaining: 10.5s\n",
      "229:\tlearn: 1.9962291\ttotal: 3.12s\tremaining: 10.4s\n",
      "230:\tlearn: 1.9957304\ttotal: 3.13s\tremaining: 10.4s\n",
      "231:\tlearn: 1.9954468\ttotal: 3.14s\tremaining: 10.4s\n",
      "232:\tlearn: 1.9937131\ttotal: 3.16s\tremaining: 10.4s\n",
      "233:\tlearn: 1.9936259\ttotal: 3.17s\tremaining: 10.4s\n",
      "234:\tlearn: 1.9930193\ttotal: 3.18s\tremaining: 10.4s\n",
      "235:\tlearn: 1.9929044\ttotal: 3.2s\tremaining: 10.4s\n",
      "236:\tlearn: 1.9928214\ttotal: 3.21s\tremaining: 10.3s\n",
      "237:\tlearn: 1.9924702\ttotal: 3.22s\tremaining: 10.3s\n",
      "238:\tlearn: 1.9921302\ttotal: 3.24s\tremaining: 10.3s\n",
      "239:\tlearn: 1.9921267\ttotal: 3.25s\tremaining: 10.3s\n",
      "240:\tlearn: 1.9920671\ttotal: 3.26s\tremaining: 10.3s\n",
      "241:\tlearn: 1.9920542\ttotal: 3.28s\tremaining: 10.3s\n",
      "242:\tlearn: 1.9912266\ttotal: 3.29s\tremaining: 10.2s\n",
      "243:\tlearn: 1.9903399\ttotal: 3.3s\tremaining: 10.2s\n",
      "244:\tlearn: 1.9896574\ttotal: 3.32s\tremaining: 10.2s\n",
      "245:\tlearn: 1.9895733\ttotal: 3.33s\tremaining: 10.2s\n",
      "246:\tlearn: 1.9895507\ttotal: 3.34s\tremaining: 10.2s\n",
      "247:\tlearn: 1.9885027\ttotal: 3.36s\tremaining: 10.2s\n",
      "248:\tlearn: 1.9881980\ttotal: 3.37s\tremaining: 10.2s\n",
      "249:\tlearn: 1.9881625\ttotal: 3.38s\tremaining: 10.2s\n",
      "250:\tlearn: 1.9879030\ttotal: 3.4s\tremaining: 10.1s\n",
      "251:\tlearn: 1.9862204\ttotal: 3.41s\tremaining: 10.1s\n",
      "252:\tlearn: 1.9844665\ttotal: 3.42s\tremaining: 10.1s\n",
      "253:\tlearn: 1.9827259\ttotal: 3.44s\tremaining: 10.1s\n",
      "254:\tlearn: 1.9816571\ttotal: 3.45s\tremaining: 10.1s\n",
      "255:\tlearn: 1.9790650\ttotal: 3.46s\tremaining: 10.1s\n",
      "256:\tlearn: 1.9787501\ttotal: 3.48s\tremaining: 10.1s\n",
      "257:\tlearn: 1.9770646\ttotal: 3.49s\tremaining: 10s\n",
      "258:\tlearn: 1.9770235\ttotal: 3.5s\tremaining: 10s\n",
      "259:\tlearn: 1.9769197\ttotal: 3.52s\tremaining: 10s\n",
      "260:\tlearn: 1.9757585\ttotal: 3.53s\tremaining: 10s\n",
      "261:\tlearn: 1.9748840\ttotal: 3.54s\tremaining: 9.99s\n",
      "262:\tlearn: 1.9719470\ttotal: 3.56s\tremaining: 9.97s\n",
      "263:\tlearn: 1.9713191\ttotal: 3.57s\tremaining: 9.96s\n",
      "264:\tlearn: 1.9706195\ttotal: 3.58s\tremaining: 9.94s\n",
      "265:\tlearn: 1.9690910\ttotal: 3.6s\tremaining: 9.93s\n",
      "266:\tlearn: 1.9682384\ttotal: 3.61s\tremaining: 9.92s\n",
      "267:\tlearn: 1.9675204\ttotal: 3.63s\tremaining: 9.9s\n",
      "268:\tlearn: 1.9643540\ttotal: 3.64s\tremaining: 9.89s\n",
      "269:\tlearn: 1.9635624\ttotal: 3.65s\tremaining: 9.88s\n",
      "270:\tlearn: 1.9622888\ttotal: 3.67s\tremaining: 9.86s\n",
      "271:\tlearn: 1.9617288\ttotal: 3.68s\tremaining: 9.85s\n",
      "272:\tlearn: 1.9611001\ttotal: 3.69s\tremaining: 9.83s\n",
      "273:\tlearn: 1.9603078\ttotal: 3.71s\tremaining: 9.82s\n",
      "274:\tlearn: 1.9602878\ttotal: 3.72s\tremaining: 9.8s\n",
      "275:\tlearn: 1.9599354\ttotal: 3.73s\tremaining: 9.79s\n",
      "276:\tlearn: 1.9589888\ttotal: 3.75s\tremaining: 9.78s\n",
      "277:\tlearn: 1.9589629\ttotal: 3.76s\tremaining: 9.76s\n",
      "278:\tlearn: 1.9580985\ttotal: 3.77s\tremaining: 9.75s\n",
      "279:\tlearn: 1.9569077\ttotal: 3.79s\tremaining: 9.73s\n",
      "280:\tlearn: 1.9551143\ttotal: 3.8s\tremaining: 9.72s\n",
      "281:\tlearn: 1.9535945\ttotal: 3.81s\tremaining: 9.71s\n",
      "282:\tlearn: 1.9524685\ttotal: 3.83s\tremaining: 9.7s\n",
      "283:\tlearn: 1.9524673\ttotal: 3.84s\tremaining: 9.68s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284:\tlearn: 1.9512799\ttotal: 3.85s\tremaining: 9.67s\n",
      "285:\tlearn: 1.9507086\ttotal: 3.87s\tremaining: 9.65s\n",
      "286:\tlearn: 1.9499504\ttotal: 3.88s\tremaining: 9.64s\n",
      "287:\tlearn: 1.9494783\ttotal: 3.89s\tremaining: 9.63s\n",
      "288:\tlearn: 1.9486336\ttotal: 3.91s\tremaining: 9.61s\n",
      "289:\tlearn: 1.9482280\ttotal: 3.92s\tremaining: 9.6s\n",
      "290:\tlearn: 1.9481587\ttotal: 3.93s\tremaining: 9.58s\n",
      "291:\tlearn: 1.9481414\ttotal: 3.94s\tremaining: 9.56s\n",
      "292:\tlearn: 1.9480544\ttotal: 3.96s\tremaining: 9.55s\n",
      "293:\tlearn: 1.9476624\ttotal: 3.97s\tremaining: 9.54s\n",
      "294:\tlearn: 1.9475833\ttotal: 3.98s\tremaining: 9.52s\n",
      "295:\tlearn: 1.9475757\ttotal: 4s\tremaining: 9.51s\n",
      "296:\tlearn: 1.9473430\ttotal: 4.01s\tremaining: 9.49s\n",
      "297:\tlearn: 1.9465989\ttotal: 4.02s\tremaining: 9.48s\n",
      "298:\tlearn: 1.9465693\ttotal: 4.04s\tremaining: 9.46s\n",
      "299:\tlearn: 1.9465626\ttotal: 4.05s\tremaining: 9.45s\n",
      "300:\tlearn: 1.9461329\ttotal: 4.06s\tremaining: 9.43s\n",
      "301:\tlearn: 1.9460058\ttotal: 4.08s\tremaining: 9.42s\n",
      "302:\tlearn: 1.9455290\ttotal: 4.09s\tremaining: 9.41s\n",
      "303:\tlearn: 1.9454718\ttotal: 4.1s\tremaining: 9.39s\n",
      "304:\tlearn: 1.9453515\ttotal: 4.12s\tremaining: 9.38s\n",
      "305:\tlearn: 1.9449793\ttotal: 4.13s\tremaining: 9.37s\n",
      "306:\tlearn: 1.9445849\ttotal: 4.14s\tremaining: 9.35s\n",
      "307:\tlearn: 1.9437942\ttotal: 4.16s\tremaining: 9.34s\n",
      "308:\tlearn: 1.9436138\ttotal: 4.17s\tremaining: 9.32s\n",
      "309:\tlearn: 1.9425504\ttotal: 4.18s\tremaining: 9.31s\n",
      "310:\tlearn: 1.9419266\ttotal: 4.2s\tremaining: 9.3s\n",
      "311:\tlearn: 1.9413009\ttotal: 4.21s\tremaining: 9.28s\n",
      "312:\tlearn: 1.9409381\ttotal: 4.22s\tremaining: 9.27s\n",
      "313:\tlearn: 1.9399873\ttotal: 4.24s\tremaining: 9.26s\n",
      "314:\tlearn: 1.9389907\ttotal: 4.25s\tremaining: 9.24s\n",
      "315:\tlearn: 1.9379265\ttotal: 4.26s\tremaining: 9.23s\n",
      "316:\tlearn: 1.9365412\ttotal: 4.28s\tremaining: 9.21s\n",
      "317:\tlearn: 1.9359723\ttotal: 4.29s\tremaining: 9.2s\n",
      "318:\tlearn: 1.9358662\ttotal: 4.3s\tremaining: 9.19s\n",
      "319:\tlearn: 1.9348630\ttotal: 4.32s\tremaining: 9.18s\n",
      "320:\tlearn: 1.9348557\ttotal: 4.33s\tremaining: 9.16s\n",
      "321:\tlearn: 1.9348499\ttotal: 4.34s\tremaining: 9.15s\n",
      "322:\tlearn: 1.9345633\ttotal: 4.36s\tremaining: 9.13s\n",
      "323:\tlearn: 1.9345590\ttotal: 4.37s\tremaining: 9.12s\n",
      "324:\tlearn: 1.9343291\ttotal: 4.38s\tremaining: 9.11s\n",
      "325:\tlearn: 1.9339065\ttotal: 4.4s\tremaining: 9.09s\n",
      "326:\tlearn: 1.9334655\ttotal: 4.41s\tremaining: 9.08s\n",
      "327:\tlearn: 1.9334497\ttotal: 4.42s\tremaining: 9.06s\n",
      "328:\tlearn: 1.9333381\ttotal: 4.44s\tremaining: 9.05s\n",
      "329:\tlearn: 1.9327135\ttotal: 4.45s\tremaining: 9.03s\n",
      "330:\tlearn: 1.9314710\ttotal: 4.46s\tremaining: 9.02s\n",
      "331:\tlearn: 1.9305047\ttotal: 4.47s\tremaining: 9s\n",
      "332:\tlearn: 1.9297615\ttotal: 4.49s\tremaining: 8.99s\n",
      "333:\tlearn: 1.9296108\ttotal: 4.5s\tremaining: 8.98s\n",
      "334:\tlearn: 1.9290765\ttotal: 4.52s\tremaining: 8.96s\n",
      "335:\tlearn: 1.9289950\ttotal: 4.53s\tremaining: 8.95s\n",
      "336:\tlearn: 1.9286992\ttotal: 4.54s\tremaining: 8.94s\n",
      "337:\tlearn: 1.9284608\ttotal: 4.55s\tremaining: 8.92s\n",
      "338:\tlearn: 1.9283519\ttotal: 4.57s\tremaining: 8.91s\n",
      "339:\tlearn: 1.9282685\ttotal: 4.58s\tremaining: 8.89s\n",
      "340:\tlearn: 1.9281974\ttotal: 4.59s\tremaining: 8.88s\n",
      "341:\tlearn: 1.9280436\ttotal: 4.61s\tremaining: 8.86s\n",
      "342:\tlearn: 1.9279074\ttotal: 4.62s\tremaining: 8.85s\n",
      "343:\tlearn: 1.9271156\ttotal: 4.63s\tremaining: 8.84s\n",
      "344:\tlearn: 1.9270157\ttotal: 4.65s\tremaining: 8.82s\n",
      "345:\tlearn: 1.9269853\ttotal: 4.66s\tremaining: 8.81s\n",
      "346:\tlearn: 1.9269096\ttotal: 4.67s\tremaining: 8.79s\n",
      "347:\tlearn: 1.9269012\ttotal: 4.68s\tremaining: 8.78s\n",
      "348:\tlearn: 1.9264273\ttotal: 4.7s\tremaining: 8.77s\n",
      "349:\tlearn: 1.9263909\ttotal: 4.71s\tremaining: 8.75s\n",
      "350:\tlearn: 1.9263902\ttotal: 4.72s\tremaining: 8.74s\n",
      "351:\tlearn: 1.9263672\ttotal: 4.74s\tremaining: 8.72s\n",
      "352:\tlearn: 1.9257650\ttotal: 4.75s\tremaining: 8.71s\n",
      "353:\tlearn: 1.9256409\ttotal: 4.76s\tremaining: 8.7s\n",
      "354:\tlearn: 1.9255944\ttotal: 4.78s\tremaining: 8.68s\n",
      "355:\tlearn: 1.9255893\ttotal: 4.79s\tremaining: 8.67s\n",
      "356:\tlearn: 1.9252906\ttotal: 4.8s\tremaining: 8.65s\n",
      "357:\tlearn: 1.9250355\ttotal: 4.82s\tremaining: 8.64s\n",
      "358:\tlearn: 1.9245987\ttotal: 4.83s\tremaining: 8.62s\n",
      "359:\tlearn: 1.9245820\ttotal: 4.84s\tremaining: 8.61s\n",
      "360:\tlearn: 1.9245423\ttotal: 4.85s\tremaining: 8.59s\n",
      "361:\tlearn: 1.9245409\ttotal: 4.87s\tremaining: 8.58s\n",
      "362:\tlearn: 1.9243020\ttotal: 4.88s\tremaining: 8.56s\n",
      "363:\tlearn: 1.9238176\ttotal: 4.89s\tremaining: 8.55s\n",
      "364:\tlearn: 1.9231258\ttotal: 4.91s\tremaining: 8.53s\n",
      "365:\tlearn: 1.9230876\ttotal: 4.92s\tremaining: 8.52s\n",
      "366:\tlearn: 1.9215725\ttotal: 4.93s\tremaining: 8.51s\n",
      "367:\tlearn: 1.9205994\ttotal: 4.95s\tremaining: 8.49s\n",
      "368:\tlearn: 1.9205050\ttotal: 4.96s\tremaining: 8.48s\n",
      "369:\tlearn: 1.9205037\ttotal: 4.97s\tremaining: 8.46s\n",
      "370:\tlearn: 1.9201627\ttotal: 4.98s\tremaining: 8.45s\n",
      "371:\tlearn: 1.9199434\ttotal: 5s\tremaining: 8.44s\n",
      "372:\tlearn: 1.9199327\ttotal: 5.01s\tremaining: 8.42s\n",
      "373:\tlearn: 1.9198446\ttotal: 5.02s\tremaining: 8.41s\n",
      "374:\tlearn: 1.9190354\ttotal: 5.04s\tremaining: 8.4s\n",
      "375:\tlearn: 1.9189006\ttotal: 5.05s\tremaining: 8.38s\n",
      "376:\tlearn: 1.9184121\ttotal: 5.06s\tremaining: 8.37s\n",
      "377:\tlearn: 1.9176016\ttotal: 5.08s\tremaining: 8.36s\n",
      "378:\tlearn: 1.9173995\ttotal: 5.09s\tremaining: 8.34s\n",
      "379:\tlearn: 1.9171961\ttotal: 5.1s\tremaining: 8.33s\n",
      "380:\tlearn: 1.9171050\ttotal: 5.12s\tremaining: 8.31s\n",
      "381:\tlearn: 1.9168728\ttotal: 5.13s\tremaining: 8.3s\n",
      "382:\tlearn: 1.9168609\ttotal: 5.14s\tremaining: 8.29s\n",
      "383:\tlearn: 1.9167140\ttotal: 5.16s\tremaining: 8.27s\n",
      "384:\tlearn: 1.9162290\ttotal: 5.17s\tremaining: 8.26s\n",
      "385:\tlearn: 1.9161948\ttotal: 5.18s\tremaining: 8.25s\n",
      "386:\tlearn: 1.9161859\ttotal: 5.2s\tremaining: 8.23s\n",
      "387:\tlearn: 1.9161846\ttotal: 5.21s\tremaining: 8.22s\n",
      "388:\tlearn: 1.9161773\ttotal: 5.22s\tremaining: 8.21s\n",
      "389:\tlearn: 1.9161773\ttotal: 5.24s\tremaining: 8.19s\n",
      "390:\tlearn: 1.9161670\ttotal: 5.25s\tremaining: 8.18s\n",
      "391:\tlearn: 1.9157132\ttotal: 5.26s\tremaining: 8.16s\n",
      "392:\tlearn: 1.9156970\ttotal: 5.28s\tremaining: 8.15s\n",
      "393:\tlearn: 1.9156795\ttotal: 5.29s\tremaining: 8.14s\n",
      "394:\tlearn: 1.9156647\ttotal: 5.3s\tremaining: 8.13s\n",
      "395:\tlearn: 1.9156592\ttotal: 5.32s\tremaining: 8.11s\n",
      "396:\tlearn: 1.9155832\ttotal: 5.33s\tremaining: 8.1s\n",
      "397:\tlearn: 1.9154718\ttotal: 5.34s\tremaining: 8.08s\n",
      "398:\tlearn: 1.9150673\ttotal: 5.36s\tremaining: 8.07s\n",
      "399:\tlearn: 1.9149770\ttotal: 5.37s\tremaining: 8.06s\n",
      "400:\tlearn: 1.9149125\ttotal: 5.38s\tremaining: 8.04s\n",
      "401:\tlearn: 1.9146224\ttotal: 5.4s\tremaining: 8.03s\n",
      "402:\tlearn: 1.9133524\ttotal: 5.41s\tremaining: 8.02s\n",
      "403:\tlearn: 1.9129819\ttotal: 5.42s\tremaining: 8s\n",
      "404:\tlearn: 1.9129659\ttotal: 5.44s\tremaining: 7.99s\n",
      "405:\tlearn: 1.9129659\ttotal: 5.45s\tremaining: 7.97s\n",
      "406:\tlearn: 1.9129135\ttotal: 5.46s\tremaining: 7.96s\n",
      "407:\tlearn: 1.9129132\ttotal: 5.48s\tremaining: 7.95s\n",
      "408:\tlearn: 1.9128990\ttotal: 5.49s\tremaining: 7.93s\n",
      "409:\tlearn: 1.9128710\ttotal: 5.5s\tremaining: 7.92s\n",
      "410:\tlearn: 1.9121354\ttotal: 5.52s\tremaining: 7.91s\n",
      "411:\tlearn: 1.9119883\ttotal: 5.53s\tremaining: 7.89s\n",
      "412:\tlearn: 1.9118372\ttotal: 5.54s\tremaining: 7.88s\n",
      "413:\tlearn: 1.9118186\ttotal: 5.55s\tremaining: 7.86s\n",
      "414:\tlearn: 1.9115793\ttotal: 5.57s\tremaining: 7.85s\n",
      "415:\tlearn: 1.9114700\ttotal: 5.58s\tremaining: 7.84s\n",
      "416:\tlearn: 1.9113746\ttotal: 5.6s\tremaining: 7.82s\n",
      "417:\tlearn: 1.9113721\ttotal: 5.61s\tremaining: 7.81s\n",
      "418:\tlearn: 1.9113432\ttotal: 5.62s\tremaining: 7.8s\n",
      "419:\tlearn: 1.9111563\ttotal: 5.63s\tremaining: 7.78s\n",
      "420:\tlearn: 1.9110514\ttotal: 5.65s\tremaining: 7.77s\n",
      "421:\tlearn: 1.9109932\ttotal: 5.66s\tremaining: 7.75s\n",
      "422:\tlearn: 1.9106969\ttotal: 5.67s\tremaining: 7.74s\n",
      "423:\tlearn: 1.9106814\ttotal: 5.69s\tremaining: 7.73s\n",
      "424:\tlearn: 1.9106759\ttotal: 5.7s\tremaining: 7.71s\n",
      "425:\tlearn: 1.9101903\ttotal: 5.71s\tremaining: 7.7s\n",
      "426:\tlearn: 1.9101740\ttotal: 5.73s\tremaining: 7.68s\n",
      "427:\tlearn: 1.9101282\ttotal: 5.74s\tremaining: 7.67s\n",
      "428:\tlearn: 1.9100712\ttotal: 5.75s\tremaining: 7.65s\n",
      "429:\tlearn: 1.9099115\ttotal: 5.76s\tremaining: 7.64s\n",
      "430:\tlearn: 1.9098080\ttotal: 5.78s\tremaining: 7.63s\n",
      "431:\tlearn: 1.9094325\ttotal: 5.79s\tremaining: 7.61s\n",
      "432:\tlearn: 1.9091301\ttotal: 5.8s\tremaining: 7.6s\n",
      "433:\tlearn: 1.9090612\ttotal: 5.82s\tremaining: 7.58s\n",
      "434:\tlearn: 1.9089773\ttotal: 5.83s\tremaining: 7.57s\n",
      "435:\tlearn: 1.9089767\ttotal: 5.84s\tremaining: 7.56s\n",
      "436:\tlearn: 1.9089761\ttotal: 5.85s\tremaining: 7.54s\n",
      "437:\tlearn: 1.9089760\ttotal: 5.87s\tremaining: 7.53s\n",
      "438:\tlearn: 1.9089750\ttotal: 5.88s\tremaining: 7.51s\n",
      "439:\tlearn: 1.9089723\ttotal: 5.89s\tremaining: 7.5s\n",
      "440:\tlearn: 1.9089723\ttotal: 5.91s\tremaining: 7.49s\n",
      "441:\tlearn: 1.9089709\ttotal: 5.92s\tremaining: 7.47s\n",
      "442:\tlearn: 1.9085769\ttotal: 5.93s\tremaining: 7.46s\n",
      "443:\tlearn: 1.9085544\ttotal: 5.95s\tremaining: 7.45s\n",
      "444:\tlearn: 1.9079911\ttotal: 5.96s\tremaining: 7.44s\n",
      "445:\tlearn: 1.9077557\ttotal: 5.98s\tremaining: 7.42s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446:\tlearn: 1.9068124\ttotal: 5.99s\tremaining: 7.41s\n",
      "447:\tlearn: 1.9066852\ttotal: 6.01s\tremaining: 7.4s\n",
      "448:\tlearn: 1.9066834\ttotal: 6.02s\tremaining: 7.39s\n",
      "449:\tlearn: 1.9066786\ttotal: 6.04s\tremaining: 7.38s\n",
      "450:\tlearn: 1.9066774\ttotal: 6.05s\tremaining: 7.37s\n",
      "451:\tlearn: 1.9066772\ttotal: 6.07s\tremaining: 7.36s\n",
      "452:\tlearn: 1.9065988\ttotal: 6.08s\tremaining: 7.34s\n",
      "453:\tlearn: 1.9063475\ttotal: 6.09s\tremaining: 7.33s\n",
      "454:\tlearn: 1.9063003\ttotal: 6.11s\tremaining: 7.31s\n",
      "455:\tlearn: 1.9062581\ttotal: 6.12s\tremaining: 7.3s\n",
      "456:\tlearn: 1.9062581\ttotal: 6.13s\tremaining: 7.29s\n",
      "457:\tlearn: 1.9062576\ttotal: 6.14s\tremaining: 7.27s\n",
      "458:\tlearn: 1.9062576\ttotal: 6.16s\tremaining: 7.26s\n",
      "459:\tlearn: 1.9062510\ttotal: 6.17s\tremaining: 7.24s\n",
      "460:\tlearn: 1.9062328\ttotal: 6.18s\tremaining: 7.23s\n",
      "461:\tlearn: 1.9062095\ttotal: 6.2s\tremaining: 7.22s\n",
      "462:\tlearn: 1.9061865\ttotal: 6.21s\tremaining: 7.2s\n",
      "463:\tlearn: 1.9060861\ttotal: 6.22s\tremaining: 7.19s\n",
      "464:\tlearn: 1.9051283\ttotal: 6.24s\tremaining: 7.18s\n",
      "465:\tlearn: 1.9051102\ttotal: 6.25s\tremaining: 7.16s\n",
      "466:\tlearn: 1.9050893\ttotal: 6.26s\tremaining: 7.15s\n",
      "467:\tlearn: 1.9038972\ttotal: 6.28s\tremaining: 7.14s\n",
      "468:\tlearn: 1.9032286\ttotal: 6.29s\tremaining: 7.12s\n",
      "469:\tlearn: 1.9030867\ttotal: 6.31s\tremaining: 7.11s\n",
      "470:\tlearn: 1.9019736\ttotal: 6.32s\tremaining: 7.1s\n",
      "471:\tlearn: 1.8999793\ttotal: 6.33s\tremaining: 7.08s\n",
      "472:\tlearn: 1.8999765\ttotal: 6.34s\tremaining: 7.07s\n",
      "473:\tlearn: 1.8999228\ttotal: 6.36s\tremaining: 7.06s\n",
      "474:\tlearn: 1.8998732\ttotal: 6.37s\tremaining: 7.04s\n",
      "475:\tlearn: 1.8998582\ttotal: 6.38s\tremaining: 7.03s\n",
      "476:\tlearn: 1.8998482\ttotal: 6.4s\tremaining: 7.01s\n",
      "477:\tlearn: 1.8998290\ttotal: 6.41s\tremaining: 7s\n",
      "478:\tlearn: 1.8998257\ttotal: 6.42s\tremaining: 6.99s\n",
      "479:\tlearn: 1.8997800\ttotal: 6.44s\tremaining: 6.97s\n",
      "480:\tlearn: 1.8991513\ttotal: 6.45s\tremaining: 6.96s\n",
      "481:\tlearn: 1.8991512\ttotal: 6.46s\tremaining: 6.95s\n",
      "482:\tlearn: 1.8991511\ttotal: 6.48s\tremaining: 6.93s\n",
      "483:\tlearn: 1.8988516\ttotal: 6.49s\tremaining: 6.92s\n",
      "484:\tlearn: 1.8988391\ttotal: 6.5s\tremaining: 6.91s\n",
      "485:\tlearn: 1.8978462\ttotal: 6.52s\tremaining: 6.89s\n",
      "486:\tlearn: 1.8978389\ttotal: 6.53s\tremaining: 6.88s\n",
      "487:\tlearn: 1.8978389\ttotal: 6.56s\tremaining: 6.88s\n",
      "488:\tlearn: 1.8978375\ttotal: 6.57s\tremaining: 6.87s\n",
      "489:\tlearn: 1.8973389\ttotal: 6.58s\tremaining: 6.85s\n",
      "490:\tlearn: 1.8970288\ttotal: 6.6s\tremaining: 6.84s\n",
      "491:\tlearn: 1.8967139\ttotal: 6.61s\tremaining: 6.83s\n",
      "492:\tlearn: 1.8962071\ttotal: 6.62s\tremaining: 6.81s\n",
      "493:\tlearn: 1.8953804\ttotal: 6.64s\tremaining: 6.8s\n",
      "494:\tlearn: 1.8925487\ttotal: 6.65s\tremaining: 6.79s\n",
      "495:\tlearn: 1.8925481\ttotal: 6.67s\tremaining: 6.77s\n",
      "496:\tlearn: 1.8925372\ttotal: 6.68s\tremaining: 6.76s\n",
      "497:\tlearn: 1.8925371\ttotal: 6.69s\tremaining: 6.75s\n",
      "498:\tlearn: 1.8925357\ttotal: 6.71s\tremaining: 6.73s\n",
      "499:\tlearn: 1.8924659\ttotal: 6.72s\tremaining: 6.72s\n",
      "500:\tlearn: 1.8923346\ttotal: 6.73s\tremaining: 6.71s\n",
      "501:\tlearn: 1.8923068\ttotal: 6.75s\tremaining: 6.69s\n",
      "502:\tlearn: 1.8922894\ttotal: 6.76s\tremaining: 6.68s\n",
      "503:\tlearn: 1.8918241\ttotal: 6.77s\tremaining: 6.66s\n",
      "504:\tlearn: 1.8916228\ttotal: 6.78s\tremaining: 6.65s\n",
      "505:\tlearn: 1.8914981\ttotal: 6.8s\tremaining: 6.64s\n",
      "506:\tlearn: 1.8914475\ttotal: 6.81s\tremaining: 6.62s\n",
      "507:\tlearn: 1.8913199\ttotal: 6.82s\tremaining: 6.61s\n",
      "508:\tlearn: 1.8912470\ttotal: 6.84s\tremaining: 6.59s\n",
      "509:\tlearn: 1.8911950\ttotal: 6.85s\tremaining: 6.58s\n",
      "510:\tlearn: 1.8911929\ttotal: 6.86s\tremaining: 6.57s\n",
      "511:\tlearn: 1.8910067\ttotal: 6.88s\tremaining: 6.55s\n",
      "512:\tlearn: 1.8899011\ttotal: 6.89s\tremaining: 6.54s\n",
      "513:\tlearn: 1.8870016\ttotal: 6.9s\tremaining: 6.53s\n",
      "514:\tlearn: 1.8869918\ttotal: 6.92s\tremaining: 6.51s\n",
      "515:\tlearn: 1.8869760\ttotal: 6.93s\tremaining: 6.5s\n",
      "516:\tlearn: 1.8869659\ttotal: 6.94s\tremaining: 6.49s\n",
      "517:\tlearn: 1.8869659\ttotal: 6.96s\tremaining: 6.47s\n",
      "518:\tlearn: 1.8869655\ttotal: 6.97s\tremaining: 6.46s\n",
      "519:\tlearn: 1.8869655\ttotal: 6.98s\tremaining: 6.45s\n",
      "520:\tlearn: 1.8868593\ttotal: 7s\tremaining: 6.43s\n",
      "521:\tlearn: 1.8863958\ttotal: 7.01s\tremaining: 6.42s\n",
      "522:\tlearn: 1.8863953\ttotal: 7.02s\tremaining: 6.41s\n",
      "523:\tlearn: 1.8863952\ttotal: 7.04s\tremaining: 6.39s\n",
      "524:\tlearn: 1.8863952\ttotal: 7.05s\tremaining: 6.38s\n",
      "525:\tlearn: 1.8862172\ttotal: 7.07s\tremaining: 6.37s\n",
      "526:\tlearn: 1.8856415\ttotal: 7.08s\tremaining: 6.35s\n",
      "527:\tlearn: 1.8854974\ttotal: 7.09s\tremaining: 6.34s\n",
      "528:\tlearn: 1.8846074\ttotal: 7.11s\tremaining: 6.33s\n",
      "529:\tlearn: 1.8840503\ttotal: 7.12s\tremaining: 6.31s\n",
      "530:\tlearn: 1.8837416\ttotal: 7.13s\tremaining: 6.3s\n",
      "531:\tlearn: 1.8836963\ttotal: 7.14s\tremaining: 6.29s\n",
      "532:\tlearn: 1.8836595\ttotal: 7.16s\tremaining: 6.27s\n",
      "533:\tlearn: 1.8836590\ttotal: 7.17s\tremaining: 6.26s\n",
      "534:\tlearn: 1.8836590\ttotal: 7.18s\tremaining: 6.24s\n",
      "535:\tlearn: 1.8836582\ttotal: 7.2s\tremaining: 6.23s\n",
      "536:\tlearn: 1.8836256\ttotal: 7.21s\tremaining: 6.22s\n",
      "537:\tlearn: 1.8826043\ttotal: 7.22s\tremaining: 6.2s\n",
      "538:\tlearn: 1.8820296\ttotal: 7.24s\tremaining: 6.19s\n",
      "539:\tlearn: 1.8819848\ttotal: 7.25s\tremaining: 6.18s\n",
      "540:\tlearn: 1.8818976\ttotal: 7.26s\tremaining: 6.16s\n",
      "541:\tlearn: 1.8818828\ttotal: 7.28s\tremaining: 6.15s\n",
      "542:\tlearn: 1.8817114\ttotal: 7.29s\tremaining: 6.13s\n",
      "543:\tlearn: 1.8803305\ttotal: 7.3s\tremaining: 6.12s\n",
      "544:\tlearn: 1.8799327\ttotal: 7.32s\tremaining: 6.11s\n",
      "545:\tlearn: 1.8798991\ttotal: 7.33s\tremaining: 6.09s\n",
      "546:\tlearn: 1.8798779\ttotal: 7.34s\tremaining: 6.08s\n",
      "547:\tlearn: 1.8798764\ttotal: 7.36s\tremaining: 6.07s\n",
      "548:\tlearn: 1.8795428\ttotal: 7.37s\tremaining: 6.05s\n",
      "549:\tlearn: 1.8788951\ttotal: 7.38s\tremaining: 6.04s\n",
      "550:\tlearn: 1.8785303\ttotal: 7.39s\tremaining: 6.03s\n",
      "551:\tlearn: 1.8784674\ttotal: 7.41s\tremaining: 6.01s\n",
      "552:\tlearn: 1.8782086\ttotal: 7.42s\tremaining: 6s\n",
      "553:\tlearn: 1.8781871\ttotal: 7.43s\tremaining: 5.98s\n",
      "554:\tlearn: 1.8780964\ttotal: 7.44s\tremaining: 5.97s\n",
      "555:\tlearn: 1.8780339\ttotal: 7.46s\tremaining: 5.95s\n",
      "556:\tlearn: 1.8776233\ttotal: 7.47s\tremaining: 5.94s\n",
      "557:\tlearn: 1.8772683\ttotal: 7.48s\tremaining: 5.93s\n",
      "558:\tlearn: 1.8766927\ttotal: 7.5s\tremaining: 5.91s\n",
      "559:\tlearn: 1.8766697\ttotal: 7.51s\tremaining: 5.9s\n",
      "560:\tlearn: 1.8766696\ttotal: 7.52s\tremaining: 5.89s\n",
      "561:\tlearn: 1.8766674\ttotal: 7.53s\tremaining: 5.87s\n",
      "562:\tlearn: 1.8766653\ttotal: 7.55s\tremaining: 5.86s\n",
      "563:\tlearn: 1.8766653\ttotal: 7.56s\tremaining: 5.84s\n",
      "564:\tlearn: 1.8766652\ttotal: 7.57s\tremaining: 5.83s\n",
      "565:\tlearn: 1.8766648\ttotal: 7.59s\tremaining: 5.82s\n",
      "566:\tlearn: 1.8765331\ttotal: 7.6s\tremaining: 5.8s\n",
      "567:\tlearn: 1.8765330\ttotal: 7.61s\tremaining: 5.79s\n",
      "568:\tlearn: 1.8765329\ttotal: 7.63s\tremaining: 5.78s\n",
      "569:\tlearn: 1.8765327\ttotal: 7.64s\tremaining: 5.76s\n",
      "570:\tlearn: 1.8765317\ttotal: 7.65s\tremaining: 5.75s\n",
      "571:\tlearn: 1.8765311\ttotal: 7.67s\tremaining: 5.74s\n",
      "572:\tlearn: 1.8765026\ttotal: 7.68s\tremaining: 5.72s\n",
      "573:\tlearn: 1.8751719\ttotal: 7.69s\tremaining: 5.71s\n",
      "574:\tlearn: 1.8744366\ttotal: 7.7s\tremaining: 5.69s\n",
      "575:\tlearn: 1.8742047\ttotal: 7.72s\tremaining: 5.68s\n",
      "576:\tlearn: 1.8742003\ttotal: 7.73s\tremaining: 5.67s\n",
      "577:\tlearn: 1.8741800\ttotal: 7.74s\tremaining: 5.65s\n",
      "578:\tlearn: 1.8741793\ttotal: 7.75s\tremaining: 5.64s\n",
      "579:\tlearn: 1.8741792\ttotal: 7.77s\tremaining: 5.63s\n",
      "580:\tlearn: 1.8741710\ttotal: 7.78s\tremaining: 5.61s\n",
      "581:\tlearn: 1.8741707\ttotal: 7.79s\tremaining: 5.6s\n",
      "582:\tlearn: 1.8741706\ttotal: 7.81s\tremaining: 5.58s\n",
      "583:\tlearn: 1.8741706\ttotal: 7.82s\tremaining: 5.57s\n",
      "584:\tlearn: 1.8741208\ttotal: 7.83s\tremaining: 5.56s\n",
      "585:\tlearn: 1.8741203\ttotal: 7.84s\tremaining: 5.54s\n",
      "586:\tlearn: 1.8741203\ttotal: 7.86s\tremaining: 5.53s\n",
      "587:\tlearn: 1.8741200\ttotal: 7.87s\tremaining: 5.51s\n",
      "588:\tlearn: 1.8741199\ttotal: 7.88s\tremaining: 5.5s\n",
      "589:\tlearn: 1.8741193\ttotal: 7.9s\tremaining: 5.49s\n",
      "590:\tlearn: 1.8741035\ttotal: 7.91s\tremaining: 5.47s\n",
      "591:\tlearn: 1.8741031\ttotal: 7.92s\tremaining: 5.46s\n",
      "592:\tlearn: 1.8741030\ttotal: 7.93s\tremaining: 5.45s\n",
      "593:\tlearn: 1.8741026\ttotal: 7.95s\tremaining: 5.43s\n",
      "594:\tlearn: 1.8741026\ttotal: 7.96s\tremaining: 5.42s\n",
      "595:\tlearn: 1.8741026\ttotal: 7.97s\tremaining: 5.41s\n",
      "596:\tlearn: 1.8741026\ttotal: 7.99s\tremaining: 5.39s\n",
      "597:\tlearn: 1.8741026\ttotal: 8s\tremaining: 5.38s\n",
      "598:\tlearn: 1.8740862\ttotal: 8.01s\tremaining: 5.36s\n",
      "599:\tlearn: 1.8740842\ttotal: 8.03s\tremaining: 5.35s\n",
      "600:\tlearn: 1.8740841\ttotal: 8.04s\tremaining: 5.34s\n",
      "601:\tlearn: 1.8740841\ttotal: 8.05s\tremaining: 5.32s\n",
      "602:\tlearn: 1.8740839\ttotal: 8.06s\tremaining: 5.31s\n",
      "603:\tlearn: 1.8740839\ttotal: 8.08s\tremaining: 5.29s\n",
      "604:\tlearn: 1.8740801\ttotal: 8.09s\tremaining: 5.28s\n",
      "605:\tlearn: 1.8740779\ttotal: 8.1s\tremaining: 5.27s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606:\tlearn: 1.8738345\ttotal: 8.12s\tremaining: 5.25s\n",
      "607:\tlearn: 1.8735478\ttotal: 8.13s\tremaining: 5.24s\n",
      "608:\tlearn: 1.8727283\ttotal: 8.14s\tremaining: 5.23s\n",
      "609:\tlearn: 1.8714412\ttotal: 8.16s\tremaining: 5.21s\n",
      "610:\tlearn: 1.8712268\ttotal: 8.17s\tremaining: 5.2s\n",
      "611:\tlearn: 1.8712153\ttotal: 8.18s\tremaining: 5.19s\n",
      "612:\tlearn: 1.8711810\ttotal: 8.2s\tremaining: 5.17s\n",
      "613:\tlearn: 1.8709585\ttotal: 8.21s\tremaining: 5.16s\n",
      "614:\tlearn: 1.8709562\ttotal: 8.22s\tremaining: 5.15s\n",
      "615:\tlearn: 1.8706911\ttotal: 8.23s\tremaining: 5.13s\n",
      "616:\tlearn: 1.8706814\ttotal: 8.25s\tremaining: 5.12s\n",
      "617:\tlearn: 1.8706802\ttotal: 8.26s\tremaining: 5.11s\n",
      "618:\tlearn: 1.8706801\ttotal: 8.27s\tremaining: 5.09s\n",
      "619:\tlearn: 1.8706799\ttotal: 8.29s\tremaining: 5.08s\n",
      "620:\tlearn: 1.8704262\ttotal: 8.3s\tremaining: 5.06s\n",
      "621:\tlearn: 1.8698088\ttotal: 8.31s\tremaining: 5.05s\n",
      "622:\tlearn: 1.8693715\ttotal: 8.33s\tremaining: 5.04s\n",
      "623:\tlearn: 1.8692006\ttotal: 8.35s\tremaining: 5.03s\n",
      "624:\tlearn: 1.8691893\ttotal: 8.36s\tremaining: 5.01s\n",
      "625:\tlearn: 1.8691890\ttotal: 8.37s\tremaining: 5s\n",
      "626:\tlearn: 1.8691887\ttotal: 8.38s\tremaining: 4.99s\n",
      "627:\tlearn: 1.8691750\ttotal: 8.4s\tremaining: 4.97s\n",
      "628:\tlearn: 1.8690699\ttotal: 8.41s\tremaining: 4.96s\n",
      "629:\tlearn: 1.8690399\ttotal: 8.42s\tremaining: 4.95s\n",
      "630:\tlearn: 1.8682649\ttotal: 8.44s\tremaining: 4.93s\n",
      "631:\tlearn: 1.8673170\ttotal: 8.45s\tremaining: 4.92s\n",
      "632:\tlearn: 1.8664143\ttotal: 8.46s\tremaining: 4.91s\n",
      "633:\tlearn: 1.8663964\ttotal: 8.47s\tremaining: 4.89s\n",
      "634:\tlearn: 1.8662998\ttotal: 8.49s\tremaining: 4.88s\n",
      "635:\tlearn: 1.8659769\ttotal: 8.5s\tremaining: 4.86s\n",
      "636:\tlearn: 1.8655067\ttotal: 8.51s\tremaining: 4.85s\n",
      "637:\tlearn: 1.8654249\ttotal: 8.52s\tremaining: 4.84s\n",
      "638:\tlearn: 1.8641644\ttotal: 8.54s\tremaining: 4.82s\n",
      "639:\tlearn: 1.8638726\ttotal: 8.55s\tremaining: 4.81s\n",
      "640:\tlearn: 1.8634715\ttotal: 8.56s\tremaining: 4.79s\n",
      "641:\tlearn: 1.8634380\ttotal: 8.58s\tremaining: 4.78s\n",
      "642:\tlearn: 1.8632406\ttotal: 8.59s\tremaining: 4.77s\n",
      "643:\tlearn: 1.8629372\ttotal: 8.6s\tremaining: 4.75s\n",
      "644:\tlearn: 1.8627999\ttotal: 8.62s\tremaining: 4.74s\n",
      "645:\tlearn: 1.8627666\ttotal: 8.63s\tremaining: 4.73s\n",
      "646:\tlearn: 1.8624653\ttotal: 8.64s\tremaining: 4.72s\n",
      "647:\tlearn: 1.8622668\ttotal: 8.66s\tremaining: 4.7s\n",
      "648:\tlearn: 1.8622238\ttotal: 8.67s\tremaining: 4.69s\n",
      "649:\tlearn: 1.8622237\ttotal: 8.69s\tremaining: 4.68s\n",
      "650:\tlearn: 1.8621834\ttotal: 8.7s\tremaining: 4.66s\n",
      "651:\tlearn: 1.8620997\ttotal: 8.71s\tremaining: 4.65s\n",
      "652:\tlearn: 1.8620988\ttotal: 8.72s\tremaining: 4.64s\n",
      "653:\tlearn: 1.8620982\ttotal: 8.74s\tremaining: 4.62s\n",
      "654:\tlearn: 1.8620968\ttotal: 8.75s\tremaining: 4.61s\n",
      "655:\tlearn: 1.8620953\ttotal: 8.77s\tremaining: 4.6s\n",
      "656:\tlearn: 1.8618931\ttotal: 8.78s\tremaining: 4.58s\n",
      "657:\tlearn: 1.8616732\ttotal: 8.79s\tremaining: 4.57s\n",
      "658:\tlearn: 1.8607386\ttotal: 8.81s\tremaining: 4.56s\n",
      "659:\tlearn: 1.8607236\ttotal: 8.82s\tremaining: 4.54s\n",
      "660:\tlearn: 1.8597917\ttotal: 8.83s\tremaining: 4.53s\n",
      "661:\tlearn: 1.8597665\ttotal: 8.84s\tremaining: 4.51s\n",
      "662:\tlearn: 1.8592674\ttotal: 8.86s\tremaining: 4.5s\n",
      "663:\tlearn: 1.8584243\ttotal: 8.87s\tremaining: 4.49s\n",
      "664:\tlearn: 1.8580960\ttotal: 8.88s\tremaining: 4.47s\n",
      "665:\tlearn: 1.8574525\ttotal: 8.9s\tremaining: 4.46s\n",
      "666:\tlearn: 1.8574448\ttotal: 8.91s\tremaining: 4.45s\n",
      "667:\tlearn: 1.8574376\ttotal: 8.92s\tremaining: 4.43s\n",
      "668:\tlearn: 1.8571044\ttotal: 8.94s\tremaining: 4.42s\n",
      "669:\tlearn: 1.8569902\ttotal: 8.95s\tremaining: 4.41s\n",
      "670:\tlearn: 1.8565816\ttotal: 8.96s\tremaining: 4.39s\n",
      "671:\tlearn: 1.8565403\ttotal: 8.97s\tremaining: 4.38s\n",
      "672:\tlearn: 1.8560413\ttotal: 8.99s\tremaining: 4.37s\n",
      "673:\tlearn: 1.8556478\ttotal: 9s\tremaining: 4.35s\n",
      "674:\tlearn: 1.8555047\ttotal: 9.02s\tremaining: 4.34s\n",
      "675:\tlearn: 1.8553252\ttotal: 9.03s\tremaining: 4.33s\n",
      "676:\tlearn: 1.8551735\ttotal: 9.04s\tremaining: 4.31s\n",
      "677:\tlearn: 1.8550571\ttotal: 9.05s\tremaining: 4.3s\n",
      "678:\tlearn: 1.8549238\ttotal: 9.07s\tremaining: 4.29s\n",
      "679:\tlearn: 1.8546497\ttotal: 9.08s\tremaining: 4.27s\n",
      "680:\tlearn: 1.8546464\ttotal: 9.09s\tremaining: 4.26s\n",
      "681:\tlearn: 1.8544611\ttotal: 9.11s\tremaining: 4.25s\n",
      "682:\tlearn: 1.8544500\ttotal: 9.12s\tremaining: 4.23s\n",
      "683:\tlearn: 1.8544456\ttotal: 9.13s\tremaining: 4.22s\n",
      "684:\tlearn: 1.8542170\ttotal: 9.14s\tremaining: 4.21s\n",
      "685:\tlearn: 1.8541568\ttotal: 9.16s\tremaining: 4.19s\n",
      "686:\tlearn: 1.8538890\ttotal: 9.17s\tremaining: 4.18s\n",
      "687:\tlearn: 1.8538732\ttotal: 9.19s\tremaining: 4.17s\n",
      "688:\tlearn: 1.8534611\ttotal: 9.2s\tremaining: 4.15s\n",
      "689:\tlearn: 1.8533397\ttotal: 9.21s\tremaining: 4.14s\n",
      "690:\tlearn: 1.8531407\ttotal: 9.23s\tremaining: 4.13s\n",
      "691:\tlearn: 1.8530325\ttotal: 9.24s\tremaining: 4.11s\n",
      "692:\tlearn: 1.8530303\ttotal: 9.25s\tremaining: 4.1s\n",
      "693:\tlearn: 1.8528430\ttotal: 9.27s\tremaining: 4.08s\n",
      "694:\tlearn: 1.8521577\ttotal: 9.28s\tremaining: 4.07s\n",
      "695:\tlearn: 1.8517109\ttotal: 9.29s\tremaining: 4.06s\n",
      "696:\tlearn: 1.8517059\ttotal: 9.3s\tremaining: 4.04s\n",
      "697:\tlearn: 1.8516215\ttotal: 9.32s\tremaining: 4.03s\n",
      "698:\tlearn: 1.8515757\ttotal: 9.33s\tremaining: 4.02s\n",
      "699:\tlearn: 1.8514600\ttotal: 9.34s\tremaining: 4s\n",
      "700:\tlearn: 1.8514355\ttotal: 9.36s\tremaining: 3.99s\n",
      "701:\tlearn: 1.8512994\ttotal: 9.37s\tremaining: 3.98s\n",
      "702:\tlearn: 1.8511259\ttotal: 9.38s\tremaining: 3.96s\n",
      "703:\tlearn: 1.8510400\ttotal: 9.39s\tremaining: 3.95s\n",
      "704:\tlearn: 1.8509629\ttotal: 9.41s\tremaining: 3.94s\n",
      "705:\tlearn: 1.8509498\ttotal: 9.42s\tremaining: 3.92s\n",
      "706:\tlearn: 1.8509472\ttotal: 9.44s\tremaining: 3.91s\n",
      "707:\tlearn: 1.8509161\ttotal: 9.45s\tremaining: 3.9s\n",
      "708:\tlearn: 1.8509154\ttotal: 9.46s\tremaining: 3.88s\n",
      "709:\tlearn: 1.8506823\ttotal: 9.47s\tremaining: 3.87s\n",
      "710:\tlearn: 1.8503763\ttotal: 9.49s\tremaining: 3.86s\n",
      "711:\tlearn: 1.8500323\ttotal: 9.5s\tremaining: 3.84s\n",
      "712:\tlearn: 1.8497613\ttotal: 9.52s\tremaining: 3.83s\n",
      "713:\tlearn: 1.8496568\ttotal: 9.53s\tremaining: 3.82s\n",
      "714:\tlearn: 1.8492960\ttotal: 9.54s\tremaining: 3.8s\n",
      "715:\tlearn: 1.8492279\ttotal: 9.55s\tremaining: 3.79s\n",
      "716:\tlearn: 1.8490210\ttotal: 9.57s\tremaining: 3.78s\n",
      "717:\tlearn: 1.8485916\ttotal: 9.58s\tremaining: 3.76s\n",
      "718:\tlearn: 1.8482282\ttotal: 9.59s\tremaining: 3.75s\n",
      "719:\tlearn: 1.8471356\ttotal: 9.61s\tremaining: 3.73s\n",
      "720:\tlearn: 1.8470803\ttotal: 9.62s\tremaining: 3.72s\n",
      "721:\tlearn: 1.8470340\ttotal: 9.63s\tremaining: 3.71s\n",
      "722:\tlearn: 1.8465800\ttotal: 9.65s\tremaining: 3.7s\n",
      "723:\tlearn: 1.8463787\ttotal: 9.66s\tremaining: 3.68s\n",
      "724:\tlearn: 1.8463535\ttotal: 9.67s\tremaining: 3.67s\n",
      "725:\tlearn: 1.8463534\ttotal: 9.69s\tremaining: 3.65s\n",
      "726:\tlearn: 1.8463533\ttotal: 9.7s\tremaining: 3.64s\n",
      "727:\tlearn: 1.8462767\ttotal: 9.71s\tremaining: 3.63s\n",
      "728:\tlearn: 1.8462719\ttotal: 9.72s\tremaining: 3.61s\n",
      "729:\tlearn: 1.8460561\ttotal: 9.74s\tremaining: 3.6s\n",
      "730:\tlearn: 1.8457448\ttotal: 9.75s\tremaining: 3.59s\n",
      "731:\tlearn: 1.8457447\ttotal: 9.76s\tremaining: 3.57s\n",
      "732:\tlearn: 1.8452000\ttotal: 9.77s\tremaining: 3.56s\n",
      "733:\tlearn: 1.8447442\ttotal: 9.79s\tremaining: 3.55s\n",
      "734:\tlearn: 1.8447439\ttotal: 9.8s\tremaining: 3.53s\n",
      "735:\tlearn: 1.8447211\ttotal: 9.81s\tremaining: 3.52s\n",
      "736:\tlearn: 1.8447207\ttotal: 9.82s\tremaining: 3.5s\n",
      "737:\tlearn: 1.8447002\ttotal: 9.84s\tremaining: 3.49s\n",
      "738:\tlearn: 1.8446864\ttotal: 9.85s\tremaining: 3.48s\n",
      "739:\tlearn: 1.8446708\ttotal: 9.86s\tremaining: 3.46s\n",
      "740:\tlearn: 1.8441057\ttotal: 9.88s\tremaining: 3.45s\n",
      "741:\tlearn: 1.8432268\ttotal: 9.89s\tremaining: 3.44s\n",
      "742:\tlearn: 1.8425103\ttotal: 9.9s\tremaining: 3.42s\n",
      "743:\tlearn: 1.8423845\ttotal: 9.92s\tremaining: 3.41s\n",
      "744:\tlearn: 1.8420651\ttotal: 9.93s\tremaining: 3.4s\n",
      "745:\tlearn: 1.8420611\ttotal: 9.94s\tremaining: 3.38s\n",
      "746:\tlearn: 1.8420570\ttotal: 9.96s\tremaining: 3.37s\n",
      "747:\tlearn: 1.8416826\ttotal: 9.97s\tremaining: 3.36s\n",
      "748:\tlearn: 1.8416327\ttotal: 9.98s\tremaining: 3.35s\n",
      "749:\tlearn: 1.8415658\ttotal: 10s\tremaining: 3.33s\n",
      "750:\tlearn: 1.8415588\ttotal: 10s\tremaining: 3.32s\n",
      "751:\tlearn: 1.8415528\ttotal: 10s\tremaining: 3.31s\n",
      "752:\tlearn: 1.8414915\ttotal: 10s\tremaining: 3.29s\n",
      "753:\tlearn: 1.8414676\ttotal: 10s\tremaining: 3.28s\n",
      "754:\tlearn: 1.8414426\ttotal: 10.1s\tremaining: 3.27s\n",
      "755:\tlearn: 1.8414389\ttotal: 10.1s\tremaining: 3.25s\n",
      "756:\tlearn: 1.8411258\ttotal: 10.1s\tremaining: 3.24s\n",
      "757:\tlearn: 1.8410471\ttotal: 10.1s\tremaining: 3.23s\n",
      "758:\tlearn: 1.8402402\ttotal: 10.1s\tremaining: 3.21s\n",
      "759:\tlearn: 1.8401459\ttotal: 10.1s\tremaining: 3.2s\n",
      "760:\tlearn: 1.8400738\ttotal: 10.1s\tremaining: 3.18s\n",
      "761:\tlearn: 1.8400735\ttotal: 10.2s\tremaining: 3.17s\n",
      "762:\tlearn: 1.8400734\ttotal: 10.2s\tremaining: 3.16s\n",
      "763:\tlearn: 1.8397075\ttotal: 10.2s\tremaining: 3.14s\n",
      "764:\tlearn: 1.8392735\ttotal: 10.2s\tremaining: 3.13s\n",
      "765:\tlearn: 1.8391304\ttotal: 10.2s\tremaining: 3.12s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766:\tlearn: 1.8388901\ttotal: 10.2s\tremaining: 3.1s\n",
      "767:\tlearn: 1.8388408\ttotal: 10.2s\tremaining: 3.09s\n",
      "768:\tlearn: 1.8386401\ttotal: 10.2s\tremaining: 3.08s\n",
      "769:\tlearn: 1.8381536\ttotal: 10.3s\tremaining: 3.06s\n",
      "770:\tlearn: 1.8369474\ttotal: 10.3s\tremaining: 3.05s\n",
      "771:\tlearn: 1.8368967\ttotal: 10.3s\tremaining: 3.04s\n",
      "772:\tlearn: 1.8367474\ttotal: 10.3s\tremaining: 3.02s\n",
      "773:\tlearn: 1.8367473\ttotal: 10.3s\tremaining: 3.01s\n",
      "774:\tlearn: 1.8366974\ttotal: 10.3s\tremaining: 3s\n",
      "775:\tlearn: 1.8365004\ttotal: 10.3s\tremaining: 2.98s\n",
      "776:\tlearn: 1.8364328\ttotal: 10.4s\tremaining: 2.97s\n",
      "777:\tlearn: 1.8364228\ttotal: 10.4s\tremaining: 2.96s\n",
      "778:\tlearn: 1.8363456\ttotal: 10.4s\tremaining: 2.94s\n",
      "779:\tlearn: 1.8363273\ttotal: 10.4s\tremaining: 2.93s\n",
      "780:\tlearn: 1.8359578\ttotal: 10.4s\tremaining: 2.92s\n",
      "781:\tlearn: 1.8355000\ttotal: 10.4s\tremaining: 2.9s\n",
      "782:\tlearn: 1.8354955\ttotal: 10.4s\tremaining: 2.89s\n",
      "783:\tlearn: 1.8354922\ttotal: 10.4s\tremaining: 2.88s\n",
      "784:\tlearn: 1.8353442\ttotal: 10.5s\tremaining: 2.86s\n",
      "785:\tlearn: 1.8353348\ttotal: 10.5s\tremaining: 2.85s\n",
      "786:\tlearn: 1.8353288\ttotal: 10.5s\tremaining: 2.84s\n",
      "787:\tlearn: 1.8353288\ttotal: 10.5s\tremaining: 2.82s\n",
      "788:\tlearn: 1.8346925\ttotal: 10.5s\tremaining: 2.81s\n",
      "789:\tlearn: 1.8334098\ttotal: 10.5s\tremaining: 2.8s\n",
      "790:\tlearn: 1.8326951\ttotal: 10.5s\tremaining: 2.78s\n",
      "791:\tlearn: 1.8326585\ttotal: 10.5s\tremaining: 2.77s\n",
      "792:\tlearn: 1.8320795\ttotal: 10.6s\tremaining: 2.76s\n",
      "793:\tlearn: 1.8320732\ttotal: 10.6s\tremaining: 2.74s\n",
      "794:\tlearn: 1.8320358\ttotal: 10.6s\tremaining: 2.73s\n",
      "795:\tlearn: 1.8319790\ttotal: 10.6s\tremaining: 2.72s\n",
      "796:\tlearn: 1.8319640\ttotal: 10.6s\tremaining: 2.7s\n",
      "797:\tlearn: 1.8316726\ttotal: 10.6s\tremaining: 2.69s\n",
      "798:\tlearn: 1.8308014\ttotal: 10.6s\tremaining: 2.68s\n",
      "799:\tlearn: 1.8304980\ttotal: 10.7s\tremaining: 2.66s\n",
      "800:\tlearn: 1.8304251\ttotal: 10.7s\tremaining: 2.65s\n",
      "801:\tlearn: 1.8303441\ttotal: 10.7s\tremaining: 2.64s\n",
      "802:\tlearn: 1.8303362\ttotal: 10.7s\tremaining: 2.62s\n",
      "803:\tlearn: 1.8303294\ttotal: 10.7s\tremaining: 2.61s\n",
      "804:\tlearn: 1.8295800\ttotal: 10.7s\tremaining: 2.6s\n",
      "805:\tlearn: 1.8295545\ttotal: 10.7s\tremaining: 2.58s\n",
      "806:\tlearn: 1.8295541\ttotal: 10.7s\tremaining: 2.57s\n",
      "807:\tlearn: 1.8295467\ttotal: 10.8s\tremaining: 2.56s\n",
      "808:\tlearn: 1.8295358\ttotal: 10.8s\tremaining: 2.54s\n",
      "809:\tlearn: 1.8293093\ttotal: 10.8s\tremaining: 2.53s\n",
      "810:\tlearn: 1.8287489\ttotal: 10.8s\tremaining: 2.52s\n",
      "811:\tlearn: 1.8287373\ttotal: 10.8s\tremaining: 2.5s\n",
      "812:\tlearn: 1.8287371\ttotal: 10.8s\tremaining: 2.49s\n",
      "813:\tlearn: 1.8287363\ttotal: 10.8s\tremaining: 2.47s\n",
      "814:\tlearn: 1.8287346\ttotal: 10.8s\tremaining: 2.46s\n",
      "815:\tlearn: 1.8287339\ttotal: 10.9s\tremaining: 2.45s\n",
      "816:\tlearn: 1.8287339\ttotal: 10.9s\tremaining: 2.43s\n",
      "817:\tlearn: 1.8287335\ttotal: 10.9s\tremaining: 2.42s\n",
      "818:\tlearn: 1.8286987\ttotal: 10.9s\tremaining: 2.41s\n",
      "819:\tlearn: 1.8281363\ttotal: 10.9s\tremaining: 2.39s\n",
      "820:\tlearn: 1.8280479\ttotal: 10.9s\tremaining: 2.38s\n",
      "821:\tlearn: 1.8276493\ttotal: 10.9s\tremaining: 2.37s\n",
      "822:\tlearn: 1.8268274\ttotal: 10.9s\tremaining: 2.35s\n",
      "823:\tlearn: 1.8264169\ttotal: 11s\tremaining: 2.34s\n",
      "824:\tlearn: 1.8263886\ttotal: 11s\tremaining: 2.33s\n",
      "825:\tlearn: 1.8263750\ttotal: 11s\tremaining: 2.31s\n",
      "826:\tlearn: 1.8263749\ttotal: 11s\tremaining: 2.3s\n",
      "827:\tlearn: 1.8263730\ttotal: 11s\tremaining: 2.29s\n",
      "828:\tlearn: 1.8260267\ttotal: 11s\tremaining: 2.27s\n",
      "829:\tlearn: 1.8258656\ttotal: 11s\tremaining: 2.26s\n",
      "830:\tlearn: 1.8258629\ttotal: 11.1s\tremaining: 2.25s\n",
      "831:\tlearn: 1.8258373\ttotal: 11.1s\tremaining: 2.23s\n",
      "832:\tlearn: 1.8254103\ttotal: 11.1s\tremaining: 2.22s\n",
      "833:\tlearn: 1.8254049\ttotal: 11.1s\tremaining: 2.21s\n",
      "834:\tlearn: 1.8251628\ttotal: 11.1s\tremaining: 2.19s\n",
      "835:\tlearn: 1.8250594\ttotal: 11.1s\tremaining: 2.18s\n",
      "836:\tlearn: 1.8250525\ttotal: 11.1s\tremaining: 2.17s\n",
      "837:\tlearn: 1.8249997\ttotal: 11.1s\tremaining: 2.15s\n",
      "838:\tlearn: 1.8249952\ttotal: 11.2s\tremaining: 2.14s\n",
      "839:\tlearn: 1.8243873\ttotal: 11.2s\tremaining: 2.13s\n",
      "840:\tlearn: 1.8242864\ttotal: 11.2s\tremaining: 2.11s\n",
      "841:\tlearn: 1.8235289\ttotal: 11.2s\tremaining: 2.1s\n",
      "842:\tlearn: 1.8228979\ttotal: 11.2s\tremaining: 2.09s\n",
      "843:\tlearn: 1.8224114\ttotal: 11.2s\tremaining: 2.07s\n",
      "844:\tlearn: 1.8223955\ttotal: 11.2s\tremaining: 2.06s\n",
      "845:\tlearn: 1.8219351\ttotal: 11.2s\tremaining: 2.05s\n",
      "846:\tlearn: 1.8210646\ttotal: 11.3s\tremaining: 2.03s\n",
      "847:\tlearn: 1.8205301\ttotal: 11.3s\tremaining: 2.02s\n",
      "848:\tlearn: 1.8201789\ttotal: 11.3s\tremaining: 2.01s\n",
      "849:\tlearn: 1.8201455\ttotal: 11.3s\tremaining: 1.99s\n",
      "850:\tlearn: 1.8201360\ttotal: 11.3s\tremaining: 1.98s\n",
      "851:\tlearn: 1.8189997\ttotal: 11.3s\tremaining: 1.97s\n",
      "852:\tlearn: 1.8177793\ttotal: 11.3s\tremaining: 1.95s\n",
      "853:\tlearn: 1.8169578\ttotal: 11.4s\tremaining: 1.94s\n",
      "854:\tlearn: 1.8168910\ttotal: 11.4s\tremaining: 1.93s\n",
      "855:\tlearn: 1.8166394\ttotal: 11.4s\tremaining: 1.91s\n",
      "856:\tlearn: 1.8166316\ttotal: 11.4s\tremaining: 1.9s\n",
      "857:\tlearn: 1.8165926\ttotal: 11.4s\tremaining: 1.89s\n",
      "858:\tlearn: 1.8165923\ttotal: 11.4s\tremaining: 1.87s\n",
      "859:\tlearn: 1.8165877\ttotal: 11.4s\tremaining: 1.86s\n",
      "860:\tlearn: 1.8165790\ttotal: 11.4s\tremaining: 1.85s\n",
      "861:\tlearn: 1.8165775\ttotal: 11.5s\tremaining: 1.83s\n",
      "862:\tlearn: 1.8165409\ttotal: 11.5s\tremaining: 1.82s\n",
      "863:\tlearn: 1.8160103\ttotal: 11.5s\tremaining: 1.81s\n",
      "864:\tlearn: 1.8160090\ttotal: 11.5s\tremaining: 1.79s\n",
      "865:\tlearn: 1.8159908\ttotal: 11.5s\tremaining: 1.78s\n",
      "866:\tlearn: 1.8159908\ttotal: 11.5s\tremaining: 1.77s\n",
      "867:\tlearn: 1.8159876\ttotal: 11.5s\tremaining: 1.75s\n",
      "868:\tlearn: 1.8159821\ttotal: 11.5s\tremaining: 1.74s\n",
      "869:\tlearn: 1.8159760\ttotal: 11.6s\tremaining: 1.73s\n",
      "870:\tlearn: 1.8156613\ttotal: 11.6s\tremaining: 1.71s\n",
      "871:\tlearn: 1.8156592\ttotal: 11.6s\tremaining: 1.7s\n",
      "872:\tlearn: 1.8156098\ttotal: 11.6s\tremaining: 1.69s\n",
      "873:\tlearn: 1.8151547\ttotal: 11.6s\tremaining: 1.67s\n",
      "874:\tlearn: 1.8151545\ttotal: 11.6s\tremaining: 1.66s\n",
      "875:\tlearn: 1.8151339\ttotal: 11.6s\tremaining: 1.65s\n",
      "876:\tlearn: 1.8151283\ttotal: 11.7s\tremaining: 1.63s\n",
      "877:\tlearn: 1.8151266\ttotal: 11.7s\tremaining: 1.62s\n",
      "878:\tlearn: 1.8148831\ttotal: 11.7s\tremaining: 1.61s\n",
      "879:\tlearn: 1.8148519\ttotal: 11.7s\tremaining: 1.59s\n",
      "880:\tlearn: 1.8148466\ttotal: 11.7s\tremaining: 1.58s\n",
      "881:\tlearn: 1.8144122\ttotal: 11.7s\tremaining: 1.57s\n",
      "882:\tlearn: 1.8134778\ttotal: 11.7s\tremaining: 1.55s\n",
      "883:\tlearn: 1.8133705\ttotal: 11.7s\tremaining: 1.54s\n",
      "884:\tlearn: 1.8129507\ttotal: 11.8s\tremaining: 1.53s\n",
      "885:\tlearn: 1.8129502\ttotal: 11.8s\tremaining: 1.51s\n",
      "886:\tlearn: 1.8129500\ttotal: 11.8s\tremaining: 1.5s\n",
      "887:\tlearn: 1.8129004\ttotal: 11.8s\tremaining: 1.49s\n",
      "888:\tlearn: 1.8128916\ttotal: 11.8s\tremaining: 1.47s\n",
      "889:\tlearn: 1.8128893\ttotal: 11.8s\tremaining: 1.46s\n",
      "890:\tlearn: 1.8126067\ttotal: 11.8s\tremaining: 1.45s\n",
      "891:\tlearn: 1.8126002\ttotal: 11.8s\tremaining: 1.43s\n",
      "892:\tlearn: 1.8123055\ttotal: 11.9s\tremaining: 1.42s\n",
      "893:\tlearn: 1.8122961\ttotal: 11.9s\tremaining: 1.41s\n",
      "894:\tlearn: 1.8122879\ttotal: 11.9s\tremaining: 1.39s\n",
      "895:\tlearn: 1.8122483\ttotal: 11.9s\tremaining: 1.38s\n",
      "896:\tlearn: 1.8118450\ttotal: 11.9s\tremaining: 1.37s\n",
      "897:\tlearn: 1.8102263\ttotal: 11.9s\tremaining: 1.35s\n",
      "898:\tlearn: 1.8102074\ttotal: 11.9s\tremaining: 1.34s\n",
      "899:\tlearn: 1.8099767\ttotal: 11.9s\tremaining: 1.33s\n",
      "900:\tlearn: 1.8093113\ttotal: 12s\tremaining: 1.31s\n",
      "901:\tlearn: 1.8090741\ttotal: 12s\tremaining: 1.3s\n",
      "902:\tlearn: 1.8088269\ttotal: 12s\tremaining: 1.29s\n",
      "903:\tlearn: 1.8088265\ttotal: 12s\tremaining: 1.27s\n",
      "904:\tlearn: 1.8088261\ttotal: 12s\tremaining: 1.26s\n",
      "905:\tlearn: 1.8087018\ttotal: 12s\tremaining: 1.25s\n",
      "906:\tlearn: 1.8086457\ttotal: 12.1s\tremaining: 1.24s\n",
      "907:\tlearn: 1.8085866\ttotal: 12.1s\tremaining: 1.22s\n",
      "908:\tlearn: 1.8079731\ttotal: 12.1s\tremaining: 1.21s\n",
      "909:\tlearn: 1.8079565\ttotal: 12.1s\tremaining: 1.2s\n",
      "910:\tlearn: 1.8078179\ttotal: 12.1s\tremaining: 1.18s\n",
      "911:\tlearn: 1.8076980\ttotal: 12.1s\tremaining: 1.17s\n",
      "912:\tlearn: 1.8076941\ttotal: 12.1s\tremaining: 1.16s\n",
      "913:\tlearn: 1.8076780\ttotal: 12.2s\tremaining: 1.14s\n",
      "914:\tlearn: 1.8076253\ttotal: 12.2s\tremaining: 1.13s\n",
      "915:\tlearn: 1.8066530\ttotal: 12.2s\tremaining: 1.12s\n",
      "916:\tlearn: 1.8063972\ttotal: 12.2s\tremaining: 1.1s\n",
      "917:\tlearn: 1.8059128\ttotal: 12.2s\tremaining: 1.09s\n",
      "918:\tlearn: 1.8056541\ttotal: 12.2s\tremaining: 1.08s\n",
      "919:\tlearn: 1.8054477\ttotal: 12.2s\tremaining: 1.06s\n",
      "920:\tlearn: 1.8045014\ttotal: 12.3s\tremaining: 1.05s\n",
      "921:\tlearn: 1.8044929\ttotal: 12.3s\tremaining: 1.04s\n",
      "922:\tlearn: 1.8044704\ttotal: 12.3s\tremaining: 1.02s\n",
      "923:\tlearn: 1.8043779\ttotal: 12.3s\tremaining: 1.01s\n",
      "924:\tlearn: 1.8043273\ttotal: 12.3s\tremaining: 998ms\n",
      "925:\tlearn: 1.8043266\ttotal: 12.3s\tremaining: 984ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "926:\tlearn: 1.8042706\ttotal: 12.3s\tremaining: 971ms\n",
      "927:\tlearn: 1.8041152\ttotal: 12.3s\tremaining: 958ms\n",
      "928:\tlearn: 1.8040961\ttotal: 12.4s\tremaining: 945ms\n",
      "929:\tlearn: 1.8040958\ttotal: 12.4s\tremaining: 931ms\n",
      "930:\tlearn: 1.8039140\ttotal: 12.4s\tremaining: 918ms\n",
      "931:\tlearn: 1.8039058\ttotal: 12.4s\tremaining: 905ms\n",
      "932:\tlearn: 1.8039024\ttotal: 12.4s\tremaining: 891ms\n",
      "933:\tlearn: 1.8039014\ttotal: 12.4s\tremaining: 878ms\n",
      "934:\tlearn: 1.8039013\ttotal: 12.4s\tremaining: 864ms\n",
      "935:\tlearn: 1.8038103\ttotal: 12.4s\tremaining: 851ms\n",
      "936:\tlearn: 1.8035783\ttotal: 12.5s\tremaining: 838ms\n",
      "937:\tlearn: 1.8034998\ttotal: 12.5s\tremaining: 824ms\n",
      "938:\tlearn: 1.8032956\ttotal: 12.5s\tremaining: 811ms\n",
      "939:\tlearn: 1.8032488\ttotal: 12.5s\tremaining: 798ms\n",
      "940:\tlearn: 1.8025157\ttotal: 12.5s\tremaining: 784ms\n",
      "941:\tlearn: 1.8025154\ttotal: 12.5s\tremaining: 771ms\n",
      "942:\tlearn: 1.8025010\ttotal: 12.5s\tremaining: 758ms\n",
      "943:\tlearn: 1.8020710\ttotal: 12.5s\tremaining: 744ms\n",
      "944:\tlearn: 1.8020176\ttotal: 12.6s\tremaining: 731ms\n",
      "945:\tlearn: 1.8020044\ttotal: 12.6s\tremaining: 718ms\n",
      "946:\tlearn: 1.8016274\ttotal: 12.6s\tremaining: 704ms\n",
      "947:\tlearn: 1.8013827\ttotal: 12.6s\tremaining: 691ms\n",
      "948:\tlearn: 1.8012600\ttotal: 12.6s\tremaining: 678ms\n",
      "949:\tlearn: 1.8012583\ttotal: 12.6s\tremaining: 665ms\n",
      "950:\tlearn: 1.8012421\ttotal: 12.6s\tremaining: 651ms\n",
      "951:\tlearn: 1.8012316\ttotal: 12.7s\tremaining: 638ms\n",
      "952:\tlearn: 1.8012255\ttotal: 12.7s\tremaining: 625ms\n",
      "953:\tlearn: 1.8012253\ttotal: 12.7s\tremaining: 611ms\n",
      "954:\tlearn: 1.8007417\ttotal: 12.7s\tremaining: 598ms\n",
      "955:\tlearn: 1.8006510\ttotal: 12.7s\tremaining: 585ms\n",
      "956:\tlearn: 1.8006281\ttotal: 12.7s\tremaining: 571ms\n",
      "957:\tlearn: 1.8002469\ttotal: 12.7s\tremaining: 558ms\n",
      "958:\tlearn: 1.8001399\ttotal: 12.7s\tremaining: 545ms\n",
      "959:\tlearn: 1.7997649\ttotal: 12.8s\tremaining: 531ms\n",
      "960:\tlearn: 1.7997454\ttotal: 12.8s\tremaining: 518ms\n",
      "961:\tlearn: 1.7997422\ttotal: 12.8s\tremaining: 505ms\n",
      "962:\tlearn: 1.7997344\ttotal: 12.8s\tremaining: 491ms\n",
      "963:\tlearn: 1.7997329\ttotal: 12.8s\tremaining: 478ms\n",
      "964:\tlearn: 1.7996121\ttotal: 12.8s\tremaining: 465ms\n",
      "965:\tlearn: 1.7992145\ttotal: 12.8s\tremaining: 452ms\n",
      "966:\tlearn: 1.7989937\ttotal: 12.8s\tremaining: 438ms\n",
      "967:\tlearn: 1.7989136\ttotal: 12.9s\tremaining: 425ms\n",
      "968:\tlearn: 1.7983981\ttotal: 12.9s\tremaining: 412ms\n",
      "969:\tlearn: 1.7983507\ttotal: 12.9s\tremaining: 398ms\n",
      "970:\tlearn: 1.7979092\ttotal: 12.9s\tremaining: 385ms\n",
      "971:\tlearn: 1.7978799\ttotal: 12.9s\tremaining: 372ms\n",
      "972:\tlearn: 1.7978459\ttotal: 12.9s\tremaining: 359ms\n",
      "973:\tlearn: 1.7978151\ttotal: 12.9s\tremaining: 345ms\n",
      "974:\tlearn: 1.7978148\ttotal: 12.9s\tremaining: 332ms\n",
      "975:\tlearn: 1.7975961\ttotal: 13s\tremaining: 319ms\n",
      "976:\tlearn: 1.7974092\ttotal: 13s\tremaining: 305ms\n",
      "977:\tlearn: 1.7972362\ttotal: 13s\tremaining: 292ms\n",
      "978:\tlearn: 1.7970489\ttotal: 13s\tremaining: 279ms\n",
      "979:\tlearn: 1.7970210\ttotal: 13s\tremaining: 266ms\n",
      "980:\tlearn: 1.7962745\ttotal: 13s\tremaining: 252ms\n",
      "981:\tlearn: 1.7962735\ttotal: 13s\tremaining: 239ms\n",
      "982:\tlearn: 1.7957767\ttotal: 13s\tremaining: 226ms\n",
      "983:\tlearn: 1.7956106\ttotal: 13.1s\tremaining: 212ms\n",
      "984:\tlearn: 1.7955305\ttotal: 13.1s\tremaining: 199ms\n",
      "985:\tlearn: 1.7954301\ttotal: 13.1s\tremaining: 186ms\n",
      "986:\tlearn: 1.7953321\ttotal: 13.1s\tremaining: 173ms\n",
      "987:\tlearn: 1.7952687\ttotal: 13.1s\tremaining: 159ms\n",
      "988:\tlearn: 1.7952119\ttotal: 13.1s\tremaining: 146ms\n",
      "989:\tlearn: 1.7949192\ttotal: 13.1s\tremaining: 133ms\n",
      "990:\tlearn: 1.7943850\ttotal: 13.2s\tremaining: 119ms\n",
      "991:\tlearn: 1.7937503\ttotal: 13.2s\tremaining: 106ms\n",
      "992:\tlearn: 1.7936679\ttotal: 13.2s\tremaining: 92.9ms\n",
      "993:\tlearn: 1.7936667\ttotal: 13.2s\tremaining: 79.6ms\n",
      "994:\tlearn: 1.7936611\ttotal: 13.2s\tremaining: 66.3ms\n",
      "995:\tlearn: 1.7936466\ttotal: 13.2s\tremaining: 53.1ms\n",
      "996:\tlearn: 1.7935608\ttotal: 13.2s\tremaining: 39.8ms\n",
      "997:\tlearn: 1.7935053\ttotal: 13.2s\tremaining: 26.5ms\n",
      "998:\tlearn: 1.7934986\ttotal: 13.3s\tremaining: 13.3ms\n",
      "999:\tlearn: 1.7934966\ttotal: 13.3s\tremaining: 0us\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "final_model_1, final_pred_1 = stacking_models(base_models,\n",
    "                                          X_train, y_train_transformed,\n",
    "                                          test=X_test, final_regressor='linear',\n",
    "                                          final_params={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0c1b959c-5f68-4a7f-bbd1-ff73a7327c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_1_2 = pred_to_df(final_pred_1, squared=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd432acd-d034-4173-894c-21460cc5beb3",
   "metadata": {},
   "source": [
    "### Stacking 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "91ecf01f-425e-421d-904d-7b6dad55fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models_2 = [\n",
    "    ('lgbm', lgbm),\n",
    "    ('catboost', catboostm),\n",
    "    ('xgboost', xgboost),\n",
    "    ('randomforest', randomforest)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4b546186-4a7f-40e0-9364-26eab991614c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 339\n",
      "[LightGBM] [Info] Number of data points in the train set: 79218, number of used features: 54\n",
      "[LightGBM] [Info] Start training from score 9.924039\n",
      "0:\tlearn: 9.0625740\ttotal: 21ms\tremaining: 21s\n",
      "1:\tlearn: 8.4133972\ttotal: 40.6ms\tremaining: 20.3s\n",
      "2:\tlearn: 7.8099768\ttotal: 59.8ms\tremaining: 19.9s\n",
      "3:\tlearn: 7.1189953\ttotal: 79.2ms\tremaining: 19.7s\n",
      "4:\tlearn: 6.5480038\ttotal: 97.9ms\tremaining: 19.5s\n",
      "5:\tlearn: 6.1447702\ttotal: 117ms\tremaining: 19.4s\n",
      "6:\tlearn: 5.6831695\ttotal: 136ms\tremaining: 19.3s\n",
      "7:\tlearn: 5.2592029\ttotal: 155ms\tremaining: 19.2s\n",
      "8:\tlearn: 4.8578495\ttotal: 174ms\tremaining: 19.1s\n",
      "9:\tlearn: 4.5101983\ttotal: 193ms\tremaining: 19.1s\n",
      "10:\tlearn: 4.2214233\ttotal: 212ms\tremaining: 19.1s\n",
      "11:\tlearn: 4.0145113\ttotal: 231ms\tremaining: 19s\n",
      "12:\tlearn: 3.7663852\ttotal: 251ms\tremaining: 19.1s\n",
      "13:\tlearn: 3.5508344\ttotal: 270ms\tremaining: 19s\n",
      "14:\tlearn: 3.3660768\ttotal: 289ms\tremaining: 19s\n",
      "15:\tlearn: 3.2461008\ttotal: 308ms\tremaining: 18.9s\n",
      "16:\tlearn: 3.1503877\ttotal: 326ms\tremaining: 18.9s\n",
      "17:\tlearn: 3.0181972\ttotal: 344ms\tremaining: 18.8s\n",
      "18:\tlearn: 2.9418795\ttotal: 362ms\tremaining: 18.7s\n",
      "19:\tlearn: 2.8248909\ttotal: 381ms\tremaining: 18.7s\n",
      "20:\tlearn: 2.7679296\ttotal: 399ms\tremaining: 18.6s\n",
      "21:\tlearn: 2.7168477\ttotal: 418ms\tremaining: 18.6s\n",
      "22:\tlearn: 2.6735806\ttotal: 437ms\tremaining: 18.6s\n",
      "23:\tlearn: 2.6248225\ttotal: 459ms\tremaining: 18.6s\n",
      "24:\tlearn: 2.5607037\ttotal: 477ms\tremaining: 18.6s\n",
      "25:\tlearn: 2.5115372\ttotal: 496ms\tremaining: 18.6s\n",
      "26:\tlearn: 2.4882104\ttotal: 513ms\tremaining: 18.5s\n",
      "27:\tlearn: 2.4611594\ttotal: 531ms\tremaining: 18.4s\n",
      "28:\tlearn: 2.4410608\ttotal: 549ms\tremaining: 18.4s\n",
      "29:\tlearn: 2.3899064\ttotal: 567ms\tremaining: 18.3s\n",
      "30:\tlearn: 2.3623715\ttotal: 585ms\tremaining: 18.3s\n",
      "31:\tlearn: 2.3473465\ttotal: 603ms\tremaining: 18.2s\n",
      "32:\tlearn: 2.3210701\ttotal: 620ms\tremaining: 18.2s\n",
      "33:\tlearn: 2.2891452\ttotal: 638ms\tremaining: 18.1s\n",
      "34:\tlearn: 2.2796365\ttotal: 657ms\tremaining: 18.1s\n",
      "35:\tlearn: 2.2697524\ttotal: 678ms\tremaining: 18.2s\n",
      "36:\tlearn: 2.2449804\ttotal: 697ms\tremaining: 18.1s\n",
      "37:\tlearn: 2.2316725\ttotal: 714ms\tremaining: 18.1s\n",
      "38:\tlearn: 2.2148337\ttotal: 732ms\tremaining: 18s\n",
      "39:\tlearn: 2.2098784\ttotal: 749ms\tremaining: 18s\n",
      "40:\tlearn: 2.2021916\ttotal: 766ms\tremaining: 17.9s\n",
      "41:\tlearn: 2.1972459\ttotal: 783ms\tremaining: 17.9s\n",
      "42:\tlearn: 2.1922020\ttotal: 801ms\tremaining: 17.8s\n",
      "43:\tlearn: 2.1901579\ttotal: 818ms\tremaining: 17.8s\n",
      "44:\tlearn: 2.1885948\ttotal: 836ms\tremaining: 17.7s\n",
      "45:\tlearn: 2.1863853\ttotal: 853ms\tremaining: 17.7s\n",
      "46:\tlearn: 2.1687848\ttotal: 873ms\tremaining: 17.7s\n",
      "47:\tlearn: 2.1661821\ttotal: 894ms\tremaining: 17.7s\n",
      "48:\tlearn: 2.1630093\ttotal: 912ms\tremaining: 17.7s\n",
      "49:\tlearn: 2.1609104\ttotal: 929ms\tremaining: 17.7s\n",
      "50:\tlearn: 2.1588285\ttotal: 946ms\tremaining: 17.6s\n",
      "51:\tlearn: 2.1564277\ttotal: 964ms\tremaining: 17.6s\n",
      "52:\tlearn: 2.1527741\ttotal: 981ms\tremaining: 17.5s\n",
      "53:\tlearn: 2.1520782\ttotal: 998ms\tremaining: 17.5s\n",
      "54:\tlearn: 2.1502300\ttotal: 1.02s\tremaining: 17.5s\n",
      "55:\tlearn: 2.1322229\ttotal: 1.03s\tremaining: 17.4s\n",
      "56:\tlearn: 2.1294096\ttotal: 1.05s\tremaining: 17.4s\n",
      "57:\tlearn: 2.1261664\ttotal: 1.07s\tremaining: 17.4s\n",
      "58:\tlearn: 2.1259865\ttotal: 1.09s\tremaining: 17.4s\n",
      "59:\tlearn: 2.1253059\ttotal: 1.11s\tremaining: 17.4s\n",
      "60:\tlearn: 2.1251454\ttotal: 1.13s\tremaining: 17.3s\n",
      "61:\tlearn: 2.1246183\ttotal: 1.14s\tremaining: 17.3s\n",
      "62:\tlearn: 2.1170591\ttotal: 1.16s\tremaining: 17.3s\n",
      "63:\tlearn: 2.1151568\ttotal: 1.18s\tremaining: 17.2s\n",
      "64:\tlearn: 2.1147531\ttotal: 1.2s\tremaining: 17.2s\n",
      "65:\tlearn: 2.1045100\ttotal: 1.21s\tremaining: 17.2s\n",
      "66:\tlearn: 2.1039708\ttotal: 1.23s\tremaining: 17.1s\n",
      "67:\tlearn: 2.1007006\ttotal: 1.25s\tremaining: 17.1s\n",
      "68:\tlearn: 2.0971870\ttotal: 1.26s\tremaining: 17.1s\n",
      "69:\tlearn: 2.0958785\ttotal: 1.28s\tremaining: 17s\n",
      "70:\tlearn: 2.0956003\ttotal: 1.3s\tremaining: 17s\n",
      "71:\tlearn: 2.0955235\ttotal: 1.32s\tremaining: 17s\n",
      "72:\tlearn: 2.0950717\ttotal: 1.33s\tremaining: 17s\n",
      "73:\tlearn: 2.0929360\ttotal: 1.35s\tremaining: 16.9s\n",
      "74:\tlearn: 2.0923191\ttotal: 1.37s\tremaining: 16.9s\n",
      "75:\tlearn: 2.0911181\ttotal: 1.39s\tremaining: 16.9s\n",
      "76:\tlearn: 2.0896094\ttotal: 1.41s\tremaining: 16.8s\n",
      "77:\tlearn: 2.0892318\ttotal: 1.42s\tremaining: 16.8s\n",
      "78:\tlearn: 2.0885337\ttotal: 1.44s\tremaining: 16.8s\n",
      "79:\tlearn: 2.0879237\ttotal: 1.46s\tremaining: 16.7s\n",
      "80:\tlearn: 2.0859293\ttotal: 1.47s\tremaining: 16.7s\n",
      "81:\tlearn: 2.0787234\ttotal: 1.49s\tremaining: 16.7s\n",
      "82:\tlearn: 2.0782299\ttotal: 1.5s\tremaining: 16.6s\n",
      "83:\tlearn: 2.0779779\ttotal: 1.52s\tremaining: 16.6s\n",
      "84:\tlearn: 2.0745414\ttotal: 1.54s\tremaining: 16.6s\n",
      "85:\tlearn: 2.0742712\ttotal: 1.56s\tremaining: 16.6s\n",
      "86:\tlearn: 2.0739254\ttotal: 1.58s\tremaining: 16.6s\n",
      "87:\tlearn: 2.0728982\ttotal: 1.59s\tremaining: 16.5s\n",
      "88:\tlearn: 2.0721155\ttotal: 1.61s\tremaining: 16.5s\n",
      "89:\tlearn: 2.0708139\ttotal: 1.63s\tremaining: 16.4s\n",
      "90:\tlearn: 2.0706068\ttotal: 1.64s\tremaining: 16.4s\n",
      "91:\tlearn: 2.0698130\ttotal: 1.66s\tremaining: 16.4s\n",
      "92:\tlearn: 2.0698078\ttotal: 1.67s\tremaining: 16.3s\n",
      "93:\tlearn: 2.0691319\ttotal: 1.69s\tremaining: 16.3s\n",
      "94:\tlearn: 2.0683299\ttotal: 1.7s\tremaining: 16.2s\n",
      "95:\tlearn: 2.0682265\ttotal: 1.72s\tremaining: 16.2s\n",
      "96:\tlearn: 2.0681748\ttotal: 1.74s\tremaining: 16.2s\n",
      "97:\tlearn: 2.0677758\ttotal: 1.76s\tremaining: 16.2s\n",
      "98:\tlearn: 2.0604453\ttotal: 1.78s\tremaining: 16.2s\n",
      "99:\tlearn: 2.0601571\ttotal: 1.79s\tremaining: 16.1s\n",
      "100:\tlearn: 2.0599629\ttotal: 1.81s\tremaining: 16.1s\n",
      "101:\tlearn: 2.0581087\ttotal: 1.82s\tremaining: 16s\n",
      "102:\tlearn: 2.0574210\ttotal: 1.84s\tremaining: 16s\n",
      "103:\tlearn: 2.0495505\ttotal: 1.85s\tremaining: 16s\n",
      "104:\tlearn: 2.0491661\ttotal: 1.87s\tremaining: 15.9s\n",
      "105:\tlearn: 2.0488888\ttotal: 1.89s\tremaining: 15.9s\n",
      "106:\tlearn: 2.0488297\ttotal: 1.9s\tremaining: 15.9s\n",
      "107:\tlearn: 2.0457459\ttotal: 1.92s\tremaining: 15.8s\n",
      "108:\tlearn: 2.0451842\ttotal: 1.93s\tremaining: 15.8s\n",
      "109:\tlearn: 2.0449781\ttotal: 1.95s\tremaining: 15.7s\n",
      "110:\tlearn: 2.0446407\ttotal: 1.97s\tremaining: 15.7s\n",
      "111:\tlearn: 2.0443334\ttotal: 1.98s\tremaining: 15.7s\n",
      "112:\tlearn: 2.0441884\ttotal: 2s\tremaining: 15.7s\n",
      "113:\tlearn: 2.0441142\ttotal: 2.02s\tremaining: 15.7s\n",
      "114:\tlearn: 2.0440816\ttotal: 2.03s\tremaining: 15.6s\n",
      "115:\tlearn: 2.0427003\ttotal: 2.05s\tremaining: 15.6s\n",
      "116:\tlearn: 2.0420012\ttotal: 2.06s\tremaining: 15.6s\n",
      "117:\tlearn: 2.0416852\ttotal: 2.08s\tremaining: 15.5s\n",
      "118:\tlearn: 2.0415388\ttotal: 2.09s\tremaining: 15.5s\n",
      "119:\tlearn: 2.0321863\ttotal: 2.11s\tremaining: 15.5s\n",
      "120:\tlearn: 2.0288617\ttotal: 2.12s\tremaining: 15.4s\n",
      "121:\tlearn: 2.0276089\ttotal: 2.14s\tremaining: 15.4s\n",
      "122:\tlearn: 2.0240351\ttotal: 2.15s\tremaining: 15.4s\n",
      "123:\tlearn: 2.0236964\ttotal: 2.17s\tremaining: 15.3s\n",
      "124:\tlearn: 2.0190659\ttotal: 2.19s\tremaining: 15.3s\n",
      "125:\tlearn: 2.0180172\ttotal: 2.2s\tremaining: 15.3s\n",
      "126:\tlearn: 2.0172872\ttotal: 2.21s\tremaining: 15.2s\n",
      "127:\tlearn: 2.0140679\ttotal: 2.23s\tremaining: 15.2s\n",
      "128:\tlearn: 2.0081441\ttotal: 2.24s\tremaining: 15.2s\n",
      "129:\tlearn: 2.0063871\ttotal: 2.26s\tremaining: 15.1s\n",
      "130:\tlearn: 2.0048432\ttotal: 2.27s\tremaining: 15.1s\n",
      "131:\tlearn: 1.9997133\ttotal: 2.29s\tremaining: 15.1s\n",
      "132:\tlearn: 1.9987263\ttotal: 2.31s\tremaining: 15s\n",
      "133:\tlearn: 1.9972355\ttotal: 2.32s\tremaining: 15s\n",
      "134:\tlearn: 1.9967367\ttotal: 2.33s\tremaining: 15s\n",
      "135:\tlearn: 1.9940983\ttotal: 2.35s\tremaining: 14.9s\n",
      "136:\tlearn: 1.9917453\ttotal: 2.37s\tremaining: 14.9s\n",
      "137:\tlearn: 1.9899005\ttotal: 2.38s\tremaining: 14.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138:\tlearn: 1.9891141\ttotal: 2.4s\tremaining: 14.9s\n",
      "139:\tlearn: 1.9872972\ttotal: 2.42s\tremaining: 14.9s\n",
      "140:\tlearn: 1.9856725\ttotal: 2.44s\tremaining: 14.9s\n",
      "141:\tlearn: 1.9829191\ttotal: 2.46s\tremaining: 14.8s\n",
      "142:\tlearn: 1.9779575\ttotal: 2.47s\tremaining: 14.8s\n",
      "143:\tlearn: 1.9751523\ttotal: 2.49s\tremaining: 14.8s\n",
      "144:\tlearn: 1.9706630\ttotal: 2.5s\tremaining: 14.7s\n",
      "145:\tlearn: 1.9671126\ttotal: 2.52s\tremaining: 14.7s\n",
      "146:\tlearn: 1.9652524\ttotal: 2.53s\tremaining: 14.7s\n",
      "147:\tlearn: 1.9619327\ttotal: 2.54s\tremaining: 14.7s\n",
      "148:\tlearn: 1.9601310\ttotal: 2.56s\tremaining: 14.6s\n",
      "149:\tlearn: 1.9589545\ttotal: 2.58s\tremaining: 14.6s\n",
      "150:\tlearn: 1.9551591\ttotal: 2.59s\tremaining: 14.6s\n",
      "151:\tlearn: 1.9506114\ttotal: 2.6s\tremaining: 14.5s\n",
      "152:\tlearn: 1.9483762\ttotal: 2.62s\tremaining: 14.5s\n",
      "153:\tlearn: 1.9446391\ttotal: 2.64s\tremaining: 14.5s\n",
      "154:\tlearn: 1.9417674\ttotal: 2.65s\tremaining: 14.5s\n",
      "155:\tlearn: 1.9389325\ttotal: 2.67s\tremaining: 14.4s\n",
      "156:\tlearn: 1.9388090\ttotal: 2.69s\tremaining: 14.4s\n",
      "157:\tlearn: 1.9388017\ttotal: 2.7s\tremaining: 14.4s\n",
      "158:\tlearn: 1.9373594\ttotal: 2.71s\tremaining: 14.4s\n",
      "159:\tlearn: 1.9359200\ttotal: 2.73s\tremaining: 14.3s\n",
      "160:\tlearn: 1.9345239\ttotal: 2.75s\tremaining: 14.3s\n",
      "161:\tlearn: 1.9341969\ttotal: 2.76s\tremaining: 14.3s\n",
      "162:\tlearn: 1.9327716\ttotal: 2.77s\tremaining: 14.3s\n",
      "163:\tlearn: 1.9301553\ttotal: 2.79s\tremaining: 14.2s\n",
      "164:\tlearn: 1.9283528\ttotal: 2.81s\tremaining: 14.2s\n",
      "165:\tlearn: 1.9280087\ttotal: 2.82s\tremaining: 14.2s\n",
      "166:\tlearn: 1.9258202\ttotal: 2.84s\tremaining: 14.1s\n",
      "167:\tlearn: 1.9249009\ttotal: 2.85s\tremaining: 14.1s\n",
      "168:\tlearn: 1.9233442\ttotal: 2.87s\tremaining: 14.1s\n",
      "169:\tlearn: 1.9214365\ttotal: 2.88s\tremaining: 14.1s\n",
      "170:\tlearn: 1.9195310\ttotal: 2.9s\tremaining: 14s\n",
      "171:\tlearn: 1.9149621\ttotal: 2.91s\tremaining: 14s\n",
      "172:\tlearn: 1.9141947\ttotal: 2.93s\tremaining: 14s\n",
      "173:\tlearn: 1.9137737\ttotal: 2.94s\tremaining: 14s\n",
      "174:\tlearn: 1.9114799\ttotal: 2.96s\tremaining: 13.9s\n",
      "175:\tlearn: 1.9103112\ttotal: 2.97s\tremaining: 13.9s\n",
      "176:\tlearn: 1.9091528\ttotal: 2.99s\tremaining: 13.9s\n",
      "177:\tlearn: 1.9057268\ttotal: 3s\tremaining: 13.9s\n",
      "178:\tlearn: 1.9053700\ttotal: 3.02s\tremaining: 13.8s\n",
      "179:\tlearn: 1.9045469\ttotal: 3.03s\tremaining: 13.8s\n",
      "180:\tlearn: 1.9025230\ttotal: 3.05s\tremaining: 13.8s\n",
      "181:\tlearn: 1.9015473\ttotal: 3.06s\tremaining: 13.8s\n",
      "182:\tlearn: 1.9007332\ttotal: 3.08s\tremaining: 13.8s\n",
      "183:\tlearn: 1.8995969\ttotal: 3.1s\tremaining: 13.7s\n",
      "184:\tlearn: 1.8994565\ttotal: 3.11s\tremaining: 13.7s\n",
      "185:\tlearn: 1.8989545\ttotal: 3.13s\tremaining: 13.7s\n",
      "186:\tlearn: 1.8987218\ttotal: 3.14s\tremaining: 13.7s\n",
      "187:\tlearn: 1.8971754\ttotal: 3.16s\tremaining: 13.6s\n",
      "188:\tlearn: 1.8963783\ttotal: 3.17s\tremaining: 13.6s\n",
      "189:\tlearn: 1.8944328\ttotal: 3.19s\tremaining: 13.6s\n",
      "190:\tlearn: 1.8932171\ttotal: 3.2s\tremaining: 13.6s\n",
      "191:\tlearn: 1.8930453\ttotal: 3.21s\tremaining: 13.5s\n",
      "192:\tlearn: 1.8929188\ttotal: 3.23s\tremaining: 13.5s\n",
      "193:\tlearn: 1.8921292\ttotal: 3.24s\tremaining: 13.5s\n",
      "194:\tlearn: 1.8914647\ttotal: 3.26s\tremaining: 13.5s\n",
      "195:\tlearn: 1.8910278\ttotal: 3.28s\tremaining: 13.4s\n",
      "196:\tlearn: 1.8900427\ttotal: 3.29s\tremaining: 13.4s\n",
      "197:\tlearn: 1.8895467\ttotal: 3.31s\tremaining: 13.4s\n",
      "198:\tlearn: 1.8888445\ttotal: 3.32s\tremaining: 13.4s\n",
      "199:\tlearn: 1.8880036\ttotal: 3.34s\tremaining: 13.4s\n",
      "200:\tlearn: 1.8877507\ttotal: 3.35s\tremaining: 13.3s\n",
      "201:\tlearn: 1.8867576\ttotal: 3.37s\tremaining: 13.3s\n",
      "202:\tlearn: 1.8863023\ttotal: 3.38s\tremaining: 13.3s\n",
      "203:\tlearn: 1.8835915\ttotal: 3.4s\tremaining: 13.3s\n",
      "204:\tlearn: 1.8820079\ttotal: 3.41s\tremaining: 13.2s\n",
      "205:\tlearn: 1.8809665\ttotal: 3.43s\tremaining: 13.2s\n",
      "206:\tlearn: 1.8801201\ttotal: 3.44s\tremaining: 13.2s\n",
      "207:\tlearn: 1.8790738\ttotal: 3.46s\tremaining: 13.2s\n",
      "208:\tlearn: 1.8777644\ttotal: 3.48s\tremaining: 13.2s\n",
      "209:\tlearn: 1.8752109\ttotal: 3.49s\tremaining: 13.1s\n",
      "210:\tlearn: 1.8732623\ttotal: 3.51s\tremaining: 13.1s\n",
      "211:\tlearn: 1.8716975\ttotal: 3.52s\tremaining: 13.1s\n",
      "212:\tlearn: 1.8703801\ttotal: 3.54s\tremaining: 13.1s\n",
      "213:\tlearn: 1.8693834\ttotal: 3.55s\tremaining: 13s\n",
      "214:\tlearn: 1.8685898\ttotal: 3.57s\tremaining: 13s\n",
      "215:\tlearn: 1.8672259\ttotal: 3.58s\tremaining: 13s\n",
      "216:\tlearn: 1.8672080\ttotal: 3.6s\tremaining: 13s\n",
      "217:\tlearn: 1.8671844\ttotal: 3.61s\tremaining: 13s\n",
      "218:\tlearn: 1.8668864\ttotal: 3.63s\tremaining: 12.9s\n",
      "219:\tlearn: 1.8663534\ttotal: 3.64s\tremaining: 12.9s\n",
      "220:\tlearn: 1.8658230\ttotal: 3.65s\tremaining: 12.9s\n",
      "221:\tlearn: 1.8649730\ttotal: 3.67s\tremaining: 12.9s\n",
      "222:\tlearn: 1.8626805\ttotal: 3.69s\tremaining: 12.8s\n",
      "223:\tlearn: 1.8616880\ttotal: 3.7s\tremaining: 12.8s\n",
      "224:\tlearn: 1.8610799\ttotal: 3.72s\tremaining: 12.8s\n",
      "225:\tlearn: 1.8591019\ttotal: 3.73s\tremaining: 12.8s\n",
      "226:\tlearn: 1.8581987\ttotal: 3.75s\tremaining: 12.8s\n",
      "227:\tlearn: 1.8578647\ttotal: 3.76s\tremaining: 12.7s\n",
      "228:\tlearn: 1.8573248\ttotal: 3.78s\tremaining: 12.7s\n",
      "229:\tlearn: 1.8571350\ttotal: 3.79s\tremaining: 12.7s\n",
      "230:\tlearn: 1.8566375\ttotal: 3.81s\tremaining: 12.7s\n",
      "231:\tlearn: 1.8559832\ttotal: 3.82s\tremaining: 12.7s\n",
      "232:\tlearn: 1.8554336\ttotal: 3.84s\tremaining: 12.6s\n",
      "233:\tlearn: 1.8537901\ttotal: 3.85s\tremaining: 12.6s\n",
      "234:\tlearn: 1.8535463\ttotal: 3.87s\tremaining: 12.6s\n",
      "235:\tlearn: 1.8534159\ttotal: 3.88s\tremaining: 12.6s\n",
      "236:\tlearn: 1.8522909\ttotal: 3.9s\tremaining: 12.5s\n",
      "237:\tlearn: 1.8516133\ttotal: 3.91s\tremaining: 12.5s\n",
      "238:\tlearn: 1.8512367\ttotal: 3.93s\tremaining: 12.5s\n",
      "239:\tlearn: 1.8509131\ttotal: 3.94s\tremaining: 12.5s\n",
      "240:\tlearn: 1.8502461\ttotal: 3.96s\tremaining: 12.5s\n",
      "241:\tlearn: 1.8495338\ttotal: 3.98s\tremaining: 12.5s\n",
      "242:\tlearn: 1.8479457\ttotal: 3.99s\tremaining: 12.4s\n",
      "243:\tlearn: 1.8472134\ttotal: 4s\tremaining: 12.4s\n",
      "244:\tlearn: 1.8470181\ttotal: 4.02s\tremaining: 12.4s\n",
      "245:\tlearn: 1.8462283\ttotal: 4.03s\tremaining: 12.4s\n",
      "246:\tlearn: 1.8452517\ttotal: 4.05s\tremaining: 12.3s\n",
      "247:\tlearn: 1.8443376\ttotal: 4.07s\tremaining: 12.3s\n",
      "248:\tlearn: 1.8435179\ttotal: 4.08s\tremaining: 12.3s\n",
      "249:\tlearn: 1.8434509\ttotal: 4.09s\tremaining: 12.3s\n",
      "250:\tlearn: 1.8425094\ttotal: 4.11s\tremaining: 12.3s\n",
      "251:\tlearn: 1.8419361\ttotal: 4.13s\tremaining: 12.3s\n",
      "252:\tlearn: 1.8414748\ttotal: 4.14s\tremaining: 12.2s\n",
      "253:\tlearn: 1.8400368\ttotal: 4.16s\tremaining: 12.2s\n",
      "254:\tlearn: 1.8398776\ttotal: 4.17s\tremaining: 12.2s\n",
      "255:\tlearn: 1.8397375\ttotal: 4.19s\tremaining: 12.2s\n",
      "256:\tlearn: 1.8395893\ttotal: 4.2s\tremaining: 12.2s\n",
      "257:\tlearn: 1.8393136\ttotal: 4.22s\tremaining: 12.1s\n",
      "258:\tlearn: 1.8392001\ttotal: 4.24s\tremaining: 12.1s\n",
      "259:\tlearn: 1.8381785\ttotal: 4.25s\tremaining: 12.1s\n",
      "260:\tlearn: 1.8371989\ttotal: 4.27s\tremaining: 12.1s\n",
      "261:\tlearn: 1.8365953\ttotal: 4.28s\tremaining: 12.1s\n",
      "262:\tlearn: 1.8357134\ttotal: 4.3s\tremaining: 12s\n",
      "263:\tlearn: 1.8352408\ttotal: 4.31s\tremaining: 12s\n",
      "264:\tlearn: 1.8340000\ttotal: 4.33s\tremaining: 12s\n",
      "265:\tlearn: 1.8330499\ttotal: 4.34s\tremaining: 12s\n",
      "266:\tlearn: 1.8327918\ttotal: 4.36s\tremaining: 12s\n",
      "267:\tlearn: 1.8327817\ttotal: 4.37s\tremaining: 11.9s\n",
      "268:\tlearn: 1.8313451\ttotal: 4.39s\tremaining: 11.9s\n",
      "269:\tlearn: 1.8305117\ttotal: 4.4s\tremaining: 11.9s\n",
      "270:\tlearn: 1.8295019\ttotal: 4.42s\tremaining: 11.9s\n",
      "271:\tlearn: 1.8287796\ttotal: 4.43s\tremaining: 11.9s\n",
      "272:\tlearn: 1.8281713\ttotal: 4.45s\tremaining: 11.8s\n",
      "273:\tlearn: 1.8268401\ttotal: 4.46s\tremaining: 11.8s\n",
      "274:\tlearn: 1.8245490\ttotal: 4.48s\tremaining: 11.8s\n",
      "275:\tlearn: 1.8233848\ttotal: 4.5s\tremaining: 11.8s\n",
      "276:\tlearn: 1.8229835\ttotal: 4.51s\tremaining: 11.8s\n",
      "277:\tlearn: 1.8227998\ttotal: 4.53s\tremaining: 11.8s\n",
      "278:\tlearn: 1.8225979\ttotal: 4.54s\tremaining: 11.7s\n",
      "279:\tlearn: 1.8220904\ttotal: 4.56s\tremaining: 11.7s\n",
      "280:\tlearn: 1.8220166\ttotal: 4.57s\tremaining: 11.7s\n",
      "281:\tlearn: 1.8215671\ttotal: 4.59s\tremaining: 11.7s\n",
      "282:\tlearn: 1.8207528\ttotal: 4.6s\tremaining: 11.7s\n",
      "283:\tlearn: 1.8204759\ttotal: 4.62s\tremaining: 11.6s\n",
      "284:\tlearn: 1.8203249\ttotal: 4.63s\tremaining: 11.6s\n",
      "285:\tlearn: 1.8196582\ttotal: 4.65s\tremaining: 11.6s\n",
      "286:\tlearn: 1.8188473\ttotal: 4.66s\tremaining: 11.6s\n",
      "287:\tlearn: 1.8188291\ttotal: 4.68s\tremaining: 11.6s\n",
      "288:\tlearn: 1.8186903\ttotal: 4.69s\tremaining: 11.5s\n",
      "289:\tlearn: 1.8183928\ttotal: 4.71s\tremaining: 11.5s\n",
      "290:\tlearn: 1.8177073\ttotal: 4.72s\tremaining: 11.5s\n",
      "291:\tlearn: 1.8176749\ttotal: 4.74s\tremaining: 11.5s\n",
      "292:\tlearn: 1.8176591\ttotal: 4.75s\tremaining: 11.5s\n",
      "293:\tlearn: 1.8170325\ttotal: 4.77s\tremaining: 11.5s\n",
      "294:\tlearn: 1.8168994\ttotal: 4.79s\tremaining: 11.4s\n",
      "295:\tlearn: 1.8168742\ttotal: 4.8s\tremaining: 11.4s\n",
      "296:\tlearn: 1.8168717\ttotal: 4.82s\tremaining: 11.4s\n",
      "297:\tlearn: 1.8168413\ttotal: 4.84s\tremaining: 11.4s\n",
      "298:\tlearn: 1.8157356\ttotal: 4.85s\tremaining: 11.4s\n",
      "299:\tlearn: 1.8155865\ttotal: 4.87s\tremaining: 11.4s\n",
      "300:\tlearn: 1.8154606\ttotal: 4.88s\tremaining: 11.3s\n",
      "301:\tlearn: 1.8154045\ttotal: 4.9s\tremaining: 11.3s\n",
      "302:\tlearn: 1.8152173\ttotal: 4.92s\tremaining: 11.3s\n",
      "303:\tlearn: 1.8149142\ttotal: 4.93s\tremaining: 11.3s\n",
      "304:\tlearn: 1.8142967\ttotal: 4.94s\tremaining: 11.3s\n",
      "305:\tlearn: 1.8142815\ttotal: 4.96s\tremaining: 11.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306:\tlearn: 1.8136887\ttotal: 4.97s\tremaining: 11.2s\n",
      "307:\tlearn: 1.8128219\ttotal: 4.99s\tremaining: 11.2s\n",
      "308:\tlearn: 1.8113340\ttotal: 5.01s\tremaining: 11.2s\n",
      "309:\tlearn: 1.8107824\ttotal: 5.02s\tremaining: 11.2s\n",
      "310:\tlearn: 1.8100839\ttotal: 5.04s\tremaining: 11.2s\n",
      "311:\tlearn: 1.8093794\ttotal: 5.05s\tremaining: 11.1s\n",
      "312:\tlearn: 1.8084826\ttotal: 5.07s\tremaining: 11.1s\n",
      "313:\tlearn: 1.8082373\ttotal: 5.08s\tremaining: 11.1s\n",
      "314:\tlearn: 1.8077990\ttotal: 5.09s\tremaining: 11.1s\n",
      "315:\tlearn: 1.8077766\ttotal: 5.11s\tremaining: 11.1s\n",
      "316:\tlearn: 1.8069710\ttotal: 5.13s\tremaining: 11s\n",
      "317:\tlearn: 1.8059846\ttotal: 5.14s\tremaining: 11s\n",
      "318:\tlearn: 1.8049258\ttotal: 5.16s\tremaining: 11s\n",
      "319:\tlearn: 1.8043324\ttotal: 5.17s\tremaining: 11s\n",
      "320:\tlearn: 1.8034837\ttotal: 5.19s\tremaining: 11s\n",
      "321:\tlearn: 1.8029842\ttotal: 5.21s\tremaining: 11s\n",
      "322:\tlearn: 1.8024648\ttotal: 5.22s\tremaining: 10.9s\n",
      "323:\tlearn: 1.8021273\ttotal: 5.24s\tremaining: 10.9s\n",
      "324:\tlearn: 1.8021262\ttotal: 5.25s\tremaining: 10.9s\n",
      "325:\tlearn: 1.8021194\ttotal: 5.26s\tremaining: 10.9s\n",
      "326:\tlearn: 1.8021106\ttotal: 5.28s\tremaining: 10.9s\n",
      "327:\tlearn: 1.8016701\ttotal: 5.29s\tremaining: 10.8s\n",
      "328:\tlearn: 1.8007070\ttotal: 5.31s\tremaining: 10.8s\n",
      "329:\tlearn: 1.7993552\ttotal: 5.33s\tremaining: 10.8s\n",
      "330:\tlearn: 1.7984531\ttotal: 5.34s\tremaining: 10.8s\n",
      "331:\tlearn: 1.7980068\ttotal: 5.36s\tremaining: 10.8s\n",
      "332:\tlearn: 1.7966227\ttotal: 5.37s\tremaining: 10.8s\n",
      "333:\tlearn: 1.7965378\ttotal: 5.39s\tremaining: 10.7s\n",
      "334:\tlearn: 1.7954117\ttotal: 5.4s\tremaining: 10.7s\n",
      "335:\tlearn: 1.7949064\ttotal: 5.42s\tremaining: 10.7s\n",
      "336:\tlearn: 1.7943672\ttotal: 5.43s\tremaining: 10.7s\n",
      "337:\tlearn: 1.7933856\ttotal: 5.45s\tremaining: 10.7s\n",
      "338:\tlearn: 1.7930651\ttotal: 5.46s\tremaining: 10.7s\n",
      "339:\tlearn: 1.7929690\ttotal: 5.48s\tremaining: 10.6s\n",
      "340:\tlearn: 1.7927526\ttotal: 5.49s\tremaining: 10.6s\n",
      "341:\tlearn: 1.7925562\ttotal: 5.51s\tremaining: 10.6s\n",
      "342:\tlearn: 1.7923408\ttotal: 5.52s\tremaining: 10.6s\n",
      "343:\tlearn: 1.7920615\ttotal: 5.54s\tremaining: 10.6s\n",
      "344:\tlearn: 1.7909520\ttotal: 5.56s\tremaining: 10.5s\n",
      "345:\tlearn: 1.7901912\ttotal: 5.57s\tremaining: 10.5s\n",
      "346:\tlearn: 1.7892391\ttotal: 5.59s\tremaining: 10.5s\n",
      "347:\tlearn: 1.7885900\ttotal: 5.6s\tremaining: 10.5s\n",
      "348:\tlearn: 1.7881704\ttotal: 5.62s\tremaining: 10.5s\n",
      "349:\tlearn: 1.7873722\ttotal: 5.64s\tremaining: 10.5s\n",
      "350:\tlearn: 1.7872712\ttotal: 5.65s\tremaining: 10.5s\n",
      "351:\tlearn: 1.7872091\ttotal: 5.67s\tremaining: 10.4s\n",
      "352:\tlearn: 1.7872072\ttotal: 5.68s\tremaining: 10.4s\n",
      "353:\tlearn: 1.7872041\ttotal: 5.7s\tremaining: 10.4s\n",
      "354:\tlearn: 1.7871028\ttotal: 5.71s\tremaining: 10.4s\n",
      "355:\tlearn: 1.7871004\ttotal: 5.73s\tremaining: 10.4s\n",
      "356:\tlearn: 1.7870983\ttotal: 5.74s\tremaining: 10.3s\n",
      "357:\tlearn: 1.7859547\ttotal: 5.76s\tremaining: 10.3s\n",
      "358:\tlearn: 1.7852089\ttotal: 5.77s\tremaining: 10.3s\n",
      "359:\tlearn: 1.7848231\ttotal: 5.79s\tremaining: 10.3s\n",
      "360:\tlearn: 1.7846729\ttotal: 5.8s\tremaining: 10.3s\n",
      "361:\tlearn: 1.7842862\ttotal: 5.82s\tremaining: 10.2s\n",
      "362:\tlearn: 1.7842848\ttotal: 5.83s\tremaining: 10.2s\n",
      "363:\tlearn: 1.7842840\ttotal: 5.85s\tremaining: 10.2s\n",
      "364:\tlearn: 1.7842831\ttotal: 5.86s\tremaining: 10.2s\n",
      "365:\tlearn: 1.7842827\ttotal: 5.88s\tremaining: 10.2s\n",
      "366:\tlearn: 1.7842823\ttotal: 5.89s\tremaining: 10.2s\n",
      "367:\tlearn: 1.7841609\ttotal: 5.91s\tremaining: 10.1s\n",
      "368:\tlearn: 1.7841602\ttotal: 5.92s\tremaining: 10.1s\n",
      "369:\tlearn: 1.7841600\ttotal: 5.94s\tremaining: 10.1s\n",
      "370:\tlearn: 1.7841593\ttotal: 5.95s\tremaining: 10.1s\n",
      "371:\tlearn: 1.7841592\ttotal: 5.96s\tremaining: 10.1s\n",
      "372:\tlearn: 1.7841550\ttotal: 5.98s\tremaining: 10.1s\n",
      "373:\tlearn: 1.7840570\ttotal: 6s\tremaining: 10s\n",
      "374:\tlearn: 1.7840477\ttotal: 6.01s\tremaining: 10s\n",
      "375:\tlearn: 1.7840472\ttotal: 6.03s\tremaining: 10s\n",
      "376:\tlearn: 1.7840469\ttotal: 6.04s\tremaining: 9.99s\n",
      "377:\tlearn: 1.7831453\ttotal: 6.06s\tremaining: 9.97s\n",
      "378:\tlearn: 1.7831424\ttotal: 6.08s\tremaining: 9.96s\n",
      "379:\tlearn: 1.7830564\ttotal: 6.09s\tremaining: 9.94s\n",
      "380:\tlearn: 1.7829583\ttotal: 6.11s\tremaining: 9.92s\n",
      "381:\tlearn: 1.7811121\ttotal: 6.12s\tremaining: 9.9s\n",
      "382:\tlearn: 1.7809592\ttotal: 6.14s\tremaining: 9.88s\n",
      "383:\tlearn: 1.7803724\ttotal: 6.15s\tremaining: 9.87s\n",
      "384:\tlearn: 1.7799479\ttotal: 6.17s\tremaining: 9.85s\n",
      "385:\tlearn: 1.7797670\ttotal: 6.18s\tremaining: 9.83s\n",
      "386:\tlearn: 1.7791005\ttotal: 6.2s\tremaining: 9.81s\n",
      "387:\tlearn: 1.7790908\ttotal: 6.21s\tremaining: 9.8s\n",
      "388:\tlearn: 1.7790545\ttotal: 6.23s\tremaining: 9.78s\n",
      "389:\tlearn: 1.7789998\ttotal: 6.24s\tremaining: 9.76s\n",
      "390:\tlearn: 1.7770243\ttotal: 6.26s\tremaining: 9.74s\n",
      "391:\tlearn: 1.7770032\ttotal: 6.27s\tremaining: 9.73s\n",
      "392:\tlearn: 1.7762745\ttotal: 6.29s\tremaining: 9.71s\n",
      "393:\tlearn: 1.7762009\ttotal: 6.3s\tremaining: 9.69s\n",
      "394:\tlearn: 1.7749342\ttotal: 6.32s\tremaining: 9.68s\n",
      "395:\tlearn: 1.7740262\ttotal: 6.33s\tremaining: 9.66s\n",
      "396:\tlearn: 1.7725883\ttotal: 6.35s\tremaining: 9.64s\n",
      "397:\tlearn: 1.7717568\ttotal: 6.36s\tremaining: 9.62s\n",
      "398:\tlearn: 1.7716379\ttotal: 6.38s\tremaining: 9.61s\n",
      "399:\tlearn: 1.7715810\ttotal: 6.39s\tremaining: 9.59s\n",
      "400:\tlearn: 1.7712219\ttotal: 6.41s\tremaining: 9.57s\n",
      "401:\tlearn: 1.7711951\ttotal: 6.42s\tremaining: 9.55s\n",
      "402:\tlearn: 1.7699618\ttotal: 6.44s\tremaining: 9.54s\n",
      "403:\tlearn: 1.7697984\ttotal: 6.45s\tremaining: 9.52s\n",
      "404:\tlearn: 1.7697416\ttotal: 6.47s\tremaining: 9.5s\n",
      "405:\tlearn: 1.7697218\ttotal: 6.48s\tremaining: 9.49s\n",
      "406:\tlearn: 1.7697144\ttotal: 6.5s\tremaining: 9.47s\n",
      "407:\tlearn: 1.7696973\ttotal: 6.51s\tremaining: 9.45s\n",
      "408:\tlearn: 1.7693903\ttotal: 6.53s\tremaining: 9.44s\n",
      "409:\tlearn: 1.7687719\ttotal: 6.54s\tremaining: 9.42s\n",
      "410:\tlearn: 1.7687326\ttotal: 6.56s\tremaining: 9.4s\n",
      "411:\tlearn: 1.7685306\ttotal: 6.57s\tremaining: 9.38s\n",
      "412:\tlearn: 1.7676306\ttotal: 6.59s\tremaining: 9.37s\n",
      "413:\tlearn: 1.7670521\ttotal: 6.61s\tremaining: 9.35s\n",
      "414:\tlearn: 1.7663850\ttotal: 6.62s\tremaining: 9.33s\n",
      "415:\tlearn: 1.7663844\ttotal: 6.64s\tremaining: 9.31s\n",
      "416:\tlearn: 1.7663181\ttotal: 6.65s\tremaining: 9.3s\n",
      "417:\tlearn: 1.7662542\ttotal: 6.66s\tremaining: 9.28s\n",
      "418:\tlearn: 1.7657844\ttotal: 6.68s\tremaining: 9.26s\n",
      "419:\tlearn: 1.7651466\ttotal: 6.7s\tremaining: 9.25s\n",
      "420:\tlearn: 1.7651386\ttotal: 6.71s\tremaining: 9.23s\n",
      "421:\tlearn: 1.7651364\ttotal: 6.73s\tremaining: 9.22s\n",
      "422:\tlearn: 1.7651262\ttotal: 6.75s\tremaining: 9.2s\n",
      "423:\tlearn: 1.7643020\ttotal: 6.76s\tremaining: 9.18s\n",
      "424:\tlearn: 1.7642272\ttotal: 6.77s\tremaining: 9.16s\n",
      "425:\tlearn: 1.7641283\ttotal: 6.79s\tremaining: 9.15s\n",
      "426:\tlearn: 1.7639365\ttotal: 6.81s\tremaining: 9.13s\n",
      "427:\tlearn: 1.7638456\ttotal: 6.82s\tremaining: 9.12s\n",
      "428:\tlearn: 1.7637623\ttotal: 6.84s\tremaining: 9.1s\n",
      "429:\tlearn: 1.7635623\ttotal: 6.85s\tremaining: 9.08s\n",
      "430:\tlearn: 1.7634931\ttotal: 6.87s\tremaining: 9.06s\n",
      "431:\tlearn: 1.7633909\ttotal: 6.88s\tremaining: 9.05s\n",
      "432:\tlearn: 1.7631527\ttotal: 6.89s\tremaining: 9.03s\n",
      "433:\tlearn: 1.7628176\ttotal: 6.91s\tremaining: 9.01s\n",
      "434:\tlearn: 1.7625110\ttotal: 6.93s\tremaining: 9s\n",
      "435:\tlearn: 1.7624420\ttotal: 6.94s\tremaining: 8.98s\n",
      "436:\tlearn: 1.7624337\ttotal: 6.96s\tremaining: 8.96s\n",
      "437:\tlearn: 1.7624204\ttotal: 6.97s\tremaining: 8.94s\n",
      "438:\tlearn: 1.7623884\ttotal: 6.99s\tremaining: 8.93s\n",
      "439:\tlearn: 1.7623440\ttotal: 7s\tremaining: 8.91s\n",
      "440:\tlearn: 1.7623387\ttotal: 7.01s\tremaining: 8.89s\n",
      "441:\tlearn: 1.7623383\ttotal: 7.03s\tremaining: 8.87s\n",
      "442:\tlearn: 1.7622978\ttotal: 7.04s\tremaining: 8.86s\n",
      "443:\tlearn: 1.7618399\ttotal: 7.06s\tremaining: 8.84s\n",
      "444:\tlearn: 1.7617677\ttotal: 7.07s\tremaining: 8.82s\n",
      "445:\tlearn: 1.7616022\ttotal: 7.09s\tremaining: 8.81s\n",
      "446:\tlearn: 1.7615812\ttotal: 7.11s\tremaining: 8.79s\n",
      "447:\tlearn: 1.7615664\ttotal: 7.12s\tremaining: 8.77s\n",
      "448:\tlearn: 1.7615603\ttotal: 7.13s\tremaining: 8.76s\n",
      "449:\tlearn: 1.7603757\ttotal: 7.15s\tremaining: 8.74s\n",
      "450:\tlearn: 1.7601563\ttotal: 7.17s\tremaining: 8.72s\n",
      "451:\tlearn: 1.7599345\ttotal: 7.18s\tremaining: 8.71s\n",
      "452:\tlearn: 1.7596989\ttotal: 7.2s\tremaining: 8.69s\n",
      "453:\tlearn: 1.7595450\ttotal: 7.21s\tremaining: 8.67s\n",
      "454:\tlearn: 1.7592870\ttotal: 7.23s\tremaining: 8.65s\n",
      "455:\tlearn: 1.7589760\ttotal: 7.24s\tremaining: 8.64s\n",
      "456:\tlearn: 1.7586233\ttotal: 7.25s\tremaining: 8.62s\n",
      "457:\tlearn: 1.7584268\ttotal: 7.27s\tremaining: 8.6s\n",
      "458:\tlearn: 1.7584197\ttotal: 7.28s\tremaining: 8.58s\n",
      "459:\tlearn: 1.7584104\ttotal: 7.3s\tremaining: 8.57s\n",
      "460:\tlearn: 1.7584028\ttotal: 7.31s\tremaining: 8.55s\n",
      "461:\tlearn: 1.7582991\ttotal: 7.33s\tremaining: 8.54s\n",
      "462:\tlearn: 1.7575445\ttotal: 7.35s\tremaining: 8.52s\n",
      "463:\tlearn: 1.7569663\ttotal: 7.36s\tremaining: 8.5s\n",
      "464:\tlearn: 1.7569583\ttotal: 7.38s\tremaining: 8.49s\n",
      "465:\tlearn: 1.7568902\ttotal: 7.39s\tremaining: 8.47s\n",
      "466:\tlearn: 1.7565124\ttotal: 7.41s\tremaining: 8.46s\n",
      "467:\tlearn: 1.7564843\ttotal: 7.42s\tremaining: 8.44s\n",
      "468:\tlearn: 1.7564034\ttotal: 7.44s\tremaining: 8.42s\n",
      "469:\tlearn: 1.7560449\ttotal: 7.45s\tremaining: 8.4s\n",
      "470:\tlearn: 1.7560442\ttotal: 7.47s\tremaining: 8.39s\n",
      "471:\tlearn: 1.7560136\ttotal: 7.48s\tremaining: 8.37s\n",
      "472:\tlearn: 1.7557695\ttotal: 7.5s\tremaining: 8.35s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "473:\tlearn: 1.7553185\ttotal: 7.51s\tremaining: 8.34s\n",
      "474:\tlearn: 1.7551719\ttotal: 7.53s\tremaining: 8.32s\n",
      "475:\tlearn: 1.7549059\ttotal: 7.54s\tremaining: 8.3s\n",
      "476:\tlearn: 1.7544021\ttotal: 7.56s\tremaining: 8.29s\n",
      "477:\tlearn: 1.7543940\ttotal: 7.57s\tremaining: 8.27s\n",
      "478:\tlearn: 1.7543767\ttotal: 7.59s\tremaining: 8.25s\n",
      "479:\tlearn: 1.7543757\ttotal: 7.6s\tremaining: 8.24s\n",
      "480:\tlearn: 1.7543752\ttotal: 7.62s\tremaining: 8.22s\n",
      "481:\tlearn: 1.7543742\ttotal: 7.63s\tremaining: 8.2s\n",
      "482:\tlearn: 1.7543295\ttotal: 7.65s\tremaining: 8.19s\n",
      "483:\tlearn: 1.7543187\ttotal: 7.66s\tremaining: 8.17s\n",
      "484:\tlearn: 1.7542598\ttotal: 7.68s\tremaining: 8.15s\n",
      "485:\tlearn: 1.7533241\ttotal: 7.7s\tremaining: 8.14s\n",
      "486:\tlearn: 1.7532856\ttotal: 7.71s\tremaining: 8.12s\n",
      "487:\tlearn: 1.7532782\ttotal: 7.73s\tremaining: 8.11s\n",
      "488:\tlearn: 1.7532523\ttotal: 7.74s\tremaining: 8.09s\n",
      "489:\tlearn: 1.7531935\ttotal: 7.76s\tremaining: 8.07s\n",
      "490:\tlearn: 1.7531780\ttotal: 7.77s\tremaining: 8.05s\n",
      "491:\tlearn: 1.7531712\ttotal: 7.79s\tremaining: 8.04s\n",
      "492:\tlearn: 1.7530885\ttotal: 7.8s\tremaining: 8.02s\n",
      "493:\tlearn: 1.7530527\ttotal: 7.81s\tremaining: 8s\n",
      "494:\tlearn: 1.7530367\ttotal: 7.83s\tremaining: 7.99s\n",
      "495:\tlearn: 1.7530244\ttotal: 7.84s\tremaining: 7.97s\n",
      "496:\tlearn: 1.7530172\ttotal: 7.86s\tremaining: 7.95s\n",
      "497:\tlearn: 1.7529024\ttotal: 7.87s\tremaining: 7.94s\n",
      "498:\tlearn: 1.7528579\ttotal: 7.89s\tremaining: 7.92s\n",
      "499:\tlearn: 1.7527873\ttotal: 7.9s\tremaining: 7.9s\n",
      "500:\tlearn: 1.7527537\ttotal: 7.92s\tremaining: 7.88s\n",
      "501:\tlearn: 1.7527166\ttotal: 7.93s\tremaining: 7.87s\n",
      "502:\tlearn: 1.7526143\ttotal: 7.95s\tremaining: 7.85s\n",
      "503:\tlearn: 1.7525823\ttotal: 7.96s\tremaining: 7.84s\n",
      "504:\tlearn: 1.7525746\ttotal: 7.98s\tremaining: 7.82s\n",
      "505:\tlearn: 1.7525700\ttotal: 8s\tremaining: 7.8s\n",
      "506:\tlearn: 1.7525700\ttotal: 8.01s\tremaining: 7.79s\n",
      "507:\tlearn: 1.7520058\ttotal: 8.02s\tremaining: 7.77s\n",
      "508:\tlearn: 1.7514377\ttotal: 8.04s\tremaining: 7.75s\n",
      "509:\tlearn: 1.7511650\ttotal: 8.05s\tremaining: 7.74s\n",
      "510:\tlearn: 1.7511319\ttotal: 8.07s\tremaining: 7.72s\n",
      "511:\tlearn: 1.7511302\ttotal: 8.08s\tremaining: 7.7s\n",
      "512:\tlearn: 1.7511299\ttotal: 8.1s\tremaining: 7.69s\n",
      "513:\tlearn: 1.7511205\ttotal: 8.11s\tremaining: 7.67s\n",
      "514:\tlearn: 1.7510868\ttotal: 8.13s\tremaining: 7.65s\n",
      "515:\tlearn: 1.7510460\ttotal: 8.14s\tremaining: 7.64s\n",
      "516:\tlearn: 1.7509688\ttotal: 8.16s\tremaining: 7.62s\n",
      "517:\tlearn: 1.7509606\ttotal: 8.17s\tremaining: 7.6s\n",
      "518:\tlearn: 1.7509489\ttotal: 8.19s\tremaining: 7.59s\n",
      "519:\tlearn: 1.7509256\ttotal: 8.2s\tremaining: 7.57s\n",
      "520:\tlearn: 1.7496631\ttotal: 8.22s\tremaining: 7.55s\n",
      "521:\tlearn: 1.7494850\ttotal: 8.23s\tremaining: 7.54s\n",
      "522:\tlearn: 1.7494476\ttotal: 8.25s\tremaining: 7.52s\n",
      "523:\tlearn: 1.7494276\ttotal: 8.26s\tremaining: 7.5s\n",
      "524:\tlearn: 1.7493859\ttotal: 8.28s\tremaining: 7.49s\n",
      "525:\tlearn: 1.7493858\ttotal: 8.29s\tremaining: 7.47s\n",
      "526:\tlearn: 1.7493857\ttotal: 8.3s\tremaining: 7.45s\n",
      "527:\tlearn: 1.7493642\ttotal: 8.32s\tremaining: 7.44s\n",
      "528:\tlearn: 1.7493115\ttotal: 8.34s\tremaining: 7.42s\n",
      "529:\tlearn: 1.7492974\ttotal: 8.35s\tremaining: 7.4s\n",
      "530:\tlearn: 1.7492841\ttotal: 8.37s\tremaining: 7.39s\n",
      "531:\tlearn: 1.7490318\ttotal: 8.38s\tremaining: 7.37s\n",
      "532:\tlearn: 1.7489594\ttotal: 8.4s\tremaining: 7.36s\n",
      "533:\tlearn: 1.7489339\ttotal: 8.41s\tremaining: 7.34s\n",
      "534:\tlearn: 1.7489287\ttotal: 8.43s\tremaining: 7.33s\n",
      "535:\tlearn: 1.7489287\ttotal: 8.44s\tremaining: 7.31s\n",
      "536:\tlearn: 1.7489287\ttotal: 8.46s\tremaining: 7.29s\n",
      "537:\tlearn: 1.7489284\ttotal: 8.47s\tremaining: 7.28s\n",
      "538:\tlearn: 1.7489283\ttotal: 8.48s\tremaining: 7.26s\n",
      "539:\tlearn: 1.7489283\ttotal: 8.5s\tremaining: 7.24s\n",
      "540:\tlearn: 1.7489280\ttotal: 8.51s\tremaining: 7.22s\n",
      "541:\tlearn: 1.7489280\ttotal: 8.53s\tremaining: 7.21s\n",
      "542:\tlearn: 1.7489279\ttotal: 8.54s\tremaining: 7.19s\n",
      "543:\tlearn: 1.7489277\ttotal: 8.56s\tremaining: 7.17s\n",
      "544:\tlearn: 1.7489274\ttotal: 8.57s\tremaining: 7.16s\n",
      "545:\tlearn: 1.7489273\ttotal: 8.59s\tremaining: 7.14s\n",
      "546:\tlearn: 1.7489253\ttotal: 8.6s\tremaining: 7.12s\n",
      "547:\tlearn: 1.7489251\ttotal: 8.62s\tremaining: 7.11s\n",
      "548:\tlearn: 1.7489246\ttotal: 8.63s\tremaining: 7.09s\n",
      "549:\tlearn: 1.7489242\ttotal: 8.65s\tremaining: 7.07s\n",
      "550:\tlearn: 1.7489225\ttotal: 8.66s\tremaining: 7.06s\n",
      "551:\tlearn: 1.7489213\ttotal: 8.68s\tremaining: 7.04s\n",
      "552:\tlearn: 1.7489195\ttotal: 8.69s\tremaining: 7.03s\n",
      "553:\tlearn: 1.7489143\ttotal: 8.71s\tremaining: 7.01s\n",
      "554:\tlearn: 1.7489136\ttotal: 8.72s\tremaining: 6.99s\n",
      "555:\tlearn: 1.7488953\ttotal: 8.73s\tremaining: 6.97s\n",
      "556:\tlearn: 1.7487514\ttotal: 8.75s\tremaining: 6.96s\n",
      "557:\tlearn: 1.7487288\ttotal: 8.76s\tremaining: 6.94s\n",
      "558:\tlearn: 1.7487208\ttotal: 8.78s\tremaining: 6.93s\n",
      "559:\tlearn: 1.7482841\ttotal: 8.8s\tremaining: 6.91s\n",
      "560:\tlearn: 1.7482839\ttotal: 8.81s\tremaining: 6.9s\n",
      "561:\tlearn: 1.7482422\ttotal: 8.83s\tremaining: 6.88s\n",
      "562:\tlearn: 1.7482393\ttotal: 8.84s\tremaining: 6.86s\n",
      "563:\tlearn: 1.7482272\ttotal: 8.86s\tremaining: 6.85s\n",
      "564:\tlearn: 1.7482021\ttotal: 8.87s\tremaining: 6.83s\n",
      "565:\tlearn: 1.7476693\ttotal: 8.89s\tremaining: 6.81s\n",
      "566:\tlearn: 1.7476685\ttotal: 8.9s\tremaining: 6.8s\n",
      "567:\tlearn: 1.7472011\ttotal: 8.91s\tremaining: 6.78s\n",
      "568:\tlearn: 1.7471765\ttotal: 8.93s\tremaining: 6.76s\n",
      "569:\tlearn: 1.7471765\ttotal: 8.95s\tremaining: 6.75s\n",
      "570:\tlearn: 1.7471701\ttotal: 8.96s\tremaining: 6.73s\n",
      "571:\tlearn: 1.7471701\ttotal: 8.97s\tremaining: 6.71s\n",
      "572:\tlearn: 1.7471700\ttotal: 8.99s\tremaining: 6.7s\n",
      "573:\tlearn: 1.7471700\ttotal: 9.01s\tremaining: 6.68s\n",
      "574:\tlearn: 1.7471517\ttotal: 9.02s\tremaining: 6.67s\n",
      "575:\tlearn: 1.7471517\ttotal: 9.04s\tremaining: 6.65s\n",
      "576:\tlearn: 1.7471019\ttotal: 9.05s\tremaining: 6.64s\n",
      "577:\tlearn: 1.7469869\ttotal: 9.07s\tremaining: 6.62s\n",
      "578:\tlearn: 1.7467625\ttotal: 9.08s\tremaining: 6.61s\n",
      "579:\tlearn: 1.7467536\ttotal: 9.1s\tremaining: 6.59s\n",
      "580:\tlearn: 1.7467536\ttotal: 9.11s\tremaining: 6.57s\n",
      "581:\tlearn: 1.7467490\ttotal: 9.13s\tremaining: 6.56s\n",
      "582:\tlearn: 1.7460683\ttotal: 9.14s\tremaining: 6.54s\n",
      "583:\tlearn: 1.7455147\ttotal: 9.16s\tremaining: 6.53s\n",
      "584:\tlearn: 1.7455144\ttotal: 9.18s\tremaining: 6.51s\n",
      "585:\tlearn: 1.7448250\ttotal: 9.19s\tremaining: 6.49s\n",
      "586:\tlearn: 1.7444366\ttotal: 9.21s\tremaining: 6.48s\n",
      "587:\tlearn: 1.7444231\ttotal: 9.22s\tremaining: 6.46s\n",
      "588:\tlearn: 1.7444217\ttotal: 9.24s\tremaining: 6.45s\n",
      "589:\tlearn: 1.7444216\ttotal: 9.25s\tremaining: 6.43s\n",
      "590:\tlearn: 1.7442924\ttotal: 9.27s\tremaining: 6.41s\n",
      "591:\tlearn: 1.7442258\ttotal: 9.28s\tremaining: 6.4s\n",
      "592:\tlearn: 1.7442078\ttotal: 9.3s\tremaining: 6.38s\n",
      "593:\tlearn: 1.7440969\ttotal: 9.31s\tremaining: 6.36s\n",
      "594:\tlearn: 1.7440523\ttotal: 9.33s\tremaining: 6.35s\n",
      "595:\tlearn: 1.7440350\ttotal: 9.34s\tremaining: 6.33s\n",
      "596:\tlearn: 1.7440107\ttotal: 9.36s\tremaining: 6.32s\n",
      "597:\tlearn: 1.7440104\ttotal: 9.37s\tremaining: 6.3s\n",
      "598:\tlearn: 1.7440104\ttotal: 9.39s\tremaining: 6.28s\n",
      "599:\tlearn: 1.7440014\ttotal: 9.4s\tremaining: 6.27s\n",
      "600:\tlearn: 1.7440009\ttotal: 9.41s\tremaining: 6.25s\n",
      "601:\tlearn: 1.7439974\ttotal: 9.43s\tremaining: 6.23s\n",
      "602:\tlearn: 1.7439619\ttotal: 9.45s\tremaining: 6.22s\n",
      "603:\tlearn: 1.7439617\ttotal: 9.46s\tremaining: 6.21s\n",
      "604:\tlearn: 1.7439617\ttotal: 9.48s\tremaining: 6.19s\n",
      "605:\tlearn: 1.7439616\ttotal: 9.49s\tremaining: 6.17s\n",
      "606:\tlearn: 1.7439615\ttotal: 9.51s\tremaining: 6.16s\n",
      "607:\tlearn: 1.7439614\ttotal: 9.53s\tremaining: 6.14s\n",
      "608:\tlearn: 1.7439612\ttotal: 9.54s\tremaining: 6.13s\n",
      "609:\tlearn: 1.7439378\ttotal: 9.56s\tremaining: 6.11s\n",
      "610:\tlearn: 1.7433648\ttotal: 9.57s\tremaining: 6.09s\n",
      "611:\tlearn: 1.7428155\ttotal: 9.59s\tremaining: 6.08s\n",
      "612:\tlearn: 1.7424188\ttotal: 9.6s\tremaining: 6.06s\n",
      "613:\tlearn: 1.7423658\ttotal: 9.62s\tremaining: 6.04s\n",
      "614:\tlearn: 1.7423579\ttotal: 9.63s\tremaining: 6.03s\n",
      "615:\tlearn: 1.7423572\ttotal: 9.64s\tremaining: 6.01s\n",
      "616:\tlearn: 1.7423572\ttotal: 9.66s\tremaining: 6s\n",
      "617:\tlearn: 1.7423572\ttotal: 9.68s\tremaining: 5.98s\n",
      "618:\tlearn: 1.7423572\ttotal: 9.69s\tremaining: 5.97s\n",
      "619:\tlearn: 1.7423567\ttotal: 9.71s\tremaining: 5.95s\n",
      "620:\tlearn: 1.7423489\ttotal: 9.72s\tremaining: 5.93s\n",
      "621:\tlearn: 1.7421100\ttotal: 9.74s\tremaining: 5.92s\n",
      "622:\tlearn: 1.7420363\ttotal: 9.75s\tremaining: 5.9s\n",
      "623:\tlearn: 1.7410083\ttotal: 9.77s\tremaining: 5.89s\n",
      "624:\tlearn: 1.7407440\ttotal: 9.78s\tremaining: 5.87s\n",
      "625:\tlearn: 1.7407283\ttotal: 9.8s\tremaining: 5.86s\n",
      "626:\tlearn: 1.7407281\ttotal: 9.81s\tremaining: 5.84s\n",
      "627:\tlearn: 1.7401204\ttotal: 9.83s\tremaining: 5.82s\n",
      "628:\tlearn: 1.7395555\ttotal: 9.84s\tremaining: 5.8s\n",
      "629:\tlearn: 1.7395150\ttotal: 9.86s\tremaining: 5.79s\n",
      "630:\tlearn: 1.7395088\ttotal: 9.87s\tremaining: 5.77s\n",
      "631:\tlearn: 1.7395069\ttotal: 9.89s\tremaining: 5.76s\n",
      "632:\tlearn: 1.7395068\ttotal: 9.9s\tremaining: 5.74s\n",
      "633:\tlearn: 1.7395058\ttotal: 9.92s\tremaining: 5.73s\n",
      "634:\tlearn: 1.7394743\ttotal: 9.93s\tremaining: 5.71s\n",
      "635:\tlearn: 1.7394593\ttotal: 9.95s\tremaining: 5.69s\n",
      "636:\tlearn: 1.7393909\ttotal: 9.96s\tremaining: 5.68s\n",
      "637:\tlearn: 1.7390701\ttotal: 9.98s\tremaining: 5.66s\n",
      "638:\tlearn: 1.7381592\ttotal: 9.99s\tremaining: 5.65s\n",
      "639:\tlearn: 1.7373696\ttotal: 10s\tremaining: 5.63s\n",
      "640:\tlearn: 1.7373310\ttotal: 10s\tremaining: 5.62s\n",
      "641:\tlearn: 1.7373293\ttotal: 10s\tremaining: 5.6s\n",
      "642:\tlearn: 1.7369252\ttotal: 10.1s\tremaining: 5.58s\n",
      "643:\tlearn: 1.7360217\ttotal: 10.1s\tremaining: 5.57s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644:\tlearn: 1.7356947\ttotal: 10.1s\tremaining: 5.55s\n",
      "645:\tlearn: 1.7356944\ttotal: 10.1s\tremaining: 5.54s\n",
      "646:\tlearn: 1.7356934\ttotal: 10.1s\tremaining: 5.52s\n",
      "647:\tlearn: 1.7356769\ttotal: 10.1s\tremaining: 5.5s\n",
      "648:\tlearn: 1.7353705\ttotal: 10.1s\tremaining: 5.49s\n",
      "649:\tlearn: 1.7353702\ttotal: 10.2s\tremaining: 5.47s\n",
      "650:\tlearn: 1.7353602\ttotal: 10.2s\tremaining: 5.46s\n",
      "651:\tlearn: 1.7353596\ttotal: 10.2s\tremaining: 5.44s\n",
      "652:\tlearn: 1.7353594\ttotal: 10.2s\tremaining: 5.42s\n",
      "653:\tlearn: 1.7353591\ttotal: 10.2s\tremaining: 5.41s\n",
      "654:\tlearn: 1.7353587\ttotal: 10.2s\tremaining: 5.39s\n",
      "655:\tlearn: 1.7353587\ttotal: 10.3s\tremaining: 5.38s\n",
      "656:\tlearn: 1.7353587\ttotal: 10.3s\tremaining: 5.36s\n",
      "657:\tlearn: 1.7353587\ttotal: 10.3s\tremaining: 5.34s\n",
      "658:\tlearn: 1.7353587\ttotal: 10.3s\tremaining: 5.33s\n",
      "659:\tlearn: 1.7353586\ttotal: 10.3s\tremaining: 5.31s\n",
      "660:\tlearn: 1.7353576\ttotal: 10.3s\tremaining: 5.3s\n",
      "661:\tlearn: 1.7353576\ttotal: 10.3s\tremaining: 5.28s\n",
      "662:\tlearn: 1.7353576\ttotal: 10.4s\tremaining: 5.27s\n",
      "663:\tlearn: 1.7353576\ttotal: 10.4s\tremaining: 5.25s\n",
      "664:\tlearn: 1.7353432\ttotal: 10.4s\tremaining: 5.23s\n",
      "665:\tlearn: 1.7353249\ttotal: 10.4s\tremaining: 5.22s\n",
      "666:\tlearn: 1.7351599\ttotal: 10.4s\tremaining: 5.2s\n",
      "667:\tlearn: 1.7351539\ttotal: 10.4s\tremaining: 5.19s\n",
      "668:\tlearn: 1.7351066\ttotal: 10.5s\tremaining: 5.17s\n",
      "669:\tlearn: 1.7346863\ttotal: 10.5s\tremaining: 5.16s\n",
      "670:\tlearn: 1.7345987\ttotal: 10.5s\tremaining: 5.14s\n",
      "671:\tlearn: 1.7340104\ttotal: 10.5s\tremaining: 5.12s\n",
      "672:\tlearn: 1.7337174\ttotal: 10.5s\tremaining: 5.11s\n",
      "673:\tlearn: 1.7329657\ttotal: 10.5s\tremaining: 5.09s\n",
      "674:\tlearn: 1.7328504\ttotal: 10.5s\tremaining: 5.08s\n",
      "675:\tlearn: 1.7328470\ttotal: 10.6s\tremaining: 5.06s\n",
      "676:\tlearn: 1.7328020\ttotal: 10.6s\tremaining: 5.04s\n",
      "677:\tlearn: 1.7327546\ttotal: 10.6s\tremaining: 5.03s\n",
      "678:\tlearn: 1.7325035\ttotal: 10.6s\tremaining: 5.01s\n",
      "679:\tlearn: 1.7324801\ttotal: 10.6s\tremaining: 5s\n",
      "680:\tlearn: 1.7324800\ttotal: 10.6s\tremaining: 4.98s\n",
      "681:\tlearn: 1.7324797\ttotal: 10.6s\tremaining: 4.96s\n",
      "682:\tlearn: 1.7324793\ttotal: 10.7s\tremaining: 4.95s\n",
      "683:\tlearn: 1.7324787\ttotal: 10.7s\tremaining: 4.93s\n",
      "684:\tlearn: 1.7324782\ttotal: 10.7s\tremaining: 4.92s\n",
      "685:\tlearn: 1.7324776\ttotal: 10.7s\tremaining: 4.9s\n",
      "686:\tlearn: 1.7324772\ttotal: 10.7s\tremaining: 4.89s\n",
      "687:\tlearn: 1.7324772\ttotal: 10.7s\tremaining: 4.87s\n",
      "688:\tlearn: 1.7324032\ttotal: 10.8s\tremaining: 4.86s\n",
      "689:\tlearn: 1.7322466\ttotal: 10.8s\tremaining: 4.84s\n",
      "690:\tlearn: 1.7315667\ttotal: 10.8s\tremaining: 4.82s\n",
      "691:\tlearn: 1.7315665\ttotal: 10.8s\tremaining: 4.81s\n",
      "692:\tlearn: 1.7315620\ttotal: 10.8s\tremaining: 4.79s\n",
      "693:\tlearn: 1.7315612\ttotal: 10.8s\tremaining: 4.78s\n",
      "694:\tlearn: 1.7315612\ttotal: 10.8s\tremaining: 4.76s\n",
      "695:\tlearn: 1.7315234\ttotal: 10.9s\tremaining: 4.74s\n",
      "696:\tlearn: 1.7315234\ttotal: 10.9s\tremaining: 4.73s\n",
      "697:\tlearn: 1.7315233\ttotal: 10.9s\tremaining: 4.71s\n",
      "698:\tlearn: 1.7313127\ttotal: 10.9s\tremaining: 4.7s\n",
      "699:\tlearn: 1.7313127\ttotal: 10.9s\tremaining: 4.68s\n",
      "700:\tlearn: 1.7313127\ttotal: 10.9s\tremaining: 4.66s\n",
      "701:\tlearn: 1.7312426\ttotal: 11s\tremaining: 4.65s\n",
      "702:\tlearn: 1.7304471\ttotal: 11s\tremaining: 4.63s\n",
      "703:\tlearn: 1.7295921\ttotal: 11s\tremaining: 4.62s\n",
      "704:\tlearn: 1.7295522\ttotal: 11s\tremaining: 4.6s\n",
      "705:\tlearn: 1.7295517\ttotal: 11s\tremaining: 4.58s\n",
      "706:\tlearn: 1.7295517\ttotal: 11s\tremaining: 4.57s\n",
      "707:\tlearn: 1.7295517\ttotal: 11s\tremaining: 4.55s\n",
      "708:\tlearn: 1.7294731\ttotal: 11.1s\tremaining: 4.54s\n",
      "709:\tlearn: 1.7294577\ttotal: 11.1s\tremaining: 4.52s\n",
      "710:\tlearn: 1.7294292\ttotal: 11.1s\tremaining: 4.51s\n",
      "711:\tlearn: 1.7291354\ttotal: 11.1s\tremaining: 4.49s\n",
      "712:\tlearn: 1.7283150\ttotal: 11.1s\tremaining: 4.47s\n",
      "713:\tlearn: 1.7283115\ttotal: 11.1s\tremaining: 4.46s\n",
      "714:\tlearn: 1.7275320\ttotal: 11.1s\tremaining: 4.44s\n",
      "715:\tlearn: 1.7274830\ttotal: 11.2s\tremaining: 4.43s\n",
      "716:\tlearn: 1.7270898\ttotal: 11.2s\tremaining: 4.41s\n",
      "717:\tlearn: 1.7270719\ttotal: 11.2s\tremaining: 4.4s\n",
      "718:\tlearn: 1.7270718\ttotal: 11.2s\tremaining: 4.38s\n",
      "719:\tlearn: 1.7270693\ttotal: 11.2s\tremaining: 4.36s\n",
      "720:\tlearn: 1.7270693\ttotal: 11.2s\tremaining: 4.35s\n",
      "721:\tlearn: 1.7270528\ttotal: 11.2s\tremaining: 4.33s\n",
      "722:\tlearn: 1.7269988\ttotal: 11.3s\tremaining: 4.32s\n",
      "723:\tlearn: 1.7269860\ttotal: 11.3s\tremaining: 4.3s\n",
      "724:\tlearn: 1.7266809\ttotal: 11.3s\tremaining: 4.28s\n",
      "725:\tlearn: 1.7266429\ttotal: 11.3s\tremaining: 4.27s\n",
      "726:\tlearn: 1.7265255\ttotal: 11.3s\tremaining: 4.25s\n",
      "727:\tlearn: 1.7265254\ttotal: 11.3s\tremaining: 4.23s\n",
      "728:\tlearn: 1.7264860\ttotal: 11.3s\tremaining: 4.22s\n",
      "729:\tlearn: 1.7264668\ttotal: 11.4s\tremaining: 4.2s\n",
      "730:\tlearn: 1.7264062\ttotal: 11.4s\tremaining: 4.19s\n",
      "731:\tlearn: 1.7263994\ttotal: 11.4s\tremaining: 4.17s\n",
      "732:\tlearn: 1.7263991\ttotal: 11.4s\tremaining: 4.16s\n",
      "733:\tlearn: 1.7263842\ttotal: 11.4s\tremaining: 4.14s\n",
      "734:\tlearn: 1.7263839\ttotal: 11.4s\tremaining: 4.13s\n",
      "735:\tlearn: 1.7263824\ttotal: 11.5s\tremaining: 4.11s\n",
      "736:\tlearn: 1.7263198\ttotal: 11.5s\tremaining: 4.09s\n",
      "737:\tlearn: 1.7259420\ttotal: 11.5s\tremaining: 4.08s\n",
      "738:\tlearn: 1.7259199\ttotal: 11.5s\tremaining: 4.06s\n",
      "739:\tlearn: 1.7258819\ttotal: 11.5s\tremaining: 4.05s\n",
      "740:\tlearn: 1.7258812\ttotal: 11.5s\tremaining: 4.03s\n",
      "741:\tlearn: 1.7258811\ttotal: 11.5s\tremaining: 4.01s\n",
      "742:\tlearn: 1.7258308\ttotal: 11.6s\tremaining: 4s\n",
      "743:\tlearn: 1.7257512\ttotal: 11.6s\tremaining: 3.98s\n",
      "744:\tlearn: 1.7256227\ttotal: 11.6s\tremaining: 3.97s\n",
      "745:\tlearn: 1.7255443\ttotal: 11.6s\tremaining: 3.95s\n",
      "746:\tlearn: 1.7255229\ttotal: 11.6s\tremaining: 3.94s\n",
      "747:\tlearn: 1.7254917\ttotal: 11.6s\tremaining: 3.92s\n",
      "748:\tlearn: 1.7253209\ttotal: 11.7s\tremaining: 3.9s\n",
      "749:\tlearn: 1.7253175\ttotal: 11.7s\tremaining: 3.89s\n",
      "750:\tlearn: 1.7253174\ttotal: 11.7s\tremaining: 3.87s\n",
      "751:\tlearn: 1.7252893\ttotal: 11.7s\tremaining: 3.86s\n",
      "752:\tlearn: 1.7252771\ttotal: 11.7s\tremaining: 3.84s\n",
      "753:\tlearn: 1.7252740\ttotal: 11.7s\tremaining: 3.83s\n",
      "754:\tlearn: 1.7252720\ttotal: 11.7s\tremaining: 3.81s\n",
      "755:\tlearn: 1.7252716\ttotal: 11.8s\tremaining: 3.79s\n",
      "756:\tlearn: 1.7250257\ttotal: 11.8s\tremaining: 3.78s\n",
      "757:\tlearn: 1.7238413\ttotal: 11.8s\tremaining: 3.76s\n",
      "758:\tlearn: 1.7238042\ttotal: 11.8s\tremaining: 3.75s\n",
      "759:\tlearn: 1.7237703\ttotal: 11.8s\tremaining: 3.73s\n",
      "760:\tlearn: 1.7235749\ttotal: 11.8s\tremaining: 3.72s\n",
      "761:\tlearn: 1.7235652\ttotal: 11.8s\tremaining: 3.7s\n",
      "762:\tlearn: 1.7231896\ttotal: 11.9s\tremaining: 3.69s\n",
      "763:\tlearn: 1.7231753\ttotal: 11.9s\tremaining: 3.67s\n",
      "764:\tlearn: 1.7231624\ttotal: 11.9s\tremaining: 3.65s\n",
      "765:\tlearn: 1.7231063\ttotal: 11.9s\tremaining: 3.64s\n",
      "766:\tlearn: 1.7231047\ttotal: 11.9s\tremaining: 3.62s\n",
      "767:\tlearn: 1.7227991\ttotal: 11.9s\tremaining: 3.61s\n",
      "768:\tlearn: 1.7226929\ttotal: 12s\tremaining: 3.59s\n",
      "769:\tlearn: 1.7223178\ttotal: 12s\tremaining: 3.58s\n",
      "770:\tlearn: 1.7223172\ttotal: 12s\tremaining: 3.56s\n",
      "771:\tlearn: 1.7218181\ttotal: 12s\tremaining: 3.54s\n",
      "772:\tlearn: 1.7218174\ttotal: 12s\tremaining: 3.53s\n",
      "773:\tlearn: 1.7218087\ttotal: 12s\tremaining: 3.51s\n",
      "774:\tlearn: 1.7218087\ttotal: 12s\tremaining: 3.5s\n",
      "775:\tlearn: 1.7218076\ttotal: 12.1s\tremaining: 3.48s\n",
      "776:\tlearn: 1.7218076\ttotal: 12.1s\tremaining: 3.46s\n",
      "777:\tlearn: 1.7218058\ttotal: 12.1s\tremaining: 3.45s\n",
      "778:\tlearn: 1.7218055\ttotal: 12.1s\tremaining: 3.43s\n",
      "779:\tlearn: 1.7217909\ttotal: 12.1s\tremaining: 3.42s\n",
      "780:\tlearn: 1.7217909\ttotal: 12.1s\tremaining: 3.4s\n",
      "781:\tlearn: 1.7213589\ttotal: 12.1s\tremaining: 3.39s\n",
      "782:\tlearn: 1.7213568\ttotal: 12.2s\tremaining: 3.37s\n",
      "783:\tlearn: 1.7198187\ttotal: 12.2s\tremaining: 3.35s\n",
      "784:\tlearn: 1.7195736\ttotal: 12.2s\tremaining: 3.34s\n",
      "785:\tlearn: 1.7191727\ttotal: 12.2s\tremaining: 3.32s\n",
      "786:\tlearn: 1.7189381\ttotal: 12.2s\tremaining: 3.31s\n",
      "787:\tlearn: 1.7189259\ttotal: 12.2s\tremaining: 3.29s\n",
      "788:\tlearn: 1.7183368\ttotal: 12.3s\tremaining: 3.28s\n",
      "789:\tlearn: 1.7179197\ttotal: 12.3s\tremaining: 3.26s\n",
      "790:\tlearn: 1.7177393\ttotal: 12.3s\tremaining: 3.25s\n",
      "791:\tlearn: 1.7169027\ttotal: 12.3s\tremaining: 3.23s\n",
      "792:\tlearn: 1.7169025\ttotal: 12.3s\tremaining: 3.21s\n",
      "793:\tlearn: 1.7169025\ttotal: 12.3s\tremaining: 3.2s\n",
      "794:\tlearn: 1.7169025\ttotal: 12.3s\tremaining: 3.18s\n",
      "795:\tlearn: 1.7168869\ttotal: 12.4s\tremaining: 3.17s\n",
      "796:\tlearn: 1.7168865\ttotal: 12.4s\tremaining: 3.15s\n",
      "797:\tlearn: 1.7168718\ttotal: 12.4s\tremaining: 3.13s\n",
      "798:\tlearn: 1.7168070\ttotal: 12.4s\tremaining: 3.12s\n",
      "799:\tlearn: 1.7163368\ttotal: 12.4s\tremaining: 3.1s\n",
      "800:\tlearn: 1.7159492\ttotal: 12.4s\tremaining: 3.09s\n",
      "801:\tlearn: 1.7159414\ttotal: 12.4s\tremaining: 3.07s\n",
      "802:\tlearn: 1.7159414\ttotal: 12.5s\tremaining: 3.06s\n",
      "803:\tlearn: 1.7159403\ttotal: 12.5s\tremaining: 3.04s\n",
      "804:\tlearn: 1.7159403\ttotal: 12.5s\tremaining: 3.03s\n",
      "805:\tlearn: 1.7159385\ttotal: 12.5s\tremaining: 3.01s\n",
      "806:\tlearn: 1.7158688\ttotal: 12.5s\tremaining: 3s\n",
      "807:\tlearn: 1.7150822\ttotal: 12.5s\tremaining: 2.98s\n",
      "808:\tlearn: 1.7147902\ttotal: 12.6s\tremaining: 2.96s\n",
      "809:\tlearn: 1.7147901\ttotal: 12.6s\tremaining: 2.95s\n",
      "810:\tlearn: 1.7147898\ttotal: 12.6s\tremaining: 2.93s\n",
      "811:\tlearn: 1.7147897\ttotal: 12.6s\tremaining: 2.92s\n",
      "812:\tlearn: 1.7147740\ttotal: 12.6s\tremaining: 2.9s\n",
      "813:\tlearn: 1.7147696\ttotal: 12.6s\tremaining: 2.88s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814:\tlearn: 1.7147097\ttotal: 12.6s\tremaining: 2.87s\n",
      "815:\tlearn: 1.7147064\ttotal: 12.7s\tremaining: 2.85s\n",
      "816:\tlearn: 1.7146727\ttotal: 12.7s\tremaining: 2.84s\n",
      "817:\tlearn: 1.7146725\ttotal: 12.7s\tremaining: 2.82s\n",
      "818:\tlearn: 1.7146606\ttotal: 12.7s\tremaining: 2.81s\n",
      "819:\tlearn: 1.7146367\ttotal: 12.7s\tremaining: 2.79s\n",
      "820:\tlearn: 1.7142682\ttotal: 12.7s\tremaining: 2.78s\n",
      "821:\tlearn: 1.7141721\ttotal: 12.7s\tremaining: 2.76s\n",
      "822:\tlearn: 1.7141570\ttotal: 12.8s\tremaining: 2.75s\n",
      "823:\tlearn: 1.7141565\ttotal: 12.8s\tremaining: 2.73s\n",
      "824:\tlearn: 1.7141564\ttotal: 12.8s\tremaining: 2.71s\n",
      "825:\tlearn: 1.7140566\ttotal: 12.8s\tremaining: 2.7s\n",
      "826:\tlearn: 1.7137803\ttotal: 12.8s\tremaining: 2.68s\n",
      "827:\tlearn: 1.7137543\ttotal: 12.8s\tremaining: 2.67s\n",
      "828:\tlearn: 1.7136933\ttotal: 12.9s\tremaining: 2.65s\n",
      "829:\tlearn: 1.7136705\ttotal: 12.9s\tremaining: 2.64s\n",
      "830:\tlearn: 1.7136703\ttotal: 12.9s\tremaining: 2.62s\n",
      "831:\tlearn: 1.7136703\ttotal: 12.9s\tremaining: 2.6s\n",
      "832:\tlearn: 1.7136673\ttotal: 12.9s\tremaining: 2.59s\n",
      "833:\tlearn: 1.7136673\ttotal: 12.9s\tremaining: 2.57s\n",
      "834:\tlearn: 1.7136662\ttotal: 12.9s\tremaining: 2.56s\n",
      "835:\tlearn: 1.7136661\ttotal: 13s\tremaining: 2.54s\n",
      "836:\tlearn: 1.7136661\ttotal: 13s\tremaining: 2.53s\n",
      "837:\tlearn: 1.7136621\ttotal: 13s\tremaining: 2.51s\n",
      "838:\tlearn: 1.7136621\ttotal: 13s\tremaining: 2.5s\n",
      "839:\tlearn: 1.7136540\ttotal: 13s\tremaining: 2.48s\n",
      "840:\tlearn: 1.7136379\ttotal: 13s\tremaining: 2.46s\n",
      "841:\tlearn: 1.7136379\ttotal: 13s\tremaining: 2.45s\n",
      "842:\tlearn: 1.7136379\ttotal: 13.1s\tremaining: 2.43s\n",
      "843:\tlearn: 1.7136365\ttotal: 13.1s\tremaining: 2.42s\n",
      "844:\tlearn: 1.7136364\ttotal: 13.1s\tremaining: 2.4s\n",
      "845:\tlearn: 1.7136249\ttotal: 13.1s\tremaining: 2.39s\n",
      "846:\tlearn: 1.7136240\ttotal: 13.1s\tremaining: 2.37s\n",
      "847:\tlearn: 1.7136239\ttotal: 13.1s\tremaining: 2.35s\n",
      "848:\tlearn: 1.7136067\ttotal: 13.2s\tremaining: 2.34s\n",
      "849:\tlearn: 1.7136067\ttotal: 13.2s\tremaining: 2.32s\n",
      "850:\tlearn: 1.7136067\ttotal: 13.2s\tremaining: 2.31s\n",
      "851:\tlearn: 1.7136067\ttotal: 13.2s\tremaining: 2.29s\n",
      "852:\tlearn: 1.7121789\ttotal: 13.2s\tremaining: 2.28s\n",
      "853:\tlearn: 1.7115736\ttotal: 13.2s\tremaining: 2.26s\n",
      "854:\tlearn: 1.7115529\ttotal: 13.2s\tremaining: 2.25s\n",
      "855:\tlearn: 1.7115527\ttotal: 13.3s\tremaining: 2.23s\n",
      "856:\tlearn: 1.7115527\ttotal: 13.3s\tremaining: 2.21s\n",
      "857:\tlearn: 1.7115527\ttotal: 13.3s\tremaining: 2.2s\n",
      "858:\tlearn: 1.7115527\ttotal: 13.3s\tremaining: 2.18s\n",
      "859:\tlearn: 1.7115519\ttotal: 13.3s\tremaining: 2.17s\n",
      "860:\tlearn: 1.7115506\ttotal: 13.3s\tremaining: 2.15s\n",
      "861:\tlearn: 1.7115502\ttotal: 13.4s\tremaining: 2.14s\n",
      "862:\tlearn: 1.7115500\ttotal: 13.4s\tremaining: 2.12s\n",
      "863:\tlearn: 1.7115500\ttotal: 13.4s\tremaining: 2.11s\n",
      "864:\tlearn: 1.7115500\ttotal: 13.4s\tremaining: 2.09s\n",
      "865:\tlearn: 1.7110812\ttotal: 13.4s\tremaining: 2.07s\n",
      "866:\tlearn: 1.7110524\ttotal: 13.4s\tremaining: 2.06s\n",
      "867:\tlearn: 1.7106690\ttotal: 13.4s\tremaining: 2.04s\n",
      "868:\tlearn: 1.7106505\ttotal: 13.5s\tremaining: 2.03s\n",
      "869:\tlearn: 1.7105965\ttotal: 13.5s\tremaining: 2.01s\n",
      "870:\tlearn: 1.7105871\ttotal: 13.5s\tremaining: 2s\n",
      "871:\tlearn: 1.7105871\ttotal: 13.5s\tremaining: 1.98s\n",
      "872:\tlearn: 1.7105597\ttotal: 13.5s\tremaining: 1.97s\n",
      "873:\tlearn: 1.7102593\ttotal: 13.5s\tremaining: 1.95s\n",
      "874:\tlearn: 1.7102322\ttotal: 13.5s\tremaining: 1.93s\n",
      "875:\tlearn: 1.7102220\ttotal: 13.6s\tremaining: 1.92s\n",
      "876:\tlearn: 1.7102220\ttotal: 13.6s\tremaining: 1.9s\n",
      "877:\tlearn: 1.7102219\ttotal: 13.6s\tremaining: 1.89s\n",
      "878:\tlearn: 1.7102214\ttotal: 13.6s\tremaining: 1.87s\n",
      "879:\tlearn: 1.7102207\ttotal: 13.6s\tremaining: 1.86s\n",
      "880:\tlearn: 1.7102207\ttotal: 13.6s\tremaining: 1.84s\n",
      "881:\tlearn: 1.7102206\ttotal: 13.6s\tremaining: 1.82s\n",
      "882:\tlearn: 1.7102206\ttotal: 13.7s\tremaining: 1.81s\n",
      "883:\tlearn: 1.7100929\ttotal: 13.7s\tremaining: 1.79s\n",
      "884:\tlearn: 1.7100262\ttotal: 13.7s\tremaining: 1.78s\n",
      "885:\tlearn: 1.7100240\ttotal: 13.7s\tremaining: 1.76s\n",
      "886:\tlearn: 1.7100109\ttotal: 13.7s\tremaining: 1.75s\n",
      "887:\tlearn: 1.7100108\ttotal: 13.7s\tremaining: 1.73s\n",
      "888:\tlearn: 1.7099986\ttotal: 13.7s\tremaining: 1.72s\n",
      "889:\tlearn: 1.7098744\ttotal: 13.8s\tremaining: 1.7s\n",
      "890:\tlearn: 1.7098504\ttotal: 13.8s\tremaining: 1.69s\n",
      "891:\tlearn: 1.7090856\ttotal: 13.8s\tremaining: 1.67s\n",
      "892:\tlearn: 1.7089761\ttotal: 13.8s\tremaining: 1.65s\n",
      "893:\tlearn: 1.7089419\ttotal: 13.8s\tremaining: 1.64s\n",
      "894:\tlearn: 1.7086559\ttotal: 13.8s\tremaining: 1.62s\n",
      "895:\tlearn: 1.7085835\ttotal: 13.8s\tremaining: 1.61s\n",
      "896:\tlearn: 1.7084305\ttotal: 13.9s\tremaining: 1.59s\n",
      "897:\tlearn: 1.7082241\ttotal: 13.9s\tremaining: 1.58s\n",
      "898:\tlearn: 1.7081738\ttotal: 13.9s\tremaining: 1.56s\n",
      "899:\tlearn: 1.7081392\ttotal: 13.9s\tremaining: 1.54s\n",
      "900:\tlearn: 1.7081177\ttotal: 13.9s\tremaining: 1.53s\n",
      "901:\tlearn: 1.7080764\ttotal: 13.9s\tremaining: 1.51s\n",
      "902:\tlearn: 1.7080323\ttotal: 14s\tremaining: 1.5s\n",
      "903:\tlearn: 1.7080036\ttotal: 14s\tremaining: 1.48s\n",
      "904:\tlearn: 1.7079944\ttotal: 14s\tremaining: 1.47s\n",
      "905:\tlearn: 1.7079939\ttotal: 14s\tremaining: 1.45s\n",
      "906:\tlearn: 1.7079904\ttotal: 14s\tremaining: 1.44s\n",
      "907:\tlearn: 1.7079843\ttotal: 14s\tremaining: 1.42s\n",
      "908:\tlearn: 1.7079251\ttotal: 14s\tremaining: 1.41s\n",
      "909:\tlearn: 1.7077511\ttotal: 14.1s\tremaining: 1.39s\n",
      "910:\tlearn: 1.7074548\ttotal: 14.1s\tremaining: 1.37s\n",
      "911:\tlearn: 1.7074536\ttotal: 14.1s\tremaining: 1.36s\n",
      "912:\tlearn: 1.7074235\ttotal: 14.1s\tremaining: 1.34s\n",
      "913:\tlearn: 1.7071550\ttotal: 14.1s\tremaining: 1.33s\n",
      "914:\tlearn: 1.7071473\ttotal: 14.1s\tremaining: 1.31s\n",
      "915:\tlearn: 1.7071425\ttotal: 14.1s\tremaining: 1.3s\n",
      "916:\tlearn: 1.7068653\ttotal: 14.2s\tremaining: 1.28s\n",
      "917:\tlearn: 1.7064951\ttotal: 14.2s\tremaining: 1.27s\n",
      "918:\tlearn: 1.7064818\ttotal: 14.2s\tremaining: 1.25s\n",
      "919:\tlearn: 1.7064604\ttotal: 14.2s\tremaining: 1.24s\n",
      "920:\tlearn: 1.7064472\ttotal: 14.2s\tremaining: 1.22s\n",
      "921:\tlearn: 1.7064455\ttotal: 14.2s\tremaining: 1.2s\n",
      "922:\tlearn: 1.7064005\ttotal: 14.3s\tremaining: 1.19s\n",
      "923:\tlearn: 1.7063896\ttotal: 14.3s\tremaining: 1.17s\n",
      "924:\tlearn: 1.7058838\ttotal: 14.3s\tremaining: 1.16s\n",
      "925:\tlearn: 1.7058601\ttotal: 14.3s\tremaining: 1.14s\n",
      "926:\tlearn: 1.7048198\ttotal: 14.3s\tremaining: 1.13s\n",
      "927:\tlearn: 1.7045481\ttotal: 14.3s\tremaining: 1.11s\n",
      "928:\tlearn: 1.7044466\ttotal: 14.3s\tremaining: 1.09s\n",
      "929:\tlearn: 1.7044453\ttotal: 14.4s\tremaining: 1.08s\n",
      "930:\tlearn: 1.7044452\ttotal: 14.4s\tremaining: 1.06s\n",
      "931:\tlearn: 1.7044362\ttotal: 14.4s\tremaining: 1.05s\n",
      "932:\tlearn: 1.7043916\ttotal: 14.4s\tremaining: 1.03s\n",
      "933:\tlearn: 1.7043873\ttotal: 14.4s\tremaining: 1.02s\n",
      "934:\tlearn: 1.7043873\ttotal: 14.4s\tremaining: 1s\n",
      "935:\tlearn: 1.7043872\ttotal: 14.4s\tremaining: 988ms\n",
      "936:\tlearn: 1.7043869\ttotal: 14.5s\tremaining: 973ms\n",
      "937:\tlearn: 1.7043816\ttotal: 14.5s\tremaining: 957ms\n",
      "938:\tlearn: 1.7042279\ttotal: 14.5s\tremaining: 942ms\n",
      "939:\tlearn: 1.7042098\ttotal: 14.5s\tremaining: 926ms\n",
      "940:\tlearn: 1.7041801\ttotal: 14.5s\tremaining: 911ms\n",
      "941:\tlearn: 1.7041514\ttotal: 14.5s\tremaining: 895ms\n",
      "942:\tlearn: 1.7041493\ttotal: 14.6s\tremaining: 880ms\n",
      "943:\tlearn: 1.7041491\ttotal: 14.6s\tremaining: 864ms\n",
      "944:\tlearn: 1.7040723\ttotal: 14.6s\tremaining: 849ms\n",
      "945:\tlearn: 1.7040629\ttotal: 14.6s\tremaining: 833ms\n",
      "946:\tlearn: 1.7038990\ttotal: 14.6s\tremaining: 818ms\n",
      "947:\tlearn: 1.7038681\ttotal: 14.6s\tremaining: 802ms\n",
      "948:\tlearn: 1.7038473\ttotal: 14.6s\tremaining: 787ms\n",
      "949:\tlearn: 1.7036391\ttotal: 14.7s\tremaining: 772ms\n",
      "950:\tlearn: 1.7036317\ttotal: 14.7s\tremaining: 757ms\n",
      "951:\tlearn: 1.7035953\ttotal: 14.7s\tremaining: 741ms\n",
      "952:\tlearn: 1.7035841\ttotal: 14.7s\tremaining: 726ms\n",
      "953:\tlearn: 1.7035792\ttotal: 14.7s\tremaining: 710ms\n",
      "954:\tlearn: 1.7033889\ttotal: 14.7s\tremaining: 695ms\n",
      "955:\tlearn: 1.7032461\ttotal: 14.8s\tremaining: 679ms\n",
      "956:\tlearn: 1.7032171\ttotal: 14.8s\tremaining: 664ms\n",
      "957:\tlearn: 1.7031892\ttotal: 14.8s\tremaining: 648ms\n",
      "958:\tlearn: 1.7031727\ttotal: 14.8s\tremaining: 633ms\n",
      "959:\tlearn: 1.7031264\ttotal: 14.8s\tremaining: 618ms\n",
      "960:\tlearn: 1.7031119\ttotal: 14.8s\tremaining: 602ms\n",
      "961:\tlearn: 1.7031119\ttotal: 14.9s\tremaining: 587ms\n",
      "962:\tlearn: 1.7031112\ttotal: 14.9s\tremaining: 571ms\n",
      "963:\tlearn: 1.7030886\ttotal: 14.9s\tremaining: 556ms\n",
      "964:\tlearn: 1.7030847\ttotal: 14.9s\tremaining: 540ms\n",
      "965:\tlearn: 1.7030829\ttotal: 14.9s\tremaining: 525ms\n",
      "966:\tlearn: 1.7030829\ttotal: 14.9s\tremaining: 509ms\n",
      "967:\tlearn: 1.7030829\ttotal: 14.9s\tremaining: 494ms\n",
      "968:\tlearn: 1.7030817\ttotal: 15s\tremaining: 479ms\n",
      "969:\tlearn: 1.7030817\ttotal: 15s\tremaining: 463ms\n",
      "970:\tlearn: 1.7030817\ttotal: 15s\tremaining: 448ms\n",
      "971:\tlearn: 1.7030817\ttotal: 15s\tremaining: 432ms\n",
      "972:\tlearn: 1.7030817\ttotal: 15s\tremaining: 417ms\n",
      "973:\tlearn: 1.7030817\ttotal: 15s\tremaining: 401ms\n",
      "974:\tlearn: 1.7030740\ttotal: 15.1s\tremaining: 386ms\n",
      "975:\tlearn: 1.7029180\ttotal: 15.1s\tremaining: 370ms\n",
      "976:\tlearn: 1.7029104\ttotal: 15.1s\tremaining: 355ms\n",
      "977:\tlearn: 1.7028819\ttotal: 15.1s\tremaining: 340ms\n",
      "978:\tlearn: 1.7028817\ttotal: 15.1s\tremaining: 324ms\n",
      "979:\tlearn: 1.7028469\ttotal: 15.1s\tremaining: 309ms\n",
      "980:\tlearn: 1.7028469\ttotal: 15.1s\tremaining: 293ms\n",
      "981:\tlearn: 1.7028462\ttotal: 15.2s\tremaining: 278ms\n",
      "982:\tlearn: 1.7028310\ttotal: 15.2s\tremaining: 262ms\n",
      "983:\tlearn: 1.7028127\ttotal: 15.2s\tremaining: 247ms\n",
      "984:\tlearn: 1.7028113\ttotal: 15.2s\tremaining: 231ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "985:\tlearn: 1.7027115\ttotal: 15.2s\tremaining: 216ms\n",
      "986:\tlearn: 1.7020938\ttotal: 15.2s\tremaining: 201ms\n",
      "987:\tlearn: 1.7017415\ttotal: 15.2s\tremaining: 185ms\n",
      "988:\tlearn: 1.7017369\ttotal: 15.3s\tremaining: 170ms\n",
      "989:\tlearn: 1.7017311\ttotal: 15.3s\tremaining: 154ms\n",
      "990:\tlearn: 1.7017280\ttotal: 15.3s\tremaining: 139ms\n",
      "991:\tlearn: 1.7004403\ttotal: 15.3s\tremaining: 123ms\n",
      "992:\tlearn: 1.7004376\ttotal: 15.3s\tremaining: 108ms\n",
      "993:\tlearn: 1.6997987\ttotal: 15.3s\tremaining: 92.5ms\n",
      "994:\tlearn: 1.6997655\ttotal: 15.3s\tremaining: 77.1ms\n",
      "995:\tlearn: 1.6997203\ttotal: 15.4s\tremaining: 61.7ms\n",
      "996:\tlearn: 1.6997203\ttotal: 15.4s\tremaining: 46.3ms\n",
      "997:\tlearn: 1.6997202\ttotal: 15.4s\tremaining: 30.8ms\n",
      "998:\tlearn: 1.6997202\ttotal: 15.4s\tremaining: 15.4ms\n",
      "999:\tlearn: 1.6996980\ttotal: 15.4s\tremaining: 0us\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 337\n",
      "[LightGBM] [Info] Number of data points in the train set: 63374, number of used features: 54\n",
      "[LightGBM] [Info] Start training from score 8.848466\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 63374, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 8.409162\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 346\n",
      "[LightGBM] [Info] Number of data points in the train set: 63374, number of used features: 54\n",
      "[LightGBM] [Info] Start training from score 10.510467\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 329\n",
      "[LightGBM] [Info] Number of data points in the train set: 63375, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 10.969636\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001793 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 321\n",
      "[LightGBM] [Info] Number of data points in the train set: 63375, number of used features: 45\n",
      "[LightGBM] [Info] Start training from score 10.882431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0:\tlearn: 8.1763373\ttotal: 16.9ms\tremaining: 16.9s\n",
      "1:\tlearn: 7.5836425\ttotal: 34ms\tremaining: 17s\n",
      "2:\tlearn: 7.0461478\ttotal: 52.2ms\tremaining: 17.3s\n",
      "3:\tlearn: 6.5649757\ttotal: 71.8ms\tremaining: 17.9s\n",
      "4:\tlearn: 6.0332550\ttotal: 89.1ms\tremaining: 17.7s\n",
      "5:\tlearn: 5.6687886\ttotal: 106ms\tremaining: 17.6s\n",
      "6:\tlearn: 5.2329079\ttotal: 124ms\tremaining: 17.6s\n",
      "7:\tlearn: 4.8376908\ttotal: 141ms\tremaining: 17.4s\n",
      "8:\tlearn: 4.4638830\ttotal: 157ms\tremaining: 17.3s\n",
      "9:\tlearn: 4.1391092\ttotal: 175ms\tremaining: 17.4s\n",
      "10:\tlearn: 3.8550104\ttotal: 193ms\tremaining: 17.3s\n",
      "11:\tlearn: 3.6660284\ttotal: 210ms\tremaining: 17.3s\n",
      "12:\tlearn: 3.4243658\ttotal: 226ms\tremaining: 17.1s\n",
      "13:\tlearn: 3.2266809\ttotal: 243ms\tremaining: 17.1s\n",
      "14:\tlearn: 3.0466553\ttotal: 262ms\tremaining: 17.2s\n",
      "15:\tlearn: 2.9363339\ttotal: 279ms\tremaining: 17.1s\n",
      "16:\tlearn: 2.8463279\ttotal: 295ms\tremaining: 17s\n",
      "17:\tlearn: 2.7227787\ttotal: 312ms\tremaining: 17s\n",
      "18:\tlearn: 2.6508875\ttotal: 327ms\tremaining: 16.9s\n",
      "19:\tlearn: 2.5392880\ttotal: 343ms\tremaining: 16.8s\n",
      "20:\tlearn: 2.4889679\ttotal: 359ms\tremaining: 16.8s\n",
      "21:\tlearn: 2.4422827\ttotal: 376ms\tremaining: 16.7s\n",
      "22:\tlearn: 2.4000894\ttotal: 393ms\tremaining: 16.7s\n",
      "23:\tlearn: 2.3319366\ttotal: 410ms\tremaining: 16.7s\n",
      "24:\tlearn: 2.2711496\ttotal: 426ms\tremaining: 16.6s\n",
      "25:\tlearn: 2.2164356\ttotal: 443ms\tremaining: 16.6s\n",
      "26:\tlearn: 2.1930910\ttotal: 459ms\tremaining: 16.5s\n",
      "27:\tlearn: 2.1665237\ttotal: 477ms\tremaining: 16.5s\n",
      "28:\tlearn: 2.1475267\ttotal: 495ms\tremaining: 16.6s\n",
      "29:\tlearn: 2.1130382\ttotal: 512ms\tremaining: 16.6s\n",
      "30:\tlearn: 2.0712086\ttotal: 529ms\tremaining: 16.5s\n",
      "31:\tlearn: 2.0572371\ttotal: 544ms\tremaining: 16.5s\n",
      "32:\tlearn: 2.0264774\ttotal: 560ms\tremaining: 16.4s\n",
      "33:\tlearn: 1.9984197\ttotal: 576ms\tremaining: 16.4s\n",
      "34:\tlearn: 1.9878476\ttotal: 592ms\tremaining: 16.3s\n",
      "35:\tlearn: 1.9791812\ttotal: 609ms\tremaining: 16.3s\n",
      "36:\tlearn: 1.9635189\ttotal: 624ms\tremaining: 16.2s\n",
      "37:\tlearn: 1.9517677\ttotal: 639ms\tremaining: 16.2s\n",
      "38:\tlearn: 1.9421914\ttotal: 654ms\tremaining: 16.1s\n",
      "39:\tlearn: 1.9405267\ttotal: 670ms\tremaining: 16.1s\n",
      "40:\tlearn: 1.9322093\ttotal: 686ms\tremaining: 16.1s\n",
      "41:\tlearn: 1.9194211\ttotal: 704ms\tremaining: 16s\n",
      "42:\tlearn: 1.9136387\ttotal: 719ms\tremaining: 16s\n",
      "43:\tlearn: 1.9101871\ttotal: 736ms\tremaining: 16s\n",
      "44:\tlearn: 1.9079664\ttotal: 751ms\tremaining: 15.9s\n",
      "45:\tlearn: 1.9051864\ttotal: 766ms\tremaining: 15.9s\n",
      "46:\tlearn: 1.8986454\ttotal: 782ms\tremaining: 15.9s\n",
      "47:\tlearn: 1.8948776\ttotal: 798ms\tremaining: 15.8s\n",
      "48:\tlearn: 1.8910938\ttotal: 813ms\tremaining: 15.8s\n",
      "49:\tlearn: 1.8888906\ttotal: 829ms\tremaining: 15.7s\n",
      "50:\tlearn: 1.8871133\ttotal: 844ms\tremaining: 15.7s\n",
      "51:\tlearn: 1.8846107\ttotal: 860ms\tremaining: 15.7s\n",
      "52:\tlearn: 1.8817426\ttotal: 874ms\tremaining: 15.6s\n",
      "53:\tlearn: 1.8804745\ttotal: 890ms\tremaining: 15.6s\n",
      "54:\tlearn: 1.8729157\ttotal: 906ms\tremaining: 15.6s\n",
      "55:\tlearn: 1.8613128\ttotal: 922ms\tremaining: 15.5s\n",
      "56:\tlearn: 1.8580366\ttotal: 938ms\tremaining: 15.5s\n",
      "57:\tlearn: 1.8572932\ttotal: 953ms\tremaining: 15.5s\n",
      "58:\tlearn: 1.8570772\ttotal: 968ms\tremaining: 15.4s\n",
      "59:\tlearn: 1.8559343\ttotal: 983ms\tremaining: 15.4s\n",
      "60:\tlearn: 1.8557464\ttotal: 998ms\tremaining: 15.4s\n",
      "61:\tlearn: 1.8550094\ttotal: 1.01s\tremaining: 15.3s\n",
      "62:\tlearn: 1.8453168\ttotal: 1.03s\tremaining: 15.3s\n",
      "63:\tlearn: 1.8436991\ttotal: 1.04s\tremaining: 15.2s\n",
      "64:\tlearn: 1.8432293\ttotal: 1.06s\tremaining: 15.2s\n",
      "65:\tlearn: 1.8424969\ttotal: 1.07s\tremaining: 15.2s\n",
      "66:\tlearn: 1.8418318\ttotal: 1.08s\tremaining: 15.1s\n",
      "67:\tlearn: 1.8389614\ttotal: 1.1s\tremaining: 15s\n",
      "68:\tlearn: 1.8383194\ttotal: 1.11s\tremaining: 15s\n",
      "69:\tlearn: 1.8369019\ttotal: 1.13s\tremaining: 15s\n",
      "70:\tlearn: 1.8365826\ttotal: 1.14s\tremaining: 14.9s\n",
      "71:\tlearn: 1.8364750\ttotal: 1.15s\tremaining: 14.9s\n",
      "72:\tlearn: 1.8358158\ttotal: 1.17s\tremaining: 14.8s\n",
      "73:\tlearn: 1.8353055\ttotal: 1.18s\tremaining: 14.8s\n",
      "74:\tlearn: 1.8348008\ttotal: 1.19s\tremaining: 14.7s\n",
      "75:\tlearn: 1.8333896\ttotal: 1.21s\tremaining: 14.7s\n",
      "76:\tlearn: 1.8322245\ttotal: 1.22s\tremaining: 14.7s\n",
      "77:\tlearn: 1.8319302\ttotal: 1.24s\tremaining: 14.6s\n",
      "78:\tlearn: 1.8310917\ttotal: 1.25s\tremaining: 14.6s\n",
      "79:\tlearn: 1.8303461\ttotal: 1.26s\tremaining: 14.5s\n",
      "80:\tlearn: 1.8277953\ttotal: 1.28s\tremaining: 14.5s\n",
      "81:\tlearn: 1.8268455\ttotal: 1.29s\tremaining: 14.5s\n",
      "82:\tlearn: 1.8263264\ttotal: 1.31s\tremaining: 14.4s\n",
      "83:\tlearn: 1.8260386\ttotal: 1.32s\tremaining: 14.4s\n",
      "84:\tlearn: 1.8213846\ttotal: 1.33s\tremaining: 14.4s\n",
      "85:\tlearn: 1.8211084\ttotal: 1.35s\tremaining: 14.4s\n",
      "86:\tlearn: 1.8208848\ttotal: 1.36s\tremaining: 14.3s\n",
      "87:\tlearn: 1.8198992\ttotal: 1.38s\tremaining: 14.3s\n",
      "88:\tlearn: 1.8188455\ttotal: 1.39s\tremaining: 14.3s\n",
      "89:\tlearn: 1.8175407\ttotal: 1.41s\tremaining: 14.2s\n",
      "90:\tlearn: 1.8173503\ttotal: 1.42s\tremaining: 14.2s\n",
      "91:\tlearn: 1.8167180\ttotal: 1.44s\tremaining: 14.2s\n",
      "92:\tlearn: 1.8167146\ttotal: 1.45s\tremaining: 14.1s\n",
      "93:\tlearn: 1.8159614\ttotal: 1.46s\tremaining: 14.1s\n",
      "94:\tlearn: 1.8156456\ttotal: 1.47s\tremaining: 14s\n",
      "95:\tlearn: 1.8156305\ttotal: 1.49s\tremaining: 14s\n",
      "96:\tlearn: 1.8144875\ttotal: 1.5s\tremaining: 14s\n",
      "97:\tlearn: 1.8138491\ttotal: 1.51s\tremaining: 13.9s\n",
      "98:\tlearn: 1.8079010\ttotal: 1.53s\tremaining: 13.9s\n",
      "99:\tlearn: 1.8077337\ttotal: 1.54s\tremaining: 13.9s\n",
      "100:\tlearn: 1.8072877\ttotal: 1.55s\tremaining: 13.8s\n",
      "101:\tlearn: 1.8056487\ttotal: 1.57s\tremaining: 13.8s\n",
      "102:\tlearn: 1.8031277\ttotal: 1.58s\tremaining: 13.8s\n",
      "103:\tlearn: 1.7951203\ttotal: 1.6s\tremaining: 13.8s\n",
      "104:\tlearn: 1.7945629\ttotal: 1.61s\tremaining: 13.7s\n",
      "105:\tlearn: 1.7937082\ttotal: 1.63s\tremaining: 13.7s\n",
      "106:\tlearn: 1.7936835\ttotal: 1.64s\tremaining: 13.7s\n",
      "107:\tlearn: 1.7934366\ttotal: 1.65s\tremaining: 13.7s\n",
      "108:\tlearn: 1.7913378\ttotal: 1.67s\tremaining: 13.6s\n",
      "109:\tlearn: 1.7911889\ttotal: 1.68s\tremaining: 13.6s\n",
      "110:\tlearn: 1.7854528\ttotal: 1.69s\tremaining: 13.6s\n",
      "111:\tlearn: 1.7850924\ttotal: 1.71s\tremaining: 13.5s\n",
      "112:\tlearn: 1.7845209\ttotal: 1.72s\tremaining: 13.5s\n",
      "113:\tlearn: 1.7844059\ttotal: 1.74s\tremaining: 13.5s\n",
      "114:\tlearn: 1.7839212\ttotal: 1.75s\tremaining: 13.5s\n",
      "115:\tlearn: 1.7836821\ttotal: 1.76s\tremaining: 13.4s\n",
      "116:\tlearn: 1.7827405\ttotal: 1.78s\tremaining: 13.4s\n",
      "117:\tlearn: 1.7795088\ttotal: 1.79s\tremaining: 13.4s\n",
      "118:\tlearn: 1.7793252\ttotal: 1.81s\tremaining: 13.4s\n",
      "119:\tlearn: 1.7750614\ttotal: 1.82s\tremaining: 13.4s\n",
      "120:\tlearn: 1.7709862\ttotal: 1.83s\tremaining: 13.3s\n",
      "121:\tlearn: 1.7687356\ttotal: 1.85s\tremaining: 13.3s\n",
      "122:\tlearn: 1.7684121\ttotal: 1.86s\tremaining: 13.3s\n",
      "123:\tlearn: 1.7675211\ttotal: 1.88s\tremaining: 13.3s\n",
      "124:\tlearn: 1.7671757\ttotal: 1.89s\tremaining: 13.2s\n",
      "125:\tlearn: 1.7670719\ttotal: 1.9s\tremaining: 13.2s\n",
      "126:\tlearn: 1.7623185\ttotal: 1.92s\tremaining: 13.2s\n",
      "127:\tlearn: 1.7605378\ttotal: 1.93s\tremaining: 13.2s\n",
      "128:\tlearn: 1.7591164\ttotal: 1.94s\tremaining: 13.1s\n",
      "129:\tlearn: 1.7528406\ttotal: 1.96s\tremaining: 13.1s\n",
      "130:\tlearn: 1.7450706\ttotal: 1.98s\tremaining: 13.1s\n",
      "131:\tlearn: 1.7385758\ttotal: 1.99s\tremaining: 13.1s\n",
      "132:\tlearn: 1.7352597\ttotal: 2s\tremaining: 13.1s\n",
      "133:\tlearn: 1.7308696\ttotal: 2.02s\tremaining: 13.1s\n",
      "134:\tlearn: 1.7293376\ttotal: 2.03s\tremaining: 13s\n",
      "135:\tlearn: 1.7250837\ttotal: 2.05s\tremaining: 13s\n",
      "136:\tlearn: 1.7240466\ttotal: 2.06s\tremaining: 13s\n",
      "137:\tlearn: 1.7230000\ttotal: 2.08s\tremaining: 13s\n",
      "138:\tlearn: 1.7211632\ttotal: 2.09s\tremaining: 12.9s\n",
      "139:\tlearn: 1.7184667\ttotal: 2.1s\tremaining: 12.9s\n",
      "140:\tlearn: 1.7178159\ttotal: 2.12s\tremaining: 12.9s\n",
      "141:\tlearn: 1.7134568\ttotal: 2.13s\tremaining: 12.9s\n",
      "142:\tlearn: 1.7126048\ttotal: 2.14s\tremaining: 12.9s\n",
      "143:\tlearn: 1.7115020\ttotal: 2.16s\tremaining: 12.8s\n",
      "144:\tlearn: 1.7079821\ttotal: 2.17s\tremaining: 12.8s\n",
      "145:\tlearn: 1.7068888\ttotal: 2.19s\tremaining: 12.8s\n",
      "146:\tlearn: 1.7034214\ttotal: 2.2s\tremaining: 12.8s\n",
      "147:\tlearn: 1.7018542\ttotal: 2.22s\tremaining: 12.8s\n",
      "148:\tlearn: 1.7007268\ttotal: 2.23s\tremaining: 12.7s\n",
      "149:\tlearn: 1.6987356\ttotal: 2.24s\tremaining: 12.7s\n",
      "150:\tlearn: 1.6974425\ttotal: 2.26s\tremaining: 12.7s\n",
      "151:\tlearn: 1.6952371\ttotal: 2.27s\tremaining: 12.7s\n",
      "152:\tlearn: 1.6938276\ttotal: 2.29s\tremaining: 12.7s\n",
      "153:\tlearn: 1.6914177\ttotal: 2.3s\tremaining: 12.6s\n",
      "154:\tlearn: 1.6892812\ttotal: 2.31s\tremaining: 12.6s\n",
      "155:\tlearn: 1.6868363\ttotal: 2.33s\tremaining: 12.6s\n",
      "156:\tlearn: 1.6853062\ttotal: 2.34s\tremaining: 12.6s\n",
      "157:\tlearn: 1.6824092\ttotal: 2.35s\tremaining: 12.6s\n",
      "158:\tlearn: 1.6809796\ttotal: 2.37s\tremaining: 12.5s\n",
      "159:\tlearn: 1.6791178\ttotal: 2.38s\tremaining: 12.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160:\tlearn: 1.6760844\ttotal: 2.4s\tremaining: 12.5s\n",
      "161:\tlearn: 1.6731492\ttotal: 2.41s\tremaining: 12.5s\n",
      "162:\tlearn: 1.6711923\ttotal: 2.43s\tremaining: 12.5s\n",
      "163:\tlearn: 1.6696355\ttotal: 2.44s\tremaining: 12.5s\n",
      "164:\tlearn: 1.6688697\ttotal: 2.46s\tremaining: 12.4s\n",
      "165:\tlearn: 1.6659371\ttotal: 2.47s\tremaining: 12.4s\n",
      "166:\tlearn: 1.6637987\ttotal: 2.48s\tremaining: 12.4s\n",
      "167:\tlearn: 1.6625144\ttotal: 2.5s\tremaining: 12.4s\n",
      "168:\tlearn: 1.6603173\ttotal: 2.51s\tremaining: 12.4s\n",
      "169:\tlearn: 1.6584921\ttotal: 2.53s\tremaining: 12.3s\n",
      "170:\tlearn: 1.6562649\ttotal: 2.54s\tremaining: 12.3s\n",
      "171:\tlearn: 1.6529374\ttotal: 2.55s\tremaining: 12.3s\n",
      "172:\tlearn: 1.6503792\ttotal: 2.57s\tremaining: 12.3s\n",
      "173:\tlearn: 1.6478162\ttotal: 2.58s\tremaining: 12.3s\n",
      "174:\tlearn: 1.6449929\ttotal: 2.6s\tremaining: 12.2s\n",
      "175:\tlearn: 1.6443501\ttotal: 2.61s\tremaining: 12.2s\n",
      "176:\tlearn: 1.6431198\ttotal: 2.63s\tremaining: 12.2s\n",
      "177:\tlearn: 1.6424072\ttotal: 2.64s\tremaining: 12.2s\n",
      "178:\tlearn: 1.6415602\ttotal: 2.65s\tremaining: 12.2s\n",
      "179:\tlearn: 1.6394865\ttotal: 2.67s\tremaining: 12.2s\n",
      "180:\tlearn: 1.6368252\ttotal: 2.68s\tremaining: 12.1s\n",
      "181:\tlearn: 1.6348797\ttotal: 2.7s\tremaining: 12.1s\n",
      "182:\tlearn: 1.6324605\ttotal: 2.71s\tremaining: 12.1s\n",
      "183:\tlearn: 1.6302138\ttotal: 2.73s\tremaining: 12.1s\n",
      "184:\tlearn: 1.6269914\ttotal: 2.74s\tremaining: 12.1s\n",
      "185:\tlearn: 1.6241723\ttotal: 2.75s\tremaining: 12.1s\n",
      "186:\tlearn: 1.6233533\ttotal: 2.77s\tremaining: 12s\n",
      "187:\tlearn: 1.6218388\ttotal: 2.78s\tremaining: 12s\n",
      "188:\tlearn: 1.6204021\ttotal: 2.8s\tremaining: 12s\n",
      "189:\tlearn: 1.6191340\ttotal: 2.81s\tremaining: 12s\n",
      "190:\tlearn: 1.6179553\ttotal: 2.83s\tremaining: 12s\n",
      "191:\tlearn: 1.6172073\ttotal: 2.84s\tremaining: 12s\n",
      "192:\tlearn: 1.6158925\ttotal: 2.85s\tremaining: 11.9s\n",
      "193:\tlearn: 1.6149754\ttotal: 2.87s\tremaining: 11.9s\n",
      "194:\tlearn: 1.6140257\ttotal: 2.88s\tremaining: 11.9s\n",
      "195:\tlearn: 1.6124861\ttotal: 2.9s\tremaining: 11.9s\n",
      "196:\tlearn: 1.6109190\ttotal: 2.91s\tremaining: 11.9s\n",
      "197:\tlearn: 1.6070461\ttotal: 2.92s\tremaining: 11.8s\n",
      "198:\tlearn: 1.6038052\ttotal: 2.94s\tremaining: 11.8s\n",
      "199:\tlearn: 1.6018530\ttotal: 2.95s\tremaining: 11.8s\n",
      "200:\tlearn: 1.6004375\ttotal: 2.97s\tremaining: 11.8s\n",
      "201:\tlearn: 1.5999729\ttotal: 2.98s\tremaining: 11.8s\n",
      "202:\tlearn: 1.5997432\ttotal: 3s\tremaining: 11.8s\n",
      "203:\tlearn: 1.5996256\ttotal: 3.01s\tremaining: 11.8s\n",
      "204:\tlearn: 1.5989147\ttotal: 3.02s\tremaining: 11.7s\n",
      "205:\tlearn: 1.5976191\ttotal: 3.04s\tremaining: 11.7s\n",
      "206:\tlearn: 1.5972481\ttotal: 3.05s\tremaining: 11.7s\n",
      "207:\tlearn: 1.5964177\ttotal: 3.07s\tremaining: 11.7s\n",
      "208:\tlearn: 1.5961189\ttotal: 3.08s\tremaining: 11.7s\n",
      "209:\tlearn: 1.5959369\ttotal: 3.1s\tremaining: 11.6s\n",
      "210:\tlearn: 1.5956003\ttotal: 3.11s\tremaining: 11.6s\n",
      "211:\tlearn: 1.5951996\ttotal: 3.12s\tremaining: 11.6s\n",
      "212:\tlearn: 1.5945183\ttotal: 3.14s\tremaining: 11.6s\n",
      "213:\tlearn: 1.5938457\ttotal: 3.15s\tremaining: 11.6s\n",
      "214:\tlearn: 1.5933852\ttotal: 3.17s\tremaining: 11.6s\n",
      "215:\tlearn: 1.5929999\ttotal: 3.18s\tremaining: 11.5s\n",
      "216:\tlearn: 1.5918201\ttotal: 3.19s\tremaining: 11.5s\n",
      "217:\tlearn: 1.5914721\ttotal: 3.21s\tremaining: 11.5s\n",
      "218:\tlearn: 1.5908009\ttotal: 3.22s\tremaining: 11.5s\n",
      "219:\tlearn: 1.5891050\ttotal: 3.23s\tremaining: 11.5s\n",
      "220:\tlearn: 1.5885104\ttotal: 3.25s\tremaining: 11.5s\n",
      "221:\tlearn: 1.5876437\ttotal: 3.27s\tremaining: 11.4s\n",
      "222:\tlearn: 1.5870378\ttotal: 3.28s\tremaining: 11.4s\n",
      "223:\tlearn: 1.5864685\ttotal: 3.29s\tremaining: 11.4s\n",
      "224:\tlearn: 1.5857589\ttotal: 3.31s\tremaining: 11.4s\n",
      "225:\tlearn: 1.5856873\ttotal: 3.32s\tremaining: 11.4s\n",
      "226:\tlearn: 1.5851825\ttotal: 3.33s\tremaining: 11.4s\n",
      "227:\tlearn: 1.5843215\ttotal: 3.35s\tremaining: 11.3s\n",
      "228:\tlearn: 1.5839228\ttotal: 3.36s\tremaining: 11.3s\n",
      "229:\tlearn: 1.5833166\ttotal: 3.38s\tremaining: 11.3s\n",
      "230:\tlearn: 1.5818010\ttotal: 3.39s\tremaining: 11.3s\n",
      "231:\tlearn: 1.5815155\ttotal: 3.4s\tremaining: 11.3s\n",
      "232:\tlearn: 1.5796869\ttotal: 3.42s\tremaining: 11.3s\n",
      "233:\tlearn: 1.5783846\ttotal: 3.43s\tremaining: 11.2s\n",
      "234:\tlearn: 1.5779102\ttotal: 3.44s\tremaining: 11.2s\n",
      "235:\tlearn: 1.5776733\ttotal: 3.46s\tremaining: 11.2s\n",
      "236:\tlearn: 1.5762271\ttotal: 3.47s\tremaining: 11.2s\n",
      "237:\tlearn: 1.5749107\ttotal: 3.49s\tremaining: 11.2s\n",
      "238:\tlearn: 1.5737889\ttotal: 3.5s\tremaining: 11.1s\n",
      "239:\tlearn: 1.5728778\ttotal: 3.52s\tremaining: 11.1s\n",
      "240:\tlearn: 1.5719234\ttotal: 3.53s\tremaining: 11.1s\n",
      "241:\tlearn: 1.5703926\ttotal: 3.54s\tremaining: 11.1s\n",
      "242:\tlearn: 1.5701946\ttotal: 3.56s\tremaining: 11.1s\n",
      "243:\tlearn: 1.5698532\ttotal: 3.57s\tremaining: 11.1s\n",
      "244:\tlearn: 1.5685232\ttotal: 3.58s\tremaining: 11s\n",
      "245:\tlearn: 1.5677963\ttotal: 3.6s\tremaining: 11s\n",
      "246:\tlearn: 1.5672988\ttotal: 3.61s\tremaining: 11s\n",
      "247:\tlearn: 1.5668694\ttotal: 3.63s\tremaining: 11s\n",
      "248:\tlearn: 1.5662055\ttotal: 3.64s\tremaining: 11s\n",
      "249:\tlearn: 1.5656877\ttotal: 3.65s\tremaining: 11s\n",
      "250:\tlearn: 1.5649897\ttotal: 3.67s\tremaining: 10.9s\n",
      "251:\tlearn: 1.5643692\ttotal: 3.68s\tremaining: 10.9s\n",
      "252:\tlearn: 1.5635783\ttotal: 3.7s\tremaining: 10.9s\n",
      "253:\tlearn: 1.5627030\ttotal: 3.71s\tremaining: 10.9s\n",
      "254:\tlearn: 1.5617559\ttotal: 3.73s\tremaining: 10.9s\n",
      "255:\tlearn: 1.5608268\ttotal: 3.74s\tremaining: 10.9s\n",
      "256:\tlearn: 1.5598695\ttotal: 3.76s\tremaining: 10.9s\n",
      "257:\tlearn: 1.5590959\ttotal: 3.77s\tremaining: 10.8s\n",
      "258:\tlearn: 1.5583781\ttotal: 3.78s\tremaining: 10.8s\n",
      "259:\tlearn: 1.5572363\ttotal: 3.8s\tremaining: 10.8s\n",
      "260:\tlearn: 1.5567106\ttotal: 3.81s\tremaining: 10.8s\n",
      "261:\tlearn: 1.5559436\ttotal: 3.83s\tremaining: 10.8s\n",
      "262:\tlearn: 1.5541705\ttotal: 3.84s\tremaining: 10.8s\n",
      "263:\tlearn: 1.5537578\ttotal: 3.85s\tremaining: 10.7s\n",
      "264:\tlearn: 1.5527337\ttotal: 3.87s\tremaining: 10.7s\n",
      "265:\tlearn: 1.5520995\ttotal: 3.88s\tremaining: 10.7s\n",
      "266:\tlearn: 1.5512756\ttotal: 3.9s\tremaining: 10.7s\n",
      "267:\tlearn: 1.5509337\ttotal: 3.91s\tremaining: 10.7s\n",
      "268:\tlearn: 1.5501138\ttotal: 3.92s\tremaining: 10.7s\n",
      "269:\tlearn: 1.5492543\ttotal: 3.94s\tremaining: 10.7s\n",
      "270:\tlearn: 1.5487994\ttotal: 3.95s\tremaining: 10.6s\n",
      "271:\tlearn: 1.5482421\ttotal: 3.97s\tremaining: 10.6s\n",
      "272:\tlearn: 1.5475466\ttotal: 3.98s\tremaining: 10.6s\n",
      "273:\tlearn: 1.5470727\ttotal: 3.99s\tremaining: 10.6s\n",
      "274:\tlearn: 1.5465523\ttotal: 4.01s\tremaining: 10.6s\n",
      "275:\tlearn: 1.5463340\ttotal: 4.02s\tremaining: 10.5s\n",
      "276:\tlearn: 1.5457169\ttotal: 4.04s\tremaining: 10.5s\n",
      "277:\tlearn: 1.5449559\ttotal: 4.05s\tremaining: 10.5s\n",
      "278:\tlearn: 1.5433079\ttotal: 4.06s\tremaining: 10.5s\n",
      "279:\tlearn: 1.5430110\ttotal: 4.08s\tremaining: 10.5s\n",
      "280:\tlearn: 1.5424301\ttotal: 4.09s\tremaining: 10.5s\n",
      "281:\tlearn: 1.5419417\ttotal: 4.11s\tremaining: 10.5s\n",
      "282:\tlearn: 1.5416862\ttotal: 4.12s\tremaining: 10.4s\n",
      "283:\tlearn: 1.5416064\ttotal: 4.13s\tremaining: 10.4s\n",
      "284:\tlearn: 1.5415430\ttotal: 4.15s\tremaining: 10.4s\n",
      "285:\tlearn: 1.5414203\ttotal: 4.16s\tremaining: 10.4s\n",
      "286:\tlearn: 1.5413171\ttotal: 4.17s\tremaining: 10.4s\n",
      "287:\tlearn: 1.5412187\ttotal: 4.19s\tremaining: 10.4s\n",
      "288:\tlearn: 1.5411693\ttotal: 4.2s\tremaining: 10.3s\n",
      "289:\tlearn: 1.5411387\ttotal: 4.22s\tremaining: 10.3s\n",
      "290:\tlearn: 1.5407092\ttotal: 4.23s\tremaining: 10.3s\n",
      "291:\tlearn: 1.5399421\ttotal: 4.25s\tremaining: 10.3s\n",
      "292:\tlearn: 1.5381884\ttotal: 4.26s\tremaining: 10.3s\n",
      "293:\tlearn: 1.5381146\ttotal: 4.27s\tremaining: 10.3s\n",
      "294:\tlearn: 1.5380438\ttotal: 4.29s\tremaining: 10.2s\n",
      "295:\tlearn: 1.5379483\ttotal: 4.3s\tremaining: 10.2s\n",
      "296:\tlearn: 1.5376386\ttotal: 4.32s\tremaining: 10.2s\n",
      "297:\tlearn: 1.5375852\ttotal: 4.33s\tremaining: 10.2s\n",
      "298:\tlearn: 1.5374718\ttotal: 4.34s\tremaining: 10.2s\n",
      "299:\tlearn: 1.5373476\ttotal: 4.36s\tremaining: 10.2s\n",
      "300:\tlearn: 1.5371831\ttotal: 4.37s\tremaining: 10.2s\n",
      "301:\tlearn: 1.5371338\ttotal: 4.38s\tremaining: 10.1s\n",
      "302:\tlearn: 1.5369618\ttotal: 4.4s\tremaining: 10.1s\n",
      "303:\tlearn: 1.5368951\ttotal: 4.41s\tremaining: 10.1s\n",
      "304:\tlearn: 1.5364842\ttotal: 4.43s\tremaining: 10.1s\n",
      "305:\tlearn: 1.5362516\ttotal: 4.44s\tremaining: 10.1s\n",
      "306:\tlearn: 1.5355378\ttotal: 4.45s\tremaining: 10.1s\n",
      "307:\tlearn: 1.5354317\ttotal: 4.47s\tremaining: 10s\n",
      "308:\tlearn: 1.5352278\ttotal: 4.48s\tremaining: 10s\n",
      "309:\tlearn: 1.5345836\ttotal: 4.49s\tremaining: 10s\n",
      "310:\tlearn: 1.5341874\ttotal: 4.51s\tremaining: 9.99s\n",
      "311:\tlearn: 1.5334098\ttotal: 4.52s\tremaining: 9.97s\n",
      "312:\tlearn: 1.5329232\ttotal: 4.54s\tremaining: 9.96s\n",
      "313:\tlearn: 1.5323769\ttotal: 4.55s\tremaining: 9.95s\n",
      "314:\tlearn: 1.5315849\ttotal: 4.57s\tremaining: 9.94s\n",
      "315:\tlearn: 1.5313965\ttotal: 4.58s\tremaining: 9.92s\n",
      "316:\tlearn: 1.5305884\ttotal: 4.59s\tremaining: 9.9s\n",
      "317:\tlearn: 1.5303916\ttotal: 4.61s\tremaining: 9.88s\n",
      "318:\tlearn: 1.5298247\ttotal: 4.62s\tremaining: 9.87s\n",
      "319:\tlearn: 1.5289499\ttotal: 4.64s\tremaining: 9.85s\n",
      "320:\tlearn: 1.5282328\ttotal: 4.65s\tremaining: 9.84s\n",
      "321:\tlearn: 1.5275583\ttotal: 4.66s\tremaining: 9.82s\n",
      "322:\tlearn: 1.5274035\ttotal: 4.68s\tremaining: 9.8s\n",
      "323:\tlearn: 1.5260096\ttotal: 4.69s\tremaining: 9.79s\n",
      "324:\tlearn: 1.5258131\ttotal: 4.71s\tremaining: 9.78s\n",
      "325:\tlearn: 1.5243445\ttotal: 4.72s\tremaining: 9.76s\n",
      "326:\tlearn: 1.5238732\ttotal: 4.74s\tremaining: 9.74s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327:\tlearn: 1.5236722\ttotal: 4.75s\tremaining: 9.73s\n",
      "328:\tlearn: 1.5231755\ttotal: 4.77s\tremaining: 9.72s\n",
      "329:\tlearn: 1.5220118\ttotal: 4.78s\tremaining: 9.71s\n",
      "330:\tlearn: 1.5216382\ttotal: 4.8s\tremaining: 9.69s\n",
      "331:\tlearn: 1.5209461\ttotal: 4.81s\tremaining: 9.68s\n",
      "332:\tlearn: 1.5203683\ttotal: 4.82s\tremaining: 9.66s\n",
      "333:\tlearn: 1.5195060\ttotal: 4.84s\tremaining: 9.65s\n",
      "334:\tlearn: 1.5190031\ttotal: 4.85s\tremaining: 9.63s\n",
      "335:\tlearn: 1.5189880\ttotal: 4.87s\tremaining: 9.62s\n",
      "336:\tlearn: 1.5183818\ttotal: 4.88s\tremaining: 9.6s\n",
      "337:\tlearn: 1.5179702\ttotal: 4.89s\tremaining: 9.58s\n",
      "338:\tlearn: 1.5170726\ttotal: 4.91s\tremaining: 9.57s\n",
      "339:\tlearn: 1.5160070\ttotal: 4.92s\tremaining: 9.55s\n",
      "340:\tlearn: 1.5157808\ttotal: 4.93s\tremaining: 9.54s\n",
      "341:\tlearn: 1.5149018\ttotal: 4.95s\tremaining: 9.52s\n",
      "342:\tlearn: 1.5137647\ttotal: 4.96s\tremaining: 9.51s\n",
      "343:\tlearn: 1.5124624\ttotal: 4.98s\tremaining: 9.49s\n",
      "344:\tlearn: 1.5118194\ttotal: 4.99s\tremaining: 9.47s\n",
      "345:\tlearn: 1.5112158\ttotal: 5s\tremaining: 9.46s\n",
      "346:\tlearn: 1.5108921\ttotal: 5.02s\tremaining: 9.44s\n",
      "347:\tlearn: 1.5108311\ttotal: 5.03s\tremaining: 9.43s\n",
      "348:\tlearn: 1.5108018\ttotal: 5.05s\tremaining: 9.41s\n",
      "349:\tlearn: 1.5107021\ttotal: 5.06s\tremaining: 9.4s\n",
      "350:\tlearn: 1.5098887\ttotal: 5.07s\tremaining: 9.38s\n",
      "351:\tlearn: 1.5098822\ttotal: 5.09s\tremaining: 9.37s\n",
      "352:\tlearn: 1.5088624\ttotal: 5.1s\tremaining: 9.35s\n",
      "353:\tlearn: 1.5086970\ttotal: 5.12s\tremaining: 9.33s\n",
      "354:\tlearn: 1.5086760\ttotal: 5.13s\tremaining: 9.32s\n",
      "355:\tlearn: 1.5077326\ttotal: 5.14s\tremaining: 9.3s\n",
      "356:\tlearn: 1.5071664\ttotal: 5.16s\tremaining: 9.29s\n",
      "357:\tlearn: 1.5070086\ttotal: 5.17s\tremaining: 9.27s\n",
      "358:\tlearn: 1.5069406\ttotal: 5.19s\tremaining: 9.26s\n",
      "359:\tlearn: 1.5066379\ttotal: 5.2s\tremaining: 9.24s\n",
      "360:\tlearn: 1.5065757\ttotal: 5.21s\tremaining: 9.23s\n",
      "361:\tlearn: 1.5058066\ttotal: 5.23s\tremaining: 9.21s\n",
      "362:\tlearn: 1.5055984\ttotal: 5.24s\tremaining: 9.2s\n",
      "363:\tlearn: 1.5053852\ttotal: 5.25s\tremaining: 9.18s\n",
      "364:\tlearn: 1.5050624\ttotal: 5.27s\tremaining: 9.17s\n",
      "365:\tlearn: 1.5050262\ttotal: 5.28s\tremaining: 9.15s\n",
      "366:\tlearn: 1.5049984\ttotal: 5.3s\tremaining: 9.13s\n",
      "367:\tlearn: 1.5045369\ttotal: 5.31s\tremaining: 9.12s\n",
      "368:\tlearn: 1.5040369\ttotal: 5.32s\tremaining: 9.1s\n",
      "369:\tlearn: 1.5035792\ttotal: 5.34s\tremaining: 9.09s\n",
      "370:\tlearn: 1.5032889\ttotal: 5.35s\tremaining: 9.07s\n",
      "371:\tlearn: 1.5027985\ttotal: 5.37s\tremaining: 9.06s\n",
      "372:\tlearn: 1.5026781\ttotal: 5.38s\tremaining: 9.04s\n",
      "373:\tlearn: 1.5022860\ttotal: 5.39s\tremaining: 9.03s\n",
      "374:\tlearn: 1.5020118\ttotal: 5.41s\tremaining: 9.02s\n",
      "375:\tlearn: 1.5017083\ttotal: 5.42s\tremaining: 9s\n",
      "376:\tlearn: 1.5013169\ttotal: 5.44s\tremaining: 8.99s\n",
      "377:\tlearn: 1.5012476\ttotal: 5.45s\tremaining: 8.97s\n",
      "378:\tlearn: 1.5012217\ttotal: 5.46s\tremaining: 8.95s\n",
      "379:\tlearn: 1.5011776\ttotal: 5.48s\tremaining: 8.94s\n",
      "380:\tlearn: 1.5011266\ttotal: 5.49s\tremaining: 8.92s\n",
      "381:\tlearn: 1.5011070\ttotal: 5.5s\tremaining: 8.91s\n",
      "382:\tlearn: 1.5004861\ttotal: 5.52s\tremaining: 8.89s\n",
      "383:\tlearn: 1.5004709\ttotal: 5.53s\tremaining: 8.88s\n",
      "384:\tlearn: 1.5004187\ttotal: 5.55s\tremaining: 8.86s\n",
      "385:\tlearn: 1.5002249\ttotal: 5.56s\tremaining: 8.84s\n",
      "386:\tlearn: 1.5001056\ttotal: 5.57s\tremaining: 8.83s\n",
      "387:\tlearn: 1.4996947\ttotal: 5.59s\tremaining: 8.81s\n",
      "388:\tlearn: 1.4990839\ttotal: 5.6s\tremaining: 8.8s\n",
      "389:\tlearn: 1.4981609\ttotal: 5.62s\tremaining: 8.79s\n",
      "390:\tlearn: 1.4981260\ttotal: 5.63s\tremaining: 8.78s\n",
      "391:\tlearn: 1.4976501\ttotal: 5.65s\tremaining: 8.76s\n",
      "392:\tlearn: 1.4975115\ttotal: 5.66s\tremaining: 8.74s\n",
      "393:\tlearn: 1.4967254\ttotal: 5.67s\tremaining: 8.73s\n",
      "394:\tlearn: 1.4966392\ttotal: 5.69s\tremaining: 8.71s\n",
      "395:\tlearn: 1.4963277\ttotal: 5.7s\tremaining: 8.7s\n",
      "396:\tlearn: 1.4960352\ttotal: 5.71s\tremaining: 8.68s\n",
      "397:\tlearn: 1.4957988\ttotal: 5.73s\tremaining: 8.66s\n",
      "398:\tlearn: 1.4955784\ttotal: 5.74s\tremaining: 8.65s\n",
      "399:\tlearn: 1.4954688\ttotal: 5.75s\tremaining: 8.63s\n",
      "400:\tlearn: 1.4952996\ttotal: 5.77s\tremaining: 8.62s\n",
      "401:\tlearn: 1.4952976\ttotal: 5.78s\tremaining: 8.6s\n",
      "402:\tlearn: 1.4952737\ttotal: 5.79s\tremaining: 8.59s\n",
      "403:\tlearn: 1.4952736\ttotal: 5.81s\tremaining: 8.57s\n",
      "404:\tlearn: 1.4952585\ttotal: 5.82s\tremaining: 8.56s\n",
      "405:\tlearn: 1.4951405\ttotal: 5.84s\tremaining: 8.54s\n",
      "406:\tlearn: 1.4949773\ttotal: 5.85s\tremaining: 8.53s\n",
      "407:\tlearn: 1.4949176\ttotal: 5.87s\tremaining: 8.51s\n",
      "408:\tlearn: 1.4948551\ttotal: 5.88s\tremaining: 8.5s\n",
      "409:\tlearn: 1.4938350\ttotal: 5.89s\tremaining: 8.48s\n",
      "410:\tlearn: 1.4938245\ttotal: 5.91s\tremaining: 8.47s\n",
      "411:\tlearn: 1.4938091\ttotal: 5.92s\tremaining: 8.45s\n",
      "412:\tlearn: 1.4937174\ttotal: 5.93s\tremaining: 8.44s\n",
      "413:\tlearn: 1.4935556\ttotal: 5.95s\tremaining: 8.42s\n",
      "414:\tlearn: 1.4935536\ttotal: 5.96s\tremaining: 8.4s\n",
      "415:\tlearn: 1.4935239\ttotal: 5.97s\tremaining: 8.39s\n",
      "416:\tlearn: 1.4934881\ttotal: 5.99s\tremaining: 8.37s\n",
      "417:\tlearn: 1.4933175\ttotal: 6s\tremaining: 8.36s\n",
      "418:\tlearn: 1.4924547\ttotal: 6.01s\tremaining: 8.34s\n",
      "419:\tlearn: 1.4922634\ttotal: 6.03s\tremaining: 8.33s\n",
      "420:\tlearn: 1.4921891\ttotal: 6.04s\tremaining: 8.31s\n",
      "421:\tlearn: 1.4919197\ttotal: 6.06s\tremaining: 8.3s\n",
      "422:\tlearn: 1.4917750\ttotal: 6.07s\tremaining: 8.29s\n",
      "423:\tlearn: 1.4915383\ttotal: 6.09s\tremaining: 8.27s\n",
      "424:\tlearn: 1.4909495\ttotal: 6.1s\tremaining: 8.25s\n",
      "425:\tlearn: 1.4899926\ttotal: 6.12s\tremaining: 8.24s\n",
      "426:\tlearn: 1.4889454\ttotal: 6.13s\tremaining: 8.22s\n",
      "427:\tlearn: 1.4889433\ttotal: 6.14s\tremaining: 8.21s\n",
      "428:\tlearn: 1.4889431\ttotal: 6.16s\tremaining: 8.2s\n",
      "429:\tlearn: 1.4889392\ttotal: 6.17s\tremaining: 8.18s\n",
      "430:\tlearn: 1.4889331\ttotal: 6.18s\tremaining: 8.16s\n",
      "431:\tlearn: 1.4889165\ttotal: 6.2s\tremaining: 8.15s\n",
      "432:\tlearn: 1.4888885\ttotal: 6.21s\tremaining: 8.13s\n",
      "433:\tlearn: 1.4888885\ttotal: 6.22s\tremaining: 8.12s\n",
      "434:\tlearn: 1.4888854\ttotal: 6.24s\tremaining: 8.1s\n",
      "435:\tlearn: 1.4887555\ttotal: 6.25s\tremaining: 8.09s\n",
      "436:\tlearn: 1.4886218\ttotal: 6.27s\tremaining: 8.07s\n",
      "437:\tlearn: 1.4886173\ttotal: 6.28s\tremaining: 8.06s\n",
      "438:\tlearn: 1.4884410\ttotal: 6.29s\tremaining: 8.04s\n",
      "439:\tlearn: 1.4884403\ttotal: 6.31s\tremaining: 8.03s\n",
      "440:\tlearn: 1.4884392\ttotal: 6.32s\tremaining: 8.01s\n",
      "441:\tlearn: 1.4884385\ttotal: 6.33s\tremaining: 8s\n",
      "442:\tlearn: 1.4884385\ttotal: 6.35s\tremaining: 7.98s\n",
      "443:\tlearn: 1.4884383\ttotal: 6.36s\tremaining: 7.96s\n",
      "444:\tlearn: 1.4884383\ttotal: 6.37s\tremaining: 7.95s\n",
      "445:\tlearn: 1.4880122\ttotal: 6.39s\tremaining: 7.93s\n",
      "446:\tlearn: 1.4877770\ttotal: 6.4s\tremaining: 7.92s\n",
      "447:\tlearn: 1.4877767\ttotal: 6.42s\tremaining: 7.9s\n",
      "448:\tlearn: 1.4877759\ttotal: 6.43s\tremaining: 7.89s\n",
      "449:\tlearn: 1.4877759\ttotal: 6.44s\tremaining: 7.87s\n",
      "450:\tlearn: 1.4877759\ttotal: 6.45s\tremaining: 7.86s\n",
      "451:\tlearn: 1.4873725\ttotal: 6.47s\tremaining: 7.84s\n",
      "452:\tlearn: 1.4873502\ttotal: 6.49s\tremaining: 7.83s\n",
      "453:\tlearn: 1.4872974\ttotal: 6.5s\tremaining: 7.82s\n",
      "454:\tlearn: 1.4869525\ttotal: 6.51s\tremaining: 7.8s\n",
      "455:\tlearn: 1.4869388\ttotal: 6.53s\tremaining: 7.79s\n",
      "456:\tlearn: 1.4869369\ttotal: 6.54s\tremaining: 7.77s\n",
      "457:\tlearn: 1.4869361\ttotal: 6.55s\tremaining: 7.75s\n",
      "458:\tlearn: 1.4868832\ttotal: 6.57s\tremaining: 7.74s\n",
      "459:\tlearn: 1.4866894\ttotal: 6.58s\tremaining: 7.72s\n",
      "460:\tlearn: 1.4863588\ttotal: 6.59s\tremaining: 7.71s\n",
      "461:\tlearn: 1.4863577\ttotal: 6.61s\tremaining: 7.69s\n",
      "462:\tlearn: 1.4863442\ttotal: 6.62s\tremaining: 7.68s\n",
      "463:\tlearn: 1.4855112\ttotal: 6.63s\tremaining: 7.66s\n",
      "464:\tlearn: 1.4854143\ttotal: 6.65s\tremaining: 7.65s\n",
      "465:\tlearn: 1.4848842\ttotal: 6.66s\tremaining: 7.63s\n",
      "466:\tlearn: 1.4843068\ttotal: 6.68s\tremaining: 7.62s\n",
      "467:\tlearn: 1.4842841\ttotal: 6.69s\tremaining: 7.61s\n",
      "468:\tlearn: 1.4842623\ttotal: 6.71s\tremaining: 7.59s\n",
      "469:\tlearn: 1.4841399\ttotal: 6.72s\tremaining: 7.58s\n",
      "470:\tlearn: 1.4841269\ttotal: 6.73s\tremaining: 7.56s\n",
      "471:\tlearn: 1.4841198\ttotal: 6.75s\tremaining: 7.55s\n",
      "472:\tlearn: 1.4841198\ttotal: 6.76s\tremaining: 7.53s\n",
      "473:\tlearn: 1.4841168\ttotal: 6.78s\tremaining: 7.52s\n",
      "474:\tlearn: 1.4835782\ttotal: 6.79s\tremaining: 7.51s\n",
      "475:\tlearn: 1.4835453\ttotal: 6.81s\tremaining: 7.49s\n",
      "476:\tlearn: 1.4835452\ttotal: 6.82s\tremaining: 7.48s\n",
      "477:\tlearn: 1.4835449\ttotal: 6.83s\tremaining: 7.46s\n",
      "478:\tlearn: 1.4835438\ttotal: 6.85s\tremaining: 7.45s\n",
      "479:\tlearn: 1.4834110\ttotal: 6.86s\tremaining: 7.43s\n",
      "480:\tlearn: 1.4833984\ttotal: 6.87s\tremaining: 7.42s\n",
      "481:\tlearn: 1.4829857\ttotal: 6.89s\tremaining: 7.41s\n",
      "482:\tlearn: 1.4828977\ttotal: 6.91s\tremaining: 7.39s\n",
      "483:\tlearn: 1.4828660\ttotal: 6.92s\tremaining: 7.38s\n",
      "484:\tlearn: 1.4825660\ttotal: 6.93s\tremaining: 7.36s\n",
      "485:\tlearn: 1.4825660\ttotal: 6.95s\tremaining: 7.35s\n",
      "486:\tlearn: 1.4824019\ttotal: 6.96s\tremaining: 7.33s\n",
      "487:\tlearn: 1.4823738\ttotal: 6.97s\tremaining: 7.32s\n",
      "488:\tlearn: 1.4817460\ttotal: 6.99s\tremaining: 7.3s\n",
      "489:\tlearn: 1.4815538\ttotal: 7s\tremaining: 7.29s\n",
      "490:\tlearn: 1.4814506\ttotal: 7.01s\tremaining: 7.27s\n",
      "491:\tlearn: 1.4807131\ttotal: 7.03s\tremaining: 7.26s\n",
      "492:\tlearn: 1.4804409\ttotal: 7.04s\tremaining: 7.24s\n",
      "493:\tlearn: 1.4803697\ttotal: 7.05s\tremaining: 7.23s\n",
      "494:\tlearn: 1.4796862\ttotal: 7.07s\tremaining: 7.21s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495:\tlearn: 1.4796408\ttotal: 7.08s\tremaining: 7.2s\n",
      "496:\tlearn: 1.4796311\ttotal: 7.1s\tremaining: 7.18s\n",
      "497:\tlearn: 1.4796280\ttotal: 7.11s\tremaining: 7.17s\n",
      "498:\tlearn: 1.4796274\ttotal: 7.13s\tremaining: 7.15s\n",
      "499:\tlearn: 1.4795605\ttotal: 7.14s\tremaining: 7.14s\n",
      "500:\tlearn: 1.4795009\ttotal: 7.15s\tremaining: 7.12s\n",
      "501:\tlearn: 1.4790174\ttotal: 7.17s\tremaining: 7.11s\n",
      "502:\tlearn: 1.4790139\ttotal: 7.18s\tremaining: 7.09s\n",
      "503:\tlearn: 1.4790056\ttotal: 7.19s\tremaining: 7.08s\n",
      "504:\tlearn: 1.4790034\ttotal: 7.21s\tremaining: 7.06s\n",
      "505:\tlearn: 1.4789552\ttotal: 7.22s\tremaining: 7.05s\n",
      "506:\tlearn: 1.4786028\ttotal: 7.23s\tremaining: 7.03s\n",
      "507:\tlearn: 1.4782537\ttotal: 7.25s\tremaining: 7.02s\n",
      "508:\tlearn: 1.4781899\ttotal: 7.26s\tremaining: 7s\n",
      "509:\tlearn: 1.4780595\ttotal: 7.28s\tremaining: 6.99s\n",
      "510:\tlearn: 1.4773102\ttotal: 7.29s\tremaining: 6.97s\n",
      "511:\tlearn: 1.4772248\ttotal: 7.3s\tremaining: 6.96s\n",
      "512:\tlearn: 1.4771460\ttotal: 7.32s\tremaining: 6.95s\n",
      "513:\tlearn: 1.4771460\ttotal: 7.33s\tremaining: 6.93s\n",
      "514:\tlearn: 1.4771178\ttotal: 7.35s\tremaining: 6.92s\n",
      "515:\tlearn: 1.4770515\ttotal: 7.36s\tremaining: 6.9s\n",
      "516:\tlearn: 1.4766385\ttotal: 7.37s\tremaining: 6.89s\n",
      "517:\tlearn: 1.4766337\ttotal: 7.39s\tremaining: 6.87s\n",
      "518:\tlearn: 1.4766315\ttotal: 7.4s\tremaining: 6.86s\n",
      "519:\tlearn: 1.4766303\ttotal: 7.41s\tremaining: 6.84s\n",
      "520:\tlearn: 1.4765580\ttotal: 7.43s\tremaining: 6.83s\n",
      "521:\tlearn: 1.4759996\ttotal: 7.44s\tremaining: 6.81s\n",
      "522:\tlearn: 1.4759976\ttotal: 7.45s\tremaining: 6.8s\n",
      "523:\tlearn: 1.4759959\ttotal: 7.47s\tremaining: 6.78s\n",
      "524:\tlearn: 1.4759914\ttotal: 7.48s\tremaining: 6.77s\n",
      "525:\tlearn: 1.4759748\ttotal: 7.49s\tremaining: 6.75s\n",
      "526:\tlearn: 1.4759156\ttotal: 7.51s\tremaining: 6.74s\n",
      "527:\tlearn: 1.4758809\ttotal: 7.52s\tremaining: 6.73s\n",
      "528:\tlearn: 1.4758152\ttotal: 7.54s\tremaining: 6.71s\n",
      "529:\tlearn: 1.4757748\ttotal: 7.55s\tremaining: 6.7s\n",
      "530:\tlearn: 1.4756576\ttotal: 7.57s\tremaining: 6.68s\n",
      "531:\tlearn: 1.4756002\ttotal: 7.58s\tremaining: 6.67s\n",
      "532:\tlearn: 1.4752511\ttotal: 7.59s\tremaining: 6.65s\n",
      "533:\tlearn: 1.4748930\ttotal: 7.61s\tremaining: 6.64s\n",
      "534:\tlearn: 1.4741704\ttotal: 7.62s\tremaining: 6.62s\n",
      "535:\tlearn: 1.4741704\ttotal: 7.63s\tremaining: 6.61s\n",
      "536:\tlearn: 1.4739407\ttotal: 7.65s\tremaining: 6.59s\n",
      "537:\tlearn: 1.4737176\ttotal: 7.66s\tremaining: 6.58s\n",
      "538:\tlearn: 1.4733190\ttotal: 7.68s\tremaining: 6.57s\n",
      "539:\tlearn: 1.4728761\ttotal: 7.69s\tremaining: 6.55s\n",
      "540:\tlearn: 1.4725020\ttotal: 7.7s\tremaining: 6.54s\n",
      "541:\tlearn: 1.4724098\ttotal: 7.72s\tremaining: 6.52s\n",
      "542:\tlearn: 1.4720202\ttotal: 7.73s\tremaining: 6.51s\n",
      "543:\tlearn: 1.4709819\ttotal: 7.75s\tremaining: 6.5s\n",
      "544:\tlearn: 1.4709785\ttotal: 7.76s\tremaining: 6.48s\n",
      "545:\tlearn: 1.4709729\ttotal: 7.78s\tremaining: 6.47s\n",
      "546:\tlearn: 1.4709717\ttotal: 7.79s\tremaining: 6.45s\n",
      "547:\tlearn: 1.4709715\ttotal: 7.8s\tremaining: 6.43s\n",
      "548:\tlearn: 1.4708996\ttotal: 7.82s\tremaining: 6.42s\n",
      "549:\tlearn: 1.4708959\ttotal: 7.83s\tremaining: 6.41s\n",
      "550:\tlearn: 1.4708482\ttotal: 7.84s\tremaining: 6.39s\n",
      "551:\tlearn: 1.4708357\ttotal: 7.86s\tremaining: 6.38s\n",
      "552:\tlearn: 1.4708252\ttotal: 7.87s\tremaining: 6.36s\n",
      "553:\tlearn: 1.4708252\ttotal: 7.88s\tremaining: 6.35s\n",
      "554:\tlearn: 1.4708228\ttotal: 7.9s\tremaining: 6.33s\n",
      "555:\tlearn: 1.4708227\ttotal: 7.91s\tremaining: 6.32s\n",
      "556:\tlearn: 1.4708227\ttotal: 7.92s\tremaining: 6.3s\n",
      "557:\tlearn: 1.4708227\ttotal: 7.94s\tremaining: 6.29s\n",
      "558:\tlearn: 1.4708113\ttotal: 7.95s\tremaining: 6.27s\n",
      "559:\tlearn: 1.4701607\ttotal: 7.97s\tremaining: 6.26s\n",
      "560:\tlearn: 1.4700397\ttotal: 7.98s\tremaining: 6.25s\n",
      "561:\tlearn: 1.4697762\ttotal: 7.99s\tremaining: 6.23s\n",
      "562:\tlearn: 1.4697520\ttotal: 8.01s\tremaining: 6.21s\n",
      "563:\tlearn: 1.4691684\ttotal: 8.02s\tremaining: 6.2s\n",
      "564:\tlearn: 1.4691278\ttotal: 8.03s\tremaining: 6.18s\n",
      "565:\tlearn: 1.4691277\ttotal: 8.05s\tremaining: 6.17s\n",
      "566:\tlearn: 1.4691277\ttotal: 8.06s\tremaining: 6.16s\n",
      "567:\tlearn: 1.4691277\ttotal: 8.08s\tremaining: 6.14s\n",
      "568:\tlearn: 1.4691272\ttotal: 8.09s\tremaining: 6.13s\n",
      "569:\tlearn: 1.4691213\ttotal: 8.11s\tremaining: 6.11s\n",
      "570:\tlearn: 1.4688062\ttotal: 8.12s\tremaining: 6.1s\n",
      "571:\tlearn: 1.4688062\ttotal: 8.14s\tremaining: 6.09s\n",
      "572:\tlearn: 1.4688062\ttotal: 8.15s\tremaining: 6.08s\n",
      "573:\tlearn: 1.4688056\ttotal: 8.17s\tremaining: 6.06s\n",
      "574:\tlearn: 1.4688023\ttotal: 8.19s\tremaining: 6.05s\n",
      "575:\tlearn: 1.4688009\ttotal: 8.2s\tremaining: 6.04s\n",
      "576:\tlearn: 1.4687997\ttotal: 8.21s\tremaining: 6.02s\n",
      "577:\tlearn: 1.4687995\ttotal: 8.23s\tremaining: 6.01s\n",
      "578:\tlearn: 1.4687981\ttotal: 8.24s\tremaining: 5.99s\n",
      "579:\tlearn: 1.4687959\ttotal: 8.26s\tremaining: 5.98s\n",
      "580:\tlearn: 1.4687959\ttotal: 8.27s\tremaining: 5.96s\n",
      "581:\tlearn: 1.4687959\ttotal: 8.29s\tremaining: 5.95s\n",
      "582:\tlearn: 1.4687958\ttotal: 8.3s\tremaining: 5.94s\n",
      "583:\tlearn: 1.4687956\ttotal: 8.31s\tremaining: 5.92s\n",
      "584:\tlearn: 1.4687866\ttotal: 8.33s\tremaining: 5.91s\n",
      "585:\tlearn: 1.4687665\ttotal: 8.34s\tremaining: 5.89s\n",
      "586:\tlearn: 1.4680634\ttotal: 8.36s\tremaining: 5.88s\n",
      "587:\tlearn: 1.4680293\ttotal: 8.37s\tremaining: 5.87s\n",
      "588:\tlearn: 1.4668948\ttotal: 8.39s\tremaining: 5.85s\n",
      "589:\tlearn: 1.4668635\ttotal: 8.4s\tremaining: 5.84s\n",
      "590:\tlearn: 1.4668451\ttotal: 8.41s\tremaining: 5.82s\n",
      "591:\tlearn: 1.4664821\ttotal: 8.43s\tremaining: 5.81s\n",
      "592:\tlearn: 1.4652572\ttotal: 8.44s\tremaining: 5.79s\n",
      "593:\tlearn: 1.4645411\ttotal: 8.46s\tremaining: 5.78s\n",
      "594:\tlearn: 1.4645410\ttotal: 8.47s\tremaining: 5.76s\n",
      "595:\tlearn: 1.4645410\ttotal: 8.48s\tremaining: 5.75s\n",
      "596:\tlearn: 1.4645339\ttotal: 8.5s\tremaining: 5.74s\n",
      "597:\tlearn: 1.4645338\ttotal: 8.51s\tremaining: 5.72s\n",
      "598:\tlearn: 1.4645070\ttotal: 8.52s\tremaining: 5.71s\n",
      "599:\tlearn: 1.4645070\ttotal: 8.54s\tremaining: 5.69s\n",
      "600:\tlearn: 1.4645068\ttotal: 8.55s\tremaining: 5.68s\n",
      "601:\tlearn: 1.4645062\ttotal: 8.56s\tremaining: 5.66s\n",
      "602:\tlearn: 1.4645015\ttotal: 8.58s\tremaining: 5.65s\n",
      "603:\tlearn: 1.4645005\ttotal: 8.59s\tremaining: 5.63s\n",
      "604:\tlearn: 1.4638636\ttotal: 8.61s\tremaining: 5.62s\n",
      "605:\tlearn: 1.4634216\ttotal: 8.62s\tremaining: 5.61s\n",
      "606:\tlearn: 1.4634206\ttotal: 8.63s\tremaining: 5.59s\n",
      "607:\tlearn: 1.4634194\ttotal: 8.65s\tremaining: 5.58s\n",
      "608:\tlearn: 1.4634120\ttotal: 8.66s\tremaining: 5.56s\n",
      "609:\tlearn: 1.4634120\ttotal: 8.68s\tremaining: 5.55s\n",
      "610:\tlearn: 1.4634116\ttotal: 8.69s\tremaining: 5.53s\n",
      "611:\tlearn: 1.4634116\ttotal: 8.7s\tremaining: 5.52s\n",
      "612:\tlearn: 1.4634068\ttotal: 8.71s\tremaining: 5.5s\n",
      "613:\tlearn: 1.4634066\ttotal: 8.73s\tremaining: 5.49s\n",
      "614:\tlearn: 1.4634065\ttotal: 8.74s\tremaining: 5.47s\n",
      "615:\tlearn: 1.4633822\ttotal: 8.76s\tremaining: 5.46s\n",
      "616:\tlearn: 1.4625633\ttotal: 8.77s\tremaining: 5.44s\n",
      "617:\tlearn: 1.4624329\ttotal: 8.78s\tremaining: 5.43s\n",
      "618:\tlearn: 1.4619026\ttotal: 8.8s\tremaining: 5.42s\n",
      "619:\tlearn: 1.4618168\ttotal: 8.81s\tremaining: 5.4s\n",
      "620:\tlearn: 1.4613791\ttotal: 8.83s\tremaining: 5.39s\n",
      "621:\tlearn: 1.4613334\ttotal: 8.84s\tremaining: 5.38s\n",
      "622:\tlearn: 1.4611900\ttotal: 8.86s\tremaining: 5.36s\n",
      "623:\tlearn: 1.4611899\ttotal: 8.87s\tremaining: 5.34s\n",
      "624:\tlearn: 1.4611899\ttotal: 8.88s\tremaining: 5.33s\n",
      "625:\tlearn: 1.4611899\ttotal: 8.9s\tremaining: 5.32s\n",
      "626:\tlearn: 1.4611899\ttotal: 8.91s\tremaining: 5.3s\n",
      "627:\tlearn: 1.4611848\ttotal: 8.92s\tremaining: 5.29s\n",
      "628:\tlearn: 1.4611832\ttotal: 8.94s\tremaining: 5.27s\n",
      "629:\tlearn: 1.4611832\ttotal: 8.95s\tremaining: 5.26s\n",
      "630:\tlearn: 1.4611794\ttotal: 8.96s\tremaining: 5.24s\n",
      "631:\tlearn: 1.4610298\ttotal: 8.98s\tremaining: 5.23s\n",
      "632:\tlearn: 1.4610294\ttotal: 8.99s\tremaining: 5.21s\n",
      "633:\tlearn: 1.4610294\ttotal: 9.01s\tremaining: 5.2s\n",
      "634:\tlearn: 1.4610291\ttotal: 9.02s\tremaining: 5.18s\n",
      "635:\tlearn: 1.4610291\ttotal: 9.03s\tremaining: 5.17s\n",
      "636:\tlearn: 1.4610291\ttotal: 9.05s\tremaining: 5.16s\n",
      "637:\tlearn: 1.4610291\ttotal: 9.06s\tremaining: 5.14s\n",
      "638:\tlearn: 1.4609602\ttotal: 9.07s\tremaining: 5.13s\n",
      "639:\tlearn: 1.4609150\ttotal: 9.09s\tremaining: 5.11s\n",
      "640:\tlearn: 1.4609043\ttotal: 9.1s\tremaining: 5.1s\n",
      "641:\tlearn: 1.4609042\ttotal: 9.11s\tremaining: 5.08s\n",
      "642:\tlearn: 1.4609042\ttotal: 9.13s\tremaining: 5.07s\n",
      "643:\tlearn: 1.4609042\ttotal: 9.14s\tremaining: 5.05s\n",
      "644:\tlearn: 1.4609037\ttotal: 9.15s\tremaining: 5.04s\n",
      "645:\tlearn: 1.4609037\ttotal: 9.17s\tremaining: 5.02s\n",
      "646:\tlearn: 1.4609036\ttotal: 9.18s\tremaining: 5.01s\n",
      "647:\tlearn: 1.4609025\ttotal: 9.19s\tremaining: 4.99s\n",
      "648:\tlearn: 1.4609016\ttotal: 9.21s\tremaining: 4.98s\n",
      "649:\tlearn: 1.4609016\ttotal: 9.22s\tremaining: 4.96s\n",
      "650:\tlearn: 1.4609016\ttotal: 9.23s\tremaining: 4.95s\n",
      "651:\tlearn: 1.4609016\ttotal: 9.25s\tremaining: 4.94s\n",
      "652:\tlearn: 1.4608972\ttotal: 9.27s\tremaining: 4.92s\n",
      "653:\tlearn: 1.4608959\ttotal: 9.28s\tremaining: 4.91s\n",
      "654:\tlearn: 1.4608782\ttotal: 9.29s\tremaining: 4.89s\n",
      "655:\tlearn: 1.4603318\ttotal: 9.31s\tremaining: 4.88s\n",
      "656:\tlearn: 1.4601447\ttotal: 9.32s\tremaining: 4.87s\n",
      "657:\tlearn: 1.4595365\ttotal: 9.33s\tremaining: 4.85s\n",
      "658:\tlearn: 1.4594656\ttotal: 9.35s\tremaining: 4.84s\n",
      "659:\tlearn: 1.4594371\ttotal: 9.36s\tremaining: 4.82s\n",
      "660:\tlearn: 1.4594326\ttotal: 9.38s\tremaining: 4.81s\n",
      "661:\tlearn: 1.4594326\ttotal: 9.39s\tremaining: 4.79s\n",
      "662:\tlearn: 1.4594324\ttotal: 9.4s\tremaining: 4.78s\n",
      "663:\tlearn: 1.4594236\ttotal: 9.42s\tremaining: 4.76s\n",
      "664:\tlearn: 1.4594236\ttotal: 9.43s\tremaining: 4.75s\n",
      "665:\tlearn: 1.4594214\ttotal: 9.44s\tremaining: 4.74s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666:\tlearn: 1.4593516\ttotal: 9.46s\tremaining: 4.72s\n",
      "667:\tlearn: 1.4593485\ttotal: 9.47s\tremaining: 4.71s\n",
      "668:\tlearn: 1.4593475\ttotal: 9.48s\tremaining: 4.69s\n",
      "669:\tlearn: 1.4593472\ttotal: 9.5s\tremaining: 4.68s\n",
      "670:\tlearn: 1.4593371\ttotal: 9.51s\tremaining: 4.66s\n",
      "671:\tlearn: 1.4593370\ttotal: 9.53s\tremaining: 4.65s\n",
      "672:\tlearn: 1.4593370\ttotal: 9.54s\tremaining: 4.63s\n",
      "673:\tlearn: 1.4593369\ttotal: 9.55s\tremaining: 4.62s\n",
      "674:\tlearn: 1.4593368\ttotal: 9.56s\tremaining: 4.61s\n",
      "675:\tlearn: 1.4593368\ttotal: 9.58s\tremaining: 4.59s\n",
      "676:\tlearn: 1.4593368\ttotal: 9.59s\tremaining: 4.58s\n",
      "677:\tlearn: 1.4593179\ttotal: 9.61s\tremaining: 4.56s\n",
      "678:\tlearn: 1.4593155\ttotal: 9.62s\tremaining: 4.55s\n",
      "679:\tlearn: 1.4593155\ttotal: 9.63s\tremaining: 4.53s\n",
      "680:\tlearn: 1.4593155\ttotal: 9.65s\tremaining: 4.52s\n",
      "681:\tlearn: 1.4593045\ttotal: 9.66s\tremaining: 4.5s\n",
      "682:\tlearn: 1.4585345\ttotal: 9.68s\tremaining: 4.49s\n",
      "683:\tlearn: 1.4583442\ttotal: 9.69s\tremaining: 4.48s\n",
      "684:\tlearn: 1.4578776\ttotal: 9.7s\tremaining: 4.46s\n",
      "685:\tlearn: 1.4574901\ttotal: 9.72s\tremaining: 4.45s\n",
      "686:\tlearn: 1.4566765\ttotal: 9.73s\tremaining: 4.43s\n",
      "687:\tlearn: 1.4566260\ttotal: 9.74s\tremaining: 4.42s\n",
      "688:\tlearn: 1.4566065\ttotal: 9.76s\tremaining: 4.4s\n",
      "689:\tlearn: 1.4565567\ttotal: 9.77s\tremaining: 4.39s\n",
      "690:\tlearn: 1.4564414\ttotal: 9.78s\tremaining: 4.38s\n",
      "691:\tlearn: 1.4558637\ttotal: 9.8s\tremaining: 4.36s\n",
      "692:\tlearn: 1.4555156\ttotal: 9.81s\tremaining: 4.35s\n",
      "693:\tlearn: 1.4554740\ttotal: 9.83s\tremaining: 4.33s\n",
      "694:\tlearn: 1.4550351\ttotal: 9.84s\tremaining: 4.32s\n",
      "695:\tlearn: 1.4549769\ttotal: 9.85s\tremaining: 4.3s\n",
      "696:\tlearn: 1.4548294\ttotal: 9.87s\tremaining: 4.29s\n",
      "697:\tlearn: 1.4547859\ttotal: 9.88s\tremaining: 4.28s\n",
      "698:\tlearn: 1.4547859\ttotal: 9.9s\tremaining: 4.26s\n",
      "699:\tlearn: 1.4547603\ttotal: 9.91s\tremaining: 4.25s\n",
      "700:\tlearn: 1.4545174\ttotal: 9.92s\tremaining: 4.23s\n",
      "701:\tlearn: 1.4540000\ttotal: 9.94s\tremaining: 4.22s\n",
      "702:\tlearn: 1.4539205\ttotal: 9.95s\tremaining: 4.21s\n",
      "703:\tlearn: 1.4536718\ttotal: 9.97s\tremaining: 4.19s\n",
      "704:\tlearn: 1.4536435\ttotal: 9.98s\tremaining: 4.18s\n",
      "705:\tlearn: 1.4536422\ttotal: 9.99s\tremaining: 4.16s\n",
      "706:\tlearn: 1.4536418\ttotal: 10s\tremaining: 4.15s\n",
      "707:\tlearn: 1.4536342\ttotal: 10s\tremaining: 4.13s\n",
      "708:\tlearn: 1.4534393\ttotal: 10s\tremaining: 4.12s\n",
      "709:\tlearn: 1.4531478\ttotal: 10s\tremaining: 4.1s\n",
      "710:\tlearn: 1.4531478\ttotal: 10.1s\tremaining: 4.09s\n",
      "711:\tlearn: 1.4531251\ttotal: 10.1s\tremaining: 4.08s\n",
      "712:\tlearn: 1.4531251\ttotal: 10.1s\tremaining: 4.06s\n",
      "713:\tlearn: 1.4531251\ttotal: 10.1s\tremaining: 4.05s\n",
      "714:\tlearn: 1.4531052\ttotal: 10.1s\tremaining: 4.03s\n",
      "715:\tlearn: 1.4531052\ttotal: 10.1s\tremaining: 4.02s\n",
      "716:\tlearn: 1.4531052\ttotal: 10.1s\tremaining: 4s\n",
      "717:\tlearn: 1.4531052\ttotal: 10.2s\tremaining: 3.99s\n",
      "718:\tlearn: 1.4530617\ttotal: 10.2s\tremaining: 3.97s\n",
      "719:\tlearn: 1.4530519\ttotal: 10.2s\tremaining: 3.96s\n",
      "720:\tlearn: 1.4530257\ttotal: 10.2s\tremaining: 3.95s\n",
      "721:\tlearn: 1.4529893\ttotal: 10.2s\tremaining: 3.93s\n",
      "722:\tlearn: 1.4529876\ttotal: 10.2s\tremaining: 3.92s\n",
      "723:\tlearn: 1.4529874\ttotal: 10.2s\tremaining: 3.9s\n",
      "724:\tlearn: 1.4529874\ttotal: 10.3s\tremaining: 3.89s\n",
      "725:\tlearn: 1.4529749\ttotal: 10.3s\tremaining: 3.87s\n",
      "726:\tlearn: 1.4529110\ttotal: 10.3s\tremaining: 3.86s\n",
      "727:\tlearn: 1.4528942\ttotal: 10.3s\tremaining: 3.85s\n",
      "728:\tlearn: 1.4525220\ttotal: 10.3s\tremaining: 3.83s\n",
      "729:\tlearn: 1.4524240\ttotal: 10.3s\tremaining: 3.82s\n",
      "730:\tlearn: 1.4516351\ttotal: 10.3s\tremaining: 3.8s\n",
      "731:\tlearn: 1.4508472\ttotal: 10.3s\tremaining: 3.79s\n",
      "732:\tlearn: 1.4506879\ttotal: 10.4s\tremaining: 3.77s\n",
      "733:\tlearn: 1.4502022\ttotal: 10.4s\tremaining: 3.76s\n",
      "734:\tlearn: 1.4501881\ttotal: 10.4s\tremaining: 3.75s\n",
      "735:\tlearn: 1.4499951\ttotal: 10.4s\tremaining: 3.73s\n",
      "736:\tlearn: 1.4499895\ttotal: 10.4s\tremaining: 3.72s\n",
      "737:\tlearn: 1.4499702\ttotal: 10.4s\tremaining: 3.7s\n",
      "738:\tlearn: 1.4497924\ttotal: 10.4s\tremaining: 3.69s\n",
      "739:\tlearn: 1.4497916\ttotal: 10.5s\tremaining: 3.67s\n",
      "740:\tlearn: 1.4497908\ttotal: 10.5s\tremaining: 3.66s\n",
      "741:\tlearn: 1.4497908\ttotal: 10.5s\tremaining: 3.64s\n",
      "742:\tlearn: 1.4497778\ttotal: 10.5s\tremaining: 3.63s\n",
      "743:\tlearn: 1.4497774\ttotal: 10.5s\tremaining: 3.62s\n",
      "744:\tlearn: 1.4497771\ttotal: 10.5s\tremaining: 3.6s\n",
      "745:\tlearn: 1.4497770\ttotal: 10.5s\tremaining: 3.59s\n",
      "746:\tlearn: 1.4497759\ttotal: 10.6s\tremaining: 3.57s\n",
      "747:\tlearn: 1.4497759\ttotal: 10.6s\tremaining: 3.56s\n",
      "748:\tlearn: 1.4497758\ttotal: 10.6s\tremaining: 3.54s\n",
      "749:\tlearn: 1.4493852\ttotal: 10.6s\tremaining: 3.53s\n",
      "750:\tlearn: 1.4491248\ttotal: 10.6s\tremaining: 3.52s\n",
      "751:\tlearn: 1.4490754\ttotal: 10.6s\tremaining: 3.5s\n",
      "752:\tlearn: 1.4490678\ttotal: 10.6s\tremaining: 3.49s\n",
      "753:\tlearn: 1.4486374\ttotal: 10.6s\tremaining: 3.47s\n",
      "754:\tlearn: 1.4483058\ttotal: 10.7s\tremaining: 3.46s\n",
      "755:\tlearn: 1.4480609\ttotal: 10.7s\tremaining: 3.45s\n",
      "756:\tlearn: 1.4480414\ttotal: 10.7s\tremaining: 3.43s\n",
      "757:\tlearn: 1.4480414\ttotal: 10.7s\tremaining: 3.42s\n",
      "758:\tlearn: 1.4480413\ttotal: 10.7s\tremaining: 3.4s\n",
      "759:\tlearn: 1.4480413\ttotal: 10.7s\tremaining: 3.39s\n",
      "760:\tlearn: 1.4480413\ttotal: 10.7s\tremaining: 3.38s\n",
      "761:\tlearn: 1.4474131\ttotal: 10.8s\tremaining: 3.36s\n",
      "762:\tlearn: 1.4473831\ttotal: 10.8s\tremaining: 3.35s\n",
      "763:\tlearn: 1.4473064\ttotal: 10.8s\tremaining: 3.33s\n",
      "764:\tlearn: 1.4471731\ttotal: 10.8s\tremaining: 3.32s\n",
      "765:\tlearn: 1.4469585\ttotal: 10.8s\tremaining: 3.3s\n",
      "766:\tlearn: 1.4469564\ttotal: 10.8s\tremaining: 3.29s\n",
      "767:\tlearn: 1.4468896\ttotal: 10.8s\tremaining: 3.28s\n",
      "768:\tlearn: 1.4468716\ttotal: 10.9s\tremaining: 3.26s\n",
      "769:\tlearn: 1.4468714\ttotal: 10.9s\tremaining: 3.25s\n",
      "770:\tlearn: 1.4468453\ttotal: 10.9s\tremaining: 3.23s\n",
      "771:\tlearn: 1.4468147\ttotal: 10.9s\tremaining: 3.22s\n",
      "772:\tlearn: 1.4468127\ttotal: 10.9s\tremaining: 3.21s\n",
      "773:\tlearn: 1.4468110\ttotal: 10.9s\tremaining: 3.19s\n",
      "774:\tlearn: 1.4468110\ttotal: 10.9s\tremaining: 3.18s\n",
      "775:\tlearn: 1.4468109\ttotal: 11s\tremaining: 3.16s\n",
      "776:\tlearn: 1.4468106\ttotal: 11s\tremaining: 3.15s\n",
      "777:\tlearn: 1.4468084\ttotal: 11s\tremaining: 3.13s\n",
      "778:\tlearn: 1.4468080\ttotal: 11s\tremaining: 3.12s\n",
      "779:\tlearn: 1.4468077\ttotal: 11s\tremaining: 3.11s\n",
      "780:\tlearn: 1.4463569\ttotal: 11s\tremaining: 3.09s\n",
      "781:\tlearn: 1.4463466\ttotal: 11s\tremaining: 3.08s\n",
      "782:\tlearn: 1.4463466\ttotal: 11.1s\tremaining: 3.06s\n",
      "783:\tlearn: 1.4463466\ttotal: 11.1s\tremaining: 3.05s\n",
      "784:\tlearn: 1.4463381\ttotal: 11.1s\tremaining: 3.03s\n",
      "785:\tlearn: 1.4463381\ttotal: 11.1s\tremaining: 3.02s\n",
      "786:\tlearn: 1.4463381\ttotal: 11.1s\tremaining: 3.01s\n",
      "787:\tlearn: 1.4461222\ttotal: 11.1s\tremaining: 2.99s\n",
      "788:\tlearn: 1.4458278\ttotal: 11.1s\tremaining: 2.98s\n",
      "789:\tlearn: 1.4457122\ttotal: 11.1s\tremaining: 2.96s\n",
      "790:\tlearn: 1.4456809\ttotal: 11.2s\tremaining: 2.95s\n",
      "791:\tlearn: 1.4456129\ttotal: 11.2s\tremaining: 2.94s\n",
      "792:\tlearn: 1.4456129\ttotal: 11.2s\tremaining: 2.92s\n",
      "793:\tlearn: 1.4456083\ttotal: 11.2s\tremaining: 2.91s\n",
      "794:\tlearn: 1.4455503\ttotal: 11.2s\tremaining: 2.89s\n",
      "795:\tlearn: 1.4449112\ttotal: 11.2s\tremaining: 2.88s\n",
      "796:\tlearn: 1.4447315\ttotal: 11.2s\tremaining: 2.86s\n",
      "797:\tlearn: 1.4436842\ttotal: 11.3s\tremaining: 2.85s\n",
      "798:\tlearn: 1.4433208\ttotal: 11.3s\tremaining: 2.84s\n",
      "799:\tlearn: 1.4428558\ttotal: 11.3s\tremaining: 2.82s\n",
      "800:\tlearn: 1.4428558\ttotal: 11.3s\tremaining: 2.81s\n",
      "801:\tlearn: 1.4428558\ttotal: 11.3s\tremaining: 2.79s\n",
      "802:\tlearn: 1.4427753\ttotal: 11.3s\tremaining: 2.78s\n",
      "803:\tlearn: 1.4427370\ttotal: 11.3s\tremaining: 2.77s\n",
      "804:\tlearn: 1.4427243\ttotal: 11.4s\tremaining: 2.75s\n",
      "805:\tlearn: 1.4421201\ttotal: 11.4s\tremaining: 2.74s\n",
      "806:\tlearn: 1.4419534\ttotal: 11.4s\tremaining: 2.72s\n",
      "807:\tlearn: 1.4418546\ttotal: 11.4s\tremaining: 2.71s\n",
      "808:\tlearn: 1.4412153\ttotal: 11.4s\tremaining: 2.69s\n",
      "809:\tlearn: 1.4412057\ttotal: 11.4s\tremaining: 2.68s\n",
      "810:\tlearn: 1.4412054\ttotal: 11.4s\tremaining: 2.67s\n",
      "811:\tlearn: 1.4411570\ttotal: 11.5s\tremaining: 2.65s\n",
      "812:\tlearn: 1.4411528\ttotal: 11.5s\tremaining: 2.64s\n",
      "813:\tlearn: 1.4411340\ttotal: 11.5s\tremaining: 2.62s\n",
      "814:\tlearn: 1.4409021\ttotal: 11.5s\tremaining: 2.61s\n",
      "815:\tlearn: 1.4407006\ttotal: 11.5s\tremaining: 2.6s\n",
      "816:\tlearn: 1.4406937\ttotal: 11.5s\tremaining: 2.58s\n",
      "817:\tlearn: 1.4406888\ttotal: 11.5s\tremaining: 2.57s\n",
      "818:\tlearn: 1.4406614\ttotal: 11.6s\tremaining: 2.55s\n",
      "819:\tlearn: 1.4406416\ttotal: 11.6s\tremaining: 2.54s\n",
      "820:\tlearn: 1.4406180\ttotal: 11.6s\tremaining: 2.52s\n",
      "821:\tlearn: 1.4403724\ttotal: 11.6s\tremaining: 2.51s\n",
      "822:\tlearn: 1.4403718\ttotal: 11.6s\tremaining: 2.5s\n",
      "823:\tlearn: 1.4403718\ttotal: 11.6s\tremaining: 2.48s\n",
      "824:\tlearn: 1.4403716\ttotal: 11.6s\tremaining: 2.47s\n",
      "825:\tlearn: 1.4402761\ttotal: 11.6s\tremaining: 2.45s\n",
      "826:\tlearn: 1.4400590\ttotal: 11.7s\tremaining: 2.44s\n",
      "827:\tlearn: 1.4400133\ttotal: 11.7s\tremaining: 2.42s\n",
      "828:\tlearn: 1.4399948\ttotal: 11.7s\tremaining: 2.41s\n",
      "829:\tlearn: 1.4399195\ttotal: 11.7s\tremaining: 2.4s\n",
      "830:\tlearn: 1.4399121\ttotal: 11.7s\tremaining: 2.38s\n",
      "831:\tlearn: 1.4399115\ttotal: 11.7s\tremaining: 2.37s\n",
      "832:\tlearn: 1.4399114\ttotal: 11.7s\tremaining: 2.35s\n",
      "833:\tlearn: 1.4398950\ttotal: 11.8s\tremaining: 2.34s\n",
      "834:\tlearn: 1.4398805\ttotal: 11.8s\tremaining: 2.33s\n",
      "835:\tlearn: 1.4397176\ttotal: 11.8s\tremaining: 2.31s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836:\tlearn: 1.4394311\ttotal: 11.8s\tremaining: 2.3s\n",
      "837:\tlearn: 1.4391105\ttotal: 11.8s\tremaining: 2.28s\n",
      "838:\tlearn: 1.4386626\ttotal: 11.8s\tremaining: 2.27s\n",
      "839:\tlearn: 1.4385998\ttotal: 11.8s\tremaining: 2.26s\n",
      "840:\tlearn: 1.4384960\ttotal: 11.9s\tremaining: 2.24s\n",
      "841:\tlearn: 1.4384930\ttotal: 11.9s\tremaining: 2.23s\n",
      "842:\tlearn: 1.4384429\ttotal: 11.9s\tremaining: 2.21s\n",
      "843:\tlearn: 1.4383800\ttotal: 11.9s\tremaining: 2.2s\n",
      "844:\tlearn: 1.4383373\ttotal: 11.9s\tremaining: 2.19s\n",
      "845:\tlearn: 1.4380541\ttotal: 11.9s\tremaining: 2.17s\n",
      "846:\tlearn: 1.4379657\ttotal: 11.9s\tremaining: 2.16s\n",
      "847:\tlearn: 1.4372534\ttotal: 12s\tremaining: 2.14s\n",
      "848:\tlearn: 1.4372156\ttotal: 12s\tremaining: 2.13s\n",
      "849:\tlearn: 1.4370824\ttotal: 12s\tremaining: 2.11s\n",
      "850:\tlearn: 1.4370760\ttotal: 12s\tremaining: 2.1s\n",
      "851:\tlearn: 1.4370711\ttotal: 12s\tremaining: 2.09s\n",
      "852:\tlearn: 1.4370708\ttotal: 12s\tremaining: 2.07s\n",
      "853:\tlearn: 1.4370704\ttotal: 12s\tremaining: 2.06s\n",
      "854:\tlearn: 1.4369730\ttotal: 12.1s\tremaining: 2.04s\n",
      "855:\tlearn: 1.4369163\ttotal: 12.1s\tremaining: 2.03s\n",
      "856:\tlearn: 1.4369135\ttotal: 12.1s\tremaining: 2.02s\n",
      "857:\tlearn: 1.4368519\ttotal: 12.1s\tremaining: 2s\n",
      "858:\tlearn: 1.4368490\ttotal: 12.1s\tremaining: 1.99s\n",
      "859:\tlearn: 1.4368485\ttotal: 12.1s\tremaining: 1.97s\n",
      "860:\tlearn: 1.4364874\ttotal: 12.1s\tremaining: 1.96s\n",
      "861:\tlearn: 1.4364868\ttotal: 12.2s\tremaining: 1.95s\n",
      "862:\tlearn: 1.4364712\ttotal: 12.2s\tremaining: 1.93s\n",
      "863:\tlearn: 1.4362021\ttotal: 12.2s\tremaining: 1.92s\n",
      "864:\tlearn: 1.4360409\ttotal: 12.2s\tremaining: 1.9s\n",
      "865:\tlearn: 1.4359395\ttotal: 12.2s\tremaining: 1.89s\n",
      "866:\tlearn: 1.4358441\ttotal: 12.2s\tremaining: 1.87s\n",
      "867:\tlearn: 1.4358245\ttotal: 12.2s\tremaining: 1.86s\n",
      "868:\tlearn: 1.4358245\ttotal: 12.2s\tremaining: 1.85s\n",
      "869:\tlearn: 1.4357902\ttotal: 12.3s\tremaining: 1.83s\n",
      "870:\tlearn: 1.4357464\ttotal: 12.3s\tremaining: 1.82s\n",
      "871:\tlearn: 1.4357464\ttotal: 12.3s\tremaining: 1.8s\n",
      "872:\tlearn: 1.4357429\ttotal: 12.3s\tremaining: 1.79s\n",
      "873:\tlearn: 1.4356273\ttotal: 12.3s\tremaining: 1.77s\n",
      "874:\tlearn: 1.4356246\ttotal: 12.3s\tremaining: 1.76s\n",
      "875:\tlearn: 1.4354741\ttotal: 12.3s\tremaining: 1.75s\n",
      "876:\tlearn: 1.4352950\ttotal: 12.4s\tremaining: 1.73s\n",
      "877:\tlearn: 1.4349662\ttotal: 12.4s\tremaining: 1.72s\n",
      "878:\tlearn: 1.4346433\ttotal: 12.4s\tremaining: 1.7s\n",
      "879:\tlearn: 1.4342259\ttotal: 12.4s\tremaining: 1.69s\n",
      "880:\tlearn: 1.4342218\ttotal: 12.4s\tremaining: 1.68s\n",
      "881:\tlearn: 1.4342218\ttotal: 12.4s\tremaining: 1.66s\n",
      "882:\tlearn: 1.4341899\ttotal: 12.4s\tremaining: 1.65s\n",
      "883:\tlearn: 1.4341689\ttotal: 12.5s\tremaining: 1.63s\n",
      "884:\tlearn: 1.4340885\ttotal: 12.5s\tremaining: 1.62s\n",
      "885:\tlearn: 1.4340387\ttotal: 12.5s\tremaining: 1.61s\n",
      "886:\tlearn: 1.4340370\ttotal: 12.5s\tremaining: 1.59s\n",
      "887:\tlearn: 1.4339503\ttotal: 12.5s\tremaining: 1.58s\n",
      "888:\tlearn: 1.4338503\ttotal: 12.5s\tremaining: 1.56s\n",
      "889:\tlearn: 1.4337319\ttotal: 12.5s\tremaining: 1.55s\n",
      "890:\tlearn: 1.4332970\ttotal: 12.6s\tremaining: 1.53s\n",
      "891:\tlearn: 1.4332932\ttotal: 12.6s\tremaining: 1.52s\n",
      "892:\tlearn: 1.4332777\ttotal: 12.6s\tremaining: 1.51s\n",
      "893:\tlearn: 1.4332496\ttotal: 12.6s\tremaining: 1.49s\n",
      "894:\tlearn: 1.4332344\ttotal: 12.6s\tremaining: 1.48s\n",
      "895:\tlearn: 1.4331687\ttotal: 12.6s\tremaining: 1.46s\n",
      "896:\tlearn: 1.4331644\ttotal: 12.6s\tremaining: 1.45s\n",
      "897:\tlearn: 1.4330821\ttotal: 12.6s\tremaining: 1.44s\n",
      "898:\tlearn: 1.4330177\ttotal: 12.7s\tremaining: 1.42s\n",
      "899:\tlearn: 1.4328060\ttotal: 12.7s\tremaining: 1.41s\n",
      "900:\tlearn: 1.4328055\ttotal: 12.7s\tremaining: 1.39s\n",
      "901:\tlearn: 1.4321329\ttotal: 12.7s\tremaining: 1.38s\n",
      "902:\tlearn: 1.4321302\ttotal: 12.7s\tremaining: 1.36s\n",
      "903:\tlearn: 1.4320916\ttotal: 12.7s\tremaining: 1.35s\n",
      "904:\tlearn: 1.4320673\ttotal: 12.7s\tremaining: 1.34s\n",
      "905:\tlearn: 1.4315894\ttotal: 12.8s\tremaining: 1.32s\n",
      "906:\tlearn: 1.4311671\ttotal: 12.8s\tremaining: 1.31s\n",
      "907:\tlearn: 1.4308636\ttotal: 12.8s\tremaining: 1.29s\n",
      "908:\tlearn: 1.4304676\ttotal: 12.8s\tremaining: 1.28s\n",
      "909:\tlearn: 1.4304268\ttotal: 12.8s\tremaining: 1.27s\n",
      "910:\tlearn: 1.4301427\ttotal: 12.8s\tremaining: 1.25s\n",
      "911:\tlearn: 1.4301183\ttotal: 12.8s\tremaining: 1.24s\n",
      "912:\tlearn: 1.4301181\ttotal: 12.8s\tremaining: 1.22s\n",
      "913:\tlearn: 1.4301181\ttotal: 12.9s\tremaining: 1.21s\n",
      "914:\tlearn: 1.4301160\ttotal: 12.9s\tremaining: 1.2s\n",
      "915:\tlearn: 1.4295567\ttotal: 12.9s\tremaining: 1.18s\n",
      "916:\tlearn: 1.4295511\ttotal: 12.9s\tremaining: 1.17s\n",
      "917:\tlearn: 1.4289237\ttotal: 12.9s\tremaining: 1.15s\n",
      "918:\tlearn: 1.4289119\ttotal: 12.9s\tremaining: 1.14s\n",
      "919:\tlearn: 1.4288900\ttotal: 12.9s\tremaining: 1.13s\n",
      "920:\tlearn: 1.4286618\ttotal: 13s\tremaining: 1.11s\n",
      "921:\tlearn: 1.4286458\ttotal: 13s\tremaining: 1.1s\n",
      "922:\tlearn: 1.4286386\ttotal: 13s\tremaining: 1.08s\n",
      "923:\tlearn: 1.4286345\ttotal: 13s\tremaining: 1.07s\n",
      "924:\tlearn: 1.4283614\ttotal: 13s\tremaining: 1.05s\n",
      "925:\tlearn: 1.4283431\ttotal: 13s\tremaining: 1.04s\n",
      "926:\tlearn: 1.4278354\ttotal: 13s\tremaining: 1.03s\n",
      "927:\tlearn: 1.4275659\ttotal: 13.1s\tremaining: 1.01s\n",
      "928:\tlearn: 1.4275379\ttotal: 13.1s\tremaining: 999ms\n",
      "929:\tlearn: 1.4274746\ttotal: 13.1s\tremaining: 985ms\n",
      "930:\tlearn: 1.4269330\ttotal: 13.1s\tremaining: 971ms\n",
      "931:\tlearn: 1.4265290\ttotal: 13.1s\tremaining: 957ms\n",
      "932:\tlearn: 1.4263380\ttotal: 13.1s\tremaining: 943ms\n",
      "933:\tlearn: 1.4260744\ttotal: 13.1s\tremaining: 929ms\n",
      "934:\tlearn: 1.4260638\ttotal: 13.2s\tremaining: 915ms\n",
      "935:\tlearn: 1.4260469\ttotal: 13.2s\tremaining: 900ms\n",
      "936:\tlearn: 1.4258804\ttotal: 13.2s\tremaining: 886ms\n",
      "937:\tlearn: 1.4258753\ttotal: 13.2s\tremaining: 873ms\n",
      "938:\tlearn: 1.4249645\ttotal: 13.2s\tremaining: 859ms\n",
      "939:\tlearn: 1.4249553\ttotal: 13.2s\tremaining: 845ms\n",
      "940:\tlearn: 1.4249433\ttotal: 13.3s\tremaining: 832ms\n",
      "941:\tlearn: 1.4249431\ttotal: 13.3s\tremaining: 817ms\n",
      "942:\tlearn: 1.4249333\ttotal: 13.3s\tremaining: 803ms\n",
      "943:\tlearn: 1.4249077\ttotal: 13.3s\tremaining: 789ms\n",
      "944:\tlearn: 1.4249009\ttotal: 13.3s\tremaining: 775ms\n",
      "945:\tlearn: 1.4249009\ttotal: 13.3s\tremaining: 761ms\n",
      "946:\tlearn: 1.4246198\ttotal: 13.3s\tremaining: 747ms\n",
      "947:\tlearn: 1.4245548\ttotal: 13.4s\tremaining: 733ms\n",
      "948:\tlearn: 1.4245509\ttotal: 13.4s\tremaining: 719ms\n",
      "949:\tlearn: 1.4245502\ttotal: 13.4s\tremaining: 705ms\n",
      "950:\tlearn: 1.4245500\ttotal: 13.4s\tremaining: 691ms\n",
      "951:\tlearn: 1.4245333\ttotal: 13.4s\tremaining: 677ms\n",
      "952:\tlearn: 1.4245219\ttotal: 13.4s\tremaining: 662ms\n",
      "953:\tlearn: 1.4245217\ttotal: 13.4s\tremaining: 648ms\n",
      "954:\tlearn: 1.4243353\ttotal: 13.5s\tremaining: 634ms\n",
      "955:\tlearn: 1.4243314\ttotal: 13.5s\tremaining: 620ms\n",
      "956:\tlearn: 1.4243314\ttotal: 13.5s\tremaining: 606ms\n",
      "957:\tlearn: 1.4243272\ttotal: 13.5s\tremaining: 592ms\n",
      "958:\tlearn: 1.4243270\ttotal: 13.5s\tremaining: 578ms\n",
      "959:\tlearn: 1.4243149\ttotal: 13.5s\tremaining: 564ms\n",
      "960:\tlearn: 1.4242213\ttotal: 13.5s\tremaining: 550ms\n",
      "961:\tlearn: 1.4242078\ttotal: 13.6s\tremaining: 536ms\n",
      "962:\tlearn: 1.4239123\ttotal: 13.6s\tremaining: 521ms\n",
      "963:\tlearn: 1.4238812\ttotal: 13.6s\tremaining: 507ms\n",
      "964:\tlearn: 1.4238800\ttotal: 13.6s\tremaining: 493ms\n",
      "965:\tlearn: 1.4235928\ttotal: 13.6s\tremaining: 479ms\n",
      "966:\tlearn: 1.4235034\ttotal: 13.6s\tremaining: 465ms\n",
      "967:\tlearn: 1.4234932\ttotal: 13.6s\tremaining: 451ms\n",
      "968:\tlearn: 1.4234903\ttotal: 13.7s\tremaining: 437ms\n",
      "969:\tlearn: 1.4233046\ttotal: 13.7s\tremaining: 423ms\n",
      "970:\tlearn: 1.4232976\ttotal: 13.7s\tremaining: 409ms\n",
      "971:\tlearn: 1.4231757\ttotal: 13.7s\tremaining: 395ms\n",
      "972:\tlearn: 1.4231693\ttotal: 13.7s\tremaining: 380ms\n",
      "973:\tlearn: 1.4229106\ttotal: 13.7s\tremaining: 366ms\n",
      "974:\tlearn: 1.4227480\ttotal: 13.7s\tremaining: 352ms\n",
      "975:\tlearn: 1.4227449\ttotal: 13.8s\tremaining: 338ms\n",
      "976:\tlearn: 1.4224691\ttotal: 13.8s\tremaining: 324ms\n",
      "977:\tlearn: 1.4224454\ttotal: 13.8s\tremaining: 310ms\n",
      "978:\tlearn: 1.4221296\ttotal: 13.8s\tremaining: 296ms\n",
      "979:\tlearn: 1.4218117\ttotal: 13.8s\tremaining: 282ms\n",
      "980:\tlearn: 1.4217741\ttotal: 13.8s\tremaining: 268ms\n",
      "981:\tlearn: 1.4217529\ttotal: 13.8s\tremaining: 254ms\n",
      "982:\tlearn: 1.4217301\ttotal: 13.8s\tremaining: 239ms\n",
      "983:\tlearn: 1.4215865\ttotal: 13.9s\tremaining: 225ms\n",
      "984:\tlearn: 1.4215490\ttotal: 13.9s\tremaining: 211ms\n",
      "985:\tlearn: 1.4213931\ttotal: 13.9s\tremaining: 197ms\n",
      "986:\tlearn: 1.4213665\ttotal: 13.9s\tremaining: 183ms\n",
      "987:\tlearn: 1.4209686\ttotal: 13.9s\tremaining: 169ms\n",
      "988:\tlearn: 1.4208440\ttotal: 13.9s\tremaining: 155ms\n",
      "989:\tlearn: 1.4208390\ttotal: 13.9s\tremaining: 141ms\n",
      "990:\tlearn: 1.4208389\ttotal: 14s\tremaining: 127ms\n",
      "991:\tlearn: 1.4203988\ttotal: 14s\tremaining: 113ms\n",
      "992:\tlearn: 1.4203920\ttotal: 14s\tremaining: 98.6ms\n",
      "993:\tlearn: 1.4203802\ttotal: 14s\tremaining: 84.5ms\n",
      "994:\tlearn: 1.4200669\ttotal: 14s\tremaining: 70.5ms\n",
      "995:\tlearn: 1.4200557\ttotal: 14s\tremaining: 56.4ms\n",
      "996:\tlearn: 1.4196327\ttotal: 14s\tremaining: 42.3ms\n",
      "997:\tlearn: 1.4196324\ttotal: 14.1s\tremaining: 28.2ms\n",
      "998:\tlearn: 1.4196311\ttotal: 14.1s\tremaining: 14.1ms\n",
      "999:\tlearn: 1.4195533\ttotal: 14.1s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 7.7363396\ttotal: 17.1ms\tremaining: 17s\n",
      "1:\tlearn: 7.1942445\ttotal: 34.8ms\tremaining: 17.4s\n",
      "2:\tlearn: 6.6802956\ttotal: 52.6ms\tremaining: 17.5s\n",
      "3:\tlearn: 6.2028020\ttotal: 70.4ms\tremaining: 17.5s\n",
      "4:\tlearn: 5.7018303\ttotal: 88.5ms\tremaining: 17.6s\n",
      "5:\tlearn: 5.3417593\ttotal: 107ms\tremaining: 17.7s\n",
      "6:\tlearn: 4.9361376\ttotal: 124ms\tremaining: 17.6s\n",
      "7:\tlearn: 4.5860986\ttotal: 142ms\tremaining: 17.5s\n",
      "8:\tlearn: 4.2543175\ttotal: 158ms\tremaining: 17.4s\n",
      "9:\tlearn: 3.9421313\ttotal: 176ms\tremaining: 17.4s\n",
      "10:\tlearn: 3.6916733\ttotal: 195ms\tremaining: 17.5s\n",
      "11:\tlearn: 3.5131462\ttotal: 212ms\tremaining: 17.5s\n",
      "12:\tlearn: 3.3557144\ttotal: 231ms\tremaining: 17.5s\n",
      "13:\tlearn: 3.1571921\ttotal: 249ms\tremaining: 17.5s\n",
      "14:\tlearn: 3.0417049\ttotal: 267ms\tremaining: 17.5s\n",
      "15:\tlearn: 2.9387032\ttotal: 284ms\tremaining: 17.5s\n",
      "16:\tlearn: 2.8037035\ttotal: 303ms\tremaining: 17.5s\n",
      "17:\tlearn: 2.6825430\ttotal: 319ms\tremaining: 17.4s\n",
      "18:\tlearn: 2.6131815\ttotal: 336ms\tremaining: 17.4s\n",
      "19:\tlearn: 2.5164971\ttotal: 354ms\tremaining: 17.4s\n",
      "20:\tlearn: 2.4673435\ttotal: 373ms\tremaining: 17.4s\n",
      "21:\tlearn: 2.4188497\ttotal: 391ms\tremaining: 17.4s\n",
      "22:\tlearn: 2.3798825\ttotal: 410ms\tremaining: 17.4s\n",
      "23:\tlearn: 2.3121073\ttotal: 429ms\tremaining: 17.4s\n",
      "24:\tlearn: 2.2592076\ttotal: 447ms\tremaining: 17.4s\n",
      "25:\tlearn: 2.2327586\ttotal: 464ms\tremaining: 17.4s\n",
      "26:\tlearn: 2.2094816\ttotal: 479ms\tremaining: 17.3s\n",
      "27:\tlearn: 2.1692380\ttotal: 496ms\tremaining: 17.2s\n",
      "28:\tlearn: 2.1513174\ttotal: 513ms\tremaining: 17.2s\n",
      "29:\tlearn: 2.1126676\ttotal: 529ms\tremaining: 17.1s\n",
      "30:\tlearn: 2.0980670\ttotal: 545ms\tremaining: 17s\n",
      "31:\tlearn: 2.0844858\ttotal: 561ms\tremaining: 17s\n",
      "32:\tlearn: 2.0575448\ttotal: 577ms\tremaining: 16.9s\n",
      "33:\tlearn: 2.0332401\ttotal: 592ms\tremaining: 16.8s\n",
      "34:\tlearn: 2.0251430\ttotal: 609ms\tremaining: 16.8s\n",
      "35:\tlearn: 2.0158696\ttotal: 626ms\tremaining: 16.8s\n",
      "36:\tlearn: 1.9997434\ttotal: 642ms\tremaining: 16.7s\n",
      "37:\tlearn: 1.9798144\ttotal: 660ms\tremaining: 16.7s\n",
      "38:\tlearn: 1.9750801\ttotal: 677ms\tremaining: 16.7s\n",
      "39:\tlearn: 1.9709956\ttotal: 693ms\tremaining: 16.6s\n",
      "40:\tlearn: 1.9643633\ttotal: 709ms\tremaining: 16.6s\n",
      "41:\tlearn: 1.9594847\ttotal: 726ms\tremaining: 16.6s\n",
      "42:\tlearn: 1.9559500\ttotal: 742ms\tremaining: 16.5s\n",
      "43:\tlearn: 1.9546472\ttotal: 758ms\tremaining: 16.5s\n",
      "44:\tlearn: 1.9527022\ttotal: 774ms\tremaining: 16.4s\n",
      "45:\tlearn: 1.9503985\ttotal: 791ms\tremaining: 16.4s\n",
      "46:\tlearn: 1.9437658\ttotal: 808ms\tremaining: 16.4s\n",
      "47:\tlearn: 1.9408190\ttotal: 824ms\tremaining: 16.3s\n",
      "48:\tlearn: 1.9370822\ttotal: 840ms\tremaining: 16.3s\n",
      "49:\tlearn: 1.9350379\ttotal: 857ms\tremaining: 16.3s\n",
      "50:\tlearn: 1.9344470\ttotal: 874ms\tremaining: 16.3s\n",
      "51:\tlearn: 1.9320180\ttotal: 892ms\tremaining: 16.3s\n",
      "52:\tlearn: 1.9318358\ttotal: 908ms\tremaining: 16.2s\n",
      "53:\tlearn: 1.9308543\ttotal: 924ms\tremaining: 16.2s\n",
      "54:\tlearn: 1.9237713\ttotal: 940ms\tremaining: 16.2s\n",
      "55:\tlearn: 1.9085301\ttotal: 957ms\tremaining: 16.1s\n",
      "56:\tlearn: 1.9055188\ttotal: 973ms\tremaining: 16.1s\n",
      "57:\tlearn: 1.9044848\ttotal: 989ms\tremaining: 16.1s\n",
      "58:\tlearn: 1.9043663\ttotal: 1s\tremaining: 16s\n",
      "59:\tlearn: 1.9035879\ttotal: 1.02s\tremaining: 16s\n",
      "60:\tlearn: 1.9032118\ttotal: 1.04s\tremaining: 16s\n",
      "61:\tlearn: 1.9026836\ttotal: 1.05s\tremaining: 16s\n",
      "62:\tlearn: 1.9015586\ttotal: 1.07s\tremaining: 15.9s\n",
      "63:\tlearn: 1.8999190\ttotal: 1.09s\tremaining: 15.9s\n",
      "64:\tlearn: 1.8995865\ttotal: 1.1s\tremaining: 15.9s\n",
      "65:\tlearn: 1.8993495\ttotal: 1.12s\tremaining: 15.9s\n",
      "66:\tlearn: 1.8985254\ttotal: 1.14s\tremaining: 15.8s\n",
      "67:\tlearn: 1.8952995\ttotal: 1.15s\tremaining: 15.8s\n",
      "68:\tlearn: 1.8908065\ttotal: 1.17s\tremaining: 15.8s\n",
      "69:\tlearn: 1.8893996\ttotal: 1.19s\tremaining: 15.8s\n",
      "70:\tlearn: 1.8892314\ttotal: 1.2s\tremaining: 15.7s\n",
      "71:\tlearn: 1.8890631\ttotal: 1.22s\tremaining: 15.7s\n",
      "72:\tlearn: 1.8887791\ttotal: 1.24s\tremaining: 15.7s\n",
      "73:\tlearn: 1.8885602\ttotal: 1.25s\tremaining: 15.7s\n",
      "74:\tlearn: 1.8881951\ttotal: 1.27s\tremaining: 15.7s\n",
      "75:\tlearn: 1.8873591\ttotal: 1.28s\tremaining: 15.6s\n",
      "76:\tlearn: 1.8859059\ttotal: 1.3s\tremaining: 15.6s\n",
      "77:\tlearn: 1.8858177\ttotal: 1.32s\tremaining: 15.6s\n",
      "78:\tlearn: 1.8850594\ttotal: 1.34s\tremaining: 15.6s\n",
      "79:\tlearn: 1.8747827\ttotal: 1.35s\tremaining: 15.6s\n",
      "80:\tlearn: 1.8729075\ttotal: 1.37s\tremaining: 15.6s\n",
      "81:\tlearn: 1.8640891\ttotal: 1.39s\tremaining: 15.5s\n",
      "82:\tlearn: 1.8637815\ttotal: 1.4s\tremaining: 15.5s\n",
      "83:\tlearn: 1.8634911\ttotal: 1.42s\tremaining: 15.5s\n",
      "84:\tlearn: 1.8599992\ttotal: 1.43s\tremaining: 15.4s\n",
      "85:\tlearn: 1.8597412\ttotal: 1.45s\tremaining: 15.4s\n",
      "86:\tlearn: 1.8595355\ttotal: 1.47s\tremaining: 15.4s\n",
      "87:\tlearn: 1.8587448\ttotal: 1.48s\tremaining: 15.4s\n",
      "88:\tlearn: 1.8575030\ttotal: 1.5s\tremaining: 15.4s\n",
      "89:\tlearn: 1.8562056\ttotal: 1.52s\tremaining: 15.4s\n",
      "90:\tlearn: 1.8559219\ttotal: 1.54s\tremaining: 15.3s\n",
      "91:\tlearn: 1.8545473\ttotal: 1.55s\tremaining: 15.3s\n",
      "92:\tlearn: 1.8545450\ttotal: 1.56s\tremaining: 15.3s\n",
      "93:\tlearn: 1.8538355\ttotal: 1.58s\tremaining: 15.2s\n",
      "94:\tlearn: 1.8534858\ttotal: 1.6s\tremaining: 15.2s\n",
      "95:\tlearn: 1.8533704\ttotal: 1.61s\tremaining: 15.2s\n",
      "96:\tlearn: 1.8533137\ttotal: 1.63s\tremaining: 15.2s\n",
      "97:\tlearn: 1.8524898\ttotal: 1.64s\tremaining: 15.1s\n",
      "98:\tlearn: 1.8432344\ttotal: 1.66s\tremaining: 15.1s\n",
      "99:\tlearn: 1.8429704\ttotal: 1.68s\tremaining: 15.1s\n",
      "100:\tlearn: 1.8427771\ttotal: 1.69s\tremaining: 15.1s\n",
      "101:\tlearn: 1.8405458\ttotal: 1.71s\tremaining: 15s\n",
      "102:\tlearn: 1.8404499\ttotal: 1.72s\tremaining: 15s\n",
      "103:\tlearn: 1.8312030\ttotal: 1.74s\tremaining: 15s\n",
      "104:\tlearn: 1.8303361\ttotal: 1.76s\tremaining: 15s\n",
      "105:\tlearn: 1.8299903\ttotal: 1.77s\tremaining: 15s\n",
      "106:\tlearn: 1.8298594\ttotal: 1.79s\tremaining: 14.9s\n",
      "107:\tlearn: 1.8275312\ttotal: 1.81s\tremaining: 14.9s\n",
      "108:\tlearn: 1.8269531\ttotal: 1.82s\tremaining: 14.9s\n",
      "109:\tlearn: 1.8268448\ttotal: 1.84s\tremaining: 14.9s\n",
      "110:\tlearn: 1.8264581\ttotal: 1.85s\tremaining: 14.9s\n",
      "111:\tlearn: 1.8259661\ttotal: 1.87s\tremaining: 14.8s\n",
      "112:\tlearn: 1.8251750\ttotal: 1.89s\tremaining: 14.8s\n",
      "113:\tlearn: 1.8250206\ttotal: 1.9s\tremaining: 14.8s\n",
      "114:\tlearn: 1.8249795\ttotal: 1.92s\tremaining: 14.8s\n",
      "115:\tlearn: 1.8234450\ttotal: 1.94s\tremaining: 14.8s\n",
      "116:\tlearn: 1.8205446\ttotal: 1.96s\tremaining: 14.8s\n",
      "117:\tlearn: 1.8201721\ttotal: 1.97s\tremaining: 14.7s\n",
      "118:\tlearn: 1.8198680\ttotal: 1.99s\tremaining: 14.7s\n",
      "119:\tlearn: 1.8099870\ttotal: 2s\tremaining: 14.7s\n",
      "120:\tlearn: 1.8066177\ttotal: 2.02s\tremaining: 14.7s\n",
      "121:\tlearn: 1.8005126\ttotal: 2.04s\tremaining: 14.7s\n",
      "122:\tlearn: 1.7961012\ttotal: 2.05s\tremaining: 14.6s\n",
      "123:\tlearn: 1.7956833\ttotal: 2.07s\tremaining: 14.6s\n",
      "124:\tlearn: 1.7905448\ttotal: 2.08s\tremaining: 14.6s\n",
      "125:\tlearn: 1.7891939\ttotal: 2.1s\tremaining: 14.6s\n",
      "126:\tlearn: 1.7886773\ttotal: 2.11s\tremaining: 14.5s\n",
      "127:\tlearn: 1.7873164\ttotal: 2.13s\tremaining: 14.5s\n",
      "128:\tlearn: 1.7848580\ttotal: 2.15s\tremaining: 14.5s\n",
      "129:\tlearn: 1.7763639\ttotal: 2.16s\tremaining: 14.5s\n",
      "130:\tlearn: 1.7757335\ttotal: 2.18s\tremaining: 14.5s\n",
      "131:\tlearn: 1.7756962\ttotal: 2.2s\tremaining: 14.4s\n",
      "132:\tlearn: 1.7753400\ttotal: 2.21s\tremaining: 14.4s\n",
      "133:\tlearn: 1.7751805\ttotal: 2.23s\tremaining: 14.4s\n",
      "134:\tlearn: 1.7751060\ttotal: 2.24s\tremaining: 14.4s\n",
      "135:\tlearn: 1.7747315\ttotal: 2.26s\tremaining: 14.4s\n",
      "136:\tlearn: 1.7746075\ttotal: 2.27s\tremaining: 14.3s\n",
      "137:\tlearn: 1.7745441\ttotal: 2.29s\tremaining: 14.3s\n",
      "138:\tlearn: 1.7744534\ttotal: 2.31s\tremaining: 14.3s\n",
      "139:\tlearn: 1.7742810\ttotal: 2.32s\tremaining: 14.3s\n",
      "140:\tlearn: 1.7741720\ttotal: 2.33s\tremaining: 14.2s\n",
      "141:\tlearn: 1.7706893\ttotal: 2.35s\tremaining: 14.2s\n",
      "142:\tlearn: 1.7704892\ttotal: 2.37s\tremaining: 14.2s\n",
      "143:\tlearn: 1.7692384\ttotal: 2.38s\tremaining: 14.2s\n",
      "144:\tlearn: 1.7691759\ttotal: 2.4s\tremaining: 14.1s\n",
      "145:\tlearn: 1.7691084\ttotal: 2.41s\tremaining: 14.1s\n",
      "146:\tlearn: 1.7689502\ttotal: 2.43s\tremaining: 14.1s\n",
      "147:\tlearn: 1.7687881\ttotal: 2.44s\tremaining: 14.1s\n",
      "148:\tlearn: 1.7686982\ttotal: 2.46s\tremaining: 14s\n",
      "149:\tlearn: 1.7686444\ttotal: 2.47s\tremaining: 14s\n",
      "150:\tlearn: 1.7684003\ttotal: 2.49s\tremaining: 14s\n",
      "151:\tlearn: 1.7683098\ttotal: 2.5s\tremaining: 14s\n",
      "152:\tlearn: 1.7682178\ttotal: 2.52s\tremaining: 13.9s\n",
      "153:\tlearn: 1.7680332\ttotal: 2.53s\tremaining: 13.9s\n",
      "154:\tlearn: 1.7665096\ttotal: 2.55s\tremaining: 13.9s\n",
      "155:\tlearn: 1.7626502\ttotal: 2.56s\tremaining: 13.9s\n",
      "156:\tlearn: 1.7621092\ttotal: 2.58s\tremaining: 13.9s\n",
      "157:\tlearn: 1.7562211\ttotal: 2.6s\tremaining: 13.8s\n",
      "158:\tlearn: 1.7494947\ttotal: 2.62s\tremaining: 13.8s\n",
      "159:\tlearn: 1.7464626\ttotal: 2.63s\tremaining: 13.8s\n",
      "160:\tlearn: 1.7431066\ttotal: 2.65s\tremaining: 13.8s\n",
      "161:\tlearn: 1.7403949\ttotal: 2.66s\tremaining: 13.8s\n",
      "162:\tlearn: 1.7402739\ttotal: 2.67s\tremaining: 13.7s\n",
      "163:\tlearn: 1.7401199\ttotal: 2.69s\tremaining: 13.7s\n",
      "164:\tlearn: 1.7398089\ttotal: 2.71s\tremaining: 13.7s\n",
      "165:\tlearn: 1.7397384\ttotal: 2.72s\tremaining: 13.7s\n",
      "166:\tlearn: 1.7395108\ttotal: 2.74s\tremaining: 13.7s\n",
      "167:\tlearn: 1.7392830\ttotal: 2.75s\tremaining: 13.6s\n",
      "168:\tlearn: 1.7389589\ttotal: 2.77s\tremaining: 13.6s\n",
      "169:\tlearn: 1.7387353\ttotal: 2.78s\tremaining: 13.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170:\tlearn: 1.7362343\ttotal: 2.81s\tremaining: 13.6s\n",
      "171:\tlearn: 1.7354000\ttotal: 2.83s\tremaining: 13.6s\n",
      "172:\tlearn: 1.7351245\ttotal: 2.85s\tremaining: 13.6s\n",
      "173:\tlearn: 1.7349294\ttotal: 2.86s\tremaining: 13.6s\n",
      "174:\tlearn: 1.7347011\ttotal: 2.88s\tremaining: 13.6s\n",
      "175:\tlearn: 1.7345231\ttotal: 2.89s\tremaining: 13.5s\n",
      "176:\tlearn: 1.7333666\ttotal: 2.91s\tremaining: 13.5s\n",
      "177:\tlearn: 1.7328974\ttotal: 2.92s\tremaining: 13.5s\n",
      "178:\tlearn: 1.7327566\ttotal: 2.94s\tremaining: 13.5s\n",
      "179:\tlearn: 1.7319477\ttotal: 2.96s\tremaining: 13.5s\n",
      "180:\tlearn: 1.7317614\ttotal: 2.97s\tremaining: 13.4s\n",
      "181:\tlearn: 1.7316414\ttotal: 2.98s\tremaining: 13.4s\n",
      "182:\tlearn: 1.7300208\ttotal: 3s\tremaining: 13.4s\n",
      "183:\tlearn: 1.7293949\ttotal: 3.02s\tremaining: 13.4s\n",
      "184:\tlearn: 1.7289575\ttotal: 3.03s\tremaining: 13.4s\n",
      "185:\tlearn: 1.7286798\ttotal: 3.05s\tremaining: 13.3s\n",
      "186:\tlearn: 1.7285692\ttotal: 3.06s\tremaining: 13.3s\n",
      "187:\tlearn: 1.7283644\ttotal: 3.08s\tremaining: 13.3s\n",
      "188:\tlearn: 1.7282955\ttotal: 3.09s\tremaining: 13.3s\n",
      "189:\tlearn: 1.7262435\ttotal: 3.11s\tremaining: 13.3s\n",
      "190:\tlearn: 1.7257990\ttotal: 3.13s\tremaining: 13.2s\n",
      "191:\tlearn: 1.7256955\ttotal: 3.14s\tremaining: 13.2s\n",
      "192:\tlearn: 1.7256360\ttotal: 3.16s\tremaining: 13.2s\n",
      "193:\tlearn: 1.7254522\ttotal: 3.17s\tremaining: 13.2s\n",
      "194:\tlearn: 1.7252552\ttotal: 3.19s\tremaining: 13.2s\n",
      "195:\tlearn: 1.7248529\ttotal: 3.2s\tremaining: 13.1s\n",
      "196:\tlearn: 1.7246878\ttotal: 3.22s\tremaining: 13.1s\n",
      "197:\tlearn: 1.7245564\ttotal: 3.23s\tremaining: 13.1s\n",
      "198:\tlearn: 1.7225241\ttotal: 3.25s\tremaining: 13.1s\n",
      "199:\tlearn: 1.7214963\ttotal: 3.27s\tremaining: 13.1s\n",
      "200:\tlearn: 1.7203967\ttotal: 3.28s\tremaining: 13s\n",
      "201:\tlearn: 1.7190301\ttotal: 3.3s\tremaining: 13s\n",
      "202:\tlearn: 1.7187863\ttotal: 3.31s\tremaining: 13s\n",
      "203:\tlearn: 1.7185968\ttotal: 3.33s\tremaining: 13s\n",
      "204:\tlearn: 1.7184402\ttotal: 3.34s\tremaining: 13s\n",
      "205:\tlearn: 1.7183114\ttotal: 3.36s\tremaining: 12.9s\n",
      "206:\tlearn: 1.7160941\ttotal: 3.37s\tremaining: 12.9s\n",
      "207:\tlearn: 1.7150344\ttotal: 3.39s\tremaining: 12.9s\n",
      "208:\tlearn: 1.7133233\ttotal: 3.4s\tremaining: 12.9s\n",
      "209:\tlearn: 1.7121517\ttotal: 3.42s\tremaining: 12.9s\n",
      "210:\tlearn: 1.7121011\ttotal: 3.43s\tremaining: 12.8s\n",
      "211:\tlearn: 1.7112844\ttotal: 3.44s\tremaining: 12.8s\n",
      "212:\tlearn: 1.7100094\ttotal: 3.46s\tremaining: 12.8s\n",
      "213:\tlearn: 1.7086073\ttotal: 3.48s\tremaining: 12.8s\n",
      "214:\tlearn: 1.7069367\ttotal: 3.5s\tremaining: 12.8s\n",
      "215:\tlearn: 1.7055621\ttotal: 3.52s\tremaining: 12.8s\n",
      "216:\tlearn: 1.7040617\ttotal: 3.53s\tremaining: 12.7s\n",
      "217:\tlearn: 1.7039301\ttotal: 3.54s\tremaining: 12.7s\n",
      "218:\tlearn: 1.7037744\ttotal: 3.56s\tremaining: 12.7s\n",
      "219:\tlearn: 1.7036581\ttotal: 3.57s\tremaining: 12.7s\n",
      "220:\tlearn: 1.7024160\ttotal: 3.59s\tremaining: 12.6s\n",
      "221:\tlearn: 1.7008400\ttotal: 3.6s\tremaining: 12.6s\n",
      "222:\tlearn: 1.6972906\ttotal: 3.62s\tremaining: 12.6s\n",
      "223:\tlearn: 1.6962417\ttotal: 3.63s\tremaining: 12.6s\n",
      "224:\tlearn: 1.6961630\ttotal: 3.65s\tremaining: 12.6s\n",
      "225:\tlearn: 1.6956694\ttotal: 3.66s\tremaining: 12.5s\n",
      "226:\tlearn: 1.6956426\ttotal: 3.68s\tremaining: 12.5s\n",
      "227:\tlearn: 1.6939881\ttotal: 3.69s\tremaining: 12.5s\n",
      "228:\tlearn: 1.6933633\ttotal: 3.71s\tremaining: 12.5s\n",
      "229:\tlearn: 1.6920588\ttotal: 3.72s\tremaining: 12.5s\n",
      "230:\tlearn: 1.6903785\ttotal: 3.74s\tremaining: 12.4s\n",
      "231:\tlearn: 1.6892742\ttotal: 3.75s\tremaining: 12.4s\n",
      "232:\tlearn: 1.6891824\ttotal: 3.77s\tremaining: 12.4s\n",
      "233:\tlearn: 1.6887645\ttotal: 3.78s\tremaining: 12.4s\n",
      "234:\tlearn: 1.6879766\ttotal: 3.79s\tremaining: 12.4s\n",
      "235:\tlearn: 1.6872770\ttotal: 3.81s\tremaining: 12.3s\n",
      "236:\tlearn: 1.6871899\ttotal: 3.82s\tremaining: 12.3s\n",
      "237:\tlearn: 1.6866706\ttotal: 3.84s\tremaining: 12.3s\n",
      "238:\tlearn: 1.6839648\ttotal: 3.85s\tremaining: 12.3s\n",
      "239:\tlearn: 1.6829916\ttotal: 3.87s\tremaining: 12.3s\n",
      "240:\tlearn: 1.6821867\ttotal: 3.88s\tremaining: 12.2s\n",
      "241:\tlearn: 1.6812095\ttotal: 3.9s\tremaining: 12.2s\n",
      "242:\tlearn: 1.6798521\ttotal: 3.92s\tremaining: 12.2s\n",
      "243:\tlearn: 1.6782639\ttotal: 3.93s\tremaining: 12.2s\n",
      "244:\tlearn: 1.6748362\ttotal: 3.94s\tremaining: 12.2s\n",
      "245:\tlearn: 1.6738944\ttotal: 3.96s\tremaining: 12.1s\n",
      "246:\tlearn: 1.6703935\ttotal: 3.97s\tremaining: 12.1s\n",
      "247:\tlearn: 1.6692043\ttotal: 3.99s\tremaining: 12.1s\n",
      "248:\tlearn: 1.6683941\ttotal: 4s\tremaining: 12.1s\n",
      "249:\tlearn: 1.6660075\ttotal: 4.02s\tremaining: 12.1s\n",
      "250:\tlearn: 1.6639736\ttotal: 4.03s\tremaining: 12s\n",
      "251:\tlearn: 1.6625610\ttotal: 4.05s\tremaining: 12s\n",
      "252:\tlearn: 1.6616889\ttotal: 4.06s\tremaining: 12s\n",
      "253:\tlearn: 1.6609611\ttotal: 4.08s\tremaining: 12s\n",
      "254:\tlearn: 1.6594255\ttotal: 4.09s\tremaining: 11.9s\n",
      "255:\tlearn: 1.6583120\ttotal: 4.1s\tremaining: 11.9s\n",
      "256:\tlearn: 1.6569459\ttotal: 4.12s\tremaining: 11.9s\n",
      "257:\tlearn: 1.6566082\ttotal: 4.13s\tremaining: 11.9s\n",
      "258:\tlearn: 1.6555884\ttotal: 4.15s\tremaining: 11.9s\n",
      "259:\tlearn: 1.6548625\ttotal: 4.16s\tremaining: 11.8s\n",
      "260:\tlearn: 1.6536203\ttotal: 4.17s\tremaining: 11.8s\n",
      "261:\tlearn: 1.6514329\ttotal: 4.19s\tremaining: 11.8s\n",
      "262:\tlearn: 1.6503350\ttotal: 4.21s\tremaining: 11.8s\n",
      "263:\tlearn: 1.6483387\ttotal: 4.22s\tremaining: 11.8s\n",
      "264:\tlearn: 1.6470432\ttotal: 4.23s\tremaining: 11.7s\n",
      "265:\tlearn: 1.6452637\ttotal: 4.25s\tremaining: 11.7s\n",
      "266:\tlearn: 1.6425874\ttotal: 4.26s\tremaining: 11.7s\n",
      "267:\tlearn: 1.6397011\ttotal: 4.28s\tremaining: 11.7s\n",
      "268:\tlearn: 1.6381097\ttotal: 4.29s\tremaining: 11.7s\n",
      "269:\tlearn: 1.6367478\ttotal: 4.31s\tremaining: 11.6s\n",
      "270:\tlearn: 1.6348818\ttotal: 4.32s\tremaining: 11.6s\n",
      "271:\tlearn: 1.6324368\ttotal: 4.34s\tremaining: 11.6s\n",
      "272:\tlearn: 1.6320320\ttotal: 4.35s\tremaining: 11.6s\n",
      "273:\tlearn: 1.6309347\ttotal: 4.37s\tremaining: 11.6s\n",
      "274:\tlearn: 1.6304683\ttotal: 4.38s\tremaining: 11.5s\n",
      "275:\tlearn: 1.6298638\ttotal: 4.39s\tremaining: 11.5s\n",
      "276:\tlearn: 1.6281336\ttotal: 4.41s\tremaining: 11.5s\n",
      "277:\tlearn: 1.6277494\ttotal: 4.42s\tremaining: 11.5s\n",
      "278:\tlearn: 1.6271590\ttotal: 4.43s\tremaining: 11.5s\n",
      "279:\tlearn: 1.6267622\ttotal: 4.45s\tremaining: 11.4s\n",
      "280:\tlearn: 1.6259869\ttotal: 4.46s\tremaining: 11.4s\n",
      "281:\tlearn: 1.6250290\ttotal: 4.48s\tremaining: 11.4s\n",
      "282:\tlearn: 1.6239931\ttotal: 4.49s\tremaining: 11.4s\n",
      "283:\tlearn: 1.6232555\ttotal: 4.5s\tremaining: 11.4s\n",
      "284:\tlearn: 1.6217816\ttotal: 4.52s\tremaining: 11.3s\n",
      "285:\tlearn: 1.6210478\ttotal: 4.54s\tremaining: 11.3s\n",
      "286:\tlearn: 1.6204529\ttotal: 4.55s\tremaining: 11.3s\n",
      "287:\tlearn: 1.6194852\ttotal: 4.57s\tremaining: 11.3s\n",
      "288:\tlearn: 1.6191593\ttotal: 4.58s\tremaining: 11.3s\n",
      "289:\tlearn: 1.6181430\ttotal: 4.59s\tremaining: 11.2s\n",
      "290:\tlearn: 1.6180592\ttotal: 4.61s\tremaining: 11.2s\n",
      "291:\tlearn: 1.6177624\ttotal: 4.62s\tremaining: 11.2s\n",
      "292:\tlearn: 1.6163465\ttotal: 4.64s\tremaining: 11.2s\n",
      "293:\tlearn: 1.6159138\ttotal: 4.65s\tremaining: 11.2s\n",
      "294:\tlearn: 1.6157192\ttotal: 4.67s\tremaining: 11.2s\n",
      "295:\tlearn: 1.6152061\ttotal: 4.68s\tremaining: 11.1s\n",
      "296:\tlearn: 1.6138052\ttotal: 4.7s\tremaining: 11.1s\n",
      "297:\tlearn: 1.6134898\ttotal: 4.71s\tremaining: 11.1s\n",
      "298:\tlearn: 1.6128712\ttotal: 4.72s\tremaining: 11.1s\n",
      "299:\tlearn: 1.6115185\ttotal: 4.74s\tremaining: 11.1s\n",
      "300:\tlearn: 1.6104840\ttotal: 4.75s\tremaining: 11s\n",
      "301:\tlearn: 1.6096169\ttotal: 4.77s\tremaining: 11s\n",
      "302:\tlearn: 1.6092525\ttotal: 4.78s\tremaining: 11s\n",
      "303:\tlearn: 1.6087087\ttotal: 4.8s\tremaining: 11s\n",
      "304:\tlearn: 1.6078291\ttotal: 4.81s\tremaining: 11s\n",
      "305:\tlearn: 1.6068162\ttotal: 4.83s\tremaining: 10.9s\n",
      "306:\tlearn: 1.6067851\ttotal: 4.84s\tremaining: 10.9s\n",
      "307:\tlearn: 1.6065135\ttotal: 4.85s\tremaining: 10.9s\n",
      "308:\tlearn: 1.6057928\ttotal: 4.87s\tremaining: 10.9s\n",
      "309:\tlearn: 1.6052397\ttotal: 4.88s\tremaining: 10.9s\n",
      "310:\tlearn: 1.6048470\ttotal: 4.89s\tremaining: 10.8s\n",
      "311:\tlearn: 1.6046256\ttotal: 4.91s\tremaining: 10.8s\n",
      "312:\tlearn: 1.6045139\ttotal: 4.92s\tremaining: 10.8s\n",
      "313:\tlearn: 1.6038671\ttotal: 4.94s\tremaining: 10.8s\n",
      "314:\tlearn: 1.6038102\ttotal: 4.95s\tremaining: 10.8s\n",
      "315:\tlearn: 1.6029231\ttotal: 4.96s\tremaining: 10.7s\n",
      "316:\tlearn: 1.6015926\ttotal: 4.98s\tremaining: 10.7s\n",
      "317:\tlearn: 1.6003352\ttotal: 5s\tremaining: 10.7s\n",
      "318:\tlearn: 1.5996876\ttotal: 5.01s\tremaining: 10.7s\n",
      "319:\tlearn: 1.5994645\ttotal: 5.03s\tremaining: 10.7s\n",
      "320:\tlearn: 1.5973280\ttotal: 5.04s\tremaining: 10.7s\n",
      "321:\tlearn: 1.5968049\ttotal: 5.05s\tremaining: 10.6s\n",
      "322:\tlearn: 1.5962074\ttotal: 5.07s\tremaining: 10.6s\n",
      "323:\tlearn: 1.5960068\ttotal: 5.08s\tremaining: 10.6s\n",
      "324:\tlearn: 1.5952134\ttotal: 5.1s\tremaining: 10.6s\n",
      "325:\tlearn: 1.5946446\ttotal: 5.11s\tremaining: 10.6s\n",
      "326:\tlearn: 1.5939656\ttotal: 5.13s\tremaining: 10.6s\n",
      "327:\tlearn: 1.5932261\ttotal: 5.14s\tremaining: 10.5s\n",
      "328:\tlearn: 1.5930466\ttotal: 5.15s\tremaining: 10.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329:\tlearn: 1.5926600\ttotal: 5.17s\tremaining: 10.5s\n",
      "330:\tlearn: 1.5913129\ttotal: 5.18s\tremaining: 10.5s\n",
      "331:\tlearn: 1.5895883\ttotal: 5.2s\tremaining: 10.5s\n",
      "332:\tlearn: 1.5891647\ttotal: 5.21s\tremaining: 10.4s\n",
      "333:\tlearn: 1.5889231\ttotal: 5.23s\tremaining: 10.4s\n",
      "334:\tlearn: 1.5884747\ttotal: 5.24s\tremaining: 10.4s\n",
      "335:\tlearn: 1.5882528\ttotal: 5.26s\tremaining: 10.4s\n",
      "336:\tlearn: 1.5879965\ttotal: 5.27s\tremaining: 10.4s\n",
      "337:\tlearn: 1.5867352\ttotal: 5.29s\tremaining: 10.4s\n",
      "338:\tlearn: 1.5857146\ttotal: 5.3s\tremaining: 10.3s\n",
      "339:\tlearn: 1.5852800\ttotal: 5.31s\tremaining: 10.3s\n",
      "340:\tlearn: 1.5852282\ttotal: 5.33s\tremaining: 10.3s\n",
      "341:\tlearn: 1.5850328\ttotal: 5.34s\tremaining: 10.3s\n",
      "342:\tlearn: 1.5850082\ttotal: 5.36s\tremaining: 10.3s\n",
      "343:\tlearn: 1.5848312\ttotal: 5.37s\tremaining: 10.2s\n",
      "344:\tlearn: 1.5839536\ttotal: 5.39s\tremaining: 10.2s\n",
      "345:\tlearn: 1.5838518\ttotal: 5.4s\tremaining: 10.2s\n",
      "346:\tlearn: 1.5838066\ttotal: 5.42s\tremaining: 10.2s\n",
      "347:\tlearn: 1.5830093\ttotal: 5.43s\tremaining: 10.2s\n",
      "348:\tlearn: 1.5816938\ttotal: 5.44s\tremaining: 10.2s\n",
      "349:\tlearn: 1.5814388\ttotal: 5.46s\tremaining: 10.1s\n",
      "350:\tlearn: 1.5809796\ttotal: 5.47s\tremaining: 10.1s\n",
      "351:\tlearn: 1.5804125\ttotal: 5.49s\tremaining: 10.1s\n",
      "352:\tlearn: 1.5799096\ttotal: 5.5s\tremaining: 10.1s\n",
      "353:\tlearn: 1.5798133\ttotal: 5.51s\tremaining: 10.1s\n",
      "354:\tlearn: 1.5795396\ttotal: 5.53s\tremaining: 10s\n",
      "355:\tlearn: 1.5793784\ttotal: 5.54s\tremaining: 10s\n",
      "356:\tlearn: 1.5790382\ttotal: 5.55s\tremaining: 10s\n",
      "357:\tlearn: 1.5784357\ttotal: 5.57s\tremaining: 9.99s\n",
      "358:\tlearn: 1.5780293\ttotal: 5.58s\tremaining: 9.97s\n",
      "359:\tlearn: 1.5779960\ttotal: 5.6s\tremaining: 9.95s\n",
      "360:\tlearn: 1.5756293\ttotal: 5.61s\tremaining: 9.94s\n",
      "361:\tlearn: 1.5745952\ttotal: 5.63s\tremaining: 9.92s\n",
      "362:\tlearn: 1.5744652\ttotal: 5.64s\tremaining: 9.91s\n",
      "363:\tlearn: 1.5742917\ttotal: 5.66s\tremaining: 9.89s\n",
      "364:\tlearn: 1.5738079\ttotal: 5.67s\tremaining: 9.87s\n",
      "365:\tlearn: 1.5733362\ttotal: 5.69s\tremaining: 9.85s\n",
      "366:\tlearn: 1.5725957\ttotal: 5.7s\tremaining: 9.83s\n",
      "367:\tlearn: 1.5715996\ttotal: 5.71s\tremaining: 9.81s\n",
      "368:\tlearn: 1.5710672\ttotal: 5.73s\tremaining: 9.8s\n",
      "369:\tlearn: 1.5706153\ttotal: 5.74s\tremaining: 9.78s\n",
      "370:\tlearn: 1.5704758\ttotal: 5.76s\tremaining: 9.76s\n",
      "371:\tlearn: 1.5701093\ttotal: 5.77s\tremaining: 9.74s\n",
      "372:\tlearn: 1.5694900\ttotal: 5.79s\tremaining: 9.73s\n",
      "373:\tlearn: 1.5693359\ttotal: 5.8s\tremaining: 9.71s\n",
      "374:\tlearn: 1.5687365\ttotal: 5.82s\tremaining: 9.7s\n",
      "375:\tlearn: 1.5683198\ttotal: 5.83s\tremaining: 9.68s\n",
      "376:\tlearn: 1.5682739\ttotal: 5.84s\tremaining: 9.66s\n",
      "377:\tlearn: 1.5678739\ttotal: 5.86s\tremaining: 9.64s\n",
      "378:\tlearn: 1.5664779\ttotal: 5.87s\tremaining: 9.62s\n",
      "379:\tlearn: 1.5654513\ttotal: 5.89s\tremaining: 9.61s\n",
      "380:\tlearn: 1.5652513\ttotal: 5.9s\tremaining: 9.59s\n",
      "381:\tlearn: 1.5643083\ttotal: 5.92s\tremaining: 9.57s\n",
      "382:\tlearn: 1.5638145\ttotal: 5.93s\tremaining: 9.55s\n",
      "383:\tlearn: 1.5634543\ttotal: 5.95s\tremaining: 9.54s\n",
      "384:\tlearn: 1.5631703\ttotal: 5.96s\tremaining: 9.52s\n",
      "385:\tlearn: 1.5629326\ttotal: 5.97s\tremaining: 9.5s\n",
      "386:\tlearn: 1.5624193\ttotal: 5.99s\tremaining: 9.48s\n",
      "387:\tlearn: 1.5623219\ttotal: 6s\tremaining: 9.47s\n",
      "388:\tlearn: 1.5622943\ttotal: 6.02s\tremaining: 9.45s\n",
      "389:\tlearn: 1.5619354\ttotal: 6.03s\tremaining: 9.44s\n",
      "390:\tlearn: 1.5611340\ttotal: 6.05s\tremaining: 9.42s\n",
      "391:\tlearn: 1.5610204\ttotal: 6.06s\tremaining: 9.4s\n",
      "392:\tlearn: 1.5602416\ttotal: 6.08s\tremaining: 9.38s\n",
      "393:\tlearn: 1.5582628\ttotal: 6.09s\tremaining: 9.37s\n",
      "394:\tlearn: 1.5565356\ttotal: 6.1s\tremaining: 9.35s\n",
      "395:\tlearn: 1.5563947\ttotal: 6.12s\tremaining: 9.33s\n",
      "396:\tlearn: 1.5556704\ttotal: 6.13s\tremaining: 9.31s\n",
      "397:\tlearn: 1.5551905\ttotal: 6.15s\tremaining: 9.3s\n",
      "398:\tlearn: 1.5538841\ttotal: 6.16s\tremaining: 9.28s\n",
      "399:\tlearn: 1.5537898\ttotal: 6.17s\tremaining: 9.26s\n",
      "400:\tlearn: 1.5534803\ttotal: 6.19s\tremaining: 9.24s\n",
      "401:\tlearn: 1.5531765\ttotal: 6.2s\tremaining: 9.22s\n",
      "402:\tlearn: 1.5531542\ttotal: 6.22s\tremaining: 9.21s\n",
      "403:\tlearn: 1.5530990\ttotal: 6.23s\tremaining: 9.19s\n",
      "404:\tlearn: 1.5520232\ttotal: 6.25s\tremaining: 9.18s\n",
      "405:\tlearn: 1.5518949\ttotal: 6.26s\tremaining: 9.16s\n",
      "406:\tlearn: 1.5518706\ttotal: 6.27s\tremaining: 9.14s\n",
      "407:\tlearn: 1.5518638\ttotal: 6.29s\tremaining: 9.12s\n",
      "408:\tlearn: 1.5514093\ttotal: 6.3s\tremaining: 9.11s\n",
      "409:\tlearn: 1.5512142\ttotal: 6.32s\tremaining: 9.09s\n",
      "410:\tlearn: 1.5509918\ttotal: 6.33s\tremaining: 9.07s\n",
      "411:\tlearn: 1.5509802\ttotal: 6.34s\tremaining: 9.05s\n",
      "412:\tlearn: 1.5509692\ttotal: 6.36s\tremaining: 9.04s\n",
      "413:\tlearn: 1.5508825\ttotal: 6.37s\tremaining: 9.02s\n",
      "414:\tlearn: 1.5505676\ttotal: 6.38s\tremaining: 9s\n",
      "415:\tlearn: 1.5501816\ttotal: 6.4s\tremaining: 8.98s\n",
      "416:\tlearn: 1.5500671\ttotal: 6.41s\tremaining: 8.96s\n",
      "417:\tlearn: 1.5500484\ttotal: 6.43s\tremaining: 8.95s\n",
      "418:\tlearn: 1.5497986\ttotal: 6.44s\tremaining: 8.93s\n",
      "419:\tlearn: 1.5493038\ttotal: 6.46s\tremaining: 8.92s\n",
      "420:\tlearn: 1.5493008\ttotal: 6.47s\tremaining: 8.9s\n",
      "421:\tlearn: 1.5492872\ttotal: 6.48s\tremaining: 8.88s\n",
      "422:\tlearn: 1.5492808\ttotal: 6.5s\tremaining: 8.87s\n",
      "423:\tlearn: 1.5481693\ttotal: 6.51s\tremaining: 8.85s\n",
      "424:\tlearn: 1.5477946\ttotal: 6.53s\tremaining: 8.83s\n",
      "425:\tlearn: 1.5477574\ttotal: 6.54s\tremaining: 8.81s\n",
      "426:\tlearn: 1.5477405\ttotal: 6.55s\tremaining: 8.79s\n",
      "427:\tlearn: 1.5475363\ttotal: 6.57s\tremaining: 8.78s\n",
      "428:\tlearn: 1.5474994\ttotal: 6.58s\tremaining: 8.76s\n",
      "429:\tlearn: 1.5474594\ttotal: 6.59s\tremaining: 8.74s\n",
      "430:\tlearn: 1.5474188\ttotal: 6.61s\tremaining: 8.73s\n",
      "431:\tlearn: 1.5465060\ttotal: 6.62s\tremaining: 8.71s\n",
      "432:\tlearn: 1.5459521\ttotal: 6.64s\tremaining: 8.69s\n",
      "433:\tlearn: 1.5459321\ttotal: 6.65s\tremaining: 8.68s\n",
      "434:\tlearn: 1.5455897\ttotal: 6.67s\tremaining: 8.66s\n",
      "435:\tlearn: 1.5455254\ttotal: 6.68s\tremaining: 8.65s\n",
      "436:\tlearn: 1.5455061\ttotal: 6.7s\tremaining: 8.63s\n",
      "437:\tlearn: 1.5453524\ttotal: 6.71s\tremaining: 8.61s\n",
      "438:\tlearn: 1.5451211\ttotal: 6.73s\tremaining: 8.6s\n",
      "439:\tlearn: 1.5449877\ttotal: 6.74s\tremaining: 8.58s\n",
      "440:\tlearn: 1.5448787\ttotal: 6.76s\tremaining: 8.56s\n",
      "441:\tlearn: 1.5448787\ttotal: 6.77s\tremaining: 8.55s\n",
      "442:\tlearn: 1.5448787\ttotal: 6.78s\tremaining: 8.53s\n",
      "443:\tlearn: 1.5448787\ttotal: 6.8s\tremaining: 8.51s\n",
      "444:\tlearn: 1.5448787\ttotal: 6.81s\tremaining: 8.49s\n",
      "445:\tlearn: 1.5448713\ttotal: 6.82s\tremaining: 8.48s\n",
      "446:\tlearn: 1.5448713\ttotal: 6.84s\tremaining: 8.46s\n",
      "447:\tlearn: 1.5448713\ttotal: 6.85s\tremaining: 8.44s\n",
      "448:\tlearn: 1.5448689\ttotal: 6.87s\tremaining: 8.43s\n",
      "449:\tlearn: 1.5448632\ttotal: 6.88s\tremaining: 8.41s\n",
      "450:\tlearn: 1.5447948\ttotal: 6.9s\tremaining: 8.39s\n",
      "451:\tlearn: 1.5447073\ttotal: 6.91s\tremaining: 8.38s\n",
      "452:\tlearn: 1.5446371\ttotal: 6.92s\tremaining: 8.36s\n",
      "453:\tlearn: 1.5446322\ttotal: 6.94s\tremaining: 8.35s\n",
      "454:\tlearn: 1.5445755\ttotal: 6.95s\tremaining: 8.33s\n",
      "455:\tlearn: 1.5445711\ttotal: 6.97s\tremaining: 8.31s\n",
      "456:\tlearn: 1.5445310\ttotal: 6.98s\tremaining: 8.29s\n",
      "457:\tlearn: 1.5443607\ttotal: 7s\tremaining: 8.28s\n",
      "458:\tlearn: 1.5443595\ttotal: 7.01s\tremaining: 8.26s\n",
      "459:\tlearn: 1.5442546\ttotal: 7.02s\tremaining: 8.24s\n",
      "460:\tlearn: 1.5442508\ttotal: 7.04s\tremaining: 8.23s\n",
      "461:\tlearn: 1.5442499\ttotal: 7.05s\tremaining: 8.21s\n",
      "462:\tlearn: 1.5442383\ttotal: 7.07s\tremaining: 8.2s\n",
      "463:\tlearn: 1.5442382\ttotal: 7.08s\tremaining: 8.18s\n",
      "464:\tlearn: 1.5442343\ttotal: 7.09s\tremaining: 8.16s\n",
      "465:\tlearn: 1.5441843\ttotal: 7.11s\tremaining: 8.14s\n",
      "466:\tlearn: 1.5441508\ttotal: 7.12s\tremaining: 8.13s\n",
      "467:\tlearn: 1.5441220\ttotal: 7.14s\tremaining: 8.12s\n",
      "468:\tlearn: 1.5441095\ttotal: 7.15s\tremaining: 8.1s\n",
      "469:\tlearn: 1.5441085\ttotal: 7.17s\tremaining: 8.08s\n",
      "470:\tlearn: 1.5440508\ttotal: 7.18s\tremaining: 8.07s\n",
      "471:\tlearn: 1.5440469\ttotal: 7.2s\tremaining: 8.05s\n",
      "472:\tlearn: 1.5440467\ttotal: 7.21s\tremaining: 8.03s\n",
      "473:\tlearn: 1.5440155\ttotal: 7.22s\tremaining: 8.02s\n",
      "474:\tlearn: 1.5439752\ttotal: 7.24s\tremaining: 8s\n",
      "475:\tlearn: 1.5439416\ttotal: 7.25s\tremaining: 7.98s\n",
      "476:\tlearn: 1.5439002\ttotal: 7.27s\tremaining: 7.97s\n",
      "477:\tlearn: 1.5438353\ttotal: 7.28s\tremaining: 7.95s\n",
      "478:\tlearn: 1.5437107\ttotal: 7.3s\tremaining: 7.94s\n",
      "479:\tlearn: 1.5437107\ttotal: 7.31s\tremaining: 7.92s\n",
      "480:\tlearn: 1.5437097\ttotal: 7.33s\tremaining: 7.91s\n",
      "481:\tlearn: 1.5433672\ttotal: 7.34s\tremaining: 7.89s\n",
      "482:\tlearn: 1.5433569\ttotal: 7.36s\tremaining: 7.87s\n",
      "483:\tlearn: 1.5433568\ttotal: 7.37s\tremaining: 7.86s\n",
      "484:\tlearn: 1.5430096\ttotal: 7.38s\tremaining: 7.84s\n",
      "485:\tlearn: 1.5430063\ttotal: 7.4s\tremaining: 7.82s\n",
      "486:\tlearn: 1.5429992\ttotal: 7.41s\tremaining: 7.81s\n",
      "487:\tlearn: 1.5429991\ttotal: 7.43s\tremaining: 7.79s\n",
      "488:\tlearn: 1.5429991\ttotal: 7.44s\tremaining: 7.77s\n",
      "489:\tlearn: 1.5429931\ttotal: 7.45s\tremaining: 7.76s\n",
      "490:\tlearn: 1.5429930\ttotal: 7.47s\tremaining: 7.74s\n",
      "491:\tlearn: 1.5429929\ttotal: 7.48s\tremaining: 7.73s\n",
      "492:\tlearn: 1.5429929\ttotal: 7.5s\tremaining: 7.71s\n",
      "493:\tlearn: 1.5429929\ttotal: 7.51s\tremaining: 7.7s\n",
      "494:\tlearn: 1.5429929\ttotal: 7.53s\tremaining: 7.68s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495:\tlearn: 1.5429926\ttotal: 7.54s\tremaining: 7.67s\n",
      "496:\tlearn: 1.5429912\ttotal: 7.56s\tremaining: 7.65s\n",
      "497:\tlearn: 1.5429912\ttotal: 7.58s\tremaining: 7.63s\n",
      "498:\tlearn: 1.5429912\ttotal: 7.59s\tremaining: 7.62s\n",
      "499:\tlearn: 1.5429912\ttotal: 7.6s\tremaining: 7.6s\n",
      "500:\tlearn: 1.5429911\ttotal: 7.62s\tremaining: 7.59s\n",
      "501:\tlearn: 1.5429876\ttotal: 7.63s\tremaining: 7.57s\n",
      "502:\tlearn: 1.5429808\ttotal: 7.65s\tremaining: 7.55s\n",
      "503:\tlearn: 1.5429685\ttotal: 7.66s\tremaining: 7.54s\n",
      "504:\tlearn: 1.5424994\ttotal: 7.67s\tremaining: 7.52s\n",
      "505:\tlearn: 1.5420812\ttotal: 7.69s\tremaining: 7.5s\n",
      "506:\tlearn: 1.5414663\ttotal: 7.7s\tremaining: 7.49s\n",
      "507:\tlearn: 1.5408453\ttotal: 7.71s\tremaining: 7.47s\n",
      "508:\tlearn: 1.5401167\ttotal: 7.73s\tremaining: 7.46s\n",
      "509:\tlearn: 1.5401129\ttotal: 7.74s\tremaining: 7.44s\n",
      "510:\tlearn: 1.5401110\ttotal: 7.76s\tremaining: 7.43s\n",
      "511:\tlearn: 1.5401036\ttotal: 7.78s\tremaining: 7.41s\n",
      "512:\tlearn: 1.5400730\ttotal: 7.79s\tremaining: 7.39s\n",
      "513:\tlearn: 1.5400725\ttotal: 7.8s\tremaining: 7.38s\n",
      "514:\tlearn: 1.5400723\ttotal: 7.82s\tremaining: 7.36s\n",
      "515:\tlearn: 1.5400721\ttotal: 7.83s\tremaining: 7.35s\n",
      "516:\tlearn: 1.5394398\ttotal: 7.85s\tremaining: 7.33s\n",
      "517:\tlearn: 1.5394245\ttotal: 7.86s\tremaining: 7.32s\n",
      "518:\tlearn: 1.5394212\ttotal: 7.88s\tremaining: 7.3s\n",
      "519:\tlearn: 1.5387925\ttotal: 7.89s\tremaining: 7.29s\n",
      "520:\tlearn: 1.5387584\ttotal: 7.91s\tremaining: 7.27s\n",
      "521:\tlearn: 1.5385251\ttotal: 7.92s\tremaining: 7.25s\n",
      "522:\tlearn: 1.5378081\ttotal: 7.93s\tremaining: 7.24s\n",
      "523:\tlearn: 1.5372623\ttotal: 7.95s\tremaining: 7.22s\n",
      "524:\tlearn: 1.5366433\ttotal: 7.96s\tremaining: 7.21s\n",
      "525:\tlearn: 1.5363805\ttotal: 7.98s\tremaining: 7.19s\n",
      "526:\tlearn: 1.5363792\ttotal: 8s\tremaining: 7.17s\n",
      "527:\tlearn: 1.5363791\ttotal: 8.01s\tremaining: 7.16s\n",
      "528:\tlearn: 1.5363791\ttotal: 8.02s\tremaining: 7.14s\n",
      "529:\tlearn: 1.5363748\ttotal: 8.04s\tremaining: 7.13s\n",
      "530:\tlearn: 1.5363747\ttotal: 8.05s\tremaining: 7.11s\n",
      "531:\tlearn: 1.5363747\ttotal: 8.07s\tremaining: 7.09s\n",
      "532:\tlearn: 1.5363744\ttotal: 8.08s\tremaining: 7.08s\n",
      "533:\tlearn: 1.5363742\ttotal: 8.1s\tremaining: 7.06s\n",
      "534:\tlearn: 1.5363647\ttotal: 8.11s\tremaining: 7.05s\n",
      "535:\tlearn: 1.5363644\ttotal: 8.12s\tremaining: 7.03s\n",
      "536:\tlearn: 1.5363643\ttotal: 8.14s\tremaining: 7.02s\n",
      "537:\tlearn: 1.5363640\ttotal: 8.15s\tremaining: 7s\n",
      "538:\tlearn: 1.5363640\ttotal: 8.17s\tremaining: 6.98s\n",
      "539:\tlearn: 1.5363601\ttotal: 8.18s\tremaining: 6.97s\n",
      "540:\tlearn: 1.5357572\ttotal: 8.2s\tremaining: 6.95s\n",
      "541:\tlearn: 1.5357571\ttotal: 8.21s\tremaining: 6.94s\n",
      "542:\tlearn: 1.5357571\ttotal: 8.22s\tremaining: 6.92s\n",
      "543:\tlearn: 1.5357571\ttotal: 8.24s\tremaining: 6.91s\n",
      "544:\tlearn: 1.5357570\ttotal: 8.25s\tremaining: 6.89s\n",
      "545:\tlearn: 1.5357494\ttotal: 8.27s\tremaining: 6.87s\n",
      "546:\tlearn: 1.5357493\ttotal: 8.28s\tremaining: 6.86s\n",
      "547:\tlearn: 1.5357465\ttotal: 8.29s\tremaining: 6.84s\n",
      "548:\tlearn: 1.5357442\ttotal: 8.31s\tremaining: 6.83s\n",
      "549:\tlearn: 1.5357429\ttotal: 8.32s\tremaining: 6.81s\n",
      "550:\tlearn: 1.5357388\ttotal: 8.34s\tremaining: 6.79s\n",
      "551:\tlearn: 1.5357388\ttotal: 8.35s\tremaining: 6.78s\n",
      "552:\tlearn: 1.5357386\ttotal: 8.37s\tremaining: 6.76s\n",
      "553:\tlearn: 1.5357191\ttotal: 8.38s\tremaining: 6.75s\n",
      "554:\tlearn: 1.5357162\ttotal: 8.39s\tremaining: 6.73s\n",
      "555:\tlearn: 1.5357081\ttotal: 8.41s\tremaining: 6.71s\n",
      "556:\tlearn: 1.5356971\ttotal: 8.42s\tremaining: 6.7s\n",
      "557:\tlearn: 1.5351905\ttotal: 8.44s\tremaining: 6.68s\n",
      "558:\tlearn: 1.5349994\ttotal: 8.45s\tremaining: 6.67s\n",
      "559:\tlearn: 1.5348443\ttotal: 8.47s\tremaining: 6.65s\n",
      "560:\tlearn: 1.5341384\ttotal: 8.48s\tremaining: 6.64s\n",
      "561:\tlearn: 1.5329122\ttotal: 8.49s\tremaining: 6.62s\n",
      "562:\tlearn: 1.5320938\ttotal: 8.51s\tremaining: 6.6s\n",
      "563:\tlearn: 1.5320237\ttotal: 8.52s\tremaining: 6.59s\n",
      "564:\tlearn: 1.5319948\ttotal: 8.54s\tremaining: 6.57s\n",
      "565:\tlearn: 1.5319656\ttotal: 8.55s\tremaining: 6.56s\n",
      "566:\tlearn: 1.5319636\ttotal: 8.56s\tremaining: 6.54s\n",
      "567:\tlearn: 1.5319449\ttotal: 8.59s\tremaining: 6.54s\n",
      "568:\tlearn: 1.5315814\ttotal: 8.61s\tremaining: 6.52s\n",
      "569:\tlearn: 1.5315063\ttotal: 8.62s\tremaining: 6.5s\n",
      "570:\tlearn: 1.5315062\ttotal: 8.64s\tremaining: 6.49s\n",
      "571:\tlearn: 1.5315061\ttotal: 8.65s\tremaining: 6.47s\n",
      "572:\tlearn: 1.5314830\ttotal: 8.67s\tremaining: 6.46s\n",
      "573:\tlearn: 1.5314625\ttotal: 8.68s\tremaining: 6.44s\n",
      "574:\tlearn: 1.5314350\ttotal: 8.7s\tremaining: 6.43s\n",
      "575:\tlearn: 1.5314094\ttotal: 8.71s\tremaining: 6.41s\n",
      "576:\tlearn: 1.5314092\ttotal: 8.73s\tremaining: 6.4s\n",
      "577:\tlearn: 1.5314084\ttotal: 8.74s\tremaining: 6.38s\n",
      "578:\tlearn: 1.5314039\ttotal: 8.76s\tremaining: 6.37s\n",
      "579:\tlearn: 1.5314038\ttotal: 8.77s\tremaining: 6.35s\n",
      "580:\tlearn: 1.5314035\ttotal: 8.78s\tremaining: 6.33s\n",
      "581:\tlearn: 1.5313974\ttotal: 8.8s\tremaining: 6.32s\n",
      "582:\tlearn: 1.5313947\ttotal: 8.81s\tremaining: 6.3s\n",
      "583:\tlearn: 1.5310009\ttotal: 8.83s\tremaining: 6.29s\n",
      "584:\tlearn: 1.5295867\ttotal: 8.84s\tremaining: 6.27s\n",
      "585:\tlearn: 1.5295364\ttotal: 8.86s\tremaining: 6.26s\n",
      "586:\tlearn: 1.5294870\ttotal: 8.87s\tremaining: 6.24s\n",
      "587:\tlearn: 1.5294839\ttotal: 8.89s\tremaining: 6.23s\n",
      "588:\tlearn: 1.5294833\ttotal: 8.9s\tremaining: 6.21s\n",
      "589:\tlearn: 1.5294833\ttotal: 8.92s\tremaining: 6.2s\n",
      "590:\tlearn: 1.5294830\ttotal: 8.93s\tremaining: 6.18s\n",
      "591:\tlearn: 1.5294828\ttotal: 8.95s\tremaining: 6.17s\n",
      "592:\tlearn: 1.5294827\ttotal: 8.96s\tremaining: 6.15s\n",
      "593:\tlearn: 1.5294763\ttotal: 8.98s\tremaining: 6.13s\n",
      "594:\tlearn: 1.5294763\ttotal: 8.99s\tremaining: 6.12s\n",
      "595:\tlearn: 1.5294762\ttotal: 9.01s\tremaining: 6.1s\n",
      "596:\tlearn: 1.5294760\ttotal: 9.02s\tremaining: 6.09s\n",
      "597:\tlearn: 1.5294760\ttotal: 9.03s\tremaining: 6.07s\n",
      "598:\tlearn: 1.5289923\ttotal: 9.05s\tremaining: 6.06s\n",
      "599:\tlearn: 1.5283432\ttotal: 9.06s\tremaining: 6.04s\n",
      "600:\tlearn: 1.5277612\ttotal: 9.08s\tremaining: 6.03s\n",
      "601:\tlearn: 1.5274303\ttotal: 9.1s\tremaining: 6.01s\n",
      "602:\tlearn: 1.5274134\ttotal: 9.11s\tremaining: 6s\n",
      "603:\tlearn: 1.5274134\ttotal: 9.12s\tremaining: 5.98s\n",
      "604:\tlearn: 1.5273980\ttotal: 9.14s\tremaining: 5.97s\n",
      "605:\tlearn: 1.5273853\ttotal: 9.15s\tremaining: 5.95s\n",
      "606:\tlearn: 1.5273594\ttotal: 9.17s\tremaining: 5.93s\n",
      "607:\tlearn: 1.5272742\ttotal: 9.18s\tremaining: 5.92s\n",
      "608:\tlearn: 1.5259527\ttotal: 9.2s\tremaining: 5.9s\n",
      "609:\tlearn: 1.5257654\ttotal: 9.21s\tremaining: 5.89s\n",
      "610:\tlearn: 1.5251962\ttotal: 9.22s\tremaining: 5.87s\n",
      "611:\tlearn: 1.5251958\ttotal: 9.24s\tremaining: 5.86s\n",
      "612:\tlearn: 1.5251958\ttotal: 9.25s\tremaining: 5.84s\n",
      "613:\tlearn: 1.5251957\ttotal: 9.27s\tremaining: 5.83s\n",
      "614:\tlearn: 1.5251956\ttotal: 9.29s\tremaining: 5.81s\n",
      "615:\tlearn: 1.5251955\ttotal: 9.3s\tremaining: 5.8s\n",
      "616:\tlearn: 1.5251954\ttotal: 9.31s\tremaining: 5.78s\n",
      "617:\tlearn: 1.5251705\ttotal: 9.33s\tremaining: 5.77s\n",
      "618:\tlearn: 1.5251206\ttotal: 9.34s\tremaining: 5.75s\n",
      "619:\tlearn: 1.5250940\ttotal: 9.36s\tremaining: 5.73s\n",
      "620:\tlearn: 1.5241937\ttotal: 9.37s\tremaining: 5.72s\n",
      "621:\tlearn: 1.5236388\ttotal: 9.38s\tremaining: 5.7s\n",
      "622:\tlearn: 1.5234787\ttotal: 9.4s\tremaining: 5.69s\n",
      "623:\tlearn: 1.5230967\ttotal: 9.41s\tremaining: 5.67s\n",
      "624:\tlearn: 1.5228696\ttotal: 9.43s\tremaining: 5.66s\n",
      "625:\tlearn: 1.5224319\ttotal: 9.44s\tremaining: 5.64s\n",
      "626:\tlearn: 1.5223158\ttotal: 9.46s\tremaining: 5.63s\n",
      "627:\tlearn: 1.5223157\ttotal: 9.47s\tremaining: 5.61s\n",
      "628:\tlearn: 1.5223157\ttotal: 9.49s\tremaining: 5.6s\n",
      "629:\tlearn: 1.5222846\ttotal: 9.5s\tremaining: 5.58s\n",
      "630:\tlearn: 1.5213164\ttotal: 9.52s\tremaining: 5.57s\n",
      "631:\tlearn: 1.5212722\ttotal: 9.53s\tremaining: 5.55s\n",
      "632:\tlearn: 1.5205576\ttotal: 9.55s\tremaining: 5.53s\n",
      "633:\tlearn: 1.5202249\ttotal: 9.56s\tremaining: 5.52s\n",
      "634:\tlearn: 1.5202201\ttotal: 9.57s\tremaining: 5.5s\n",
      "635:\tlearn: 1.5202201\ttotal: 9.59s\tremaining: 5.49s\n",
      "636:\tlearn: 1.5202201\ttotal: 9.6s\tremaining: 5.47s\n",
      "637:\tlearn: 1.5202201\ttotal: 9.62s\tremaining: 5.46s\n",
      "638:\tlearn: 1.5202201\ttotal: 9.63s\tremaining: 5.44s\n",
      "639:\tlearn: 1.5202201\ttotal: 9.64s\tremaining: 5.42s\n",
      "640:\tlearn: 1.5202201\ttotal: 9.66s\tremaining: 5.41s\n",
      "641:\tlearn: 1.5202200\ttotal: 9.68s\tremaining: 5.39s\n",
      "642:\tlearn: 1.5202197\ttotal: 9.69s\tremaining: 5.38s\n",
      "643:\tlearn: 1.5202159\ttotal: 9.71s\tremaining: 5.37s\n",
      "644:\tlearn: 1.5202159\ttotal: 9.72s\tremaining: 5.35s\n",
      "645:\tlearn: 1.5202159\ttotal: 9.73s\tremaining: 5.33s\n",
      "646:\tlearn: 1.5201887\ttotal: 9.75s\tremaining: 5.32s\n",
      "647:\tlearn: 1.5201885\ttotal: 9.76s\tremaining: 5.3s\n",
      "648:\tlearn: 1.5201885\ttotal: 9.78s\tremaining: 5.29s\n",
      "649:\tlearn: 1.5201404\ttotal: 9.79s\tremaining: 5.27s\n",
      "650:\tlearn: 1.5191821\ttotal: 9.8s\tremaining: 5.25s\n",
      "651:\tlearn: 1.5186780\ttotal: 9.82s\tremaining: 5.24s\n",
      "652:\tlearn: 1.5185718\ttotal: 9.83s\tremaining: 5.22s\n",
      "653:\tlearn: 1.5185718\ttotal: 9.85s\tremaining: 5.21s\n",
      "654:\tlearn: 1.5185718\ttotal: 9.86s\tremaining: 5.19s\n",
      "655:\tlearn: 1.5185681\ttotal: 9.87s\tremaining: 5.18s\n",
      "656:\tlearn: 1.5185681\ttotal: 9.89s\tremaining: 5.16s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657:\tlearn: 1.5185681\ttotal: 9.9s\tremaining: 5.15s\n",
      "658:\tlearn: 1.5185681\ttotal: 9.92s\tremaining: 5.13s\n",
      "659:\tlearn: 1.5185681\ttotal: 9.93s\tremaining: 5.12s\n",
      "660:\tlearn: 1.5185492\ttotal: 9.94s\tremaining: 5.1s\n",
      "661:\tlearn: 1.5184802\ttotal: 9.96s\tremaining: 5.08s\n",
      "662:\tlearn: 1.5166409\ttotal: 9.97s\tremaining: 5.07s\n",
      "663:\tlearn: 1.5166112\ttotal: 9.99s\tremaining: 5.05s\n",
      "664:\tlearn: 1.5166103\ttotal: 10s\tremaining: 5.04s\n",
      "665:\tlearn: 1.5166103\ttotal: 10s\tremaining: 5.02s\n",
      "666:\tlearn: 1.5166103\ttotal: 10s\tremaining: 5.01s\n",
      "667:\tlearn: 1.5166102\ttotal: 10s\tremaining: 4.99s\n",
      "668:\tlearn: 1.5166101\ttotal: 10.1s\tremaining: 4.98s\n",
      "669:\tlearn: 1.5166082\ttotal: 10.1s\tremaining: 4.96s\n",
      "670:\tlearn: 1.5166082\ttotal: 10.1s\tremaining: 4.95s\n",
      "671:\tlearn: 1.5166082\ttotal: 10.1s\tremaining: 4.93s\n",
      "672:\tlearn: 1.5161872\ttotal: 10.1s\tremaining: 4.92s\n",
      "673:\tlearn: 1.5160915\ttotal: 10.1s\tremaining: 4.9s\n",
      "674:\tlearn: 1.5157313\ttotal: 10.1s\tremaining: 4.88s\n",
      "675:\tlearn: 1.5156119\ttotal: 10.2s\tremaining: 4.87s\n",
      "676:\tlearn: 1.5155747\ttotal: 10.2s\tremaining: 4.86s\n",
      "677:\tlearn: 1.5155298\ttotal: 10.2s\tremaining: 4.84s\n",
      "678:\tlearn: 1.5155226\ttotal: 10.2s\tremaining: 4.82s\n",
      "679:\tlearn: 1.5154731\ttotal: 10.2s\tremaining: 4.81s\n",
      "680:\tlearn: 1.5150201\ttotal: 10.2s\tremaining: 4.79s\n",
      "681:\tlearn: 1.5148913\ttotal: 10.2s\tremaining: 4.78s\n",
      "682:\tlearn: 1.5148612\ttotal: 10.3s\tremaining: 4.76s\n",
      "683:\tlearn: 1.5142350\ttotal: 10.3s\tremaining: 4.75s\n",
      "684:\tlearn: 1.5142314\ttotal: 10.3s\tremaining: 4.73s\n",
      "685:\tlearn: 1.5142309\ttotal: 10.3s\tremaining: 4.72s\n",
      "686:\tlearn: 1.5140847\ttotal: 10.3s\tremaining: 4.7s\n",
      "687:\tlearn: 1.5139039\ttotal: 10.3s\tremaining: 4.69s\n",
      "688:\tlearn: 1.5136312\ttotal: 10.4s\tremaining: 4.67s\n",
      "689:\tlearn: 1.5131728\ttotal: 10.4s\tremaining: 4.66s\n",
      "690:\tlearn: 1.5131728\ttotal: 10.4s\tremaining: 4.64s\n",
      "691:\tlearn: 1.5131727\ttotal: 10.4s\tremaining: 4.63s\n",
      "692:\tlearn: 1.5131717\ttotal: 10.4s\tremaining: 4.61s\n",
      "693:\tlearn: 1.5131717\ttotal: 10.4s\tremaining: 4.59s\n",
      "694:\tlearn: 1.5130827\ttotal: 10.4s\tremaining: 4.58s\n",
      "695:\tlearn: 1.5129282\ttotal: 10.4s\tremaining: 4.56s\n",
      "696:\tlearn: 1.5129255\ttotal: 10.5s\tremaining: 4.55s\n",
      "697:\tlearn: 1.5128331\ttotal: 10.5s\tremaining: 4.53s\n",
      "698:\tlearn: 1.5125650\ttotal: 10.5s\tremaining: 4.52s\n",
      "699:\tlearn: 1.5124992\ttotal: 10.5s\tremaining: 4.5s\n",
      "700:\tlearn: 1.5124705\ttotal: 10.5s\tremaining: 4.49s\n",
      "701:\tlearn: 1.5124611\ttotal: 10.5s\tremaining: 4.47s\n",
      "702:\tlearn: 1.5124159\ttotal: 10.6s\tremaining: 4.46s\n",
      "703:\tlearn: 1.5124158\ttotal: 10.6s\tremaining: 4.44s\n",
      "704:\tlearn: 1.5124151\ttotal: 10.6s\tremaining: 4.43s\n",
      "705:\tlearn: 1.5124148\ttotal: 10.6s\tremaining: 4.41s\n",
      "706:\tlearn: 1.5124086\ttotal: 10.6s\tremaining: 4.4s\n",
      "707:\tlearn: 1.5118713\ttotal: 10.6s\tremaining: 4.38s\n",
      "708:\tlearn: 1.5117959\ttotal: 10.6s\tremaining: 4.37s\n",
      "709:\tlearn: 1.5113072\ttotal: 10.7s\tremaining: 4.35s\n",
      "710:\tlearn: 1.5111945\ttotal: 10.7s\tremaining: 4.34s\n",
      "711:\tlearn: 1.5111696\ttotal: 10.7s\tremaining: 4.32s\n",
      "712:\tlearn: 1.5111696\ttotal: 10.7s\tremaining: 4.31s\n",
      "713:\tlearn: 1.5111696\ttotal: 10.7s\tremaining: 4.29s\n",
      "714:\tlearn: 1.5111690\ttotal: 10.7s\tremaining: 4.28s\n",
      "715:\tlearn: 1.5111690\ttotal: 10.7s\tremaining: 4.26s\n",
      "716:\tlearn: 1.5111687\ttotal: 10.8s\tremaining: 4.25s\n",
      "717:\tlearn: 1.5111683\ttotal: 10.8s\tremaining: 4.23s\n",
      "718:\tlearn: 1.5111506\ttotal: 10.8s\tremaining: 4.21s\n",
      "719:\tlearn: 1.5108910\ttotal: 10.8s\tremaining: 4.2s\n",
      "720:\tlearn: 1.5108565\ttotal: 10.8s\tremaining: 4.18s\n",
      "721:\tlearn: 1.5099811\ttotal: 10.8s\tremaining: 4.17s\n",
      "722:\tlearn: 1.5099811\ttotal: 10.8s\tremaining: 4.15s\n",
      "723:\tlearn: 1.5099811\ttotal: 10.9s\tremaining: 4.14s\n",
      "724:\tlearn: 1.5099811\ttotal: 10.9s\tremaining: 4.12s\n",
      "725:\tlearn: 1.5099811\ttotal: 10.9s\tremaining: 4.11s\n",
      "726:\tlearn: 1.5099810\ttotal: 10.9s\tremaining: 4.09s\n",
      "727:\tlearn: 1.5099810\ttotal: 10.9s\tremaining: 4.08s\n",
      "728:\tlearn: 1.5099780\ttotal: 10.9s\tremaining: 4.06s\n",
      "729:\tlearn: 1.5099780\ttotal: 10.9s\tremaining: 4.04s\n",
      "730:\tlearn: 1.5099780\ttotal: 10.9s\tremaining: 4.03s\n",
      "731:\tlearn: 1.5099780\ttotal: 11s\tremaining: 4.01s\n",
      "732:\tlearn: 1.5099780\ttotal: 11s\tremaining: 4s\n",
      "733:\tlearn: 1.5099780\ttotal: 11s\tremaining: 3.98s\n",
      "734:\tlearn: 1.5099780\ttotal: 11s\tremaining: 3.97s\n",
      "735:\tlearn: 1.5099780\ttotal: 11s\tremaining: 3.95s\n",
      "736:\tlearn: 1.5099780\ttotal: 11s\tremaining: 3.94s\n",
      "737:\tlearn: 1.5099780\ttotal: 11s\tremaining: 3.92s\n",
      "738:\tlearn: 1.5088844\ttotal: 11.1s\tremaining: 3.91s\n",
      "739:\tlearn: 1.5083191\ttotal: 11.1s\tremaining: 3.89s\n",
      "740:\tlearn: 1.5082389\ttotal: 11.1s\tremaining: 3.88s\n",
      "741:\tlearn: 1.5071352\ttotal: 11.1s\tremaining: 3.86s\n",
      "742:\tlearn: 1.5070658\ttotal: 11.1s\tremaining: 3.85s\n",
      "743:\tlearn: 1.5069824\ttotal: 11.1s\tremaining: 3.83s\n",
      "744:\tlearn: 1.5069696\ttotal: 11.1s\tremaining: 3.81s\n",
      "745:\tlearn: 1.5069507\ttotal: 11.2s\tremaining: 3.8s\n",
      "746:\tlearn: 1.5069506\ttotal: 11.2s\tremaining: 3.79s\n",
      "747:\tlearn: 1.5069505\ttotal: 11.2s\tremaining: 3.77s\n",
      "748:\tlearn: 1.5068238\ttotal: 11.2s\tremaining: 3.76s\n",
      "749:\tlearn: 1.5068004\ttotal: 11.2s\tremaining: 3.74s\n",
      "750:\tlearn: 1.5066000\ttotal: 11.2s\tremaining: 3.73s\n",
      "751:\tlearn: 1.5063285\ttotal: 11.3s\tremaining: 3.71s\n",
      "752:\tlearn: 1.5063228\ttotal: 11.3s\tremaining: 3.69s\n",
      "753:\tlearn: 1.5063137\ttotal: 11.3s\tremaining: 3.68s\n",
      "754:\tlearn: 1.5062842\ttotal: 11.3s\tremaining: 3.67s\n",
      "755:\tlearn: 1.5062838\ttotal: 11.3s\tremaining: 3.65s\n",
      "756:\tlearn: 1.5062837\ttotal: 11.3s\tremaining: 3.63s\n",
      "757:\tlearn: 1.5062743\ttotal: 11.3s\tremaining: 3.62s\n",
      "758:\tlearn: 1.5062742\ttotal: 11.3s\tremaining: 3.6s\n",
      "759:\tlearn: 1.5062732\ttotal: 11.4s\tremaining: 3.59s\n",
      "760:\tlearn: 1.5062720\ttotal: 11.4s\tremaining: 3.57s\n",
      "761:\tlearn: 1.5062719\ttotal: 11.4s\tremaining: 3.56s\n",
      "762:\tlearn: 1.5062718\ttotal: 11.4s\tremaining: 3.54s\n",
      "763:\tlearn: 1.5062696\ttotal: 11.4s\tremaining: 3.53s\n",
      "764:\tlearn: 1.5062696\ttotal: 11.4s\tremaining: 3.51s\n",
      "765:\tlearn: 1.5062696\ttotal: 11.5s\tremaining: 3.5s\n",
      "766:\tlearn: 1.5062314\ttotal: 11.5s\tremaining: 3.48s\n",
      "767:\tlearn: 1.5055427\ttotal: 11.5s\tremaining: 3.47s\n",
      "768:\tlearn: 1.5055349\ttotal: 11.5s\tremaining: 3.45s\n",
      "769:\tlearn: 1.5055349\ttotal: 11.5s\tremaining: 3.44s\n",
      "770:\tlearn: 1.5055348\ttotal: 11.5s\tremaining: 3.42s\n",
      "771:\tlearn: 1.5055322\ttotal: 11.5s\tremaining: 3.41s\n",
      "772:\tlearn: 1.5055096\ttotal: 11.6s\tremaining: 3.39s\n",
      "773:\tlearn: 1.5052162\ttotal: 11.6s\tremaining: 3.38s\n",
      "774:\tlearn: 1.5048025\ttotal: 11.6s\tremaining: 3.36s\n",
      "775:\tlearn: 1.5047980\ttotal: 11.6s\tremaining: 3.35s\n",
      "776:\tlearn: 1.5039046\ttotal: 11.6s\tremaining: 3.33s\n",
      "777:\tlearn: 1.5039023\ttotal: 11.6s\tremaining: 3.32s\n",
      "778:\tlearn: 1.5039023\ttotal: 11.6s\tremaining: 3.3s\n",
      "779:\tlearn: 1.5039022\ttotal: 11.7s\tremaining: 3.29s\n",
      "780:\tlearn: 1.5039018\ttotal: 11.7s\tremaining: 3.27s\n",
      "781:\tlearn: 1.5039016\ttotal: 11.7s\tremaining: 3.26s\n",
      "782:\tlearn: 1.5038991\ttotal: 11.7s\tremaining: 3.24s\n",
      "783:\tlearn: 1.5038866\ttotal: 11.7s\tremaining: 3.23s\n",
      "784:\tlearn: 1.5038644\ttotal: 11.7s\tremaining: 3.21s\n",
      "785:\tlearn: 1.5038643\ttotal: 11.7s\tremaining: 3.2s\n",
      "786:\tlearn: 1.5038093\ttotal: 11.8s\tremaining: 3.18s\n",
      "787:\tlearn: 1.5037999\ttotal: 11.8s\tremaining: 3.17s\n",
      "788:\tlearn: 1.5037999\ttotal: 11.8s\tremaining: 3.15s\n",
      "789:\tlearn: 1.5037999\ttotal: 11.8s\tremaining: 3.13s\n",
      "790:\tlearn: 1.5037737\ttotal: 11.8s\tremaining: 3.12s\n",
      "791:\tlearn: 1.5028499\ttotal: 11.8s\tremaining: 3.1s\n",
      "792:\tlearn: 1.5027831\ttotal: 11.8s\tremaining: 3.09s\n",
      "793:\tlearn: 1.5022912\ttotal: 11.9s\tremaining: 3.08s\n",
      "794:\tlearn: 1.5020212\ttotal: 11.9s\tremaining: 3.06s\n",
      "795:\tlearn: 1.5019888\ttotal: 11.9s\tremaining: 3.05s\n",
      "796:\tlearn: 1.5019808\ttotal: 11.9s\tremaining: 3.03s\n",
      "797:\tlearn: 1.5019782\ttotal: 11.9s\tremaining: 3.02s\n",
      "798:\tlearn: 1.5019763\ttotal: 11.9s\tremaining: 3s\n",
      "799:\tlearn: 1.5019762\ttotal: 11.9s\tremaining: 2.98s\n",
      "800:\tlearn: 1.5019760\ttotal: 12s\tremaining: 2.97s\n",
      "801:\tlearn: 1.5019441\ttotal: 12s\tremaining: 2.95s\n",
      "802:\tlearn: 1.5019268\ttotal: 12s\tremaining: 2.94s\n",
      "803:\tlearn: 1.5019063\ttotal: 12s\tremaining: 2.92s\n",
      "804:\tlearn: 1.5019040\ttotal: 12s\tremaining: 2.91s\n",
      "805:\tlearn: 1.5019017\ttotal: 12s\tremaining: 2.89s\n",
      "806:\tlearn: 1.5019017\ttotal: 12s\tremaining: 2.88s\n",
      "807:\tlearn: 1.5019017\ttotal: 12.1s\tremaining: 2.86s\n",
      "808:\tlearn: 1.5019017\ttotal: 12.1s\tremaining: 2.85s\n",
      "809:\tlearn: 1.5019017\ttotal: 12.1s\tremaining: 2.83s\n",
      "810:\tlearn: 1.5019017\ttotal: 12.1s\tremaining: 2.82s\n",
      "811:\tlearn: 1.5019016\ttotal: 12.1s\tremaining: 2.81s\n",
      "812:\tlearn: 1.5018846\ttotal: 12.1s\tremaining: 2.79s\n",
      "813:\tlearn: 1.5018759\ttotal: 12.1s\tremaining: 2.77s\n",
      "814:\tlearn: 1.5018721\ttotal: 12.2s\tremaining: 2.76s\n",
      "815:\tlearn: 1.5018581\ttotal: 12.2s\tremaining: 2.74s\n",
      "816:\tlearn: 1.5012763\ttotal: 12.2s\tremaining: 2.73s\n",
      "817:\tlearn: 1.5008195\ttotal: 12.2s\tremaining: 2.71s\n",
      "818:\tlearn: 1.5007431\ttotal: 12.2s\tremaining: 2.7s\n",
      "819:\tlearn: 1.4997973\ttotal: 12.2s\tremaining: 2.68s\n",
      "820:\tlearn: 1.4997843\ttotal: 12.2s\tremaining: 2.67s\n",
      "821:\tlearn: 1.4997838\ttotal: 12.3s\tremaining: 2.65s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "822:\tlearn: 1.4997631\ttotal: 12.3s\tremaining: 2.64s\n",
      "823:\tlearn: 1.4997520\ttotal: 12.3s\tremaining: 2.62s\n",
      "824:\tlearn: 1.4997520\ttotal: 12.3s\tremaining: 2.61s\n",
      "825:\tlearn: 1.4997519\ttotal: 12.3s\tremaining: 2.6s\n",
      "826:\tlearn: 1.4997121\ttotal: 12.3s\tremaining: 2.58s\n",
      "827:\tlearn: 1.4995328\ttotal: 12.3s\tremaining: 2.56s\n",
      "828:\tlearn: 1.4994745\ttotal: 12.4s\tremaining: 2.55s\n",
      "829:\tlearn: 1.4994304\ttotal: 12.4s\tremaining: 2.54s\n",
      "830:\tlearn: 1.4994303\ttotal: 12.4s\tremaining: 2.52s\n",
      "831:\tlearn: 1.4993903\ttotal: 12.4s\tremaining: 2.5s\n",
      "832:\tlearn: 1.4993744\ttotal: 12.4s\tremaining: 2.49s\n",
      "833:\tlearn: 1.4988933\ttotal: 12.4s\tremaining: 2.47s\n",
      "834:\tlearn: 1.4988929\ttotal: 12.4s\tremaining: 2.46s\n",
      "835:\tlearn: 1.4985129\ttotal: 12.5s\tremaining: 2.44s\n",
      "836:\tlearn: 1.4984195\ttotal: 12.5s\tremaining: 2.43s\n",
      "837:\tlearn: 1.4983495\ttotal: 12.5s\tremaining: 2.41s\n",
      "838:\tlearn: 1.4983361\ttotal: 12.5s\tremaining: 2.4s\n",
      "839:\tlearn: 1.4983342\ttotal: 12.5s\tremaining: 2.38s\n",
      "840:\tlearn: 1.4983342\ttotal: 12.5s\tremaining: 2.37s\n",
      "841:\tlearn: 1.4983342\ttotal: 12.5s\tremaining: 2.35s\n",
      "842:\tlearn: 1.4983243\ttotal: 12.6s\tremaining: 2.34s\n",
      "843:\tlearn: 1.4983242\ttotal: 12.6s\tremaining: 2.32s\n",
      "844:\tlearn: 1.4983160\ttotal: 12.6s\tremaining: 2.31s\n",
      "845:\tlearn: 1.4982885\ttotal: 12.6s\tremaining: 2.29s\n",
      "846:\tlearn: 1.4982605\ttotal: 12.6s\tremaining: 2.28s\n",
      "847:\tlearn: 1.4973609\ttotal: 12.6s\tremaining: 2.26s\n",
      "848:\tlearn: 1.4973018\ttotal: 12.6s\tremaining: 2.25s\n",
      "849:\tlearn: 1.4972935\ttotal: 12.7s\tremaining: 2.23s\n",
      "850:\tlearn: 1.4972935\ttotal: 12.7s\tremaining: 2.22s\n",
      "851:\tlearn: 1.4972929\ttotal: 12.7s\tremaining: 2.2s\n",
      "852:\tlearn: 1.4972928\ttotal: 12.7s\tremaining: 2.19s\n",
      "853:\tlearn: 1.4972909\ttotal: 12.7s\tremaining: 2.17s\n",
      "854:\tlearn: 1.4972909\ttotal: 12.7s\tremaining: 2.16s\n",
      "855:\tlearn: 1.4972908\ttotal: 12.8s\tremaining: 2.14s\n",
      "856:\tlearn: 1.4972907\ttotal: 12.8s\tremaining: 2.13s\n",
      "857:\tlearn: 1.4972906\ttotal: 12.8s\tremaining: 2.11s\n",
      "858:\tlearn: 1.4972906\ttotal: 12.8s\tremaining: 2.1s\n",
      "859:\tlearn: 1.4972906\ttotal: 12.8s\tremaining: 2.08s\n",
      "860:\tlearn: 1.4972905\ttotal: 12.8s\tremaining: 2.07s\n",
      "861:\tlearn: 1.4972905\ttotal: 12.8s\tremaining: 2.05s\n",
      "862:\tlearn: 1.4972752\ttotal: 12.9s\tremaining: 2.04s\n",
      "863:\tlearn: 1.4968775\ttotal: 12.9s\tremaining: 2.02s\n",
      "864:\tlearn: 1.4960898\ttotal: 12.9s\tremaining: 2.01s\n",
      "865:\tlearn: 1.4960347\ttotal: 12.9s\tremaining: 2s\n",
      "866:\tlearn: 1.4959551\ttotal: 12.9s\tremaining: 1.98s\n",
      "867:\tlearn: 1.4954676\ttotal: 12.9s\tremaining: 1.97s\n",
      "868:\tlearn: 1.4954668\ttotal: 12.9s\tremaining: 1.95s\n",
      "869:\tlearn: 1.4954664\ttotal: 13s\tremaining: 1.94s\n",
      "870:\tlearn: 1.4954426\ttotal: 13s\tremaining: 1.92s\n",
      "871:\tlearn: 1.4950414\ttotal: 13s\tremaining: 1.91s\n",
      "872:\tlearn: 1.4946248\ttotal: 13s\tremaining: 1.89s\n",
      "873:\tlearn: 1.4941983\ttotal: 13s\tremaining: 1.88s\n",
      "874:\tlearn: 1.4934778\ttotal: 13s\tremaining: 1.86s\n",
      "875:\tlearn: 1.4933435\ttotal: 13s\tremaining: 1.84s\n",
      "876:\tlearn: 1.4933435\ttotal: 13.1s\tremaining: 1.83s\n",
      "877:\tlearn: 1.4933435\ttotal: 13.1s\tremaining: 1.81s\n",
      "878:\tlearn: 1.4933434\ttotal: 13.1s\tremaining: 1.8s\n",
      "879:\tlearn: 1.4933428\ttotal: 13.1s\tremaining: 1.78s\n",
      "880:\tlearn: 1.4933428\ttotal: 13.1s\tremaining: 1.77s\n",
      "881:\tlearn: 1.4933386\ttotal: 13.1s\tremaining: 1.75s\n",
      "882:\tlearn: 1.4931682\ttotal: 13.1s\tremaining: 1.74s\n",
      "883:\tlearn: 1.4928696\ttotal: 13.2s\tremaining: 1.73s\n",
      "884:\tlearn: 1.4928496\ttotal: 13.2s\tremaining: 1.71s\n",
      "885:\tlearn: 1.4927052\ttotal: 13.2s\tremaining: 1.7s\n",
      "886:\tlearn: 1.4926600\ttotal: 13.2s\tremaining: 1.68s\n",
      "887:\tlearn: 1.4925042\ttotal: 13.2s\tremaining: 1.67s\n",
      "888:\tlearn: 1.4924890\ttotal: 13.2s\tremaining: 1.65s\n",
      "889:\tlearn: 1.4924746\ttotal: 13.2s\tremaining: 1.64s\n",
      "890:\tlearn: 1.4924627\ttotal: 13.3s\tremaining: 1.62s\n",
      "891:\tlearn: 1.4917518\ttotal: 13.3s\tremaining: 1.61s\n",
      "892:\tlearn: 1.4917272\ttotal: 13.3s\tremaining: 1.59s\n",
      "893:\tlearn: 1.4917271\ttotal: 13.3s\tremaining: 1.58s\n",
      "894:\tlearn: 1.4916967\ttotal: 13.3s\tremaining: 1.56s\n",
      "895:\tlearn: 1.4907102\ttotal: 13.3s\tremaining: 1.55s\n",
      "896:\tlearn: 1.4906270\ttotal: 13.3s\tremaining: 1.53s\n",
      "897:\tlearn: 1.4905491\ttotal: 13.4s\tremaining: 1.52s\n",
      "898:\tlearn: 1.4901771\ttotal: 13.4s\tremaining: 1.5s\n",
      "899:\tlearn: 1.4900683\ttotal: 13.4s\tremaining: 1.49s\n",
      "900:\tlearn: 1.4895031\ttotal: 13.4s\tremaining: 1.47s\n",
      "901:\tlearn: 1.4893575\ttotal: 13.4s\tremaining: 1.46s\n",
      "902:\tlearn: 1.4892816\ttotal: 13.4s\tremaining: 1.44s\n",
      "903:\tlearn: 1.4880887\ttotal: 13.4s\tremaining: 1.43s\n",
      "904:\tlearn: 1.4880878\ttotal: 13.5s\tremaining: 1.41s\n",
      "905:\tlearn: 1.4880550\ttotal: 13.5s\tremaining: 1.4s\n",
      "906:\tlearn: 1.4877048\ttotal: 13.5s\tremaining: 1.38s\n",
      "907:\tlearn: 1.4870677\ttotal: 13.5s\tremaining: 1.37s\n",
      "908:\tlearn: 1.4870573\ttotal: 13.5s\tremaining: 1.35s\n",
      "909:\tlearn: 1.4870572\ttotal: 13.5s\tremaining: 1.34s\n",
      "910:\tlearn: 1.4870186\ttotal: 13.5s\tremaining: 1.32s\n",
      "911:\tlearn: 1.4870138\ttotal: 13.6s\tremaining: 1.31s\n",
      "912:\tlearn: 1.4869704\ttotal: 13.6s\tremaining: 1.29s\n",
      "913:\tlearn: 1.4869085\ttotal: 13.6s\tremaining: 1.28s\n",
      "914:\tlearn: 1.4865395\ttotal: 13.6s\tremaining: 1.26s\n",
      "915:\tlearn: 1.4865240\ttotal: 13.6s\tremaining: 1.25s\n",
      "916:\tlearn: 1.4861200\ttotal: 13.6s\tremaining: 1.23s\n",
      "917:\tlearn: 1.4857432\ttotal: 13.7s\tremaining: 1.22s\n",
      "918:\tlearn: 1.4851467\ttotal: 13.7s\tremaining: 1.2s\n",
      "919:\tlearn: 1.4851021\ttotal: 13.7s\tremaining: 1.19s\n",
      "920:\tlearn: 1.4847504\ttotal: 13.7s\tremaining: 1.17s\n",
      "921:\tlearn: 1.4846541\ttotal: 13.7s\tremaining: 1.16s\n",
      "922:\tlearn: 1.4838874\ttotal: 13.7s\tremaining: 1.15s\n",
      "923:\tlearn: 1.4833080\ttotal: 13.7s\tremaining: 1.13s\n",
      "924:\tlearn: 1.4830148\ttotal: 13.8s\tremaining: 1.11s\n",
      "925:\tlearn: 1.4827041\ttotal: 13.8s\tremaining: 1.1s\n",
      "926:\tlearn: 1.4823896\ttotal: 13.8s\tremaining: 1.08s\n",
      "927:\tlearn: 1.4818184\ttotal: 13.8s\tremaining: 1.07s\n",
      "928:\tlearn: 1.4815443\ttotal: 13.8s\tremaining: 1.06s\n",
      "929:\tlearn: 1.4815235\ttotal: 13.8s\tremaining: 1.04s\n",
      "930:\tlearn: 1.4812847\ttotal: 13.8s\tremaining: 1.03s\n",
      "931:\tlearn: 1.4812846\ttotal: 13.9s\tremaining: 1.01s\n",
      "932:\tlearn: 1.4812846\ttotal: 13.9s\tremaining: 996ms\n",
      "933:\tlearn: 1.4812846\ttotal: 13.9s\tremaining: 981ms\n",
      "934:\tlearn: 1.4812839\ttotal: 13.9s\tremaining: 967ms\n",
      "935:\tlearn: 1.4812838\ttotal: 13.9s\tremaining: 952ms\n",
      "936:\tlearn: 1.4812838\ttotal: 13.9s\tremaining: 937ms\n",
      "937:\tlearn: 1.4812838\ttotal: 13.9s\tremaining: 922ms\n",
      "938:\tlearn: 1.4812838\ttotal: 14s\tremaining: 907ms\n",
      "939:\tlearn: 1.4812816\ttotal: 14s\tremaining: 892ms\n",
      "940:\tlearn: 1.4811673\ttotal: 14s\tremaining: 877ms\n",
      "941:\tlearn: 1.4811355\ttotal: 14s\tremaining: 862ms\n",
      "942:\tlearn: 1.4811283\ttotal: 14s\tremaining: 848ms\n",
      "943:\tlearn: 1.4811246\ttotal: 14s\tremaining: 833ms\n",
      "944:\tlearn: 1.4811154\ttotal: 14.1s\tremaining: 818ms\n",
      "945:\tlearn: 1.4811147\ttotal: 14.1s\tremaining: 803ms\n",
      "946:\tlearn: 1.4810736\ttotal: 14.1s\tremaining: 788ms\n",
      "947:\tlearn: 1.4808076\ttotal: 14.1s\tremaining: 773ms\n",
      "948:\tlearn: 1.4807571\ttotal: 14.1s\tremaining: 758ms\n",
      "949:\tlearn: 1.4805109\ttotal: 14.1s\tremaining: 743ms\n",
      "950:\tlearn: 1.4804920\ttotal: 14.1s\tremaining: 728ms\n",
      "951:\tlearn: 1.4802712\ttotal: 14.2s\tremaining: 714ms\n",
      "952:\tlearn: 1.4802358\ttotal: 14.2s\tremaining: 699ms\n",
      "953:\tlearn: 1.4802330\ttotal: 14.2s\tremaining: 684ms\n",
      "954:\tlearn: 1.4801965\ttotal: 14.2s\tremaining: 669ms\n",
      "955:\tlearn: 1.4800870\ttotal: 14.2s\tremaining: 654ms\n",
      "956:\tlearn: 1.4800200\ttotal: 14.2s\tremaining: 639ms\n",
      "957:\tlearn: 1.4800188\ttotal: 14.2s\tremaining: 624ms\n",
      "958:\tlearn: 1.4798095\ttotal: 14.3s\tremaining: 609ms\n",
      "959:\tlearn: 1.4798095\ttotal: 14.3s\tremaining: 595ms\n",
      "960:\tlearn: 1.4798091\ttotal: 14.3s\tremaining: 580ms\n",
      "961:\tlearn: 1.4797032\ttotal: 14.3s\tremaining: 565ms\n",
      "962:\tlearn: 1.4796236\ttotal: 14.3s\tremaining: 550ms\n",
      "963:\tlearn: 1.4796061\ttotal: 14.3s\tremaining: 535ms\n",
      "964:\tlearn: 1.4796032\ttotal: 14.3s\tremaining: 520ms\n",
      "965:\tlearn: 1.4791307\ttotal: 14.4s\tremaining: 505ms\n",
      "966:\tlearn: 1.4781691\ttotal: 14.4s\tremaining: 490ms\n",
      "967:\tlearn: 1.4781448\ttotal: 14.4s\tremaining: 475ms\n",
      "968:\tlearn: 1.4780484\ttotal: 14.4s\tremaining: 460ms\n",
      "969:\tlearn: 1.4780445\ttotal: 14.4s\tremaining: 446ms\n",
      "970:\tlearn: 1.4780219\ttotal: 14.4s\tremaining: 431ms\n",
      "971:\tlearn: 1.4778873\ttotal: 14.4s\tremaining: 416ms\n",
      "972:\tlearn: 1.4778768\ttotal: 14.5s\tremaining: 401ms\n",
      "973:\tlearn: 1.4777993\ttotal: 14.5s\tremaining: 386ms\n",
      "974:\tlearn: 1.4777990\ttotal: 14.5s\tremaining: 371ms\n",
      "975:\tlearn: 1.4774150\ttotal: 14.5s\tremaining: 356ms\n",
      "976:\tlearn: 1.4774091\ttotal: 14.5s\tremaining: 342ms\n",
      "977:\tlearn: 1.4773973\ttotal: 14.5s\tremaining: 327ms\n",
      "978:\tlearn: 1.4771906\ttotal: 14.5s\tremaining: 312ms\n",
      "979:\tlearn: 1.4771872\ttotal: 14.5s\tremaining: 297ms\n",
      "980:\tlearn: 1.4770337\ttotal: 14.6s\tremaining: 282ms\n",
      "981:\tlearn: 1.4770336\ttotal: 14.6s\tremaining: 267ms\n",
      "982:\tlearn: 1.4770304\ttotal: 14.6s\tremaining: 252ms\n",
      "983:\tlearn: 1.4770302\ttotal: 14.6s\tremaining: 238ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "984:\tlearn: 1.4770302\ttotal: 14.6s\tremaining: 223ms\n",
      "985:\tlearn: 1.4770216\ttotal: 14.6s\tremaining: 208ms\n",
      "986:\tlearn: 1.4770214\ttotal: 14.7s\tremaining: 193ms\n",
      "987:\tlearn: 1.4769946\ttotal: 14.7s\tremaining: 178ms\n",
      "988:\tlearn: 1.4769938\ttotal: 14.7s\tremaining: 163ms\n",
      "989:\tlearn: 1.4768920\ttotal: 14.7s\tremaining: 148ms\n",
      "990:\tlearn: 1.4768919\ttotal: 14.7s\tremaining: 134ms\n",
      "991:\tlearn: 1.4768907\ttotal: 14.7s\tremaining: 119ms\n",
      "992:\tlearn: 1.4768066\ttotal: 14.7s\tremaining: 104ms\n",
      "993:\tlearn: 1.4761112\ttotal: 14.8s\tremaining: 89ms\n",
      "994:\tlearn: 1.4754762\ttotal: 14.8s\tremaining: 74.2ms\n",
      "995:\tlearn: 1.4754315\ttotal: 14.8s\tremaining: 59.4ms\n",
      "996:\tlearn: 1.4750733\ttotal: 14.8s\tremaining: 44.5ms\n",
      "997:\tlearn: 1.4748903\ttotal: 14.8s\tremaining: 29.7ms\n",
      "998:\tlearn: 1.4746443\ttotal: 14.8s\tremaining: 14.8ms\n",
      "999:\tlearn: 1.4746353\ttotal: 14.8s\tremaining: 0us\n",
      "0:\tlearn: 9.6049396\ttotal: 17.2ms\tremaining: 17.2s\n",
      "1:\tlearn: 8.9116760\ttotal: 35.7ms\tremaining: 17.8s\n",
      "2:\tlearn: 8.2376176\ttotal: 53.9ms\tremaining: 17.9s\n",
      "3:\tlearn: 7.6454094\ttotal: 73.7ms\tremaining: 18.3s\n",
      "4:\tlearn: 7.0283600\ttotal: 92.7ms\tremaining: 18.4s\n",
      "5:\tlearn: 6.5677190\ttotal: 110ms\tremaining: 18.3s\n",
      "6:\tlearn: 6.0512962\ttotal: 129ms\tremaining: 18.2s\n",
      "7:\tlearn: 5.6969473\ttotal: 146ms\tremaining: 18s\n",
      "8:\tlearn: 5.2491109\ttotal: 163ms\tremaining: 17.9s\n",
      "9:\tlearn: 4.8620231\ttotal: 181ms\tremaining: 18s\n",
      "10:\tlearn: 4.5486492\ttotal: 199ms\tremaining: 17.9s\n",
      "11:\tlearn: 4.3428171\ttotal: 216ms\tremaining: 17.8s\n",
      "12:\tlearn: 4.0683896\ttotal: 233ms\tremaining: 17.7s\n",
      "13:\tlearn: 3.8349811\ttotal: 250ms\tremaining: 17.6s\n",
      "14:\tlearn: 3.6284363\ttotal: 266ms\tremaining: 17.5s\n",
      "15:\tlearn: 3.4457690\ttotal: 285ms\tremaining: 17.5s\n",
      "16:\tlearn: 3.3525010\ttotal: 303ms\tremaining: 17.5s\n",
      "17:\tlearn: 3.2136442\ttotal: 321ms\tremaining: 17.5s\n",
      "18:\tlearn: 3.0920471\ttotal: 338ms\tremaining: 17.4s\n",
      "19:\tlearn: 2.9724254\ttotal: 355ms\tremaining: 17.4s\n",
      "20:\tlearn: 2.9146224\ttotal: 370ms\tremaining: 17.2s\n",
      "21:\tlearn: 2.8642378\ttotal: 385ms\tremaining: 17.1s\n",
      "22:\tlearn: 2.8225494\ttotal: 400ms\tremaining: 17s\n",
      "23:\tlearn: 2.7663312\ttotal: 415ms\tremaining: 16.9s\n",
      "24:\tlearn: 2.7057133\ttotal: 430ms\tremaining: 16.8s\n",
      "25:\tlearn: 2.6805568\ttotal: 445ms\tremaining: 16.7s\n",
      "26:\tlearn: 2.6574582\ttotal: 459ms\tremaining: 16.5s\n",
      "27:\tlearn: 2.6124078\ttotal: 475ms\tremaining: 16.5s\n",
      "28:\tlearn: 2.5919888\ttotal: 491ms\tremaining: 16.4s\n",
      "29:\tlearn: 2.5478758\ttotal: 508ms\tremaining: 16.4s\n",
      "30:\tlearn: 2.5237616\ttotal: 523ms\tremaining: 16.4s\n",
      "31:\tlearn: 2.5088120\ttotal: 537ms\tremaining: 16.3s\n",
      "32:\tlearn: 2.4824120\ttotal: 551ms\tremaining: 16.2s\n",
      "33:\tlearn: 2.4487691\ttotal: 566ms\tremaining: 16.1s\n",
      "34:\tlearn: 2.4364287\ttotal: 581ms\tremaining: 16s\n",
      "35:\tlearn: 2.4268359\ttotal: 596ms\tremaining: 16s\n",
      "36:\tlearn: 2.4018124\ttotal: 612ms\tremaining: 15.9s\n",
      "37:\tlearn: 2.3844473\ttotal: 626ms\tremaining: 15.9s\n",
      "38:\tlearn: 2.3604134\ttotal: 641ms\tremaining: 15.8s\n",
      "39:\tlearn: 2.3554887\ttotal: 656ms\tremaining: 15.7s\n",
      "40:\tlearn: 2.3478867\ttotal: 671ms\tremaining: 15.7s\n",
      "41:\tlearn: 2.3444673\ttotal: 685ms\tremaining: 15.6s\n",
      "42:\tlearn: 2.3389402\ttotal: 699ms\tremaining: 15.6s\n",
      "43:\tlearn: 2.3371329\ttotal: 715ms\tremaining: 15.5s\n",
      "44:\tlearn: 2.3355670\ttotal: 732ms\tremaining: 15.5s\n",
      "45:\tlearn: 2.3336859\ttotal: 747ms\tremaining: 15.5s\n",
      "46:\tlearn: 2.3184872\ttotal: 761ms\tremaining: 15.4s\n",
      "47:\tlearn: 2.3139723\ttotal: 776ms\tremaining: 15.4s\n",
      "48:\tlearn: 2.3097543\ttotal: 791ms\tremaining: 15.4s\n",
      "49:\tlearn: 2.3077576\ttotal: 806ms\tremaining: 15.3s\n",
      "50:\tlearn: 2.3068511\ttotal: 821ms\tremaining: 15.3s\n",
      "51:\tlearn: 2.3038821\ttotal: 836ms\tremaining: 15.2s\n",
      "52:\tlearn: 2.3023571\ttotal: 851ms\tremaining: 15.2s\n",
      "53:\tlearn: 2.2999125\ttotal: 866ms\tremaining: 15.2s\n",
      "54:\tlearn: 2.2986210\ttotal: 881ms\tremaining: 15.1s\n",
      "55:\tlearn: 2.2864308\ttotal: 895ms\tremaining: 15.1s\n",
      "56:\tlearn: 2.2827103\ttotal: 909ms\tremaining: 15s\n",
      "57:\tlearn: 2.2820972\ttotal: 924ms\tremaining: 15s\n",
      "58:\tlearn: 2.2819695\ttotal: 941ms\tremaining: 15s\n",
      "59:\tlearn: 2.2813955\ttotal: 955ms\tremaining: 15s\n",
      "60:\tlearn: 2.2812602\ttotal: 970ms\tremaining: 14.9s\n",
      "61:\tlearn: 2.2807935\ttotal: 986ms\tremaining: 14.9s\n",
      "62:\tlearn: 2.2701476\ttotal: 1s\tremaining: 14.9s\n",
      "63:\tlearn: 2.2679000\ttotal: 1.01s\tremaining: 14.8s\n",
      "64:\tlearn: 2.2673523\ttotal: 1.03s\tremaining: 14.8s\n",
      "65:\tlearn: 2.2654044\ttotal: 1.04s\tremaining: 14.8s\n",
      "66:\tlearn: 2.2648472\ttotal: 1.06s\tremaining: 14.7s\n",
      "67:\tlearn: 2.2593992\ttotal: 1.07s\tremaining: 14.7s\n",
      "68:\tlearn: 2.2518622\ttotal: 1.09s\tremaining: 14.7s\n",
      "69:\tlearn: 2.2506867\ttotal: 1.1s\tremaining: 14.6s\n",
      "70:\tlearn: 2.2504264\ttotal: 1.12s\tremaining: 14.6s\n",
      "71:\tlearn: 2.2502052\ttotal: 1.13s\tremaining: 14.6s\n",
      "72:\tlearn: 2.2497791\ttotal: 1.15s\tremaining: 14.6s\n",
      "73:\tlearn: 2.2495807\ttotal: 1.16s\tremaining: 14.6s\n",
      "74:\tlearn: 2.2491108\ttotal: 1.18s\tremaining: 14.5s\n",
      "75:\tlearn: 2.2476759\ttotal: 1.19s\tremaining: 14.5s\n",
      "76:\tlearn: 2.2461550\ttotal: 1.21s\tremaining: 14.5s\n",
      "77:\tlearn: 2.2459961\ttotal: 1.22s\tremaining: 14.4s\n",
      "78:\tlearn: 2.2449357\ttotal: 1.24s\tremaining: 14.4s\n",
      "79:\tlearn: 2.2448112\ttotal: 1.25s\tremaining: 14.4s\n",
      "80:\tlearn: 2.2431860\ttotal: 1.26s\tremaining: 14.3s\n",
      "81:\tlearn: 2.2348982\ttotal: 1.28s\tremaining: 14.3s\n",
      "82:\tlearn: 2.2343212\ttotal: 1.29s\tremaining: 14.3s\n",
      "83:\tlearn: 2.2340269\ttotal: 1.31s\tremaining: 14.3s\n",
      "84:\tlearn: 2.2282926\ttotal: 1.32s\tremaining: 14.2s\n",
      "85:\tlearn: 2.2280050\ttotal: 1.34s\tremaining: 14.2s\n",
      "86:\tlearn: 2.2274732\ttotal: 1.35s\tremaining: 14.2s\n",
      "87:\tlearn: 2.2263613\ttotal: 1.37s\tremaining: 14.2s\n",
      "88:\tlearn: 2.2260777\ttotal: 1.38s\tremaining: 14.2s\n",
      "89:\tlearn: 2.2244637\ttotal: 1.4s\tremaining: 14.1s\n",
      "90:\tlearn: 2.2242780\ttotal: 1.41s\tremaining: 14.1s\n",
      "91:\tlearn: 2.2235494\ttotal: 1.43s\tremaining: 14.1s\n",
      "92:\tlearn: 2.2235459\ttotal: 1.44s\tremaining: 14s\n",
      "93:\tlearn: 2.2227520\ttotal: 1.45s\tremaining: 14s\n",
      "94:\tlearn: 2.2217401\ttotal: 1.47s\tremaining: 14s\n",
      "95:\tlearn: 2.2217316\ttotal: 1.48s\tremaining: 14s\n",
      "96:\tlearn: 2.2210667\ttotal: 1.5s\tremaining: 13.9s\n",
      "97:\tlearn: 2.2204366\ttotal: 1.51s\tremaining: 13.9s\n",
      "98:\tlearn: 2.2197398\ttotal: 1.53s\tremaining: 13.9s\n",
      "99:\tlearn: 2.2196209\ttotal: 1.54s\tremaining: 13.9s\n",
      "100:\tlearn: 2.2194746\ttotal: 1.55s\tremaining: 13.8s\n",
      "101:\tlearn: 2.2130109\ttotal: 1.57s\tremaining: 13.8s\n",
      "102:\tlearn: 2.2097834\ttotal: 1.59s\tremaining: 13.8s\n",
      "103:\tlearn: 2.2037826\ttotal: 1.6s\tremaining: 13.8s\n",
      "104:\tlearn: 2.2029397\ttotal: 1.62s\tremaining: 13.8s\n",
      "105:\tlearn: 2.2022152\ttotal: 1.63s\tremaining: 13.8s\n",
      "106:\tlearn: 2.2018472\ttotal: 1.65s\tremaining: 13.7s\n",
      "107:\tlearn: 2.2009874\ttotal: 1.66s\tremaining: 13.7s\n",
      "108:\tlearn: 2.2000644\ttotal: 1.68s\tremaining: 13.7s\n",
      "109:\tlearn: 2.1998986\ttotal: 1.69s\tremaining: 13.7s\n",
      "110:\tlearn: 2.1991565\ttotal: 1.71s\tremaining: 13.7s\n",
      "111:\tlearn: 2.1987893\ttotal: 1.72s\tremaining: 13.6s\n",
      "112:\tlearn: 2.1980590\ttotal: 1.74s\tremaining: 13.6s\n",
      "113:\tlearn: 2.1978090\ttotal: 1.75s\tremaining: 13.6s\n",
      "114:\tlearn: 2.1970882\ttotal: 1.76s\tremaining: 13.6s\n",
      "115:\tlearn: 2.1968980\ttotal: 1.78s\tremaining: 13.6s\n",
      "116:\tlearn: 2.1964123\ttotal: 1.8s\tremaining: 13.6s\n",
      "117:\tlearn: 2.1961334\ttotal: 1.81s\tremaining: 13.5s\n",
      "118:\tlearn: 2.1960140\ttotal: 1.82s\tremaining: 13.5s\n",
      "119:\tlearn: 2.1902546\ttotal: 1.84s\tremaining: 13.5s\n",
      "120:\tlearn: 2.1848395\ttotal: 1.85s\tremaining: 13.5s\n",
      "121:\tlearn: 2.1795578\ttotal: 1.87s\tremaining: 13.4s\n",
      "122:\tlearn: 2.1790154\ttotal: 1.88s\tremaining: 13.4s\n",
      "123:\tlearn: 2.1787580\ttotal: 1.9s\tremaining: 13.4s\n",
      "124:\tlearn: 2.1786069\ttotal: 1.91s\tremaining: 13.4s\n",
      "125:\tlearn: 2.1768968\ttotal: 1.93s\tremaining: 13.4s\n",
      "126:\tlearn: 2.1766373\ttotal: 1.94s\tremaining: 13.3s\n",
      "127:\tlearn: 2.1763821\ttotal: 1.96s\tremaining: 13.3s\n",
      "128:\tlearn: 2.1760164\ttotal: 1.97s\tremaining: 13.3s\n",
      "129:\tlearn: 2.1751134\ttotal: 1.99s\tremaining: 13.3s\n",
      "130:\tlearn: 2.1743129\ttotal: 2s\tremaining: 13.3s\n",
      "131:\tlearn: 2.1721180\ttotal: 2.02s\tremaining: 13.3s\n",
      "132:\tlearn: 2.1702613\ttotal: 2.03s\tremaining: 13.2s\n",
      "133:\tlearn: 2.1682752\ttotal: 2.04s\tremaining: 13.2s\n",
      "134:\tlearn: 2.1624280\ttotal: 2.06s\tremaining: 13.2s\n",
      "135:\tlearn: 2.1564164\ttotal: 2.08s\tremaining: 13.2s\n",
      "136:\tlearn: 2.1502690\ttotal: 2.09s\tremaining: 13.2s\n",
      "137:\tlearn: 2.1486667\ttotal: 2.1s\tremaining: 13.1s\n",
      "138:\tlearn: 2.1465760\ttotal: 2.12s\tremaining: 13.1s\n",
      "139:\tlearn: 2.1436612\ttotal: 2.13s\tremaining: 13.1s\n",
      "140:\tlearn: 2.1364742\ttotal: 2.15s\tremaining: 13.1s\n",
      "141:\tlearn: 2.1319237\ttotal: 2.16s\tremaining: 13.1s\n",
      "142:\tlearn: 2.1264773\ttotal: 2.18s\tremaining: 13s\n",
      "143:\tlearn: 2.1213840\ttotal: 2.19s\tremaining: 13s\n",
      "144:\tlearn: 2.1158080\ttotal: 2.21s\tremaining: 13s\n",
      "145:\tlearn: 2.1112029\ttotal: 2.23s\tremaining: 13s\n",
      "146:\tlearn: 2.1060747\ttotal: 2.24s\tremaining: 13s\n",
      "147:\tlearn: 2.1032107\ttotal: 2.25s\tremaining: 13s\n",
      "148:\tlearn: 2.1016861\ttotal: 2.27s\tremaining: 13s\n",
      "149:\tlearn: 2.1000204\ttotal: 2.28s\tremaining: 12.9s\n",
      "150:\tlearn: 2.0986949\ttotal: 2.3s\tremaining: 12.9s\n",
      "151:\tlearn: 2.0977709\ttotal: 2.31s\tremaining: 12.9s\n",
      "152:\tlearn: 2.0930140\ttotal: 2.33s\tremaining: 12.9s\n",
      "153:\tlearn: 2.0898845\ttotal: 2.34s\tremaining: 12.9s\n",
      "154:\tlearn: 2.0886588\ttotal: 2.36s\tremaining: 12.8s\n",
      "155:\tlearn: 2.0881616\ttotal: 2.37s\tremaining: 12.8s\n",
      "156:\tlearn: 2.0864799\ttotal: 2.38s\tremaining: 12.8s\n",
      "157:\tlearn: 2.0840874\ttotal: 2.4s\tremaining: 12.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158:\tlearn: 2.0805638\ttotal: 2.41s\tremaining: 12.8s\n",
      "159:\tlearn: 2.0773430\ttotal: 2.43s\tremaining: 12.8s\n",
      "160:\tlearn: 2.0742732\ttotal: 2.45s\tremaining: 12.8s\n",
      "161:\tlearn: 2.0717802\ttotal: 2.46s\tremaining: 12.7s\n",
      "162:\tlearn: 2.0712830\ttotal: 2.48s\tremaining: 12.7s\n",
      "163:\tlearn: 2.0702127\ttotal: 2.49s\tremaining: 12.7s\n",
      "164:\tlearn: 2.0684909\ttotal: 2.51s\tremaining: 12.7s\n",
      "165:\tlearn: 2.0667112\ttotal: 2.52s\tremaining: 12.7s\n",
      "166:\tlearn: 2.0655845\ttotal: 2.54s\tremaining: 12.7s\n",
      "167:\tlearn: 2.0650625\ttotal: 2.55s\tremaining: 12.6s\n",
      "168:\tlearn: 2.0647434\ttotal: 2.57s\tremaining: 12.6s\n",
      "169:\tlearn: 2.0635666\ttotal: 2.58s\tremaining: 12.6s\n",
      "170:\tlearn: 2.0622215\ttotal: 2.59s\tremaining: 12.6s\n",
      "171:\tlearn: 2.0601583\ttotal: 2.61s\tremaining: 12.6s\n",
      "172:\tlearn: 2.0564468\ttotal: 2.62s\tremaining: 12.5s\n",
      "173:\tlearn: 2.0560797\ttotal: 2.64s\tremaining: 12.5s\n",
      "174:\tlearn: 2.0558376\ttotal: 2.65s\tremaining: 12.5s\n",
      "175:\tlearn: 2.0535703\ttotal: 2.67s\tremaining: 12.5s\n",
      "176:\tlearn: 2.0512174\ttotal: 2.68s\tremaining: 12.5s\n",
      "177:\tlearn: 2.0480872\ttotal: 2.7s\tremaining: 12.5s\n",
      "178:\tlearn: 2.0471504\ttotal: 2.71s\tremaining: 12.4s\n",
      "179:\tlearn: 2.0470166\ttotal: 2.73s\tremaining: 12.4s\n",
      "180:\tlearn: 2.0454864\ttotal: 2.74s\tremaining: 12.4s\n",
      "181:\tlearn: 2.0440369\ttotal: 2.76s\tremaining: 12.4s\n",
      "182:\tlearn: 2.0426625\ttotal: 2.77s\tremaining: 12.4s\n",
      "183:\tlearn: 2.0400811\ttotal: 2.79s\tremaining: 12.4s\n",
      "184:\tlearn: 2.0390683\ttotal: 2.81s\tremaining: 12.4s\n",
      "185:\tlearn: 2.0369104\ttotal: 2.82s\tremaining: 12.3s\n",
      "186:\tlearn: 2.0348825\ttotal: 2.83s\tremaining: 12.3s\n",
      "187:\tlearn: 2.0330133\ttotal: 2.85s\tremaining: 12.3s\n",
      "188:\tlearn: 2.0318392\ttotal: 2.87s\tremaining: 12.3s\n",
      "189:\tlearn: 2.0309067\ttotal: 2.88s\tremaining: 12.3s\n",
      "190:\tlearn: 2.0299596\ttotal: 2.9s\tremaining: 12.3s\n",
      "191:\tlearn: 2.0276006\ttotal: 2.91s\tremaining: 12.2s\n",
      "192:\tlearn: 2.0271681\ttotal: 2.92s\tremaining: 12.2s\n",
      "193:\tlearn: 2.0269239\ttotal: 2.94s\tremaining: 12.2s\n",
      "194:\tlearn: 2.0265508\ttotal: 2.95s\tremaining: 12.2s\n",
      "195:\tlearn: 2.0256552\ttotal: 2.97s\tremaining: 12.2s\n",
      "196:\tlearn: 2.0229729\ttotal: 2.98s\tremaining: 12.2s\n",
      "197:\tlearn: 2.0211700\ttotal: 3s\tremaining: 12.1s\n",
      "198:\tlearn: 2.0191903\ttotal: 3.01s\tremaining: 12.1s\n",
      "199:\tlearn: 2.0163230\ttotal: 3.02s\tremaining: 12.1s\n",
      "200:\tlearn: 2.0146641\ttotal: 3.04s\tremaining: 12.1s\n",
      "201:\tlearn: 2.0137518\ttotal: 3.06s\tremaining: 12.1s\n",
      "202:\tlearn: 2.0125353\ttotal: 3.07s\tremaining: 12.1s\n",
      "203:\tlearn: 2.0103851\ttotal: 3.09s\tremaining: 12.1s\n",
      "204:\tlearn: 2.0096387\ttotal: 3.1s\tremaining: 12s\n",
      "205:\tlearn: 2.0076615\ttotal: 3.12s\tremaining: 12s\n",
      "206:\tlearn: 2.0056126\ttotal: 3.13s\tremaining: 12s\n",
      "207:\tlearn: 2.0032602\ttotal: 3.15s\tremaining: 12s\n",
      "208:\tlearn: 2.0015561\ttotal: 3.16s\tremaining: 12s\n",
      "209:\tlearn: 2.0003324\ttotal: 3.17s\tremaining: 11.9s\n",
      "210:\tlearn: 1.9992689\ttotal: 3.19s\tremaining: 11.9s\n",
      "211:\tlearn: 1.9980273\ttotal: 3.21s\tremaining: 11.9s\n",
      "212:\tlearn: 1.9974848\ttotal: 3.22s\tremaining: 11.9s\n",
      "213:\tlearn: 1.9970303\ttotal: 3.23s\tremaining: 11.9s\n",
      "214:\tlearn: 1.9970034\ttotal: 3.25s\tremaining: 11.9s\n",
      "215:\tlearn: 1.9957171\ttotal: 3.27s\tremaining: 11.9s\n",
      "216:\tlearn: 1.9945738\ttotal: 3.28s\tremaining: 11.8s\n",
      "217:\tlearn: 1.9940814\ttotal: 3.29s\tremaining: 11.8s\n",
      "218:\tlearn: 1.9939976\ttotal: 3.31s\tremaining: 11.8s\n",
      "219:\tlearn: 1.9929841\ttotal: 3.32s\tremaining: 11.8s\n",
      "220:\tlearn: 1.9912511\ttotal: 3.34s\tremaining: 11.8s\n",
      "221:\tlearn: 1.9897066\ttotal: 3.35s\tremaining: 11.8s\n",
      "222:\tlearn: 1.9890495\ttotal: 3.37s\tremaining: 11.7s\n",
      "223:\tlearn: 1.9885374\ttotal: 3.38s\tremaining: 11.7s\n",
      "224:\tlearn: 1.9874016\ttotal: 3.4s\tremaining: 11.7s\n",
      "225:\tlearn: 1.9869895\ttotal: 3.41s\tremaining: 11.7s\n",
      "226:\tlearn: 1.9858260\ttotal: 3.43s\tremaining: 11.7s\n",
      "227:\tlearn: 1.9849210\ttotal: 3.44s\tremaining: 11.7s\n",
      "228:\tlearn: 1.9840927\ttotal: 3.46s\tremaining: 11.6s\n",
      "229:\tlearn: 1.9835932\ttotal: 3.47s\tremaining: 11.6s\n",
      "230:\tlearn: 1.9827729\ttotal: 3.49s\tremaining: 11.6s\n",
      "231:\tlearn: 1.9819852\ttotal: 3.5s\tremaining: 11.6s\n",
      "232:\tlearn: 1.9818877\ttotal: 3.52s\tremaining: 11.6s\n",
      "233:\tlearn: 1.9809038\ttotal: 3.53s\tremaining: 11.6s\n",
      "234:\tlearn: 1.9804311\ttotal: 3.55s\tremaining: 11.5s\n",
      "235:\tlearn: 1.9802249\ttotal: 3.56s\tremaining: 11.5s\n",
      "236:\tlearn: 1.9775817\ttotal: 3.58s\tremaining: 11.5s\n",
      "237:\tlearn: 1.9761737\ttotal: 3.59s\tremaining: 11.5s\n",
      "238:\tlearn: 1.9753967\ttotal: 3.6s\tremaining: 11.5s\n",
      "239:\tlearn: 1.9750175\ttotal: 3.62s\tremaining: 11.5s\n",
      "240:\tlearn: 1.9733647\ttotal: 3.63s\tremaining: 11.4s\n",
      "241:\tlearn: 1.9722355\ttotal: 3.65s\tremaining: 11.4s\n",
      "242:\tlearn: 1.9711546\ttotal: 3.66s\tremaining: 11.4s\n",
      "243:\tlearn: 1.9698251\ttotal: 3.68s\tremaining: 11.4s\n",
      "244:\tlearn: 1.9686682\ttotal: 3.69s\tremaining: 11.4s\n",
      "245:\tlearn: 1.9684641\ttotal: 3.71s\tremaining: 11.4s\n",
      "246:\tlearn: 1.9672386\ttotal: 3.72s\tremaining: 11.4s\n",
      "247:\tlearn: 1.9658963\ttotal: 3.74s\tremaining: 11.3s\n",
      "248:\tlearn: 1.9657743\ttotal: 3.75s\tremaining: 11.3s\n",
      "249:\tlearn: 1.9648214\ttotal: 3.77s\tremaining: 11.3s\n",
      "250:\tlearn: 1.9637963\ttotal: 3.78s\tremaining: 11.3s\n",
      "251:\tlearn: 1.9625454\ttotal: 3.8s\tremaining: 11.3s\n",
      "252:\tlearn: 1.9615672\ttotal: 3.81s\tremaining: 11.3s\n",
      "253:\tlearn: 1.9614789\ttotal: 3.83s\tremaining: 11.2s\n",
      "254:\tlearn: 1.9602897\ttotal: 3.84s\tremaining: 11.2s\n",
      "255:\tlearn: 1.9589398\ttotal: 3.85s\tremaining: 11.2s\n",
      "256:\tlearn: 1.9581220\ttotal: 3.87s\tremaining: 11.2s\n",
      "257:\tlearn: 1.9564180\ttotal: 3.88s\tremaining: 11.2s\n",
      "258:\tlearn: 1.9553336\ttotal: 3.9s\tremaining: 11.2s\n",
      "259:\tlearn: 1.9553329\ttotal: 3.92s\tremaining: 11.1s\n",
      "260:\tlearn: 1.9550966\ttotal: 3.93s\tremaining: 11.1s\n",
      "261:\tlearn: 1.9547998\ttotal: 3.95s\tremaining: 11.1s\n",
      "262:\tlearn: 1.9542645\ttotal: 3.96s\tremaining: 11.1s\n",
      "263:\tlearn: 1.9539936\ttotal: 3.98s\tremaining: 11.1s\n",
      "264:\tlearn: 1.9531046\ttotal: 3.99s\tremaining: 11.1s\n",
      "265:\tlearn: 1.9529814\ttotal: 4.01s\tremaining: 11.1s\n",
      "266:\tlearn: 1.9528462\ttotal: 4.02s\tremaining: 11s\n",
      "267:\tlearn: 1.9527350\ttotal: 4.04s\tremaining: 11s\n",
      "268:\tlearn: 1.9522945\ttotal: 4.05s\tremaining: 11s\n",
      "269:\tlearn: 1.9519443\ttotal: 4.07s\tremaining: 11s\n",
      "270:\tlearn: 1.9514554\ttotal: 4.08s\tremaining: 11s\n",
      "271:\tlearn: 1.9508866\ttotal: 4.09s\tremaining: 11s\n",
      "272:\tlearn: 1.9507800\ttotal: 4.11s\tremaining: 10.9s\n",
      "273:\tlearn: 1.9506689\ttotal: 4.12s\tremaining: 10.9s\n",
      "274:\tlearn: 1.9503176\ttotal: 4.14s\tremaining: 10.9s\n",
      "275:\tlearn: 1.9497070\ttotal: 4.16s\tremaining: 10.9s\n",
      "276:\tlearn: 1.9494565\ttotal: 4.17s\tremaining: 10.9s\n",
      "277:\tlearn: 1.9490790\ttotal: 4.18s\tremaining: 10.9s\n",
      "278:\tlearn: 1.9489295\ttotal: 4.2s\tremaining: 10.9s\n",
      "279:\tlearn: 1.9486812\ttotal: 4.21s\tremaining: 10.8s\n",
      "280:\tlearn: 1.9484974\ttotal: 4.23s\tremaining: 10.8s\n",
      "281:\tlearn: 1.9481347\ttotal: 4.24s\tremaining: 10.8s\n",
      "282:\tlearn: 1.9471716\ttotal: 4.26s\tremaining: 10.8s\n",
      "283:\tlearn: 1.9469446\ttotal: 4.27s\tremaining: 10.8s\n",
      "284:\tlearn: 1.9465498\ttotal: 4.29s\tremaining: 10.8s\n",
      "285:\tlearn: 1.9458678\ttotal: 4.3s\tremaining: 10.7s\n",
      "286:\tlearn: 1.9456455\ttotal: 4.31s\tremaining: 10.7s\n",
      "287:\tlearn: 1.9454104\ttotal: 4.33s\tremaining: 10.7s\n",
      "288:\tlearn: 1.9443738\ttotal: 4.34s\tremaining: 10.7s\n",
      "289:\tlearn: 1.9442462\ttotal: 4.36s\tremaining: 10.7s\n",
      "290:\tlearn: 1.9432362\ttotal: 4.38s\tremaining: 10.7s\n",
      "291:\tlearn: 1.9423554\ttotal: 4.39s\tremaining: 10.6s\n",
      "292:\tlearn: 1.9423553\ttotal: 4.41s\tremaining: 10.6s\n",
      "293:\tlearn: 1.9411283\ttotal: 4.42s\tremaining: 10.6s\n",
      "294:\tlearn: 1.9410134\ttotal: 4.43s\tremaining: 10.6s\n",
      "295:\tlearn: 1.9397150\ttotal: 4.45s\tremaining: 10.6s\n",
      "296:\tlearn: 1.9393369\ttotal: 4.46s\tremaining: 10.6s\n",
      "297:\tlearn: 1.9387948\ttotal: 4.48s\tremaining: 10.5s\n",
      "298:\tlearn: 1.9384441\ttotal: 4.49s\tremaining: 10.5s\n",
      "299:\tlearn: 1.9375455\ttotal: 4.5s\tremaining: 10.5s\n",
      "300:\tlearn: 1.9372397\ttotal: 4.52s\tremaining: 10.5s\n",
      "301:\tlearn: 1.9369717\ttotal: 4.53s\tremaining: 10.5s\n",
      "302:\tlearn: 1.9367968\ttotal: 4.55s\tremaining: 10.5s\n",
      "303:\tlearn: 1.9366660\ttotal: 4.56s\tremaining: 10.4s\n",
      "304:\tlearn: 1.9363429\ttotal: 4.58s\tremaining: 10.4s\n",
      "305:\tlearn: 1.9354432\ttotal: 4.59s\tremaining: 10.4s\n",
      "306:\tlearn: 1.9353051\ttotal: 4.61s\tremaining: 10.4s\n",
      "307:\tlearn: 1.9351223\ttotal: 4.62s\tremaining: 10.4s\n",
      "308:\tlearn: 1.9347503\ttotal: 4.64s\tremaining: 10.4s\n",
      "309:\tlearn: 1.9347426\ttotal: 4.66s\tremaining: 10.4s\n",
      "310:\tlearn: 1.9345554\ttotal: 4.67s\tremaining: 10.3s\n",
      "311:\tlearn: 1.9340175\ttotal: 4.68s\tremaining: 10.3s\n",
      "312:\tlearn: 1.9340016\ttotal: 4.7s\tremaining: 10.3s\n",
      "313:\tlearn: 1.9338654\ttotal: 4.71s\tremaining: 10.3s\n",
      "314:\tlearn: 1.9333482\ttotal: 4.73s\tremaining: 10.3s\n",
      "315:\tlearn: 1.9329538\ttotal: 4.74s\tremaining: 10.3s\n",
      "316:\tlearn: 1.9317600\ttotal: 4.76s\tremaining: 10.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317:\tlearn: 1.9309595\ttotal: 4.77s\tremaining: 10.2s\n",
      "318:\tlearn: 1.9307103\ttotal: 4.79s\tremaining: 10.2s\n",
      "319:\tlearn: 1.9302420\ttotal: 4.8s\tremaining: 10.2s\n",
      "320:\tlearn: 1.9295808\ttotal: 4.82s\tremaining: 10.2s\n",
      "321:\tlearn: 1.9294279\ttotal: 4.83s\tremaining: 10.2s\n",
      "322:\tlearn: 1.9282252\ttotal: 4.85s\tremaining: 10.2s\n",
      "323:\tlearn: 1.9277603\ttotal: 4.86s\tremaining: 10.1s\n",
      "324:\tlearn: 1.9271840\ttotal: 4.88s\tremaining: 10.1s\n",
      "325:\tlearn: 1.9265885\ttotal: 4.89s\tremaining: 10.1s\n",
      "326:\tlearn: 1.9260825\ttotal: 4.91s\tremaining: 10.1s\n",
      "327:\tlearn: 1.9257886\ttotal: 4.92s\tremaining: 10.1s\n",
      "328:\tlearn: 1.9251808\ttotal: 4.94s\tremaining: 10.1s\n",
      "329:\tlearn: 1.9250280\ttotal: 4.95s\tremaining: 10.1s\n",
      "330:\tlearn: 1.9240686\ttotal: 4.96s\tremaining: 10s\n",
      "331:\tlearn: 1.9235913\ttotal: 4.98s\tremaining: 10s\n",
      "332:\tlearn: 1.9229719\ttotal: 4.99s\tremaining: 10s\n",
      "333:\tlearn: 1.9224365\ttotal: 5.01s\tremaining: 9.99s\n",
      "334:\tlearn: 1.9220503\ttotal: 5.02s\tremaining: 9.97s\n",
      "335:\tlearn: 1.9219232\ttotal: 5.04s\tremaining: 9.96s\n",
      "336:\tlearn: 1.9217776\ttotal: 5.05s\tremaining: 9.94s\n",
      "337:\tlearn: 1.9216082\ttotal: 5.07s\tremaining: 9.92s\n",
      "338:\tlearn: 1.9201674\ttotal: 5.08s\tremaining: 9.91s\n",
      "339:\tlearn: 1.9197662\ttotal: 5.09s\tremaining: 9.89s\n",
      "340:\tlearn: 1.9185247\ttotal: 5.11s\tremaining: 9.88s\n",
      "341:\tlearn: 1.9176121\ttotal: 5.12s\tremaining: 9.86s\n",
      "342:\tlearn: 1.9167662\ttotal: 5.14s\tremaining: 9.84s\n",
      "343:\tlearn: 1.9167586\ttotal: 5.15s\tremaining: 9.83s\n",
      "344:\tlearn: 1.9167586\ttotal: 5.17s\tremaining: 9.81s\n",
      "345:\tlearn: 1.9165789\ttotal: 5.18s\tremaining: 9.79s\n",
      "346:\tlearn: 1.9163188\ttotal: 5.2s\tremaining: 9.78s\n",
      "347:\tlearn: 1.9162682\ttotal: 5.21s\tremaining: 9.76s\n",
      "348:\tlearn: 1.9162599\ttotal: 5.22s\tremaining: 9.75s\n",
      "349:\tlearn: 1.9162544\ttotal: 5.24s\tremaining: 9.73s\n",
      "350:\tlearn: 1.9162541\ttotal: 5.25s\tremaining: 9.71s\n",
      "351:\tlearn: 1.9161160\ttotal: 5.27s\tremaining: 9.7s\n",
      "352:\tlearn: 1.9161145\ttotal: 5.28s\tremaining: 9.68s\n",
      "353:\tlearn: 1.9161145\ttotal: 5.29s\tremaining: 9.66s\n",
      "354:\tlearn: 1.9157027\ttotal: 5.31s\tremaining: 9.64s\n",
      "355:\tlearn: 1.9157027\ttotal: 5.32s\tremaining: 9.63s\n",
      "356:\tlearn: 1.9156481\ttotal: 5.34s\tremaining: 9.61s\n",
      "357:\tlearn: 1.9156476\ttotal: 5.35s\tremaining: 9.6s\n",
      "358:\tlearn: 1.9156073\ttotal: 5.37s\tremaining: 9.58s\n",
      "359:\tlearn: 1.9154852\ttotal: 5.38s\tremaining: 9.56s\n",
      "360:\tlearn: 1.9154829\ttotal: 5.39s\tremaining: 9.55s\n",
      "361:\tlearn: 1.9154749\ttotal: 5.41s\tremaining: 9.53s\n",
      "362:\tlearn: 1.9152641\ttotal: 5.42s\tremaining: 9.52s\n",
      "363:\tlearn: 1.9152633\ttotal: 5.44s\tremaining: 9.5s\n",
      "364:\tlearn: 1.9151813\ttotal: 5.45s\tremaining: 9.49s\n",
      "365:\tlearn: 1.9148631\ttotal: 5.47s\tremaining: 9.47s\n",
      "366:\tlearn: 1.9145344\ttotal: 5.48s\tremaining: 9.46s\n",
      "367:\tlearn: 1.9140711\ttotal: 5.5s\tremaining: 9.44s\n",
      "368:\tlearn: 1.9140427\ttotal: 5.51s\tremaining: 9.42s\n",
      "369:\tlearn: 1.9138718\ttotal: 5.52s\tremaining: 9.41s\n",
      "370:\tlearn: 1.9137920\ttotal: 5.54s\tremaining: 9.39s\n",
      "371:\tlearn: 1.9136253\ttotal: 5.55s\tremaining: 9.37s\n",
      "372:\tlearn: 1.9129964\ttotal: 5.57s\tremaining: 9.36s\n",
      "373:\tlearn: 1.9129095\ttotal: 5.58s\tremaining: 9.34s\n",
      "374:\tlearn: 1.9128609\ttotal: 5.6s\tremaining: 9.33s\n",
      "375:\tlearn: 1.9128069\ttotal: 5.61s\tremaining: 9.31s\n",
      "376:\tlearn: 1.9126778\ttotal: 5.63s\tremaining: 9.29s\n",
      "377:\tlearn: 1.9126694\ttotal: 5.64s\tremaining: 9.28s\n",
      "378:\tlearn: 1.9117549\ttotal: 5.66s\tremaining: 9.27s\n",
      "379:\tlearn: 1.9107705\ttotal: 5.67s\tremaining: 9.25s\n",
      "380:\tlearn: 1.9099694\ttotal: 5.69s\tremaining: 9.24s\n",
      "381:\tlearn: 1.9098985\ttotal: 5.7s\tremaining: 9.22s\n",
      "382:\tlearn: 1.9093115\ttotal: 5.71s\tremaining: 9.21s\n",
      "383:\tlearn: 1.9090216\ttotal: 5.73s\tremaining: 9.19s\n",
      "384:\tlearn: 1.9088247\ttotal: 5.74s\tremaining: 9.18s\n",
      "385:\tlearn: 1.9087433\ttotal: 5.76s\tremaining: 9.16s\n",
      "386:\tlearn: 1.9081894\ttotal: 5.77s\tremaining: 9.14s\n",
      "387:\tlearn: 1.9080855\ttotal: 5.79s\tremaining: 9.13s\n",
      "388:\tlearn: 1.9080086\ttotal: 5.8s\tremaining: 9.12s\n",
      "389:\tlearn: 1.9074836\ttotal: 5.82s\tremaining: 9.1s\n",
      "390:\tlearn: 1.9074037\ttotal: 5.83s\tremaining: 9.08s\n",
      "391:\tlearn: 1.9073170\ttotal: 5.84s\tremaining: 9.07s\n",
      "392:\tlearn: 1.9070765\ttotal: 5.86s\tremaining: 9.05s\n",
      "393:\tlearn: 1.9068273\ttotal: 5.88s\tremaining: 9.04s\n",
      "394:\tlearn: 1.9067389\ttotal: 5.89s\tremaining: 9.03s\n",
      "395:\tlearn: 1.9066744\ttotal: 5.91s\tremaining: 9.01s\n",
      "396:\tlearn: 1.9066313\ttotal: 5.92s\tremaining: 8.99s\n",
      "397:\tlearn: 1.9063382\ttotal: 5.93s\tremaining: 8.98s\n",
      "398:\tlearn: 1.9063025\ttotal: 5.95s\tremaining: 8.96s\n",
      "399:\tlearn: 1.9057087\ttotal: 5.96s\tremaining: 8.95s\n",
      "400:\tlearn: 1.9057032\ttotal: 5.98s\tremaining: 8.93s\n",
      "401:\tlearn: 1.9052706\ttotal: 5.99s\tremaining: 8.91s\n",
      "402:\tlearn: 1.9047944\ttotal: 6.01s\tremaining: 8.9s\n",
      "403:\tlearn: 1.9040911\ttotal: 6.02s\tremaining: 8.88s\n",
      "404:\tlearn: 1.9033589\ttotal: 6.03s\tremaining: 8.87s\n",
      "405:\tlearn: 1.9028327\ttotal: 6.05s\tremaining: 8.85s\n",
      "406:\tlearn: 1.9026106\ttotal: 6.06s\tremaining: 8.84s\n",
      "407:\tlearn: 1.9024230\ttotal: 6.08s\tremaining: 8.82s\n",
      "408:\tlearn: 1.9020985\ttotal: 6.09s\tremaining: 8.81s\n",
      "409:\tlearn: 1.9020844\ttotal: 6.11s\tremaining: 8.79s\n",
      "410:\tlearn: 1.9020843\ttotal: 6.12s\tremaining: 8.78s\n",
      "411:\tlearn: 1.9015452\ttotal: 6.14s\tremaining: 8.76s\n",
      "412:\tlearn: 1.9009006\ttotal: 6.15s\tremaining: 8.74s\n",
      "413:\tlearn: 1.9008356\ttotal: 6.17s\tremaining: 8.73s\n",
      "414:\tlearn: 1.9008225\ttotal: 6.18s\tremaining: 8.71s\n",
      "415:\tlearn: 1.9007065\ttotal: 6.19s\tremaining: 8.7s\n",
      "416:\tlearn: 1.9007008\ttotal: 6.21s\tremaining: 8.68s\n",
      "417:\tlearn: 1.9006920\ttotal: 6.22s\tremaining: 8.66s\n",
      "418:\tlearn: 1.9006470\ttotal: 6.24s\tremaining: 8.65s\n",
      "419:\tlearn: 1.9000929\ttotal: 6.25s\tremaining: 8.63s\n",
      "420:\tlearn: 1.9000811\ttotal: 6.27s\tremaining: 8.62s\n",
      "421:\tlearn: 1.9000723\ttotal: 6.28s\tremaining: 8.6s\n",
      "422:\tlearn: 1.9000691\ttotal: 6.3s\tremaining: 8.59s\n",
      "423:\tlearn: 1.9000365\ttotal: 6.31s\tremaining: 8.58s\n",
      "424:\tlearn: 1.8999912\ttotal: 6.33s\tremaining: 8.56s\n",
      "425:\tlearn: 1.8996341\ttotal: 6.34s\tremaining: 8.54s\n",
      "426:\tlearn: 1.8994754\ttotal: 6.36s\tremaining: 8.53s\n",
      "427:\tlearn: 1.8992874\ttotal: 6.37s\tremaining: 8.51s\n",
      "428:\tlearn: 1.8992512\ttotal: 6.38s\tremaining: 8.5s\n",
      "429:\tlearn: 1.8992502\ttotal: 6.4s\tremaining: 8.48s\n",
      "430:\tlearn: 1.8991371\ttotal: 6.41s\tremaining: 8.46s\n",
      "431:\tlearn: 1.8991266\ttotal: 6.43s\tremaining: 8.45s\n",
      "432:\tlearn: 1.8982703\ttotal: 6.44s\tremaining: 8.44s\n",
      "433:\tlearn: 1.8980751\ttotal: 6.46s\tremaining: 8.42s\n",
      "434:\tlearn: 1.8980742\ttotal: 6.47s\tremaining: 8.4s\n",
      "435:\tlearn: 1.8980742\ttotal: 6.49s\tremaining: 8.39s\n",
      "436:\tlearn: 1.8980546\ttotal: 6.5s\tremaining: 8.38s\n",
      "437:\tlearn: 1.8980400\ttotal: 6.52s\tremaining: 8.36s\n",
      "438:\tlearn: 1.8978102\ttotal: 6.53s\tremaining: 8.35s\n",
      "439:\tlearn: 1.8978008\ttotal: 6.55s\tremaining: 8.33s\n",
      "440:\tlearn: 1.8977662\ttotal: 6.56s\tremaining: 8.32s\n",
      "441:\tlearn: 1.8974479\ttotal: 6.58s\tremaining: 8.3s\n",
      "442:\tlearn: 1.8971609\ttotal: 6.59s\tremaining: 8.29s\n",
      "443:\tlearn: 1.8967988\ttotal: 6.61s\tremaining: 8.27s\n",
      "444:\tlearn: 1.8966781\ttotal: 6.62s\tremaining: 8.26s\n",
      "445:\tlearn: 1.8965240\ttotal: 6.63s\tremaining: 8.24s\n",
      "446:\tlearn: 1.8963247\ttotal: 6.65s\tremaining: 8.23s\n",
      "447:\tlearn: 1.8963247\ttotal: 6.66s\tremaining: 8.21s\n",
      "448:\tlearn: 1.8963247\ttotal: 6.68s\tremaining: 8.2s\n",
      "449:\tlearn: 1.8963176\ttotal: 6.69s\tremaining: 8.18s\n",
      "450:\tlearn: 1.8962572\ttotal: 6.71s\tremaining: 8.16s\n",
      "451:\tlearn: 1.8962560\ttotal: 6.72s\tremaining: 8.15s\n",
      "452:\tlearn: 1.8962550\ttotal: 6.74s\tremaining: 8.13s\n",
      "453:\tlearn: 1.8962485\ttotal: 6.75s\tremaining: 8.12s\n",
      "454:\tlearn: 1.8948011\ttotal: 6.76s\tremaining: 8.1s\n",
      "455:\tlearn: 1.8947359\ttotal: 6.78s\tremaining: 8.09s\n",
      "456:\tlearn: 1.8940133\ttotal: 6.79s\tremaining: 8.07s\n",
      "457:\tlearn: 1.8940006\ttotal: 6.81s\tremaining: 8.05s\n",
      "458:\tlearn: 1.8938153\ttotal: 6.82s\tremaining: 8.04s\n",
      "459:\tlearn: 1.8938057\ttotal: 6.83s\tremaining: 8.02s\n",
      "460:\tlearn: 1.8937293\ttotal: 6.85s\tremaining: 8.01s\n",
      "461:\tlearn: 1.8934980\ttotal: 6.86s\tremaining: 7.99s\n",
      "462:\tlearn: 1.8932476\ttotal: 6.88s\tremaining: 7.97s\n",
      "463:\tlearn: 1.8932352\ttotal: 6.89s\tremaining: 7.96s\n",
      "464:\tlearn: 1.8927360\ttotal: 6.9s\tremaining: 7.94s\n",
      "465:\tlearn: 1.8923963\ttotal: 6.92s\tremaining: 7.93s\n",
      "466:\tlearn: 1.8921766\ttotal: 6.93s\tremaining: 7.91s\n",
      "467:\tlearn: 1.8918958\ttotal: 6.95s\tremaining: 7.9s\n",
      "468:\tlearn: 1.8915571\ttotal: 6.96s\tremaining: 7.89s\n",
      "469:\tlearn: 1.8899703\ttotal: 6.98s\tremaining: 7.87s\n",
      "470:\tlearn: 1.8899532\ttotal: 6.99s\tremaining: 7.86s\n",
      "471:\tlearn: 1.8899524\ttotal: 7.01s\tremaining: 7.84s\n",
      "472:\tlearn: 1.8899258\ttotal: 7.02s\tremaining: 7.82s\n",
      "473:\tlearn: 1.8895929\ttotal: 7.04s\tremaining: 7.81s\n",
      "474:\tlearn: 1.8895817\ttotal: 7.05s\tremaining: 7.79s\n",
      "475:\tlearn: 1.8895059\ttotal: 7.06s\tremaining: 7.78s\n",
      "476:\tlearn: 1.8894949\ttotal: 7.08s\tremaining: 7.76s\n",
      "477:\tlearn: 1.8894825\ttotal: 7.09s\tremaining: 7.75s\n",
      "478:\tlearn: 1.8880903\ttotal: 7.11s\tremaining: 7.73s\n",
      "479:\tlearn: 1.8880888\ttotal: 7.12s\tremaining: 7.71s\n",
      "480:\tlearn: 1.8880884\ttotal: 7.13s\tremaining: 7.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481:\tlearn: 1.8880884\ttotal: 7.16s\tremaining: 7.7s\n",
      "482:\tlearn: 1.8880539\ttotal: 7.18s\tremaining: 7.68s\n",
      "483:\tlearn: 1.8880538\ttotal: 7.19s\tremaining: 7.67s\n",
      "484:\tlearn: 1.8880533\ttotal: 7.21s\tremaining: 7.65s\n",
      "485:\tlearn: 1.8880533\ttotal: 7.22s\tremaining: 7.64s\n",
      "486:\tlearn: 1.8880533\ttotal: 7.23s\tremaining: 7.62s\n",
      "487:\tlearn: 1.8875367\ttotal: 7.25s\tremaining: 7.6s\n",
      "488:\tlearn: 1.8874995\ttotal: 7.26s\tremaining: 7.59s\n",
      "489:\tlearn: 1.8867278\ttotal: 7.28s\tremaining: 7.57s\n",
      "490:\tlearn: 1.8861812\ttotal: 7.29s\tremaining: 7.56s\n",
      "491:\tlearn: 1.8852356\ttotal: 7.3s\tremaining: 7.54s\n",
      "492:\tlearn: 1.8850084\ttotal: 7.32s\tremaining: 7.53s\n",
      "493:\tlearn: 1.8846975\ttotal: 7.33s\tremaining: 7.51s\n",
      "494:\tlearn: 1.8842947\ttotal: 7.35s\tremaining: 7.5s\n",
      "495:\tlearn: 1.8842011\ttotal: 7.36s\tremaining: 7.48s\n",
      "496:\tlearn: 1.8840452\ttotal: 7.38s\tremaining: 7.47s\n",
      "497:\tlearn: 1.8837506\ttotal: 7.39s\tremaining: 7.45s\n",
      "498:\tlearn: 1.8837506\ttotal: 7.41s\tremaining: 7.44s\n",
      "499:\tlearn: 1.8837446\ttotal: 7.42s\tremaining: 7.42s\n",
      "500:\tlearn: 1.8837406\ttotal: 7.44s\tremaining: 7.41s\n",
      "501:\tlearn: 1.8837391\ttotal: 7.45s\tremaining: 7.39s\n",
      "502:\tlearn: 1.8836668\ttotal: 7.47s\tremaining: 7.38s\n",
      "503:\tlearn: 1.8832978\ttotal: 7.48s\tremaining: 7.36s\n",
      "504:\tlearn: 1.8832971\ttotal: 7.49s\tremaining: 7.35s\n",
      "505:\tlearn: 1.8832971\ttotal: 7.51s\tremaining: 7.33s\n",
      "506:\tlearn: 1.8832970\ttotal: 7.52s\tremaining: 7.32s\n",
      "507:\tlearn: 1.8832968\ttotal: 7.54s\tremaining: 7.3s\n",
      "508:\tlearn: 1.8832968\ttotal: 7.55s\tremaining: 7.29s\n",
      "509:\tlearn: 1.8832951\ttotal: 7.57s\tremaining: 7.27s\n",
      "510:\tlearn: 1.8832950\ttotal: 7.58s\tremaining: 7.26s\n",
      "511:\tlearn: 1.8832950\ttotal: 7.6s\tremaining: 7.24s\n",
      "512:\tlearn: 1.8832946\ttotal: 7.61s\tremaining: 7.23s\n",
      "513:\tlearn: 1.8819735\ttotal: 7.63s\tremaining: 7.21s\n",
      "514:\tlearn: 1.8819732\ttotal: 7.64s\tremaining: 7.2s\n",
      "515:\tlearn: 1.8819607\ttotal: 7.66s\tremaining: 7.18s\n",
      "516:\tlearn: 1.8819578\ttotal: 7.67s\tremaining: 7.17s\n",
      "517:\tlearn: 1.8819492\ttotal: 7.69s\tremaining: 7.15s\n",
      "518:\tlearn: 1.8813581\ttotal: 7.7s\tremaining: 7.14s\n",
      "519:\tlearn: 1.8812663\ttotal: 7.71s\tremaining: 7.12s\n",
      "520:\tlearn: 1.8812662\ttotal: 7.73s\tremaining: 7.11s\n",
      "521:\tlearn: 1.8812328\ttotal: 7.74s\tremaining: 7.09s\n",
      "522:\tlearn: 1.8811524\ttotal: 7.76s\tremaining: 7.08s\n",
      "523:\tlearn: 1.8811294\ttotal: 7.77s\tremaining: 7.06s\n",
      "524:\tlearn: 1.8811234\ttotal: 7.79s\tremaining: 7.05s\n",
      "525:\tlearn: 1.8809222\ttotal: 7.82s\tremaining: 7.04s\n",
      "526:\tlearn: 1.8809181\ttotal: 7.83s\tremaining: 7.03s\n",
      "527:\tlearn: 1.8809149\ttotal: 7.85s\tremaining: 7.02s\n",
      "528:\tlearn: 1.8809042\ttotal: 7.86s\tremaining: 7s\n",
      "529:\tlearn: 1.8809012\ttotal: 7.88s\tremaining: 6.98s\n",
      "530:\tlearn: 1.8802271\ttotal: 7.89s\tremaining: 6.97s\n",
      "531:\tlearn: 1.8799640\ttotal: 7.91s\tremaining: 6.95s\n",
      "532:\tlearn: 1.8798562\ttotal: 7.92s\tremaining: 6.94s\n",
      "533:\tlearn: 1.8789972\ttotal: 7.94s\tremaining: 6.92s\n",
      "534:\tlearn: 1.8789780\ttotal: 7.95s\tremaining: 6.91s\n",
      "535:\tlearn: 1.8789732\ttotal: 7.96s\tremaining: 6.89s\n",
      "536:\tlearn: 1.8789702\ttotal: 7.98s\tremaining: 6.88s\n",
      "537:\tlearn: 1.8789275\ttotal: 7.99s\tremaining: 6.87s\n",
      "538:\tlearn: 1.8789175\ttotal: 8.01s\tremaining: 6.85s\n",
      "539:\tlearn: 1.8789112\ttotal: 8.03s\tremaining: 6.84s\n",
      "540:\tlearn: 1.8789096\ttotal: 8.04s\tremaining: 6.82s\n",
      "541:\tlearn: 1.8789093\ttotal: 8.05s\tremaining: 6.8s\n",
      "542:\tlearn: 1.8789025\ttotal: 8.07s\tremaining: 6.79s\n",
      "543:\tlearn: 1.8788688\ttotal: 8.08s\tremaining: 6.77s\n",
      "544:\tlearn: 1.8788684\ttotal: 8.1s\tremaining: 6.76s\n",
      "545:\tlearn: 1.8788682\ttotal: 8.11s\tremaining: 6.74s\n",
      "546:\tlearn: 1.8788682\ttotal: 8.13s\tremaining: 6.73s\n",
      "547:\tlearn: 1.8788674\ttotal: 8.14s\tremaining: 6.71s\n",
      "548:\tlearn: 1.8788670\ttotal: 8.15s\tremaining: 6.7s\n",
      "549:\tlearn: 1.8788668\ttotal: 8.17s\tremaining: 6.68s\n",
      "550:\tlearn: 1.8788667\ttotal: 8.18s\tremaining: 6.67s\n",
      "551:\tlearn: 1.8788654\ttotal: 8.2s\tremaining: 6.65s\n",
      "552:\tlearn: 1.8788652\ttotal: 8.21s\tremaining: 6.64s\n",
      "553:\tlearn: 1.8788646\ttotal: 8.23s\tremaining: 6.63s\n",
      "554:\tlearn: 1.8788643\ttotal: 8.25s\tremaining: 6.61s\n",
      "555:\tlearn: 1.8788643\ttotal: 8.26s\tremaining: 6.6s\n",
      "556:\tlearn: 1.8788524\ttotal: 8.28s\tremaining: 6.58s\n",
      "557:\tlearn: 1.8788289\ttotal: 8.29s\tremaining: 6.57s\n",
      "558:\tlearn: 1.8788254\ttotal: 8.3s\tremaining: 6.55s\n",
      "559:\tlearn: 1.8779120\ttotal: 8.32s\tremaining: 6.54s\n",
      "560:\tlearn: 1.8777609\ttotal: 8.33s\tremaining: 6.52s\n",
      "561:\tlearn: 1.8777540\ttotal: 8.35s\tremaining: 6.5s\n",
      "562:\tlearn: 1.8777301\ttotal: 8.36s\tremaining: 6.49s\n",
      "563:\tlearn: 1.8777285\ttotal: 8.38s\tremaining: 6.47s\n",
      "564:\tlearn: 1.8777143\ttotal: 8.39s\tremaining: 6.46s\n",
      "565:\tlearn: 1.8773861\ttotal: 8.4s\tremaining: 6.45s\n",
      "566:\tlearn: 1.8769436\ttotal: 8.42s\tremaining: 6.43s\n",
      "567:\tlearn: 1.8758169\ttotal: 8.44s\tremaining: 6.42s\n",
      "568:\tlearn: 1.8754516\ttotal: 8.45s\tremaining: 6.4s\n",
      "569:\tlearn: 1.8741639\ttotal: 8.46s\tremaining: 6.39s\n",
      "570:\tlearn: 1.8738286\ttotal: 8.48s\tremaining: 6.37s\n",
      "571:\tlearn: 1.8732457\ttotal: 8.49s\tremaining: 6.36s\n",
      "572:\tlearn: 1.8731652\ttotal: 8.51s\tremaining: 6.34s\n",
      "573:\tlearn: 1.8728711\ttotal: 8.52s\tremaining: 6.33s\n",
      "574:\tlearn: 1.8728261\ttotal: 8.54s\tremaining: 6.31s\n",
      "575:\tlearn: 1.8726782\ttotal: 8.55s\tremaining: 6.29s\n",
      "576:\tlearn: 1.8726566\ttotal: 8.57s\tremaining: 6.28s\n",
      "577:\tlearn: 1.8726461\ttotal: 8.58s\tremaining: 6.27s\n",
      "578:\tlearn: 1.8726279\ttotal: 8.6s\tremaining: 6.25s\n",
      "579:\tlearn: 1.8724835\ttotal: 8.61s\tremaining: 6.24s\n",
      "580:\tlearn: 1.8724790\ttotal: 8.63s\tremaining: 6.22s\n",
      "581:\tlearn: 1.8721857\ttotal: 8.65s\tremaining: 6.21s\n",
      "582:\tlearn: 1.8717622\ttotal: 8.67s\tremaining: 6.2s\n",
      "583:\tlearn: 1.8715119\ttotal: 8.69s\tremaining: 6.19s\n",
      "584:\tlearn: 1.8711951\ttotal: 8.7s\tremaining: 6.17s\n",
      "585:\tlearn: 1.8708007\ttotal: 8.72s\tremaining: 6.16s\n",
      "586:\tlearn: 1.8708007\ttotal: 8.73s\tremaining: 6.14s\n",
      "587:\tlearn: 1.8707782\ttotal: 8.74s\tremaining: 6.13s\n",
      "588:\tlearn: 1.8703411\ttotal: 8.76s\tremaining: 6.11s\n",
      "589:\tlearn: 1.8703116\ttotal: 8.77s\tremaining: 6.1s\n",
      "590:\tlearn: 1.8703084\ttotal: 8.79s\tremaining: 6.08s\n",
      "591:\tlearn: 1.8702964\ttotal: 8.8s\tremaining: 6.07s\n",
      "592:\tlearn: 1.8702919\ttotal: 8.82s\tremaining: 6.05s\n",
      "593:\tlearn: 1.8701118\ttotal: 8.83s\tremaining: 6.04s\n",
      "594:\tlearn: 1.8693464\ttotal: 8.85s\tremaining: 6.02s\n",
      "595:\tlearn: 1.8686662\ttotal: 8.86s\tremaining: 6.01s\n",
      "596:\tlearn: 1.8683865\ttotal: 8.88s\tremaining: 5.99s\n",
      "597:\tlearn: 1.8683689\ttotal: 8.89s\tremaining: 5.98s\n",
      "598:\tlearn: 1.8683181\ttotal: 8.91s\tremaining: 5.96s\n",
      "599:\tlearn: 1.8683119\ttotal: 8.92s\tremaining: 5.95s\n",
      "600:\tlearn: 1.8672872\ttotal: 8.94s\tremaining: 5.93s\n",
      "601:\tlearn: 1.8670129\ttotal: 8.95s\tremaining: 5.92s\n",
      "602:\tlearn: 1.8669899\ttotal: 8.97s\tremaining: 5.9s\n",
      "603:\tlearn: 1.8669877\ttotal: 8.98s\tremaining: 5.89s\n",
      "604:\tlearn: 1.8669877\ttotal: 8.99s\tremaining: 5.87s\n",
      "605:\tlearn: 1.8669877\ttotal: 9.01s\tremaining: 5.86s\n",
      "606:\tlearn: 1.8669841\ttotal: 9.02s\tremaining: 5.84s\n",
      "607:\tlearn: 1.8669020\ttotal: 9.04s\tremaining: 5.83s\n",
      "608:\tlearn: 1.8664443\ttotal: 9.05s\tremaining: 5.81s\n",
      "609:\tlearn: 1.8659604\ttotal: 9.07s\tremaining: 5.8s\n",
      "610:\tlearn: 1.8656119\ttotal: 9.09s\tremaining: 5.78s\n",
      "611:\tlearn: 1.8648010\ttotal: 9.1s\tremaining: 5.77s\n",
      "612:\tlearn: 1.8646028\ttotal: 9.12s\tremaining: 5.75s\n",
      "613:\tlearn: 1.8646016\ttotal: 9.13s\tremaining: 5.74s\n",
      "614:\tlearn: 1.8641004\ttotal: 9.14s\tremaining: 5.72s\n",
      "615:\tlearn: 1.8632583\ttotal: 9.16s\tremaining: 5.71s\n",
      "616:\tlearn: 1.8631671\ttotal: 9.17s\tremaining: 5.69s\n",
      "617:\tlearn: 1.8631671\ttotal: 9.19s\tremaining: 5.68s\n",
      "618:\tlearn: 1.8631670\ttotal: 9.2s\tremaining: 5.66s\n",
      "619:\tlearn: 1.8631645\ttotal: 9.22s\tremaining: 5.65s\n",
      "620:\tlearn: 1.8631613\ttotal: 9.23s\tremaining: 5.63s\n",
      "621:\tlearn: 1.8631588\ttotal: 9.25s\tremaining: 5.62s\n",
      "622:\tlearn: 1.8631277\ttotal: 9.26s\tremaining: 5.6s\n",
      "623:\tlearn: 1.8630963\ttotal: 9.28s\tremaining: 5.59s\n",
      "624:\tlearn: 1.8630689\ttotal: 9.29s\tremaining: 5.57s\n",
      "625:\tlearn: 1.8630632\ttotal: 9.3s\tremaining: 5.56s\n",
      "626:\tlearn: 1.8630631\ttotal: 9.32s\tremaining: 5.54s\n",
      "627:\tlearn: 1.8630623\ttotal: 9.33s\tremaining: 5.53s\n",
      "628:\tlearn: 1.8630623\ttotal: 9.35s\tremaining: 5.51s\n",
      "629:\tlearn: 1.8630605\ttotal: 9.36s\tremaining: 5.5s\n",
      "630:\tlearn: 1.8630605\ttotal: 9.38s\tremaining: 5.48s\n",
      "631:\tlearn: 1.8630605\ttotal: 9.39s\tremaining: 5.47s\n",
      "632:\tlearn: 1.8630605\ttotal: 9.4s\tremaining: 5.45s\n",
      "633:\tlearn: 1.8630597\ttotal: 9.42s\tremaining: 5.44s\n",
      "634:\tlearn: 1.8630597\ttotal: 9.43s\tremaining: 5.42s\n",
      "635:\tlearn: 1.8630589\ttotal: 9.45s\tremaining: 5.41s\n",
      "636:\tlearn: 1.8630575\ttotal: 9.46s\tremaining: 5.39s\n",
      "637:\tlearn: 1.8630575\ttotal: 9.48s\tremaining: 5.38s\n",
      "638:\tlearn: 1.8630548\ttotal: 9.49s\tremaining: 5.36s\n",
      "639:\tlearn: 1.8630548\ttotal: 9.51s\tremaining: 5.35s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640:\tlearn: 1.8627193\ttotal: 9.52s\tremaining: 5.33s\n",
      "641:\tlearn: 1.8625599\ttotal: 9.54s\tremaining: 5.32s\n",
      "642:\tlearn: 1.8622199\ttotal: 9.55s\tremaining: 5.3s\n",
      "643:\tlearn: 1.8621465\ttotal: 9.57s\tremaining: 5.29s\n",
      "644:\tlearn: 1.8621462\ttotal: 9.58s\tremaining: 5.27s\n",
      "645:\tlearn: 1.8617087\ttotal: 9.59s\tremaining: 5.26s\n",
      "646:\tlearn: 1.8610698\ttotal: 9.61s\tremaining: 5.24s\n",
      "647:\tlearn: 1.8609985\ttotal: 9.62s\tremaining: 5.23s\n",
      "648:\tlearn: 1.8609339\ttotal: 9.64s\tremaining: 5.21s\n",
      "649:\tlearn: 1.8608708\ttotal: 9.65s\tremaining: 5.2s\n",
      "650:\tlearn: 1.8606772\ttotal: 9.67s\tremaining: 5.18s\n",
      "651:\tlearn: 1.8605546\ttotal: 9.68s\tremaining: 5.17s\n",
      "652:\tlearn: 1.8605498\ttotal: 9.7s\tremaining: 5.15s\n",
      "653:\tlearn: 1.8596469\ttotal: 9.71s\tremaining: 5.14s\n",
      "654:\tlearn: 1.8591638\ttotal: 9.73s\tremaining: 5.12s\n",
      "655:\tlearn: 1.8583676\ttotal: 9.74s\tremaining: 5.11s\n",
      "656:\tlearn: 1.8579702\ttotal: 9.76s\tremaining: 5.09s\n",
      "657:\tlearn: 1.8579697\ttotal: 9.77s\tremaining: 5.08s\n",
      "658:\tlearn: 1.8579694\ttotal: 9.79s\tremaining: 5.06s\n",
      "659:\tlearn: 1.8578635\ttotal: 9.8s\tremaining: 5.05s\n",
      "660:\tlearn: 1.8565911\ttotal: 9.81s\tremaining: 5.03s\n",
      "661:\tlearn: 1.8560489\ttotal: 9.83s\tremaining: 5.02s\n",
      "662:\tlearn: 1.8560488\ttotal: 9.84s\tremaining: 5s\n",
      "663:\tlearn: 1.8560488\ttotal: 9.86s\tremaining: 4.99s\n",
      "664:\tlearn: 1.8560207\ttotal: 9.87s\tremaining: 4.97s\n",
      "665:\tlearn: 1.8560200\ttotal: 9.88s\tremaining: 4.96s\n",
      "666:\tlearn: 1.8559907\ttotal: 9.9s\tremaining: 4.94s\n",
      "667:\tlearn: 1.8557211\ttotal: 9.91s\tremaining: 4.93s\n",
      "668:\tlearn: 1.8544035\ttotal: 9.93s\tremaining: 4.91s\n",
      "669:\tlearn: 1.8543929\ttotal: 9.94s\tremaining: 4.9s\n",
      "670:\tlearn: 1.8543928\ttotal: 9.96s\tremaining: 4.88s\n",
      "671:\tlearn: 1.8543928\ttotal: 9.98s\tremaining: 4.87s\n",
      "672:\tlearn: 1.8543928\ttotal: 9.99s\tremaining: 4.85s\n",
      "673:\tlearn: 1.8543924\ttotal: 10s\tremaining: 4.84s\n",
      "674:\tlearn: 1.8539009\ttotal: 10s\tremaining: 4.82s\n",
      "675:\tlearn: 1.8527457\ttotal: 10s\tremaining: 4.81s\n",
      "676:\tlearn: 1.8526679\ttotal: 10s\tremaining: 4.79s\n",
      "677:\tlearn: 1.8526678\ttotal: 10.1s\tremaining: 4.78s\n",
      "678:\tlearn: 1.8521213\ttotal: 10.1s\tremaining: 4.76s\n",
      "679:\tlearn: 1.8518585\ttotal: 10.1s\tremaining: 4.75s\n",
      "680:\tlearn: 1.8516926\ttotal: 10.1s\tremaining: 4.73s\n",
      "681:\tlearn: 1.8516874\ttotal: 10.1s\tremaining: 4.72s\n",
      "682:\tlearn: 1.8516871\ttotal: 10.1s\tremaining: 4.7s\n",
      "683:\tlearn: 1.8516868\ttotal: 10.1s\tremaining: 4.69s\n",
      "684:\tlearn: 1.8516868\ttotal: 10.2s\tremaining: 4.67s\n",
      "685:\tlearn: 1.8516868\ttotal: 10.2s\tremaining: 4.66s\n",
      "686:\tlearn: 1.8516868\ttotal: 10.2s\tremaining: 4.64s\n",
      "687:\tlearn: 1.8516868\ttotal: 10.2s\tremaining: 4.63s\n",
      "688:\tlearn: 1.8515722\ttotal: 10.2s\tremaining: 4.61s\n",
      "689:\tlearn: 1.8509618\ttotal: 10.2s\tremaining: 4.6s\n",
      "690:\tlearn: 1.8509611\ttotal: 10.3s\tremaining: 4.58s\n",
      "691:\tlearn: 1.8509611\ttotal: 10.3s\tremaining: 4.57s\n",
      "692:\tlearn: 1.8509611\ttotal: 10.3s\tremaining: 4.55s\n",
      "693:\tlearn: 1.8508994\ttotal: 10.3s\tremaining: 4.54s\n",
      "694:\tlearn: 1.8502485\ttotal: 10.3s\tremaining: 4.52s\n",
      "695:\tlearn: 1.8502460\ttotal: 10.3s\tremaining: 4.51s\n",
      "696:\tlearn: 1.8502460\ttotal: 10.3s\tremaining: 4.49s\n",
      "697:\tlearn: 1.8502460\ttotal: 10.4s\tremaining: 4.48s\n",
      "698:\tlearn: 1.8502460\ttotal: 10.4s\tremaining: 4.46s\n",
      "699:\tlearn: 1.8502460\ttotal: 10.4s\tremaining: 4.45s\n",
      "700:\tlearn: 1.8502345\ttotal: 10.4s\tremaining: 4.43s\n",
      "701:\tlearn: 1.8493174\ttotal: 10.4s\tremaining: 4.42s\n",
      "702:\tlearn: 1.8487231\ttotal: 10.4s\tremaining: 4.41s\n",
      "703:\tlearn: 1.8484878\ttotal: 10.4s\tremaining: 4.39s\n",
      "704:\tlearn: 1.8484874\ttotal: 10.5s\tremaining: 4.37s\n",
      "705:\tlearn: 1.8481827\ttotal: 10.5s\tremaining: 4.36s\n",
      "706:\tlearn: 1.8481823\ttotal: 10.5s\tremaining: 4.34s\n",
      "707:\tlearn: 1.8481823\ttotal: 10.5s\tremaining: 4.33s\n",
      "708:\tlearn: 1.8481823\ttotal: 10.5s\tremaining: 4.31s\n",
      "709:\tlearn: 1.8481823\ttotal: 10.5s\tremaining: 4.3s\n",
      "710:\tlearn: 1.8481802\ttotal: 10.5s\tremaining: 4.28s\n",
      "711:\tlearn: 1.8481720\ttotal: 10.6s\tremaining: 4.27s\n",
      "712:\tlearn: 1.8477527\ttotal: 10.6s\tremaining: 4.25s\n",
      "713:\tlearn: 1.8476958\ttotal: 10.6s\tremaining: 4.24s\n",
      "714:\tlearn: 1.8476384\ttotal: 10.6s\tremaining: 4.22s\n",
      "715:\tlearn: 1.8473438\ttotal: 10.6s\tremaining: 4.21s\n",
      "716:\tlearn: 1.8470873\ttotal: 10.6s\tremaining: 4.2s\n",
      "717:\tlearn: 1.8463838\ttotal: 10.6s\tremaining: 4.18s\n",
      "718:\tlearn: 1.8463265\ttotal: 10.7s\tremaining: 4.17s\n",
      "719:\tlearn: 1.8461056\ttotal: 10.7s\tremaining: 4.15s\n",
      "720:\tlearn: 1.8459594\ttotal: 10.7s\tremaining: 4.13s\n",
      "721:\tlearn: 1.8456096\ttotal: 10.7s\tremaining: 4.12s\n",
      "722:\tlearn: 1.8453675\ttotal: 10.7s\tremaining: 4.11s\n",
      "723:\tlearn: 1.8451009\ttotal: 10.7s\tremaining: 4.09s\n",
      "724:\tlearn: 1.8450893\ttotal: 10.7s\tremaining: 4.08s\n",
      "725:\tlearn: 1.8442261\ttotal: 10.8s\tremaining: 4.06s\n",
      "726:\tlearn: 1.8440266\ttotal: 10.8s\tremaining: 4.05s\n",
      "727:\tlearn: 1.8440240\ttotal: 10.8s\tremaining: 4.03s\n",
      "728:\tlearn: 1.8440093\ttotal: 10.8s\tremaining: 4.02s\n",
      "729:\tlearn: 1.8439957\ttotal: 10.8s\tremaining: 4s\n",
      "730:\tlearn: 1.8437035\ttotal: 10.8s\tremaining: 3.99s\n",
      "731:\tlearn: 1.8434909\ttotal: 10.8s\tremaining: 3.97s\n",
      "732:\tlearn: 1.8433798\ttotal: 10.9s\tremaining: 3.96s\n",
      "733:\tlearn: 1.8433750\ttotal: 10.9s\tremaining: 3.94s\n",
      "734:\tlearn: 1.8433743\ttotal: 10.9s\tremaining: 3.93s\n",
      "735:\tlearn: 1.8429387\ttotal: 10.9s\tremaining: 3.91s\n",
      "736:\tlearn: 1.8429311\ttotal: 10.9s\tremaining: 3.9s\n",
      "737:\tlearn: 1.8420612\ttotal: 10.9s\tremaining: 3.88s\n",
      "738:\tlearn: 1.8420582\ttotal: 11s\tremaining: 3.87s\n",
      "739:\tlearn: 1.8417483\ttotal: 11s\tremaining: 3.85s\n",
      "740:\tlearn: 1.8417436\ttotal: 11s\tremaining: 3.84s\n",
      "741:\tlearn: 1.8417377\ttotal: 11s\tremaining: 3.82s\n",
      "742:\tlearn: 1.8417341\ttotal: 11s\tremaining: 3.81s\n",
      "743:\tlearn: 1.8417303\ttotal: 11s\tremaining: 3.79s\n",
      "744:\tlearn: 1.8417298\ttotal: 11s\tremaining: 3.78s\n",
      "745:\tlearn: 1.8417286\ttotal: 11.1s\tremaining: 3.76s\n",
      "746:\tlearn: 1.8417283\ttotal: 11.1s\tremaining: 3.75s\n",
      "747:\tlearn: 1.8417150\ttotal: 11.1s\tremaining: 3.73s\n",
      "748:\tlearn: 1.8417150\ttotal: 11.1s\tremaining: 3.72s\n",
      "749:\tlearn: 1.8417148\ttotal: 11.1s\tremaining: 3.7s\n",
      "750:\tlearn: 1.8417128\ttotal: 11.1s\tremaining: 3.69s\n",
      "751:\tlearn: 1.8417126\ttotal: 11.1s\tremaining: 3.67s\n",
      "752:\tlearn: 1.8417122\ttotal: 11.2s\tremaining: 3.66s\n",
      "753:\tlearn: 1.8417004\ttotal: 11.2s\tremaining: 3.64s\n",
      "754:\tlearn: 1.8416990\ttotal: 11.2s\tremaining: 3.63s\n",
      "755:\tlearn: 1.8416971\ttotal: 11.2s\tremaining: 3.61s\n",
      "756:\tlearn: 1.8416968\ttotal: 11.2s\tremaining: 3.6s\n",
      "757:\tlearn: 1.8416643\ttotal: 11.2s\tremaining: 3.58s\n",
      "758:\tlearn: 1.8416479\ttotal: 11.2s\tremaining: 3.57s\n",
      "759:\tlearn: 1.8414299\ttotal: 11.3s\tremaining: 3.55s\n",
      "760:\tlearn: 1.8414292\ttotal: 11.3s\tremaining: 3.54s\n",
      "761:\tlearn: 1.8414292\ttotal: 11.3s\tremaining: 3.52s\n",
      "762:\tlearn: 1.8414264\ttotal: 11.3s\tremaining: 3.51s\n",
      "763:\tlearn: 1.8414236\ttotal: 11.3s\tremaining: 3.5s\n",
      "764:\tlearn: 1.8413767\ttotal: 11.3s\tremaining: 3.48s\n",
      "765:\tlearn: 1.8407871\ttotal: 11.3s\tremaining: 3.46s\n",
      "766:\tlearn: 1.8404982\ttotal: 11.4s\tremaining: 3.45s\n",
      "767:\tlearn: 1.8404180\ttotal: 11.4s\tremaining: 3.44s\n",
      "768:\tlearn: 1.8402645\ttotal: 11.4s\tremaining: 3.42s\n",
      "769:\tlearn: 1.8397991\ttotal: 11.4s\tremaining: 3.41s\n",
      "770:\tlearn: 1.8395091\ttotal: 11.4s\tremaining: 3.39s\n",
      "771:\tlearn: 1.8393025\ttotal: 11.4s\tremaining: 3.38s\n",
      "772:\tlearn: 1.8392950\ttotal: 11.4s\tremaining: 3.36s\n",
      "773:\tlearn: 1.8392870\ttotal: 11.5s\tremaining: 3.35s\n",
      "774:\tlearn: 1.8383878\ttotal: 11.5s\tremaining: 3.33s\n",
      "775:\tlearn: 1.8383579\ttotal: 11.5s\tremaining: 3.32s\n",
      "776:\tlearn: 1.8380700\ttotal: 11.5s\tremaining: 3.3s\n",
      "777:\tlearn: 1.8375560\ttotal: 11.5s\tremaining: 3.29s\n",
      "778:\tlearn: 1.8373476\ttotal: 11.5s\tremaining: 3.27s\n",
      "779:\tlearn: 1.8373468\ttotal: 11.5s\tremaining: 3.26s\n",
      "780:\tlearn: 1.8372318\ttotal: 11.6s\tremaining: 3.24s\n",
      "781:\tlearn: 1.8370685\ttotal: 11.6s\tremaining: 3.23s\n",
      "782:\tlearn: 1.8365654\ttotal: 11.6s\tremaining: 3.21s\n",
      "783:\tlearn: 1.8360606\ttotal: 11.6s\tremaining: 3.2s\n",
      "784:\tlearn: 1.8356195\ttotal: 11.6s\tremaining: 3.18s\n",
      "785:\tlearn: 1.8354195\ttotal: 11.6s\tremaining: 3.17s\n",
      "786:\tlearn: 1.8354163\ttotal: 11.7s\tremaining: 3.15s\n",
      "787:\tlearn: 1.8349310\ttotal: 11.7s\tremaining: 3.14s\n",
      "788:\tlearn: 1.8346821\ttotal: 11.7s\tremaining: 3.13s\n",
      "789:\tlearn: 1.8345875\ttotal: 11.7s\tremaining: 3.11s\n",
      "790:\tlearn: 1.8345379\ttotal: 11.7s\tremaining: 3.1s\n",
      "791:\tlearn: 1.8345378\ttotal: 11.7s\tremaining: 3.08s\n",
      "792:\tlearn: 1.8344010\ttotal: 11.8s\tremaining: 3.07s\n",
      "793:\tlearn: 1.8343217\ttotal: 11.8s\tremaining: 3.05s\n",
      "794:\tlearn: 1.8337258\ttotal: 11.8s\tremaining: 3.04s\n",
      "795:\tlearn: 1.8336526\ttotal: 11.8s\tremaining: 3.02s\n",
      "796:\tlearn: 1.8328546\ttotal: 11.8s\tremaining: 3.01s\n",
      "797:\tlearn: 1.8325521\ttotal: 11.8s\tremaining: 2.99s\n",
      "798:\tlearn: 1.8320225\ttotal: 11.8s\tremaining: 2.98s\n",
      "799:\tlearn: 1.8313607\ttotal: 11.9s\tremaining: 2.96s\n",
      "800:\tlearn: 1.8313606\ttotal: 11.9s\tremaining: 2.95s\n",
      "801:\tlearn: 1.8313537\ttotal: 11.9s\tremaining: 2.93s\n",
      "802:\tlearn: 1.8310992\ttotal: 11.9s\tremaining: 2.92s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "803:\tlearn: 1.8310981\ttotal: 11.9s\tremaining: 2.9s\n",
      "804:\tlearn: 1.8310640\ttotal: 11.9s\tremaining: 2.89s\n",
      "805:\tlearn: 1.8310201\ttotal: 11.9s\tremaining: 2.87s\n",
      "806:\tlearn: 1.8310200\ttotal: 11.9s\tremaining: 2.86s\n",
      "807:\tlearn: 1.8310200\ttotal: 12s\tremaining: 2.84s\n",
      "808:\tlearn: 1.8310197\ttotal: 12s\tremaining: 2.83s\n",
      "809:\tlearn: 1.8310175\ttotal: 12s\tremaining: 2.81s\n",
      "810:\tlearn: 1.8309455\ttotal: 12s\tremaining: 2.8s\n",
      "811:\tlearn: 1.8306037\ttotal: 12s\tremaining: 2.78s\n",
      "812:\tlearn: 1.8300666\ttotal: 12s\tremaining: 2.77s\n",
      "813:\tlearn: 1.8300532\ttotal: 12s\tremaining: 2.75s\n",
      "814:\tlearn: 1.8300098\ttotal: 12.1s\tremaining: 2.74s\n",
      "815:\tlearn: 1.8299462\ttotal: 12.1s\tremaining: 2.72s\n",
      "816:\tlearn: 1.8298852\ttotal: 12.1s\tremaining: 2.71s\n",
      "817:\tlearn: 1.8298423\ttotal: 12.1s\tremaining: 2.69s\n",
      "818:\tlearn: 1.8297688\ttotal: 12.1s\tremaining: 2.68s\n",
      "819:\tlearn: 1.8296833\ttotal: 12.1s\tremaining: 2.66s\n",
      "820:\tlearn: 1.8296583\ttotal: 12.2s\tremaining: 2.65s\n",
      "821:\tlearn: 1.8296486\ttotal: 12.2s\tremaining: 2.63s\n",
      "822:\tlearn: 1.8296485\ttotal: 12.2s\tremaining: 2.62s\n",
      "823:\tlearn: 1.8296397\ttotal: 12.2s\tremaining: 2.6s\n",
      "824:\tlearn: 1.8296397\ttotal: 12.2s\tremaining: 2.59s\n",
      "825:\tlearn: 1.8296397\ttotal: 12.2s\tremaining: 2.58s\n",
      "826:\tlearn: 1.8296397\ttotal: 12.2s\tremaining: 2.56s\n",
      "827:\tlearn: 1.8292601\ttotal: 12.3s\tremaining: 2.54s\n",
      "828:\tlearn: 1.8292480\ttotal: 12.3s\tremaining: 2.53s\n",
      "829:\tlearn: 1.8292476\ttotal: 12.3s\tremaining: 2.52s\n",
      "830:\tlearn: 1.8290406\ttotal: 12.3s\tremaining: 2.5s\n",
      "831:\tlearn: 1.8289947\ttotal: 12.3s\tremaining: 2.48s\n",
      "832:\tlearn: 1.8288540\ttotal: 12.3s\tremaining: 2.47s\n",
      "833:\tlearn: 1.8287775\ttotal: 12.3s\tremaining: 2.46s\n",
      "834:\tlearn: 1.8287729\ttotal: 12.4s\tremaining: 2.44s\n",
      "835:\tlearn: 1.8287726\ttotal: 12.4s\tremaining: 2.43s\n",
      "836:\tlearn: 1.8287722\ttotal: 12.4s\tremaining: 2.41s\n",
      "837:\tlearn: 1.8287722\ttotal: 12.4s\tremaining: 2.4s\n",
      "838:\tlearn: 1.8287722\ttotal: 12.4s\tremaining: 2.38s\n",
      "839:\tlearn: 1.8287721\ttotal: 12.4s\tremaining: 2.37s\n",
      "840:\tlearn: 1.8287721\ttotal: 12.4s\tremaining: 2.35s\n",
      "841:\tlearn: 1.8287720\ttotal: 12.5s\tremaining: 2.34s\n",
      "842:\tlearn: 1.8287544\ttotal: 12.5s\tremaining: 2.32s\n",
      "843:\tlearn: 1.8287519\ttotal: 12.5s\tremaining: 2.31s\n",
      "844:\tlearn: 1.8287516\ttotal: 12.5s\tremaining: 2.29s\n",
      "845:\tlearn: 1.8287453\ttotal: 12.5s\tremaining: 2.28s\n",
      "846:\tlearn: 1.8287452\ttotal: 12.5s\tremaining: 2.26s\n",
      "847:\tlearn: 1.8287262\ttotal: 12.5s\tremaining: 2.25s\n",
      "848:\tlearn: 1.8283315\ttotal: 12.6s\tremaining: 2.23s\n",
      "849:\tlearn: 1.8282715\ttotal: 12.6s\tremaining: 2.22s\n",
      "850:\tlearn: 1.8282700\ttotal: 12.6s\tremaining: 2.2s\n",
      "851:\tlearn: 1.8282545\ttotal: 12.6s\tremaining: 2.19s\n",
      "852:\tlearn: 1.8281549\ttotal: 12.6s\tremaining: 2.17s\n",
      "853:\tlearn: 1.8274822\ttotal: 12.6s\tremaining: 2.16s\n",
      "854:\tlearn: 1.8274107\ttotal: 12.6s\tremaining: 2.14s\n",
      "855:\tlearn: 1.8271072\ttotal: 12.7s\tremaining: 2.13s\n",
      "856:\tlearn: 1.8270843\ttotal: 12.7s\tremaining: 2.12s\n",
      "857:\tlearn: 1.8270784\ttotal: 12.7s\tremaining: 2.1s\n",
      "858:\tlearn: 1.8270563\ttotal: 12.7s\tremaining: 2.08s\n",
      "859:\tlearn: 1.8270526\ttotal: 12.7s\tremaining: 2.07s\n",
      "860:\tlearn: 1.8270526\ttotal: 12.7s\tremaining: 2.06s\n",
      "861:\tlearn: 1.8270526\ttotal: 12.7s\tremaining: 2.04s\n",
      "862:\tlearn: 1.8270420\ttotal: 12.8s\tremaining: 2.03s\n",
      "863:\tlearn: 1.8265905\ttotal: 12.8s\tremaining: 2.01s\n",
      "864:\tlearn: 1.8251921\ttotal: 12.8s\tremaining: 2s\n",
      "865:\tlearn: 1.8246052\ttotal: 12.8s\tremaining: 1.98s\n",
      "866:\tlearn: 1.8245022\ttotal: 12.8s\tremaining: 1.97s\n",
      "867:\tlearn: 1.8244579\ttotal: 12.8s\tremaining: 1.95s\n",
      "868:\tlearn: 1.8243656\ttotal: 12.9s\tremaining: 1.94s\n",
      "869:\tlearn: 1.8240823\ttotal: 12.9s\tremaining: 1.92s\n",
      "870:\tlearn: 1.8240783\ttotal: 12.9s\tremaining: 1.91s\n",
      "871:\tlearn: 1.8240563\ttotal: 12.9s\tremaining: 1.89s\n",
      "872:\tlearn: 1.8234171\ttotal: 12.9s\tremaining: 1.88s\n",
      "873:\tlearn: 1.8233897\ttotal: 12.9s\tremaining: 1.86s\n",
      "874:\tlearn: 1.8233897\ttotal: 12.9s\tremaining: 1.85s\n",
      "875:\tlearn: 1.8233896\ttotal: 13s\tremaining: 1.83s\n",
      "876:\tlearn: 1.8233893\ttotal: 13s\tremaining: 1.82s\n",
      "877:\tlearn: 1.8233893\ttotal: 13s\tremaining: 1.8s\n",
      "878:\tlearn: 1.8233615\ttotal: 13s\tremaining: 1.79s\n",
      "879:\tlearn: 1.8233615\ttotal: 13s\tremaining: 1.77s\n",
      "880:\tlearn: 1.8233614\ttotal: 13s\tremaining: 1.76s\n",
      "881:\tlearn: 1.8230306\ttotal: 13s\tremaining: 1.75s\n",
      "882:\tlearn: 1.8230297\ttotal: 13.1s\tremaining: 1.73s\n",
      "883:\tlearn: 1.8230296\ttotal: 13.1s\tremaining: 1.72s\n",
      "884:\tlearn: 1.8230285\ttotal: 13.1s\tremaining: 1.7s\n",
      "885:\tlearn: 1.8230167\ttotal: 13.1s\tremaining: 1.69s\n",
      "886:\tlearn: 1.8230128\ttotal: 13.1s\tremaining: 1.67s\n",
      "887:\tlearn: 1.8230126\ttotal: 13.1s\tremaining: 1.66s\n",
      "888:\tlearn: 1.8224882\ttotal: 13.1s\tremaining: 1.64s\n",
      "889:\tlearn: 1.8224711\ttotal: 13.2s\tremaining: 1.63s\n",
      "890:\tlearn: 1.8219128\ttotal: 13.2s\tremaining: 1.61s\n",
      "891:\tlearn: 1.8211014\ttotal: 13.2s\tremaining: 1.6s\n",
      "892:\tlearn: 1.8209656\ttotal: 13.2s\tremaining: 1.58s\n",
      "893:\tlearn: 1.8209618\ttotal: 13.2s\tremaining: 1.57s\n",
      "894:\tlearn: 1.8209616\ttotal: 13.2s\tremaining: 1.55s\n",
      "895:\tlearn: 1.8209374\ttotal: 13.2s\tremaining: 1.54s\n",
      "896:\tlearn: 1.8200515\ttotal: 13.3s\tremaining: 1.52s\n",
      "897:\tlearn: 1.8200122\ttotal: 13.3s\tremaining: 1.51s\n",
      "898:\tlearn: 1.8196193\ttotal: 13.3s\tremaining: 1.49s\n",
      "899:\tlearn: 1.8191309\ttotal: 13.3s\tremaining: 1.48s\n",
      "900:\tlearn: 1.8190990\ttotal: 13.3s\tremaining: 1.46s\n",
      "901:\tlearn: 1.8190871\ttotal: 13.3s\tremaining: 1.45s\n",
      "902:\tlearn: 1.8189510\ttotal: 13.3s\tremaining: 1.43s\n",
      "903:\tlearn: 1.8189295\ttotal: 13.4s\tremaining: 1.42s\n",
      "904:\tlearn: 1.8188693\ttotal: 13.4s\tremaining: 1.4s\n",
      "905:\tlearn: 1.8177426\ttotal: 13.4s\tremaining: 1.39s\n",
      "906:\tlearn: 1.8168981\ttotal: 13.4s\tremaining: 1.38s\n",
      "907:\tlearn: 1.8164470\ttotal: 13.4s\tremaining: 1.36s\n",
      "908:\tlearn: 1.8156587\ttotal: 13.4s\tremaining: 1.35s\n",
      "909:\tlearn: 1.8156523\ttotal: 13.5s\tremaining: 1.33s\n",
      "910:\tlearn: 1.8154275\ttotal: 13.5s\tremaining: 1.32s\n",
      "911:\tlearn: 1.8152148\ttotal: 13.5s\tremaining: 1.3s\n",
      "912:\tlearn: 1.8146928\ttotal: 13.5s\tremaining: 1.29s\n",
      "913:\tlearn: 1.8146920\ttotal: 13.5s\tremaining: 1.27s\n",
      "914:\tlearn: 1.8146167\ttotal: 13.5s\tremaining: 1.26s\n",
      "915:\tlearn: 1.8138917\ttotal: 13.6s\tremaining: 1.24s\n",
      "916:\tlearn: 1.8138354\ttotal: 13.6s\tremaining: 1.23s\n",
      "917:\tlearn: 1.8138119\ttotal: 13.6s\tremaining: 1.21s\n",
      "918:\tlearn: 1.8133213\ttotal: 13.6s\tremaining: 1.2s\n",
      "919:\tlearn: 1.8130985\ttotal: 13.6s\tremaining: 1.18s\n",
      "920:\tlearn: 1.8130965\ttotal: 13.6s\tremaining: 1.17s\n",
      "921:\tlearn: 1.8130929\ttotal: 13.7s\tremaining: 1.16s\n",
      "922:\tlearn: 1.8130185\ttotal: 13.7s\tremaining: 1.14s\n",
      "923:\tlearn: 1.8130080\ttotal: 13.7s\tremaining: 1.13s\n",
      "924:\tlearn: 1.8128869\ttotal: 13.7s\tremaining: 1.11s\n",
      "925:\tlearn: 1.8128220\ttotal: 13.7s\tremaining: 1.09s\n",
      "926:\tlearn: 1.8126470\ttotal: 13.7s\tremaining: 1.08s\n",
      "927:\tlearn: 1.8126169\ttotal: 13.7s\tremaining: 1.07s\n",
      "928:\tlearn: 1.8125362\ttotal: 13.8s\tremaining: 1.05s\n",
      "929:\tlearn: 1.8123833\ttotal: 13.8s\tremaining: 1.04s\n",
      "930:\tlearn: 1.8123822\ttotal: 13.8s\tremaining: 1.02s\n",
      "931:\tlearn: 1.8123820\ttotal: 13.8s\tremaining: 1.01s\n",
      "932:\tlearn: 1.8122768\ttotal: 13.8s\tremaining: 992ms\n",
      "933:\tlearn: 1.8122668\ttotal: 13.8s\tremaining: 977ms\n",
      "934:\tlearn: 1.8121951\ttotal: 13.8s\tremaining: 962ms\n",
      "935:\tlearn: 1.8121944\ttotal: 13.9s\tremaining: 948ms\n",
      "936:\tlearn: 1.8121381\ttotal: 13.9s\tremaining: 933ms\n",
      "937:\tlearn: 1.8120496\ttotal: 13.9s\tremaining: 918ms\n",
      "938:\tlearn: 1.8118470\ttotal: 13.9s\tremaining: 903ms\n",
      "939:\tlearn: 1.8113695\ttotal: 13.9s\tremaining: 888ms\n",
      "940:\tlearn: 1.8112479\ttotal: 13.9s\tremaining: 873ms\n",
      "941:\tlearn: 1.8112430\ttotal: 13.9s\tremaining: 859ms\n",
      "942:\tlearn: 1.8112256\ttotal: 14s\tremaining: 844ms\n",
      "943:\tlearn: 1.8112091\ttotal: 14s\tremaining: 829ms\n",
      "944:\tlearn: 1.8111972\ttotal: 14s\tremaining: 814ms\n",
      "945:\tlearn: 1.8102817\ttotal: 14s\tremaining: 799ms\n",
      "946:\tlearn: 1.8100811\ttotal: 14s\tremaining: 784ms\n",
      "947:\tlearn: 1.8095434\ttotal: 14s\tremaining: 770ms\n",
      "948:\tlearn: 1.8094669\ttotal: 14s\tremaining: 755ms\n",
      "949:\tlearn: 1.8087611\ttotal: 14.1s\tremaining: 740ms\n",
      "950:\tlearn: 1.8083185\ttotal: 14.1s\tremaining: 725ms\n",
      "951:\tlearn: 1.8083180\ttotal: 14.1s\tremaining: 710ms\n",
      "952:\tlearn: 1.8083080\ttotal: 14.1s\tremaining: 696ms\n",
      "953:\tlearn: 1.8083079\ttotal: 14.1s\tremaining: 681ms\n",
      "954:\tlearn: 1.8083023\ttotal: 14.1s\tremaining: 666ms\n",
      "955:\tlearn: 1.8082965\ttotal: 14.1s\tremaining: 651ms\n",
      "956:\tlearn: 1.8082720\ttotal: 14.2s\tremaining: 636ms\n",
      "957:\tlearn: 1.8082197\ttotal: 14.2s\tremaining: 622ms\n",
      "958:\tlearn: 1.8081342\ttotal: 14.2s\tremaining: 607ms\n",
      "959:\tlearn: 1.8081332\ttotal: 14.2s\tremaining: 592ms\n",
      "960:\tlearn: 1.8080333\ttotal: 14.2s\tremaining: 577ms\n",
      "961:\tlearn: 1.8080219\ttotal: 14.2s\tremaining: 562ms\n",
      "962:\tlearn: 1.8080213\ttotal: 14.2s\tremaining: 547ms\n",
      "963:\tlearn: 1.8080074\ttotal: 14.3s\tremaining: 533ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "964:\tlearn: 1.8080059\ttotal: 14.3s\tremaining: 518ms\n",
      "965:\tlearn: 1.8079920\ttotal: 14.3s\tremaining: 503ms\n",
      "966:\tlearn: 1.8074702\ttotal: 14.3s\tremaining: 488ms\n",
      "967:\tlearn: 1.8067497\ttotal: 14.3s\tremaining: 474ms\n",
      "968:\tlearn: 1.8067468\ttotal: 14.3s\tremaining: 459ms\n",
      "969:\tlearn: 1.8067449\ttotal: 14.4s\tremaining: 444ms\n",
      "970:\tlearn: 1.8067411\ttotal: 14.4s\tremaining: 429ms\n",
      "971:\tlearn: 1.8067402\ttotal: 14.4s\tremaining: 414ms\n",
      "972:\tlearn: 1.8066277\ttotal: 14.4s\tremaining: 400ms\n",
      "973:\tlearn: 1.8064740\ttotal: 14.4s\tremaining: 385ms\n",
      "974:\tlearn: 1.8064686\ttotal: 14.4s\tremaining: 370ms\n",
      "975:\tlearn: 1.8064682\ttotal: 14.4s\tremaining: 355ms\n",
      "976:\tlearn: 1.8064383\ttotal: 14.5s\tremaining: 340ms\n",
      "977:\tlearn: 1.8064383\ttotal: 14.5s\tremaining: 326ms\n",
      "978:\tlearn: 1.8064171\ttotal: 14.5s\tremaining: 311ms\n",
      "979:\tlearn: 1.8064170\ttotal: 14.5s\tremaining: 296ms\n",
      "980:\tlearn: 1.8064139\ttotal: 14.5s\tremaining: 281ms\n",
      "981:\tlearn: 1.8063991\ttotal: 14.5s\tremaining: 266ms\n",
      "982:\tlearn: 1.8055813\ttotal: 14.5s\tremaining: 252ms\n",
      "983:\tlearn: 1.8048597\ttotal: 14.6s\tremaining: 237ms\n",
      "984:\tlearn: 1.8047513\ttotal: 14.6s\tremaining: 222ms\n",
      "985:\tlearn: 1.8045777\ttotal: 14.6s\tremaining: 207ms\n",
      "986:\tlearn: 1.8038675\ttotal: 14.6s\tremaining: 192ms\n",
      "987:\tlearn: 1.8035382\ttotal: 14.6s\tremaining: 178ms\n",
      "988:\tlearn: 1.8028694\ttotal: 14.6s\tremaining: 163ms\n",
      "989:\tlearn: 1.8026760\ttotal: 14.6s\tremaining: 148ms\n",
      "990:\tlearn: 1.8023660\ttotal: 14.7s\tremaining: 133ms\n",
      "991:\tlearn: 1.8022051\ttotal: 14.7s\tremaining: 118ms\n",
      "992:\tlearn: 1.8014745\ttotal: 14.7s\tremaining: 104ms\n",
      "993:\tlearn: 1.8012603\ttotal: 14.7s\tremaining: 88.8ms\n",
      "994:\tlearn: 1.8012601\ttotal: 14.7s\tremaining: 74ms\n",
      "995:\tlearn: 1.8012580\ttotal: 14.7s\tremaining: 59.2ms\n",
      "996:\tlearn: 1.8012347\ttotal: 14.8s\tremaining: 44.4ms\n",
      "997:\tlearn: 1.8012102\ttotal: 14.8s\tremaining: 29.6ms\n",
      "998:\tlearn: 1.8009059\ttotal: 14.8s\tremaining: 14.8ms\n",
      "999:\tlearn: 1.8008232\ttotal: 14.8s\tremaining: 0us\n",
      "0:\tlearn: 10.0031048\ttotal: 18.8ms\tremaining: 18.8s\n",
      "1:\tlearn: 9.2579120\ttotal: 37.4ms\tremaining: 18.7s\n",
      "2:\tlearn: 8.5579824\ttotal: 56.1ms\tremaining: 18.6s\n",
      "3:\tlearn: 7.7973883\ttotal: 74.7ms\tremaining: 18.6s\n",
      "4:\tlearn: 7.1465675\ttotal: 94ms\tremaining: 18.7s\n",
      "5:\tlearn: 6.6822942\ttotal: 113ms\tremaining: 18.8s\n",
      "6:\tlearn: 6.1654339\ttotal: 131ms\tremaining: 18.6s\n",
      "7:\tlearn: 5.7092116\ttotal: 149ms\tremaining: 18.5s\n",
      "8:\tlearn: 5.2695716\ttotal: 166ms\tremaining: 18.3s\n",
      "9:\tlearn: 4.8902153\ttotal: 184ms\tremaining: 18.2s\n",
      "10:\tlearn: 4.5998959\ttotal: 203ms\tremaining: 18.3s\n",
      "11:\tlearn: 4.3767025\ttotal: 221ms\tremaining: 18.2s\n",
      "12:\tlearn: 4.1100601\ttotal: 241ms\tremaining: 18.3s\n",
      "13:\tlearn: 3.8974456\ttotal: 258ms\tremaining: 18.2s\n",
      "14:\tlearn: 3.6927632\ttotal: 276ms\tremaining: 18.1s\n",
      "15:\tlearn: 3.5671854\ttotal: 295ms\tremaining: 18.1s\n",
      "16:\tlearn: 3.4608092\ttotal: 314ms\tremaining: 18.1s\n",
      "17:\tlearn: 3.3115412\ttotal: 331ms\tremaining: 18.1s\n",
      "18:\tlearn: 3.2276489\ttotal: 348ms\tremaining: 18s\n",
      "19:\tlearn: 3.1025997\ttotal: 365ms\tremaining: 17.9s\n",
      "20:\tlearn: 3.0455977\ttotal: 383ms\tremaining: 17.8s\n",
      "21:\tlearn: 2.9910043\ttotal: 400ms\tremaining: 17.8s\n",
      "22:\tlearn: 2.9325953\ttotal: 419ms\tremaining: 17.8s\n",
      "23:\tlearn: 2.8847060\ttotal: 438ms\tremaining: 17.8s\n",
      "24:\tlearn: 2.8135043\ttotal: 455ms\tremaining: 17.8s\n",
      "25:\tlearn: 2.7529540\ttotal: 472ms\tremaining: 17.7s\n",
      "26:\tlearn: 2.7265103\ttotal: 489ms\tremaining: 17.6s\n",
      "27:\tlearn: 2.6974741\ttotal: 506ms\tremaining: 17.6s\n",
      "28:\tlearn: 2.6517812\ttotal: 522ms\tremaining: 17.5s\n",
      "29:\tlearn: 2.6038499\ttotal: 540ms\tremaining: 17.5s\n",
      "30:\tlearn: 2.5652697\ttotal: 559ms\tremaining: 17.5s\n",
      "31:\tlearn: 2.5509696\ttotal: 577ms\tremaining: 17.5s\n",
      "32:\tlearn: 2.5251295\ttotal: 595ms\tremaining: 17.4s\n",
      "33:\tlearn: 2.4939697\ttotal: 612ms\tremaining: 17.4s\n",
      "34:\tlearn: 2.4826367\ttotal: 631ms\tremaining: 17.4s\n",
      "35:\tlearn: 2.4663961\ttotal: 651ms\tremaining: 17.4s\n",
      "36:\tlearn: 2.4460968\ttotal: 668ms\tremaining: 17.4s\n",
      "37:\tlearn: 2.4342356\ttotal: 685ms\tremaining: 17.4s\n",
      "38:\tlearn: 2.4123594\ttotal: 702ms\tremaining: 17.3s\n",
      "39:\tlearn: 2.4059848\ttotal: 718ms\tremaining: 17.2s\n",
      "40:\tlearn: 2.3853628\ttotal: 736ms\tremaining: 17.2s\n",
      "41:\tlearn: 2.3786275\ttotal: 754ms\tremaining: 17.2s\n",
      "42:\tlearn: 2.3742441\ttotal: 770ms\tremaining: 17.1s\n",
      "43:\tlearn: 2.3706696\ttotal: 787ms\tremaining: 17.1s\n",
      "44:\tlearn: 2.3681586\ttotal: 803ms\tremaining: 17s\n",
      "45:\tlearn: 2.3653708\ttotal: 820ms\tremaining: 17s\n",
      "46:\tlearn: 2.3510739\ttotal: 837ms\tremaining: 17s\n",
      "47:\tlearn: 2.3490245\ttotal: 853ms\tremaining: 16.9s\n",
      "48:\tlearn: 2.3443773\ttotal: 872ms\tremaining: 16.9s\n",
      "49:\tlearn: 2.3416225\ttotal: 889ms\tremaining: 16.9s\n",
      "50:\tlearn: 2.3402084\ttotal: 906ms\tremaining: 16.9s\n",
      "51:\tlearn: 2.3367238\ttotal: 921ms\tremaining: 16.8s\n",
      "52:\tlearn: 2.3362767\ttotal: 937ms\tremaining: 16.7s\n",
      "53:\tlearn: 2.3347297\ttotal: 954ms\tremaining: 16.7s\n",
      "54:\tlearn: 2.3293298\ttotal: 971ms\tremaining: 16.7s\n",
      "55:\tlearn: 2.3125877\ttotal: 988ms\tremaining: 16.7s\n",
      "56:\tlearn: 2.3092081\ttotal: 1s\tremaining: 16.6s\n",
      "57:\tlearn: 2.3079260\ttotal: 1.02s\tremaining: 16.6s\n",
      "58:\tlearn: 2.3070280\ttotal: 1.04s\tremaining: 16.6s\n",
      "59:\tlearn: 2.3055902\ttotal: 1.05s\tremaining: 16.5s\n",
      "60:\tlearn: 2.3053519\ttotal: 1.07s\tremaining: 16.5s\n",
      "61:\tlearn: 2.3045030\ttotal: 1.09s\tremaining: 16.5s\n",
      "62:\tlearn: 2.2994339\ttotal: 1.11s\tremaining: 16.5s\n",
      "63:\tlearn: 2.2976378\ttotal: 1.12s\tremaining: 16.5s\n",
      "64:\tlearn: 2.2973013\ttotal: 1.14s\tremaining: 16.4s\n",
      "65:\tlearn: 2.2960546\ttotal: 1.16s\tremaining: 16.4s\n",
      "66:\tlearn: 2.2952996\ttotal: 1.17s\tremaining: 16.3s\n",
      "67:\tlearn: 2.2899753\ttotal: 1.19s\tremaining: 16.3s\n",
      "68:\tlearn: 2.2891351\ttotal: 1.2s\tremaining: 16.3s\n",
      "69:\tlearn: 2.2878145\ttotal: 1.22s\tremaining: 16.2s\n",
      "70:\tlearn: 2.2874240\ttotal: 1.24s\tremaining: 16.2s\n",
      "71:\tlearn: 2.2873157\ttotal: 1.25s\tremaining: 16.1s\n",
      "72:\tlearn: 2.2866132\ttotal: 1.27s\tremaining: 16.1s\n",
      "73:\tlearn: 2.2839591\ttotal: 1.29s\tremaining: 16.1s\n",
      "74:\tlearn: 2.2834071\ttotal: 1.3s\tremaining: 16.1s\n",
      "75:\tlearn: 2.2824198\ttotal: 1.32s\tremaining: 16s\n",
      "76:\tlearn: 2.2807992\ttotal: 1.34s\tremaining: 16s\n",
      "77:\tlearn: 2.2802602\ttotal: 1.35s\tremaining: 16s\n",
      "78:\tlearn: 2.2796089\ttotal: 1.37s\tremaining: 16s\n",
      "79:\tlearn: 2.2794207\ttotal: 1.38s\tremaining: 15.9s\n",
      "80:\tlearn: 2.2709881\ttotal: 1.4s\tremaining: 15.9s\n",
      "81:\tlearn: 2.2700574\ttotal: 1.42s\tremaining: 15.9s\n",
      "82:\tlearn: 2.2695059\ttotal: 1.43s\tremaining: 15.8s\n",
      "83:\tlearn: 2.2691392\ttotal: 1.45s\tremaining: 15.8s\n",
      "84:\tlearn: 2.2655326\ttotal: 1.46s\tremaining: 15.8s\n",
      "85:\tlearn: 2.2651670\ttotal: 1.48s\tremaining: 15.7s\n",
      "86:\tlearn: 2.2648784\ttotal: 1.5s\tremaining: 15.7s\n",
      "87:\tlearn: 2.2637748\ttotal: 1.51s\tremaining: 15.7s\n",
      "88:\tlearn: 2.2627500\ttotal: 1.53s\tremaining: 15.7s\n",
      "89:\tlearn: 2.2611788\ttotal: 1.55s\tremaining: 15.7s\n",
      "90:\tlearn: 2.2610666\ttotal: 1.56s\tremaining: 15.6s\n",
      "91:\tlearn: 2.2551351\ttotal: 1.58s\tremaining: 15.6s\n",
      "92:\tlearn: 2.2548086\ttotal: 1.59s\tremaining: 15.6s\n",
      "93:\tlearn: 2.2547611\ttotal: 1.61s\tremaining: 15.5s\n",
      "94:\tlearn: 2.2529804\ttotal: 1.63s\tremaining: 15.5s\n",
      "95:\tlearn: 2.2519643\ttotal: 1.64s\tremaining: 15.5s\n",
      "96:\tlearn: 2.2517909\ttotal: 1.66s\tremaining: 15.4s\n",
      "97:\tlearn: 2.2499806\ttotal: 1.67s\tremaining: 15.4s\n",
      "98:\tlearn: 2.2497949\ttotal: 1.69s\tremaining: 15.4s\n",
      "99:\tlearn: 2.2492172\ttotal: 1.7s\tremaining: 15.3s\n",
      "100:\tlearn: 2.2491359\ttotal: 1.72s\tremaining: 15.3s\n",
      "101:\tlearn: 2.2490506\ttotal: 1.73s\tremaining: 15.3s\n",
      "102:\tlearn: 2.2478261\ttotal: 1.75s\tremaining: 15.2s\n",
      "103:\tlearn: 2.2467951\ttotal: 1.76s\tremaining: 15.2s\n",
      "104:\tlearn: 2.2463983\ttotal: 1.78s\tremaining: 15.2s\n",
      "105:\tlearn: 2.2454108\ttotal: 1.79s\tremaining: 15.1s\n",
      "106:\tlearn: 2.2436141\ttotal: 1.81s\tremaining: 15.1s\n",
      "107:\tlearn: 2.2427107\ttotal: 1.82s\tremaining: 15.1s\n",
      "108:\tlearn: 2.2424464\ttotal: 1.84s\tremaining: 15s\n",
      "109:\tlearn: 2.2413955\ttotal: 1.85s\tremaining: 15s\n",
      "110:\tlearn: 2.2407716\ttotal: 1.87s\tremaining: 15s\n",
      "111:\tlearn: 2.2406448\ttotal: 1.89s\tremaining: 15s\n",
      "112:\tlearn: 2.2386700\ttotal: 1.9s\tremaining: 14.9s\n",
      "113:\tlearn: 2.2334367\ttotal: 1.92s\tremaining: 14.9s\n",
      "114:\tlearn: 2.2295623\ttotal: 1.93s\tremaining: 14.9s\n",
      "115:\tlearn: 2.2294650\ttotal: 1.95s\tremaining: 14.8s\n",
      "116:\tlearn: 2.2287042\ttotal: 1.96s\tremaining: 14.8s\n",
      "117:\tlearn: 2.2252738\ttotal: 1.98s\tremaining: 14.8s\n",
      "118:\tlearn: 2.2212250\ttotal: 1.99s\tremaining: 14.8s\n",
      "119:\tlearn: 2.2185070\ttotal: 2.01s\tremaining: 14.7s\n",
      "120:\tlearn: 2.2179863\ttotal: 2.02s\tremaining: 14.7s\n",
      "121:\tlearn: 2.2152700\ttotal: 2.04s\tremaining: 14.7s\n",
      "122:\tlearn: 2.2146909\ttotal: 2.05s\tremaining: 14.6s\n",
      "123:\tlearn: 2.2138721\ttotal: 2.07s\tremaining: 14.6s\n",
      "124:\tlearn: 2.2133639\ttotal: 2.08s\tremaining: 14.6s\n",
      "125:\tlearn: 2.2132498\ttotal: 2.1s\tremaining: 14.5s\n",
      "126:\tlearn: 2.2106645\ttotal: 2.11s\tremaining: 14.5s\n",
      "127:\tlearn: 2.2100561\ttotal: 2.12s\tremaining: 14.5s\n",
      "128:\tlearn: 2.2096831\ttotal: 2.14s\tremaining: 14.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129:\tlearn: 2.2082605\ttotal: 2.16s\tremaining: 14.4s\n",
      "130:\tlearn: 2.2073188\ttotal: 2.17s\tremaining: 14.4s\n",
      "131:\tlearn: 2.2031188\ttotal: 2.19s\tremaining: 14.4s\n",
      "132:\tlearn: 2.1984407\ttotal: 2.2s\tremaining: 14.4s\n",
      "133:\tlearn: 2.1929272\ttotal: 2.22s\tremaining: 14.3s\n",
      "134:\tlearn: 2.1894852\ttotal: 2.23s\tremaining: 14.3s\n",
      "135:\tlearn: 2.1871495\ttotal: 2.25s\tremaining: 14.3s\n",
      "136:\tlearn: 2.1866185\ttotal: 2.26s\tremaining: 14.3s\n",
      "137:\tlearn: 2.1861257\ttotal: 2.28s\tremaining: 14.2s\n",
      "138:\tlearn: 2.1832371\ttotal: 2.29s\tremaining: 14.2s\n",
      "139:\tlearn: 2.1827582\ttotal: 2.31s\tremaining: 14.2s\n",
      "140:\tlearn: 2.1804017\ttotal: 2.32s\tremaining: 14.1s\n",
      "141:\tlearn: 2.1798179\ttotal: 2.33s\tremaining: 14.1s\n",
      "142:\tlearn: 2.1791606\ttotal: 2.35s\tremaining: 14.1s\n",
      "143:\tlearn: 2.1786897\ttotal: 2.36s\tremaining: 14.1s\n",
      "144:\tlearn: 2.1771216\ttotal: 2.38s\tremaining: 14s\n",
      "145:\tlearn: 2.1766458\ttotal: 2.39s\tremaining: 14s\n",
      "146:\tlearn: 2.1730486\ttotal: 2.41s\tremaining: 14s\n",
      "147:\tlearn: 2.1720036\ttotal: 2.42s\tremaining: 14s\n",
      "148:\tlearn: 2.1706125\ttotal: 2.44s\tremaining: 13.9s\n",
      "149:\tlearn: 2.1665456\ttotal: 2.46s\tremaining: 13.9s\n",
      "150:\tlearn: 2.1640280\ttotal: 2.47s\tremaining: 13.9s\n",
      "151:\tlearn: 2.1614209\ttotal: 2.48s\tremaining: 13.9s\n",
      "152:\tlearn: 2.1588057\ttotal: 2.5s\tremaining: 13.8s\n",
      "153:\tlearn: 2.1543540\ttotal: 2.51s\tremaining: 13.8s\n",
      "154:\tlearn: 2.1519770\ttotal: 2.53s\tremaining: 13.8s\n",
      "155:\tlearn: 2.1499534\ttotal: 2.54s\tremaining: 13.8s\n",
      "156:\tlearn: 2.1466910\ttotal: 2.56s\tremaining: 13.7s\n",
      "157:\tlearn: 2.1429309\ttotal: 2.57s\tremaining: 13.7s\n",
      "158:\tlearn: 2.1411978\ttotal: 2.59s\tremaining: 13.7s\n",
      "159:\tlearn: 2.1403012\ttotal: 2.6s\tremaining: 13.7s\n",
      "160:\tlearn: 2.1383890\ttotal: 2.62s\tremaining: 13.6s\n",
      "161:\tlearn: 2.1371412\ttotal: 2.63s\tremaining: 13.6s\n",
      "162:\tlearn: 2.1349387\ttotal: 2.65s\tremaining: 13.6s\n",
      "163:\tlearn: 2.1315089\ttotal: 2.67s\tremaining: 13.6s\n",
      "164:\tlearn: 2.1281642\ttotal: 2.68s\tremaining: 13.6s\n",
      "165:\tlearn: 2.1239776\ttotal: 2.69s\tremaining: 13.5s\n",
      "166:\tlearn: 2.1204323\ttotal: 2.71s\tremaining: 13.5s\n",
      "167:\tlearn: 2.1170089\ttotal: 2.72s\tremaining: 13.5s\n",
      "168:\tlearn: 2.1122890\ttotal: 2.74s\tremaining: 13.5s\n",
      "169:\tlearn: 2.1104240\ttotal: 2.75s\tremaining: 13.5s\n",
      "170:\tlearn: 2.1082935\ttotal: 2.77s\tremaining: 13.4s\n",
      "171:\tlearn: 2.1062743\ttotal: 2.79s\tremaining: 13.4s\n",
      "172:\tlearn: 2.1044071\ttotal: 2.8s\tremaining: 13.4s\n",
      "173:\tlearn: 2.1022314\ttotal: 2.82s\tremaining: 13.4s\n",
      "174:\tlearn: 2.0979042\ttotal: 2.83s\tremaining: 13.4s\n",
      "175:\tlearn: 2.0968087\ttotal: 2.85s\tremaining: 13.3s\n",
      "176:\tlearn: 2.0957238\ttotal: 2.86s\tremaining: 13.3s\n",
      "177:\tlearn: 2.0952297\ttotal: 2.88s\tremaining: 13.3s\n",
      "178:\tlearn: 2.0945908\ttotal: 2.89s\tremaining: 13.3s\n",
      "179:\tlearn: 2.0935040\ttotal: 2.91s\tremaining: 13.2s\n",
      "180:\tlearn: 2.0913661\ttotal: 2.92s\tremaining: 13.2s\n",
      "181:\tlearn: 2.0900289\ttotal: 2.94s\tremaining: 13.2s\n",
      "182:\tlearn: 2.0888955\ttotal: 2.95s\tremaining: 13.2s\n",
      "183:\tlearn: 2.0881790\ttotal: 2.96s\tremaining: 13.2s\n",
      "184:\tlearn: 2.0862909\ttotal: 2.98s\tremaining: 13.1s\n",
      "185:\tlearn: 2.0837377\ttotal: 2.99s\tremaining: 13.1s\n",
      "186:\tlearn: 2.0815106\ttotal: 3.01s\tremaining: 13.1s\n",
      "187:\tlearn: 2.0797962\ttotal: 3.03s\tremaining: 13.1s\n",
      "188:\tlearn: 2.0782097\ttotal: 3.04s\tremaining: 13.1s\n",
      "189:\tlearn: 2.0770009\ttotal: 3.06s\tremaining: 13s\n",
      "190:\tlearn: 2.0754481\ttotal: 3.07s\tremaining: 13s\n",
      "191:\tlearn: 2.0748472\ttotal: 3.09s\tremaining: 13s\n",
      "192:\tlearn: 2.0727394\ttotal: 3.1s\tremaining: 13s\n",
      "193:\tlearn: 2.0718567\ttotal: 3.12s\tremaining: 12.9s\n",
      "194:\tlearn: 2.0705184\ttotal: 3.13s\tremaining: 12.9s\n",
      "195:\tlearn: 2.0703062\ttotal: 3.14s\tremaining: 12.9s\n",
      "196:\tlearn: 2.0690025\ttotal: 3.16s\tremaining: 12.9s\n",
      "197:\tlearn: 2.0687180\ttotal: 3.18s\tremaining: 12.9s\n",
      "198:\tlearn: 2.0676511\ttotal: 3.2s\tremaining: 12.9s\n",
      "199:\tlearn: 2.0655948\ttotal: 3.22s\tremaining: 12.9s\n",
      "200:\tlearn: 2.0629082\ttotal: 3.23s\tremaining: 12.9s\n",
      "201:\tlearn: 2.0604110\ttotal: 3.25s\tremaining: 12.8s\n",
      "202:\tlearn: 2.0578015\ttotal: 3.26s\tremaining: 12.8s\n",
      "203:\tlearn: 2.0549372\ttotal: 3.28s\tremaining: 12.8s\n",
      "204:\tlearn: 2.0531809\ttotal: 3.29s\tremaining: 12.8s\n",
      "205:\tlearn: 2.0513905\ttotal: 3.31s\tremaining: 12.8s\n",
      "206:\tlearn: 2.0505609\ttotal: 3.32s\tremaining: 12.7s\n",
      "207:\tlearn: 2.0497593\ttotal: 3.34s\tremaining: 12.7s\n",
      "208:\tlearn: 2.0486367\ttotal: 3.35s\tremaining: 12.7s\n",
      "209:\tlearn: 2.0470014\ttotal: 3.37s\tremaining: 12.7s\n",
      "210:\tlearn: 2.0452643\ttotal: 3.38s\tremaining: 12.6s\n",
      "211:\tlearn: 2.0436783\ttotal: 3.4s\tremaining: 12.6s\n",
      "212:\tlearn: 2.0425269\ttotal: 3.41s\tremaining: 12.6s\n",
      "213:\tlearn: 2.0419615\ttotal: 3.43s\tremaining: 12.6s\n",
      "214:\tlearn: 2.0415392\ttotal: 3.44s\tremaining: 12.6s\n",
      "215:\tlearn: 2.0412156\ttotal: 3.46s\tremaining: 12.6s\n",
      "216:\tlearn: 2.0398884\ttotal: 3.47s\tremaining: 12.5s\n",
      "217:\tlearn: 2.0390148\ttotal: 3.49s\tremaining: 12.5s\n",
      "218:\tlearn: 2.0385559\ttotal: 3.5s\tremaining: 12.5s\n",
      "219:\tlearn: 2.0375774\ttotal: 3.52s\tremaining: 12.5s\n",
      "220:\tlearn: 2.0364218\ttotal: 3.53s\tremaining: 12.5s\n",
      "221:\tlearn: 2.0351347\ttotal: 3.55s\tremaining: 12.4s\n",
      "222:\tlearn: 2.0349622\ttotal: 3.56s\tremaining: 12.4s\n",
      "223:\tlearn: 2.0341101\ttotal: 3.58s\tremaining: 12.4s\n",
      "224:\tlearn: 2.0334369\ttotal: 3.59s\tremaining: 12.4s\n",
      "225:\tlearn: 2.0330842\ttotal: 3.61s\tremaining: 12.4s\n",
      "226:\tlearn: 2.0326596\ttotal: 3.62s\tremaining: 12.3s\n",
      "227:\tlearn: 2.0319656\ttotal: 3.64s\tremaining: 12.3s\n",
      "228:\tlearn: 2.0314821\ttotal: 3.65s\tremaining: 12.3s\n",
      "229:\tlearn: 2.0306395\ttotal: 3.67s\tremaining: 12.3s\n",
      "230:\tlearn: 2.0298926\ttotal: 3.69s\tremaining: 12.3s\n",
      "231:\tlearn: 2.0278186\ttotal: 3.7s\tremaining: 12.3s\n",
      "232:\tlearn: 2.0259225\ttotal: 3.72s\tremaining: 12.2s\n",
      "233:\tlearn: 2.0248487\ttotal: 3.73s\tremaining: 12.2s\n",
      "234:\tlearn: 2.0240073\ttotal: 3.75s\tremaining: 12.2s\n",
      "235:\tlearn: 2.0214269\ttotal: 3.76s\tremaining: 12.2s\n",
      "236:\tlearn: 2.0191038\ttotal: 3.78s\tremaining: 12.2s\n",
      "237:\tlearn: 2.0171745\ttotal: 3.79s\tremaining: 12.1s\n",
      "238:\tlearn: 2.0149268\ttotal: 3.81s\tremaining: 12.1s\n",
      "239:\tlearn: 2.0139310\ttotal: 3.82s\tremaining: 12.1s\n",
      "240:\tlearn: 2.0127110\ttotal: 3.84s\tremaining: 12.1s\n",
      "241:\tlearn: 2.0114389\ttotal: 3.85s\tremaining: 12.1s\n",
      "242:\tlearn: 2.0110192\ttotal: 3.87s\tremaining: 12.1s\n",
      "243:\tlearn: 2.0104708\ttotal: 3.88s\tremaining: 12s\n",
      "244:\tlearn: 2.0100075\ttotal: 3.9s\tremaining: 12s\n",
      "245:\tlearn: 2.0094155\ttotal: 3.92s\tremaining: 12s\n",
      "246:\tlearn: 2.0092348\ttotal: 3.93s\tremaining: 12s\n",
      "247:\tlearn: 2.0090892\ttotal: 3.95s\tremaining: 12s\n",
      "248:\tlearn: 2.0088939\ttotal: 3.96s\tremaining: 11.9s\n",
      "249:\tlearn: 2.0084144\ttotal: 3.98s\tremaining: 11.9s\n",
      "250:\tlearn: 2.0081099\ttotal: 3.99s\tremaining: 11.9s\n",
      "251:\tlearn: 2.0067067\ttotal: 4s\tremaining: 11.9s\n",
      "252:\tlearn: 2.0059706\ttotal: 4.02s\tremaining: 11.9s\n",
      "253:\tlearn: 2.0049933\ttotal: 4.04s\tremaining: 11.8s\n",
      "254:\tlearn: 2.0041927\ttotal: 4.05s\tremaining: 11.8s\n",
      "255:\tlearn: 2.0036071\ttotal: 4.06s\tremaining: 11.8s\n",
      "256:\tlearn: 2.0033045\ttotal: 4.08s\tremaining: 11.8s\n",
      "257:\tlearn: 2.0030127\ttotal: 4.1s\tremaining: 11.8s\n",
      "258:\tlearn: 2.0023393\ttotal: 4.11s\tremaining: 11.8s\n",
      "259:\tlearn: 2.0017260\ttotal: 4.13s\tremaining: 11.7s\n",
      "260:\tlearn: 2.0014946\ttotal: 4.14s\tremaining: 11.7s\n",
      "261:\tlearn: 2.0012260\ttotal: 4.15s\tremaining: 11.7s\n",
      "262:\tlearn: 1.9996862\ttotal: 4.17s\tremaining: 11.7s\n",
      "263:\tlearn: 1.9996074\ttotal: 4.18s\tremaining: 11.7s\n",
      "264:\tlearn: 1.9990841\ttotal: 4.2s\tremaining: 11.6s\n",
      "265:\tlearn: 1.9980825\ttotal: 4.21s\tremaining: 11.6s\n",
      "266:\tlearn: 1.9976241\ttotal: 4.23s\tremaining: 11.6s\n",
      "267:\tlearn: 1.9973521\ttotal: 4.24s\tremaining: 11.6s\n",
      "268:\tlearn: 1.9971134\ttotal: 4.26s\tremaining: 11.6s\n",
      "269:\tlearn: 1.9966480\ttotal: 4.27s\tremaining: 11.6s\n",
      "270:\tlearn: 1.9963880\ttotal: 4.29s\tremaining: 11.5s\n",
      "271:\tlearn: 1.9960225\ttotal: 4.31s\tremaining: 11.5s\n",
      "272:\tlearn: 1.9960179\ttotal: 4.32s\tremaining: 11.5s\n",
      "273:\tlearn: 1.9959575\ttotal: 4.34s\tremaining: 11.5s\n",
      "274:\tlearn: 1.9959010\ttotal: 4.35s\tremaining: 11.5s\n",
      "275:\tlearn: 1.9958508\ttotal: 4.37s\tremaining: 11.5s\n",
      "276:\tlearn: 1.9956780\ttotal: 4.38s\tremaining: 11.4s\n",
      "277:\tlearn: 1.9954662\ttotal: 4.39s\tremaining: 11.4s\n",
      "278:\tlearn: 1.9951334\ttotal: 4.41s\tremaining: 11.4s\n",
      "279:\tlearn: 1.9950337\ttotal: 4.42s\tremaining: 11.4s\n",
      "280:\tlearn: 1.9949466\ttotal: 4.44s\tremaining: 11.4s\n",
      "281:\tlearn: 1.9944749\ttotal: 4.45s\tremaining: 11.3s\n",
      "282:\tlearn: 1.9943120\ttotal: 4.47s\tremaining: 11.3s\n",
      "283:\tlearn: 1.9942869\ttotal: 4.48s\tremaining: 11.3s\n",
      "284:\tlearn: 1.9942312\ttotal: 4.5s\tremaining: 11.3s\n",
      "285:\tlearn: 1.9942005\ttotal: 4.51s\tremaining: 11.3s\n",
      "286:\tlearn: 1.9941182\ttotal: 4.53s\tremaining: 11.3s\n",
      "287:\tlearn: 1.9940599\ttotal: 4.54s\tremaining: 11.2s\n",
      "288:\tlearn: 1.9940205\ttotal: 4.56s\tremaining: 11.2s\n",
      "289:\tlearn: 1.9938073\ttotal: 4.58s\tremaining: 11.2s\n",
      "290:\tlearn: 1.9937161\ttotal: 4.59s\tremaining: 11.2s\n",
      "291:\tlearn: 1.9935541\ttotal: 4.6s\tremaining: 11.2s\n",
      "292:\tlearn: 1.9934987\ttotal: 4.62s\tremaining: 11.1s\n",
      "293:\tlearn: 1.9923725\ttotal: 4.63s\tremaining: 11.1s\n",
      "294:\tlearn: 1.9922155\ttotal: 4.65s\tremaining: 11.1s\n",
      "295:\tlearn: 1.9914884\ttotal: 4.66s\tremaining: 11.1s\n",
      "296:\tlearn: 1.9912536\ttotal: 4.68s\tremaining: 11.1s\n",
      "297:\tlearn: 1.9887652\ttotal: 4.69s\tremaining: 11.1s\n",
      "298:\tlearn: 1.9878122\ttotal: 4.71s\tremaining: 11s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299:\tlearn: 1.9876883\ttotal: 4.72s\tremaining: 11s\n",
      "300:\tlearn: 1.9874751\ttotal: 4.74s\tremaining: 11s\n",
      "301:\tlearn: 1.9863446\ttotal: 4.76s\tremaining: 11s\n",
      "302:\tlearn: 1.9848154\ttotal: 4.77s\tremaining: 11s\n",
      "303:\tlearn: 1.9841600\ttotal: 4.79s\tremaining: 11s\n",
      "304:\tlearn: 1.9830413\ttotal: 4.8s\tremaining: 10.9s\n",
      "305:\tlearn: 1.9828839\ttotal: 4.82s\tremaining: 10.9s\n",
      "306:\tlearn: 1.9821305\ttotal: 4.83s\tremaining: 10.9s\n",
      "307:\tlearn: 1.9821305\ttotal: 4.85s\tremaining: 10.9s\n",
      "308:\tlearn: 1.9821157\ttotal: 4.86s\tremaining: 10.9s\n",
      "309:\tlearn: 1.9811686\ttotal: 4.88s\tremaining: 10.9s\n",
      "310:\tlearn: 1.9803885\ttotal: 4.89s\tremaining: 10.8s\n",
      "311:\tlearn: 1.9800488\ttotal: 4.91s\tremaining: 10.8s\n",
      "312:\tlearn: 1.9787334\ttotal: 4.92s\tremaining: 10.8s\n",
      "313:\tlearn: 1.9774994\ttotal: 4.94s\tremaining: 10.8s\n",
      "314:\tlearn: 1.9770739\ttotal: 4.95s\tremaining: 10.8s\n",
      "315:\tlearn: 1.9770419\ttotal: 4.97s\tremaining: 10.8s\n",
      "316:\tlearn: 1.9761067\ttotal: 4.99s\tremaining: 10.7s\n",
      "317:\tlearn: 1.9759958\ttotal: 5s\tremaining: 10.7s\n",
      "318:\tlearn: 1.9755496\ttotal: 5.01s\tremaining: 10.7s\n",
      "319:\tlearn: 1.9752008\ttotal: 5.03s\tremaining: 10.7s\n",
      "320:\tlearn: 1.9737748\ttotal: 5.04s\tremaining: 10.7s\n",
      "321:\tlearn: 1.9711813\ttotal: 5.06s\tremaining: 10.7s\n",
      "322:\tlearn: 1.9706481\ttotal: 5.08s\tremaining: 10.6s\n",
      "323:\tlearn: 1.9706448\ttotal: 5.09s\tremaining: 10.6s\n",
      "324:\tlearn: 1.9706424\ttotal: 5.1s\tremaining: 10.6s\n",
      "325:\tlearn: 1.9706404\ttotal: 5.12s\tremaining: 10.6s\n",
      "326:\tlearn: 1.9704994\ttotal: 5.13s\tremaining: 10.6s\n",
      "327:\tlearn: 1.9704896\ttotal: 5.15s\tremaining: 10.5s\n",
      "328:\tlearn: 1.9703655\ttotal: 5.17s\tremaining: 10.5s\n",
      "329:\tlearn: 1.9682389\ttotal: 5.18s\tremaining: 10.5s\n",
      "330:\tlearn: 1.9682349\ttotal: 5.19s\tremaining: 10.5s\n",
      "331:\tlearn: 1.9682095\ttotal: 5.21s\tremaining: 10.5s\n",
      "332:\tlearn: 1.9681169\ttotal: 5.22s\tremaining: 10.5s\n",
      "333:\tlearn: 1.9681089\ttotal: 5.24s\tremaining: 10.4s\n",
      "334:\tlearn: 1.9671917\ttotal: 5.25s\tremaining: 10.4s\n",
      "335:\tlearn: 1.9671432\ttotal: 5.27s\tremaining: 10.4s\n",
      "336:\tlearn: 1.9659360\ttotal: 5.28s\tremaining: 10.4s\n",
      "337:\tlearn: 1.9658878\ttotal: 5.3s\tremaining: 10.4s\n",
      "338:\tlearn: 1.9655605\ttotal: 5.31s\tremaining: 10.4s\n",
      "339:\tlearn: 1.9650493\ttotal: 5.33s\tremaining: 10.3s\n",
      "340:\tlearn: 1.9649398\ttotal: 5.34s\tremaining: 10.3s\n",
      "341:\tlearn: 1.9649221\ttotal: 5.36s\tremaining: 10.3s\n",
      "342:\tlearn: 1.9648740\ttotal: 5.37s\tremaining: 10.3s\n",
      "343:\tlearn: 1.9643429\ttotal: 5.39s\tremaining: 10.3s\n",
      "344:\tlearn: 1.9641934\ttotal: 5.4s\tremaining: 10.3s\n",
      "345:\tlearn: 1.9639176\ttotal: 5.42s\tremaining: 10.2s\n",
      "346:\tlearn: 1.9638158\ttotal: 5.43s\tremaining: 10.2s\n",
      "347:\tlearn: 1.9636613\ttotal: 5.45s\tremaining: 10.2s\n",
      "348:\tlearn: 1.9635104\ttotal: 5.46s\tremaining: 10.2s\n",
      "349:\tlearn: 1.9634292\ttotal: 5.48s\tremaining: 10.2s\n",
      "350:\tlearn: 1.9634220\ttotal: 5.49s\tremaining: 10.2s\n",
      "351:\tlearn: 1.9633508\ttotal: 5.51s\tremaining: 10.1s\n",
      "352:\tlearn: 1.9631598\ttotal: 5.52s\tremaining: 10.1s\n",
      "353:\tlearn: 1.9629245\ttotal: 5.54s\tremaining: 10.1s\n",
      "354:\tlearn: 1.9628695\ttotal: 5.55s\tremaining: 10.1s\n",
      "355:\tlearn: 1.9628361\ttotal: 5.56s\tremaining: 10.1s\n",
      "356:\tlearn: 1.9626932\ttotal: 5.58s\tremaining: 10.1s\n",
      "357:\tlearn: 1.9626537\ttotal: 5.6s\tremaining: 10s\n",
      "358:\tlearn: 1.9625369\ttotal: 5.61s\tremaining: 10s\n",
      "359:\tlearn: 1.9625024\ttotal: 5.63s\tremaining: 10s\n",
      "360:\tlearn: 1.9624750\ttotal: 5.64s\tremaining: 9.99s\n",
      "361:\tlearn: 1.9618190\ttotal: 5.66s\tremaining: 9.97s\n",
      "362:\tlearn: 1.9615015\ttotal: 5.67s\tremaining: 9.96s\n",
      "363:\tlearn: 1.9614432\ttotal: 5.69s\tremaining: 9.94s\n",
      "364:\tlearn: 1.9613641\ttotal: 5.7s\tremaining: 9.92s\n",
      "365:\tlearn: 1.9612697\ttotal: 5.72s\tremaining: 9.9s\n",
      "366:\tlearn: 1.9610069\ttotal: 5.73s\tremaining: 9.88s\n",
      "367:\tlearn: 1.9610040\ttotal: 5.75s\tremaining: 9.87s\n",
      "368:\tlearn: 1.9609822\ttotal: 5.76s\tremaining: 9.85s\n",
      "369:\tlearn: 1.9608549\ttotal: 5.77s\tremaining: 9.83s\n",
      "370:\tlearn: 1.9608452\ttotal: 5.79s\tremaining: 9.81s\n",
      "371:\tlearn: 1.9606477\ttotal: 5.8s\tremaining: 9.8s\n",
      "372:\tlearn: 1.9606388\ttotal: 5.82s\tremaining: 9.78s\n",
      "373:\tlearn: 1.9606246\ttotal: 5.83s\tremaining: 9.77s\n",
      "374:\tlearn: 1.9604559\ttotal: 5.85s\tremaining: 9.75s\n",
      "375:\tlearn: 1.9604548\ttotal: 5.86s\tremaining: 9.73s\n",
      "376:\tlearn: 1.9604295\ttotal: 5.88s\tremaining: 9.71s\n",
      "377:\tlearn: 1.9602071\ttotal: 5.89s\tremaining: 9.7s\n",
      "378:\tlearn: 1.9598609\ttotal: 5.91s\tremaining: 9.68s\n",
      "379:\tlearn: 1.9595224\ttotal: 5.92s\tremaining: 9.66s\n",
      "380:\tlearn: 1.9594521\ttotal: 5.93s\tremaining: 9.64s\n",
      "381:\tlearn: 1.9594459\ttotal: 5.95s\tremaining: 9.62s\n",
      "382:\tlearn: 1.9593734\ttotal: 5.96s\tremaining: 9.61s\n",
      "383:\tlearn: 1.9587036\ttotal: 5.98s\tremaining: 9.59s\n",
      "384:\tlearn: 1.9581371\ttotal: 5.99s\tremaining: 9.57s\n",
      "385:\tlearn: 1.9573841\ttotal: 6.01s\tremaining: 9.56s\n",
      "386:\tlearn: 1.9573793\ttotal: 6.03s\tremaining: 9.54s\n",
      "387:\tlearn: 1.9573782\ttotal: 6.04s\tremaining: 9.53s\n",
      "388:\tlearn: 1.9573592\ttotal: 6.06s\tremaining: 9.51s\n",
      "389:\tlearn: 1.9572232\ttotal: 6.07s\tremaining: 9.49s\n",
      "390:\tlearn: 1.9572048\ttotal: 6.08s\tremaining: 9.48s\n",
      "391:\tlearn: 1.9570465\ttotal: 6.1s\tremaining: 9.46s\n",
      "392:\tlearn: 1.9557910\ttotal: 6.12s\tremaining: 9.45s\n",
      "393:\tlearn: 1.9544236\ttotal: 6.13s\tremaining: 9.43s\n",
      "394:\tlearn: 1.9531159\ttotal: 6.14s\tremaining: 9.41s\n",
      "395:\tlearn: 1.9530402\ttotal: 6.16s\tremaining: 9.39s\n",
      "396:\tlearn: 1.9527545\ttotal: 6.17s\tremaining: 9.38s\n",
      "397:\tlearn: 1.9524924\ttotal: 6.19s\tremaining: 9.36s\n",
      "398:\tlearn: 1.9523530\ttotal: 6.2s\tremaining: 9.34s\n",
      "399:\tlearn: 1.9523351\ttotal: 6.22s\tremaining: 9.33s\n",
      "400:\tlearn: 1.9521186\ttotal: 6.24s\tremaining: 9.31s\n",
      "401:\tlearn: 1.9521073\ttotal: 6.25s\tremaining: 9.3s\n",
      "402:\tlearn: 1.9521032\ttotal: 6.26s\tremaining: 9.28s\n",
      "403:\tlearn: 1.9513733\ttotal: 6.28s\tremaining: 9.26s\n",
      "404:\tlearn: 1.9511739\ttotal: 6.29s\tremaining: 9.24s\n",
      "405:\tlearn: 1.9511739\ttotal: 6.31s\tremaining: 9.23s\n",
      "406:\tlearn: 1.9509908\ttotal: 6.32s\tremaining: 9.21s\n",
      "407:\tlearn: 1.9501718\ttotal: 6.34s\tremaining: 9.2s\n",
      "408:\tlearn: 1.9496270\ttotal: 6.35s\tremaining: 9.18s\n",
      "409:\tlearn: 1.9495355\ttotal: 6.37s\tremaining: 9.16s\n",
      "410:\tlearn: 1.9493529\ttotal: 6.38s\tremaining: 9.15s\n",
      "411:\tlearn: 1.9492652\ttotal: 6.4s\tremaining: 9.13s\n",
      "412:\tlearn: 1.9489619\ttotal: 6.41s\tremaining: 9.11s\n",
      "413:\tlearn: 1.9486969\ttotal: 6.43s\tremaining: 9.1s\n",
      "414:\tlearn: 1.9483041\ttotal: 6.44s\tremaining: 9.08s\n",
      "415:\tlearn: 1.9482567\ttotal: 6.46s\tremaining: 9.07s\n",
      "416:\tlearn: 1.9482171\ttotal: 6.47s\tremaining: 9.05s\n",
      "417:\tlearn: 1.9479196\ttotal: 6.49s\tremaining: 9.03s\n",
      "418:\tlearn: 1.9467878\ttotal: 6.5s\tremaining: 9.02s\n",
      "419:\tlearn: 1.9458068\ttotal: 6.52s\tremaining: 9s\n",
      "420:\tlearn: 1.9447856\ttotal: 6.53s\tremaining: 8.98s\n",
      "421:\tlearn: 1.9447797\ttotal: 6.55s\tremaining: 8.97s\n",
      "422:\tlearn: 1.9445520\ttotal: 6.56s\tremaining: 8.95s\n",
      "423:\tlearn: 1.9438945\ttotal: 6.58s\tremaining: 8.94s\n",
      "424:\tlearn: 1.9435956\ttotal: 6.59s\tremaining: 8.92s\n",
      "425:\tlearn: 1.9421264\ttotal: 6.61s\tremaining: 8.9s\n",
      "426:\tlearn: 1.9419220\ttotal: 6.62s\tremaining: 8.89s\n",
      "427:\tlearn: 1.9406926\ttotal: 6.64s\tremaining: 8.87s\n",
      "428:\tlearn: 1.9406615\ttotal: 6.66s\tremaining: 8.86s\n",
      "429:\tlearn: 1.9398441\ttotal: 6.67s\tremaining: 8.84s\n",
      "430:\tlearn: 1.9398228\ttotal: 6.69s\tremaining: 8.83s\n",
      "431:\tlearn: 1.9398228\ttotal: 6.7s\tremaining: 8.81s\n",
      "432:\tlearn: 1.9398226\ttotal: 6.71s\tremaining: 8.79s\n",
      "433:\tlearn: 1.9397670\ttotal: 6.73s\tremaining: 8.78s\n",
      "434:\tlearn: 1.9392192\ttotal: 6.74s\tremaining: 8.76s\n",
      "435:\tlearn: 1.9384905\ttotal: 6.76s\tremaining: 8.74s\n",
      "436:\tlearn: 1.9384884\ttotal: 6.77s\tremaining: 8.72s\n",
      "437:\tlearn: 1.9383991\ttotal: 6.79s\tremaining: 8.71s\n",
      "438:\tlearn: 1.9381790\ttotal: 6.8s\tremaining: 8.69s\n",
      "439:\tlearn: 1.9370367\ttotal: 6.82s\tremaining: 8.68s\n",
      "440:\tlearn: 1.9368629\ttotal: 6.83s\tremaining: 8.66s\n",
      "441:\tlearn: 1.9362413\ttotal: 6.85s\tremaining: 8.64s\n",
      "442:\tlearn: 1.9358123\ttotal: 6.86s\tremaining: 8.63s\n",
      "443:\tlearn: 1.9354810\ttotal: 6.88s\tremaining: 8.62s\n",
      "444:\tlearn: 1.9354120\ttotal: 6.89s\tremaining: 8.6s\n",
      "445:\tlearn: 1.9352595\ttotal: 6.91s\tremaining: 8.58s\n",
      "446:\tlearn: 1.9352450\ttotal: 6.92s\tremaining: 8.57s\n",
      "447:\tlearn: 1.9352179\ttotal: 6.94s\tremaining: 8.55s\n",
      "448:\tlearn: 1.9347397\ttotal: 6.95s\tremaining: 8.53s\n",
      "449:\tlearn: 1.9347264\ttotal: 6.97s\tremaining: 8.52s\n",
      "450:\tlearn: 1.9344903\ttotal: 6.98s\tremaining: 8.5s\n",
      "451:\tlearn: 1.9344415\ttotal: 7s\tremaining: 8.48s\n",
      "452:\tlearn: 1.9343979\ttotal: 7.01s\tremaining: 8.46s\n",
      "453:\tlearn: 1.9338109\ttotal: 7.02s\tremaining: 8.45s\n",
      "454:\tlearn: 1.9337341\ttotal: 7.04s\tremaining: 8.43s\n",
      "455:\tlearn: 1.9337199\ttotal: 7.05s\tremaining: 8.42s\n",
      "456:\tlearn: 1.9336854\ttotal: 7.07s\tremaining: 8.4s\n",
      "457:\tlearn: 1.9335780\ttotal: 7.09s\tremaining: 8.39s\n",
      "458:\tlearn: 1.9335680\ttotal: 7.1s\tremaining: 8.37s\n",
      "459:\tlearn: 1.9334480\ttotal: 7.12s\tremaining: 8.35s\n",
      "460:\tlearn: 1.9334154\ttotal: 7.13s\tremaining: 8.34s\n",
      "461:\tlearn: 1.9333851\ttotal: 7.14s\tremaining: 8.32s\n",
      "462:\tlearn: 1.9322455\ttotal: 7.16s\tremaining: 8.3s\n",
      "463:\tlearn: 1.9322179\ttotal: 7.17s\tremaining: 8.29s\n",
      "464:\tlearn: 1.9321854\ttotal: 7.19s\tremaining: 8.27s\n",
      "465:\tlearn: 1.9317638\ttotal: 7.2s\tremaining: 8.25s\n",
      "466:\tlearn: 1.9301921\ttotal: 7.22s\tremaining: 8.24s\n",
      "467:\tlearn: 1.9297033\ttotal: 7.23s\tremaining: 8.22s\n",
      "468:\tlearn: 1.9284294\ttotal: 7.25s\tremaining: 8.21s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469:\tlearn: 1.9280251\ttotal: 7.26s\tremaining: 8.19s\n",
      "470:\tlearn: 1.9279206\ttotal: 7.28s\tremaining: 8.18s\n",
      "471:\tlearn: 1.9278767\ttotal: 7.29s\tremaining: 8.16s\n",
      "472:\tlearn: 1.9278456\ttotal: 7.31s\tremaining: 8.14s\n",
      "473:\tlearn: 1.9276473\ttotal: 7.32s\tremaining: 8.13s\n",
      "474:\tlearn: 1.9273727\ttotal: 7.34s\tremaining: 8.11s\n",
      "475:\tlearn: 1.9272140\ttotal: 7.35s\tremaining: 8.09s\n",
      "476:\tlearn: 1.9271212\ttotal: 7.37s\tremaining: 8.08s\n",
      "477:\tlearn: 1.9270947\ttotal: 7.38s\tremaining: 8.06s\n",
      "478:\tlearn: 1.9267089\ttotal: 7.39s\tremaining: 8.04s\n",
      "479:\tlearn: 1.9265311\ttotal: 7.41s\tremaining: 8.03s\n",
      "480:\tlearn: 1.9265218\ttotal: 7.42s\tremaining: 8.01s\n",
      "481:\tlearn: 1.9265217\ttotal: 7.44s\tremaining: 7.99s\n",
      "482:\tlearn: 1.9259937\ttotal: 7.45s\tremaining: 7.98s\n",
      "483:\tlearn: 1.9253510\ttotal: 7.47s\tremaining: 7.96s\n",
      "484:\tlearn: 1.9248148\ttotal: 7.48s\tremaining: 7.95s\n",
      "485:\tlearn: 1.9246010\ttotal: 7.5s\tremaining: 7.93s\n",
      "486:\tlearn: 1.9246005\ttotal: 7.51s\tremaining: 7.91s\n",
      "487:\tlearn: 1.9244803\ttotal: 7.53s\tremaining: 7.9s\n",
      "488:\tlearn: 1.9242492\ttotal: 7.54s\tremaining: 7.88s\n",
      "489:\tlearn: 1.9239975\ttotal: 7.55s\tremaining: 7.86s\n",
      "490:\tlearn: 1.9233824\ttotal: 7.57s\tremaining: 7.85s\n",
      "491:\tlearn: 1.9229514\ttotal: 7.59s\tremaining: 7.83s\n",
      "492:\tlearn: 1.9217283\ttotal: 7.6s\tremaining: 7.82s\n",
      "493:\tlearn: 1.9214319\ttotal: 7.62s\tremaining: 7.8s\n",
      "494:\tlearn: 1.9210963\ttotal: 7.63s\tremaining: 7.79s\n",
      "495:\tlearn: 1.9205960\ttotal: 7.64s\tremaining: 7.77s\n",
      "496:\tlearn: 1.9201069\ttotal: 7.66s\tremaining: 7.75s\n",
      "497:\tlearn: 1.9200709\ttotal: 7.67s\tremaining: 7.74s\n",
      "498:\tlearn: 1.9195449\ttotal: 7.69s\tremaining: 7.72s\n",
      "499:\tlearn: 1.9195037\ttotal: 7.71s\tremaining: 7.71s\n",
      "500:\tlearn: 1.9191850\ttotal: 7.72s\tremaining: 7.69s\n",
      "501:\tlearn: 1.9189959\ttotal: 7.74s\tremaining: 7.67s\n",
      "502:\tlearn: 1.9189855\ttotal: 7.75s\tremaining: 7.66s\n",
      "503:\tlearn: 1.9187205\ttotal: 7.76s\tremaining: 7.64s\n",
      "504:\tlearn: 1.9186302\ttotal: 7.78s\tremaining: 7.63s\n",
      "505:\tlearn: 1.9184002\ttotal: 7.79s\tremaining: 7.61s\n",
      "506:\tlearn: 1.9181398\ttotal: 7.81s\tremaining: 7.59s\n",
      "507:\tlearn: 1.9180663\ttotal: 7.82s\tremaining: 7.58s\n",
      "508:\tlearn: 1.9180352\ttotal: 7.84s\tremaining: 7.56s\n",
      "509:\tlearn: 1.9178977\ttotal: 7.85s\tremaining: 7.54s\n",
      "510:\tlearn: 1.9178018\ttotal: 7.87s\tremaining: 7.53s\n",
      "511:\tlearn: 1.9177975\ttotal: 7.88s\tremaining: 7.51s\n",
      "512:\tlearn: 1.9177925\ttotal: 7.9s\tremaining: 7.5s\n",
      "513:\tlearn: 1.9177713\ttotal: 7.91s\tremaining: 7.48s\n",
      "514:\tlearn: 1.9177400\ttotal: 7.93s\tremaining: 7.46s\n",
      "515:\tlearn: 1.9177374\ttotal: 7.94s\tremaining: 7.45s\n",
      "516:\tlearn: 1.9177160\ttotal: 7.96s\tremaining: 7.43s\n",
      "517:\tlearn: 1.9177073\ttotal: 7.97s\tremaining: 7.42s\n",
      "518:\tlearn: 1.9176416\ttotal: 7.98s\tremaining: 7.4s\n",
      "519:\tlearn: 1.9174625\ttotal: 8s\tremaining: 7.38s\n",
      "520:\tlearn: 1.9174195\ttotal: 8.01s\tremaining: 7.37s\n",
      "521:\tlearn: 1.9170965\ttotal: 8.03s\tremaining: 7.35s\n",
      "522:\tlearn: 1.9170962\ttotal: 8.04s\tremaining: 7.33s\n",
      "523:\tlearn: 1.9170441\ttotal: 8.06s\tremaining: 7.32s\n",
      "524:\tlearn: 1.9170433\ttotal: 8.07s\tremaining: 7.3s\n",
      "525:\tlearn: 1.9170298\ttotal: 8.09s\tremaining: 7.29s\n",
      "526:\tlearn: 1.9170259\ttotal: 8.1s\tremaining: 7.27s\n",
      "527:\tlearn: 1.9170130\ttotal: 8.12s\tremaining: 7.25s\n",
      "528:\tlearn: 1.9170120\ttotal: 8.13s\tremaining: 7.24s\n",
      "529:\tlearn: 1.9170109\ttotal: 8.15s\tremaining: 7.22s\n",
      "530:\tlearn: 1.9170109\ttotal: 8.16s\tremaining: 7.21s\n",
      "531:\tlearn: 1.9170102\ttotal: 8.18s\tremaining: 7.19s\n",
      "532:\tlearn: 1.9170032\ttotal: 8.19s\tremaining: 7.18s\n",
      "533:\tlearn: 1.9170028\ttotal: 8.2s\tremaining: 7.16s\n",
      "534:\tlearn: 1.9170025\ttotal: 8.22s\tremaining: 7.14s\n",
      "535:\tlearn: 1.9169982\ttotal: 8.23s\tremaining: 7.13s\n",
      "536:\tlearn: 1.9169939\ttotal: 8.25s\tremaining: 7.11s\n",
      "537:\tlearn: 1.9169123\ttotal: 8.26s\tremaining: 7.09s\n",
      "538:\tlearn: 1.9168738\ttotal: 8.27s\tremaining: 7.08s\n",
      "539:\tlearn: 1.9168579\ttotal: 8.29s\tremaining: 7.06s\n",
      "540:\tlearn: 1.9168559\ttotal: 8.3s\tremaining: 7.04s\n",
      "541:\tlearn: 1.9168559\ttotal: 8.32s\tremaining: 7.03s\n",
      "542:\tlearn: 1.9168529\ttotal: 8.33s\tremaining: 7.01s\n",
      "543:\tlearn: 1.9168529\ttotal: 8.35s\tremaining: 7s\n",
      "544:\tlearn: 1.9168529\ttotal: 8.36s\tremaining: 6.98s\n",
      "545:\tlearn: 1.9168529\ttotal: 8.38s\tremaining: 6.96s\n",
      "546:\tlearn: 1.9168529\ttotal: 8.39s\tremaining: 6.95s\n",
      "547:\tlearn: 1.9168529\ttotal: 8.4s\tremaining: 6.93s\n",
      "548:\tlearn: 1.9168503\ttotal: 8.42s\tremaining: 6.92s\n",
      "549:\tlearn: 1.9168503\ttotal: 8.44s\tremaining: 6.9s\n",
      "550:\tlearn: 1.9168503\ttotal: 8.45s\tremaining: 6.88s\n",
      "551:\tlearn: 1.9168503\ttotal: 8.46s\tremaining: 6.87s\n",
      "552:\tlearn: 1.9168503\ttotal: 8.48s\tremaining: 6.85s\n",
      "553:\tlearn: 1.9168481\ttotal: 8.49s\tremaining: 6.84s\n",
      "554:\tlearn: 1.9160582\ttotal: 8.51s\tremaining: 6.82s\n",
      "555:\tlearn: 1.9160509\ttotal: 8.52s\tremaining: 6.8s\n",
      "556:\tlearn: 1.9160442\ttotal: 8.54s\tremaining: 6.79s\n",
      "557:\tlearn: 1.9159845\ttotal: 8.55s\tremaining: 6.77s\n",
      "558:\tlearn: 1.9159835\ttotal: 8.57s\tremaining: 6.76s\n",
      "559:\tlearn: 1.9159802\ttotal: 8.58s\tremaining: 6.74s\n",
      "560:\tlearn: 1.9159789\ttotal: 8.6s\tremaining: 6.73s\n",
      "561:\tlearn: 1.9157418\ttotal: 8.61s\tremaining: 6.71s\n",
      "562:\tlearn: 1.9153896\ttotal: 8.63s\tremaining: 6.7s\n",
      "563:\tlearn: 1.9153665\ttotal: 8.64s\tremaining: 6.68s\n",
      "564:\tlearn: 1.9151775\ttotal: 8.66s\tremaining: 6.67s\n",
      "565:\tlearn: 1.9147579\ttotal: 8.67s\tremaining: 6.65s\n",
      "566:\tlearn: 1.9146924\ttotal: 8.69s\tremaining: 6.63s\n",
      "567:\tlearn: 1.9146557\ttotal: 8.7s\tremaining: 6.62s\n",
      "568:\tlearn: 1.9146543\ttotal: 8.72s\tremaining: 6.6s\n",
      "569:\tlearn: 1.9146407\ttotal: 8.73s\tremaining: 6.59s\n",
      "570:\tlearn: 1.9146407\ttotal: 8.75s\tremaining: 6.57s\n",
      "571:\tlearn: 1.9146194\ttotal: 8.77s\tremaining: 6.56s\n",
      "572:\tlearn: 1.9145901\ttotal: 8.78s\tremaining: 6.54s\n",
      "573:\tlearn: 1.9138274\ttotal: 8.8s\tremaining: 6.53s\n",
      "574:\tlearn: 1.9136699\ttotal: 8.81s\tremaining: 6.51s\n",
      "575:\tlearn: 1.9136374\ttotal: 8.83s\tremaining: 6.5s\n",
      "576:\tlearn: 1.9136135\ttotal: 8.85s\tremaining: 6.48s\n",
      "577:\tlearn: 1.9136032\ttotal: 8.86s\tremaining: 6.47s\n",
      "578:\tlearn: 1.9135948\ttotal: 8.88s\tremaining: 6.45s\n",
      "579:\tlearn: 1.9135500\ttotal: 8.89s\tremaining: 6.44s\n",
      "580:\tlearn: 1.9135385\ttotal: 8.91s\tremaining: 6.42s\n",
      "581:\tlearn: 1.9134274\ttotal: 8.92s\tremaining: 6.41s\n",
      "582:\tlearn: 1.9133233\ttotal: 8.94s\tremaining: 6.39s\n",
      "583:\tlearn: 1.9131443\ttotal: 8.96s\tremaining: 6.38s\n",
      "584:\tlearn: 1.9131392\ttotal: 8.97s\tremaining: 6.36s\n",
      "585:\tlearn: 1.9128507\ttotal: 8.99s\tremaining: 6.35s\n",
      "586:\tlearn: 1.9123483\ttotal: 9s\tremaining: 6.33s\n",
      "587:\tlearn: 1.9118336\ttotal: 9.02s\tremaining: 6.32s\n",
      "588:\tlearn: 1.9112312\ttotal: 9.03s\tremaining: 6.3s\n",
      "589:\tlearn: 1.9110256\ttotal: 9.05s\tremaining: 6.29s\n",
      "590:\tlearn: 1.9103866\ttotal: 9.06s\tremaining: 6.27s\n",
      "591:\tlearn: 1.9103422\ttotal: 9.08s\tremaining: 6.26s\n",
      "592:\tlearn: 1.9103238\ttotal: 9.1s\tremaining: 6.24s\n",
      "593:\tlearn: 1.9103238\ttotal: 9.11s\tremaining: 6.23s\n",
      "594:\tlearn: 1.9101527\ttotal: 9.13s\tremaining: 6.21s\n",
      "595:\tlearn: 1.9097637\ttotal: 9.14s\tremaining: 6.2s\n",
      "596:\tlearn: 1.9093095\ttotal: 9.16s\tremaining: 6.18s\n",
      "597:\tlearn: 1.9090233\ttotal: 9.18s\tremaining: 6.17s\n",
      "598:\tlearn: 1.9089907\ttotal: 9.19s\tremaining: 6.15s\n",
      "599:\tlearn: 1.9089393\ttotal: 9.21s\tremaining: 6.14s\n",
      "600:\tlearn: 1.9089179\ttotal: 9.22s\tremaining: 6.12s\n",
      "601:\tlearn: 1.9089118\ttotal: 9.24s\tremaining: 6.11s\n",
      "602:\tlearn: 1.9089084\ttotal: 9.26s\tremaining: 6.09s\n",
      "603:\tlearn: 1.9089019\ttotal: 9.27s\tremaining: 6.08s\n",
      "604:\tlearn: 1.9088712\ttotal: 9.29s\tremaining: 6.06s\n",
      "605:\tlearn: 1.9088501\ttotal: 9.3s\tremaining: 6.05s\n",
      "606:\tlearn: 1.9088208\ttotal: 9.32s\tremaining: 6.03s\n",
      "607:\tlearn: 1.9087424\ttotal: 9.33s\tremaining: 6.02s\n",
      "608:\tlearn: 1.9087368\ttotal: 9.35s\tremaining: 6s\n",
      "609:\tlearn: 1.9087364\ttotal: 9.36s\tremaining: 5.99s\n",
      "610:\tlearn: 1.9087332\ttotal: 9.38s\tremaining: 5.97s\n",
      "611:\tlearn: 1.9087332\ttotal: 9.39s\tremaining: 5.96s\n",
      "612:\tlearn: 1.9087331\ttotal: 9.41s\tremaining: 5.94s\n",
      "613:\tlearn: 1.9087330\ttotal: 9.43s\tremaining: 5.93s\n",
      "614:\tlearn: 1.9087330\ttotal: 9.44s\tremaining: 5.91s\n",
      "615:\tlearn: 1.9087330\ttotal: 9.46s\tremaining: 5.9s\n",
      "616:\tlearn: 1.9087330\ttotal: 9.47s\tremaining: 5.88s\n",
      "617:\tlearn: 1.9087330\ttotal: 9.49s\tremaining: 5.87s\n",
      "618:\tlearn: 1.9087320\ttotal: 9.51s\tremaining: 5.85s\n",
      "619:\tlearn: 1.9087315\ttotal: 9.52s\tremaining: 5.83s\n",
      "620:\tlearn: 1.9087315\ttotal: 9.54s\tremaining: 5.82s\n",
      "621:\tlearn: 1.9087294\ttotal: 9.55s\tremaining: 5.8s\n",
      "622:\tlearn: 1.9083482\ttotal: 9.57s\tremaining: 5.79s\n",
      "623:\tlearn: 1.9078049\ttotal: 9.58s\tremaining: 5.77s\n",
      "624:\tlearn: 1.9075050\ttotal: 9.6s\tremaining: 5.76s\n",
      "625:\tlearn: 1.9074567\ttotal: 9.62s\tremaining: 5.74s\n",
      "626:\tlearn: 1.9073261\ttotal: 9.63s\tremaining: 5.73s\n",
      "627:\tlearn: 1.9070726\ttotal: 9.65s\tremaining: 5.71s\n",
      "628:\tlearn: 1.9070304\ttotal: 9.66s\tremaining: 5.7s\n",
      "629:\tlearn: 1.9070288\ttotal: 9.68s\tremaining: 5.68s\n",
      "630:\tlearn: 1.9068286\ttotal: 9.7s\tremaining: 5.67s\n",
      "631:\tlearn: 1.9062809\ttotal: 9.71s\tremaining: 5.65s\n",
      "632:\tlearn: 1.9062006\ttotal: 9.73s\tremaining: 5.64s\n",
      "633:\tlearn: 1.9061975\ttotal: 9.74s\tremaining: 5.62s\n",
      "634:\tlearn: 1.9060879\ttotal: 9.76s\tremaining: 5.61s\n",
      "635:\tlearn: 1.9059691\ttotal: 9.78s\tremaining: 5.59s\n",
      "636:\tlearn: 1.9059691\ttotal: 9.79s\tremaining: 5.58s\n",
      "637:\tlearn: 1.9059691\ttotal: 9.8s\tremaining: 5.56s\n",
      "638:\tlearn: 1.9059688\ttotal: 9.82s\tremaining: 5.55s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639:\tlearn: 1.9059684\ttotal: 9.84s\tremaining: 5.53s\n",
      "640:\tlearn: 1.9059458\ttotal: 9.85s\tremaining: 5.52s\n",
      "641:\tlearn: 1.9059458\ttotal: 9.87s\tremaining: 5.5s\n",
      "642:\tlearn: 1.9059456\ttotal: 9.88s\tremaining: 5.49s\n",
      "643:\tlearn: 1.9059140\ttotal: 9.9s\tremaining: 5.47s\n",
      "644:\tlearn: 1.9058767\ttotal: 9.91s\tremaining: 5.46s\n",
      "645:\tlearn: 1.9058766\ttotal: 9.93s\tremaining: 5.44s\n",
      "646:\tlearn: 1.9058273\ttotal: 9.95s\tremaining: 5.43s\n",
      "647:\tlearn: 1.9058252\ttotal: 9.96s\tremaining: 5.41s\n",
      "648:\tlearn: 1.9058252\ttotal: 9.97s\tremaining: 5.39s\n",
      "649:\tlearn: 1.9058174\ttotal: 9.99s\tremaining: 5.38s\n",
      "650:\tlearn: 1.9057869\ttotal: 10s\tremaining: 5.37s\n",
      "651:\tlearn: 1.9057821\ttotal: 10s\tremaining: 5.35s\n",
      "652:\tlearn: 1.9057681\ttotal: 10s\tremaining: 5.33s\n",
      "653:\tlearn: 1.9057063\ttotal: 10.1s\tremaining: 5.32s\n",
      "654:\tlearn: 1.9051373\ttotal: 10.1s\tremaining: 5.3s\n",
      "655:\tlearn: 1.9051217\ttotal: 10.1s\tremaining: 5.29s\n",
      "656:\tlearn: 1.9049460\ttotal: 10.1s\tremaining: 5.27s\n",
      "657:\tlearn: 1.9048926\ttotal: 10.1s\tremaining: 5.26s\n",
      "658:\tlearn: 1.9045378\ttotal: 10.1s\tremaining: 5.24s\n",
      "659:\tlearn: 1.9038912\ttotal: 10.1s\tremaining: 5.23s\n",
      "660:\tlearn: 1.9038421\ttotal: 10.2s\tremaining: 5.21s\n",
      "661:\tlearn: 1.9033908\ttotal: 10.2s\tremaining: 5.2s\n",
      "662:\tlearn: 1.9033189\ttotal: 10.2s\tremaining: 5.18s\n",
      "663:\tlearn: 1.9027343\ttotal: 10.2s\tremaining: 5.17s\n",
      "664:\tlearn: 1.9022044\ttotal: 10.2s\tremaining: 5.15s\n",
      "665:\tlearn: 1.9020411\ttotal: 10.2s\tremaining: 5.13s\n",
      "666:\tlearn: 1.9020406\ttotal: 10.3s\tremaining: 5.12s\n",
      "667:\tlearn: 1.9020208\ttotal: 10.3s\tremaining: 5.11s\n",
      "668:\tlearn: 1.9019996\ttotal: 10.3s\tremaining: 5.09s\n",
      "669:\tlearn: 1.9018000\ttotal: 10.3s\tremaining: 5.08s\n",
      "670:\tlearn: 1.9017486\ttotal: 10.3s\tremaining: 5.06s\n",
      "671:\tlearn: 1.9016861\ttotal: 10.3s\tremaining: 5.04s\n",
      "672:\tlearn: 1.9016818\ttotal: 10.4s\tremaining: 5.03s\n",
      "673:\tlearn: 1.9016816\ttotal: 10.4s\tremaining: 5.01s\n",
      "674:\tlearn: 1.9016816\ttotal: 10.4s\tremaining: 5s\n",
      "675:\tlearn: 1.9016816\ttotal: 10.4s\tremaining: 4.98s\n",
      "676:\tlearn: 1.9016816\ttotal: 10.4s\tremaining: 4.97s\n",
      "677:\tlearn: 1.9016813\ttotal: 10.4s\tremaining: 4.95s\n",
      "678:\tlearn: 1.9016813\ttotal: 10.4s\tremaining: 4.94s\n",
      "679:\tlearn: 1.9016808\ttotal: 10.5s\tremaining: 4.92s\n",
      "680:\tlearn: 1.9016532\ttotal: 10.5s\tremaining: 4.91s\n",
      "681:\tlearn: 1.9010086\ttotal: 10.5s\tremaining: 4.89s\n",
      "682:\tlearn: 1.9009176\ttotal: 10.5s\tremaining: 4.88s\n",
      "683:\tlearn: 1.9006726\ttotal: 10.5s\tremaining: 4.86s\n",
      "684:\tlearn: 1.9006274\ttotal: 10.5s\tremaining: 4.84s\n",
      "685:\tlearn: 1.8996254\ttotal: 10.6s\tremaining: 4.83s\n",
      "686:\tlearn: 1.8995527\ttotal: 10.6s\tremaining: 4.82s\n",
      "687:\tlearn: 1.8995520\ttotal: 10.6s\tremaining: 4.8s\n",
      "688:\tlearn: 1.8995490\ttotal: 10.6s\tremaining: 4.78s\n",
      "689:\tlearn: 1.8995487\ttotal: 10.6s\tremaining: 4.77s\n",
      "690:\tlearn: 1.8994626\ttotal: 10.6s\tremaining: 4.75s\n",
      "691:\tlearn: 1.8993114\ttotal: 10.6s\tremaining: 4.74s\n",
      "692:\tlearn: 1.8993083\ttotal: 10.7s\tremaining: 4.72s\n",
      "693:\tlearn: 1.8993069\ttotal: 10.7s\tremaining: 4.71s\n",
      "694:\tlearn: 1.8993027\ttotal: 10.7s\tremaining: 4.69s\n",
      "695:\tlearn: 1.8993024\ttotal: 10.7s\tremaining: 4.68s\n",
      "696:\tlearn: 1.8993023\ttotal: 10.7s\tremaining: 4.66s\n",
      "697:\tlearn: 1.8992966\ttotal: 10.7s\tremaining: 4.65s\n",
      "698:\tlearn: 1.8992955\ttotal: 10.8s\tremaining: 4.63s\n",
      "699:\tlearn: 1.8992390\ttotal: 10.8s\tremaining: 4.62s\n",
      "700:\tlearn: 1.8991508\ttotal: 10.8s\tremaining: 4.6s\n",
      "701:\tlearn: 1.8991461\ttotal: 10.8s\tremaining: 4.58s\n",
      "702:\tlearn: 1.8977043\ttotal: 10.8s\tremaining: 4.57s\n",
      "703:\tlearn: 1.8976581\ttotal: 10.8s\tremaining: 4.55s\n",
      "704:\tlearn: 1.8976158\ttotal: 10.8s\tremaining: 4.54s\n",
      "705:\tlearn: 1.8969096\ttotal: 10.9s\tremaining: 4.52s\n",
      "706:\tlearn: 1.8969096\ttotal: 10.9s\tremaining: 4.51s\n",
      "707:\tlearn: 1.8969010\ttotal: 10.9s\tremaining: 4.49s\n",
      "708:\tlearn: 1.8967732\ttotal: 10.9s\tremaining: 4.48s\n",
      "709:\tlearn: 1.8963005\ttotal: 10.9s\tremaining: 4.46s\n",
      "710:\tlearn: 1.8962756\ttotal: 10.9s\tremaining: 4.45s\n",
      "711:\tlearn: 1.8962755\ttotal: 11s\tremaining: 4.43s\n",
      "712:\tlearn: 1.8962285\ttotal: 11s\tremaining: 4.42s\n",
      "713:\tlearn: 1.8962044\ttotal: 11s\tremaining: 4.4s\n",
      "714:\tlearn: 1.8962042\ttotal: 11s\tremaining: 4.39s\n",
      "715:\tlearn: 1.8957607\ttotal: 11s\tremaining: 4.37s\n",
      "716:\tlearn: 1.8957607\ttotal: 11s\tremaining: 4.36s\n",
      "717:\tlearn: 1.8957607\ttotal: 11s\tremaining: 4.34s\n",
      "718:\tlearn: 1.8953817\ttotal: 11.1s\tremaining: 4.32s\n",
      "719:\tlearn: 1.8948188\ttotal: 11.1s\tremaining: 4.31s\n",
      "720:\tlearn: 1.8938850\ttotal: 11.1s\tremaining: 4.29s\n",
      "721:\tlearn: 1.8934554\ttotal: 11.1s\tremaining: 4.28s\n",
      "722:\tlearn: 1.8934553\ttotal: 11.1s\tremaining: 4.26s\n",
      "723:\tlearn: 1.8934553\ttotal: 11.1s\tremaining: 4.25s\n",
      "724:\tlearn: 1.8934552\ttotal: 11.2s\tremaining: 4.23s\n",
      "725:\tlearn: 1.8934515\ttotal: 11.2s\tremaining: 4.22s\n",
      "726:\tlearn: 1.8934515\ttotal: 11.2s\tremaining: 4.2s\n",
      "727:\tlearn: 1.8934281\ttotal: 11.2s\tremaining: 4.19s\n",
      "728:\tlearn: 1.8934029\ttotal: 11.2s\tremaining: 4.17s\n",
      "729:\tlearn: 1.8934027\ttotal: 11.2s\tremaining: 4.15s\n",
      "730:\tlearn: 1.8933954\ttotal: 11.2s\tremaining: 4.14s\n",
      "731:\tlearn: 1.8933945\ttotal: 11.3s\tremaining: 4.12s\n",
      "732:\tlearn: 1.8933903\ttotal: 11.3s\tremaining: 4.11s\n",
      "733:\tlearn: 1.8933903\ttotal: 11.3s\tremaining: 4.09s\n",
      "734:\tlearn: 1.8933903\ttotal: 11.3s\tremaining: 4.08s\n",
      "735:\tlearn: 1.8933357\ttotal: 11.3s\tremaining: 4.06s\n",
      "736:\tlearn: 1.8931330\ttotal: 11.3s\tremaining: 4.05s\n",
      "737:\tlearn: 1.8930943\ttotal: 11.4s\tremaining: 4.03s\n",
      "738:\tlearn: 1.8930508\ttotal: 11.4s\tremaining: 4.02s\n",
      "739:\tlearn: 1.8929482\ttotal: 11.4s\tremaining: 4s\n",
      "740:\tlearn: 1.8929053\ttotal: 11.4s\tremaining: 3.99s\n",
      "741:\tlearn: 1.8921241\ttotal: 11.4s\tremaining: 3.97s\n",
      "742:\tlearn: 1.8920927\ttotal: 11.4s\tremaining: 3.96s\n",
      "743:\tlearn: 1.8915280\ttotal: 11.5s\tremaining: 3.94s\n",
      "744:\tlearn: 1.8915178\ttotal: 11.5s\tremaining: 3.93s\n",
      "745:\tlearn: 1.8912320\ttotal: 11.5s\tremaining: 3.91s\n",
      "746:\tlearn: 1.8903774\ttotal: 11.5s\tremaining: 3.9s\n",
      "747:\tlearn: 1.8903650\ttotal: 11.5s\tremaining: 3.88s\n",
      "748:\tlearn: 1.8896170\ttotal: 11.5s\tremaining: 3.87s\n",
      "749:\tlearn: 1.8886624\ttotal: 11.6s\tremaining: 3.85s\n",
      "750:\tlearn: 1.8877696\ttotal: 11.6s\tremaining: 3.83s\n",
      "751:\tlearn: 1.8874428\ttotal: 11.6s\tremaining: 3.82s\n",
      "752:\tlearn: 1.8869622\ttotal: 11.6s\tremaining: 3.8s\n",
      "753:\tlearn: 1.8869205\ttotal: 11.6s\tremaining: 3.79s\n",
      "754:\tlearn: 1.8869177\ttotal: 11.6s\tremaining: 3.77s\n",
      "755:\tlearn: 1.8864469\ttotal: 11.6s\tremaining: 3.76s\n",
      "756:\tlearn: 1.8860462\ttotal: 11.7s\tremaining: 3.74s\n",
      "757:\tlearn: 1.8860370\ttotal: 11.7s\tremaining: 3.73s\n",
      "758:\tlearn: 1.8860351\ttotal: 11.7s\tremaining: 3.71s\n",
      "759:\tlearn: 1.8860343\ttotal: 11.7s\tremaining: 3.7s\n",
      "760:\tlearn: 1.8860324\ttotal: 11.7s\tremaining: 3.68s\n",
      "761:\tlearn: 1.8855008\ttotal: 11.7s\tremaining: 3.67s\n",
      "762:\tlearn: 1.8854952\ttotal: 11.8s\tremaining: 3.65s\n",
      "763:\tlearn: 1.8854897\ttotal: 11.8s\tremaining: 3.64s\n",
      "764:\tlearn: 1.8854897\ttotal: 11.8s\tremaining: 3.62s\n",
      "765:\tlearn: 1.8854301\ttotal: 11.8s\tremaining: 3.6s\n",
      "766:\tlearn: 1.8854268\ttotal: 11.8s\tremaining: 3.59s\n",
      "767:\tlearn: 1.8854167\ttotal: 11.8s\tremaining: 3.57s\n",
      "768:\tlearn: 1.8854123\ttotal: 11.8s\tremaining: 3.56s\n",
      "769:\tlearn: 1.8854028\ttotal: 11.9s\tremaining: 3.54s\n",
      "770:\tlearn: 1.8852698\ttotal: 11.9s\tremaining: 3.53s\n",
      "771:\tlearn: 1.8852304\ttotal: 11.9s\tremaining: 3.51s\n",
      "772:\tlearn: 1.8852282\ttotal: 11.9s\tremaining: 3.5s\n",
      "773:\tlearn: 1.8852271\ttotal: 11.9s\tremaining: 3.48s\n",
      "774:\tlearn: 1.8850229\ttotal: 11.9s\tremaining: 3.47s\n",
      "775:\tlearn: 1.8846822\ttotal: 12s\tremaining: 3.45s\n",
      "776:\tlearn: 1.8846819\ttotal: 12s\tremaining: 3.44s\n",
      "777:\tlearn: 1.8846818\ttotal: 12s\tremaining: 3.42s\n",
      "778:\tlearn: 1.8846818\ttotal: 12s\tremaining: 3.41s\n",
      "779:\tlearn: 1.8846817\ttotal: 12s\tremaining: 3.39s\n",
      "780:\tlearn: 1.8846817\ttotal: 12s\tremaining: 3.38s\n",
      "781:\tlearn: 1.8846816\ttotal: 12.1s\tremaining: 3.36s\n",
      "782:\tlearn: 1.8846369\ttotal: 12.1s\tremaining: 3.34s\n",
      "783:\tlearn: 1.8846312\ttotal: 12.1s\tremaining: 3.33s\n",
      "784:\tlearn: 1.8846312\ttotal: 12.1s\tremaining: 3.31s\n",
      "785:\tlearn: 1.8846310\ttotal: 12.1s\tremaining: 3.3s\n",
      "786:\tlearn: 1.8846305\ttotal: 12.1s\tremaining: 3.28s\n",
      "787:\tlearn: 1.8845644\ttotal: 12.1s\tremaining: 3.27s\n",
      "788:\tlearn: 1.8845478\ttotal: 12.2s\tremaining: 3.25s\n",
      "789:\tlearn: 1.8844754\ttotal: 12.2s\tremaining: 3.23s\n",
      "790:\tlearn: 1.8843757\ttotal: 12.2s\tremaining: 3.22s\n",
      "791:\tlearn: 1.8843735\ttotal: 12.2s\tremaining: 3.21s\n",
      "792:\tlearn: 1.8841907\ttotal: 12.2s\tremaining: 3.19s\n",
      "793:\tlearn: 1.8840547\ttotal: 12.2s\tremaining: 3.17s\n",
      "794:\tlearn: 1.8839708\ttotal: 12.3s\tremaining: 3.16s\n",
      "795:\tlearn: 1.8839540\ttotal: 12.3s\tremaining: 3.14s\n",
      "796:\tlearn: 1.8837057\ttotal: 12.3s\tremaining: 3.13s\n",
      "797:\tlearn: 1.8835141\ttotal: 12.3s\tremaining: 3.11s\n",
      "798:\tlearn: 1.8835016\ttotal: 12.3s\tremaining: 3.1s\n",
      "799:\tlearn: 1.8834843\ttotal: 12.3s\tremaining: 3.08s\n",
      "800:\tlearn: 1.8834176\ttotal: 12.3s\tremaining: 3.07s\n",
      "801:\tlearn: 1.8834176\ttotal: 12.4s\tremaining: 3.05s\n",
      "802:\tlearn: 1.8834175\ttotal: 12.4s\tremaining: 3.04s\n",
      "803:\tlearn: 1.8834169\ttotal: 12.4s\tremaining: 3.02s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804:\tlearn: 1.8827212\ttotal: 12.4s\tremaining: 3s\n",
      "805:\tlearn: 1.8819911\ttotal: 12.4s\tremaining: 2.99s\n",
      "806:\tlearn: 1.8819895\ttotal: 12.4s\tremaining: 2.97s\n",
      "807:\tlearn: 1.8819861\ttotal: 12.5s\tremaining: 2.96s\n",
      "808:\tlearn: 1.8817751\ttotal: 12.5s\tremaining: 2.94s\n",
      "809:\tlearn: 1.8817630\ttotal: 12.5s\tremaining: 2.93s\n",
      "810:\tlearn: 1.8815591\ttotal: 12.5s\tremaining: 2.91s\n",
      "811:\tlearn: 1.8811345\ttotal: 12.5s\tremaining: 2.9s\n",
      "812:\tlearn: 1.8808013\ttotal: 12.5s\tremaining: 2.88s\n",
      "813:\tlearn: 1.8807308\ttotal: 12.5s\tremaining: 2.87s\n",
      "814:\tlearn: 1.8807295\ttotal: 12.6s\tremaining: 2.85s\n",
      "815:\tlearn: 1.8806883\ttotal: 12.6s\tremaining: 2.84s\n",
      "816:\tlearn: 1.8806269\ttotal: 12.6s\tremaining: 2.82s\n",
      "817:\tlearn: 1.8789344\ttotal: 12.6s\tremaining: 2.81s\n",
      "818:\tlearn: 1.8785105\ttotal: 12.6s\tremaining: 2.79s\n",
      "819:\tlearn: 1.8785086\ttotal: 12.6s\tremaining: 2.77s\n",
      "820:\tlearn: 1.8784563\ttotal: 12.7s\tremaining: 2.76s\n",
      "821:\tlearn: 1.8784457\ttotal: 12.7s\tremaining: 2.74s\n",
      "822:\tlearn: 1.8784448\ttotal: 12.7s\tremaining: 2.73s\n",
      "823:\tlearn: 1.8784395\ttotal: 12.7s\tremaining: 2.71s\n",
      "824:\tlearn: 1.8784369\ttotal: 12.7s\tremaining: 2.7s\n",
      "825:\tlearn: 1.8783913\ttotal: 12.7s\tremaining: 2.68s\n",
      "826:\tlearn: 1.8774781\ttotal: 12.8s\tremaining: 2.67s\n",
      "827:\tlearn: 1.8774153\ttotal: 12.8s\tremaining: 2.65s\n",
      "828:\tlearn: 1.8774014\ttotal: 12.8s\tremaining: 2.64s\n",
      "829:\tlearn: 1.8773685\ttotal: 12.8s\tremaining: 2.62s\n",
      "830:\tlearn: 1.8773629\ttotal: 12.8s\tremaining: 2.61s\n",
      "831:\tlearn: 1.8767375\ttotal: 12.8s\tremaining: 2.59s\n",
      "832:\tlearn: 1.8767024\ttotal: 12.9s\tremaining: 2.58s\n",
      "833:\tlearn: 1.8765791\ttotal: 12.9s\tremaining: 2.56s\n",
      "834:\tlearn: 1.8762683\ttotal: 12.9s\tremaining: 2.55s\n",
      "835:\tlearn: 1.8761942\ttotal: 12.9s\tremaining: 2.53s\n",
      "836:\tlearn: 1.8761849\ttotal: 12.9s\tremaining: 2.52s\n",
      "837:\tlearn: 1.8761797\ttotal: 12.9s\tremaining: 2.5s\n",
      "838:\tlearn: 1.8761330\ttotal: 13s\tremaining: 2.48s\n",
      "839:\tlearn: 1.8760916\ttotal: 13s\tremaining: 2.47s\n",
      "840:\tlearn: 1.8760735\ttotal: 13s\tremaining: 2.45s\n",
      "841:\tlearn: 1.8757093\ttotal: 13s\tremaining: 2.44s\n",
      "842:\tlearn: 1.8756927\ttotal: 13s\tremaining: 2.42s\n",
      "843:\tlearn: 1.8753171\ttotal: 13s\tremaining: 2.41s\n",
      "844:\tlearn: 1.8752572\ttotal: 13s\tremaining: 2.39s\n",
      "845:\tlearn: 1.8744615\ttotal: 13.1s\tremaining: 2.38s\n",
      "846:\tlearn: 1.8740483\ttotal: 13.1s\tremaining: 2.36s\n",
      "847:\tlearn: 1.8738398\ttotal: 13.1s\tremaining: 2.35s\n",
      "848:\tlearn: 1.8738397\ttotal: 13.1s\tremaining: 2.33s\n",
      "849:\tlearn: 1.8738396\ttotal: 13.1s\tremaining: 2.32s\n",
      "850:\tlearn: 1.8738395\ttotal: 13.1s\tremaining: 2.3s\n",
      "851:\tlearn: 1.8738394\ttotal: 13.2s\tremaining: 2.29s\n",
      "852:\tlearn: 1.8738283\ttotal: 13.2s\tremaining: 2.27s\n",
      "853:\tlearn: 1.8738275\ttotal: 13.2s\tremaining: 2.25s\n",
      "854:\tlearn: 1.8738275\ttotal: 13.2s\tremaining: 2.24s\n",
      "855:\tlearn: 1.8738275\ttotal: 13.2s\tremaining: 2.22s\n",
      "856:\tlearn: 1.8738161\ttotal: 13.2s\tremaining: 2.21s\n",
      "857:\tlearn: 1.8738054\ttotal: 13.2s\tremaining: 2.19s\n",
      "858:\tlearn: 1.8738051\ttotal: 13.3s\tremaining: 2.18s\n",
      "859:\tlearn: 1.8738050\ttotal: 13.3s\tremaining: 2.16s\n",
      "860:\tlearn: 1.8738047\ttotal: 13.3s\tremaining: 2.15s\n",
      "861:\tlearn: 1.8738006\ttotal: 13.3s\tremaining: 2.13s\n",
      "862:\tlearn: 1.8735519\ttotal: 13.3s\tremaining: 2.11s\n",
      "863:\tlearn: 1.8735127\ttotal: 13.3s\tremaining: 2.1s\n",
      "864:\tlearn: 1.8734863\ttotal: 13.3s\tremaining: 2.08s\n",
      "865:\tlearn: 1.8734641\ttotal: 13.4s\tremaining: 2.07s\n",
      "866:\tlearn: 1.8733628\ttotal: 13.4s\tremaining: 2.05s\n",
      "867:\tlearn: 1.8733163\ttotal: 13.4s\tremaining: 2.04s\n",
      "868:\tlearn: 1.8732879\ttotal: 13.4s\tremaining: 2.02s\n",
      "869:\tlearn: 1.8732611\ttotal: 13.4s\tremaining: 2s\n",
      "870:\tlearn: 1.8732534\ttotal: 13.4s\tremaining: 1.99s\n",
      "871:\tlearn: 1.8731841\ttotal: 13.4s\tremaining: 1.97s\n",
      "872:\tlearn: 1.8731523\ttotal: 13.5s\tremaining: 1.96s\n",
      "873:\tlearn: 1.8731407\ttotal: 13.5s\tremaining: 1.94s\n",
      "874:\tlearn: 1.8731379\ttotal: 13.5s\tremaining: 1.93s\n",
      "875:\tlearn: 1.8731357\ttotal: 13.5s\tremaining: 1.91s\n",
      "876:\tlearn: 1.8730954\ttotal: 13.5s\tremaining: 1.9s\n",
      "877:\tlearn: 1.8730919\ttotal: 13.5s\tremaining: 1.88s\n",
      "878:\tlearn: 1.8730909\ttotal: 13.6s\tremaining: 1.86s\n",
      "879:\tlearn: 1.8730909\ttotal: 13.6s\tremaining: 1.85s\n",
      "880:\tlearn: 1.8730744\ttotal: 13.6s\tremaining: 1.83s\n",
      "881:\tlearn: 1.8730744\ttotal: 13.6s\tremaining: 1.82s\n",
      "882:\tlearn: 1.8730743\ttotal: 13.6s\tremaining: 1.8s\n",
      "883:\tlearn: 1.8730712\ttotal: 13.6s\tremaining: 1.79s\n",
      "884:\tlearn: 1.8730712\ttotal: 13.6s\tremaining: 1.77s\n",
      "885:\tlearn: 1.8730702\ttotal: 13.7s\tremaining: 1.76s\n",
      "886:\tlearn: 1.8730692\ttotal: 13.7s\tremaining: 1.74s\n",
      "887:\tlearn: 1.8730692\ttotal: 13.7s\tremaining: 1.73s\n",
      "888:\tlearn: 1.8730473\ttotal: 13.7s\tremaining: 1.71s\n",
      "889:\tlearn: 1.8730442\ttotal: 13.7s\tremaining: 1.7s\n",
      "890:\tlearn: 1.8730435\ttotal: 13.7s\tremaining: 1.68s\n",
      "891:\tlearn: 1.8730434\ttotal: 13.8s\tremaining: 1.67s\n",
      "892:\tlearn: 1.8730434\ttotal: 13.8s\tremaining: 1.65s\n",
      "893:\tlearn: 1.8729931\ttotal: 13.8s\tremaining: 1.63s\n",
      "894:\tlearn: 1.8729297\ttotal: 13.8s\tremaining: 1.62s\n",
      "895:\tlearn: 1.8729176\ttotal: 13.8s\tremaining: 1.6s\n",
      "896:\tlearn: 1.8719418\ttotal: 13.8s\tremaining: 1.59s\n",
      "897:\tlearn: 1.8717096\ttotal: 13.8s\tremaining: 1.57s\n",
      "898:\tlearn: 1.8707970\ttotal: 13.9s\tremaining: 1.56s\n",
      "899:\tlearn: 1.8707927\ttotal: 13.9s\tremaining: 1.54s\n",
      "900:\tlearn: 1.8707915\ttotal: 13.9s\tremaining: 1.53s\n",
      "901:\tlearn: 1.8707914\ttotal: 13.9s\tremaining: 1.51s\n",
      "902:\tlearn: 1.8707146\ttotal: 13.9s\tremaining: 1.5s\n",
      "903:\tlearn: 1.8703433\ttotal: 13.9s\tremaining: 1.48s\n",
      "904:\tlearn: 1.8692230\ttotal: 14s\tremaining: 1.47s\n",
      "905:\tlearn: 1.8692141\ttotal: 14s\tremaining: 1.45s\n",
      "906:\tlearn: 1.8689767\ttotal: 14s\tremaining: 1.44s\n",
      "907:\tlearn: 1.8689577\ttotal: 14s\tremaining: 1.42s\n",
      "908:\tlearn: 1.8689563\ttotal: 14s\tremaining: 1.4s\n",
      "909:\tlearn: 1.8681733\ttotal: 14s\tremaining: 1.39s\n",
      "910:\tlearn: 1.8681721\ttotal: 14.1s\tremaining: 1.37s\n",
      "911:\tlearn: 1.8681719\ttotal: 14.1s\tremaining: 1.36s\n",
      "912:\tlearn: 1.8681718\ttotal: 14.1s\tremaining: 1.34s\n",
      "913:\tlearn: 1.8681623\ttotal: 14.1s\tremaining: 1.33s\n",
      "914:\tlearn: 1.8681623\ttotal: 14.1s\tremaining: 1.31s\n",
      "915:\tlearn: 1.8681612\ttotal: 14.1s\tremaining: 1.3s\n",
      "916:\tlearn: 1.8681610\ttotal: 14.2s\tremaining: 1.28s\n",
      "917:\tlearn: 1.8681608\ttotal: 14.2s\tremaining: 1.27s\n",
      "918:\tlearn: 1.8681603\ttotal: 14.2s\tremaining: 1.25s\n",
      "919:\tlearn: 1.8681592\ttotal: 14.2s\tremaining: 1.24s\n",
      "920:\tlearn: 1.8680451\ttotal: 14.2s\tremaining: 1.22s\n",
      "921:\tlearn: 1.8677307\ttotal: 14.2s\tremaining: 1.2s\n",
      "922:\tlearn: 1.8677211\ttotal: 14.3s\tremaining: 1.19s\n",
      "923:\tlearn: 1.8677109\ttotal: 14.3s\tremaining: 1.17s\n",
      "924:\tlearn: 1.8676900\ttotal: 14.3s\tremaining: 1.16s\n",
      "925:\tlearn: 1.8675320\ttotal: 14.3s\tremaining: 1.14s\n",
      "926:\tlearn: 1.8668477\ttotal: 14.3s\tremaining: 1.13s\n",
      "927:\tlearn: 1.8666185\ttotal: 14.3s\tremaining: 1.11s\n",
      "928:\tlearn: 1.8666114\ttotal: 14.3s\tremaining: 1.1s\n",
      "929:\tlearn: 1.8664356\ttotal: 14.4s\tremaining: 1.08s\n",
      "930:\tlearn: 1.8664347\ttotal: 14.4s\tremaining: 1.06s\n",
      "931:\tlearn: 1.8664327\ttotal: 14.4s\tremaining: 1.05s\n",
      "932:\tlearn: 1.8663880\ttotal: 14.4s\tremaining: 1.03s\n",
      "933:\tlearn: 1.8663832\ttotal: 14.4s\tremaining: 1.02s\n",
      "934:\tlearn: 1.8663750\ttotal: 14.4s\tremaining: 1s\n",
      "935:\tlearn: 1.8663646\ttotal: 14.5s\tremaining: 988ms\n",
      "936:\tlearn: 1.8663525\ttotal: 14.5s\tremaining: 973ms\n",
      "937:\tlearn: 1.8658604\ttotal: 14.5s\tremaining: 957ms\n",
      "938:\tlearn: 1.8648721\ttotal: 14.5s\tremaining: 942ms\n",
      "939:\tlearn: 1.8648719\ttotal: 14.5s\tremaining: 926ms\n",
      "940:\tlearn: 1.8648218\ttotal: 14.5s\tremaining: 911ms\n",
      "941:\tlearn: 1.8647500\ttotal: 14.5s\tremaining: 895ms\n",
      "942:\tlearn: 1.8647309\ttotal: 14.6s\tremaining: 880ms\n",
      "943:\tlearn: 1.8640914\ttotal: 14.6s\tremaining: 865ms\n",
      "944:\tlearn: 1.8640873\ttotal: 14.6s\tremaining: 849ms\n",
      "945:\tlearn: 1.8638255\ttotal: 14.6s\tremaining: 834ms\n",
      "946:\tlearn: 1.8636525\ttotal: 14.6s\tremaining: 818ms\n",
      "947:\tlearn: 1.8633845\ttotal: 14.6s\tremaining: 803ms\n",
      "948:\tlearn: 1.8629846\ttotal: 14.6s\tremaining: 787ms\n",
      "949:\tlearn: 1.8625363\ttotal: 14.7s\tremaining: 772ms\n",
      "950:\tlearn: 1.8616865\ttotal: 14.7s\tremaining: 756ms\n",
      "951:\tlearn: 1.8612540\ttotal: 14.7s\tremaining: 741ms\n",
      "952:\tlearn: 1.8605289\ttotal: 14.7s\tremaining: 725ms\n",
      "953:\tlearn: 1.8605281\ttotal: 14.7s\tremaining: 710ms\n",
      "954:\tlearn: 1.8605184\ttotal: 14.7s\tremaining: 694ms\n",
      "955:\tlearn: 1.8604793\ttotal: 14.8s\tremaining: 679ms\n",
      "956:\tlearn: 1.8602602\ttotal: 14.8s\tremaining: 664ms\n",
      "957:\tlearn: 1.8598645\ttotal: 14.8s\tremaining: 648ms\n",
      "958:\tlearn: 1.8596595\ttotal: 14.8s\tremaining: 633ms\n",
      "959:\tlearn: 1.8595855\ttotal: 14.8s\tremaining: 617ms\n",
      "960:\tlearn: 1.8595453\ttotal: 14.8s\tremaining: 602ms\n",
      "961:\tlearn: 1.8594948\ttotal: 14.8s\tremaining: 586ms\n",
      "962:\tlearn: 1.8590421\ttotal: 14.9s\tremaining: 571ms\n",
      "963:\tlearn: 1.8588653\ttotal: 14.9s\tremaining: 555ms\n",
      "964:\tlearn: 1.8588529\ttotal: 14.9s\tremaining: 540ms\n",
      "965:\tlearn: 1.8584025\ttotal: 14.9s\tremaining: 525ms\n",
      "966:\tlearn: 1.8583491\ttotal: 14.9s\tremaining: 509ms\n",
      "967:\tlearn: 1.8576168\ttotal: 14.9s\tremaining: 494ms\n",
      "968:\tlearn: 1.8571341\ttotal: 14.9s\tremaining: 478ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969:\tlearn: 1.8571318\ttotal: 15s\tremaining: 463ms\n",
      "970:\tlearn: 1.8571245\ttotal: 15s\tremaining: 447ms\n",
      "971:\tlearn: 1.8571245\ttotal: 15s\tremaining: 432ms\n",
      "972:\tlearn: 1.8570315\ttotal: 15s\tremaining: 417ms\n",
      "973:\tlearn: 1.8568794\ttotal: 15s\tremaining: 401ms\n",
      "974:\tlearn: 1.8568671\ttotal: 15s\tremaining: 386ms\n",
      "975:\tlearn: 1.8564506\ttotal: 15.1s\tremaining: 370ms\n",
      "976:\tlearn: 1.8561293\ttotal: 15.1s\tremaining: 355ms\n",
      "977:\tlearn: 1.8559376\ttotal: 15.1s\tremaining: 339ms\n",
      "978:\tlearn: 1.8557933\ttotal: 15.1s\tremaining: 324ms\n",
      "979:\tlearn: 1.8557928\ttotal: 15.1s\tremaining: 308ms\n",
      "980:\tlearn: 1.8557455\ttotal: 15.1s\tremaining: 293ms\n",
      "981:\tlearn: 1.8548422\ttotal: 15.1s\tremaining: 278ms\n",
      "982:\tlearn: 1.8547953\ttotal: 15.2s\tremaining: 262ms\n",
      "983:\tlearn: 1.8547950\ttotal: 15.2s\tremaining: 247ms\n",
      "984:\tlearn: 1.8547941\ttotal: 15.2s\tremaining: 231ms\n",
      "985:\tlearn: 1.8543491\ttotal: 15.2s\tremaining: 216ms\n",
      "986:\tlearn: 1.8543491\ttotal: 15.2s\tremaining: 201ms\n",
      "987:\tlearn: 1.8543204\ttotal: 15.2s\tremaining: 185ms\n",
      "988:\tlearn: 1.8543200\ttotal: 15.3s\tremaining: 170ms\n",
      "989:\tlearn: 1.8542414\ttotal: 15.3s\tremaining: 154ms\n",
      "990:\tlearn: 1.8542204\ttotal: 15.3s\tremaining: 139ms\n",
      "991:\tlearn: 1.8541740\ttotal: 15.3s\tremaining: 123ms\n",
      "992:\tlearn: 1.8539764\ttotal: 15.3s\tremaining: 108ms\n",
      "993:\tlearn: 1.8539587\ttotal: 15.3s\tremaining: 92.5ms\n",
      "994:\tlearn: 1.8538541\ttotal: 15.3s\tremaining: 77.1ms\n",
      "995:\tlearn: 1.8538086\ttotal: 15.4s\tremaining: 61.7ms\n",
      "996:\tlearn: 1.8538065\ttotal: 15.4s\tremaining: 46.3ms\n",
      "997:\tlearn: 1.8537588\ttotal: 15.4s\tremaining: 30.8ms\n",
      "998:\tlearn: 1.8531897\ttotal: 15.4s\tremaining: 15.4ms\n",
      "999:\tlearn: 1.8516498\ttotal: 15.4s\tremaining: 0us\n",
      "0:\tlearn: 9.9489420\ttotal: 19ms\tremaining: 18.9s\n",
      "1:\tlearn: 9.0684927\ttotal: 37ms\tremaining: 18.5s\n",
      "2:\tlearn: 8.4538210\ttotal: 53.8ms\tremaining: 17.9s\n",
      "3:\tlearn: 7.7298420\ttotal: 71.3ms\tremaining: 17.8s\n",
      "4:\tlearn: 7.0895111\ttotal: 88.2ms\tremaining: 17.6s\n",
      "5:\tlearn: 6.6595027\ttotal: 105ms\tremaining: 17.3s\n",
      "6:\tlearn: 6.1174334\ttotal: 120ms\tremaining: 17s\n",
      "7:\tlearn: 5.7238521\ttotal: 136ms\tremaining: 16.9s\n",
      "8:\tlearn: 5.2933390\ttotal: 152ms\tremaining: 16.7s\n",
      "9:\tlearn: 4.9035462\ttotal: 167ms\tremaining: 16.5s\n",
      "10:\tlearn: 4.5628077\ttotal: 182ms\tremaining: 16.4s\n",
      "11:\tlearn: 4.2520875\ttotal: 197ms\tremaining: 16.2s\n",
      "12:\tlearn: 3.9881473\ttotal: 213ms\tremaining: 16.2s\n",
      "13:\tlearn: 3.7826559\ttotal: 228ms\tremaining: 16s\n",
      "14:\tlearn: 3.6349228\ttotal: 242ms\tremaining: 15.9s\n",
      "15:\tlearn: 3.4491583\ttotal: 256ms\tremaining: 15.8s\n",
      "16:\tlearn: 3.3037024\ttotal: 272ms\tremaining: 15.7s\n",
      "17:\tlearn: 3.1729983\ttotal: 287ms\tremaining: 15.6s\n",
      "18:\tlearn: 3.0885419\ttotal: 301ms\tremaining: 15.6s\n",
      "19:\tlearn: 2.9864971\ttotal: 316ms\tremaining: 15.5s\n",
      "20:\tlearn: 2.9121070\ttotal: 331ms\tremaining: 15.4s\n",
      "21:\tlearn: 2.8526739\ttotal: 345ms\tremaining: 15.3s\n",
      "22:\tlearn: 2.8007504\ttotal: 359ms\tremaining: 15.3s\n",
      "23:\tlearn: 2.7330946\ttotal: 375ms\tremaining: 15.2s\n",
      "24:\tlearn: 2.6747480\ttotal: 389ms\tremaining: 15.2s\n",
      "25:\tlearn: 2.6443929\ttotal: 403ms\tremaining: 15.1s\n",
      "26:\tlearn: 2.6121574\ttotal: 417ms\tremaining: 15s\n",
      "27:\tlearn: 2.5860594\ttotal: 431ms\tremaining: 15s\n",
      "28:\tlearn: 2.5445919\ttotal: 445ms\tremaining: 14.9s\n",
      "29:\tlearn: 2.5159992\ttotal: 459ms\tremaining: 14.9s\n",
      "30:\tlearn: 2.4925562\ttotal: 476ms\tremaining: 14.9s\n",
      "31:\tlearn: 2.4633116\ttotal: 490ms\tremaining: 14.8s\n",
      "32:\tlearn: 2.4499699\ttotal: 505ms\tremaining: 14.8s\n",
      "33:\tlearn: 2.4250337\ttotal: 519ms\tremaining: 14.7s\n",
      "34:\tlearn: 2.4144455\ttotal: 533ms\tremaining: 14.7s\n",
      "35:\tlearn: 2.3851942\ttotal: 547ms\tremaining: 14.7s\n",
      "36:\tlearn: 2.3753973\ttotal: 562ms\tremaining: 14.6s\n",
      "37:\tlearn: 2.3616695\ttotal: 576ms\tremaining: 14.6s\n",
      "38:\tlearn: 2.3544580\ttotal: 590ms\tremaining: 14.5s\n",
      "39:\tlearn: 2.3450926\ttotal: 604ms\tremaining: 14.5s\n",
      "40:\tlearn: 2.3391744\ttotal: 618ms\tremaining: 14.5s\n",
      "41:\tlearn: 2.3360188\ttotal: 632ms\tremaining: 14.4s\n",
      "42:\tlearn: 2.3160274\ttotal: 647ms\tremaining: 14.4s\n",
      "43:\tlearn: 2.3126130\ttotal: 661ms\tremaining: 14.4s\n",
      "44:\tlearn: 2.3098847\ttotal: 674ms\tremaining: 14.3s\n",
      "45:\tlearn: 2.2951448\ttotal: 691ms\tremaining: 14.3s\n",
      "46:\tlearn: 2.2925367\ttotal: 706ms\tremaining: 14.3s\n",
      "47:\tlearn: 2.2897962\ttotal: 720ms\tremaining: 14.3s\n",
      "48:\tlearn: 2.2877997\ttotal: 735ms\tremaining: 14.3s\n",
      "49:\tlearn: 2.2829495\ttotal: 748ms\tremaining: 14.2s\n",
      "50:\tlearn: 2.2817160\ttotal: 763ms\tremaining: 14.2s\n",
      "51:\tlearn: 2.2742446\ttotal: 778ms\tremaining: 14.2s\n",
      "52:\tlearn: 2.2726287\ttotal: 791ms\tremaining: 14.1s\n",
      "53:\tlearn: 2.2706099\ttotal: 805ms\tremaining: 14.1s\n",
      "54:\tlearn: 2.2695289\ttotal: 819ms\tremaining: 14.1s\n",
      "55:\tlearn: 2.2646228\ttotal: 834ms\tremaining: 14.1s\n",
      "56:\tlearn: 2.2636979\ttotal: 847ms\tremaining: 14s\n",
      "57:\tlearn: 2.2586956\ttotal: 861ms\tremaining: 14s\n",
      "58:\tlearn: 2.2579083\ttotal: 874ms\tremaining: 13.9s\n",
      "59:\tlearn: 2.2573681\ttotal: 888ms\tremaining: 13.9s\n",
      "60:\tlearn: 2.2569212\ttotal: 903ms\tremaining: 13.9s\n",
      "61:\tlearn: 2.2557164\ttotal: 918ms\tremaining: 13.9s\n",
      "62:\tlearn: 2.2551887\ttotal: 932ms\tremaining: 13.9s\n",
      "63:\tlearn: 2.2546493\ttotal: 947ms\tremaining: 13.8s\n",
      "64:\tlearn: 2.2537964\ttotal: 961ms\tremaining: 13.8s\n",
      "65:\tlearn: 2.2520912\ttotal: 976ms\tremaining: 13.8s\n",
      "66:\tlearn: 2.2517816\ttotal: 989ms\tremaining: 13.8s\n",
      "67:\tlearn: 2.2505599\ttotal: 1s\tremaining: 13.8s\n",
      "68:\tlearn: 2.2493545\ttotal: 1.02s\tremaining: 13.7s\n",
      "69:\tlearn: 2.2431102\ttotal: 1.03s\tremaining: 13.7s\n",
      "70:\tlearn: 2.2423481\ttotal: 1.04s\tremaining: 13.7s\n",
      "71:\tlearn: 2.2417701\ttotal: 1.06s\tremaining: 13.6s\n",
      "72:\tlearn: 2.2404211\ttotal: 1.07s\tremaining: 13.6s\n",
      "73:\tlearn: 2.2394677\ttotal: 1.09s\tremaining: 13.6s\n",
      "74:\tlearn: 2.2356088\ttotal: 1.1s\tremaining: 13.6s\n",
      "75:\tlearn: 2.2274752\ttotal: 1.11s\tremaining: 13.6s\n",
      "76:\tlearn: 2.2262584\ttotal: 1.13s\tremaining: 13.6s\n",
      "77:\tlearn: 2.2256307\ttotal: 1.15s\tremaining: 13.5s\n",
      "78:\tlearn: 2.2244745\ttotal: 1.16s\tremaining: 13.5s\n",
      "79:\tlearn: 2.2179540\ttotal: 1.17s\tremaining: 13.5s\n",
      "80:\tlearn: 2.2168237\ttotal: 1.19s\tremaining: 13.5s\n",
      "81:\tlearn: 2.2164597\ttotal: 1.2s\tremaining: 13.5s\n",
      "82:\tlearn: 2.2164160\ttotal: 1.22s\tremaining: 13.5s\n",
      "83:\tlearn: 2.2153599\ttotal: 1.23s\tremaining: 13.4s\n",
      "84:\tlearn: 2.2145063\ttotal: 1.25s\tremaining: 13.4s\n",
      "85:\tlearn: 2.2120130\ttotal: 1.26s\tremaining: 13.4s\n",
      "86:\tlearn: 2.2100084\ttotal: 1.27s\tremaining: 13.4s\n",
      "87:\tlearn: 2.2098672\ttotal: 1.29s\tremaining: 13.4s\n",
      "88:\tlearn: 2.2094062\ttotal: 1.3s\tremaining: 13.4s\n",
      "89:\tlearn: 2.2092143\ttotal: 1.32s\tremaining: 13.3s\n",
      "90:\tlearn: 2.2078157\ttotal: 1.33s\tremaining: 13.3s\n",
      "91:\tlearn: 2.2075374\ttotal: 1.35s\tremaining: 13.3s\n",
      "92:\tlearn: 2.2036895\ttotal: 1.36s\tremaining: 13.3s\n",
      "93:\tlearn: 2.2033529\ttotal: 1.38s\tremaining: 13.3s\n",
      "94:\tlearn: 2.2025153\ttotal: 1.39s\tremaining: 13.3s\n",
      "95:\tlearn: 2.2020064\ttotal: 1.41s\tremaining: 13.3s\n",
      "96:\tlearn: 2.2018231\ttotal: 1.42s\tremaining: 13.2s\n",
      "97:\tlearn: 2.2013540\ttotal: 1.44s\tremaining: 13.2s\n",
      "98:\tlearn: 2.2007341\ttotal: 1.45s\tremaining: 13.2s\n",
      "99:\tlearn: 2.2005548\ttotal: 1.46s\tremaining: 13.2s\n",
      "100:\tlearn: 2.1998081\ttotal: 1.48s\tremaining: 13.2s\n",
      "101:\tlearn: 2.1987063\ttotal: 1.49s\tremaining: 13.1s\n",
      "102:\tlearn: 2.1978357\ttotal: 1.5s\tremaining: 13.1s\n",
      "103:\tlearn: 2.1968051\ttotal: 1.52s\tremaining: 13.1s\n",
      "104:\tlearn: 2.1965387\ttotal: 1.53s\tremaining: 13.1s\n",
      "105:\tlearn: 2.1961991\ttotal: 1.55s\tremaining: 13.1s\n",
      "106:\tlearn: 2.1943158\ttotal: 1.56s\tremaining: 13.1s\n",
      "107:\tlearn: 2.1913405\ttotal: 1.58s\tremaining: 13s\n",
      "108:\tlearn: 2.1910104\ttotal: 1.59s\tremaining: 13s\n",
      "109:\tlearn: 2.1860230\ttotal: 1.61s\tremaining: 13s\n",
      "110:\tlearn: 2.1857919\ttotal: 1.62s\tremaining: 13s\n",
      "111:\tlearn: 2.1853734\ttotal: 1.64s\tremaining: 13s\n",
      "112:\tlearn: 2.1851944\ttotal: 1.65s\tremaining: 12.9s\n",
      "113:\tlearn: 2.1850655\ttotal: 1.66s\tremaining: 12.9s\n",
      "114:\tlearn: 2.1843197\ttotal: 1.68s\tremaining: 12.9s\n",
      "115:\tlearn: 2.1824809\ttotal: 1.69s\tremaining: 12.9s\n",
      "116:\tlearn: 2.1819529\ttotal: 1.71s\tremaining: 12.9s\n",
      "117:\tlearn: 2.1783790\ttotal: 1.72s\tremaining: 12.9s\n",
      "118:\tlearn: 2.1780321\ttotal: 1.74s\tremaining: 12.9s\n",
      "119:\tlearn: 2.1776712\ttotal: 1.75s\tremaining: 12.8s\n",
      "120:\tlearn: 2.1772480\ttotal: 1.76s\tremaining: 12.8s\n",
      "121:\tlearn: 2.1763268\ttotal: 1.78s\tremaining: 12.8s\n",
      "122:\tlearn: 2.1762790\ttotal: 1.8s\tremaining: 12.8s\n",
      "123:\tlearn: 2.1758880\ttotal: 1.81s\tremaining: 12.8s\n",
      "124:\tlearn: 2.1752959\ttotal: 1.82s\tremaining: 12.8s\n",
      "125:\tlearn: 2.1748227\ttotal: 1.84s\tremaining: 12.8s\n",
      "126:\tlearn: 2.1671480\ttotal: 1.85s\tremaining: 12.7s\n",
      "127:\tlearn: 2.1654029\ttotal: 1.87s\tremaining: 12.7s\n",
      "128:\tlearn: 2.1615356\ttotal: 1.88s\tremaining: 12.7s\n",
      "129:\tlearn: 2.1555891\ttotal: 1.9s\tremaining: 12.7s\n",
      "130:\tlearn: 2.1541481\ttotal: 1.91s\tremaining: 12.7s\n",
      "131:\tlearn: 2.1524332\ttotal: 1.92s\tremaining: 12.7s\n",
      "132:\tlearn: 2.1486197\ttotal: 1.94s\tremaining: 12.6s\n",
      "133:\tlearn: 2.1474773\ttotal: 1.95s\tremaining: 12.6s\n",
      "134:\tlearn: 2.1466256\ttotal: 1.97s\tremaining: 12.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135:\tlearn: 2.1396066\ttotal: 1.98s\tremaining: 12.6s\n",
      "136:\tlearn: 2.1392323\ttotal: 2s\tremaining: 12.6s\n",
      "137:\tlearn: 2.1366423\ttotal: 2.01s\tremaining: 12.6s\n",
      "138:\tlearn: 2.1351954\ttotal: 2.03s\tremaining: 12.6s\n",
      "139:\tlearn: 2.1344097\ttotal: 2.04s\tremaining: 12.5s\n",
      "140:\tlearn: 2.1337646\ttotal: 2.06s\tremaining: 12.5s\n",
      "141:\tlearn: 2.1311008\ttotal: 2.07s\tremaining: 12.5s\n",
      "142:\tlearn: 2.1304175\ttotal: 2.09s\tremaining: 12.5s\n",
      "143:\tlearn: 2.1293129\ttotal: 2.11s\tremaining: 12.5s\n",
      "144:\tlearn: 2.1258478\ttotal: 2.12s\tremaining: 12.5s\n",
      "145:\tlearn: 2.1215646\ttotal: 2.13s\tremaining: 12.5s\n",
      "146:\tlearn: 2.1204691\ttotal: 2.15s\tremaining: 12.5s\n",
      "147:\tlearn: 2.1187660\ttotal: 2.16s\tremaining: 12.5s\n",
      "148:\tlearn: 2.1145984\ttotal: 2.18s\tremaining: 12.5s\n",
      "149:\tlearn: 2.1129493\ttotal: 2.19s\tremaining: 12.4s\n",
      "150:\tlearn: 2.1112084\ttotal: 2.21s\tremaining: 12.4s\n",
      "151:\tlearn: 2.1094279\ttotal: 2.23s\tremaining: 12.4s\n",
      "152:\tlearn: 2.1025698\ttotal: 2.24s\tremaining: 12.4s\n",
      "153:\tlearn: 2.0995698\ttotal: 2.25s\tremaining: 12.4s\n",
      "154:\tlearn: 2.0977850\ttotal: 2.27s\tremaining: 12.4s\n",
      "155:\tlearn: 2.0928826\ttotal: 2.28s\tremaining: 12.3s\n",
      "156:\tlearn: 2.0900366\ttotal: 2.3s\tremaining: 12.3s\n",
      "157:\tlearn: 2.0883629\ttotal: 2.31s\tremaining: 12.3s\n",
      "158:\tlearn: 2.0833555\ttotal: 2.33s\tremaining: 12.3s\n",
      "159:\tlearn: 2.0802134\ttotal: 2.34s\tremaining: 12.3s\n",
      "160:\tlearn: 2.0769116\ttotal: 2.35s\tremaining: 12.3s\n",
      "161:\tlearn: 2.0753476\ttotal: 2.37s\tremaining: 12.2s\n",
      "162:\tlearn: 2.0734989\ttotal: 2.38s\tremaining: 12.2s\n",
      "163:\tlearn: 2.0710493\ttotal: 2.4s\tremaining: 12.2s\n",
      "164:\tlearn: 2.0688431\ttotal: 2.41s\tremaining: 12.2s\n",
      "165:\tlearn: 2.0647663\ttotal: 2.43s\tremaining: 12.2s\n",
      "166:\tlearn: 2.0641377\ttotal: 2.44s\tremaining: 12.2s\n",
      "167:\tlearn: 2.0629509\ttotal: 2.46s\tremaining: 12.2s\n",
      "168:\tlearn: 2.0600935\ttotal: 2.47s\tremaining: 12.2s\n",
      "169:\tlearn: 2.0571909\ttotal: 2.49s\tremaining: 12.1s\n",
      "170:\tlearn: 2.0559116\ttotal: 2.5s\tremaining: 12.1s\n",
      "171:\tlearn: 2.0532117\ttotal: 2.52s\tremaining: 12.1s\n",
      "172:\tlearn: 2.0503505\ttotal: 2.53s\tremaining: 12.1s\n",
      "173:\tlearn: 2.0495864\ttotal: 2.54s\tremaining: 12.1s\n",
      "174:\tlearn: 2.0472109\ttotal: 2.56s\tremaining: 12.1s\n",
      "175:\tlearn: 2.0452108\ttotal: 2.57s\tremaining: 12s\n",
      "176:\tlearn: 2.0435819\ttotal: 2.59s\tremaining: 12s\n",
      "177:\tlearn: 2.0424246\ttotal: 2.6s\tremaining: 12s\n",
      "178:\tlearn: 2.0416596\ttotal: 2.61s\tremaining: 12s\n",
      "179:\tlearn: 2.0402792\ttotal: 2.63s\tremaining: 12s\n",
      "180:\tlearn: 2.0394453\ttotal: 2.64s\tremaining: 12s\n",
      "181:\tlearn: 2.0387053\ttotal: 2.66s\tremaining: 11.9s\n",
      "182:\tlearn: 2.0379647\ttotal: 2.67s\tremaining: 11.9s\n",
      "183:\tlearn: 2.0363919\ttotal: 2.69s\tremaining: 11.9s\n",
      "184:\tlearn: 2.0361922\ttotal: 2.7s\tremaining: 11.9s\n",
      "185:\tlearn: 2.0355055\ttotal: 2.71s\tremaining: 11.9s\n",
      "186:\tlearn: 2.0324068\ttotal: 2.73s\tremaining: 11.9s\n",
      "187:\tlearn: 2.0316721\ttotal: 2.74s\tremaining: 11.8s\n",
      "188:\tlearn: 2.0296420\ttotal: 2.75s\tremaining: 11.8s\n",
      "189:\tlearn: 2.0279105\ttotal: 2.77s\tremaining: 11.8s\n",
      "190:\tlearn: 2.0274978\ttotal: 2.78s\tremaining: 11.8s\n",
      "191:\tlearn: 2.0253354\ttotal: 2.8s\tremaining: 11.8s\n",
      "192:\tlearn: 2.0246406\ttotal: 2.81s\tremaining: 11.8s\n",
      "193:\tlearn: 2.0238478\ttotal: 2.83s\tremaining: 11.7s\n",
      "194:\tlearn: 2.0220239\ttotal: 2.84s\tremaining: 11.7s\n",
      "195:\tlearn: 2.0216887\ttotal: 2.86s\tremaining: 11.7s\n",
      "196:\tlearn: 2.0196953\ttotal: 2.87s\tremaining: 11.7s\n",
      "197:\tlearn: 2.0192223\ttotal: 2.88s\tremaining: 11.7s\n",
      "198:\tlearn: 2.0184822\ttotal: 2.9s\tremaining: 11.7s\n",
      "199:\tlearn: 2.0180001\ttotal: 2.91s\tremaining: 11.6s\n",
      "200:\tlearn: 2.0166391\ttotal: 2.93s\tremaining: 11.6s\n",
      "201:\tlearn: 2.0150757\ttotal: 2.94s\tremaining: 11.6s\n",
      "202:\tlearn: 2.0142112\ttotal: 2.95s\tremaining: 11.6s\n",
      "203:\tlearn: 2.0131769\ttotal: 2.97s\tremaining: 11.6s\n",
      "204:\tlearn: 2.0120863\ttotal: 2.98s\tremaining: 11.6s\n",
      "205:\tlearn: 2.0116554\ttotal: 3s\tremaining: 11.5s\n",
      "206:\tlearn: 2.0101821\ttotal: 3.01s\tremaining: 11.5s\n",
      "207:\tlearn: 2.0101617\ttotal: 3.02s\tremaining: 11.5s\n",
      "208:\tlearn: 2.0097744\ttotal: 3.04s\tremaining: 11.5s\n",
      "209:\tlearn: 2.0096951\ttotal: 3.05s\tremaining: 11.5s\n",
      "210:\tlearn: 2.0096595\ttotal: 3.06s\tremaining: 11.5s\n",
      "211:\tlearn: 2.0084010\ttotal: 3.08s\tremaining: 11.4s\n",
      "212:\tlearn: 2.0059713\ttotal: 3.09s\tremaining: 11.4s\n",
      "213:\tlearn: 2.0056016\ttotal: 3.11s\tremaining: 11.4s\n",
      "214:\tlearn: 2.0044115\ttotal: 3.12s\tremaining: 11.4s\n",
      "215:\tlearn: 2.0044109\ttotal: 3.13s\tremaining: 11.4s\n",
      "216:\tlearn: 2.0037241\ttotal: 3.15s\tremaining: 11.4s\n",
      "217:\tlearn: 2.0032575\ttotal: 3.16s\tremaining: 11.3s\n",
      "218:\tlearn: 2.0030333\ttotal: 3.18s\tremaining: 11.3s\n",
      "219:\tlearn: 2.0029642\ttotal: 3.19s\tremaining: 11.3s\n",
      "220:\tlearn: 2.0007694\ttotal: 3.2s\tremaining: 11.3s\n",
      "221:\tlearn: 1.9982693\ttotal: 3.22s\tremaining: 11.3s\n",
      "222:\tlearn: 1.9982466\ttotal: 3.23s\tremaining: 11.3s\n",
      "223:\tlearn: 1.9980699\ttotal: 3.25s\tremaining: 11.2s\n",
      "224:\tlearn: 1.9979367\ttotal: 3.26s\tremaining: 11.2s\n",
      "225:\tlearn: 1.9978438\ttotal: 3.27s\tremaining: 11.2s\n",
      "226:\tlearn: 1.9978288\ttotal: 3.29s\tremaining: 11.2s\n",
      "227:\tlearn: 1.9977816\ttotal: 3.3s\tremaining: 11.2s\n",
      "228:\tlearn: 1.9968901\ttotal: 3.32s\tremaining: 11.2s\n",
      "229:\tlearn: 1.9962291\ttotal: 3.33s\tremaining: 11.2s\n",
      "230:\tlearn: 1.9957304\ttotal: 3.35s\tremaining: 11.1s\n",
      "231:\tlearn: 1.9954468\ttotal: 3.36s\tremaining: 11.1s\n",
      "232:\tlearn: 1.9937131\ttotal: 3.37s\tremaining: 11.1s\n",
      "233:\tlearn: 1.9936259\ttotal: 3.38s\tremaining: 11.1s\n",
      "234:\tlearn: 1.9930193\ttotal: 3.4s\tremaining: 11.1s\n",
      "235:\tlearn: 1.9929044\ttotal: 3.41s\tremaining: 11s\n",
      "236:\tlearn: 1.9928214\ttotal: 3.43s\tremaining: 11s\n",
      "237:\tlearn: 1.9924702\ttotal: 3.44s\tremaining: 11s\n",
      "238:\tlearn: 1.9921302\ttotal: 3.45s\tremaining: 11s\n",
      "239:\tlearn: 1.9921267\ttotal: 3.47s\tremaining: 11s\n",
      "240:\tlearn: 1.9920671\ttotal: 3.48s\tremaining: 11s\n",
      "241:\tlearn: 1.9920542\ttotal: 3.5s\tremaining: 11s\n",
      "242:\tlearn: 1.9912266\ttotal: 3.51s\tremaining: 10.9s\n",
      "243:\tlearn: 1.9903399\ttotal: 3.53s\tremaining: 10.9s\n",
      "244:\tlearn: 1.9896574\ttotal: 3.54s\tremaining: 10.9s\n",
      "245:\tlearn: 1.9895733\ttotal: 3.55s\tremaining: 10.9s\n",
      "246:\tlearn: 1.9895507\ttotal: 3.57s\tremaining: 10.9s\n",
      "247:\tlearn: 1.9885027\ttotal: 3.58s\tremaining: 10.9s\n",
      "248:\tlearn: 1.9881980\ttotal: 3.6s\tremaining: 10.8s\n",
      "249:\tlearn: 1.9881625\ttotal: 3.61s\tremaining: 10.8s\n",
      "250:\tlearn: 1.9879030\ttotal: 3.62s\tremaining: 10.8s\n",
      "251:\tlearn: 1.9862204\ttotal: 3.64s\tremaining: 10.8s\n",
      "252:\tlearn: 1.9844665\ttotal: 3.65s\tremaining: 10.8s\n",
      "253:\tlearn: 1.9827259\ttotal: 3.67s\tremaining: 10.8s\n",
      "254:\tlearn: 1.9816571\ttotal: 3.68s\tremaining: 10.7s\n",
      "255:\tlearn: 1.9790650\ttotal: 3.69s\tremaining: 10.7s\n",
      "256:\tlearn: 1.9787501\ttotal: 3.71s\tremaining: 10.7s\n",
      "257:\tlearn: 1.9770646\ttotal: 3.72s\tremaining: 10.7s\n",
      "258:\tlearn: 1.9770235\ttotal: 3.74s\tremaining: 10.7s\n",
      "259:\tlearn: 1.9769197\ttotal: 3.75s\tremaining: 10.7s\n",
      "260:\tlearn: 1.9757585\ttotal: 3.77s\tremaining: 10.7s\n",
      "261:\tlearn: 1.9748840\ttotal: 3.78s\tremaining: 10.6s\n",
      "262:\tlearn: 1.9719470\ttotal: 3.79s\tremaining: 10.6s\n",
      "263:\tlearn: 1.9713191\ttotal: 3.81s\tremaining: 10.6s\n",
      "264:\tlearn: 1.9706195\ttotal: 3.82s\tremaining: 10.6s\n",
      "265:\tlearn: 1.9690910\ttotal: 3.84s\tremaining: 10.6s\n",
      "266:\tlearn: 1.9682384\ttotal: 3.85s\tremaining: 10.6s\n",
      "267:\tlearn: 1.9675204\ttotal: 3.87s\tremaining: 10.6s\n",
      "268:\tlearn: 1.9643540\ttotal: 3.88s\tremaining: 10.5s\n",
      "269:\tlearn: 1.9635624\ttotal: 3.89s\tremaining: 10.5s\n",
      "270:\tlearn: 1.9622888\ttotal: 3.91s\tremaining: 10.5s\n",
      "271:\tlearn: 1.9617288\ttotal: 3.92s\tremaining: 10.5s\n",
      "272:\tlearn: 1.9611001\ttotal: 3.95s\tremaining: 10.5s\n",
      "273:\tlearn: 1.9603078\ttotal: 3.97s\tremaining: 10.5s\n",
      "274:\tlearn: 1.9602878\ttotal: 3.98s\tremaining: 10.5s\n",
      "275:\tlearn: 1.9599354\ttotal: 4s\tremaining: 10.5s\n",
      "276:\tlearn: 1.9589888\ttotal: 4.01s\tremaining: 10.5s\n",
      "277:\tlearn: 1.9589629\ttotal: 4.03s\tremaining: 10.5s\n",
      "278:\tlearn: 1.9580985\ttotal: 4.04s\tremaining: 10.4s\n",
      "279:\tlearn: 1.9569077\ttotal: 4.05s\tremaining: 10.4s\n",
      "280:\tlearn: 1.9551143\ttotal: 4.07s\tremaining: 10.4s\n",
      "281:\tlearn: 1.9535945\ttotal: 4.08s\tremaining: 10.4s\n",
      "282:\tlearn: 1.9524685\ttotal: 4.1s\tremaining: 10.4s\n",
      "283:\tlearn: 1.9524673\ttotal: 4.11s\tremaining: 10.4s\n",
      "284:\tlearn: 1.9512799\ttotal: 4.13s\tremaining: 10.3s\n",
      "285:\tlearn: 1.9507086\ttotal: 4.14s\tremaining: 10.3s\n",
      "286:\tlearn: 1.9499504\ttotal: 4.15s\tremaining: 10.3s\n",
      "287:\tlearn: 1.9494783\ttotal: 4.17s\tremaining: 10.3s\n",
      "288:\tlearn: 1.9486336\ttotal: 4.18s\tremaining: 10.3s\n",
      "289:\tlearn: 1.9482280\ttotal: 4.19s\tremaining: 10.3s\n",
      "290:\tlearn: 1.9481587\ttotal: 4.21s\tremaining: 10.3s\n",
      "291:\tlearn: 1.9481414\ttotal: 4.22s\tremaining: 10.2s\n",
      "292:\tlearn: 1.9480544\ttotal: 4.24s\tremaining: 10.2s\n",
      "293:\tlearn: 1.9476624\ttotal: 4.25s\tremaining: 10.2s\n",
      "294:\tlearn: 1.9475833\ttotal: 4.26s\tremaining: 10.2s\n",
      "295:\tlearn: 1.9475757\ttotal: 4.28s\tremaining: 10.2s\n",
      "296:\tlearn: 1.9473430\ttotal: 4.29s\tremaining: 10.2s\n",
      "297:\tlearn: 1.9465989\ttotal: 4.3s\tremaining: 10.1s\n",
      "298:\tlearn: 1.9465693\ttotal: 4.32s\tremaining: 10.1s\n",
      "299:\tlearn: 1.9465626\ttotal: 4.33s\tremaining: 10.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300:\tlearn: 1.9461329\ttotal: 4.35s\tremaining: 10.1s\n",
      "301:\tlearn: 1.9460058\ttotal: 4.36s\tremaining: 10.1s\n",
      "302:\tlearn: 1.9455290\ttotal: 4.38s\tremaining: 10.1s\n",
      "303:\tlearn: 1.9454718\ttotal: 4.39s\tremaining: 10.1s\n",
      "304:\tlearn: 1.9453515\ttotal: 4.4s\tremaining: 10s\n",
      "305:\tlearn: 1.9449793\ttotal: 4.42s\tremaining: 10s\n",
      "306:\tlearn: 1.9445849\ttotal: 4.43s\tremaining: 10s\n",
      "307:\tlearn: 1.9437942\ttotal: 4.45s\tremaining: 9.99s\n",
      "308:\tlearn: 1.9436138\ttotal: 4.46s\tremaining: 9.97s\n",
      "309:\tlearn: 1.9425504\ttotal: 4.47s\tremaining: 9.96s\n",
      "310:\tlearn: 1.9419266\ttotal: 4.49s\tremaining: 9.94s\n",
      "311:\tlearn: 1.9413009\ttotal: 4.5s\tremaining: 9.92s\n",
      "312:\tlearn: 1.9409381\ttotal: 4.51s\tremaining: 9.91s\n",
      "313:\tlearn: 1.9399873\ttotal: 4.53s\tremaining: 9.89s\n",
      "314:\tlearn: 1.9389907\ttotal: 4.54s\tremaining: 9.88s\n",
      "315:\tlearn: 1.9379265\ttotal: 4.56s\tremaining: 9.86s\n",
      "316:\tlearn: 1.9365412\ttotal: 4.57s\tremaining: 9.85s\n",
      "317:\tlearn: 1.9359723\ttotal: 4.59s\tremaining: 9.84s\n",
      "318:\tlearn: 1.9358662\ttotal: 4.6s\tremaining: 9.82s\n",
      "319:\tlearn: 1.9348630\ttotal: 4.62s\tremaining: 9.81s\n",
      "320:\tlearn: 1.9348557\ttotal: 4.63s\tremaining: 9.79s\n",
      "321:\tlearn: 1.9348499\ttotal: 4.64s\tremaining: 9.78s\n",
      "322:\tlearn: 1.9345633\ttotal: 4.66s\tremaining: 9.76s\n",
      "323:\tlearn: 1.9345590\ttotal: 4.67s\tremaining: 9.74s\n",
      "324:\tlearn: 1.9343291\ttotal: 4.68s\tremaining: 9.73s\n",
      "325:\tlearn: 1.9339065\ttotal: 4.7s\tremaining: 9.71s\n",
      "326:\tlearn: 1.9334655\ttotal: 4.71s\tremaining: 9.69s\n",
      "327:\tlearn: 1.9334497\ttotal: 4.72s\tremaining: 9.68s\n",
      "328:\tlearn: 1.9333381\ttotal: 4.74s\tremaining: 9.66s\n",
      "329:\tlearn: 1.9327135\ttotal: 4.75s\tremaining: 9.64s\n",
      "330:\tlearn: 1.9314710\ttotal: 4.76s\tremaining: 9.63s\n",
      "331:\tlearn: 1.9305047\ttotal: 4.78s\tremaining: 9.62s\n",
      "332:\tlearn: 1.9297615\ttotal: 4.79s\tremaining: 9.6s\n",
      "333:\tlearn: 1.9296108\ttotal: 4.81s\tremaining: 9.59s\n",
      "334:\tlearn: 1.9290765\ttotal: 4.82s\tremaining: 9.57s\n",
      "335:\tlearn: 1.9289950\ttotal: 4.83s\tremaining: 9.55s\n",
      "336:\tlearn: 1.9286992\ttotal: 4.85s\tremaining: 9.54s\n",
      "337:\tlearn: 1.9284608\ttotal: 4.86s\tremaining: 9.52s\n",
      "338:\tlearn: 1.9283519\ttotal: 4.87s\tremaining: 9.51s\n",
      "339:\tlearn: 1.9282685\ttotal: 4.89s\tremaining: 9.49s\n",
      "340:\tlearn: 1.9281974\ttotal: 4.9s\tremaining: 9.47s\n",
      "341:\tlearn: 1.9280436\ttotal: 4.91s\tremaining: 9.46s\n",
      "342:\tlearn: 1.9279074\ttotal: 4.93s\tremaining: 9.44s\n",
      "343:\tlearn: 1.9271156\ttotal: 4.94s\tremaining: 9.43s\n",
      "344:\tlearn: 1.9270157\ttotal: 4.96s\tremaining: 9.41s\n",
      "345:\tlearn: 1.9269853\ttotal: 4.97s\tremaining: 9.39s\n",
      "346:\tlearn: 1.9269096\ttotal: 4.98s\tremaining: 9.38s\n",
      "347:\tlearn: 1.9269012\ttotal: 5s\tremaining: 9.37s\n",
      "348:\tlearn: 1.9264273\ttotal: 5.01s\tremaining: 9.35s\n",
      "349:\tlearn: 1.9263909\ttotal: 5.03s\tremaining: 9.33s\n",
      "350:\tlearn: 1.9263902\ttotal: 5.04s\tremaining: 9.32s\n",
      "351:\tlearn: 1.9263672\ttotal: 5.05s\tremaining: 9.3s\n",
      "352:\tlearn: 1.9257650\ttotal: 5.07s\tremaining: 9.29s\n",
      "353:\tlearn: 1.9256409\ttotal: 5.08s\tremaining: 9.27s\n",
      "354:\tlearn: 1.9255944\ttotal: 5.09s\tremaining: 9.26s\n",
      "355:\tlearn: 1.9255893\ttotal: 5.11s\tremaining: 9.24s\n",
      "356:\tlearn: 1.9252906\ttotal: 5.12s\tremaining: 9.22s\n",
      "357:\tlearn: 1.9250355\ttotal: 5.13s\tremaining: 9.21s\n",
      "358:\tlearn: 1.9245987\ttotal: 5.15s\tremaining: 9.19s\n",
      "359:\tlearn: 1.9245820\ttotal: 5.16s\tremaining: 9.18s\n",
      "360:\tlearn: 1.9245423\ttotal: 5.18s\tremaining: 9.16s\n",
      "361:\tlearn: 1.9245409\ttotal: 5.19s\tremaining: 9.14s\n",
      "362:\tlearn: 1.9243020\ttotal: 5.2s\tremaining: 9.13s\n",
      "363:\tlearn: 1.9238176\ttotal: 5.22s\tremaining: 9.12s\n",
      "364:\tlearn: 1.9231258\ttotal: 5.23s\tremaining: 9.11s\n",
      "365:\tlearn: 1.9230876\ttotal: 5.25s\tremaining: 9.09s\n",
      "366:\tlearn: 1.9215725\ttotal: 5.26s\tremaining: 9.08s\n",
      "367:\tlearn: 1.9205994\ttotal: 5.28s\tremaining: 9.06s\n",
      "368:\tlearn: 1.9205050\ttotal: 5.29s\tremaining: 9.05s\n",
      "369:\tlearn: 1.9205037\ttotal: 5.3s\tremaining: 9.03s\n",
      "370:\tlearn: 1.9201627\ttotal: 5.32s\tremaining: 9.02s\n",
      "371:\tlearn: 1.9199434\ttotal: 5.33s\tremaining: 9s\n",
      "372:\tlearn: 1.9199327\ttotal: 5.34s\tremaining: 8.98s\n",
      "373:\tlearn: 1.9198446\ttotal: 5.36s\tremaining: 8.97s\n",
      "374:\tlearn: 1.9190354\ttotal: 5.37s\tremaining: 8.95s\n",
      "375:\tlearn: 1.9189006\ttotal: 5.38s\tremaining: 8.94s\n",
      "376:\tlearn: 1.9184121\ttotal: 5.4s\tremaining: 8.92s\n",
      "377:\tlearn: 1.9176016\ttotal: 5.41s\tremaining: 8.91s\n",
      "378:\tlearn: 1.9173995\ttotal: 5.43s\tremaining: 8.89s\n",
      "379:\tlearn: 1.9171961\ttotal: 5.44s\tremaining: 8.88s\n",
      "380:\tlearn: 1.9171050\ttotal: 5.46s\tremaining: 8.86s\n",
      "381:\tlearn: 1.9168728\ttotal: 5.47s\tremaining: 8.85s\n",
      "382:\tlearn: 1.9168609\ttotal: 5.48s\tremaining: 8.83s\n",
      "383:\tlearn: 1.9167140\ttotal: 5.5s\tremaining: 8.82s\n",
      "384:\tlearn: 1.9162290\ttotal: 5.51s\tremaining: 8.8s\n",
      "385:\tlearn: 1.9161948\ttotal: 5.52s\tremaining: 8.79s\n",
      "386:\tlearn: 1.9161859\ttotal: 5.54s\tremaining: 8.77s\n",
      "387:\tlearn: 1.9161846\ttotal: 5.55s\tremaining: 8.75s\n",
      "388:\tlearn: 1.9161773\ttotal: 5.56s\tremaining: 8.74s\n",
      "389:\tlearn: 1.9161773\ttotal: 5.58s\tremaining: 8.72s\n",
      "390:\tlearn: 1.9161670\ttotal: 5.59s\tremaining: 8.71s\n",
      "391:\tlearn: 1.9157132\ttotal: 5.6s\tremaining: 8.69s\n",
      "392:\tlearn: 1.9156970\ttotal: 5.62s\tremaining: 8.68s\n",
      "393:\tlearn: 1.9156795\ttotal: 5.63s\tremaining: 8.66s\n",
      "394:\tlearn: 1.9156647\ttotal: 5.65s\tremaining: 8.65s\n",
      "395:\tlearn: 1.9156592\ttotal: 5.66s\tremaining: 8.64s\n",
      "396:\tlearn: 1.9155832\ttotal: 5.68s\tremaining: 8.62s\n",
      "397:\tlearn: 1.9154718\ttotal: 5.69s\tremaining: 8.61s\n",
      "398:\tlearn: 1.9150673\ttotal: 5.7s\tremaining: 8.59s\n",
      "399:\tlearn: 1.9149770\ttotal: 5.72s\tremaining: 8.58s\n",
      "400:\tlearn: 1.9149125\ttotal: 5.73s\tremaining: 8.56s\n",
      "401:\tlearn: 1.9146224\ttotal: 5.75s\tremaining: 8.55s\n",
      "402:\tlearn: 1.9133524\ttotal: 5.76s\tremaining: 8.53s\n",
      "403:\tlearn: 1.9129819\ttotal: 5.77s\tremaining: 8.52s\n",
      "404:\tlearn: 1.9129659\ttotal: 5.79s\tremaining: 8.5s\n",
      "405:\tlearn: 1.9129659\ttotal: 5.8s\tremaining: 8.48s\n",
      "406:\tlearn: 1.9129135\ttotal: 5.81s\tremaining: 8.47s\n",
      "407:\tlearn: 1.9129132\ttotal: 5.83s\tremaining: 8.46s\n",
      "408:\tlearn: 1.9128990\ttotal: 5.84s\tremaining: 8.44s\n",
      "409:\tlearn: 1.9128710\ttotal: 5.85s\tremaining: 8.43s\n",
      "410:\tlearn: 1.9121354\ttotal: 5.87s\tremaining: 8.41s\n",
      "411:\tlearn: 1.9119883\ttotal: 5.88s\tremaining: 8.4s\n",
      "412:\tlearn: 1.9118372\ttotal: 5.9s\tremaining: 8.38s\n",
      "413:\tlearn: 1.9118186\ttotal: 5.91s\tremaining: 8.37s\n",
      "414:\tlearn: 1.9115793\ttotal: 5.92s\tremaining: 8.35s\n",
      "415:\tlearn: 1.9114700\ttotal: 5.94s\tremaining: 8.34s\n",
      "416:\tlearn: 1.9113746\ttotal: 5.95s\tremaining: 8.32s\n",
      "417:\tlearn: 1.9113721\ttotal: 5.97s\tremaining: 8.31s\n",
      "418:\tlearn: 1.9113432\ttotal: 5.98s\tremaining: 8.29s\n",
      "419:\tlearn: 1.9111563\ttotal: 5.99s\tremaining: 8.28s\n",
      "420:\tlearn: 1.9110514\ttotal: 6.01s\tremaining: 8.26s\n",
      "421:\tlearn: 1.9109932\ttotal: 6.02s\tremaining: 8.24s\n",
      "422:\tlearn: 1.9106969\ttotal: 6.03s\tremaining: 8.23s\n",
      "423:\tlearn: 1.9106814\ttotal: 6.05s\tremaining: 8.21s\n",
      "424:\tlearn: 1.9106759\ttotal: 6.06s\tremaining: 8.2s\n",
      "425:\tlearn: 1.9101903\ttotal: 6.08s\tremaining: 8.19s\n",
      "426:\tlearn: 1.9101740\ttotal: 6.09s\tremaining: 8.17s\n",
      "427:\tlearn: 1.9101282\ttotal: 6.1s\tremaining: 8.16s\n",
      "428:\tlearn: 1.9100712\ttotal: 6.12s\tremaining: 8.14s\n",
      "429:\tlearn: 1.9099115\ttotal: 6.13s\tremaining: 8.13s\n",
      "430:\tlearn: 1.9098080\ttotal: 6.14s\tremaining: 8.11s\n",
      "431:\tlearn: 1.9094325\ttotal: 6.16s\tremaining: 8.1s\n",
      "432:\tlearn: 1.9091301\ttotal: 6.17s\tremaining: 8.08s\n",
      "433:\tlearn: 1.9090612\ttotal: 6.18s\tremaining: 8.06s\n",
      "434:\tlearn: 1.9089773\ttotal: 6.2s\tremaining: 8.05s\n",
      "435:\tlearn: 1.9089767\ttotal: 6.21s\tremaining: 8.04s\n",
      "436:\tlearn: 1.9089761\ttotal: 6.23s\tremaining: 8.02s\n",
      "437:\tlearn: 1.9089760\ttotal: 6.24s\tremaining: 8.01s\n",
      "438:\tlearn: 1.9089750\ttotal: 6.25s\tremaining: 7.99s\n",
      "439:\tlearn: 1.9089723\ttotal: 6.27s\tremaining: 7.98s\n",
      "440:\tlearn: 1.9089723\ttotal: 6.29s\tremaining: 7.97s\n",
      "441:\tlearn: 1.9089709\ttotal: 6.3s\tremaining: 7.96s\n",
      "442:\tlearn: 1.9085769\ttotal: 6.32s\tremaining: 7.94s\n",
      "443:\tlearn: 1.9085544\ttotal: 6.33s\tremaining: 7.93s\n",
      "444:\tlearn: 1.9079911\ttotal: 6.35s\tremaining: 7.92s\n",
      "445:\tlearn: 1.9077557\ttotal: 6.36s\tremaining: 7.9s\n",
      "446:\tlearn: 1.9068124\ttotal: 6.37s\tremaining: 7.88s\n",
      "447:\tlearn: 1.9066852\ttotal: 6.39s\tremaining: 7.87s\n",
      "448:\tlearn: 1.9066834\ttotal: 6.4s\tremaining: 7.86s\n",
      "449:\tlearn: 1.9066786\ttotal: 6.42s\tremaining: 7.84s\n",
      "450:\tlearn: 1.9066774\ttotal: 6.43s\tremaining: 7.83s\n",
      "451:\tlearn: 1.9066772\ttotal: 6.44s\tremaining: 7.81s\n",
      "452:\tlearn: 1.9065988\ttotal: 6.46s\tremaining: 7.79s\n",
      "453:\tlearn: 1.9063475\ttotal: 6.47s\tremaining: 7.78s\n",
      "454:\tlearn: 1.9063003\ttotal: 6.48s\tremaining: 7.76s\n",
      "455:\tlearn: 1.9062581\ttotal: 6.5s\tremaining: 7.75s\n",
      "456:\tlearn: 1.9062581\ttotal: 6.51s\tremaining: 7.74s\n",
      "457:\tlearn: 1.9062576\ttotal: 6.53s\tremaining: 7.72s\n",
      "458:\tlearn: 1.9062576\ttotal: 6.54s\tremaining: 7.71s\n",
      "459:\tlearn: 1.9062510\ttotal: 6.55s\tremaining: 7.69s\n",
      "460:\tlearn: 1.9062328\ttotal: 6.57s\tremaining: 7.68s\n",
      "461:\tlearn: 1.9062095\ttotal: 6.58s\tremaining: 7.67s\n",
      "462:\tlearn: 1.9061865\ttotal: 6.6s\tremaining: 7.65s\n",
      "463:\tlearn: 1.9060861\ttotal: 6.61s\tremaining: 7.64s\n",
      "464:\tlearn: 1.9051283\ttotal: 6.62s\tremaining: 7.62s\n",
      "465:\tlearn: 1.9051102\ttotal: 6.64s\tremaining: 7.61s\n",
      "466:\tlearn: 1.9050893\ttotal: 6.65s\tremaining: 7.59s\n",
      "467:\tlearn: 1.9038972\ttotal: 6.67s\tremaining: 7.58s\n",
      "468:\tlearn: 1.9032286\ttotal: 6.68s\tremaining: 7.56s\n",
      "469:\tlearn: 1.9030867\ttotal: 6.7s\tremaining: 7.55s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470:\tlearn: 1.9019736\ttotal: 6.71s\tremaining: 7.54s\n",
      "471:\tlearn: 1.8999793\ttotal: 6.73s\tremaining: 7.53s\n",
      "472:\tlearn: 1.8999765\ttotal: 6.74s\tremaining: 7.51s\n",
      "473:\tlearn: 1.8999228\ttotal: 6.75s\tremaining: 7.5s\n",
      "474:\tlearn: 1.8998732\ttotal: 6.77s\tremaining: 7.48s\n",
      "475:\tlearn: 1.8998582\ttotal: 6.78s\tremaining: 7.47s\n",
      "476:\tlearn: 1.8998482\ttotal: 6.8s\tremaining: 7.45s\n",
      "477:\tlearn: 1.8998290\ttotal: 6.81s\tremaining: 7.44s\n",
      "478:\tlearn: 1.8998257\ttotal: 6.82s\tremaining: 7.42s\n",
      "479:\tlearn: 1.8997800\ttotal: 6.83s\tremaining: 7.41s\n",
      "480:\tlearn: 1.8991513\ttotal: 6.85s\tremaining: 7.39s\n",
      "481:\tlearn: 1.8991512\ttotal: 6.86s\tremaining: 7.38s\n",
      "482:\tlearn: 1.8991511\ttotal: 6.88s\tremaining: 7.36s\n",
      "483:\tlearn: 1.8988516\ttotal: 6.89s\tremaining: 7.35s\n",
      "484:\tlearn: 1.8988391\ttotal: 6.91s\tremaining: 7.33s\n",
      "485:\tlearn: 1.8978462\ttotal: 6.92s\tremaining: 7.32s\n",
      "486:\tlearn: 1.8978389\ttotal: 6.93s\tremaining: 7.3s\n",
      "487:\tlearn: 1.8978389\ttotal: 6.95s\tremaining: 7.29s\n",
      "488:\tlearn: 1.8978375\ttotal: 6.96s\tremaining: 7.28s\n",
      "489:\tlearn: 1.8973389\ttotal: 6.97s\tremaining: 7.26s\n",
      "490:\tlearn: 1.8970288\ttotal: 6.99s\tremaining: 7.25s\n",
      "491:\tlearn: 1.8967139\ttotal: 7s\tremaining: 7.23s\n",
      "492:\tlearn: 1.8962071\ttotal: 7.02s\tremaining: 7.22s\n",
      "493:\tlearn: 1.8953804\ttotal: 7.03s\tremaining: 7.2s\n",
      "494:\tlearn: 1.8925487\ttotal: 7.04s\tremaining: 7.19s\n",
      "495:\tlearn: 1.8925481\ttotal: 7.06s\tremaining: 7.17s\n",
      "496:\tlearn: 1.8925372\ttotal: 7.07s\tremaining: 7.16s\n",
      "497:\tlearn: 1.8925371\ttotal: 7.09s\tremaining: 7.14s\n",
      "498:\tlearn: 1.8925357\ttotal: 7.1s\tremaining: 7.13s\n",
      "499:\tlearn: 1.8924659\ttotal: 7.12s\tremaining: 7.12s\n",
      "500:\tlearn: 1.8923346\ttotal: 7.13s\tremaining: 7.1s\n",
      "501:\tlearn: 1.8923068\ttotal: 7.14s\tremaining: 7.09s\n",
      "502:\tlearn: 1.8922894\ttotal: 7.16s\tremaining: 7.07s\n",
      "503:\tlearn: 1.8918241\ttotal: 7.17s\tremaining: 7.06s\n",
      "504:\tlearn: 1.8916228\ttotal: 7.18s\tremaining: 7.04s\n",
      "505:\tlearn: 1.8914981\ttotal: 7.2s\tremaining: 7.03s\n",
      "506:\tlearn: 1.8914475\ttotal: 7.21s\tremaining: 7.01s\n",
      "507:\tlearn: 1.8913199\ttotal: 7.22s\tremaining: 7s\n",
      "508:\tlearn: 1.8912470\ttotal: 7.24s\tremaining: 6.98s\n",
      "509:\tlearn: 1.8911950\ttotal: 7.25s\tremaining: 6.97s\n",
      "510:\tlearn: 1.8911929\ttotal: 7.26s\tremaining: 6.95s\n",
      "511:\tlearn: 1.8910067\ttotal: 7.28s\tremaining: 6.94s\n",
      "512:\tlearn: 1.8899011\ttotal: 7.29s\tremaining: 6.92s\n",
      "513:\tlearn: 1.8870016\ttotal: 7.31s\tremaining: 6.91s\n",
      "514:\tlearn: 1.8869918\ttotal: 7.32s\tremaining: 6.89s\n",
      "515:\tlearn: 1.8869760\ttotal: 7.33s\tremaining: 6.88s\n",
      "516:\tlearn: 1.8869659\ttotal: 7.35s\tremaining: 6.87s\n",
      "517:\tlearn: 1.8869659\ttotal: 7.37s\tremaining: 6.85s\n",
      "518:\tlearn: 1.8869655\ttotal: 7.38s\tremaining: 6.84s\n",
      "519:\tlearn: 1.8869655\ttotal: 7.39s\tremaining: 6.82s\n",
      "520:\tlearn: 1.8868593\ttotal: 7.41s\tremaining: 6.81s\n",
      "521:\tlearn: 1.8863958\ttotal: 7.42s\tremaining: 6.79s\n",
      "522:\tlearn: 1.8863953\ttotal: 7.43s\tremaining: 6.78s\n",
      "523:\tlearn: 1.8863952\ttotal: 7.45s\tremaining: 6.77s\n",
      "524:\tlearn: 1.8863952\ttotal: 7.46s\tremaining: 6.75s\n",
      "525:\tlearn: 1.8862172\ttotal: 7.47s\tremaining: 6.74s\n",
      "526:\tlearn: 1.8856415\ttotal: 7.49s\tremaining: 6.72s\n",
      "527:\tlearn: 1.8854974\ttotal: 7.5s\tremaining: 6.71s\n",
      "528:\tlearn: 1.8846074\ttotal: 7.52s\tremaining: 6.69s\n",
      "529:\tlearn: 1.8840503\ttotal: 7.53s\tremaining: 6.68s\n",
      "530:\tlearn: 1.8837416\ttotal: 7.54s\tremaining: 6.66s\n",
      "531:\tlearn: 1.8836963\ttotal: 7.56s\tremaining: 6.65s\n",
      "532:\tlearn: 1.8836595\ttotal: 7.57s\tremaining: 6.63s\n",
      "533:\tlearn: 1.8836590\ttotal: 7.59s\tremaining: 6.62s\n",
      "534:\tlearn: 1.8836590\ttotal: 7.6s\tremaining: 6.61s\n",
      "535:\tlearn: 1.8836582\ttotal: 7.62s\tremaining: 6.6s\n",
      "536:\tlearn: 1.8836256\ttotal: 7.64s\tremaining: 6.58s\n",
      "537:\tlearn: 1.8826043\ttotal: 7.65s\tremaining: 6.57s\n",
      "538:\tlearn: 1.8820296\ttotal: 7.67s\tremaining: 6.56s\n",
      "539:\tlearn: 1.8819848\ttotal: 7.68s\tremaining: 6.55s\n",
      "540:\tlearn: 1.8818976\ttotal: 7.7s\tremaining: 6.53s\n",
      "541:\tlearn: 1.8818828\ttotal: 7.71s\tremaining: 6.52s\n",
      "542:\tlearn: 1.8817114\ttotal: 7.73s\tremaining: 6.5s\n",
      "543:\tlearn: 1.8803305\ttotal: 7.74s\tremaining: 6.49s\n",
      "544:\tlearn: 1.8799327\ttotal: 7.76s\tremaining: 6.48s\n",
      "545:\tlearn: 1.8798991\ttotal: 7.77s\tremaining: 6.46s\n",
      "546:\tlearn: 1.8798779\ttotal: 7.79s\tremaining: 6.45s\n",
      "547:\tlearn: 1.8798764\ttotal: 7.8s\tremaining: 6.44s\n",
      "548:\tlearn: 1.8795428\ttotal: 7.82s\tremaining: 6.42s\n",
      "549:\tlearn: 1.8788951\ttotal: 7.83s\tremaining: 6.41s\n",
      "550:\tlearn: 1.8785303\ttotal: 7.84s\tremaining: 6.39s\n",
      "551:\tlearn: 1.8784674\ttotal: 7.86s\tremaining: 6.38s\n",
      "552:\tlearn: 1.8782086\ttotal: 7.88s\tremaining: 6.37s\n",
      "553:\tlearn: 1.8781871\ttotal: 7.89s\tremaining: 6.35s\n",
      "554:\tlearn: 1.8780964\ttotal: 7.91s\tremaining: 6.34s\n",
      "555:\tlearn: 1.8780339\ttotal: 7.92s\tremaining: 6.33s\n",
      "556:\tlearn: 1.8776233\ttotal: 7.94s\tremaining: 6.31s\n",
      "557:\tlearn: 1.8772683\ttotal: 7.96s\tremaining: 6.3s\n",
      "558:\tlearn: 1.8766927\ttotal: 7.97s\tremaining: 6.29s\n",
      "559:\tlearn: 1.8766697\ttotal: 7.99s\tremaining: 6.28s\n",
      "560:\tlearn: 1.8766696\ttotal: 8s\tremaining: 6.26s\n",
      "561:\tlearn: 1.8766674\ttotal: 8.02s\tremaining: 6.25s\n",
      "562:\tlearn: 1.8766653\ttotal: 8.03s\tremaining: 6.23s\n",
      "563:\tlearn: 1.8766653\ttotal: 8.04s\tremaining: 6.22s\n",
      "564:\tlearn: 1.8766652\ttotal: 8.06s\tremaining: 6.2s\n",
      "565:\tlearn: 1.8766648\ttotal: 8.07s\tremaining: 6.19s\n",
      "566:\tlearn: 1.8765331\ttotal: 8.09s\tremaining: 6.17s\n",
      "567:\tlearn: 1.8765330\ttotal: 8.1s\tremaining: 6.16s\n",
      "568:\tlearn: 1.8765329\ttotal: 8.11s\tremaining: 6.14s\n",
      "569:\tlearn: 1.8765327\ttotal: 8.13s\tremaining: 6.13s\n",
      "570:\tlearn: 1.8765317\ttotal: 8.14s\tremaining: 6.11s\n",
      "571:\tlearn: 1.8765311\ttotal: 8.15s\tremaining: 6.1s\n",
      "572:\tlearn: 1.8765026\ttotal: 8.16s\tremaining: 6.08s\n",
      "573:\tlearn: 1.8751719\ttotal: 8.18s\tremaining: 6.07s\n",
      "574:\tlearn: 1.8744366\ttotal: 8.19s\tremaining: 6.05s\n",
      "575:\tlearn: 1.8742047\ttotal: 8.21s\tremaining: 6.04s\n",
      "576:\tlearn: 1.8742003\ttotal: 8.22s\tremaining: 6.03s\n",
      "577:\tlearn: 1.8741800\ttotal: 8.23s\tremaining: 6.01s\n",
      "578:\tlearn: 1.8741793\ttotal: 8.25s\tremaining: 6s\n",
      "579:\tlearn: 1.8741792\ttotal: 8.26s\tremaining: 5.98s\n",
      "580:\tlearn: 1.8741710\ttotal: 8.27s\tremaining: 5.97s\n",
      "581:\tlearn: 1.8741707\ttotal: 8.29s\tremaining: 5.95s\n",
      "582:\tlearn: 1.8741706\ttotal: 8.3s\tremaining: 5.94s\n",
      "583:\tlearn: 1.8741706\ttotal: 8.31s\tremaining: 5.92s\n",
      "584:\tlearn: 1.8741208\ttotal: 8.32s\tremaining: 5.91s\n",
      "585:\tlearn: 1.8741203\ttotal: 8.34s\tremaining: 5.89s\n",
      "586:\tlearn: 1.8741203\ttotal: 8.35s\tremaining: 5.88s\n",
      "587:\tlearn: 1.8741200\ttotal: 8.36s\tremaining: 5.86s\n",
      "588:\tlearn: 1.8741199\ttotal: 8.38s\tremaining: 5.85s\n",
      "589:\tlearn: 1.8741193\ttotal: 8.39s\tremaining: 5.83s\n",
      "590:\tlearn: 1.8741035\ttotal: 8.4s\tremaining: 5.82s\n",
      "591:\tlearn: 1.8741031\ttotal: 8.42s\tremaining: 5.8s\n",
      "592:\tlearn: 1.8741030\ttotal: 8.43s\tremaining: 5.79s\n",
      "593:\tlearn: 1.8741026\ttotal: 8.45s\tremaining: 5.77s\n",
      "594:\tlearn: 1.8741026\ttotal: 8.46s\tremaining: 5.76s\n",
      "595:\tlearn: 1.8741026\ttotal: 8.47s\tremaining: 5.74s\n",
      "596:\tlearn: 1.8741026\ttotal: 8.49s\tremaining: 5.73s\n",
      "597:\tlearn: 1.8741026\ttotal: 8.5s\tremaining: 5.71s\n",
      "598:\tlearn: 1.8740862\ttotal: 8.51s\tremaining: 5.7s\n",
      "599:\tlearn: 1.8740842\ttotal: 8.53s\tremaining: 5.68s\n",
      "600:\tlearn: 1.8740841\ttotal: 8.54s\tremaining: 5.67s\n",
      "601:\tlearn: 1.8740841\ttotal: 8.55s\tremaining: 5.65s\n",
      "602:\tlearn: 1.8740839\ttotal: 8.57s\tremaining: 5.64s\n",
      "603:\tlearn: 1.8740839\ttotal: 8.58s\tremaining: 5.63s\n",
      "604:\tlearn: 1.8740801\ttotal: 8.59s\tremaining: 5.61s\n",
      "605:\tlearn: 1.8740779\ttotal: 8.61s\tremaining: 5.59s\n",
      "606:\tlearn: 1.8738345\ttotal: 8.62s\tremaining: 5.58s\n",
      "607:\tlearn: 1.8735478\ttotal: 8.63s\tremaining: 5.57s\n",
      "608:\tlearn: 1.8727283\ttotal: 8.65s\tremaining: 5.55s\n",
      "609:\tlearn: 1.8714412\ttotal: 8.66s\tremaining: 5.54s\n",
      "610:\tlearn: 1.8712268\ttotal: 8.68s\tremaining: 5.53s\n",
      "611:\tlearn: 1.8712153\ttotal: 8.7s\tremaining: 5.51s\n",
      "612:\tlearn: 1.8711810\ttotal: 8.71s\tremaining: 5.5s\n",
      "613:\tlearn: 1.8709585\ttotal: 8.73s\tremaining: 5.49s\n",
      "614:\tlearn: 1.8709562\ttotal: 8.74s\tremaining: 5.47s\n",
      "615:\tlearn: 1.8706911\ttotal: 8.76s\tremaining: 5.46s\n",
      "616:\tlearn: 1.8706814\ttotal: 8.77s\tremaining: 5.45s\n",
      "617:\tlearn: 1.8706802\ttotal: 8.79s\tremaining: 5.43s\n",
      "618:\tlearn: 1.8706801\ttotal: 8.8s\tremaining: 5.42s\n",
      "619:\tlearn: 1.8706799\ttotal: 8.82s\tremaining: 5.4s\n",
      "620:\tlearn: 1.8704262\ttotal: 8.83s\tremaining: 5.39s\n",
      "621:\tlearn: 1.8698088\ttotal: 8.85s\tremaining: 5.38s\n",
      "622:\tlearn: 1.8693715\ttotal: 8.86s\tremaining: 5.36s\n",
      "623:\tlearn: 1.8692006\ttotal: 8.88s\tremaining: 5.35s\n",
      "624:\tlearn: 1.8691893\ttotal: 8.89s\tremaining: 5.33s\n",
      "625:\tlearn: 1.8691890\ttotal: 8.9s\tremaining: 5.32s\n",
      "626:\tlearn: 1.8691887\ttotal: 8.92s\tremaining: 5.3s\n",
      "627:\tlearn: 1.8691750\ttotal: 8.93s\tremaining: 5.29s\n",
      "628:\tlearn: 1.8690699\ttotal: 8.94s\tremaining: 5.28s\n",
      "629:\tlearn: 1.8690399\ttotal: 8.96s\tremaining: 5.26s\n",
      "630:\tlearn: 1.8682649\ttotal: 8.97s\tremaining: 5.25s\n",
      "631:\tlearn: 1.8673170\ttotal: 8.98s\tremaining: 5.23s\n",
      "632:\tlearn: 1.8664143\ttotal: 9s\tremaining: 5.22s\n",
      "633:\tlearn: 1.8663964\ttotal: 9.01s\tremaining: 5.2s\n",
      "634:\tlearn: 1.8662998\ttotal: 9.02s\tremaining: 5.19s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635:\tlearn: 1.8659769\ttotal: 9.04s\tremaining: 5.17s\n",
      "636:\tlearn: 1.8655067\ttotal: 9.05s\tremaining: 5.16s\n",
      "637:\tlearn: 1.8654249\ttotal: 9.07s\tremaining: 5.14s\n",
      "638:\tlearn: 1.8641644\ttotal: 9.08s\tremaining: 5.13s\n",
      "639:\tlearn: 1.8638726\ttotal: 9.09s\tremaining: 5.12s\n",
      "640:\tlearn: 1.8634715\ttotal: 9.11s\tremaining: 5.1s\n",
      "641:\tlearn: 1.8634380\ttotal: 9.12s\tremaining: 5.08s\n",
      "642:\tlearn: 1.8632406\ttotal: 9.13s\tremaining: 5.07s\n",
      "643:\tlearn: 1.8629372\ttotal: 9.15s\tremaining: 5.06s\n",
      "644:\tlearn: 1.8627999\ttotal: 9.16s\tremaining: 5.04s\n",
      "645:\tlearn: 1.8627666\ttotal: 9.17s\tremaining: 5.03s\n",
      "646:\tlearn: 1.8624653\ttotal: 9.19s\tremaining: 5.01s\n",
      "647:\tlearn: 1.8622668\ttotal: 9.2s\tremaining: 5s\n",
      "648:\tlearn: 1.8622238\ttotal: 9.21s\tremaining: 4.98s\n",
      "649:\tlearn: 1.8622237\ttotal: 9.23s\tremaining: 4.97s\n",
      "650:\tlearn: 1.8621834\ttotal: 9.24s\tremaining: 4.95s\n",
      "651:\tlearn: 1.8620997\ttotal: 9.26s\tremaining: 4.94s\n",
      "652:\tlearn: 1.8620988\ttotal: 9.27s\tremaining: 4.92s\n",
      "653:\tlearn: 1.8620982\ttotal: 9.28s\tremaining: 4.91s\n",
      "654:\tlearn: 1.8620968\ttotal: 9.3s\tremaining: 4.9s\n",
      "655:\tlearn: 1.8620953\ttotal: 9.31s\tremaining: 4.88s\n",
      "656:\tlearn: 1.8618931\ttotal: 9.32s\tremaining: 4.87s\n",
      "657:\tlearn: 1.8616732\ttotal: 9.34s\tremaining: 4.85s\n",
      "658:\tlearn: 1.8607386\ttotal: 9.35s\tremaining: 4.84s\n",
      "659:\tlearn: 1.8607236\ttotal: 9.36s\tremaining: 4.82s\n",
      "660:\tlearn: 1.8597917\ttotal: 9.38s\tremaining: 4.81s\n",
      "661:\tlearn: 1.8597665\ttotal: 9.39s\tremaining: 4.79s\n",
      "662:\tlearn: 1.8592674\ttotal: 9.4s\tremaining: 4.78s\n",
      "663:\tlearn: 1.8584243\ttotal: 9.42s\tremaining: 4.76s\n",
      "664:\tlearn: 1.8580960\ttotal: 9.43s\tremaining: 4.75s\n",
      "665:\tlearn: 1.8574525\ttotal: 9.45s\tremaining: 4.74s\n",
      "666:\tlearn: 1.8574448\ttotal: 9.46s\tremaining: 4.72s\n",
      "667:\tlearn: 1.8574376\ttotal: 9.47s\tremaining: 4.71s\n",
      "668:\tlearn: 1.8571044\ttotal: 9.49s\tremaining: 4.69s\n",
      "669:\tlearn: 1.8569902\ttotal: 9.5s\tremaining: 4.68s\n",
      "670:\tlearn: 1.8565816\ttotal: 9.51s\tremaining: 4.67s\n",
      "671:\tlearn: 1.8565403\ttotal: 9.53s\tremaining: 4.65s\n",
      "672:\tlearn: 1.8560413\ttotal: 9.54s\tremaining: 4.64s\n",
      "673:\tlearn: 1.8556478\ttotal: 9.55s\tremaining: 4.62s\n",
      "674:\tlearn: 1.8555047\ttotal: 9.57s\tremaining: 4.61s\n",
      "675:\tlearn: 1.8553252\ttotal: 9.58s\tremaining: 4.59s\n",
      "676:\tlearn: 1.8551735\ttotal: 9.6s\tremaining: 4.58s\n",
      "677:\tlearn: 1.8550571\ttotal: 9.61s\tremaining: 4.56s\n",
      "678:\tlearn: 1.8549238\ttotal: 9.62s\tremaining: 4.55s\n",
      "679:\tlearn: 1.8546497\ttotal: 9.64s\tremaining: 4.54s\n",
      "680:\tlearn: 1.8546464\ttotal: 9.65s\tremaining: 4.52s\n",
      "681:\tlearn: 1.8544611\ttotal: 9.66s\tremaining: 4.51s\n",
      "682:\tlearn: 1.8544500\ttotal: 9.68s\tremaining: 4.49s\n",
      "683:\tlearn: 1.8544456\ttotal: 9.69s\tremaining: 4.48s\n",
      "684:\tlearn: 1.8542170\ttotal: 9.71s\tremaining: 4.46s\n",
      "685:\tlearn: 1.8541568\ttotal: 9.72s\tremaining: 4.45s\n",
      "686:\tlearn: 1.8538890\ttotal: 9.73s\tremaining: 4.43s\n",
      "687:\tlearn: 1.8538732\ttotal: 9.75s\tremaining: 4.42s\n",
      "688:\tlearn: 1.8534611\ttotal: 9.76s\tremaining: 4.41s\n",
      "689:\tlearn: 1.8533397\ttotal: 9.78s\tremaining: 4.39s\n",
      "690:\tlearn: 1.8531407\ttotal: 9.79s\tremaining: 4.38s\n",
      "691:\tlearn: 1.8530325\ttotal: 9.8s\tremaining: 4.36s\n",
      "692:\tlearn: 1.8530303\ttotal: 9.82s\tremaining: 4.35s\n",
      "693:\tlearn: 1.8528430\ttotal: 9.83s\tremaining: 4.33s\n",
      "694:\tlearn: 1.8521577\ttotal: 9.85s\tremaining: 4.32s\n",
      "695:\tlearn: 1.8517109\ttotal: 9.86s\tremaining: 4.31s\n",
      "696:\tlearn: 1.8517059\ttotal: 9.87s\tremaining: 4.29s\n",
      "697:\tlearn: 1.8516215\ttotal: 9.88s\tremaining: 4.28s\n",
      "698:\tlearn: 1.8515757\ttotal: 9.9s\tremaining: 4.26s\n",
      "699:\tlearn: 1.8514600\ttotal: 9.91s\tremaining: 4.25s\n",
      "700:\tlearn: 1.8514355\ttotal: 9.93s\tremaining: 4.24s\n",
      "701:\tlearn: 1.8512994\ttotal: 9.94s\tremaining: 4.22s\n",
      "702:\tlearn: 1.8511259\ttotal: 9.96s\tremaining: 4.21s\n",
      "703:\tlearn: 1.8510400\ttotal: 9.97s\tremaining: 4.19s\n",
      "704:\tlearn: 1.8509629\ttotal: 9.98s\tremaining: 4.18s\n",
      "705:\tlearn: 1.8509498\ttotal: 10s\tremaining: 4.16s\n",
      "706:\tlearn: 1.8509472\ttotal: 10s\tremaining: 4.15s\n",
      "707:\tlearn: 1.8509161\ttotal: 10s\tremaining: 4.13s\n",
      "708:\tlearn: 1.8509154\ttotal: 10s\tremaining: 4.12s\n",
      "709:\tlearn: 1.8506823\ttotal: 10.1s\tremaining: 4.11s\n",
      "710:\tlearn: 1.8503763\ttotal: 10.1s\tremaining: 4.09s\n",
      "711:\tlearn: 1.8500323\ttotal: 10.1s\tremaining: 4.08s\n",
      "712:\tlearn: 1.8497613\ttotal: 10.1s\tremaining: 4.06s\n",
      "713:\tlearn: 1.8496568\ttotal: 10.1s\tremaining: 4.05s\n",
      "714:\tlearn: 1.8492960\ttotal: 10.1s\tremaining: 4.04s\n",
      "715:\tlearn: 1.8492279\ttotal: 10.1s\tremaining: 4.02s\n",
      "716:\tlearn: 1.8490210\ttotal: 10.2s\tremaining: 4.01s\n",
      "717:\tlearn: 1.8485916\ttotal: 10.2s\tremaining: 3.99s\n",
      "718:\tlearn: 1.8482282\ttotal: 10.2s\tremaining: 3.98s\n",
      "719:\tlearn: 1.8471356\ttotal: 10.2s\tremaining: 3.96s\n",
      "720:\tlearn: 1.8470803\ttotal: 10.2s\tremaining: 3.95s\n",
      "721:\tlearn: 1.8470340\ttotal: 10.2s\tremaining: 3.94s\n",
      "722:\tlearn: 1.8465800\ttotal: 10.2s\tremaining: 3.92s\n",
      "723:\tlearn: 1.8463787\ttotal: 10.2s\tremaining: 3.91s\n",
      "724:\tlearn: 1.8463535\ttotal: 10.3s\tremaining: 3.89s\n",
      "725:\tlearn: 1.8463534\ttotal: 10.3s\tremaining: 3.88s\n",
      "726:\tlearn: 1.8463533\ttotal: 10.3s\tremaining: 3.86s\n",
      "727:\tlearn: 1.8462767\ttotal: 10.3s\tremaining: 3.85s\n",
      "728:\tlearn: 1.8462719\ttotal: 10.3s\tremaining: 3.83s\n",
      "729:\tlearn: 1.8460561\ttotal: 10.3s\tremaining: 3.82s\n",
      "730:\tlearn: 1.8457448\ttotal: 10.3s\tremaining: 3.81s\n",
      "731:\tlearn: 1.8457447\ttotal: 10.4s\tremaining: 3.79s\n",
      "732:\tlearn: 1.8452000\ttotal: 10.4s\tremaining: 3.78s\n",
      "733:\tlearn: 1.8447442\ttotal: 10.4s\tremaining: 3.76s\n",
      "734:\tlearn: 1.8447439\ttotal: 10.4s\tremaining: 3.75s\n",
      "735:\tlearn: 1.8447211\ttotal: 10.4s\tremaining: 3.73s\n",
      "736:\tlearn: 1.8447207\ttotal: 10.4s\tremaining: 3.72s\n",
      "737:\tlearn: 1.8447002\ttotal: 10.4s\tremaining: 3.71s\n",
      "738:\tlearn: 1.8446864\ttotal: 10.4s\tremaining: 3.69s\n",
      "739:\tlearn: 1.8446708\ttotal: 10.5s\tremaining: 3.68s\n",
      "740:\tlearn: 1.8441057\ttotal: 10.5s\tremaining: 3.66s\n",
      "741:\tlearn: 1.8432268\ttotal: 10.5s\tremaining: 3.65s\n",
      "742:\tlearn: 1.8425103\ttotal: 10.5s\tremaining: 3.63s\n",
      "743:\tlearn: 1.8423845\ttotal: 10.5s\tremaining: 3.62s\n",
      "744:\tlearn: 1.8420651\ttotal: 10.5s\tremaining: 3.6s\n",
      "745:\tlearn: 1.8420611\ttotal: 10.6s\tremaining: 3.59s\n",
      "746:\tlearn: 1.8420570\ttotal: 10.6s\tremaining: 3.58s\n",
      "747:\tlearn: 1.8416826\ttotal: 10.6s\tremaining: 3.56s\n",
      "748:\tlearn: 1.8416327\ttotal: 10.6s\tremaining: 3.55s\n",
      "749:\tlearn: 1.8415658\ttotal: 10.6s\tremaining: 3.54s\n",
      "750:\tlearn: 1.8415588\ttotal: 10.6s\tremaining: 3.52s\n",
      "751:\tlearn: 1.8415528\ttotal: 10.6s\tremaining: 3.51s\n",
      "752:\tlearn: 1.8414915\ttotal: 10.6s\tremaining: 3.49s\n",
      "753:\tlearn: 1.8414676\ttotal: 10.7s\tremaining: 3.48s\n",
      "754:\tlearn: 1.8414426\ttotal: 10.7s\tremaining: 3.46s\n",
      "755:\tlearn: 1.8414389\ttotal: 10.7s\tremaining: 3.45s\n",
      "756:\tlearn: 1.8411258\ttotal: 10.7s\tremaining: 3.44s\n",
      "757:\tlearn: 1.8410471\ttotal: 10.7s\tremaining: 3.42s\n",
      "758:\tlearn: 1.8402402\ttotal: 10.7s\tremaining: 3.41s\n",
      "759:\tlearn: 1.8401459\ttotal: 10.7s\tremaining: 3.39s\n",
      "760:\tlearn: 1.8400738\ttotal: 10.8s\tremaining: 3.38s\n",
      "761:\tlearn: 1.8400735\ttotal: 10.8s\tremaining: 3.37s\n",
      "762:\tlearn: 1.8400734\ttotal: 10.8s\tremaining: 3.35s\n",
      "763:\tlearn: 1.8397075\ttotal: 10.8s\tremaining: 3.34s\n",
      "764:\tlearn: 1.8392735\ttotal: 10.8s\tremaining: 3.32s\n",
      "765:\tlearn: 1.8391304\ttotal: 10.8s\tremaining: 3.31s\n",
      "766:\tlearn: 1.8388901\ttotal: 10.8s\tremaining: 3.29s\n",
      "767:\tlearn: 1.8388408\ttotal: 10.9s\tremaining: 3.28s\n",
      "768:\tlearn: 1.8386401\ttotal: 10.9s\tremaining: 3.27s\n",
      "769:\tlearn: 1.8381536\ttotal: 10.9s\tremaining: 3.25s\n",
      "770:\tlearn: 1.8369474\ttotal: 10.9s\tremaining: 3.24s\n",
      "771:\tlearn: 1.8368967\ttotal: 10.9s\tremaining: 3.22s\n",
      "772:\tlearn: 1.8367474\ttotal: 10.9s\tremaining: 3.21s\n",
      "773:\tlearn: 1.8367473\ttotal: 10.9s\tremaining: 3.19s\n",
      "774:\tlearn: 1.8366974\ttotal: 11s\tremaining: 3.18s\n",
      "775:\tlearn: 1.8365004\ttotal: 11s\tremaining: 3.17s\n",
      "776:\tlearn: 1.8364328\ttotal: 11s\tremaining: 3.15s\n",
      "777:\tlearn: 1.8364228\ttotal: 11s\tremaining: 3.14s\n",
      "778:\tlearn: 1.8363456\ttotal: 11s\tremaining: 3.13s\n",
      "779:\tlearn: 1.8363273\ttotal: 11s\tremaining: 3.11s\n",
      "780:\tlearn: 1.8359578\ttotal: 11s\tremaining: 3.1s\n",
      "781:\tlearn: 1.8355000\ttotal: 11.1s\tremaining: 3.08s\n",
      "782:\tlearn: 1.8354955\ttotal: 11.1s\tremaining: 3.07s\n",
      "783:\tlearn: 1.8354922\ttotal: 11.1s\tremaining: 3.05s\n",
      "784:\tlearn: 1.8353442\ttotal: 11.1s\tremaining: 3.04s\n",
      "785:\tlearn: 1.8353348\ttotal: 11.1s\tremaining: 3.02s\n",
      "786:\tlearn: 1.8353288\ttotal: 11.1s\tremaining: 3.01s\n",
      "787:\tlearn: 1.8353288\ttotal: 11.1s\tremaining: 3s\n",
      "788:\tlearn: 1.8346925\ttotal: 11.2s\tremaining: 2.98s\n",
      "789:\tlearn: 1.8334098\ttotal: 11.2s\tremaining: 2.97s\n",
      "790:\tlearn: 1.8326951\ttotal: 11.2s\tremaining: 2.95s\n",
      "791:\tlearn: 1.8326585\ttotal: 11.2s\tremaining: 2.94s\n",
      "792:\tlearn: 1.8320795\ttotal: 11.2s\tremaining: 2.93s\n",
      "793:\tlearn: 1.8320732\ttotal: 11.2s\tremaining: 2.91s\n",
      "794:\tlearn: 1.8320358\ttotal: 11.2s\tremaining: 2.9s\n",
      "795:\tlearn: 1.8319790\ttotal: 11.3s\tremaining: 2.88s\n",
      "796:\tlearn: 1.8319640\ttotal: 11.3s\tremaining: 2.87s\n",
      "797:\tlearn: 1.8316726\ttotal: 11.3s\tremaining: 2.85s\n",
      "798:\tlearn: 1.8308014\ttotal: 11.3s\tremaining: 2.84s\n",
      "799:\tlearn: 1.8304980\ttotal: 11.3s\tremaining: 2.83s\n",
      "800:\tlearn: 1.8304251\ttotal: 11.3s\tremaining: 2.81s\n",
      "801:\tlearn: 1.8303441\ttotal: 11.3s\tremaining: 2.8s\n",
      "802:\tlearn: 1.8303362\ttotal: 11.3s\tremaining: 2.78s\n",
      "803:\tlearn: 1.8303294\ttotal: 11.4s\tremaining: 2.77s\n",
      "804:\tlearn: 1.8295800\ttotal: 11.4s\tremaining: 2.75s\n",
      "805:\tlearn: 1.8295545\ttotal: 11.4s\tremaining: 2.74s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "806:\tlearn: 1.8295541\ttotal: 11.4s\tremaining: 2.73s\n",
      "807:\tlearn: 1.8295467\ttotal: 11.4s\tremaining: 2.71s\n",
      "808:\tlearn: 1.8295358\ttotal: 11.4s\tremaining: 2.7s\n",
      "809:\tlearn: 1.8293093\ttotal: 11.4s\tremaining: 2.68s\n",
      "810:\tlearn: 1.8287489\ttotal: 11.5s\tremaining: 2.67s\n",
      "811:\tlearn: 1.8287373\ttotal: 11.5s\tremaining: 2.66s\n",
      "812:\tlearn: 1.8287371\ttotal: 11.5s\tremaining: 2.64s\n",
      "813:\tlearn: 1.8287363\ttotal: 11.5s\tremaining: 2.63s\n",
      "814:\tlearn: 1.8287346\ttotal: 11.5s\tremaining: 2.61s\n",
      "815:\tlearn: 1.8287339\ttotal: 11.5s\tremaining: 2.6s\n",
      "816:\tlearn: 1.8287339\ttotal: 11.5s\tremaining: 2.58s\n",
      "817:\tlearn: 1.8287335\ttotal: 11.6s\tremaining: 2.57s\n",
      "818:\tlearn: 1.8286987\ttotal: 11.6s\tremaining: 2.56s\n",
      "819:\tlearn: 1.8281363\ttotal: 11.6s\tremaining: 2.54s\n",
      "820:\tlearn: 1.8280479\ttotal: 11.6s\tremaining: 2.53s\n",
      "821:\tlearn: 1.8276493\ttotal: 11.6s\tremaining: 2.51s\n",
      "822:\tlearn: 1.8268274\ttotal: 11.6s\tremaining: 2.5s\n",
      "823:\tlearn: 1.8264169\ttotal: 11.6s\tremaining: 2.48s\n",
      "824:\tlearn: 1.8263886\ttotal: 11.6s\tremaining: 2.47s\n",
      "825:\tlearn: 1.8263750\ttotal: 11.7s\tremaining: 2.46s\n",
      "826:\tlearn: 1.8263749\ttotal: 11.7s\tremaining: 2.44s\n",
      "827:\tlearn: 1.8263730\ttotal: 11.7s\tremaining: 2.43s\n",
      "828:\tlearn: 1.8260267\ttotal: 11.7s\tremaining: 2.41s\n",
      "829:\tlearn: 1.8258656\ttotal: 11.7s\tremaining: 2.4s\n",
      "830:\tlearn: 1.8258629\ttotal: 11.7s\tremaining: 2.39s\n",
      "831:\tlearn: 1.8258373\ttotal: 11.7s\tremaining: 2.37s\n",
      "832:\tlearn: 1.8254103\ttotal: 11.8s\tremaining: 2.36s\n",
      "833:\tlearn: 1.8254049\ttotal: 11.8s\tremaining: 2.34s\n",
      "834:\tlearn: 1.8251628\ttotal: 11.8s\tremaining: 2.33s\n",
      "835:\tlearn: 1.8250594\ttotal: 11.8s\tremaining: 2.31s\n",
      "836:\tlearn: 1.8250525\ttotal: 11.8s\tremaining: 2.3s\n",
      "837:\tlearn: 1.8249997\ttotal: 11.8s\tremaining: 2.29s\n",
      "838:\tlearn: 1.8249952\ttotal: 11.8s\tremaining: 2.27s\n",
      "839:\tlearn: 1.8243873\ttotal: 11.9s\tremaining: 2.26s\n",
      "840:\tlearn: 1.8242864\ttotal: 11.9s\tremaining: 2.24s\n",
      "841:\tlearn: 1.8235289\ttotal: 11.9s\tremaining: 2.23s\n",
      "842:\tlearn: 1.8228979\ttotal: 11.9s\tremaining: 2.22s\n",
      "843:\tlearn: 1.8224114\ttotal: 11.9s\tremaining: 2.2s\n",
      "844:\tlearn: 1.8223955\ttotal: 11.9s\tremaining: 2.19s\n",
      "845:\tlearn: 1.8219351\ttotal: 11.9s\tremaining: 2.17s\n",
      "846:\tlearn: 1.8210646\ttotal: 12s\tremaining: 2.16s\n",
      "847:\tlearn: 1.8205301\ttotal: 12s\tremaining: 2.15s\n",
      "848:\tlearn: 1.8201789\ttotal: 12s\tremaining: 2.13s\n",
      "849:\tlearn: 1.8201455\ttotal: 12s\tremaining: 2.12s\n",
      "850:\tlearn: 1.8201360\ttotal: 12s\tremaining: 2.1s\n",
      "851:\tlearn: 1.8189997\ttotal: 12s\tremaining: 2.09s\n",
      "852:\tlearn: 1.8177793\ttotal: 12s\tremaining: 2.08s\n",
      "853:\tlearn: 1.8169578\ttotal: 12.1s\tremaining: 2.06s\n",
      "854:\tlearn: 1.8168910\ttotal: 12.1s\tremaining: 2.05s\n",
      "855:\tlearn: 1.8166394\ttotal: 12.1s\tremaining: 2.03s\n",
      "856:\tlearn: 1.8166316\ttotal: 12.1s\tremaining: 2.02s\n",
      "857:\tlearn: 1.8165926\ttotal: 12.1s\tremaining: 2s\n",
      "858:\tlearn: 1.8165923\ttotal: 12.1s\tremaining: 1.99s\n",
      "859:\tlearn: 1.8165877\ttotal: 12.1s\tremaining: 1.98s\n",
      "860:\tlearn: 1.8165790\ttotal: 12.2s\tremaining: 1.96s\n",
      "861:\tlearn: 1.8165775\ttotal: 12.2s\tremaining: 1.95s\n",
      "862:\tlearn: 1.8165409\ttotal: 12.2s\tremaining: 1.93s\n",
      "863:\tlearn: 1.8160103\ttotal: 12.2s\tremaining: 1.92s\n",
      "864:\tlearn: 1.8160090\ttotal: 12.2s\tremaining: 1.91s\n",
      "865:\tlearn: 1.8159908\ttotal: 12.2s\tremaining: 1.89s\n",
      "866:\tlearn: 1.8159908\ttotal: 12.2s\tremaining: 1.88s\n",
      "867:\tlearn: 1.8159876\ttotal: 12.3s\tremaining: 1.86s\n",
      "868:\tlearn: 1.8159821\ttotal: 12.3s\tremaining: 1.85s\n",
      "869:\tlearn: 1.8159760\ttotal: 12.3s\tremaining: 1.83s\n",
      "870:\tlearn: 1.8156613\ttotal: 12.3s\tremaining: 1.82s\n",
      "871:\tlearn: 1.8156592\ttotal: 12.3s\tremaining: 1.81s\n",
      "872:\tlearn: 1.8156098\ttotal: 12.3s\tremaining: 1.79s\n",
      "873:\tlearn: 1.8151547\ttotal: 12.3s\tremaining: 1.78s\n",
      "874:\tlearn: 1.8151545\ttotal: 12.3s\tremaining: 1.76s\n",
      "875:\tlearn: 1.8151339\ttotal: 12.4s\tremaining: 1.75s\n",
      "876:\tlearn: 1.8151283\ttotal: 12.4s\tremaining: 1.74s\n",
      "877:\tlearn: 1.8151266\ttotal: 12.4s\tremaining: 1.72s\n",
      "878:\tlearn: 1.8148831\ttotal: 12.4s\tremaining: 1.71s\n",
      "879:\tlearn: 1.8148519\ttotal: 12.4s\tremaining: 1.69s\n",
      "880:\tlearn: 1.8148466\ttotal: 12.4s\tremaining: 1.68s\n",
      "881:\tlearn: 1.8144122\ttotal: 12.4s\tremaining: 1.66s\n",
      "882:\tlearn: 1.8134778\ttotal: 12.5s\tremaining: 1.65s\n",
      "883:\tlearn: 1.8133705\ttotal: 12.5s\tremaining: 1.64s\n",
      "884:\tlearn: 1.8129507\ttotal: 12.5s\tremaining: 1.62s\n",
      "885:\tlearn: 1.8129502\ttotal: 12.5s\tremaining: 1.61s\n",
      "886:\tlearn: 1.8129500\ttotal: 12.5s\tremaining: 1.59s\n",
      "887:\tlearn: 1.8129004\ttotal: 12.5s\tremaining: 1.58s\n",
      "888:\tlearn: 1.8128916\ttotal: 12.5s\tremaining: 1.57s\n",
      "889:\tlearn: 1.8128893\ttotal: 12.6s\tremaining: 1.55s\n",
      "890:\tlearn: 1.8126067\ttotal: 12.6s\tremaining: 1.54s\n",
      "891:\tlearn: 1.8126002\ttotal: 12.6s\tremaining: 1.52s\n",
      "892:\tlearn: 1.8123055\ttotal: 12.6s\tremaining: 1.51s\n",
      "893:\tlearn: 1.8122961\ttotal: 12.6s\tremaining: 1.5s\n",
      "894:\tlearn: 1.8122879\ttotal: 12.6s\tremaining: 1.48s\n",
      "895:\tlearn: 1.8122483\ttotal: 12.6s\tremaining: 1.47s\n",
      "896:\tlearn: 1.8118450\ttotal: 12.6s\tremaining: 1.45s\n",
      "897:\tlearn: 1.8102263\ttotal: 12.7s\tremaining: 1.44s\n",
      "898:\tlearn: 1.8102074\ttotal: 12.7s\tremaining: 1.42s\n",
      "899:\tlearn: 1.8099767\ttotal: 12.7s\tremaining: 1.41s\n",
      "900:\tlearn: 1.8093113\ttotal: 12.7s\tremaining: 1.4s\n",
      "901:\tlearn: 1.8090741\ttotal: 12.7s\tremaining: 1.38s\n",
      "902:\tlearn: 1.8088269\ttotal: 12.7s\tremaining: 1.37s\n",
      "903:\tlearn: 1.8088265\ttotal: 12.7s\tremaining: 1.35s\n",
      "904:\tlearn: 1.8088261\ttotal: 12.8s\tremaining: 1.34s\n",
      "905:\tlearn: 1.8087018\ttotal: 12.8s\tremaining: 1.32s\n",
      "906:\tlearn: 1.8086457\ttotal: 12.8s\tremaining: 1.31s\n",
      "907:\tlearn: 1.8085866\ttotal: 12.8s\tremaining: 1.3s\n",
      "908:\tlearn: 1.8079731\ttotal: 12.8s\tremaining: 1.28s\n",
      "909:\tlearn: 1.8079565\ttotal: 12.8s\tremaining: 1.27s\n",
      "910:\tlearn: 1.8078179\ttotal: 12.8s\tremaining: 1.25s\n",
      "911:\tlearn: 1.8076980\ttotal: 12.9s\tremaining: 1.24s\n",
      "912:\tlearn: 1.8076941\ttotal: 12.9s\tremaining: 1.23s\n",
      "913:\tlearn: 1.8076780\ttotal: 12.9s\tremaining: 1.21s\n",
      "914:\tlearn: 1.8076253\ttotal: 12.9s\tremaining: 1.2s\n",
      "915:\tlearn: 1.8066530\ttotal: 12.9s\tremaining: 1.18s\n",
      "916:\tlearn: 1.8063972\ttotal: 12.9s\tremaining: 1.17s\n",
      "917:\tlearn: 1.8059128\ttotal: 12.9s\tremaining: 1.16s\n",
      "918:\tlearn: 1.8056541\ttotal: 13s\tremaining: 1.14s\n",
      "919:\tlearn: 1.8054477\ttotal: 13s\tremaining: 1.13s\n",
      "920:\tlearn: 1.8045014\ttotal: 13s\tremaining: 1.11s\n",
      "921:\tlearn: 1.8044929\ttotal: 13s\tremaining: 1.1s\n",
      "922:\tlearn: 1.8044704\ttotal: 13s\tremaining: 1.08s\n",
      "923:\tlearn: 1.8043779\ttotal: 13s\tremaining: 1.07s\n",
      "924:\tlearn: 1.8043273\ttotal: 13s\tremaining: 1.06s\n",
      "925:\tlearn: 1.8043266\ttotal: 13.1s\tremaining: 1.04s\n",
      "926:\tlearn: 1.8042706\ttotal: 13.1s\tremaining: 1.03s\n",
      "927:\tlearn: 1.8041152\ttotal: 13.1s\tremaining: 1.01s\n",
      "928:\tlearn: 1.8040961\ttotal: 13.1s\tremaining: 1s\n",
      "929:\tlearn: 1.8040958\ttotal: 13.1s\tremaining: 987ms\n",
      "930:\tlearn: 1.8039140\ttotal: 13.1s\tremaining: 973ms\n",
      "931:\tlearn: 1.8039058\ttotal: 13.1s\tremaining: 959ms\n",
      "932:\tlearn: 1.8039024\ttotal: 13.2s\tremaining: 945ms\n",
      "933:\tlearn: 1.8039014\ttotal: 13.2s\tremaining: 930ms\n",
      "934:\tlearn: 1.8039013\ttotal: 13.2s\tremaining: 916ms\n",
      "935:\tlearn: 1.8038103\ttotal: 13.2s\tremaining: 902ms\n",
      "936:\tlearn: 1.8035783\ttotal: 13.2s\tremaining: 888ms\n",
      "937:\tlearn: 1.8034998\ttotal: 13.2s\tremaining: 874ms\n",
      "938:\tlearn: 1.8032956\ttotal: 13.2s\tremaining: 860ms\n",
      "939:\tlearn: 1.8032488\ttotal: 13.2s\tremaining: 846ms\n",
      "940:\tlearn: 1.8025157\ttotal: 13.3s\tremaining: 832ms\n",
      "941:\tlearn: 1.8025154\ttotal: 13.3s\tremaining: 817ms\n",
      "942:\tlearn: 1.8025010\ttotal: 13.3s\tremaining: 803ms\n",
      "943:\tlearn: 1.8020710\ttotal: 13.3s\tremaining: 789ms\n",
      "944:\tlearn: 1.8020176\ttotal: 13.3s\tremaining: 775ms\n",
      "945:\tlearn: 1.8020044\ttotal: 13.3s\tremaining: 761ms\n",
      "946:\tlearn: 1.8016274\ttotal: 13.3s\tremaining: 747ms\n",
      "947:\tlearn: 1.8013827\ttotal: 13.4s\tremaining: 733ms\n",
      "948:\tlearn: 1.8012600\ttotal: 13.4s\tremaining: 719ms\n",
      "949:\tlearn: 1.8012583\ttotal: 13.4s\tremaining: 705ms\n",
      "950:\tlearn: 1.8012421\ttotal: 13.4s\tremaining: 691ms\n",
      "951:\tlearn: 1.8012316\ttotal: 13.4s\tremaining: 677ms\n",
      "952:\tlearn: 1.8012255\ttotal: 13.4s\tremaining: 662ms\n",
      "953:\tlearn: 1.8012253\ttotal: 13.4s\tremaining: 648ms\n",
      "954:\tlearn: 1.8007417\ttotal: 13.5s\tremaining: 634ms\n",
      "955:\tlearn: 1.8006510\ttotal: 13.5s\tremaining: 620ms\n",
      "956:\tlearn: 1.8006281\ttotal: 13.5s\tremaining: 606ms\n",
      "957:\tlearn: 1.8002469\ttotal: 13.5s\tremaining: 592ms\n",
      "958:\tlearn: 1.8001399\ttotal: 13.5s\tremaining: 578ms\n",
      "959:\tlearn: 1.7997649\ttotal: 13.5s\tremaining: 564ms\n",
      "960:\tlearn: 1.7997454\ttotal: 13.5s\tremaining: 550ms\n",
      "961:\tlearn: 1.7997422\ttotal: 13.6s\tremaining: 536ms\n",
      "962:\tlearn: 1.7997344\ttotal: 13.6s\tremaining: 521ms\n",
      "963:\tlearn: 1.7997329\ttotal: 13.6s\tremaining: 507ms\n",
      "964:\tlearn: 1.7996121\ttotal: 13.6s\tremaining: 493ms\n",
      "965:\tlearn: 1.7992145\ttotal: 13.6s\tremaining: 479ms\n",
      "966:\tlearn: 1.7989937\ttotal: 13.6s\tremaining: 465ms\n",
      "967:\tlearn: 1.7989136\ttotal: 13.6s\tremaining: 451ms\n",
      "968:\tlearn: 1.7983981\ttotal: 13.7s\tremaining: 437ms\n",
      "969:\tlearn: 1.7983507\ttotal: 13.7s\tremaining: 423ms\n",
      "970:\tlearn: 1.7979092\ttotal: 13.7s\tremaining: 409ms\n",
      "971:\tlearn: 1.7978799\ttotal: 13.7s\tremaining: 394ms\n",
      "972:\tlearn: 1.7978459\ttotal: 13.7s\tremaining: 380ms\n",
      "973:\tlearn: 1.7978151\ttotal: 13.7s\tremaining: 366ms\n",
      "974:\tlearn: 1.7978148\ttotal: 13.7s\tremaining: 352ms\n",
      "975:\tlearn: 1.7975961\ttotal: 13.7s\tremaining: 338ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976:\tlearn: 1.7974092\ttotal: 13.8s\tremaining: 324ms\n",
      "977:\tlearn: 1.7972362\ttotal: 13.8s\tremaining: 310ms\n",
      "978:\tlearn: 1.7970489\ttotal: 13.8s\tremaining: 296ms\n",
      "979:\tlearn: 1.7970210\ttotal: 13.8s\tremaining: 282ms\n",
      "980:\tlearn: 1.7962745\ttotal: 13.8s\tremaining: 268ms\n",
      "981:\tlearn: 1.7962735\ttotal: 13.8s\tremaining: 254ms\n",
      "982:\tlearn: 1.7957767\ttotal: 13.8s\tremaining: 239ms\n",
      "983:\tlearn: 1.7956106\ttotal: 13.9s\tremaining: 225ms\n",
      "984:\tlearn: 1.7955305\ttotal: 13.9s\tremaining: 211ms\n",
      "985:\tlearn: 1.7954301\ttotal: 13.9s\tremaining: 197ms\n",
      "986:\tlearn: 1.7953321\ttotal: 13.9s\tremaining: 183ms\n",
      "987:\tlearn: 1.7952687\ttotal: 13.9s\tremaining: 169ms\n",
      "988:\tlearn: 1.7952119\ttotal: 13.9s\tremaining: 155ms\n",
      "989:\tlearn: 1.7949192\ttotal: 13.9s\tremaining: 141ms\n",
      "990:\tlearn: 1.7943850\ttotal: 14s\tremaining: 127ms\n",
      "991:\tlearn: 1.7937503\ttotal: 14s\tremaining: 113ms\n",
      "992:\tlearn: 1.7936679\ttotal: 14s\tremaining: 98.6ms\n",
      "993:\tlearn: 1.7936667\ttotal: 14s\tremaining: 84.5ms\n",
      "994:\tlearn: 1.7936611\ttotal: 14s\tremaining: 70.4ms\n",
      "995:\tlearn: 1.7936466\ttotal: 14s\tremaining: 56.3ms\n",
      "996:\tlearn: 1.7935608\ttotal: 14s\tremaining: 42.2ms\n",
      "997:\tlearn: 1.7935053\ttotal: 14.1s\tremaining: 28.2ms\n",
      "998:\tlearn: 1.7934986\ttotal: 14.1s\tremaining: 14.1ms\n",
      "999:\tlearn: 1.7934966\ttotal: 14.1s\tremaining: 0us\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "final_model_2, final_pred_2 = stacking_models(base_models_2, \n",
    "                                              X_train, y_train_transformed, \n",
    "                                              test=X_test, final_regressor='linear', \n",
    "                                              final_params={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "53e3a3f0-4bcd-4642-b119-68c7d8efe01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_2_2 = pred_to_df(final_pred_2, squared=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5f21ed",
   "metadata": {},
   "source": [
    "### Stacking 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d1c884e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 13.7584133\ttest: 13.8351663\tbest: 13.8351663 (0)\ttotal: 12.4ms\tremaining: 57.1s\n",
      "100:\tlearn: 3.8602765\ttest: 3.8970616\tbest: 3.8970616 (100)\ttotal: 1.19s\tremaining: 52.8s\n",
      "200:\tlearn: 3.5888459\ttest: 3.7620445\tbest: 3.7618049 (199)\ttotal: 2.33s\tremaining: 50.9s\n",
      "300:\tlearn: 3.4011340\ttest: 3.6787959\tbest: 3.6787959 (300)\ttotal: 3.47s\tremaining: 49.6s\n",
      "400:\tlearn: 3.2569407\ttest: 3.6197181\tbest: 3.6197181 (400)\ttotal: 4.62s\tremaining: 48.3s\n",
      "500:\tlearn: 3.1378183\ttest: 3.5767599\tbest: 3.5763337 (499)\ttotal: 5.77s\tremaining: 47.2s\n",
      "600:\tlearn: 3.0264306\ttest: 3.5320803\tbest: 3.5320803 (600)\ttotal: 6.93s\tremaining: 46.1s\n",
      "700:\tlearn: 2.9348615\ttest: 3.5048298\tbest: 3.5048030 (699)\ttotal: 8.08s\tremaining: 44.9s\n",
      "800:\tlearn: 2.8482367\ttest: 3.4802005\tbest: 3.4802005 (800)\ttotal: 9.25s\tremaining: 43.9s\n",
      "900:\tlearn: 2.7720002\ttest: 3.4506593\tbest: 3.4506593 (900)\ttotal: 10.4s\tremaining: 42.7s\n",
      "1000:\tlearn: 2.6994840\ttest: 3.4261103\tbest: 3.4261103 (1000)\ttotal: 11.6s\tremaining: 41.6s\n",
      "1100:\tlearn: 2.6267080\ttest: 3.4006697\tbest: 3.4006697 (1100)\ttotal: 12.8s\tremaining: 40.6s\n",
      "1200:\tlearn: 2.5622001\ttest: 3.3823246\tbest: 3.3823246 (1200)\ttotal: 13.9s\tremaining: 39.5s\n",
      "1300:\tlearn: 2.5021055\ttest: 3.3684596\tbest: 3.3684596 (1300)\ttotal: 15.1s\tremaining: 38.4s\n",
      "1400:\tlearn: 2.4435153\ttest: 3.3550911\tbest: 3.3550911 (1400)\ttotal: 16.3s\tremaining: 37.3s\n",
      "1500:\tlearn: 2.3922345\ttest: 3.3423502\tbest: 3.3423502 (1500)\ttotal: 17.5s\tremaining: 36.1s\n",
      "1600:\tlearn: 2.3433660\ttest: 3.3290642\tbest: 3.3290642 (1600)\ttotal: 18.7s\tremaining: 35s\n",
      "1700:\tlearn: 2.2936063\ttest: 3.3176336\tbest: 3.3176336 (1700)\ttotal: 19.9s\tremaining: 33.9s\n",
      "1800:\tlearn: 2.2452153\ttest: 3.3068844\tbest: 3.3064890 (1793)\ttotal: 21.1s\tremaining: 32.7s\n",
      "1900:\tlearn: 2.2030411\ttest: 3.2960427\tbest: 3.2960427 (1900)\ttotal: 22.3s\tremaining: 31.6s\n",
      "2000:\tlearn: 2.1582190\ttest: 3.2880954\tbest: 3.2878040 (1992)\ttotal: 23.5s\tremaining: 30.5s\n",
      "2100:\tlearn: 2.1170074\ttest: 3.2784696\tbest: 3.2782639 (2098)\ttotal: 24.7s\tremaining: 29.3s\n",
      "2200:\tlearn: 2.0768426\ttest: 3.2698992\tbest: 3.2698992 (2200)\ttotal: 26s\tremaining: 28.3s\n",
      "2300:\tlearn: 2.0377435\ttest: 3.2632520\tbest: 3.2632520 (2300)\ttotal: 27.3s\tremaining: 27.2s\n",
      "2400:\tlearn: 2.0030142\ttest: 3.2527367\tbest: 3.2527091 (2399)\ttotal: 28.6s\tremaining: 26.1s\n",
      "2500:\tlearn: 1.9681816\ttest: 3.2455371\tbest: 3.2455371 (2500)\ttotal: 29.9s\tremaining: 25.1s\n",
      "2600:\tlearn: 1.9340843\ttest: 3.2399912\tbest: 3.2399912 (2600)\ttotal: 31.2s\tremaining: 24s\n",
      "2700:\tlearn: 1.9026085\ttest: 3.2313185\tbest: 3.2313185 (2700)\ttotal: 32.5s\tremaining: 22.8s\n",
      "2800:\tlearn: 1.8731922\ttest: 3.2238064\tbest: 3.2238064 (2800)\ttotal: 33.8s\tremaining: 21.7s\n",
      "2900:\tlearn: 1.8417647\ttest: 3.2186074\tbest: 3.2186074 (2900)\ttotal: 35.1s\tremaining: 20.5s\n",
      "3000:\tlearn: 1.8129822\ttest: 3.2110425\tbest: 3.2110425 (3000)\ttotal: 36.4s\tremaining: 19.4s\n",
      "3100:\tlearn: 1.7843321\ttest: 3.2055627\tbest: 3.2054694 (3099)\ttotal: 37.7s\tremaining: 18.2s\n",
      "3200:\tlearn: 1.7578169\ttest: 3.2002264\tbest: 3.2002264 (3200)\ttotal: 39s\tremaining: 17s\n",
      "3300:\tlearn: 1.7315550\ttest: 3.1969226\tbest: 3.1967965 (3293)\ttotal: 40.3s\tremaining: 15.8s\n",
      "3400:\tlearn: 1.7054240\ttest: 3.1931025\tbest: 3.1931025 (3400)\ttotal: 41.6s\tremaining: 14.6s\n",
      "3500:\tlearn: 1.6801440\ttest: 3.1879928\tbest: 3.1879599 (3498)\ttotal: 42.9s\tremaining: 13.4s\n",
      "3600:\tlearn: 1.6541502\ttest: 3.1837604\tbest: 3.1837539 (3598)\ttotal: 44.1s\tremaining: 12.2s\n",
      "3700:\tlearn: 1.6305539\ttest: 3.1793643\tbest: 3.1790478 (3689)\ttotal: 45.4s\tremaining: 11s\n",
      "3800:\tlearn: 1.6078765\ttest: 3.1750702\tbest: 3.1750514 (3799)\ttotal: 46.7s\tremaining: 9.8s\n",
      "3900:\tlearn: 1.5850053\ttest: 3.1703947\tbest: 3.1702510 (3896)\ttotal: 48s\tremaining: 8.58s\n",
      "4000:\tlearn: 1.5622740\ttest: 3.1658365\tbest: 3.1658365 (4000)\ttotal: 49.3s\tremaining: 7.36s\n",
      "4100:\tlearn: 1.5419402\ttest: 3.1623351\tbest: 3.1623351 (4100)\ttotal: 50.6s\tremaining: 6.13s\n",
      "4200:\tlearn: 1.5212044\ttest: 3.1566251\tbest: 3.1566251 (4200)\ttotal: 51.9s\tremaining: 4.9s\n",
      "4300:\tlearn: 1.5013460\ttest: 3.1534428\tbest: 3.1534219 (4299)\ttotal: 53.2s\tremaining: 3.67s\n",
      "4400:\tlearn: 1.4824239\ttest: 3.1506477\tbest: 3.1506477 (4400)\ttotal: 54.5s\tremaining: 2.44s\n",
      "4500:\tlearn: 1.4636605\ttest: 3.1477489\tbest: 3.1477489 (4500)\ttotal: 55.8s\tremaining: 1.2s\n",
      "4597:\tlearn: 1.4479471\ttest: 3.1454059\tbest: 3.1453722 (4590)\ttotal: 57s\tremaining: 0us\n",
      "\n",
      "bestTest = 3.145372171\n",
      "bestIteration = 4590\n",
      "\n",
      "Shrink model to first 4591 iterations.\n"
     ]
    }
   ],
   "source": [
    "catboostm2, _ = prediction_models(X_train, y_train_transformed, test=X_test, model='catboost', params=dict_model_param['catboost_opt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "428a4fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost2, _ = prediction_models(X_train, y_train_transformed, test=X_test, model='xgboost', params=dict_model_param['xgboost3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f91d51ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models_3 = [\n",
    "    ('lgbm', lgbm),\n",
    "    ('catboost', catboostm),\n",
    "    ('catboost2', catboostm2),\n",
    "    ('xgboost', xgboost2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a0ae9bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 339\n",
      "[LightGBM] [Info] Number of data points in the train set: 79218, number of used features: 54\n",
      "[LightGBM] [Info] Start training from score 9.924039\n",
      "0:\tlearn: 9.0625740\ttotal: 20.9ms\tremaining: 20.9s\n",
      "1:\tlearn: 8.4133972\ttotal: 41.2ms\tremaining: 20.6s\n",
      "2:\tlearn: 7.8099768\ttotal: 62.5ms\tremaining: 20.8s\n",
      "3:\tlearn: 7.1189953\ttotal: 83.8ms\tremaining: 20.9s\n",
      "4:\tlearn: 6.5480038\ttotal: 105ms\tremaining: 20.8s\n",
      "5:\tlearn: 6.1447702\ttotal: 125ms\tremaining: 20.7s\n",
      "6:\tlearn: 5.6831695\ttotal: 145ms\tremaining: 20.5s\n",
      "7:\tlearn: 5.2592029\ttotal: 164ms\tremaining: 20.4s\n",
      "8:\tlearn: 4.8578495\ttotal: 186ms\tremaining: 20.5s\n",
      "9:\tlearn: 4.5101983\ttotal: 207ms\tremaining: 20.5s\n",
      "10:\tlearn: 4.2214233\ttotal: 228ms\tremaining: 20.5s\n",
      "11:\tlearn: 4.0145113\ttotal: 252ms\tremaining: 20.8s\n",
      "12:\tlearn: 3.7663852\ttotal: 271ms\tremaining: 20.6s\n",
      "13:\tlearn: 3.5508344\ttotal: 290ms\tremaining: 20.4s\n",
      "14:\tlearn: 3.3660768\ttotal: 310ms\tremaining: 20.4s\n",
      "15:\tlearn: 3.2461008\ttotal: 330ms\tremaining: 20.3s\n",
      "16:\tlearn: 3.1503877\ttotal: 350ms\tremaining: 20.2s\n",
      "17:\tlearn: 3.0181972\ttotal: 369ms\tremaining: 20.2s\n",
      "18:\tlearn: 2.9418795\ttotal: 389ms\tremaining: 20.1s\n",
      "19:\tlearn: 2.8248909\ttotal: 408ms\tremaining: 20s\n",
      "20:\tlearn: 2.7679296\ttotal: 428ms\tremaining: 19.9s\n",
      "21:\tlearn: 2.7168477\ttotal: 451ms\tremaining: 20.1s\n",
      "22:\tlearn: 2.6735806\ttotal: 474ms\tremaining: 20.1s\n",
      "23:\tlearn: 2.6248225\ttotal: 493ms\tremaining: 20.1s\n",
      "24:\tlearn: 2.5607037\ttotal: 513ms\tremaining: 20s\n",
      "25:\tlearn: 2.5115372\ttotal: 533ms\tremaining: 20s\n",
      "26:\tlearn: 2.4882104\ttotal: 552ms\tremaining: 19.9s\n",
      "27:\tlearn: 2.4611594\ttotal: 571ms\tremaining: 19.8s\n",
      "28:\tlearn: 2.4410608\ttotal: 590ms\tremaining: 19.7s\n",
      "29:\tlearn: 2.3899064\ttotal: 609ms\tremaining: 19.7s\n",
      "30:\tlearn: 2.3623715\ttotal: 627ms\tremaining: 19.6s\n",
      "31:\tlearn: 2.3473465\ttotal: 647ms\tremaining: 19.6s\n",
      "32:\tlearn: 2.3210701\ttotal: 668ms\tremaining: 19.6s\n",
      "33:\tlearn: 2.2891452\ttotal: 701ms\tremaining: 19.9s\n",
      "34:\tlearn: 2.2796365\ttotal: 720ms\tremaining: 19.8s\n",
      "35:\tlearn: 2.2697524\ttotal: 739ms\tremaining: 19.8s\n",
      "36:\tlearn: 2.2449804\ttotal: 758ms\tremaining: 19.7s\n",
      "37:\tlearn: 2.2316725\ttotal: 777ms\tremaining: 19.7s\n",
      "38:\tlearn: 2.2148337\ttotal: 796ms\tremaining: 19.6s\n",
      "39:\tlearn: 2.2098784\ttotal: 814ms\tremaining: 19.5s\n",
      "40:\tlearn: 2.2021916\ttotal: 832ms\tremaining: 19.5s\n",
      "41:\tlearn: 2.1972459\ttotal: 851ms\tremaining: 19.4s\n",
      "42:\tlearn: 2.1922020\ttotal: 870ms\tremaining: 19.4s\n",
      "43:\tlearn: 2.1901579\ttotal: 891ms\tremaining: 19.4s\n",
      "44:\tlearn: 2.1885948\ttotal: 911ms\tremaining: 19.3s\n",
      "45:\tlearn: 2.1863853\ttotal: 930ms\tremaining: 19.3s\n",
      "46:\tlearn: 2.1687848\ttotal: 950ms\tremaining: 19.3s\n",
      "47:\tlearn: 2.1661821\ttotal: 968ms\tremaining: 19.2s\n",
      "48:\tlearn: 2.1630093\ttotal: 987ms\tremaining: 19.2s\n",
      "49:\tlearn: 2.1609104\ttotal: 1s\tremaining: 19.1s\n",
      "50:\tlearn: 2.1588285\ttotal: 1.02s\tremaining: 19s\n",
      "51:\tlearn: 2.1564277\ttotal: 1.04s\tremaining: 19s\n",
      "52:\tlearn: 2.1527741\ttotal: 1.06s\tremaining: 19s\n",
      "53:\tlearn: 2.1520782\ttotal: 1.08s\tremaining: 18.9s\n",
      "54:\tlearn: 2.1502300\ttotal: 1.1s\tremaining: 18.9s\n",
      "55:\tlearn: 2.1322229\ttotal: 1.12s\tremaining: 18.9s\n",
      "56:\tlearn: 2.1294096\ttotal: 1.14s\tremaining: 18.9s\n",
      "57:\tlearn: 2.1261664\ttotal: 1.16s\tremaining: 18.9s\n",
      "58:\tlearn: 2.1259865\ttotal: 1.18s\tremaining: 18.8s\n",
      "59:\tlearn: 2.1253059\ttotal: 1.2s\tremaining: 18.8s\n",
      "60:\tlearn: 2.1251454\ttotal: 1.22s\tremaining: 18.8s\n",
      "61:\tlearn: 2.1246183\ttotal: 1.24s\tremaining: 18.7s\n",
      "62:\tlearn: 2.1170591\ttotal: 1.26s\tremaining: 18.7s\n",
      "63:\tlearn: 2.1151568\ttotal: 1.28s\tremaining: 18.7s\n",
      "64:\tlearn: 2.1147531\ttotal: 1.29s\tremaining: 18.6s\n",
      "65:\tlearn: 2.1045100\ttotal: 1.31s\tremaining: 18.6s\n",
      "66:\tlearn: 2.1039708\ttotal: 1.33s\tremaining: 18.6s\n",
      "67:\tlearn: 2.1007006\ttotal: 1.35s\tremaining: 18.6s\n",
      "68:\tlearn: 2.0971870\ttotal: 1.37s\tremaining: 18.5s\n",
      "69:\tlearn: 2.0958785\ttotal: 1.39s\tremaining: 18.5s\n",
      "70:\tlearn: 2.0956003\ttotal: 1.41s\tremaining: 18.4s\n",
      "71:\tlearn: 2.0955235\ttotal: 1.43s\tremaining: 18.4s\n",
      "72:\tlearn: 2.0950717\ttotal: 1.44s\tremaining: 18.3s\n",
      "73:\tlearn: 2.0929360\ttotal: 1.46s\tremaining: 18.3s\n",
      "74:\tlearn: 2.0923191\ttotal: 1.48s\tremaining: 18.3s\n",
      "75:\tlearn: 2.0911181\ttotal: 1.5s\tremaining: 18.2s\n",
      "76:\tlearn: 2.0896094\ttotal: 1.52s\tremaining: 18.2s\n",
      "77:\tlearn: 2.0892318\ttotal: 1.54s\tremaining: 18.2s\n",
      "78:\tlearn: 2.0885337\ttotal: 1.56s\tremaining: 18.2s\n",
      "79:\tlearn: 2.0879237\ttotal: 1.58s\tremaining: 18.2s\n",
      "80:\tlearn: 2.0859293\ttotal: 1.6s\tremaining: 18.1s\n",
      "81:\tlearn: 2.0787234\ttotal: 1.61s\tremaining: 18.1s\n",
      "82:\tlearn: 2.0782299\ttotal: 1.63s\tremaining: 18.1s\n",
      "83:\tlearn: 2.0779779\ttotal: 1.65s\tremaining: 18s\n",
      "84:\tlearn: 2.0745414\ttotal: 1.67s\tremaining: 18s\n",
      "85:\tlearn: 2.0742712\ttotal: 1.69s\tremaining: 18s\n",
      "86:\tlearn: 2.0739254\ttotal: 1.71s\tremaining: 17.9s\n",
      "87:\tlearn: 2.0728982\ttotal: 1.73s\tremaining: 17.9s\n",
      "88:\tlearn: 2.0721155\ttotal: 1.74s\tremaining: 17.8s\n",
      "89:\tlearn: 2.0708139\ttotal: 1.76s\tremaining: 17.8s\n",
      "90:\tlearn: 2.0706068\ttotal: 1.78s\tremaining: 17.8s\n",
      "91:\tlearn: 2.0698130\ttotal: 1.8s\tremaining: 17.8s\n",
      "92:\tlearn: 2.0698078\ttotal: 1.82s\tremaining: 17.7s\n",
      "93:\tlearn: 2.0691319\ttotal: 1.84s\tremaining: 17.7s\n",
      "94:\tlearn: 2.0683299\ttotal: 1.85s\tremaining: 17.7s\n",
      "95:\tlearn: 2.0682265\ttotal: 1.87s\tremaining: 17.6s\n",
      "96:\tlearn: 2.0681748\ttotal: 1.89s\tremaining: 17.6s\n",
      "97:\tlearn: 2.0677758\ttotal: 1.9s\tremaining: 17.5s\n",
      "98:\tlearn: 2.0604453\ttotal: 1.92s\tremaining: 17.5s\n",
      "99:\tlearn: 2.0601571\ttotal: 1.94s\tremaining: 17.4s\n",
      "100:\tlearn: 2.0599629\ttotal: 1.95s\tremaining: 17.4s\n",
      "101:\tlearn: 2.0581087\ttotal: 1.97s\tremaining: 17.4s\n",
      "102:\tlearn: 2.0574210\ttotal: 1.99s\tremaining: 17.3s\n",
      "103:\tlearn: 2.0495505\ttotal: 2.01s\tremaining: 17.3s\n",
      "104:\tlearn: 2.0491661\ttotal: 2.03s\tremaining: 17.3s\n",
      "105:\tlearn: 2.0488888\ttotal: 2.04s\tremaining: 17.2s\n",
      "106:\tlearn: 2.0488297\ttotal: 2.06s\tremaining: 17.2s\n",
      "107:\tlearn: 2.0457459\ttotal: 2.08s\tremaining: 17.2s\n",
      "108:\tlearn: 2.0451842\ttotal: 2.09s\tremaining: 17.1s\n",
      "109:\tlearn: 2.0449781\ttotal: 2.11s\tremaining: 17.1s\n",
      "110:\tlearn: 2.0446407\ttotal: 2.13s\tremaining: 17s\n",
      "111:\tlearn: 2.0443334\ttotal: 2.14s\tremaining: 17s\n",
      "112:\tlearn: 2.0441884\ttotal: 2.16s\tremaining: 17s\n",
      "113:\tlearn: 2.0441142\ttotal: 2.17s\tremaining: 16.9s\n",
      "114:\tlearn: 2.0440816\ttotal: 2.19s\tremaining: 16.9s\n",
      "115:\tlearn: 2.0427003\ttotal: 2.21s\tremaining: 16.8s\n",
      "116:\tlearn: 2.0420012\ttotal: 2.23s\tremaining: 16.8s\n",
      "117:\tlearn: 2.0416852\ttotal: 2.24s\tremaining: 16.8s\n",
      "118:\tlearn: 2.0415388\ttotal: 2.26s\tremaining: 16.7s\n",
      "119:\tlearn: 2.0321863\ttotal: 2.27s\tremaining: 16.7s\n",
      "120:\tlearn: 2.0288617\ttotal: 2.29s\tremaining: 16.7s\n",
      "121:\tlearn: 2.0276089\ttotal: 2.31s\tremaining: 16.6s\n",
      "122:\tlearn: 2.0240351\ttotal: 2.33s\tremaining: 16.6s\n",
      "123:\tlearn: 2.0236964\ttotal: 2.34s\tremaining: 16.6s\n",
      "124:\tlearn: 2.0190659\ttotal: 2.36s\tremaining: 16.5s\n",
      "125:\tlearn: 2.0180172\ttotal: 2.38s\tremaining: 16.5s\n",
      "126:\tlearn: 2.0172872\ttotal: 2.39s\tremaining: 16.5s\n",
      "127:\tlearn: 2.0140679\ttotal: 2.41s\tremaining: 16.4s\n",
      "128:\tlearn: 2.0081441\ttotal: 2.43s\tremaining: 16.4s\n",
      "129:\tlearn: 2.0063871\ttotal: 2.45s\tremaining: 16.4s\n",
      "130:\tlearn: 2.0048432\ttotal: 2.46s\tremaining: 16.4s\n",
      "131:\tlearn: 1.9997133\ttotal: 2.48s\tremaining: 16.3s\n",
      "132:\tlearn: 1.9987263\ttotal: 2.5s\tremaining: 16.3s\n",
      "133:\tlearn: 1.9972355\ttotal: 2.51s\tremaining: 16.2s\n",
      "134:\tlearn: 1.9967367\ttotal: 2.53s\tremaining: 16.2s\n",
      "135:\tlearn: 1.9940983\ttotal: 2.55s\tremaining: 16.2s\n",
      "136:\tlearn: 1.9917453\ttotal: 2.56s\tremaining: 16.1s\n",
      "137:\tlearn: 1.9899005\ttotal: 2.58s\tremaining: 16.1s\n",
      "138:\tlearn: 1.9891141\ttotal: 2.59s\tremaining: 16.1s\n",
      "139:\tlearn: 1.9872972\ttotal: 2.61s\tremaining: 16s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140:\tlearn: 1.9856725\ttotal: 2.63s\tremaining: 16s\n",
      "141:\tlearn: 1.9829191\ttotal: 2.65s\tremaining: 16s\n",
      "142:\tlearn: 1.9779575\ttotal: 2.66s\tremaining: 16s\n",
      "143:\tlearn: 1.9751523\ttotal: 2.68s\tremaining: 15.9s\n",
      "144:\tlearn: 1.9706630\ttotal: 2.7s\tremaining: 15.9s\n",
      "145:\tlearn: 1.9671126\ttotal: 2.71s\tremaining: 15.9s\n",
      "146:\tlearn: 1.9652524\ttotal: 2.73s\tremaining: 15.8s\n",
      "147:\tlearn: 1.9619327\ttotal: 2.75s\tremaining: 15.8s\n",
      "148:\tlearn: 1.9601310\ttotal: 2.76s\tremaining: 15.8s\n",
      "149:\tlearn: 1.9589545\ttotal: 2.78s\tremaining: 15.8s\n",
      "150:\tlearn: 1.9551591\ttotal: 2.8s\tremaining: 15.7s\n",
      "151:\tlearn: 1.9506114\ttotal: 2.81s\tremaining: 15.7s\n",
      "152:\tlearn: 1.9483762\ttotal: 2.83s\tremaining: 15.7s\n",
      "153:\tlearn: 1.9446391\ttotal: 2.85s\tremaining: 15.7s\n",
      "154:\tlearn: 1.9417674\ttotal: 2.87s\tremaining: 15.6s\n",
      "155:\tlearn: 1.9389325\ttotal: 2.88s\tremaining: 15.6s\n",
      "156:\tlearn: 1.9388090\ttotal: 2.9s\tremaining: 15.6s\n",
      "157:\tlearn: 1.9388017\ttotal: 2.92s\tremaining: 15.5s\n",
      "158:\tlearn: 1.9373594\ttotal: 2.93s\tremaining: 15.5s\n",
      "159:\tlearn: 1.9359200\ttotal: 2.95s\tremaining: 15.5s\n",
      "160:\tlearn: 1.9345239\ttotal: 2.97s\tremaining: 15.5s\n",
      "161:\tlearn: 1.9341969\ttotal: 2.98s\tremaining: 15.4s\n",
      "162:\tlearn: 1.9327716\ttotal: 3s\tremaining: 15.4s\n",
      "163:\tlearn: 1.9301553\ttotal: 3.02s\tremaining: 15.4s\n",
      "164:\tlearn: 1.9283528\ttotal: 3.03s\tremaining: 15.3s\n",
      "165:\tlearn: 1.9280087\ttotal: 3.05s\tremaining: 15.3s\n",
      "166:\tlearn: 1.9258202\ttotal: 3.07s\tremaining: 15.3s\n",
      "167:\tlearn: 1.9249009\ttotal: 3.08s\tremaining: 15.3s\n",
      "168:\tlearn: 1.9233442\ttotal: 3.1s\tremaining: 15.2s\n",
      "169:\tlearn: 1.9214365\ttotal: 3.12s\tremaining: 15.2s\n",
      "170:\tlearn: 1.9195310\ttotal: 3.13s\tremaining: 15.2s\n",
      "171:\tlearn: 1.9149621\ttotal: 3.15s\tremaining: 15.2s\n",
      "172:\tlearn: 1.9141947\ttotal: 3.16s\tremaining: 15.1s\n",
      "173:\tlearn: 1.9137737\ttotal: 3.18s\tremaining: 15.1s\n",
      "174:\tlearn: 1.9114799\ttotal: 3.2s\tremaining: 15.1s\n",
      "175:\tlearn: 1.9103112\ttotal: 3.21s\tremaining: 15s\n",
      "176:\tlearn: 1.9091528\ttotal: 3.23s\tremaining: 15s\n",
      "177:\tlearn: 1.9057268\ttotal: 3.25s\tremaining: 15s\n",
      "178:\tlearn: 1.9053700\ttotal: 3.26s\tremaining: 15s\n",
      "179:\tlearn: 1.9045469\ttotal: 3.28s\tremaining: 14.9s\n",
      "180:\tlearn: 1.9025230\ttotal: 3.3s\tremaining: 14.9s\n",
      "181:\tlearn: 1.9015473\ttotal: 3.31s\tremaining: 14.9s\n",
      "182:\tlearn: 1.9007332\ttotal: 3.33s\tremaining: 14.9s\n",
      "183:\tlearn: 1.8995969\ttotal: 3.35s\tremaining: 14.8s\n",
      "184:\tlearn: 1.8994565\ttotal: 3.36s\tremaining: 14.8s\n",
      "185:\tlearn: 1.8989545\ttotal: 3.38s\tremaining: 14.8s\n",
      "186:\tlearn: 1.8987218\ttotal: 3.4s\tremaining: 14.8s\n",
      "187:\tlearn: 1.8971754\ttotal: 3.41s\tremaining: 14.7s\n",
      "188:\tlearn: 1.8963783\ttotal: 3.43s\tremaining: 14.7s\n",
      "189:\tlearn: 1.8944328\ttotal: 3.44s\tremaining: 14.7s\n",
      "190:\tlearn: 1.8932171\ttotal: 3.46s\tremaining: 14.7s\n",
      "191:\tlearn: 1.8930453\ttotal: 3.48s\tremaining: 14.6s\n",
      "192:\tlearn: 1.8929188\ttotal: 3.5s\tremaining: 14.6s\n",
      "193:\tlearn: 1.8921292\ttotal: 3.51s\tremaining: 14.6s\n",
      "194:\tlearn: 1.8914647\ttotal: 3.53s\tremaining: 14.6s\n",
      "195:\tlearn: 1.8910278\ttotal: 3.54s\tremaining: 14.5s\n",
      "196:\tlearn: 1.8900427\ttotal: 3.56s\tremaining: 14.5s\n",
      "197:\tlearn: 1.8895467\ttotal: 3.58s\tremaining: 14.5s\n",
      "198:\tlearn: 1.8888445\ttotal: 3.6s\tremaining: 14.5s\n",
      "199:\tlearn: 1.8880036\ttotal: 3.61s\tremaining: 14.5s\n",
      "200:\tlearn: 1.8877507\ttotal: 3.63s\tremaining: 14.4s\n",
      "201:\tlearn: 1.8867576\ttotal: 3.65s\tremaining: 14.4s\n",
      "202:\tlearn: 1.8863023\ttotal: 3.66s\tremaining: 14.4s\n",
      "203:\tlearn: 1.8835915\ttotal: 3.68s\tremaining: 14.4s\n",
      "204:\tlearn: 1.8820079\ttotal: 3.7s\tremaining: 14.3s\n",
      "205:\tlearn: 1.8809665\ttotal: 3.71s\tremaining: 14.3s\n",
      "206:\tlearn: 1.8801201\ttotal: 3.73s\tremaining: 14.3s\n",
      "207:\tlearn: 1.8790738\ttotal: 3.75s\tremaining: 14.3s\n",
      "208:\tlearn: 1.8777644\ttotal: 3.77s\tremaining: 14.3s\n",
      "209:\tlearn: 1.8752109\ttotal: 3.78s\tremaining: 14.2s\n",
      "210:\tlearn: 1.8732623\ttotal: 3.8s\tremaining: 14.2s\n",
      "211:\tlearn: 1.8716975\ttotal: 3.82s\tremaining: 14.2s\n",
      "212:\tlearn: 1.8703801\ttotal: 3.83s\tremaining: 14.2s\n",
      "213:\tlearn: 1.8693834\ttotal: 3.85s\tremaining: 14.1s\n",
      "214:\tlearn: 1.8685898\ttotal: 3.86s\tremaining: 14.1s\n",
      "215:\tlearn: 1.8672259\ttotal: 3.89s\tremaining: 14.1s\n",
      "216:\tlearn: 1.8672080\ttotal: 3.91s\tremaining: 14.1s\n",
      "217:\tlearn: 1.8671844\ttotal: 3.92s\tremaining: 14.1s\n",
      "218:\tlearn: 1.8668864\ttotal: 3.94s\tremaining: 14.1s\n",
      "219:\tlearn: 1.8663534\ttotal: 3.96s\tremaining: 14s\n",
      "220:\tlearn: 1.8658230\ttotal: 3.97s\tremaining: 14s\n",
      "221:\tlearn: 1.8649730\ttotal: 3.99s\tremaining: 14s\n",
      "222:\tlearn: 1.8626805\ttotal: 4.01s\tremaining: 14s\n",
      "223:\tlearn: 1.8616880\ttotal: 4.02s\tremaining: 13.9s\n",
      "224:\tlearn: 1.8610799\ttotal: 4.04s\tremaining: 13.9s\n",
      "225:\tlearn: 1.8591019\ttotal: 4.06s\tremaining: 13.9s\n",
      "226:\tlearn: 1.8581987\ttotal: 4.07s\tremaining: 13.9s\n",
      "227:\tlearn: 1.8578647\ttotal: 4.09s\tremaining: 13.8s\n",
      "228:\tlearn: 1.8573248\ttotal: 4.11s\tremaining: 13.8s\n",
      "229:\tlearn: 1.8571350\ttotal: 4.12s\tremaining: 13.8s\n",
      "230:\tlearn: 1.8566375\ttotal: 4.14s\tremaining: 13.8s\n",
      "231:\tlearn: 1.8559832\ttotal: 4.16s\tremaining: 13.8s\n",
      "232:\tlearn: 1.8554336\ttotal: 4.17s\tremaining: 13.7s\n",
      "233:\tlearn: 1.8537901\ttotal: 4.19s\tremaining: 13.7s\n",
      "234:\tlearn: 1.8535463\ttotal: 4.21s\tremaining: 13.7s\n",
      "235:\tlearn: 1.8534159\ttotal: 4.23s\tremaining: 13.7s\n",
      "236:\tlearn: 1.8522909\ttotal: 4.24s\tremaining: 13.7s\n",
      "237:\tlearn: 1.8516133\ttotal: 4.26s\tremaining: 13.6s\n",
      "238:\tlearn: 1.8512367\ttotal: 4.28s\tremaining: 13.6s\n",
      "239:\tlearn: 1.8509131\ttotal: 4.29s\tremaining: 13.6s\n",
      "240:\tlearn: 1.8502461\ttotal: 4.31s\tremaining: 13.6s\n",
      "241:\tlearn: 1.8495338\ttotal: 4.33s\tremaining: 13.6s\n",
      "242:\tlearn: 1.8479457\ttotal: 4.35s\tremaining: 13.5s\n",
      "243:\tlearn: 1.8472134\ttotal: 4.36s\tremaining: 13.5s\n",
      "244:\tlearn: 1.8470181\ttotal: 4.38s\tremaining: 13.5s\n",
      "245:\tlearn: 1.8462283\ttotal: 4.4s\tremaining: 13.5s\n",
      "246:\tlearn: 1.8452517\ttotal: 4.42s\tremaining: 13.5s\n",
      "247:\tlearn: 1.8443376\ttotal: 4.44s\tremaining: 13.5s\n",
      "248:\tlearn: 1.8435179\ttotal: 4.45s\tremaining: 13.4s\n",
      "249:\tlearn: 1.8434509\ttotal: 4.47s\tremaining: 13.4s\n",
      "250:\tlearn: 1.8425094\ttotal: 4.49s\tremaining: 13.4s\n",
      "251:\tlearn: 1.8419361\ttotal: 4.51s\tremaining: 13.4s\n",
      "252:\tlearn: 1.8414748\ttotal: 4.52s\tremaining: 13.4s\n",
      "253:\tlearn: 1.8400368\ttotal: 4.54s\tremaining: 13.3s\n",
      "254:\tlearn: 1.8398776\ttotal: 4.56s\tremaining: 13.3s\n",
      "255:\tlearn: 1.8397375\ttotal: 4.58s\tremaining: 13.3s\n",
      "256:\tlearn: 1.8395893\ttotal: 4.6s\tremaining: 13.3s\n",
      "257:\tlearn: 1.8393136\ttotal: 4.62s\tremaining: 13.3s\n",
      "258:\tlearn: 1.8392001\ttotal: 4.63s\tremaining: 13.3s\n",
      "259:\tlearn: 1.8381785\ttotal: 4.67s\tremaining: 13.3s\n",
      "260:\tlearn: 1.8371989\ttotal: 4.68s\tremaining: 13.3s\n",
      "261:\tlearn: 1.8365953\ttotal: 4.7s\tremaining: 13.2s\n",
      "262:\tlearn: 1.8357134\ttotal: 4.72s\tremaining: 13.2s\n",
      "263:\tlearn: 1.8352408\ttotal: 4.73s\tremaining: 13.2s\n",
      "264:\tlearn: 1.8340000\ttotal: 4.75s\tremaining: 13.2s\n",
      "265:\tlearn: 1.8330499\ttotal: 4.77s\tremaining: 13.2s\n",
      "266:\tlearn: 1.8327918\ttotal: 4.79s\tremaining: 13.1s\n",
      "267:\tlearn: 1.8327817\ttotal: 4.8s\tremaining: 13.1s\n",
      "268:\tlearn: 1.8313451\ttotal: 4.82s\tremaining: 13.1s\n",
      "269:\tlearn: 1.8305117\ttotal: 4.84s\tremaining: 13.1s\n",
      "270:\tlearn: 1.8295019\ttotal: 4.86s\tremaining: 13.1s\n",
      "271:\tlearn: 1.8287796\ttotal: 4.88s\tremaining: 13s\n",
      "272:\tlearn: 1.8281713\ttotal: 4.89s\tremaining: 13s\n",
      "273:\tlearn: 1.8268401\ttotal: 4.91s\tremaining: 13s\n",
      "274:\tlearn: 1.8245490\ttotal: 4.93s\tremaining: 13s\n",
      "275:\tlearn: 1.8233848\ttotal: 4.95s\tremaining: 13s\n",
      "276:\tlearn: 1.8229835\ttotal: 4.96s\tremaining: 13s\n",
      "277:\tlearn: 1.8227998\ttotal: 4.98s\tremaining: 12.9s\n",
      "278:\tlearn: 1.8225979\ttotal: 5s\tremaining: 12.9s\n",
      "279:\tlearn: 1.8220904\ttotal: 5.02s\tremaining: 12.9s\n",
      "280:\tlearn: 1.8220166\ttotal: 5.04s\tremaining: 12.9s\n",
      "281:\tlearn: 1.8215671\ttotal: 5.06s\tremaining: 12.9s\n",
      "282:\tlearn: 1.8207528\ttotal: 5.07s\tremaining: 12.9s\n",
      "283:\tlearn: 1.8204759\ttotal: 5.09s\tremaining: 12.8s\n",
      "284:\tlearn: 1.8203249\ttotal: 5.11s\tremaining: 12.8s\n",
      "285:\tlearn: 1.8196582\ttotal: 5.13s\tremaining: 12.8s\n",
      "286:\tlearn: 1.8188473\ttotal: 5.14s\tremaining: 12.8s\n",
      "287:\tlearn: 1.8188291\ttotal: 5.16s\tremaining: 12.8s\n",
      "288:\tlearn: 1.8186903\ttotal: 5.18s\tremaining: 12.7s\n",
      "289:\tlearn: 1.8183928\ttotal: 5.2s\tremaining: 12.7s\n",
      "290:\tlearn: 1.8177073\ttotal: 5.21s\tremaining: 12.7s\n",
      "291:\tlearn: 1.8176749\ttotal: 5.23s\tremaining: 12.7s\n",
      "292:\tlearn: 1.8176591\ttotal: 5.25s\tremaining: 12.7s\n",
      "293:\tlearn: 1.8170325\ttotal: 5.27s\tremaining: 12.7s\n",
      "294:\tlearn: 1.8168994\ttotal: 5.29s\tremaining: 12.6s\n",
      "295:\tlearn: 1.8168742\ttotal: 5.3s\tremaining: 12.6s\n",
      "296:\tlearn: 1.8168717\ttotal: 5.32s\tremaining: 12.6s\n",
      "297:\tlearn: 1.8168413\ttotal: 5.34s\tremaining: 12.6s\n",
      "298:\tlearn: 1.8157356\ttotal: 5.36s\tremaining: 12.6s\n",
      "299:\tlearn: 1.8155865\ttotal: 5.38s\tremaining: 12.5s\n",
      "300:\tlearn: 1.8154606\ttotal: 5.39s\tremaining: 12.5s\n",
      "301:\tlearn: 1.8154045\ttotal: 5.41s\tremaining: 12.5s\n",
      "302:\tlearn: 1.8152173\ttotal: 5.43s\tremaining: 12.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303:\tlearn: 1.8149142\ttotal: 5.45s\tremaining: 12.5s\n",
      "304:\tlearn: 1.8142967\ttotal: 5.47s\tremaining: 12.5s\n",
      "305:\tlearn: 1.8142815\ttotal: 5.48s\tremaining: 12.4s\n",
      "306:\tlearn: 1.8136887\ttotal: 5.5s\tremaining: 12.4s\n",
      "307:\tlearn: 1.8128219\ttotal: 5.52s\tremaining: 12.4s\n",
      "308:\tlearn: 1.8113340\ttotal: 5.54s\tremaining: 12.4s\n",
      "309:\tlearn: 1.8107824\ttotal: 5.55s\tremaining: 12.4s\n",
      "310:\tlearn: 1.8100839\ttotal: 5.57s\tremaining: 12.3s\n",
      "311:\tlearn: 1.8093794\ttotal: 5.59s\tremaining: 12.3s\n",
      "312:\tlearn: 1.8084826\ttotal: 5.61s\tremaining: 12.3s\n",
      "313:\tlearn: 1.8082373\ttotal: 5.62s\tremaining: 12.3s\n",
      "314:\tlearn: 1.8077990\ttotal: 5.64s\tremaining: 12.3s\n",
      "315:\tlearn: 1.8077766\ttotal: 5.66s\tremaining: 12.3s\n",
      "316:\tlearn: 1.8069710\ttotal: 5.68s\tremaining: 12.2s\n",
      "317:\tlearn: 1.8059846\ttotal: 5.69s\tremaining: 12.2s\n",
      "318:\tlearn: 1.8049258\ttotal: 5.71s\tremaining: 12.2s\n",
      "319:\tlearn: 1.8043324\ttotal: 5.73s\tremaining: 12.2s\n",
      "320:\tlearn: 1.8034837\ttotal: 5.75s\tremaining: 12.2s\n",
      "321:\tlearn: 1.8029842\ttotal: 5.77s\tremaining: 12.1s\n",
      "322:\tlearn: 1.8024648\ttotal: 5.78s\tremaining: 12.1s\n",
      "323:\tlearn: 1.8021273\ttotal: 5.8s\tremaining: 12.1s\n",
      "324:\tlearn: 1.8021262\ttotal: 5.82s\tremaining: 12.1s\n",
      "325:\tlearn: 1.8021194\ttotal: 5.83s\tremaining: 12.1s\n",
      "326:\tlearn: 1.8021106\ttotal: 5.85s\tremaining: 12s\n",
      "327:\tlearn: 1.8016701\ttotal: 5.87s\tremaining: 12s\n",
      "328:\tlearn: 1.8007070\ttotal: 5.89s\tremaining: 12s\n",
      "329:\tlearn: 1.7993552\ttotal: 5.91s\tremaining: 12s\n",
      "330:\tlearn: 1.7984531\ttotal: 5.92s\tremaining: 12s\n",
      "331:\tlearn: 1.7980068\ttotal: 5.94s\tremaining: 12s\n",
      "332:\tlearn: 1.7966227\ttotal: 5.96s\tremaining: 11.9s\n",
      "333:\tlearn: 1.7965378\ttotal: 5.98s\tremaining: 11.9s\n",
      "334:\tlearn: 1.7954117\ttotal: 5.99s\tremaining: 11.9s\n",
      "335:\tlearn: 1.7949064\ttotal: 6.01s\tremaining: 11.9s\n",
      "336:\tlearn: 1.7943672\ttotal: 6.03s\tremaining: 11.9s\n",
      "337:\tlearn: 1.7933856\ttotal: 6.05s\tremaining: 11.8s\n",
      "338:\tlearn: 1.7930651\ttotal: 6.07s\tremaining: 11.8s\n",
      "339:\tlearn: 1.7929690\ttotal: 6.08s\tremaining: 11.8s\n",
      "340:\tlearn: 1.7927526\ttotal: 6.1s\tremaining: 11.8s\n",
      "341:\tlearn: 1.7925562\ttotal: 6.12s\tremaining: 11.8s\n",
      "342:\tlearn: 1.7923408\ttotal: 6.14s\tremaining: 11.8s\n",
      "343:\tlearn: 1.7920615\ttotal: 6.16s\tremaining: 11.7s\n",
      "344:\tlearn: 1.7909520\ttotal: 6.17s\tremaining: 11.7s\n",
      "345:\tlearn: 1.7901912\ttotal: 6.19s\tremaining: 11.7s\n",
      "346:\tlearn: 1.7892391\ttotal: 6.21s\tremaining: 11.7s\n",
      "347:\tlearn: 1.7885900\ttotal: 6.23s\tremaining: 11.7s\n",
      "348:\tlearn: 1.7881704\ttotal: 6.25s\tremaining: 11.7s\n",
      "349:\tlearn: 1.7873722\ttotal: 6.26s\tremaining: 11.6s\n",
      "350:\tlearn: 1.7872712\ttotal: 6.28s\tremaining: 11.6s\n",
      "351:\tlearn: 1.7872091\ttotal: 6.3s\tremaining: 11.6s\n",
      "352:\tlearn: 1.7872072\ttotal: 6.32s\tremaining: 11.6s\n",
      "353:\tlearn: 1.7872041\ttotal: 6.33s\tremaining: 11.6s\n",
      "354:\tlearn: 1.7871028\ttotal: 6.35s\tremaining: 11.5s\n",
      "355:\tlearn: 1.7871004\ttotal: 6.37s\tremaining: 11.5s\n",
      "356:\tlearn: 1.7870983\ttotal: 6.39s\tremaining: 11.5s\n",
      "357:\tlearn: 1.7859547\ttotal: 6.41s\tremaining: 11.5s\n",
      "358:\tlearn: 1.7852089\ttotal: 6.42s\tremaining: 11.5s\n",
      "359:\tlearn: 1.7848231\ttotal: 6.44s\tremaining: 11.4s\n",
      "360:\tlearn: 1.7846729\ttotal: 6.46s\tremaining: 11.4s\n",
      "361:\tlearn: 1.7842862\ttotal: 6.47s\tremaining: 11.4s\n",
      "362:\tlearn: 1.7842848\ttotal: 6.49s\tremaining: 11.4s\n",
      "363:\tlearn: 1.7842840\ttotal: 6.51s\tremaining: 11.4s\n",
      "364:\tlearn: 1.7842831\ttotal: 6.53s\tremaining: 11.4s\n",
      "365:\tlearn: 1.7842827\ttotal: 6.55s\tremaining: 11.3s\n",
      "366:\tlearn: 1.7842823\ttotal: 6.57s\tremaining: 11.3s\n",
      "367:\tlearn: 1.7841609\ttotal: 6.58s\tremaining: 11.3s\n",
      "368:\tlearn: 1.7841602\ttotal: 6.6s\tremaining: 11.3s\n",
      "369:\tlearn: 1.7841600\ttotal: 6.62s\tremaining: 11.3s\n",
      "370:\tlearn: 1.7841593\ttotal: 6.63s\tremaining: 11.2s\n",
      "371:\tlearn: 1.7841592\ttotal: 6.65s\tremaining: 11.2s\n",
      "372:\tlearn: 1.7841550\ttotal: 6.67s\tremaining: 11.2s\n",
      "373:\tlearn: 1.7840570\ttotal: 6.68s\tremaining: 11.2s\n",
      "374:\tlearn: 1.7840477\ttotal: 6.7s\tremaining: 11.2s\n",
      "375:\tlearn: 1.7840472\ttotal: 6.72s\tremaining: 11.2s\n",
      "376:\tlearn: 1.7840469\ttotal: 6.74s\tremaining: 11.1s\n",
      "377:\tlearn: 1.7831453\ttotal: 6.76s\tremaining: 11.1s\n",
      "378:\tlearn: 1.7831424\ttotal: 6.77s\tremaining: 11.1s\n",
      "379:\tlearn: 1.7830564\ttotal: 6.79s\tremaining: 11.1s\n",
      "380:\tlearn: 1.7829583\ttotal: 6.81s\tremaining: 11.1s\n",
      "381:\tlearn: 1.7811121\ttotal: 6.83s\tremaining: 11s\n",
      "382:\tlearn: 1.7809592\ttotal: 6.84s\tremaining: 11s\n",
      "383:\tlearn: 1.7803724\ttotal: 6.86s\tremaining: 11s\n",
      "384:\tlearn: 1.7799479\ttotal: 6.88s\tremaining: 11s\n",
      "385:\tlearn: 1.7797670\ttotal: 6.89s\tremaining: 11s\n",
      "386:\tlearn: 1.7791005\ttotal: 6.91s\tremaining: 10.9s\n",
      "387:\tlearn: 1.7790908\ttotal: 6.93s\tremaining: 10.9s\n",
      "388:\tlearn: 1.7790545\ttotal: 6.95s\tremaining: 10.9s\n",
      "389:\tlearn: 1.7789998\ttotal: 6.96s\tremaining: 10.9s\n",
      "390:\tlearn: 1.7770243\ttotal: 6.98s\tremaining: 10.9s\n",
      "391:\tlearn: 1.7770032\ttotal: 7s\tremaining: 10.9s\n",
      "392:\tlearn: 1.7762745\ttotal: 7.01s\tremaining: 10.8s\n",
      "393:\tlearn: 1.7762009\ttotal: 7.03s\tremaining: 10.8s\n",
      "394:\tlearn: 1.7749342\ttotal: 7.05s\tremaining: 10.8s\n",
      "395:\tlearn: 1.7740262\ttotal: 7.07s\tremaining: 10.8s\n",
      "396:\tlearn: 1.7725883\ttotal: 7.08s\tremaining: 10.8s\n",
      "397:\tlearn: 1.7717568\ttotal: 7.1s\tremaining: 10.7s\n",
      "398:\tlearn: 1.7716379\ttotal: 7.12s\tremaining: 10.7s\n",
      "399:\tlearn: 1.7715810\ttotal: 7.14s\tremaining: 10.7s\n",
      "400:\tlearn: 1.7712219\ttotal: 7.16s\tremaining: 10.7s\n",
      "401:\tlearn: 1.7711951\ttotal: 7.17s\tremaining: 10.7s\n",
      "402:\tlearn: 1.7699618\ttotal: 7.19s\tremaining: 10.7s\n",
      "403:\tlearn: 1.7697984\ttotal: 7.21s\tremaining: 10.6s\n",
      "404:\tlearn: 1.7697416\ttotal: 7.22s\tremaining: 10.6s\n",
      "405:\tlearn: 1.7697218\ttotal: 7.24s\tremaining: 10.6s\n",
      "406:\tlearn: 1.7697144\ttotal: 7.26s\tremaining: 10.6s\n",
      "407:\tlearn: 1.7696973\ttotal: 7.28s\tremaining: 10.6s\n",
      "408:\tlearn: 1.7693903\ttotal: 7.29s\tremaining: 10.5s\n",
      "409:\tlearn: 1.7687719\ttotal: 7.31s\tremaining: 10.5s\n",
      "410:\tlearn: 1.7687326\ttotal: 7.33s\tremaining: 10.5s\n",
      "411:\tlearn: 1.7685306\ttotal: 7.34s\tremaining: 10.5s\n",
      "412:\tlearn: 1.7676306\ttotal: 7.36s\tremaining: 10.5s\n",
      "413:\tlearn: 1.7670521\ttotal: 7.38s\tremaining: 10.5s\n",
      "414:\tlearn: 1.7663850\ttotal: 7.4s\tremaining: 10.4s\n",
      "415:\tlearn: 1.7663844\ttotal: 7.42s\tremaining: 10.4s\n",
      "416:\tlearn: 1.7663181\ttotal: 7.44s\tremaining: 10.4s\n",
      "417:\tlearn: 1.7662542\ttotal: 7.45s\tremaining: 10.4s\n",
      "418:\tlearn: 1.7657844\ttotal: 7.47s\tremaining: 10.4s\n",
      "419:\tlearn: 1.7651466\ttotal: 7.49s\tremaining: 10.3s\n",
      "420:\tlearn: 1.7651386\ttotal: 7.51s\tremaining: 10.3s\n",
      "421:\tlearn: 1.7651364\ttotal: 7.53s\tremaining: 10.3s\n",
      "422:\tlearn: 1.7651262\ttotal: 7.54s\tremaining: 10.3s\n",
      "423:\tlearn: 1.7643020\ttotal: 7.56s\tremaining: 10.3s\n",
      "424:\tlearn: 1.7642272\ttotal: 7.58s\tremaining: 10.3s\n",
      "425:\tlearn: 1.7641283\ttotal: 7.6s\tremaining: 10.2s\n",
      "426:\tlearn: 1.7639365\ttotal: 7.61s\tremaining: 10.2s\n",
      "427:\tlearn: 1.7638456\ttotal: 7.63s\tremaining: 10.2s\n",
      "428:\tlearn: 1.7637623\ttotal: 7.65s\tremaining: 10.2s\n",
      "429:\tlearn: 1.7635623\ttotal: 7.67s\tremaining: 10.2s\n",
      "430:\tlearn: 1.7634931\ttotal: 7.68s\tremaining: 10.1s\n",
      "431:\tlearn: 1.7633909\ttotal: 7.7s\tremaining: 10.1s\n",
      "432:\tlearn: 1.7631527\ttotal: 7.72s\tremaining: 10.1s\n",
      "433:\tlearn: 1.7628176\ttotal: 7.74s\tremaining: 10.1s\n",
      "434:\tlearn: 1.7625110\ttotal: 7.75s\tremaining: 10.1s\n",
      "435:\tlearn: 1.7624420\ttotal: 7.77s\tremaining: 10.1s\n",
      "436:\tlearn: 1.7624337\ttotal: 7.79s\tremaining: 10s\n",
      "437:\tlearn: 1.7624204\ttotal: 7.8s\tremaining: 10s\n",
      "438:\tlearn: 1.7623884\ttotal: 7.82s\tremaining: 10s\n",
      "439:\tlearn: 1.7623440\ttotal: 7.84s\tremaining: 9.98s\n",
      "440:\tlearn: 1.7623387\ttotal: 7.86s\tremaining: 9.96s\n",
      "441:\tlearn: 1.7623383\ttotal: 7.87s\tremaining: 9.94s\n",
      "442:\tlearn: 1.7622978\ttotal: 7.89s\tremaining: 9.92s\n",
      "443:\tlearn: 1.7618399\ttotal: 7.91s\tremaining: 9.9s\n",
      "444:\tlearn: 1.7617677\ttotal: 7.92s\tremaining: 9.88s\n",
      "445:\tlearn: 1.7616022\ttotal: 7.94s\tremaining: 9.87s\n",
      "446:\tlearn: 1.7615812\ttotal: 7.96s\tremaining: 9.85s\n",
      "447:\tlearn: 1.7615664\ttotal: 7.97s\tremaining: 9.83s\n",
      "448:\tlearn: 1.7615603\ttotal: 7.99s\tremaining: 9.81s\n",
      "449:\tlearn: 1.7603757\ttotal: 8.01s\tremaining: 9.79s\n",
      "450:\tlearn: 1.7601563\ttotal: 8.03s\tremaining: 9.78s\n",
      "451:\tlearn: 1.7599345\ttotal: 8.05s\tremaining: 9.76s\n",
      "452:\tlearn: 1.7596989\ttotal: 8.06s\tremaining: 9.74s\n",
      "453:\tlearn: 1.7595450\ttotal: 8.08s\tremaining: 9.72s\n",
      "454:\tlearn: 1.7592870\ttotal: 8.1s\tremaining: 9.7s\n",
      "455:\tlearn: 1.7589760\ttotal: 8.12s\tremaining: 9.68s\n",
      "456:\tlearn: 1.7586233\ttotal: 8.13s\tremaining: 9.67s\n",
      "457:\tlearn: 1.7584268\ttotal: 8.15s\tremaining: 9.65s\n",
      "458:\tlearn: 1.7584197\ttotal: 8.17s\tremaining: 9.63s\n",
      "459:\tlearn: 1.7584104\ttotal: 8.18s\tremaining: 9.61s\n",
      "460:\tlearn: 1.7584028\ttotal: 8.2s\tremaining: 9.59s\n",
      "461:\tlearn: 1.7582991\ttotal: 8.22s\tremaining: 9.57s\n",
      "462:\tlearn: 1.7575445\ttotal: 8.24s\tremaining: 9.56s\n",
      "463:\tlearn: 1.7569663\ttotal: 8.26s\tremaining: 9.54s\n",
      "464:\tlearn: 1.7569583\ttotal: 8.27s\tremaining: 9.52s\n",
      "465:\tlearn: 1.7568902\ttotal: 8.29s\tremaining: 9.5s\n",
      "466:\tlearn: 1.7565124\ttotal: 8.31s\tremaining: 9.48s\n",
      "467:\tlearn: 1.7564843\ttotal: 8.33s\tremaining: 9.47s\n",
      "468:\tlearn: 1.7564034\ttotal: 8.35s\tremaining: 9.45s\n",
      "469:\tlearn: 1.7560449\ttotal: 8.36s\tremaining: 9.43s\n",
      "470:\tlearn: 1.7560442\ttotal: 8.38s\tremaining: 9.41s\n",
      "471:\tlearn: 1.7560136\ttotal: 8.4s\tremaining: 9.39s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472:\tlearn: 1.7557695\ttotal: 8.41s\tremaining: 9.38s\n",
      "473:\tlearn: 1.7553185\ttotal: 8.43s\tremaining: 9.36s\n",
      "474:\tlearn: 1.7551719\ttotal: 8.45s\tremaining: 9.34s\n",
      "475:\tlearn: 1.7549059\ttotal: 8.47s\tremaining: 9.32s\n",
      "476:\tlearn: 1.7544021\ttotal: 8.49s\tremaining: 9.31s\n",
      "477:\tlearn: 1.7543940\ttotal: 8.51s\tremaining: 9.29s\n",
      "478:\tlearn: 1.7543767\ttotal: 8.52s\tremaining: 9.27s\n",
      "479:\tlearn: 1.7543757\ttotal: 8.54s\tremaining: 9.25s\n",
      "480:\tlearn: 1.7543752\ttotal: 8.56s\tremaining: 9.23s\n",
      "481:\tlearn: 1.7543742\ttotal: 8.57s\tremaining: 9.21s\n",
      "482:\tlearn: 1.7543295\ttotal: 8.59s\tremaining: 9.2s\n",
      "483:\tlearn: 1.7543187\ttotal: 8.61s\tremaining: 9.18s\n",
      "484:\tlearn: 1.7542598\ttotal: 8.63s\tremaining: 9.16s\n",
      "485:\tlearn: 1.7533241\ttotal: 8.65s\tremaining: 9.14s\n",
      "486:\tlearn: 1.7532856\ttotal: 8.66s\tremaining: 9.13s\n",
      "487:\tlearn: 1.7532782\ttotal: 8.68s\tremaining: 9.11s\n",
      "488:\tlearn: 1.7532523\ttotal: 8.7s\tremaining: 9.09s\n",
      "489:\tlearn: 1.7531935\ttotal: 8.71s\tremaining: 9.07s\n",
      "490:\tlearn: 1.7531780\ttotal: 8.73s\tremaining: 9.05s\n",
      "491:\tlearn: 1.7531712\ttotal: 8.75s\tremaining: 9.03s\n",
      "492:\tlearn: 1.7530885\ttotal: 8.77s\tremaining: 9.02s\n",
      "493:\tlearn: 1.7530527\ttotal: 8.78s\tremaining: 9s\n",
      "494:\tlearn: 1.7530367\ttotal: 8.8s\tremaining: 8.98s\n",
      "495:\tlearn: 1.7530244\ttotal: 8.82s\tremaining: 8.96s\n",
      "496:\tlearn: 1.7530172\ttotal: 8.84s\tremaining: 8.94s\n",
      "497:\tlearn: 1.7529024\ttotal: 8.85s\tremaining: 8.92s\n",
      "498:\tlearn: 1.7528579\ttotal: 8.87s\tremaining: 8.91s\n",
      "499:\tlearn: 1.7527873\ttotal: 8.89s\tremaining: 8.89s\n",
      "500:\tlearn: 1.7527537\ttotal: 8.9s\tremaining: 8.87s\n",
      "501:\tlearn: 1.7527166\ttotal: 8.92s\tremaining: 8.85s\n",
      "502:\tlearn: 1.7526143\ttotal: 8.94s\tremaining: 8.83s\n",
      "503:\tlearn: 1.7525823\ttotal: 8.96s\tremaining: 8.81s\n",
      "504:\tlearn: 1.7525746\ttotal: 8.97s\tremaining: 8.8s\n",
      "505:\tlearn: 1.7525700\ttotal: 8.99s\tremaining: 8.78s\n",
      "506:\tlearn: 1.7525700\ttotal: 9.01s\tremaining: 8.76s\n",
      "507:\tlearn: 1.7520058\ttotal: 9.03s\tremaining: 8.74s\n",
      "508:\tlearn: 1.7514377\ttotal: 9.04s\tremaining: 8.72s\n",
      "509:\tlearn: 1.7511650\ttotal: 9.06s\tremaining: 8.71s\n",
      "510:\tlearn: 1.7511319\ttotal: 9.08s\tremaining: 8.69s\n",
      "511:\tlearn: 1.7511302\ttotal: 9.1s\tremaining: 8.67s\n",
      "512:\tlearn: 1.7511299\ttotal: 9.12s\tremaining: 8.65s\n",
      "513:\tlearn: 1.7511205\ttotal: 9.13s\tremaining: 8.63s\n",
      "514:\tlearn: 1.7510868\ttotal: 9.15s\tremaining: 8.62s\n",
      "515:\tlearn: 1.7510460\ttotal: 9.17s\tremaining: 8.6s\n",
      "516:\tlearn: 1.7509688\ttotal: 9.18s\tremaining: 8.58s\n",
      "517:\tlearn: 1.7509606\ttotal: 9.2s\tremaining: 8.56s\n",
      "518:\tlearn: 1.7509489\ttotal: 9.22s\tremaining: 8.54s\n",
      "519:\tlearn: 1.7509256\ttotal: 9.23s\tremaining: 8.53s\n",
      "520:\tlearn: 1.7496631\ttotal: 9.25s\tremaining: 8.51s\n",
      "521:\tlearn: 1.7494850\ttotal: 9.27s\tremaining: 8.49s\n",
      "522:\tlearn: 1.7494476\ttotal: 9.29s\tremaining: 8.47s\n",
      "523:\tlearn: 1.7494276\ttotal: 9.31s\tremaining: 8.46s\n",
      "524:\tlearn: 1.7493859\ttotal: 9.32s\tremaining: 8.44s\n",
      "525:\tlearn: 1.7493858\ttotal: 9.34s\tremaining: 8.42s\n",
      "526:\tlearn: 1.7493857\ttotal: 9.36s\tremaining: 8.4s\n",
      "527:\tlearn: 1.7493642\ttotal: 9.38s\tremaining: 8.38s\n",
      "528:\tlearn: 1.7493115\ttotal: 9.39s\tremaining: 8.36s\n",
      "529:\tlearn: 1.7492974\ttotal: 9.41s\tremaining: 8.34s\n",
      "530:\tlearn: 1.7492841\ttotal: 9.43s\tremaining: 8.33s\n",
      "531:\tlearn: 1.7490318\ttotal: 9.45s\tremaining: 8.31s\n",
      "532:\tlearn: 1.7489594\ttotal: 9.46s\tremaining: 8.29s\n",
      "533:\tlearn: 1.7489339\ttotal: 9.48s\tremaining: 8.28s\n",
      "534:\tlearn: 1.7489287\ttotal: 9.5s\tremaining: 8.26s\n",
      "535:\tlearn: 1.7489287\ttotal: 9.52s\tremaining: 8.24s\n",
      "536:\tlearn: 1.7489287\ttotal: 9.53s\tremaining: 8.22s\n",
      "537:\tlearn: 1.7489284\ttotal: 9.55s\tremaining: 8.2s\n",
      "538:\tlearn: 1.7489283\ttotal: 9.57s\tremaining: 8.18s\n",
      "539:\tlearn: 1.7489283\ttotal: 9.58s\tremaining: 8.16s\n",
      "540:\tlearn: 1.7489280\ttotal: 9.6s\tremaining: 8.14s\n",
      "541:\tlearn: 1.7489280\ttotal: 9.62s\tremaining: 8.13s\n",
      "542:\tlearn: 1.7489279\ttotal: 9.63s\tremaining: 8.11s\n",
      "543:\tlearn: 1.7489277\ttotal: 9.65s\tremaining: 8.09s\n",
      "544:\tlearn: 1.7489274\ttotal: 9.67s\tremaining: 8.07s\n",
      "545:\tlearn: 1.7489273\ttotal: 9.69s\tremaining: 8.05s\n",
      "546:\tlearn: 1.7489253\ttotal: 9.7s\tremaining: 8.03s\n",
      "547:\tlearn: 1.7489251\ttotal: 9.72s\tremaining: 8.02s\n",
      "548:\tlearn: 1.7489246\ttotal: 9.73s\tremaining: 8s\n",
      "549:\tlearn: 1.7489242\ttotal: 9.75s\tremaining: 7.98s\n",
      "550:\tlearn: 1.7489225\ttotal: 9.77s\tremaining: 7.96s\n",
      "551:\tlearn: 1.7489213\ttotal: 9.79s\tremaining: 7.94s\n",
      "552:\tlearn: 1.7489195\ttotal: 9.8s\tremaining: 7.92s\n",
      "553:\tlearn: 1.7489143\ttotal: 9.82s\tremaining: 7.91s\n",
      "554:\tlearn: 1.7489136\ttotal: 9.84s\tremaining: 7.89s\n",
      "555:\tlearn: 1.7488953\ttotal: 9.85s\tremaining: 7.87s\n",
      "556:\tlearn: 1.7487514\ttotal: 9.87s\tremaining: 7.85s\n",
      "557:\tlearn: 1.7487288\ttotal: 9.89s\tremaining: 7.84s\n",
      "558:\tlearn: 1.7487208\ttotal: 9.91s\tremaining: 7.82s\n",
      "559:\tlearn: 1.7482841\ttotal: 9.93s\tremaining: 7.8s\n",
      "560:\tlearn: 1.7482839\ttotal: 9.94s\tremaining: 7.78s\n",
      "561:\tlearn: 1.7482422\ttotal: 9.96s\tremaining: 7.76s\n",
      "562:\tlearn: 1.7482393\ttotal: 9.98s\tremaining: 7.74s\n",
      "563:\tlearn: 1.7482272\ttotal: 9.99s\tremaining: 7.73s\n",
      "564:\tlearn: 1.7482021\ttotal: 10s\tremaining: 7.71s\n",
      "565:\tlearn: 1.7476693\ttotal: 10s\tremaining: 7.69s\n",
      "566:\tlearn: 1.7476685\ttotal: 10s\tremaining: 7.67s\n",
      "567:\tlearn: 1.7472011\ttotal: 10.1s\tremaining: 7.65s\n",
      "568:\tlearn: 1.7471765\ttotal: 10.1s\tremaining: 7.63s\n",
      "569:\tlearn: 1.7471765\ttotal: 10.1s\tremaining: 7.62s\n",
      "570:\tlearn: 1.7471701\ttotal: 10.1s\tremaining: 7.6s\n",
      "571:\tlearn: 1.7471701\ttotal: 10.1s\tremaining: 7.58s\n",
      "572:\tlearn: 1.7471700\ttotal: 10.1s\tremaining: 7.56s\n",
      "573:\tlearn: 1.7471700\ttotal: 10.2s\tremaining: 7.54s\n",
      "574:\tlearn: 1.7471517\ttotal: 10.2s\tremaining: 7.53s\n",
      "575:\tlearn: 1.7471517\ttotal: 10.2s\tremaining: 7.51s\n",
      "576:\tlearn: 1.7471019\ttotal: 10.2s\tremaining: 7.49s\n",
      "577:\tlearn: 1.7469869\ttotal: 10.2s\tremaining: 7.47s\n",
      "578:\tlearn: 1.7467625\ttotal: 10.3s\tremaining: 7.45s\n",
      "579:\tlearn: 1.7467536\ttotal: 10.3s\tremaining: 7.44s\n",
      "580:\tlearn: 1.7467536\ttotal: 10.3s\tremaining: 7.42s\n",
      "581:\tlearn: 1.7467490\ttotal: 10.3s\tremaining: 7.4s\n",
      "582:\tlearn: 1.7460683\ttotal: 10.3s\tremaining: 7.39s\n",
      "583:\tlearn: 1.7455147\ttotal: 10.3s\tremaining: 7.37s\n",
      "584:\tlearn: 1.7455144\ttotal: 10.4s\tremaining: 7.35s\n",
      "585:\tlearn: 1.7448250\ttotal: 10.4s\tremaining: 7.33s\n",
      "586:\tlearn: 1.7444366\ttotal: 10.4s\tremaining: 7.31s\n",
      "587:\tlearn: 1.7444231\ttotal: 10.4s\tremaining: 7.29s\n",
      "588:\tlearn: 1.7444217\ttotal: 10.4s\tremaining: 7.28s\n",
      "589:\tlearn: 1.7444216\ttotal: 10.4s\tremaining: 7.26s\n",
      "590:\tlearn: 1.7442924\ttotal: 10.5s\tremaining: 7.24s\n",
      "591:\tlearn: 1.7442258\ttotal: 10.5s\tremaining: 7.22s\n",
      "592:\tlearn: 1.7442078\ttotal: 10.5s\tremaining: 7.2s\n",
      "593:\tlearn: 1.7440969\ttotal: 10.5s\tremaining: 7.19s\n",
      "594:\tlearn: 1.7440523\ttotal: 10.5s\tremaining: 7.17s\n",
      "595:\tlearn: 1.7440350\ttotal: 10.6s\tremaining: 7.15s\n",
      "596:\tlearn: 1.7440107\ttotal: 10.6s\tremaining: 7.13s\n",
      "597:\tlearn: 1.7440104\ttotal: 10.6s\tremaining: 7.12s\n",
      "598:\tlearn: 1.7440104\ttotal: 10.6s\tremaining: 7.1s\n",
      "599:\tlearn: 1.7440014\ttotal: 10.6s\tremaining: 7.08s\n",
      "600:\tlearn: 1.7440009\ttotal: 10.6s\tremaining: 7.06s\n",
      "601:\tlearn: 1.7439974\ttotal: 10.7s\tremaining: 7.04s\n",
      "602:\tlearn: 1.7439619\ttotal: 10.7s\tremaining: 7.03s\n",
      "603:\tlearn: 1.7439617\ttotal: 10.7s\tremaining: 7.01s\n",
      "604:\tlearn: 1.7439617\ttotal: 10.7s\tremaining: 6.99s\n",
      "605:\tlearn: 1.7439616\ttotal: 10.7s\tremaining: 6.97s\n",
      "606:\tlearn: 1.7439615\ttotal: 10.7s\tremaining: 6.96s\n",
      "607:\tlearn: 1.7439614\ttotal: 10.8s\tremaining: 6.94s\n",
      "608:\tlearn: 1.7439612\ttotal: 10.8s\tremaining: 6.92s\n",
      "609:\tlearn: 1.7439378\ttotal: 10.8s\tremaining: 6.9s\n",
      "610:\tlearn: 1.7433648\ttotal: 10.8s\tremaining: 6.89s\n",
      "611:\tlearn: 1.7428155\ttotal: 10.8s\tremaining: 6.87s\n",
      "612:\tlearn: 1.7424188\ttotal: 10.9s\tremaining: 6.85s\n",
      "613:\tlearn: 1.7423658\ttotal: 10.9s\tremaining: 6.83s\n",
      "614:\tlearn: 1.7423579\ttotal: 10.9s\tremaining: 6.82s\n",
      "615:\tlearn: 1.7423572\ttotal: 10.9s\tremaining: 6.8s\n",
      "616:\tlearn: 1.7423572\ttotal: 10.9s\tremaining: 6.78s\n",
      "617:\tlearn: 1.7423572\ttotal: 10.9s\tremaining: 6.76s\n",
      "618:\tlearn: 1.7423572\ttotal: 11s\tremaining: 6.74s\n",
      "619:\tlearn: 1.7423567\ttotal: 11s\tremaining: 6.72s\n",
      "620:\tlearn: 1.7423489\ttotal: 11s\tremaining: 6.71s\n",
      "621:\tlearn: 1.7421100\ttotal: 11s\tremaining: 6.69s\n",
      "622:\tlearn: 1.7420363\ttotal: 11s\tremaining: 6.67s\n",
      "623:\tlearn: 1.7410083\ttotal: 11s\tremaining: 6.65s\n",
      "624:\tlearn: 1.7407440\ttotal: 11.1s\tremaining: 6.63s\n",
      "625:\tlearn: 1.7407283\ttotal: 11.1s\tremaining: 6.62s\n",
      "626:\tlearn: 1.7407281\ttotal: 11.1s\tremaining: 6.6s\n",
      "627:\tlearn: 1.7401204\ttotal: 11.1s\tremaining: 6.58s\n",
      "628:\tlearn: 1.7395555\ttotal: 11.1s\tremaining: 6.56s\n",
      "629:\tlearn: 1.7395150\ttotal: 11.1s\tremaining: 6.54s\n",
      "630:\tlearn: 1.7395088\ttotal: 11.2s\tremaining: 6.53s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631:\tlearn: 1.7395069\ttotal: 11.2s\tremaining: 6.51s\n",
      "632:\tlearn: 1.7395068\ttotal: 11.2s\tremaining: 6.49s\n",
      "633:\tlearn: 1.7395058\ttotal: 11.2s\tremaining: 6.47s\n",
      "634:\tlearn: 1.7394743\ttotal: 11.2s\tremaining: 6.46s\n",
      "635:\tlearn: 1.7394593\ttotal: 11.2s\tremaining: 6.44s\n",
      "636:\tlearn: 1.7393909\ttotal: 11.3s\tremaining: 6.42s\n",
      "637:\tlearn: 1.7390701\ttotal: 11.3s\tremaining: 6.4s\n",
      "638:\tlearn: 1.7381592\ttotal: 11.3s\tremaining: 6.38s\n",
      "639:\tlearn: 1.7373696\ttotal: 11.3s\tremaining: 6.37s\n",
      "640:\tlearn: 1.7373310\ttotal: 11.3s\tremaining: 6.35s\n",
      "641:\tlearn: 1.7373293\ttotal: 11.3s\tremaining: 6.33s\n",
      "642:\tlearn: 1.7369252\ttotal: 11.4s\tremaining: 6.31s\n",
      "643:\tlearn: 1.7360217\ttotal: 11.4s\tremaining: 6.29s\n",
      "644:\tlearn: 1.7356947\ttotal: 11.4s\tremaining: 6.28s\n",
      "645:\tlearn: 1.7356944\ttotal: 11.4s\tremaining: 6.26s\n",
      "646:\tlearn: 1.7356934\ttotal: 11.4s\tremaining: 6.24s\n",
      "647:\tlearn: 1.7356769\ttotal: 11.5s\tremaining: 6.22s\n",
      "648:\tlearn: 1.7353705\ttotal: 11.5s\tremaining: 6.2s\n",
      "649:\tlearn: 1.7353702\ttotal: 11.5s\tremaining: 6.18s\n",
      "650:\tlearn: 1.7353602\ttotal: 11.5s\tremaining: 6.17s\n",
      "651:\tlearn: 1.7353596\ttotal: 11.5s\tremaining: 6.15s\n",
      "652:\tlearn: 1.7353594\ttotal: 11.5s\tremaining: 6.13s\n",
      "653:\tlearn: 1.7353591\ttotal: 11.6s\tremaining: 6.11s\n",
      "654:\tlearn: 1.7353587\ttotal: 11.6s\tremaining: 6.09s\n",
      "655:\tlearn: 1.7353587\ttotal: 11.6s\tremaining: 6.08s\n",
      "656:\tlearn: 1.7353587\ttotal: 11.6s\tremaining: 6.06s\n",
      "657:\tlearn: 1.7353587\ttotal: 11.6s\tremaining: 6.04s\n",
      "658:\tlearn: 1.7353587\ttotal: 11.6s\tremaining: 6.02s\n",
      "659:\tlearn: 1.7353586\ttotal: 11.7s\tremaining: 6.01s\n",
      "660:\tlearn: 1.7353576\ttotal: 11.7s\tremaining: 5.99s\n",
      "661:\tlearn: 1.7353576\ttotal: 11.7s\tremaining: 5.97s\n",
      "662:\tlearn: 1.7353576\ttotal: 11.7s\tremaining: 5.95s\n",
      "663:\tlearn: 1.7353576\ttotal: 11.7s\tremaining: 5.93s\n",
      "664:\tlearn: 1.7353432\ttotal: 11.7s\tremaining: 5.92s\n",
      "665:\tlearn: 1.7353249\ttotal: 11.8s\tremaining: 5.9s\n",
      "666:\tlearn: 1.7351599\ttotal: 11.8s\tremaining: 5.88s\n",
      "667:\tlearn: 1.7351539\ttotal: 11.8s\tremaining: 5.86s\n",
      "668:\tlearn: 1.7351066\ttotal: 11.8s\tremaining: 5.85s\n",
      "669:\tlearn: 1.7346863\ttotal: 11.8s\tremaining: 5.83s\n",
      "670:\tlearn: 1.7345987\ttotal: 11.9s\tremaining: 5.81s\n",
      "671:\tlearn: 1.7340104\ttotal: 11.9s\tremaining: 5.79s\n",
      "672:\tlearn: 1.7337174\ttotal: 11.9s\tremaining: 5.78s\n",
      "673:\tlearn: 1.7329657\ttotal: 11.9s\tremaining: 5.76s\n",
      "674:\tlearn: 1.7328504\ttotal: 11.9s\tremaining: 5.74s\n",
      "675:\tlearn: 1.7328470\ttotal: 11.9s\tremaining: 5.72s\n",
      "676:\tlearn: 1.7328020\ttotal: 12s\tremaining: 5.7s\n",
      "677:\tlearn: 1.7327546\ttotal: 12s\tremaining: 5.69s\n",
      "678:\tlearn: 1.7325035\ttotal: 12s\tremaining: 5.67s\n",
      "679:\tlearn: 1.7324801\ttotal: 12s\tremaining: 5.65s\n",
      "680:\tlearn: 1.7324800\ttotal: 12s\tremaining: 5.63s\n",
      "681:\tlearn: 1.7324797\ttotal: 12s\tremaining: 5.62s\n",
      "682:\tlearn: 1.7324793\ttotal: 12.1s\tremaining: 5.6s\n",
      "683:\tlearn: 1.7324787\ttotal: 12.1s\tremaining: 5.58s\n",
      "684:\tlearn: 1.7324782\ttotal: 12.1s\tremaining: 5.56s\n",
      "685:\tlearn: 1.7324776\ttotal: 12.1s\tremaining: 5.54s\n",
      "686:\tlearn: 1.7324772\ttotal: 12.1s\tremaining: 5.53s\n",
      "687:\tlearn: 1.7324772\ttotal: 12.1s\tremaining: 5.51s\n",
      "688:\tlearn: 1.7324032\ttotal: 12.2s\tremaining: 5.49s\n",
      "689:\tlearn: 1.7322466\ttotal: 12.2s\tremaining: 5.47s\n",
      "690:\tlearn: 1.7315667\ttotal: 12.2s\tremaining: 5.45s\n",
      "691:\tlearn: 1.7315665\ttotal: 12.2s\tremaining: 5.44s\n",
      "692:\tlearn: 1.7315620\ttotal: 12.2s\tremaining: 5.42s\n",
      "693:\tlearn: 1.7315612\ttotal: 12.2s\tremaining: 5.4s\n",
      "694:\tlearn: 1.7315612\ttotal: 12.3s\tremaining: 5.38s\n",
      "695:\tlearn: 1.7315234\ttotal: 12.3s\tremaining: 5.37s\n",
      "696:\tlearn: 1.7315234\ttotal: 12.3s\tremaining: 5.35s\n",
      "697:\tlearn: 1.7315233\ttotal: 12.3s\tremaining: 5.33s\n",
      "698:\tlearn: 1.7313127\ttotal: 12.3s\tremaining: 5.31s\n",
      "699:\tlearn: 1.7313127\ttotal: 12.4s\tremaining: 5.29s\n",
      "700:\tlearn: 1.7313127\ttotal: 12.4s\tremaining: 5.28s\n",
      "701:\tlearn: 1.7312426\ttotal: 12.4s\tremaining: 5.26s\n",
      "702:\tlearn: 1.7304471\ttotal: 12.4s\tremaining: 5.24s\n",
      "703:\tlearn: 1.7295921\ttotal: 12.4s\tremaining: 5.22s\n",
      "704:\tlearn: 1.7295522\ttotal: 12.4s\tremaining: 5.21s\n",
      "705:\tlearn: 1.7295517\ttotal: 12.5s\tremaining: 5.19s\n",
      "706:\tlearn: 1.7295517\ttotal: 12.5s\tremaining: 5.17s\n",
      "707:\tlearn: 1.7295517\ttotal: 12.5s\tremaining: 5.15s\n",
      "708:\tlearn: 1.7294731\ttotal: 12.5s\tremaining: 5.13s\n",
      "709:\tlearn: 1.7294577\ttotal: 12.5s\tremaining: 5.12s\n",
      "710:\tlearn: 1.7294292\ttotal: 12.5s\tremaining: 5.1s\n",
      "711:\tlearn: 1.7291354\ttotal: 12.6s\tremaining: 5.08s\n",
      "712:\tlearn: 1.7283150\ttotal: 12.6s\tremaining: 5.06s\n",
      "713:\tlearn: 1.7283115\ttotal: 12.6s\tremaining: 5.04s\n",
      "714:\tlearn: 1.7275320\ttotal: 12.6s\tremaining: 5.03s\n",
      "715:\tlearn: 1.7274830\ttotal: 12.6s\tremaining: 5.01s\n",
      "716:\tlearn: 1.7270898\ttotal: 12.6s\tremaining: 4.99s\n",
      "717:\tlearn: 1.7270719\ttotal: 12.7s\tremaining: 4.97s\n",
      "718:\tlearn: 1.7270718\ttotal: 12.7s\tremaining: 4.95s\n",
      "719:\tlearn: 1.7270693\ttotal: 12.7s\tremaining: 4.94s\n",
      "720:\tlearn: 1.7270693\ttotal: 12.7s\tremaining: 4.92s\n",
      "721:\tlearn: 1.7270528\ttotal: 12.7s\tremaining: 4.9s\n",
      "722:\tlearn: 1.7269988\ttotal: 12.7s\tremaining: 4.88s\n",
      "723:\tlearn: 1.7269860\ttotal: 12.8s\tremaining: 4.86s\n",
      "724:\tlearn: 1.7266809\ttotal: 12.8s\tremaining: 4.85s\n",
      "725:\tlearn: 1.7266429\ttotal: 12.8s\tremaining: 4.83s\n",
      "726:\tlearn: 1.7265255\ttotal: 12.8s\tremaining: 4.81s\n",
      "727:\tlearn: 1.7265254\ttotal: 12.8s\tremaining: 4.79s\n",
      "728:\tlearn: 1.7264860\ttotal: 12.8s\tremaining: 4.77s\n",
      "729:\tlearn: 1.7264668\ttotal: 12.9s\tremaining: 4.76s\n",
      "730:\tlearn: 1.7264062\ttotal: 12.9s\tremaining: 4.74s\n",
      "731:\tlearn: 1.7263994\ttotal: 12.9s\tremaining: 4.72s\n",
      "732:\tlearn: 1.7263991\ttotal: 12.9s\tremaining: 4.7s\n",
      "733:\tlearn: 1.7263842\ttotal: 12.9s\tremaining: 4.68s\n",
      "734:\tlearn: 1.7263839\ttotal: 12.9s\tremaining: 4.67s\n",
      "735:\tlearn: 1.7263824\ttotal: 13s\tremaining: 4.65s\n",
      "736:\tlearn: 1.7263198\ttotal: 13s\tremaining: 4.63s\n",
      "737:\tlearn: 1.7259420\ttotal: 13s\tremaining: 4.61s\n",
      "738:\tlearn: 1.7259199\ttotal: 13s\tremaining: 4.6s\n",
      "739:\tlearn: 1.7258819\ttotal: 13s\tremaining: 4.58s\n",
      "740:\tlearn: 1.7258812\ttotal: 13s\tremaining: 4.56s\n",
      "741:\tlearn: 1.7258811\ttotal: 13.1s\tremaining: 4.54s\n",
      "742:\tlearn: 1.7258308\ttotal: 13.1s\tremaining: 4.53s\n",
      "743:\tlearn: 1.7257512\ttotal: 13.1s\tremaining: 4.51s\n",
      "744:\tlearn: 1.7256227\ttotal: 13.1s\tremaining: 4.49s\n",
      "745:\tlearn: 1.7255443\ttotal: 13.1s\tremaining: 4.47s\n",
      "746:\tlearn: 1.7255229\ttotal: 13.2s\tremaining: 4.45s\n",
      "747:\tlearn: 1.7254917\ttotal: 13.2s\tremaining: 4.44s\n",
      "748:\tlearn: 1.7253209\ttotal: 13.2s\tremaining: 4.42s\n",
      "749:\tlearn: 1.7253175\ttotal: 13.2s\tremaining: 4.4s\n",
      "750:\tlearn: 1.7253174\ttotal: 13.2s\tremaining: 4.38s\n",
      "751:\tlearn: 1.7252893\ttotal: 13.2s\tremaining: 4.37s\n",
      "752:\tlearn: 1.7252771\ttotal: 13.3s\tremaining: 4.35s\n",
      "753:\tlearn: 1.7252740\ttotal: 13.3s\tremaining: 4.33s\n",
      "754:\tlearn: 1.7252720\ttotal: 13.3s\tremaining: 4.31s\n",
      "755:\tlearn: 1.7252716\ttotal: 13.3s\tremaining: 4.29s\n",
      "756:\tlearn: 1.7250257\ttotal: 13.3s\tremaining: 4.28s\n",
      "757:\tlearn: 1.7238413\ttotal: 13.3s\tremaining: 4.26s\n",
      "758:\tlearn: 1.7238042\ttotal: 13.4s\tremaining: 4.24s\n",
      "759:\tlearn: 1.7237703\ttotal: 13.4s\tremaining: 4.22s\n",
      "760:\tlearn: 1.7235749\ttotal: 13.4s\tremaining: 4.21s\n",
      "761:\tlearn: 1.7235652\ttotal: 13.4s\tremaining: 4.19s\n",
      "762:\tlearn: 1.7231896\ttotal: 13.4s\tremaining: 4.17s\n",
      "763:\tlearn: 1.7231753\ttotal: 13.4s\tremaining: 4.15s\n",
      "764:\tlearn: 1.7231624\ttotal: 13.5s\tremaining: 4.13s\n",
      "765:\tlearn: 1.7231063\ttotal: 13.5s\tremaining: 4.12s\n",
      "766:\tlearn: 1.7231047\ttotal: 13.5s\tremaining: 4.1s\n",
      "767:\tlearn: 1.7227991\ttotal: 13.5s\tremaining: 4.08s\n",
      "768:\tlearn: 1.7226929\ttotal: 13.5s\tremaining: 4.06s\n",
      "769:\tlearn: 1.7223178\ttotal: 13.5s\tremaining: 4.05s\n",
      "770:\tlearn: 1.7223172\ttotal: 13.6s\tremaining: 4.03s\n",
      "771:\tlearn: 1.7218181\ttotal: 13.6s\tremaining: 4.01s\n",
      "772:\tlearn: 1.7218174\ttotal: 13.6s\tremaining: 3.99s\n",
      "773:\tlearn: 1.7218087\ttotal: 13.6s\tremaining: 3.98s\n",
      "774:\tlearn: 1.7218087\ttotal: 13.6s\tremaining: 3.96s\n",
      "775:\tlearn: 1.7218076\ttotal: 13.6s\tremaining: 3.94s\n",
      "776:\tlearn: 1.7218076\ttotal: 13.7s\tremaining: 3.92s\n",
      "777:\tlearn: 1.7218058\ttotal: 13.7s\tremaining: 3.9s\n",
      "778:\tlearn: 1.7218055\ttotal: 13.7s\tremaining: 3.89s\n",
      "779:\tlearn: 1.7217909\ttotal: 13.7s\tremaining: 3.87s\n",
      "780:\tlearn: 1.7217909\ttotal: 13.7s\tremaining: 3.85s\n",
      "781:\tlearn: 1.7213589\ttotal: 13.8s\tremaining: 3.83s\n",
      "782:\tlearn: 1.7213568\ttotal: 13.8s\tremaining: 3.81s\n",
      "783:\tlearn: 1.7198187\ttotal: 13.8s\tremaining: 3.8s\n",
      "784:\tlearn: 1.7195736\ttotal: 13.8s\tremaining: 3.78s\n",
      "785:\tlearn: 1.7191727\ttotal: 13.8s\tremaining: 3.76s\n",
      "786:\tlearn: 1.7189381\ttotal: 13.8s\tremaining: 3.74s\n",
      "787:\tlearn: 1.7189259\ttotal: 13.9s\tremaining: 3.73s\n",
      "788:\tlearn: 1.7183368\ttotal: 13.9s\tremaining: 3.71s\n",
      "789:\tlearn: 1.7179197\ttotal: 13.9s\tremaining: 3.69s\n",
      "790:\tlearn: 1.7177393\ttotal: 13.9s\tremaining: 3.67s\n",
      "791:\tlearn: 1.7169027\ttotal: 13.9s\tremaining: 3.65s\n",
      "792:\tlearn: 1.7169025\ttotal: 13.9s\tremaining: 3.64s\n",
      "793:\tlearn: 1.7169025\ttotal: 14s\tremaining: 3.62s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "794:\tlearn: 1.7169025\ttotal: 14s\tremaining: 3.6s\n",
      "795:\tlearn: 1.7168869\ttotal: 14s\tremaining: 3.58s\n",
      "796:\tlearn: 1.7168865\ttotal: 14s\tremaining: 3.57s\n",
      "797:\tlearn: 1.7168718\ttotal: 14s\tremaining: 3.55s\n",
      "798:\tlearn: 1.7168070\ttotal: 14s\tremaining: 3.53s\n",
      "799:\tlearn: 1.7163368\ttotal: 14.1s\tremaining: 3.51s\n",
      "800:\tlearn: 1.7159492\ttotal: 14.1s\tremaining: 3.5s\n",
      "801:\tlearn: 1.7159414\ttotal: 14.1s\tremaining: 3.48s\n",
      "802:\tlearn: 1.7159414\ttotal: 14.1s\tremaining: 3.46s\n",
      "803:\tlearn: 1.7159403\ttotal: 14.1s\tremaining: 3.44s\n",
      "804:\tlearn: 1.7159403\ttotal: 14.1s\tremaining: 3.42s\n",
      "805:\tlearn: 1.7159385\ttotal: 14.2s\tremaining: 3.41s\n",
      "806:\tlearn: 1.7158688\ttotal: 14.2s\tremaining: 3.39s\n",
      "807:\tlearn: 1.7150822\ttotal: 14.2s\tremaining: 3.37s\n",
      "808:\tlearn: 1.7147902\ttotal: 14.2s\tremaining: 3.35s\n",
      "809:\tlearn: 1.7147901\ttotal: 14.2s\tremaining: 3.34s\n",
      "810:\tlearn: 1.7147898\ttotal: 14.2s\tremaining: 3.32s\n",
      "811:\tlearn: 1.7147897\ttotal: 14.3s\tremaining: 3.3s\n",
      "812:\tlearn: 1.7147740\ttotal: 14.3s\tremaining: 3.28s\n",
      "813:\tlearn: 1.7147696\ttotal: 14.3s\tremaining: 3.27s\n",
      "814:\tlearn: 1.7147097\ttotal: 14.3s\tremaining: 3.25s\n",
      "815:\tlearn: 1.7147064\ttotal: 14.3s\tremaining: 3.23s\n",
      "816:\tlearn: 1.7146727\ttotal: 14.3s\tremaining: 3.21s\n",
      "817:\tlearn: 1.7146725\ttotal: 14.4s\tremaining: 3.19s\n",
      "818:\tlearn: 1.7146606\ttotal: 14.4s\tremaining: 3.18s\n",
      "819:\tlearn: 1.7146367\ttotal: 14.4s\tremaining: 3.16s\n",
      "820:\tlearn: 1.7142682\ttotal: 14.4s\tremaining: 3.14s\n",
      "821:\tlearn: 1.7141721\ttotal: 14.4s\tremaining: 3.12s\n",
      "822:\tlearn: 1.7141570\ttotal: 14.4s\tremaining: 3.11s\n",
      "823:\tlearn: 1.7141565\ttotal: 14.5s\tremaining: 3.09s\n",
      "824:\tlearn: 1.7141564\ttotal: 14.5s\tremaining: 3.07s\n",
      "825:\tlearn: 1.7140566\ttotal: 14.5s\tremaining: 3.05s\n",
      "826:\tlearn: 1.7137803\ttotal: 14.5s\tremaining: 3.04s\n",
      "827:\tlearn: 1.7137543\ttotal: 14.5s\tremaining: 3.02s\n",
      "828:\tlearn: 1.7136933\ttotal: 14.5s\tremaining: 3s\n",
      "829:\tlearn: 1.7136705\ttotal: 14.6s\tremaining: 2.98s\n",
      "830:\tlearn: 1.7136703\ttotal: 14.6s\tremaining: 2.96s\n",
      "831:\tlearn: 1.7136703\ttotal: 14.6s\tremaining: 2.95s\n",
      "832:\tlearn: 1.7136673\ttotal: 14.6s\tremaining: 2.93s\n",
      "833:\tlearn: 1.7136673\ttotal: 14.6s\tremaining: 2.91s\n",
      "834:\tlearn: 1.7136662\ttotal: 14.6s\tremaining: 2.89s\n",
      "835:\tlearn: 1.7136661\ttotal: 14.7s\tremaining: 2.88s\n",
      "836:\tlearn: 1.7136661\ttotal: 14.7s\tremaining: 2.86s\n",
      "837:\tlearn: 1.7136621\ttotal: 14.7s\tremaining: 2.84s\n",
      "838:\tlearn: 1.7136621\ttotal: 14.7s\tremaining: 2.82s\n",
      "839:\tlearn: 1.7136540\ttotal: 14.7s\tremaining: 2.81s\n",
      "840:\tlearn: 1.7136379\ttotal: 14.8s\tremaining: 2.79s\n",
      "841:\tlearn: 1.7136379\ttotal: 14.8s\tremaining: 2.77s\n",
      "842:\tlearn: 1.7136379\ttotal: 14.8s\tremaining: 2.75s\n",
      "843:\tlearn: 1.7136365\ttotal: 14.8s\tremaining: 2.73s\n",
      "844:\tlearn: 1.7136364\ttotal: 14.8s\tremaining: 2.72s\n",
      "845:\tlearn: 1.7136249\ttotal: 14.8s\tremaining: 2.7s\n",
      "846:\tlearn: 1.7136240\ttotal: 14.9s\tremaining: 2.68s\n",
      "847:\tlearn: 1.7136239\ttotal: 14.9s\tremaining: 2.67s\n",
      "848:\tlearn: 1.7136067\ttotal: 14.9s\tremaining: 2.65s\n",
      "849:\tlearn: 1.7136067\ttotal: 14.9s\tremaining: 2.63s\n",
      "850:\tlearn: 1.7136067\ttotal: 14.9s\tremaining: 2.61s\n",
      "851:\tlearn: 1.7136067\ttotal: 15s\tremaining: 2.6s\n",
      "852:\tlearn: 1.7121789\ttotal: 15s\tremaining: 2.58s\n",
      "853:\tlearn: 1.7115736\ttotal: 15s\tremaining: 2.56s\n",
      "854:\tlearn: 1.7115529\ttotal: 15s\tremaining: 2.54s\n",
      "855:\tlearn: 1.7115527\ttotal: 15s\tremaining: 2.53s\n",
      "856:\tlearn: 1.7115527\ttotal: 15s\tremaining: 2.51s\n",
      "857:\tlearn: 1.7115527\ttotal: 15.1s\tremaining: 2.49s\n",
      "858:\tlearn: 1.7115527\ttotal: 15.1s\tremaining: 2.47s\n",
      "859:\tlearn: 1.7115519\ttotal: 15.1s\tremaining: 2.46s\n",
      "860:\tlearn: 1.7115506\ttotal: 15.1s\tremaining: 2.44s\n",
      "861:\tlearn: 1.7115502\ttotal: 15.1s\tremaining: 2.42s\n",
      "862:\tlearn: 1.7115500\ttotal: 15.1s\tremaining: 2.4s\n",
      "863:\tlearn: 1.7115500\ttotal: 15.2s\tremaining: 2.39s\n",
      "864:\tlearn: 1.7115500\ttotal: 15.2s\tremaining: 2.37s\n",
      "865:\tlearn: 1.7110812\ttotal: 15.2s\tremaining: 2.35s\n",
      "866:\tlearn: 1.7110524\ttotal: 15.2s\tremaining: 2.33s\n",
      "867:\tlearn: 1.7106690\ttotal: 15.2s\tremaining: 2.31s\n",
      "868:\tlearn: 1.7106505\ttotal: 15.2s\tremaining: 2.3s\n",
      "869:\tlearn: 1.7105965\ttotal: 15.3s\tremaining: 2.28s\n",
      "870:\tlearn: 1.7105871\ttotal: 15.3s\tremaining: 2.26s\n",
      "871:\tlearn: 1.7105871\ttotal: 15.3s\tremaining: 2.25s\n",
      "872:\tlearn: 1.7105597\ttotal: 15.3s\tremaining: 2.23s\n",
      "873:\tlearn: 1.7102593\ttotal: 15.3s\tremaining: 2.21s\n",
      "874:\tlearn: 1.7102322\ttotal: 15.3s\tremaining: 2.19s\n",
      "875:\tlearn: 1.7102220\ttotal: 15.4s\tremaining: 2.17s\n",
      "876:\tlearn: 1.7102220\ttotal: 15.4s\tremaining: 2.16s\n",
      "877:\tlearn: 1.7102219\ttotal: 15.4s\tremaining: 2.14s\n",
      "878:\tlearn: 1.7102214\ttotal: 15.4s\tremaining: 2.12s\n",
      "879:\tlearn: 1.7102207\ttotal: 15.4s\tremaining: 2.1s\n",
      "880:\tlearn: 1.7102207\ttotal: 15.4s\tremaining: 2.09s\n",
      "881:\tlearn: 1.7102206\ttotal: 15.5s\tremaining: 2.07s\n",
      "882:\tlearn: 1.7102206\ttotal: 15.5s\tremaining: 2.05s\n",
      "883:\tlearn: 1.7100929\ttotal: 15.5s\tremaining: 2.03s\n",
      "884:\tlearn: 1.7100262\ttotal: 15.5s\tremaining: 2.02s\n",
      "885:\tlearn: 1.7100240\ttotal: 15.5s\tremaining: 2s\n",
      "886:\tlearn: 1.7100109\ttotal: 15.6s\tremaining: 1.98s\n",
      "887:\tlearn: 1.7100108\ttotal: 15.6s\tremaining: 1.96s\n",
      "888:\tlearn: 1.7099986\ttotal: 15.6s\tremaining: 1.95s\n",
      "889:\tlearn: 1.7098744\ttotal: 15.6s\tremaining: 1.93s\n",
      "890:\tlearn: 1.7098504\ttotal: 15.6s\tremaining: 1.91s\n",
      "891:\tlearn: 1.7090856\ttotal: 15.6s\tremaining: 1.89s\n",
      "892:\tlearn: 1.7089761\ttotal: 15.6s\tremaining: 1.88s\n",
      "893:\tlearn: 1.7089419\ttotal: 15.7s\tremaining: 1.86s\n",
      "894:\tlearn: 1.7086559\ttotal: 15.7s\tremaining: 1.84s\n",
      "895:\tlearn: 1.7085835\ttotal: 15.7s\tremaining: 1.82s\n",
      "896:\tlearn: 1.7084305\ttotal: 15.7s\tremaining: 1.8s\n",
      "897:\tlearn: 1.7082241\ttotal: 15.7s\tremaining: 1.79s\n",
      "898:\tlearn: 1.7081738\ttotal: 15.7s\tremaining: 1.77s\n",
      "899:\tlearn: 1.7081392\ttotal: 15.8s\tremaining: 1.75s\n",
      "900:\tlearn: 1.7081177\ttotal: 15.8s\tremaining: 1.73s\n",
      "901:\tlearn: 1.7080764\ttotal: 15.8s\tremaining: 1.72s\n",
      "902:\tlearn: 1.7080323\ttotal: 15.8s\tremaining: 1.7s\n",
      "903:\tlearn: 1.7080036\ttotal: 15.8s\tremaining: 1.68s\n",
      "904:\tlearn: 1.7079944\ttotal: 15.8s\tremaining: 1.66s\n",
      "905:\tlearn: 1.7079939\ttotal: 15.9s\tremaining: 1.65s\n",
      "906:\tlearn: 1.7079904\ttotal: 15.9s\tremaining: 1.63s\n",
      "907:\tlearn: 1.7079843\ttotal: 15.9s\tremaining: 1.61s\n",
      "908:\tlearn: 1.7079251\ttotal: 15.9s\tremaining: 1.59s\n",
      "909:\tlearn: 1.7077511\ttotal: 15.9s\tremaining: 1.57s\n",
      "910:\tlearn: 1.7074548\ttotal: 15.9s\tremaining: 1.56s\n",
      "911:\tlearn: 1.7074536\ttotal: 16s\tremaining: 1.54s\n",
      "912:\tlearn: 1.7074235\ttotal: 16s\tremaining: 1.52s\n",
      "913:\tlearn: 1.7071550\ttotal: 16s\tremaining: 1.5s\n",
      "914:\tlearn: 1.7071473\ttotal: 16s\tremaining: 1.49s\n",
      "915:\tlearn: 1.7071425\ttotal: 16s\tremaining: 1.47s\n",
      "916:\tlearn: 1.7068653\ttotal: 16.1s\tremaining: 1.45s\n",
      "917:\tlearn: 1.7064951\ttotal: 16.1s\tremaining: 1.44s\n",
      "918:\tlearn: 1.7064818\ttotal: 16.1s\tremaining: 1.42s\n",
      "919:\tlearn: 1.7064604\ttotal: 16.1s\tremaining: 1.4s\n",
      "920:\tlearn: 1.7064472\ttotal: 16.1s\tremaining: 1.38s\n",
      "921:\tlearn: 1.7064455\ttotal: 16.1s\tremaining: 1.36s\n",
      "922:\tlearn: 1.7064005\ttotal: 16.2s\tremaining: 1.35s\n",
      "923:\tlearn: 1.7063896\ttotal: 16.2s\tremaining: 1.33s\n",
      "924:\tlearn: 1.7058838\ttotal: 16.2s\tremaining: 1.31s\n",
      "925:\tlearn: 1.7058601\ttotal: 16.2s\tremaining: 1.29s\n",
      "926:\tlearn: 1.7048198\ttotal: 16.2s\tremaining: 1.28s\n",
      "927:\tlearn: 1.7045481\ttotal: 16.2s\tremaining: 1.26s\n",
      "928:\tlearn: 1.7044466\ttotal: 16.3s\tremaining: 1.24s\n",
      "929:\tlearn: 1.7044453\ttotal: 16.3s\tremaining: 1.22s\n",
      "930:\tlearn: 1.7044452\ttotal: 16.3s\tremaining: 1.21s\n",
      "931:\tlearn: 1.7044362\ttotal: 16.3s\tremaining: 1.19s\n",
      "932:\tlearn: 1.7043916\ttotal: 16.3s\tremaining: 1.17s\n",
      "933:\tlearn: 1.7043873\ttotal: 16.3s\tremaining: 1.15s\n",
      "934:\tlearn: 1.7043873\ttotal: 16.4s\tremaining: 1.14s\n",
      "935:\tlearn: 1.7043872\ttotal: 16.4s\tremaining: 1.12s\n",
      "936:\tlearn: 1.7043869\ttotal: 16.4s\tremaining: 1.1s\n",
      "937:\tlearn: 1.7043816\ttotal: 16.4s\tremaining: 1.08s\n",
      "938:\tlearn: 1.7042279\ttotal: 16.4s\tremaining: 1.07s\n",
      "939:\tlearn: 1.7042098\ttotal: 16.4s\tremaining: 1.05s\n",
      "940:\tlearn: 1.7041801\ttotal: 16.5s\tremaining: 1.03s\n",
      "941:\tlearn: 1.7041514\ttotal: 16.5s\tremaining: 1.01s\n",
      "942:\tlearn: 1.7041493\ttotal: 16.5s\tremaining: 997ms\n",
      "943:\tlearn: 1.7041491\ttotal: 16.5s\tremaining: 979ms\n",
      "944:\tlearn: 1.7040723\ttotal: 16.5s\tremaining: 962ms\n",
      "945:\tlearn: 1.7040629\ttotal: 16.5s\tremaining: 944ms\n",
      "946:\tlearn: 1.7038990\ttotal: 16.6s\tremaining: 927ms\n",
      "947:\tlearn: 1.7038681\ttotal: 16.6s\tremaining: 909ms\n",
      "948:\tlearn: 1.7038473\ttotal: 16.6s\tremaining: 892ms\n",
      "949:\tlearn: 1.7036391\ttotal: 16.6s\tremaining: 874ms\n",
      "950:\tlearn: 1.7036317\ttotal: 16.6s\tremaining: 857ms\n",
      "951:\tlearn: 1.7035953\ttotal: 16.6s\tremaining: 839ms\n",
      "952:\tlearn: 1.7035841\ttotal: 16.7s\tremaining: 822ms\n",
      "953:\tlearn: 1.7035792\ttotal: 16.7s\tremaining: 804ms\n",
      "954:\tlearn: 1.7033889\ttotal: 16.7s\tremaining: 787ms\n",
      "955:\tlearn: 1.7032461\ttotal: 16.7s\tremaining: 769ms\n",
      "956:\tlearn: 1.7032171\ttotal: 16.7s\tremaining: 752ms\n",
      "957:\tlearn: 1.7031892\ttotal: 16.7s\tremaining: 734ms\n",
      "958:\tlearn: 1.7031727\ttotal: 16.8s\tremaining: 717ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "959:\tlearn: 1.7031264\ttotal: 16.8s\tremaining: 699ms\n",
      "960:\tlearn: 1.7031119\ttotal: 16.8s\tremaining: 682ms\n",
      "961:\tlearn: 1.7031119\ttotal: 16.8s\tremaining: 664ms\n",
      "962:\tlearn: 1.7031112\ttotal: 16.8s\tremaining: 647ms\n",
      "963:\tlearn: 1.7030886\ttotal: 16.9s\tremaining: 629ms\n",
      "964:\tlearn: 1.7030847\ttotal: 16.9s\tremaining: 612ms\n",
      "965:\tlearn: 1.7030829\ttotal: 16.9s\tremaining: 594ms\n",
      "966:\tlearn: 1.7030829\ttotal: 16.9s\tremaining: 577ms\n",
      "967:\tlearn: 1.7030829\ttotal: 16.9s\tremaining: 559ms\n",
      "968:\tlearn: 1.7030817\ttotal: 16.9s\tremaining: 542ms\n",
      "969:\tlearn: 1.7030817\ttotal: 17s\tremaining: 524ms\n",
      "970:\tlearn: 1.7030817\ttotal: 17s\tremaining: 507ms\n",
      "971:\tlearn: 1.7030817\ttotal: 17s\tremaining: 489ms\n",
      "972:\tlearn: 1.7030817\ttotal: 17s\tremaining: 472ms\n",
      "973:\tlearn: 1.7030817\ttotal: 17s\tremaining: 454ms\n",
      "974:\tlearn: 1.7030740\ttotal: 17s\tremaining: 437ms\n",
      "975:\tlearn: 1.7029180\ttotal: 17.1s\tremaining: 419ms\n",
      "976:\tlearn: 1.7029104\ttotal: 17.1s\tremaining: 402ms\n",
      "977:\tlearn: 1.7028819\ttotal: 17.1s\tremaining: 384ms\n",
      "978:\tlearn: 1.7028817\ttotal: 17.1s\tremaining: 367ms\n",
      "979:\tlearn: 1.7028469\ttotal: 17.1s\tremaining: 349ms\n",
      "980:\tlearn: 1.7028469\ttotal: 17.1s\tremaining: 332ms\n",
      "981:\tlearn: 1.7028462\ttotal: 17.2s\tremaining: 314ms\n",
      "982:\tlearn: 1.7028310\ttotal: 17.2s\tremaining: 297ms\n",
      "983:\tlearn: 1.7028127\ttotal: 17.2s\tremaining: 279ms\n",
      "984:\tlearn: 1.7028113\ttotal: 17.2s\tremaining: 262ms\n",
      "985:\tlearn: 1.7027115\ttotal: 17.2s\tremaining: 244ms\n",
      "986:\tlearn: 1.7020938\ttotal: 17.2s\tremaining: 227ms\n",
      "987:\tlearn: 1.7017415\ttotal: 17.3s\tremaining: 210ms\n",
      "988:\tlearn: 1.7017369\ttotal: 17.3s\tremaining: 192ms\n",
      "989:\tlearn: 1.7017311\ttotal: 17.3s\tremaining: 175ms\n",
      "990:\tlearn: 1.7017280\ttotal: 17.3s\tremaining: 157ms\n",
      "991:\tlearn: 1.7004403\ttotal: 17.3s\tremaining: 140ms\n",
      "992:\tlearn: 1.7004376\ttotal: 17.3s\tremaining: 122ms\n",
      "993:\tlearn: 1.6997987\ttotal: 17.3s\tremaining: 105ms\n",
      "994:\tlearn: 1.6997655\ttotal: 17.4s\tremaining: 87.3ms\n",
      "995:\tlearn: 1.6997203\ttotal: 17.4s\tremaining: 69.8ms\n",
      "996:\tlearn: 1.6997203\ttotal: 17.4s\tremaining: 52.4ms\n",
      "997:\tlearn: 1.6997202\ttotal: 17.4s\tremaining: 34.9ms\n",
      "998:\tlearn: 1.6997202\ttotal: 17.4s\tremaining: 17.4ms\n",
      "999:\tlearn: 1.6996980\ttotal: 17.4s\tremaining: 0us\n",
      "0:\tlearn: 13.7713727\ttotal: 12.3ms\tremaining: 56.7s\n",
      "1:\tlearn: 12.4627226\ttotal: 25.8ms\tremaining: 59.2s\n",
      "2:\tlearn: 11.3163192\ttotal: 39.3ms\tremaining: 1m\n",
      "3:\tlearn: 10.3077997\ttotal: 53.5ms\tremaining: 1m 1s\n",
      "4:\tlearn: 9.4119597\ttotal: 69.3ms\tremaining: 1m 3s\n",
      "5:\tlearn: 8.6471550\ttotal: 83.1ms\tremaining: 1m 3s\n",
      "6:\tlearn: 7.9761170\ttotal: 97.4ms\tremaining: 1m 3s\n",
      "7:\tlearn: 7.4040104\ttotal: 112ms\tremaining: 1m 4s\n",
      "8:\tlearn: 6.9154962\ttotal: 126ms\tremaining: 1m 4s\n",
      "9:\tlearn: 6.4912390\ttotal: 141ms\tremaining: 1m 4s\n",
      "10:\tlearn: 6.1370313\ttotal: 156ms\tremaining: 1m 4s\n",
      "11:\tlearn: 5.8360267\ttotal: 170ms\tremaining: 1m 4s\n",
      "12:\tlearn: 5.5842031\ttotal: 184ms\tremaining: 1m 5s\n",
      "13:\tlearn: 5.3656119\ttotal: 200ms\tremaining: 1m 5s\n",
      "14:\tlearn: 5.1783211\ttotal: 215ms\tremaining: 1m 5s\n",
      "15:\tlearn: 5.0231016\ttotal: 230ms\tremaining: 1m 5s\n",
      "16:\tlearn: 4.8940370\ttotal: 244ms\tremaining: 1m 5s\n",
      "17:\tlearn: 4.7857553\ttotal: 258ms\tremaining: 1m 5s\n",
      "18:\tlearn: 4.6941053\ttotal: 273ms\tremaining: 1m 5s\n",
      "19:\tlearn: 4.6146687\ttotal: 290ms\tremaining: 1m 6s\n",
      "20:\tlearn: 4.5469645\ttotal: 305ms\tremaining: 1m 6s\n",
      "21:\tlearn: 4.4959278\ttotal: 320ms\tremaining: 1m 6s\n",
      "22:\tlearn: 4.4484756\ttotal: 335ms\tremaining: 1m 6s\n",
      "23:\tlearn: 4.4045257\ttotal: 349ms\tremaining: 1m 6s\n",
      "24:\tlearn: 4.3704478\ttotal: 364ms\tremaining: 1m 6s\n",
      "25:\tlearn: 4.3429791\ttotal: 379ms\tremaining: 1m 6s\n",
      "26:\tlearn: 4.3150285\ttotal: 393ms\tremaining: 1m 6s\n",
      "27:\tlearn: 4.2924996\ttotal: 407ms\tremaining: 1m 6s\n",
      "28:\tlearn: 4.2694313\ttotal: 421ms\tremaining: 1m 6s\n",
      "29:\tlearn: 4.2518388\ttotal: 435ms\tremaining: 1m 6s\n",
      "30:\tlearn: 4.2347480\ttotal: 449ms\tremaining: 1m 6s\n",
      "31:\tlearn: 4.2216545\ttotal: 463ms\tremaining: 1m 6s\n",
      "32:\tlearn: 4.2059620\ttotal: 479ms\tremaining: 1m 6s\n",
      "33:\tlearn: 4.1958194\ttotal: 493ms\tremaining: 1m 6s\n",
      "34:\tlearn: 4.1859408\ttotal: 508ms\tremaining: 1m 6s\n",
      "35:\tlearn: 4.1771447\ttotal: 523ms\tremaining: 1m 6s\n",
      "36:\tlearn: 4.1675226\ttotal: 537ms\tremaining: 1m 6s\n",
      "37:\tlearn: 4.1589459\ttotal: 551ms\tremaining: 1m 6s\n",
      "38:\tlearn: 4.1529033\ttotal: 564ms\tremaining: 1m 5s\n",
      "39:\tlearn: 4.1458440\ttotal: 577ms\tremaining: 1m 5s\n",
      "40:\tlearn: 4.1386728\ttotal: 591ms\tremaining: 1m 5s\n",
      "41:\tlearn: 4.1270176\ttotal: 606ms\tremaining: 1m 5s\n",
      "42:\tlearn: 4.1202274\ttotal: 620ms\tremaining: 1m 5s\n",
      "43:\tlearn: 4.1128639\ttotal: 634ms\tremaining: 1m 5s\n",
      "44:\tlearn: 4.1092245\ttotal: 646ms\tremaining: 1m 5s\n",
      "45:\tlearn: 4.1025898\ttotal: 660ms\tremaining: 1m 5s\n",
      "46:\tlearn: 4.0959917\ttotal: 675ms\tremaining: 1m 5s\n",
      "47:\tlearn: 4.0855863\ttotal: 691ms\tremaining: 1m 5s\n",
      "48:\tlearn: 4.0817642\ttotal: 704ms\tremaining: 1m 5s\n",
      "49:\tlearn: 4.0762017\ttotal: 718ms\tremaining: 1m 5s\n",
      "50:\tlearn: 4.0699104\ttotal: 732ms\tremaining: 1m 5s\n",
      "51:\tlearn: 4.0653901\ttotal: 746ms\tremaining: 1m 5s\n",
      "52:\tlearn: 4.0561988\ttotal: 762ms\tremaining: 1m 5s\n",
      "53:\tlearn: 4.0483748\ttotal: 777ms\tremaining: 1m 5s\n",
      "54:\tlearn: 4.0411011\ttotal: 793ms\tremaining: 1m 5s\n",
      "55:\tlearn: 4.0371526\ttotal: 806ms\tremaining: 1m 5s\n",
      "56:\tlearn: 4.0338588\ttotal: 819ms\tremaining: 1m 5s\n",
      "57:\tlearn: 4.0301551\ttotal: 833ms\tremaining: 1m 5s\n",
      "58:\tlearn: 4.0240531\ttotal: 848ms\tremaining: 1m 5s\n",
      "59:\tlearn: 4.0206163\ttotal: 861ms\tremaining: 1m 5s\n",
      "60:\tlearn: 4.0174054\ttotal: 874ms\tremaining: 1m 5s\n",
      "61:\tlearn: 4.0138536\ttotal: 888ms\tremaining: 1m 4s\n",
      "62:\tlearn: 4.0093212\ttotal: 901ms\tremaining: 1m 4s\n",
      "63:\tlearn: 4.0046218\ttotal: 917ms\tremaining: 1m 4s\n",
      "64:\tlearn: 3.9994725\ttotal: 933ms\tremaining: 1m 5s\n",
      "65:\tlearn: 3.9967662\ttotal: 947ms\tremaining: 1m 5s\n",
      "66:\tlearn: 3.9908015\ttotal: 961ms\tremaining: 1m 5s\n",
      "67:\tlearn: 3.9865217\ttotal: 976ms\tremaining: 1m 4s\n",
      "68:\tlearn: 3.9831236\ttotal: 990ms\tremaining: 1m 4s\n",
      "69:\tlearn: 3.9786578\ttotal: 1s\tremaining: 1m 5s\n",
      "70:\tlearn: 3.9746850\ttotal: 1.02s\tremaining: 1m 5s\n",
      "71:\tlearn: 3.9684724\ttotal: 1.03s\tremaining: 1m 4s\n",
      "72:\tlearn: 3.9650772\ttotal: 1.05s\tremaining: 1m 4s\n",
      "73:\tlearn: 3.9616598\ttotal: 1.06s\tremaining: 1m 4s\n",
      "74:\tlearn: 3.9583736\ttotal: 1.08s\tremaining: 1m 4s\n",
      "75:\tlearn: 3.9551492\ttotal: 1.09s\tremaining: 1m 4s\n",
      "76:\tlearn: 3.9518671\ttotal: 1.1s\tremaining: 1m 4s\n",
      "77:\tlearn: 3.9488572\ttotal: 1.12s\tremaining: 1m 4s\n",
      "78:\tlearn: 3.9445545\ttotal: 1.13s\tremaining: 1m 4s\n",
      "79:\tlearn: 3.9405069\ttotal: 1.15s\tremaining: 1m 4s\n",
      "80:\tlearn: 3.9357891\ttotal: 1.16s\tremaining: 1m 4s\n",
      "81:\tlearn: 3.9326063\ttotal: 1.18s\tremaining: 1m 4s\n",
      "82:\tlearn: 3.9305516\ttotal: 1.19s\tremaining: 1m 4s\n",
      "83:\tlearn: 3.9271633\ttotal: 1.21s\tremaining: 1m 4s\n",
      "84:\tlearn: 3.9254238\ttotal: 1.22s\tremaining: 1m 4s\n",
      "85:\tlearn: 3.9226038\ttotal: 1.23s\tremaining: 1m 4s\n",
      "86:\tlearn: 3.9208532\ttotal: 1.25s\tremaining: 1m 4s\n",
      "87:\tlearn: 3.9175636\ttotal: 1.26s\tremaining: 1m 4s\n",
      "88:\tlearn: 3.9124848\ttotal: 1.27s\tremaining: 1m 4s\n",
      "89:\tlearn: 3.9082277\ttotal: 1.29s\tremaining: 1m 4s\n",
      "90:\tlearn: 3.9058298\ttotal: 1.3s\tremaining: 1m 4s\n",
      "91:\tlearn: 3.9032183\ttotal: 1.32s\tremaining: 1m 4s\n",
      "92:\tlearn: 3.9000383\ttotal: 1.33s\tremaining: 1m 4s\n",
      "93:\tlearn: 3.8959887\ttotal: 1.34s\tremaining: 1m 4s\n",
      "94:\tlearn: 3.8929169\ttotal: 1.36s\tremaining: 1m 4s\n",
      "95:\tlearn: 3.8903882\ttotal: 1.37s\tremaining: 1m 4s\n",
      "96:\tlearn: 3.8883342\ttotal: 1.39s\tremaining: 1m 4s\n",
      "97:\tlearn: 3.8853348\ttotal: 1.4s\tremaining: 1m 4s\n",
      "98:\tlearn: 3.8821259\ttotal: 1.42s\tremaining: 1m 4s\n",
      "99:\tlearn: 3.8794636\ttotal: 1.43s\tremaining: 1m 4s\n",
      "100:\tlearn: 3.8770856\ttotal: 1.44s\tremaining: 1m 4s\n",
      "101:\tlearn: 3.8746419\ttotal: 1.46s\tremaining: 1m 4s\n",
      "102:\tlearn: 3.8719257\ttotal: 1.47s\tremaining: 1m 4s\n",
      "103:\tlearn: 3.8650116\ttotal: 1.49s\tremaining: 1m 4s\n",
      "104:\tlearn: 3.8620930\ttotal: 1.5s\tremaining: 1m 4s\n",
      "105:\tlearn: 3.8582939\ttotal: 1.51s\tremaining: 1m 4s\n",
      "106:\tlearn: 3.8553511\ttotal: 1.53s\tremaining: 1m 4s\n",
      "107:\tlearn: 3.8520955\ttotal: 1.54s\tremaining: 1m 4s\n",
      "108:\tlearn: 3.8486430\ttotal: 1.56s\tremaining: 1m 4s\n",
      "109:\tlearn: 3.8469730\ttotal: 1.57s\tremaining: 1m 4s\n",
      "110:\tlearn: 3.8441954\ttotal: 1.59s\tremaining: 1m 4s\n",
      "111:\tlearn: 3.8414169\ttotal: 1.6s\tremaining: 1m 4s\n",
      "112:\tlearn: 3.8386564\ttotal: 1.61s\tremaining: 1m 4s\n",
      "113:\tlearn: 3.8351549\ttotal: 1.63s\tremaining: 1m 4s\n",
      "114:\tlearn: 3.8325037\ttotal: 1.65s\tremaining: 1m 4s\n",
      "115:\tlearn: 3.8297759\ttotal: 1.66s\tremaining: 1m 4s\n",
      "116:\tlearn: 3.8260430\ttotal: 1.68s\tremaining: 1m 4s\n",
      "117:\tlearn: 3.8208716\ttotal: 1.69s\tremaining: 1m 4s\n",
      "118:\tlearn: 3.8155567\ttotal: 1.7s\tremaining: 1m 4s\n",
      "119:\tlearn: 3.8115498\ttotal: 1.72s\tremaining: 1m 4s\n",
      "120:\tlearn: 3.8086815\ttotal: 1.73s\tremaining: 1m 4s\n",
      "121:\tlearn: 3.8064400\ttotal: 1.74s\tremaining: 1m 4s\n",
      "122:\tlearn: 3.8037197\ttotal: 1.76s\tremaining: 1m 3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123:\tlearn: 3.8013270\ttotal: 1.77s\tremaining: 1m 3s\n",
      "124:\tlearn: 3.7991222\ttotal: 1.79s\tremaining: 1m 3s\n",
      "125:\tlearn: 3.7965776\ttotal: 1.8s\tremaining: 1m 3s\n",
      "126:\tlearn: 3.7940420\ttotal: 1.81s\tremaining: 1m 3s\n",
      "127:\tlearn: 3.7912750\ttotal: 1.83s\tremaining: 1m 3s\n",
      "128:\tlearn: 3.7880228\ttotal: 1.84s\tremaining: 1m 3s\n",
      "129:\tlearn: 3.7858416\ttotal: 1.86s\tremaining: 1m 3s\n",
      "130:\tlearn: 3.7815116\ttotal: 1.87s\tremaining: 1m 3s\n",
      "131:\tlearn: 3.7785711\ttotal: 1.89s\tremaining: 1m 3s\n",
      "132:\tlearn: 3.7764726\ttotal: 1.9s\tremaining: 1m 3s\n",
      "133:\tlearn: 3.7738977\ttotal: 1.92s\tremaining: 1m 3s\n",
      "134:\tlearn: 3.7704388\ttotal: 1.93s\tremaining: 1m 3s\n",
      "135:\tlearn: 3.7673566\ttotal: 1.95s\tremaining: 1m 3s\n",
      "136:\tlearn: 3.7644987\ttotal: 1.96s\tremaining: 1m 3s\n",
      "137:\tlearn: 3.7621901\ttotal: 1.97s\tremaining: 1m 3s\n",
      "138:\tlearn: 3.7605752\ttotal: 1.99s\tremaining: 1m 3s\n",
      "139:\tlearn: 3.7588800\ttotal: 2s\tremaining: 1m 3s\n",
      "140:\tlearn: 3.7562731\ttotal: 2.02s\tremaining: 1m 3s\n",
      "141:\tlearn: 3.7541594\ttotal: 2.03s\tremaining: 1m 3s\n",
      "142:\tlearn: 3.7521369\ttotal: 2.05s\tremaining: 1m 3s\n",
      "143:\tlearn: 3.7505644\ttotal: 2.06s\tremaining: 1m 3s\n",
      "144:\tlearn: 3.7477707\ttotal: 2.08s\tremaining: 1m 3s\n",
      "145:\tlearn: 3.7453568\ttotal: 2.09s\tremaining: 1m 3s\n",
      "146:\tlearn: 3.7431610\ttotal: 2.1s\tremaining: 1m 3s\n",
      "147:\tlearn: 3.7401028\ttotal: 2.12s\tremaining: 1m 3s\n",
      "148:\tlearn: 3.7374895\ttotal: 2.13s\tremaining: 1m 3s\n",
      "149:\tlearn: 3.7346512\ttotal: 2.14s\tremaining: 1m 3s\n",
      "150:\tlearn: 3.7326031\ttotal: 2.16s\tremaining: 1m 3s\n",
      "151:\tlearn: 3.7310643\ttotal: 2.17s\tremaining: 1m 3s\n",
      "152:\tlearn: 3.7287680\ttotal: 2.19s\tremaining: 1m 3s\n",
      "153:\tlearn: 3.7261286\ttotal: 2.2s\tremaining: 1m 3s\n",
      "154:\tlearn: 3.7240544\ttotal: 2.22s\tremaining: 1m 3s\n",
      "155:\tlearn: 3.7210702\ttotal: 2.23s\tremaining: 1m 3s\n",
      "156:\tlearn: 3.7190873\ttotal: 2.24s\tremaining: 1m 3s\n",
      "157:\tlearn: 3.7173684\ttotal: 2.26s\tremaining: 1m 3s\n",
      "158:\tlearn: 3.7155965\ttotal: 2.27s\tremaining: 1m 3s\n",
      "159:\tlearn: 3.7121044\ttotal: 2.29s\tremaining: 1m 3s\n",
      "160:\tlearn: 3.7104165\ttotal: 2.3s\tremaining: 1m 3s\n",
      "161:\tlearn: 3.7071676\ttotal: 2.31s\tremaining: 1m 3s\n",
      "162:\tlearn: 3.7049723\ttotal: 2.33s\tremaining: 1m 3s\n",
      "163:\tlearn: 3.7022202\ttotal: 2.34s\tremaining: 1m 3s\n",
      "164:\tlearn: 3.6984886\ttotal: 2.36s\tremaining: 1m 3s\n",
      "165:\tlearn: 3.6961633\ttotal: 2.37s\tremaining: 1m 3s\n",
      "166:\tlearn: 3.6920860\ttotal: 2.39s\tremaining: 1m 3s\n",
      "167:\tlearn: 3.6902906\ttotal: 2.4s\tremaining: 1m 3s\n",
      "168:\tlearn: 3.6882536\ttotal: 2.42s\tremaining: 1m 3s\n",
      "169:\tlearn: 3.6859582\ttotal: 2.43s\tremaining: 1m 3s\n",
      "170:\tlearn: 3.6834957\ttotal: 2.45s\tremaining: 1m 3s\n",
      "171:\tlearn: 3.6810985\ttotal: 2.46s\tremaining: 1m 3s\n",
      "172:\tlearn: 3.6792759\ttotal: 2.48s\tremaining: 1m 3s\n",
      "173:\tlearn: 3.6758852\ttotal: 2.49s\tremaining: 1m 3s\n",
      "174:\tlearn: 3.6738947\ttotal: 2.5s\tremaining: 1m 3s\n",
      "175:\tlearn: 3.6715256\ttotal: 2.52s\tremaining: 1m 3s\n",
      "176:\tlearn: 3.6694317\ttotal: 2.53s\tremaining: 1m 3s\n",
      "177:\tlearn: 3.6670457\ttotal: 2.55s\tremaining: 1m 3s\n",
      "178:\tlearn: 3.6657035\ttotal: 2.56s\tremaining: 1m 3s\n",
      "179:\tlearn: 3.6631035\ttotal: 2.57s\tremaining: 1m 3s\n",
      "180:\tlearn: 3.6622396\ttotal: 2.59s\tremaining: 1m 3s\n",
      "181:\tlearn: 3.6601277\ttotal: 2.6s\tremaining: 1m 3s\n",
      "182:\tlearn: 3.6586264\ttotal: 2.61s\tremaining: 1m 3s\n",
      "183:\tlearn: 3.6566463\ttotal: 2.63s\tremaining: 1m 3s\n",
      "184:\tlearn: 3.6553876\ttotal: 2.64s\tremaining: 1m 3s\n",
      "185:\tlearn: 3.6538573\ttotal: 2.66s\tremaining: 1m 3s\n",
      "186:\tlearn: 3.6508040\ttotal: 2.67s\tremaining: 1m 2s\n",
      "187:\tlearn: 3.6487172\ttotal: 2.69s\tremaining: 1m 3s\n",
      "188:\tlearn: 3.6469592\ttotal: 2.7s\tremaining: 1m 3s\n",
      "189:\tlearn: 3.6447506\ttotal: 2.71s\tremaining: 1m 2s\n",
      "190:\tlearn: 3.6422743\ttotal: 2.73s\tremaining: 1m 2s\n",
      "191:\tlearn: 3.6400919\ttotal: 2.74s\tremaining: 1m 2s\n",
      "192:\tlearn: 3.6366836\ttotal: 2.76s\tremaining: 1m 2s\n",
      "193:\tlearn: 3.6333240\ttotal: 2.77s\tremaining: 1m 2s\n",
      "194:\tlearn: 3.6310872\ttotal: 2.79s\tremaining: 1m 2s\n",
      "195:\tlearn: 3.6293991\ttotal: 2.8s\tremaining: 1m 2s\n",
      "196:\tlearn: 3.6273629\ttotal: 2.81s\tremaining: 1m 2s\n",
      "197:\tlearn: 3.6247284\ttotal: 2.83s\tremaining: 1m 2s\n",
      "198:\tlearn: 3.6226851\ttotal: 2.84s\tremaining: 1m 2s\n",
      "199:\tlearn: 3.6202496\ttotal: 2.86s\tremaining: 1m 2s\n",
      "200:\tlearn: 3.6181643\ttotal: 2.87s\tremaining: 1m 2s\n",
      "201:\tlearn: 3.6157321\ttotal: 2.89s\tremaining: 1m 2s\n",
      "202:\tlearn: 3.6133620\ttotal: 2.9s\tremaining: 1m 2s\n",
      "203:\tlearn: 3.6117946\ttotal: 2.92s\tremaining: 1m 2s\n",
      "204:\tlearn: 3.6104405\ttotal: 2.93s\tremaining: 1m 2s\n",
      "205:\tlearn: 3.6085255\ttotal: 2.94s\tremaining: 1m 2s\n",
      "206:\tlearn: 3.6065819\ttotal: 2.96s\tremaining: 1m 2s\n",
      "207:\tlearn: 3.6046203\ttotal: 2.97s\tremaining: 1m 2s\n",
      "208:\tlearn: 3.6024599\ttotal: 2.99s\tremaining: 1m 2s\n",
      "209:\tlearn: 3.5996166\ttotal: 3s\tremaining: 1m 2s\n",
      "210:\tlearn: 3.5985526\ttotal: 3.02s\tremaining: 1m 2s\n",
      "211:\tlearn: 3.5973580\ttotal: 3.03s\tremaining: 1m 2s\n",
      "212:\tlearn: 3.5949512\ttotal: 3.04s\tremaining: 1m 2s\n",
      "213:\tlearn: 3.5929554\ttotal: 3.06s\tremaining: 1m 2s\n",
      "214:\tlearn: 3.5906825\ttotal: 3.09s\tremaining: 1m 2s\n",
      "215:\tlearn: 3.5891665\ttotal: 3.1s\tremaining: 1m 2s\n",
      "216:\tlearn: 3.5874145\ttotal: 3.12s\tremaining: 1m 2s\n",
      "217:\tlearn: 3.5855651\ttotal: 3.13s\tremaining: 1m 2s\n",
      "218:\tlearn: 3.5829384\ttotal: 3.15s\tremaining: 1m 2s\n",
      "219:\tlearn: 3.5813982\ttotal: 3.16s\tremaining: 1m 2s\n",
      "220:\tlearn: 3.5796884\ttotal: 3.18s\tremaining: 1m 2s\n",
      "221:\tlearn: 3.5778521\ttotal: 3.19s\tremaining: 1m 2s\n",
      "222:\tlearn: 3.5751771\ttotal: 3.21s\tremaining: 1m 2s\n",
      "223:\tlearn: 3.5732004\ttotal: 3.22s\tremaining: 1m 2s\n",
      "224:\tlearn: 3.5714282\ttotal: 3.23s\tremaining: 1m 2s\n",
      "225:\tlearn: 3.5684455\ttotal: 3.25s\tremaining: 1m 2s\n",
      "226:\tlearn: 3.5652562\ttotal: 3.26s\tremaining: 1m 2s\n",
      "227:\tlearn: 3.5631288\ttotal: 3.27s\tremaining: 1m 2s\n",
      "228:\tlearn: 3.5612981\ttotal: 3.29s\tremaining: 1m 2s\n",
      "229:\tlearn: 3.5599578\ttotal: 3.3s\tremaining: 1m 2s\n",
      "230:\tlearn: 3.5571094\ttotal: 3.32s\tremaining: 1m 2s\n",
      "231:\tlearn: 3.5553918\ttotal: 3.33s\tremaining: 1m 2s\n",
      "232:\tlearn: 3.5533964\ttotal: 3.35s\tremaining: 1m 2s\n",
      "233:\tlearn: 3.5517392\ttotal: 3.36s\tremaining: 1m 2s\n",
      "234:\tlearn: 3.5495652\ttotal: 3.38s\tremaining: 1m 2s\n",
      "235:\tlearn: 3.5466782\ttotal: 3.39s\tremaining: 1m 2s\n",
      "236:\tlearn: 3.5448054\ttotal: 3.4s\tremaining: 1m 2s\n",
      "237:\tlearn: 3.5430687\ttotal: 3.42s\tremaining: 1m 2s\n",
      "238:\tlearn: 3.5407755\ttotal: 3.43s\tremaining: 1m 2s\n",
      "239:\tlearn: 3.5384330\ttotal: 3.45s\tremaining: 1m 2s\n",
      "240:\tlearn: 3.5367022\ttotal: 3.46s\tremaining: 1m 2s\n",
      "241:\tlearn: 3.5349522\ttotal: 3.48s\tremaining: 1m 2s\n",
      "242:\tlearn: 3.5333938\ttotal: 3.49s\tremaining: 1m 2s\n",
      "243:\tlearn: 3.5314471\ttotal: 3.51s\tremaining: 1m 2s\n",
      "244:\tlearn: 3.5304408\ttotal: 3.52s\tremaining: 1m 2s\n",
      "245:\tlearn: 3.5279499\ttotal: 3.54s\tremaining: 1m 2s\n",
      "246:\tlearn: 3.5260048\ttotal: 3.55s\tremaining: 1m 2s\n",
      "247:\tlearn: 3.5241480\ttotal: 3.56s\tremaining: 1m 2s\n",
      "248:\tlearn: 3.5223999\ttotal: 3.58s\tremaining: 1m 2s\n",
      "249:\tlearn: 3.5206888\ttotal: 3.59s\tremaining: 1m 2s\n",
      "250:\tlearn: 3.5186790\ttotal: 3.61s\tremaining: 1m 2s\n",
      "251:\tlearn: 3.5167484\ttotal: 3.62s\tremaining: 1m 2s\n",
      "252:\tlearn: 3.5151495\ttotal: 3.64s\tremaining: 1m 2s\n",
      "253:\tlearn: 3.5129227\ttotal: 3.65s\tremaining: 1m 2s\n",
      "254:\tlearn: 3.5113493\ttotal: 3.67s\tremaining: 1m 2s\n",
      "255:\tlearn: 3.5086139\ttotal: 3.68s\tremaining: 1m 2s\n",
      "256:\tlearn: 3.5056560\ttotal: 3.69s\tremaining: 1m 2s\n",
      "257:\tlearn: 3.5035893\ttotal: 3.71s\tremaining: 1m 2s\n",
      "258:\tlearn: 3.5015185\ttotal: 3.72s\tremaining: 1m 2s\n",
      "259:\tlearn: 3.5003122\ttotal: 3.73s\tremaining: 1m 2s\n",
      "260:\tlearn: 3.4984100\ttotal: 3.75s\tremaining: 1m 2s\n",
      "261:\tlearn: 3.4965409\ttotal: 3.76s\tremaining: 1m 2s\n",
      "262:\tlearn: 3.4950075\ttotal: 3.78s\tremaining: 1m 2s\n",
      "263:\tlearn: 3.4933649\ttotal: 3.79s\tremaining: 1m 2s\n",
      "264:\tlearn: 3.4916361\ttotal: 3.81s\tremaining: 1m 2s\n",
      "265:\tlearn: 3.4904064\ttotal: 3.82s\tremaining: 1m 2s\n",
      "266:\tlearn: 3.4890834\ttotal: 3.83s\tremaining: 1m 2s\n",
      "267:\tlearn: 3.4877465\ttotal: 3.85s\tremaining: 1m 2s\n",
      "268:\tlearn: 3.4861192\ttotal: 3.86s\tremaining: 1m 2s\n",
      "269:\tlearn: 3.4849335\ttotal: 3.88s\tremaining: 1m 2s\n",
      "270:\tlearn: 3.4823062\ttotal: 3.89s\tremaining: 1m 2s\n",
      "271:\tlearn: 3.4808573\ttotal: 3.9s\tremaining: 1m 2s\n",
      "272:\tlearn: 3.4790450\ttotal: 3.92s\tremaining: 1m 2s\n",
      "273:\tlearn: 3.4766968\ttotal: 3.93s\tremaining: 1m 2s\n",
      "274:\tlearn: 3.4752603\ttotal: 3.94s\tremaining: 1m 1s\n",
      "275:\tlearn: 3.4731020\ttotal: 3.96s\tremaining: 1m 2s\n",
      "276:\tlearn: 3.4714369\ttotal: 3.97s\tremaining: 1m 2s\n",
      "277:\tlearn: 3.4705436\ttotal: 3.99s\tremaining: 1m 1s\n",
      "278:\tlearn: 3.4694862\ttotal: 4s\tremaining: 1m 1s\n",
      "279:\tlearn: 3.4683957\ttotal: 4.02s\tremaining: 1m 1s\n",
      "280:\tlearn: 3.4669933\ttotal: 4.03s\tremaining: 1m 1s\n",
      "281:\tlearn: 3.4650123\ttotal: 4.04s\tremaining: 1m 1s\n",
      "282:\tlearn: 3.4635797\ttotal: 4.06s\tremaining: 1m 1s\n",
      "283:\tlearn: 3.4621836\ttotal: 4.07s\tremaining: 1m 1s\n",
      "284:\tlearn: 3.4609882\ttotal: 4.08s\tremaining: 1m 1s\n",
      "285:\tlearn: 3.4599665\ttotal: 4.1s\tremaining: 1m 1s\n",
      "286:\tlearn: 3.4586418\ttotal: 4.11s\tremaining: 1m 1s\n",
      "287:\tlearn: 3.4572624\ttotal: 4.13s\tremaining: 1m 1s\n",
      "288:\tlearn: 3.4562046\ttotal: 4.14s\tremaining: 1m 1s\n",
      "289:\tlearn: 3.4546717\ttotal: 4.16s\tremaining: 1m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290:\tlearn: 3.4529878\ttotal: 4.17s\tremaining: 1m 1s\n",
      "291:\tlearn: 3.4510311\ttotal: 4.19s\tremaining: 1m 1s\n",
      "292:\tlearn: 3.4495125\ttotal: 4.2s\tremaining: 1m 1s\n",
      "293:\tlearn: 3.4466882\ttotal: 4.21s\tremaining: 1m 1s\n",
      "294:\tlearn: 3.4456262\ttotal: 4.23s\tremaining: 1m 1s\n",
      "295:\tlearn: 3.4432017\ttotal: 4.24s\tremaining: 1m 1s\n",
      "296:\tlearn: 3.4419464\ttotal: 4.26s\tremaining: 1m 1s\n",
      "297:\tlearn: 3.4406923\ttotal: 4.27s\tremaining: 1m 1s\n",
      "298:\tlearn: 3.4393406\ttotal: 4.28s\tremaining: 1m 1s\n",
      "299:\tlearn: 3.4379901\ttotal: 4.3s\tremaining: 1m 1s\n",
      "300:\tlearn: 3.4361256\ttotal: 4.31s\tremaining: 1m 1s\n",
      "301:\tlearn: 3.4341435\ttotal: 4.33s\tremaining: 1m 1s\n",
      "302:\tlearn: 3.4327178\ttotal: 4.34s\tremaining: 1m 1s\n",
      "303:\tlearn: 3.4308257\ttotal: 4.36s\tremaining: 1m 1s\n",
      "304:\tlearn: 3.4295193\ttotal: 4.37s\tremaining: 1m 1s\n",
      "305:\tlearn: 3.4283732\ttotal: 4.38s\tremaining: 1m 1s\n",
      "306:\tlearn: 3.4236430\ttotal: 4.4s\tremaining: 1m 1s\n",
      "307:\tlearn: 3.4222128\ttotal: 4.41s\tremaining: 1m 1s\n",
      "308:\tlearn: 3.4209612\ttotal: 4.43s\tremaining: 1m 1s\n",
      "309:\tlearn: 3.4200676\ttotal: 4.44s\tremaining: 1m 1s\n",
      "310:\tlearn: 3.4190552\ttotal: 4.46s\tremaining: 1m 1s\n",
      "311:\tlearn: 3.4171615\ttotal: 4.47s\tremaining: 1m 1s\n",
      "312:\tlearn: 3.4155054\ttotal: 4.49s\tremaining: 1m 1s\n",
      "313:\tlearn: 3.4141735\ttotal: 4.5s\tremaining: 1m 1s\n",
      "314:\tlearn: 3.4136796\ttotal: 4.51s\tremaining: 1m 1s\n",
      "315:\tlearn: 3.4121937\ttotal: 4.53s\tremaining: 1m 1s\n",
      "316:\tlearn: 3.4102985\ttotal: 4.54s\tremaining: 1m 1s\n",
      "317:\tlearn: 3.4088974\ttotal: 4.55s\tremaining: 1m 1s\n",
      "318:\tlearn: 3.4077009\ttotal: 4.57s\tremaining: 1m 1s\n",
      "319:\tlearn: 3.4060645\ttotal: 4.58s\tremaining: 1m 1s\n",
      "320:\tlearn: 3.4051505\ttotal: 4.59s\tremaining: 1m 1s\n",
      "321:\tlearn: 3.4040139\ttotal: 4.61s\tremaining: 1m 1s\n",
      "322:\tlearn: 3.4028306\ttotal: 4.63s\tremaining: 1m 1s\n",
      "323:\tlearn: 3.4006856\ttotal: 4.64s\tremaining: 1m 1s\n",
      "324:\tlearn: 3.3997839\ttotal: 4.65s\tremaining: 1m 1s\n",
      "325:\tlearn: 3.3975547\ttotal: 4.67s\tremaining: 1m 1s\n",
      "326:\tlearn: 3.3959984\ttotal: 4.68s\tremaining: 1m 1s\n",
      "327:\tlearn: 3.3920863\ttotal: 4.69s\tremaining: 1m 1s\n",
      "328:\tlearn: 3.3907296\ttotal: 4.71s\tremaining: 1m 1s\n",
      "329:\tlearn: 3.3896008\ttotal: 4.72s\tremaining: 1m 1s\n",
      "330:\tlearn: 3.3879956\ttotal: 4.73s\tremaining: 1m 1s\n",
      "331:\tlearn: 3.3863554\ttotal: 4.75s\tremaining: 1m\n",
      "332:\tlearn: 3.3851177\ttotal: 4.76s\tremaining: 1m\n",
      "333:\tlearn: 3.3838290\ttotal: 4.78s\tremaining: 1m\n",
      "334:\tlearn: 3.3830925\ttotal: 4.79s\tremaining: 1m\n",
      "335:\tlearn: 3.3819794\ttotal: 4.8s\tremaining: 1m\n",
      "336:\tlearn: 3.3804080\ttotal: 4.82s\tremaining: 1m\n",
      "337:\tlearn: 3.3792911\ttotal: 4.83s\tremaining: 1m\n",
      "338:\tlearn: 3.3780113\ttotal: 4.84s\tremaining: 1m\n",
      "339:\tlearn: 3.3769756\ttotal: 4.86s\tremaining: 1m\n",
      "340:\tlearn: 3.3749885\ttotal: 4.87s\tremaining: 1m\n",
      "341:\tlearn: 3.3737450\ttotal: 4.88s\tremaining: 1m\n",
      "342:\tlearn: 3.3726029\ttotal: 4.9s\tremaining: 1m\n",
      "343:\tlearn: 3.3713865\ttotal: 4.91s\tremaining: 1m\n",
      "344:\tlearn: 3.3693576\ttotal: 4.92s\tremaining: 1m\n",
      "345:\tlearn: 3.3680653\ttotal: 4.94s\tremaining: 1m\n",
      "346:\tlearn: 3.3661538\ttotal: 4.95s\tremaining: 1m\n",
      "347:\tlearn: 3.3649894\ttotal: 4.97s\tremaining: 1m\n",
      "348:\tlearn: 3.3637173\ttotal: 4.98s\tremaining: 1m\n",
      "349:\tlearn: 3.3632925\ttotal: 4.99s\tremaining: 1m\n",
      "350:\tlearn: 3.3622469\ttotal: 5.01s\tremaining: 1m\n",
      "351:\tlearn: 3.3612805\ttotal: 5.02s\tremaining: 1m\n",
      "352:\tlearn: 3.3592145\ttotal: 5.04s\tremaining: 1m\n",
      "353:\tlearn: 3.3575423\ttotal: 5.05s\tremaining: 1m\n",
      "354:\tlearn: 3.3558212\ttotal: 5.07s\tremaining: 1m\n",
      "355:\tlearn: 3.3541371\ttotal: 5.08s\tremaining: 1m\n",
      "356:\tlearn: 3.3531378\ttotal: 5.1s\tremaining: 1m\n",
      "357:\tlearn: 3.3522373\ttotal: 5.11s\tremaining: 1m\n",
      "358:\tlearn: 3.3509212\ttotal: 5.12s\tremaining: 1m\n",
      "359:\tlearn: 3.3496982\ttotal: 5.14s\tremaining: 1m\n",
      "360:\tlearn: 3.3481321\ttotal: 5.15s\tremaining: 1m\n",
      "361:\tlearn: 3.3480419\ttotal: 5.16s\tremaining: 1m\n",
      "362:\tlearn: 3.3469710\ttotal: 5.17s\tremaining: 1m\n",
      "363:\tlearn: 3.3462796\ttotal: 5.19s\tremaining: 1m\n",
      "364:\tlearn: 3.3454028\ttotal: 5.2s\tremaining: 1m\n",
      "365:\tlearn: 3.3441849\ttotal: 5.22s\tremaining: 1m\n",
      "366:\tlearn: 3.3427657\ttotal: 5.23s\tremaining: 1m\n",
      "367:\tlearn: 3.3414260\ttotal: 5.24s\tremaining: 1m\n",
      "368:\tlearn: 3.3404435\ttotal: 5.26s\tremaining: 1m\n",
      "369:\tlearn: 3.3388807\ttotal: 5.27s\tremaining: 1m\n",
      "370:\tlearn: 3.3375868\ttotal: 5.29s\tremaining: 1m\n",
      "371:\tlearn: 3.3364725\ttotal: 5.3s\tremaining: 1m\n",
      "372:\tlearn: 3.3364084\ttotal: 5.31s\tremaining: 1m\n",
      "373:\tlearn: 3.3352668\ttotal: 5.33s\tremaining: 1m\n",
      "374:\tlearn: 3.3338537\ttotal: 5.34s\tremaining: 1m\n",
      "375:\tlearn: 3.3315022\ttotal: 5.36s\tremaining: 1m\n",
      "376:\tlearn: 3.3301532\ttotal: 5.37s\tremaining: 1m\n",
      "377:\tlearn: 3.3288270\ttotal: 5.38s\tremaining: 1m\n",
      "378:\tlearn: 3.3276462\ttotal: 5.4s\tremaining: 1m\n",
      "379:\tlearn: 3.3269419\ttotal: 5.41s\tremaining: 1m\n",
      "380:\tlearn: 3.3253553\ttotal: 5.43s\tremaining: 1m\n",
      "381:\tlearn: 3.3237385\ttotal: 5.44s\tremaining: 1m\n",
      "382:\tlearn: 3.3229996\ttotal: 5.46s\tremaining: 1m\n",
      "383:\tlearn: 3.3216516\ttotal: 5.47s\tremaining: 1m\n",
      "384:\tlearn: 3.3207802\ttotal: 5.49s\tremaining: 1m\n",
      "385:\tlearn: 3.3196584\ttotal: 5.5s\tremaining: 1m\n",
      "386:\tlearn: 3.3181865\ttotal: 5.51s\tremaining: 60s\n",
      "387:\tlearn: 3.3165386\ttotal: 5.53s\tremaining: 60s\n",
      "388:\tlearn: 3.3155424\ttotal: 5.54s\tremaining: 60s\n",
      "389:\tlearn: 3.3142810\ttotal: 5.55s\tremaining: 59.9s\n",
      "390:\tlearn: 3.3135414\ttotal: 5.57s\tremaining: 59.9s\n",
      "391:\tlearn: 3.3123708\ttotal: 5.58s\tremaining: 59.9s\n",
      "392:\tlearn: 3.3120240\ttotal: 5.59s\tremaining: 59.8s\n",
      "393:\tlearn: 3.3103599\ttotal: 5.61s\tremaining: 59.8s\n",
      "394:\tlearn: 3.3102614\ttotal: 5.62s\tremaining: 59.8s\n",
      "395:\tlearn: 3.3088825\ttotal: 5.63s\tremaining: 59.8s\n",
      "396:\tlearn: 3.3076431\ttotal: 5.65s\tremaining: 59.8s\n",
      "397:\tlearn: 3.3064971\ttotal: 5.66s\tremaining: 59.7s\n",
      "398:\tlearn: 3.3053227\ttotal: 5.68s\tremaining: 59.7s\n",
      "399:\tlearn: 3.3047691\ttotal: 5.69s\tremaining: 59.7s\n",
      "400:\tlearn: 3.3034135\ttotal: 5.7s\tremaining: 59.7s\n",
      "401:\tlearn: 3.3022493\ttotal: 5.72s\tremaining: 59.7s\n",
      "402:\tlearn: 3.3012413\ttotal: 5.73s\tremaining: 59.7s\n",
      "403:\tlearn: 3.3001882\ttotal: 5.75s\tremaining: 59.7s\n",
      "404:\tlearn: 3.2989480\ttotal: 5.76s\tremaining: 59.6s\n",
      "405:\tlearn: 3.2976129\ttotal: 5.78s\tremaining: 59.6s\n",
      "406:\tlearn: 3.2962522\ttotal: 5.79s\tremaining: 59.6s\n",
      "407:\tlearn: 3.2952014\ttotal: 5.8s\tremaining: 59.6s\n",
      "408:\tlearn: 3.2942113\ttotal: 5.82s\tremaining: 59.6s\n",
      "409:\tlearn: 3.2928354\ttotal: 5.83s\tremaining: 59.6s\n",
      "410:\tlearn: 3.2928159\ttotal: 5.84s\tremaining: 59.5s\n",
      "411:\tlearn: 3.2916516\ttotal: 5.86s\tremaining: 59.5s\n",
      "412:\tlearn: 3.2898667\ttotal: 5.87s\tremaining: 59.5s\n",
      "413:\tlearn: 3.2890671\ttotal: 5.89s\tremaining: 59.5s\n",
      "414:\tlearn: 3.2876781\ttotal: 5.9s\tremaining: 59.5s\n",
      "415:\tlearn: 3.2868666\ttotal: 5.92s\tremaining: 59.5s\n",
      "416:\tlearn: 3.2861339\ttotal: 5.93s\tremaining: 59.5s\n",
      "417:\tlearn: 3.2841215\ttotal: 5.94s\tremaining: 59.4s\n",
      "418:\tlearn: 3.2828357\ttotal: 5.96s\tremaining: 59.4s\n",
      "419:\tlearn: 3.2808137\ttotal: 5.97s\tremaining: 59.4s\n",
      "420:\tlearn: 3.2807958\ttotal: 5.98s\tremaining: 59.4s\n",
      "421:\tlearn: 3.2797097\ttotal: 6s\tremaining: 59.4s\n",
      "422:\tlearn: 3.2787729\ttotal: 6.01s\tremaining: 59.4s\n",
      "423:\tlearn: 3.2779217\ttotal: 6.03s\tremaining: 59.4s\n",
      "424:\tlearn: 3.2772302\ttotal: 6.04s\tremaining: 59.3s\n",
      "425:\tlearn: 3.2753901\ttotal: 6.06s\tremaining: 59.3s\n",
      "426:\tlearn: 3.2743400\ttotal: 6.07s\tremaining: 59.3s\n",
      "427:\tlearn: 3.2735317\ttotal: 6.09s\tremaining: 59.3s\n",
      "428:\tlearn: 3.2721299\ttotal: 6.1s\tremaining: 59.3s\n",
      "429:\tlearn: 3.2714230\ttotal: 6.11s\tremaining: 59.3s\n",
      "430:\tlearn: 3.2700356\ttotal: 6.13s\tremaining: 59.3s\n",
      "431:\tlearn: 3.2684477\ttotal: 6.14s\tremaining: 59.3s\n",
      "432:\tlearn: 3.2673303\ttotal: 6.16s\tremaining: 59.2s\n",
      "433:\tlearn: 3.2667476\ttotal: 6.17s\tremaining: 59.2s\n",
      "434:\tlearn: 3.2653441\ttotal: 6.18s\tremaining: 59.2s\n",
      "435:\tlearn: 3.2634426\ttotal: 6.2s\tremaining: 59.2s\n",
      "436:\tlearn: 3.2620430\ttotal: 6.21s\tremaining: 59.2s\n",
      "437:\tlearn: 3.2607217\ttotal: 6.23s\tremaining: 59.2s\n",
      "438:\tlearn: 3.2598826\ttotal: 6.24s\tremaining: 59.2s\n",
      "439:\tlearn: 3.2585163\ttotal: 6.26s\tremaining: 59.1s\n",
      "440:\tlearn: 3.2577972\ttotal: 6.27s\tremaining: 59.1s\n",
      "441:\tlearn: 3.2566251\ttotal: 6.29s\tremaining: 59.1s\n",
      "442:\tlearn: 3.2549490\ttotal: 6.3s\tremaining: 59.1s\n",
      "443:\tlearn: 3.2541493\ttotal: 6.31s\tremaining: 59.1s\n",
      "444:\tlearn: 3.2531736\ttotal: 6.33s\tremaining: 59.1s\n",
      "445:\tlearn: 3.2513068\ttotal: 6.34s\tremaining: 59s\n",
      "446:\tlearn: 3.2502615\ttotal: 6.36s\tremaining: 59s\n",
      "447:\tlearn: 3.2490591\ttotal: 6.37s\tremaining: 59s\n",
      "448:\tlearn: 3.2489885\ttotal: 6.38s\tremaining: 59s\n",
      "449:\tlearn: 3.2475780\ttotal: 6.39s\tremaining: 59s\n",
      "450:\tlearn: 3.2455534\ttotal: 6.41s\tremaining: 58.9s\n",
      "451:\tlearn: 3.2444936\ttotal: 6.42s\tremaining: 58.9s\n",
      "452:\tlearn: 3.2441125\ttotal: 6.44s\tremaining: 58.9s\n",
      "453:\tlearn: 3.2433795\ttotal: 6.45s\tremaining: 58.9s\n",
      "454:\tlearn: 3.2423243\ttotal: 6.47s\tremaining: 58.9s\n",
      "455:\tlearn: 3.2413793\ttotal: 6.48s\tremaining: 58.9s\n",
      "456:\tlearn: 3.2400880\ttotal: 6.5s\tremaining: 58.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457:\tlearn: 3.2389386\ttotal: 6.53s\tremaining: 59s\n",
      "458:\tlearn: 3.2366972\ttotal: 6.55s\tremaining: 59s\n",
      "459:\tlearn: 3.2353806\ttotal: 6.56s\tremaining: 59s\n",
      "460:\tlearn: 3.2345984\ttotal: 6.58s\tremaining: 59s\n",
      "461:\tlearn: 3.2335714\ttotal: 6.59s\tremaining: 59s\n",
      "462:\tlearn: 3.2326392\ttotal: 6.61s\tremaining: 59s\n",
      "463:\tlearn: 3.2313590\ttotal: 6.62s\tremaining: 59s\n",
      "464:\tlearn: 3.2309385\ttotal: 6.64s\tremaining: 59s\n",
      "465:\tlearn: 3.2305391\ttotal: 6.65s\tremaining: 59s\n",
      "466:\tlearn: 3.2295940\ttotal: 6.66s\tremaining: 58.9s\n",
      "467:\tlearn: 3.2282652\ttotal: 6.68s\tremaining: 58.9s\n",
      "468:\tlearn: 3.2269793\ttotal: 6.69s\tremaining: 58.9s\n",
      "469:\tlearn: 3.2257384\ttotal: 6.71s\tremaining: 58.9s\n",
      "470:\tlearn: 3.2242699\ttotal: 6.72s\tremaining: 58.9s\n",
      "471:\tlearn: 3.2234235\ttotal: 6.74s\tremaining: 58.9s\n",
      "472:\tlearn: 3.2223891\ttotal: 6.75s\tremaining: 58.9s\n",
      "473:\tlearn: 3.2207674\ttotal: 6.76s\tremaining: 58.9s\n",
      "474:\tlearn: 3.2197199\ttotal: 6.78s\tremaining: 58.8s\n",
      "475:\tlearn: 3.2185027\ttotal: 6.79s\tremaining: 58.8s\n",
      "476:\tlearn: 3.2178966\ttotal: 6.8s\tremaining: 58.8s\n",
      "477:\tlearn: 3.2166489\ttotal: 6.82s\tremaining: 58.8s\n",
      "478:\tlearn: 3.2155759\ttotal: 6.83s\tremaining: 58.7s\n",
      "479:\tlearn: 3.2148611\ttotal: 6.84s\tremaining: 58.7s\n",
      "480:\tlearn: 3.2135258\ttotal: 6.86s\tremaining: 58.7s\n",
      "481:\tlearn: 3.2124853\ttotal: 6.87s\tremaining: 58.7s\n",
      "482:\tlearn: 3.2114292\ttotal: 6.88s\tremaining: 58.6s\n",
      "483:\tlearn: 3.2104235\ttotal: 6.9s\tremaining: 58.6s\n",
      "484:\tlearn: 3.2091182\ttotal: 6.91s\tremaining: 58.6s\n",
      "485:\tlearn: 3.2088249\ttotal: 6.92s\tremaining: 58.6s\n",
      "486:\tlearn: 3.2077213\ttotal: 6.94s\tremaining: 58.5s\n",
      "487:\tlearn: 3.2060021\ttotal: 6.95s\tremaining: 58.5s\n",
      "488:\tlearn: 3.2048207\ttotal: 6.96s\tremaining: 58.5s\n",
      "489:\tlearn: 3.2029504\ttotal: 6.98s\tremaining: 58.5s\n",
      "490:\tlearn: 3.2024339\ttotal: 6.99s\tremaining: 58.5s\n",
      "491:\tlearn: 3.2015718\ttotal: 7s\tremaining: 58.5s\n",
      "492:\tlearn: 3.2009688\ttotal: 7.02s\tremaining: 58.4s\n",
      "493:\tlearn: 3.1998289\ttotal: 7.03s\tremaining: 58.4s\n",
      "494:\tlearn: 3.1991197\ttotal: 7.04s\tremaining: 58.4s\n",
      "495:\tlearn: 3.1984884\ttotal: 7.06s\tremaining: 58.4s\n",
      "496:\tlearn: 3.1969027\ttotal: 7.07s\tremaining: 58.4s\n",
      "497:\tlearn: 3.1960306\ttotal: 7.08s\tremaining: 58.3s\n",
      "498:\tlearn: 3.1954262\ttotal: 7.1s\tremaining: 58.3s\n",
      "499:\tlearn: 3.1939326\ttotal: 7.11s\tremaining: 58.3s\n",
      "500:\tlearn: 3.1926183\ttotal: 7.13s\tremaining: 58.3s\n",
      "501:\tlearn: 3.1917796\ttotal: 7.14s\tremaining: 58.3s\n",
      "502:\tlearn: 3.1908029\ttotal: 7.16s\tremaining: 58.3s\n",
      "503:\tlearn: 3.1891391\ttotal: 7.17s\tremaining: 58.2s\n",
      "504:\tlearn: 3.1869278\ttotal: 7.18s\tremaining: 58.2s\n",
      "505:\tlearn: 3.1856497\ttotal: 7.2s\tremaining: 58.2s\n",
      "506:\tlearn: 3.1848815\ttotal: 7.21s\tremaining: 58.2s\n",
      "507:\tlearn: 3.1839811\ttotal: 7.23s\tremaining: 58.2s\n",
      "508:\tlearn: 3.1831252\ttotal: 7.24s\tremaining: 58.2s\n",
      "509:\tlearn: 3.1823719\ttotal: 7.25s\tremaining: 58.2s\n",
      "510:\tlearn: 3.1822943\ttotal: 7.27s\tremaining: 58.1s\n",
      "511:\tlearn: 3.1803239\ttotal: 7.28s\tremaining: 58.1s\n",
      "512:\tlearn: 3.1795797\ttotal: 7.3s\tremaining: 58.1s\n",
      "513:\tlearn: 3.1786857\ttotal: 7.31s\tremaining: 58.1s\n",
      "514:\tlearn: 3.1777768\ttotal: 7.32s\tremaining: 58.1s\n",
      "515:\tlearn: 3.1767884\ttotal: 7.34s\tremaining: 58s\n",
      "516:\tlearn: 3.1757374\ttotal: 7.35s\tremaining: 58s\n",
      "517:\tlearn: 3.1748736\ttotal: 7.37s\tremaining: 58s\n",
      "518:\tlearn: 3.1740142\ttotal: 7.38s\tremaining: 58s\n",
      "519:\tlearn: 3.1732521\ttotal: 7.39s\tremaining: 58s\n",
      "520:\tlearn: 3.1726834\ttotal: 7.41s\tremaining: 58s\n",
      "521:\tlearn: 3.1716928\ttotal: 7.42s\tremaining: 57.9s\n",
      "522:\tlearn: 3.1703201\ttotal: 7.43s\tremaining: 57.9s\n",
      "523:\tlearn: 3.1694126\ttotal: 7.45s\tremaining: 57.9s\n",
      "524:\tlearn: 3.1687387\ttotal: 7.46s\tremaining: 57.9s\n",
      "525:\tlearn: 3.1684476\ttotal: 7.48s\tremaining: 57.9s\n",
      "526:\tlearn: 3.1671371\ttotal: 7.49s\tremaining: 57.9s\n",
      "527:\tlearn: 3.1665002\ttotal: 7.51s\tremaining: 57.9s\n",
      "528:\tlearn: 3.1658536\ttotal: 7.52s\tremaining: 57.8s\n",
      "529:\tlearn: 3.1645591\ttotal: 7.53s\tremaining: 57.8s\n",
      "530:\tlearn: 3.1629142\ttotal: 7.55s\tremaining: 57.8s\n",
      "531:\tlearn: 3.1628267\ttotal: 7.56s\tremaining: 57.8s\n",
      "532:\tlearn: 3.1623349\ttotal: 7.57s\tremaining: 57.8s\n",
      "533:\tlearn: 3.1614185\ttotal: 7.59s\tremaining: 57.8s\n",
      "534:\tlearn: 3.1602025\ttotal: 7.61s\tremaining: 57.8s\n",
      "535:\tlearn: 3.1590965\ttotal: 7.63s\tremaining: 57.8s\n",
      "536:\tlearn: 3.1581326\ttotal: 7.64s\tremaining: 57.8s\n",
      "537:\tlearn: 3.1573941\ttotal: 7.66s\tremaining: 57.8s\n",
      "538:\tlearn: 3.1567450\ttotal: 7.67s\tremaining: 57.8s\n",
      "539:\tlearn: 3.1561814\ttotal: 7.69s\tremaining: 57.8s\n",
      "540:\tlearn: 3.1552706\ttotal: 7.7s\tremaining: 57.8s\n",
      "541:\tlearn: 3.1539487\ttotal: 7.72s\tremaining: 57.8s\n",
      "542:\tlearn: 3.1530499\ttotal: 7.73s\tremaining: 57.8s\n",
      "543:\tlearn: 3.1514209\ttotal: 7.75s\tremaining: 57.8s\n",
      "544:\tlearn: 3.1500830\ttotal: 7.76s\tremaining: 57.7s\n",
      "545:\tlearn: 3.1494668\ttotal: 7.78s\tremaining: 57.7s\n",
      "546:\tlearn: 3.1486389\ttotal: 7.8s\tremaining: 57.7s\n",
      "547:\tlearn: 3.1479704\ttotal: 7.81s\tremaining: 57.7s\n",
      "548:\tlearn: 3.1466737\ttotal: 7.83s\tremaining: 57.7s\n",
      "549:\tlearn: 3.1458429\ttotal: 7.84s\tremaining: 57.7s\n",
      "550:\tlearn: 3.1448071\ttotal: 7.85s\tremaining: 57.7s\n",
      "551:\tlearn: 3.1429767\ttotal: 7.87s\tremaining: 57.7s\n",
      "552:\tlearn: 3.1415917\ttotal: 7.88s\tremaining: 57.6s\n",
      "553:\tlearn: 3.1408527\ttotal: 7.89s\tremaining: 57.6s\n",
      "554:\tlearn: 3.1401668\ttotal: 7.91s\tremaining: 57.6s\n",
      "555:\tlearn: 3.1394942\ttotal: 7.92s\tremaining: 57.6s\n",
      "556:\tlearn: 3.1383285\ttotal: 7.93s\tremaining: 57.6s\n",
      "557:\tlearn: 3.1368289\ttotal: 7.95s\tremaining: 57.6s\n",
      "558:\tlearn: 3.1355699\ttotal: 7.96s\tremaining: 57.5s\n",
      "559:\tlearn: 3.1344261\ttotal: 7.98s\tremaining: 57.5s\n",
      "560:\tlearn: 3.1335049\ttotal: 7.99s\tremaining: 57.5s\n",
      "561:\tlearn: 3.1323686\ttotal: 8.01s\tremaining: 57.5s\n",
      "562:\tlearn: 3.1317572\ttotal: 8.02s\tremaining: 57.5s\n",
      "563:\tlearn: 3.1311071\ttotal: 8.04s\tremaining: 57.5s\n",
      "564:\tlearn: 3.1303545\ttotal: 8.05s\tremaining: 57.5s\n",
      "565:\tlearn: 3.1297483\ttotal: 8.06s\tremaining: 57.4s\n",
      "566:\tlearn: 3.1283052\ttotal: 8.07s\tremaining: 57.4s\n",
      "567:\tlearn: 3.1274736\ttotal: 8.09s\tremaining: 57.4s\n",
      "568:\tlearn: 3.1266536\ttotal: 8.1s\tremaining: 57.4s\n",
      "569:\tlearn: 3.1252120\ttotal: 8.12s\tremaining: 57.4s\n",
      "570:\tlearn: 3.1246335\ttotal: 8.13s\tremaining: 57.3s\n",
      "571:\tlearn: 3.1226149\ttotal: 8.14s\tremaining: 57.3s\n",
      "572:\tlearn: 3.1216614\ttotal: 8.16s\tremaining: 57.3s\n",
      "573:\tlearn: 3.1214369\ttotal: 8.17s\tremaining: 57.3s\n",
      "574:\tlearn: 3.1204628\ttotal: 8.18s\tremaining: 57.2s\n",
      "575:\tlearn: 3.1201381\ttotal: 8.19s\tremaining: 57.2s\n",
      "576:\tlearn: 3.1184327\ttotal: 8.21s\tremaining: 57.2s\n",
      "577:\tlearn: 3.1173925\ttotal: 8.22s\tremaining: 57.2s\n",
      "578:\tlearn: 3.1168421\ttotal: 8.24s\tremaining: 57.2s\n",
      "579:\tlearn: 3.1165941\ttotal: 8.25s\tremaining: 57.1s\n",
      "580:\tlearn: 3.1158218\ttotal: 8.26s\tremaining: 57.1s\n",
      "581:\tlearn: 3.1150573\ttotal: 8.27s\tremaining: 57.1s\n",
      "582:\tlearn: 3.1135971\ttotal: 8.29s\tremaining: 57.1s\n",
      "583:\tlearn: 3.1129077\ttotal: 8.3s\tremaining: 57.1s\n",
      "584:\tlearn: 3.1122447\ttotal: 8.31s\tremaining: 57s\n",
      "585:\tlearn: 3.1115199\ttotal: 8.33s\tremaining: 57s\n",
      "586:\tlearn: 3.1106886\ttotal: 8.34s\tremaining: 57s\n",
      "587:\tlearn: 3.1104500\ttotal: 8.35s\tremaining: 57s\n",
      "588:\tlearn: 3.1090336\ttotal: 8.37s\tremaining: 56.9s\n",
      "589:\tlearn: 3.1082204\ttotal: 8.38s\tremaining: 56.9s\n",
      "590:\tlearn: 3.1070441\ttotal: 8.39s\tremaining: 56.9s\n",
      "591:\tlearn: 3.1062106\ttotal: 8.41s\tremaining: 56.9s\n",
      "592:\tlearn: 3.1052201\ttotal: 8.42s\tremaining: 56.9s\n",
      "593:\tlearn: 3.1038949\ttotal: 8.44s\tremaining: 56.9s\n",
      "594:\tlearn: 3.1031298\ttotal: 8.45s\tremaining: 56.9s\n",
      "595:\tlearn: 3.1019275\ttotal: 8.47s\tremaining: 56.9s\n",
      "596:\tlearn: 3.1013102\ttotal: 8.48s\tremaining: 56.8s\n",
      "597:\tlearn: 3.1003928\ttotal: 8.49s\tremaining: 56.8s\n",
      "598:\tlearn: 3.0996478\ttotal: 8.51s\tremaining: 56.8s\n",
      "599:\tlearn: 3.0989351\ttotal: 8.53s\tremaining: 56.8s\n",
      "600:\tlearn: 3.0982466\ttotal: 8.54s\tremaining: 56.8s\n",
      "601:\tlearn: 3.0971746\ttotal: 8.55s\tremaining: 56.8s\n",
      "602:\tlearn: 3.0959700\ttotal: 8.57s\tremaining: 56.8s\n",
      "603:\tlearn: 3.0948586\ttotal: 8.58s\tremaining: 56.8s\n",
      "604:\tlearn: 3.0937770\ttotal: 8.6s\tremaining: 56.8s\n",
      "605:\tlearn: 3.0931656\ttotal: 8.61s\tremaining: 56.7s\n",
      "606:\tlearn: 3.0926608\ttotal: 8.63s\tremaining: 56.7s\n",
      "607:\tlearn: 3.0908674\ttotal: 8.64s\tremaining: 56.7s\n",
      "608:\tlearn: 3.0895938\ttotal: 8.65s\tremaining: 56.7s\n",
      "609:\tlearn: 3.0885808\ttotal: 8.67s\tremaining: 56.7s\n",
      "610:\tlearn: 3.0884907\ttotal: 8.68s\tremaining: 56.7s\n",
      "611:\tlearn: 3.0871895\ttotal: 8.7s\tremaining: 56.6s\n",
      "612:\tlearn: 3.0859523\ttotal: 8.71s\tremaining: 56.6s\n",
      "613:\tlearn: 3.0850035\ttotal: 8.73s\tremaining: 56.6s\n",
      "614:\tlearn: 3.0843322\ttotal: 8.74s\tremaining: 56.6s\n",
      "615:\tlearn: 3.0831506\ttotal: 8.75s\tremaining: 56.6s\n",
      "616:\tlearn: 3.0819912\ttotal: 8.77s\tremaining: 56.6s\n",
      "617:\tlearn: 3.0808549\ttotal: 8.78s\tremaining: 56.6s\n",
      "618:\tlearn: 3.0802419\ttotal: 8.79s\tremaining: 56.5s\n",
      "619:\tlearn: 3.0794449\ttotal: 8.81s\tremaining: 56.5s\n",
      "620:\tlearn: 3.0783936\ttotal: 8.82s\tremaining: 56.5s\n",
      "621:\tlearn: 3.0772675\ttotal: 8.84s\tremaining: 56.5s\n",
      "622:\tlearn: 3.0761940\ttotal: 8.85s\tremaining: 56.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623:\tlearn: 3.0750317\ttotal: 8.87s\tremaining: 56.5s\n",
      "624:\tlearn: 3.0740024\ttotal: 8.88s\tremaining: 56.5s\n",
      "625:\tlearn: 3.0730157\ttotal: 8.9s\tremaining: 56.5s\n",
      "626:\tlearn: 3.0720410\ttotal: 8.91s\tremaining: 56.4s\n",
      "627:\tlearn: 3.0708222\ttotal: 8.93s\tremaining: 56.4s\n",
      "628:\tlearn: 3.0699291\ttotal: 8.94s\tremaining: 56.4s\n",
      "629:\tlearn: 3.0692620\ttotal: 8.95s\tremaining: 56.4s\n",
      "630:\tlearn: 3.0686684\ttotal: 8.97s\tremaining: 56.4s\n",
      "631:\tlearn: 3.0682165\ttotal: 8.98s\tremaining: 56.4s\n",
      "632:\tlearn: 3.0668310\ttotal: 8.99s\tremaining: 56.3s\n",
      "633:\tlearn: 3.0658391\ttotal: 9.01s\tremaining: 56.3s\n",
      "634:\tlearn: 3.0653027\ttotal: 9.02s\tremaining: 56.3s\n",
      "635:\tlearn: 3.0636067\ttotal: 9.04s\tremaining: 56.3s\n",
      "636:\tlearn: 3.0626749\ttotal: 9.05s\tremaining: 56.3s\n",
      "637:\tlearn: 3.0620725\ttotal: 9.06s\tremaining: 56.2s\n",
      "638:\tlearn: 3.0610053\ttotal: 9.08s\tremaining: 56.2s\n",
      "639:\tlearn: 3.0596970\ttotal: 9.09s\tremaining: 56.2s\n",
      "640:\tlearn: 3.0590183\ttotal: 9.11s\tremaining: 56.2s\n",
      "641:\tlearn: 3.0578326\ttotal: 9.12s\tremaining: 56.2s\n",
      "642:\tlearn: 3.0570681\ttotal: 9.13s\tremaining: 56.2s\n",
      "643:\tlearn: 3.0562292\ttotal: 9.15s\tremaining: 56.2s\n",
      "644:\tlearn: 3.0550238\ttotal: 9.16s\tremaining: 56.1s\n",
      "645:\tlearn: 3.0542242\ttotal: 9.17s\tremaining: 56.1s\n",
      "646:\tlearn: 3.0529123\ttotal: 9.19s\tremaining: 56.1s\n",
      "647:\tlearn: 3.0518433\ttotal: 9.2s\tremaining: 56.1s\n",
      "648:\tlearn: 3.0507360\ttotal: 9.22s\tremaining: 56.1s\n",
      "649:\tlearn: 3.0496041\ttotal: 9.23s\tremaining: 56.1s\n",
      "650:\tlearn: 3.0487835\ttotal: 9.24s\tremaining: 56s\n",
      "651:\tlearn: 3.0458945\ttotal: 9.26s\tremaining: 56s\n",
      "652:\tlearn: 3.0452610\ttotal: 9.27s\tremaining: 56s\n",
      "653:\tlearn: 3.0436523\ttotal: 9.29s\tremaining: 56s\n",
      "654:\tlearn: 3.0431105\ttotal: 9.3s\tremaining: 56s\n",
      "655:\tlearn: 3.0427353\ttotal: 9.31s\tremaining: 56s\n",
      "656:\tlearn: 3.0425709\ttotal: 9.33s\tremaining: 56s\n",
      "657:\tlearn: 3.0420968\ttotal: 9.34s\tremaining: 55.9s\n",
      "658:\tlearn: 3.0413738\ttotal: 9.35s\tremaining: 55.9s\n",
      "659:\tlearn: 3.0399933\ttotal: 9.37s\tremaining: 55.9s\n",
      "660:\tlearn: 3.0391915\ttotal: 9.38s\tremaining: 55.9s\n",
      "661:\tlearn: 3.0382243\ttotal: 9.39s\tremaining: 55.9s\n",
      "662:\tlearn: 3.0376131\ttotal: 9.41s\tremaining: 55.8s\n",
      "663:\tlearn: 3.0363044\ttotal: 9.42s\tremaining: 55.8s\n",
      "664:\tlearn: 3.0356252\ttotal: 9.44s\tremaining: 55.8s\n",
      "665:\tlearn: 3.0350222\ttotal: 9.45s\tremaining: 55.8s\n",
      "666:\tlearn: 3.0337429\ttotal: 9.46s\tremaining: 55.8s\n",
      "667:\tlearn: 3.0326442\ttotal: 9.48s\tremaining: 55.8s\n",
      "668:\tlearn: 3.0314126\ttotal: 9.49s\tremaining: 55.7s\n",
      "669:\tlearn: 3.0299169\ttotal: 9.51s\tremaining: 55.7s\n",
      "670:\tlearn: 3.0284441\ttotal: 9.52s\tremaining: 55.7s\n",
      "671:\tlearn: 3.0275933\ttotal: 9.53s\tremaining: 55.7s\n",
      "672:\tlearn: 3.0267297\ttotal: 9.55s\tremaining: 55.7s\n",
      "673:\tlearn: 3.0248837\ttotal: 9.56s\tremaining: 55.7s\n",
      "674:\tlearn: 3.0243604\ttotal: 9.57s\tremaining: 55.6s\n",
      "675:\tlearn: 3.0234447\ttotal: 9.59s\tremaining: 55.6s\n",
      "676:\tlearn: 3.0230099\ttotal: 9.6s\tremaining: 55.6s\n",
      "677:\tlearn: 3.0214751\ttotal: 9.62s\tremaining: 55.6s\n",
      "678:\tlearn: 3.0208847\ttotal: 9.63s\tremaining: 55.6s\n",
      "679:\tlearn: 3.0205463\ttotal: 9.64s\tremaining: 55.6s\n",
      "680:\tlearn: 3.0199567\ttotal: 9.66s\tremaining: 55.5s\n",
      "681:\tlearn: 3.0188255\ttotal: 9.67s\tremaining: 55.5s\n",
      "682:\tlearn: 3.0183367\ttotal: 9.69s\tremaining: 55.5s\n",
      "683:\tlearn: 3.0176519\ttotal: 9.7s\tremaining: 55.5s\n",
      "684:\tlearn: 3.0163213\ttotal: 9.71s\tremaining: 55.5s\n",
      "685:\tlearn: 3.0156073\ttotal: 9.73s\tremaining: 55.5s\n",
      "686:\tlearn: 3.0144184\ttotal: 9.74s\tremaining: 55.5s\n",
      "687:\tlearn: 3.0132422\ttotal: 9.76s\tremaining: 55.5s\n",
      "688:\tlearn: 3.0123065\ttotal: 9.77s\tremaining: 55.4s\n",
      "689:\tlearn: 3.0110312\ttotal: 9.79s\tremaining: 55.4s\n",
      "690:\tlearn: 3.0103527\ttotal: 9.8s\tremaining: 55.4s\n",
      "691:\tlearn: 3.0096964\ttotal: 9.81s\tremaining: 55.4s\n",
      "692:\tlearn: 3.0088734\ttotal: 9.82s\tremaining: 55.4s\n",
      "693:\tlearn: 3.0077623\ttotal: 9.84s\tremaining: 55.4s\n",
      "694:\tlearn: 3.0069800\ttotal: 9.85s\tremaining: 55.3s\n",
      "695:\tlearn: 3.0062046\ttotal: 9.87s\tremaining: 55.3s\n",
      "696:\tlearn: 3.0054525\ttotal: 9.88s\tremaining: 55.3s\n",
      "697:\tlearn: 3.0044214\ttotal: 9.9s\tremaining: 55.3s\n",
      "698:\tlearn: 3.0034796\ttotal: 9.91s\tremaining: 55.3s\n",
      "699:\tlearn: 3.0031068\ttotal: 9.93s\tremaining: 55.3s\n",
      "700:\tlearn: 3.0020552\ttotal: 9.94s\tremaining: 55.3s\n",
      "701:\tlearn: 3.0011450\ttotal: 9.96s\tremaining: 55.3s\n",
      "702:\tlearn: 3.0003305\ttotal: 9.97s\tremaining: 55.2s\n",
      "703:\tlearn: 2.9999383\ttotal: 9.98s\tremaining: 55.2s\n",
      "704:\tlearn: 2.9991727\ttotal: 10s\tremaining: 55.2s\n",
      "705:\tlearn: 2.9984986\ttotal: 10s\tremaining: 55.2s\n",
      "706:\tlearn: 2.9974840\ttotal: 10s\tremaining: 55.2s\n",
      "707:\tlearn: 2.9964247\ttotal: 10s\tremaining: 55.2s\n",
      "708:\tlearn: 2.9953720\ttotal: 10.1s\tremaining: 55.1s\n",
      "709:\tlearn: 2.9940321\ttotal: 10.1s\tremaining: 55.1s\n",
      "710:\tlearn: 2.9929951\ttotal: 10.1s\tremaining: 55.1s\n",
      "711:\tlearn: 2.9917617\ttotal: 10.1s\tremaining: 55.1s\n",
      "712:\tlearn: 2.9905927\ttotal: 10.1s\tremaining: 55.1s\n",
      "713:\tlearn: 2.9894990\ttotal: 10.1s\tremaining: 55.1s\n",
      "714:\tlearn: 2.9881715\ttotal: 10.1s\tremaining: 55.1s\n",
      "715:\tlearn: 2.9874563\ttotal: 10.2s\tremaining: 55.1s\n",
      "716:\tlearn: 2.9859836\ttotal: 10.2s\tremaining: 55s\n",
      "717:\tlearn: 2.9849654\ttotal: 10.2s\tremaining: 55s\n",
      "718:\tlearn: 2.9842077\ttotal: 10.2s\tremaining: 55s\n",
      "719:\tlearn: 2.9835379\ttotal: 10.2s\tremaining: 55s\n",
      "720:\tlearn: 2.9822913\ttotal: 10.2s\tremaining: 55s\n",
      "721:\tlearn: 2.9819958\ttotal: 10.2s\tremaining: 55s\n",
      "722:\tlearn: 2.9814001\ttotal: 10.3s\tremaining: 55s\n",
      "723:\tlearn: 2.9803642\ttotal: 10.3s\tremaining: 55s\n",
      "724:\tlearn: 2.9794781\ttotal: 10.3s\tremaining: 54.9s\n",
      "725:\tlearn: 2.9790216\ttotal: 10.3s\tremaining: 54.9s\n",
      "726:\tlearn: 2.9777956\ttotal: 10.3s\tremaining: 54.9s\n",
      "727:\tlearn: 2.9771078\ttotal: 10.3s\tremaining: 54.9s\n",
      "728:\tlearn: 2.9759845\ttotal: 10.3s\tremaining: 54.9s\n",
      "729:\tlearn: 2.9754036\ttotal: 10.4s\tremaining: 54.9s\n",
      "730:\tlearn: 2.9749055\ttotal: 10.4s\tremaining: 54.8s\n",
      "731:\tlearn: 2.9740611\ttotal: 10.4s\tremaining: 54.8s\n",
      "732:\tlearn: 2.9730958\ttotal: 10.4s\tremaining: 54.8s\n",
      "733:\tlearn: 2.9725105\ttotal: 10.4s\tremaining: 54.8s\n",
      "734:\tlearn: 2.9715927\ttotal: 10.4s\tremaining: 54.8s\n",
      "735:\tlearn: 2.9712078\ttotal: 10.4s\tremaining: 54.8s\n",
      "736:\tlearn: 2.9704227\ttotal: 10.4s\tremaining: 54.7s\n",
      "737:\tlearn: 2.9698619\ttotal: 10.5s\tremaining: 54.7s\n",
      "738:\tlearn: 2.9690641\ttotal: 10.5s\tremaining: 54.7s\n",
      "739:\tlearn: 2.9682837\ttotal: 10.5s\tremaining: 54.7s\n",
      "740:\tlearn: 2.9676758\ttotal: 10.5s\tremaining: 54.7s\n",
      "741:\tlearn: 2.9666881\ttotal: 10.5s\tremaining: 54.7s\n",
      "742:\tlearn: 2.9656327\ttotal: 10.5s\tremaining: 54.7s\n",
      "743:\tlearn: 2.9648436\ttotal: 10.5s\tremaining: 54.6s\n",
      "744:\tlearn: 2.9645429\ttotal: 10.6s\tremaining: 54.6s\n",
      "745:\tlearn: 2.9632362\ttotal: 10.6s\tremaining: 54.6s\n",
      "746:\tlearn: 2.9623390\ttotal: 10.6s\tremaining: 54.6s\n",
      "747:\tlearn: 2.9621798\ttotal: 10.6s\tremaining: 54.6s\n",
      "748:\tlearn: 2.9615504\ttotal: 10.6s\tremaining: 54.6s\n",
      "749:\tlearn: 2.9603291\ttotal: 10.6s\tremaining: 54.6s\n",
      "750:\tlearn: 2.9595074\ttotal: 10.6s\tremaining: 54.5s\n",
      "751:\tlearn: 2.9585471\ttotal: 10.7s\tremaining: 54.5s\n",
      "752:\tlearn: 2.9575606\ttotal: 10.7s\tremaining: 54.5s\n",
      "753:\tlearn: 2.9570391\ttotal: 10.7s\tremaining: 54.5s\n",
      "754:\tlearn: 2.9564549\ttotal: 10.7s\tremaining: 54.5s\n",
      "755:\tlearn: 2.9562760\ttotal: 10.7s\tremaining: 54.5s\n",
      "756:\tlearn: 2.9550996\ttotal: 10.7s\tremaining: 54.5s\n",
      "757:\tlearn: 2.9543784\ttotal: 10.7s\tremaining: 54.4s\n",
      "758:\tlearn: 2.9536050\ttotal: 10.8s\tremaining: 54.4s\n",
      "759:\tlearn: 2.9526891\ttotal: 10.8s\tremaining: 54.4s\n",
      "760:\tlearn: 2.9523964\ttotal: 10.8s\tremaining: 54.4s\n",
      "761:\tlearn: 2.9513079\ttotal: 10.8s\tremaining: 54.4s\n",
      "762:\tlearn: 2.9506089\ttotal: 10.8s\tremaining: 54.4s\n",
      "763:\tlearn: 2.9492528\ttotal: 10.8s\tremaining: 54.4s\n",
      "764:\tlearn: 2.9483230\ttotal: 10.8s\tremaining: 54.3s\n",
      "765:\tlearn: 2.9478106\ttotal: 10.9s\tremaining: 54.3s\n",
      "766:\tlearn: 2.9465786\ttotal: 10.9s\tremaining: 54.3s\n",
      "767:\tlearn: 2.9457598\ttotal: 10.9s\tremaining: 54.3s\n",
      "768:\tlearn: 2.9436080\ttotal: 10.9s\tremaining: 54.3s\n",
      "769:\tlearn: 2.9422501\ttotal: 10.9s\tremaining: 54.3s\n",
      "770:\tlearn: 2.9413119\ttotal: 10.9s\tremaining: 54.3s\n",
      "771:\tlearn: 2.9403630\ttotal: 10.9s\tremaining: 54.2s\n",
      "772:\tlearn: 2.9392786\ttotal: 11s\tremaining: 54.2s\n",
      "773:\tlearn: 2.9379859\ttotal: 11s\tremaining: 54.2s\n",
      "774:\tlearn: 2.9373390\ttotal: 11s\tremaining: 54.2s\n",
      "775:\tlearn: 2.9370378\ttotal: 11s\tremaining: 54.2s\n",
      "776:\tlearn: 2.9363269\ttotal: 11s\tremaining: 54.2s\n",
      "777:\tlearn: 2.9353776\ttotal: 11s\tremaining: 54.2s\n",
      "778:\tlearn: 2.9342266\ttotal: 11s\tremaining: 54.2s\n",
      "779:\tlearn: 2.9337877\ttotal: 11.1s\tremaining: 54.1s\n",
      "780:\tlearn: 2.9336733\ttotal: 11.1s\tremaining: 54.1s\n",
      "781:\tlearn: 2.9328771\ttotal: 11.1s\tremaining: 54.1s\n",
      "782:\tlearn: 2.9315461\ttotal: 11.1s\tremaining: 54.1s\n",
      "783:\tlearn: 2.9305200\ttotal: 11.1s\tremaining: 54.1s\n",
      "784:\tlearn: 2.9295716\ttotal: 11.1s\tremaining: 54.1s\n",
      "785:\tlearn: 2.9284519\ttotal: 11.1s\tremaining: 54.1s\n",
      "786:\tlearn: 2.9274048\ttotal: 11.2s\tremaining: 54s\n",
      "787:\tlearn: 2.9266661\ttotal: 11.2s\tremaining: 54s\n",
      "788:\tlearn: 2.9261348\ttotal: 11.2s\tremaining: 54s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "789:\tlearn: 2.9258296\ttotal: 11.2s\tremaining: 54s\n",
      "790:\tlearn: 2.9252083\ttotal: 11.2s\tremaining: 54s\n",
      "791:\tlearn: 2.9241992\ttotal: 11.2s\tremaining: 54s\n",
      "792:\tlearn: 2.9233078\ttotal: 11.2s\tremaining: 54s\n",
      "793:\tlearn: 2.9222491\ttotal: 11.3s\tremaining: 53.9s\n",
      "794:\tlearn: 2.9214478\ttotal: 11.3s\tremaining: 53.9s\n",
      "795:\tlearn: 2.9207801\ttotal: 11.3s\tremaining: 53.9s\n",
      "796:\tlearn: 2.9202483\ttotal: 11.3s\tremaining: 53.9s\n",
      "797:\tlearn: 2.9196408\ttotal: 11.3s\tremaining: 53.9s\n",
      "798:\tlearn: 2.9184998\ttotal: 11.3s\tremaining: 53.9s\n",
      "799:\tlearn: 2.9175979\ttotal: 11.3s\tremaining: 53.9s\n",
      "800:\tlearn: 2.9169606\ttotal: 11.4s\tremaining: 53.8s\n",
      "801:\tlearn: 2.9164687\ttotal: 11.4s\tremaining: 53.8s\n",
      "802:\tlearn: 2.9160065\ttotal: 11.4s\tremaining: 53.8s\n",
      "803:\tlearn: 2.9152355\ttotal: 11.4s\tremaining: 53.8s\n",
      "804:\tlearn: 2.9143902\ttotal: 11.4s\tremaining: 53.8s\n",
      "805:\tlearn: 2.9130755\ttotal: 11.4s\tremaining: 53.8s\n",
      "806:\tlearn: 2.9116276\ttotal: 11.4s\tremaining: 53.8s\n",
      "807:\tlearn: 2.9108422\ttotal: 11.5s\tremaining: 53.8s\n",
      "808:\tlearn: 2.9102617\ttotal: 11.5s\tremaining: 53.7s\n",
      "809:\tlearn: 2.9090866\ttotal: 11.5s\tremaining: 53.7s\n",
      "810:\tlearn: 2.9083486\ttotal: 11.5s\tremaining: 53.7s\n",
      "811:\tlearn: 2.9079566\ttotal: 11.5s\tremaining: 53.7s\n",
      "812:\tlearn: 2.9070175\ttotal: 11.5s\tremaining: 53.7s\n",
      "813:\tlearn: 2.9061109\ttotal: 11.5s\tremaining: 53.7s\n",
      "814:\tlearn: 2.9048149\ttotal: 11.6s\tremaining: 53.7s\n",
      "815:\tlearn: 2.9038605\ttotal: 11.6s\tremaining: 53.7s\n",
      "816:\tlearn: 2.9030155\ttotal: 11.6s\tremaining: 53.7s\n",
      "817:\tlearn: 2.9019687\ttotal: 11.6s\tremaining: 53.6s\n",
      "818:\tlearn: 2.9012444\ttotal: 11.6s\tremaining: 53.7s\n",
      "819:\tlearn: 2.9006369\ttotal: 11.6s\tremaining: 53.7s\n",
      "820:\tlearn: 2.8998970\ttotal: 11.7s\tremaining: 53.6s\n",
      "821:\tlearn: 2.8992822\ttotal: 11.7s\tremaining: 53.6s\n",
      "822:\tlearn: 2.8985156\ttotal: 11.7s\tremaining: 53.6s\n",
      "823:\tlearn: 2.8980424\ttotal: 11.7s\tremaining: 53.6s\n",
      "824:\tlearn: 2.8969913\ttotal: 11.7s\tremaining: 53.6s\n",
      "825:\tlearn: 2.8961160\ttotal: 11.7s\tremaining: 53.6s\n",
      "826:\tlearn: 2.8952935\ttotal: 11.7s\tremaining: 53.6s\n",
      "827:\tlearn: 2.8947705\ttotal: 11.8s\tremaining: 53.6s\n",
      "828:\tlearn: 2.8940931\ttotal: 11.8s\tremaining: 53.5s\n",
      "829:\tlearn: 2.8930545\ttotal: 11.8s\tremaining: 53.5s\n",
      "830:\tlearn: 2.8922329\ttotal: 11.8s\tremaining: 53.5s\n",
      "831:\tlearn: 2.8914014\ttotal: 11.8s\tremaining: 53.5s\n",
      "832:\tlearn: 2.8907719\ttotal: 11.8s\tremaining: 53.5s\n",
      "833:\tlearn: 2.8899869\ttotal: 11.9s\tremaining: 53.5s\n",
      "834:\tlearn: 2.8890256\ttotal: 11.9s\tremaining: 53.5s\n",
      "835:\tlearn: 2.8886226\ttotal: 11.9s\tremaining: 53.5s\n",
      "836:\tlearn: 2.8879510\ttotal: 11.9s\tremaining: 53.4s\n",
      "837:\tlearn: 2.8874283\ttotal: 11.9s\tremaining: 53.4s\n",
      "838:\tlearn: 2.8864306\ttotal: 11.9s\tremaining: 53.4s\n",
      "839:\tlearn: 2.8852602\ttotal: 11.9s\tremaining: 53.4s\n",
      "840:\tlearn: 2.8847684\ttotal: 11.9s\tremaining: 53.4s\n",
      "841:\tlearn: 2.8840478\ttotal: 12s\tremaining: 53.4s\n",
      "842:\tlearn: 2.8830619\ttotal: 12s\tremaining: 53.4s\n",
      "843:\tlearn: 2.8821232\ttotal: 12s\tremaining: 53.3s\n",
      "844:\tlearn: 2.8813565\ttotal: 12s\tremaining: 53.3s\n",
      "845:\tlearn: 2.8808050\ttotal: 12s\tremaining: 53.3s\n",
      "846:\tlearn: 2.8804561\ttotal: 12s\tremaining: 53.3s\n",
      "847:\tlearn: 2.8796867\ttotal: 12.1s\tremaining: 53.3s\n",
      "848:\tlearn: 2.8789845\ttotal: 12.1s\tremaining: 53.3s\n",
      "849:\tlearn: 2.8783644\ttotal: 12.1s\tremaining: 53.3s\n",
      "850:\tlearn: 2.8777005\ttotal: 12.1s\tremaining: 53.3s\n",
      "851:\tlearn: 2.8770367\ttotal: 12.1s\tremaining: 53.2s\n",
      "852:\tlearn: 2.8760586\ttotal: 12.1s\tremaining: 53.2s\n",
      "853:\tlearn: 2.8750412\ttotal: 12.1s\tremaining: 53.2s\n",
      "854:\tlearn: 2.8743358\ttotal: 12.2s\tremaining: 53.2s\n",
      "855:\tlearn: 2.8739423\ttotal: 12.2s\tremaining: 53.2s\n",
      "856:\tlearn: 2.8727460\ttotal: 12.2s\tremaining: 53.2s\n",
      "857:\tlearn: 2.8721879\ttotal: 12.2s\tremaining: 53.2s\n",
      "858:\tlearn: 2.8714752\ttotal: 12.2s\tremaining: 53.1s\n",
      "859:\tlearn: 2.8706944\ttotal: 12.2s\tremaining: 53.1s\n",
      "860:\tlearn: 2.8702846\ttotal: 12.2s\tremaining: 53.1s\n",
      "861:\tlearn: 2.8696631\ttotal: 12.3s\tremaining: 53.1s\n",
      "862:\tlearn: 2.8688213\ttotal: 12.3s\tremaining: 53.1s\n",
      "863:\tlearn: 2.8681457\ttotal: 12.3s\tremaining: 53.1s\n",
      "864:\tlearn: 2.8673754\ttotal: 12.3s\tremaining: 53.1s\n",
      "865:\tlearn: 2.8665686\ttotal: 12.3s\tremaining: 53.1s\n",
      "866:\tlearn: 2.8654968\ttotal: 12.3s\tremaining: 53s\n",
      "867:\tlearn: 2.8640583\ttotal: 12.3s\tremaining: 53s\n",
      "868:\tlearn: 2.8634170\ttotal: 12.4s\tremaining: 53s\n",
      "869:\tlearn: 2.8625921\ttotal: 12.4s\tremaining: 53s\n",
      "870:\tlearn: 2.8620338\ttotal: 12.4s\tremaining: 53s\n",
      "871:\tlearn: 2.8612854\ttotal: 12.4s\tremaining: 53s\n",
      "872:\tlearn: 2.8605830\ttotal: 12.4s\tremaining: 53s\n",
      "873:\tlearn: 2.8598126\ttotal: 12.4s\tremaining: 52.9s\n",
      "874:\tlearn: 2.8585625\ttotal: 12.4s\tremaining: 52.9s\n",
      "875:\tlearn: 2.8581206\ttotal: 12.5s\tremaining: 52.9s\n",
      "876:\tlearn: 2.8575067\ttotal: 12.5s\tremaining: 52.9s\n",
      "877:\tlearn: 2.8569168\ttotal: 12.5s\tremaining: 52.9s\n",
      "878:\tlearn: 2.8563108\ttotal: 12.5s\tremaining: 52.9s\n",
      "879:\tlearn: 2.8555388\ttotal: 12.5s\tremaining: 52.9s\n",
      "880:\tlearn: 2.8550975\ttotal: 12.5s\tremaining: 52.8s\n",
      "881:\tlearn: 2.8542236\ttotal: 12.5s\tremaining: 52.8s\n",
      "882:\tlearn: 2.8537877\ttotal: 12.6s\tremaining: 52.8s\n",
      "883:\tlearn: 2.8533964\ttotal: 12.6s\tremaining: 52.8s\n",
      "884:\tlearn: 2.8527655\ttotal: 12.6s\tremaining: 52.8s\n",
      "885:\tlearn: 2.8520705\ttotal: 12.6s\tremaining: 52.8s\n",
      "886:\tlearn: 2.8511811\ttotal: 12.6s\tremaining: 52.8s\n",
      "887:\tlearn: 2.8504053\ttotal: 12.6s\tremaining: 52.7s\n",
      "888:\tlearn: 2.8492777\ttotal: 12.6s\tremaining: 52.7s\n",
      "889:\tlearn: 2.8487580\ttotal: 12.7s\tremaining: 52.7s\n",
      "890:\tlearn: 2.8480706\ttotal: 12.7s\tremaining: 52.7s\n",
      "891:\tlearn: 2.8470476\ttotal: 12.7s\tremaining: 52.7s\n",
      "892:\tlearn: 2.8469020\ttotal: 12.7s\tremaining: 52.7s\n",
      "893:\tlearn: 2.8464169\ttotal: 12.7s\tremaining: 52.7s\n",
      "894:\tlearn: 2.8456045\ttotal: 12.7s\tremaining: 52.6s\n",
      "895:\tlearn: 2.8452256\ttotal: 12.7s\tremaining: 52.6s\n",
      "896:\tlearn: 2.8443200\ttotal: 12.8s\tremaining: 52.6s\n",
      "897:\tlearn: 2.8437917\ttotal: 12.8s\tremaining: 52.6s\n",
      "898:\tlearn: 2.8432833\ttotal: 12.8s\tremaining: 52.6s\n",
      "899:\tlearn: 2.8420875\ttotal: 12.8s\tremaining: 52.6s\n",
      "900:\tlearn: 2.8416505\ttotal: 12.8s\tremaining: 52.6s\n",
      "901:\tlearn: 2.8412489\ttotal: 12.8s\tremaining: 52.5s\n",
      "902:\tlearn: 2.8407320\ttotal: 12.8s\tremaining: 52.5s\n",
      "903:\tlearn: 2.8395047\ttotal: 12.8s\tremaining: 52.5s\n",
      "904:\tlearn: 2.8381282\ttotal: 12.9s\tremaining: 52.5s\n",
      "905:\tlearn: 2.8377352\ttotal: 12.9s\tremaining: 52.5s\n",
      "906:\tlearn: 2.8370440\ttotal: 12.9s\tremaining: 52.5s\n",
      "907:\tlearn: 2.8365558\ttotal: 12.9s\tremaining: 52.4s\n",
      "908:\tlearn: 2.8359683\ttotal: 12.9s\tremaining: 52.4s\n",
      "909:\tlearn: 2.8353590\ttotal: 12.9s\tremaining: 52.4s\n",
      "910:\tlearn: 2.8347919\ttotal: 12.9s\tremaining: 52.4s\n",
      "911:\tlearn: 2.8336798\ttotal: 13s\tremaining: 52.4s\n",
      "912:\tlearn: 2.8329437\ttotal: 13s\tremaining: 52.4s\n",
      "913:\tlearn: 2.8325416\ttotal: 13s\tremaining: 52.4s\n",
      "914:\tlearn: 2.8318813\ttotal: 13s\tremaining: 52.3s\n",
      "915:\tlearn: 2.8309286\ttotal: 13s\tremaining: 52.3s\n",
      "916:\tlearn: 2.8298904\ttotal: 13s\tremaining: 52.3s\n",
      "917:\tlearn: 2.8294395\ttotal: 13s\tremaining: 52.3s\n",
      "918:\tlearn: 2.8290221\ttotal: 13.1s\tremaining: 52.3s\n",
      "919:\tlearn: 2.8278980\ttotal: 13.1s\tremaining: 52.3s\n",
      "920:\tlearn: 2.8269901\ttotal: 13.1s\tremaining: 52.3s\n",
      "921:\tlearn: 2.8263305\ttotal: 13.1s\tremaining: 52.2s\n",
      "922:\tlearn: 2.8257781\ttotal: 13.1s\tremaining: 52.2s\n",
      "923:\tlearn: 2.8251597\ttotal: 13.1s\tremaining: 52.2s\n",
      "924:\tlearn: 2.8246726\ttotal: 13.1s\tremaining: 52.2s\n",
      "925:\tlearn: 2.8242330\ttotal: 13.2s\tremaining: 52.2s\n",
      "926:\tlearn: 2.8234827\ttotal: 13.2s\tremaining: 52.2s\n",
      "927:\tlearn: 2.8228424\ttotal: 13.2s\tremaining: 52.1s\n",
      "928:\tlearn: 2.8222822\ttotal: 13.2s\tremaining: 52.1s\n",
      "929:\tlearn: 2.8217467\ttotal: 13.2s\tremaining: 52.1s\n",
      "930:\tlearn: 2.8209623\ttotal: 13.2s\tremaining: 52.1s\n",
      "931:\tlearn: 2.8200804\ttotal: 13.2s\tremaining: 52.1s\n",
      "932:\tlearn: 2.8196716\ttotal: 13.3s\tremaining: 52.1s\n",
      "933:\tlearn: 2.8189241\ttotal: 13.3s\tremaining: 52s\n",
      "934:\tlearn: 2.8184828\ttotal: 13.3s\tremaining: 52s\n",
      "935:\tlearn: 2.8177185\ttotal: 13.3s\tremaining: 52s\n",
      "936:\tlearn: 2.8171572\ttotal: 13.3s\tremaining: 52s\n",
      "937:\tlearn: 2.8161589\ttotal: 13.3s\tremaining: 52s\n",
      "938:\tlearn: 2.8151192\ttotal: 13.3s\tremaining: 52s\n",
      "939:\tlearn: 2.8143658\ttotal: 13.4s\tremaining: 52s\n",
      "940:\tlearn: 2.8135661\ttotal: 13.4s\tremaining: 51.9s\n",
      "941:\tlearn: 2.8127513\ttotal: 13.4s\tremaining: 51.9s\n",
      "942:\tlearn: 2.8124426\ttotal: 13.4s\tremaining: 51.9s\n",
      "943:\tlearn: 2.8121246\ttotal: 13.4s\tremaining: 51.9s\n",
      "944:\tlearn: 2.8115547\ttotal: 13.4s\tremaining: 51.9s\n",
      "945:\tlearn: 2.8110952\ttotal: 13.4s\tremaining: 51.9s\n",
      "946:\tlearn: 2.8108115\ttotal: 13.4s\tremaining: 51.8s\n",
      "947:\tlearn: 2.8102962\ttotal: 13.5s\tremaining: 51.8s\n",
      "948:\tlearn: 2.8097441\ttotal: 13.5s\tremaining: 51.8s\n",
      "949:\tlearn: 2.8094999\ttotal: 13.5s\tremaining: 51.8s\n",
      "950:\tlearn: 2.8082652\ttotal: 13.5s\tremaining: 51.8s\n",
      "951:\tlearn: 2.8071739\ttotal: 13.5s\tremaining: 51.8s\n",
      "952:\tlearn: 2.8066046\ttotal: 13.5s\tremaining: 51.8s\n",
      "953:\tlearn: 2.8059191\ttotal: 13.5s\tremaining: 51.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "954:\tlearn: 2.8047354\ttotal: 13.6s\tremaining: 51.7s\n",
      "955:\tlearn: 2.8038519\ttotal: 13.6s\tremaining: 51.7s\n",
      "956:\tlearn: 2.8031889\ttotal: 13.6s\tremaining: 51.7s\n",
      "957:\tlearn: 2.8024011\ttotal: 13.6s\tremaining: 51.7s\n",
      "958:\tlearn: 2.8016858\ttotal: 13.6s\tremaining: 51.7s\n",
      "959:\tlearn: 2.8014236\ttotal: 13.6s\tremaining: 51.6s\n",
      "960:\tlearn: 2.8010146\ttotal: 13.6s\tremaining: 51.6s\n",
      "961:\tlearn: 2.8002104\ttotal: 13.7s\tremaining: 51.6s\n",
      "962:\tlearn: 2.7995060\ttotal: 13.7s\tremaining: 51.6s\n",
      "963:\tlearn: 2.7985652\ttotal: 13.7s\tremaining: 51.6s\n",
      "964:\tlearn: 2.7975240\ttotal: 13.7s\tremaining: 51.6s\n",
      "965:\tlearn: 2.7970723\ttotal: 13.7s\tremaining: 51.6s\n",
      "966:\tlearn: 2.7967362\ttotal: 13.7s\tremaining: 51.6s\n",
      "967:\tlearn: 2.7958972\ttotal: 13.7s\tremaining: 51.5s\n",
      "968:\tlearn: 2.7954093\ttotal: 13.8s\tremaining: 51.5s\n",
      "969:\tlearn: 2.7943446\ttotal: 13.8s\tremaining: 51.5s\n",
      "970:\tlearn: 2.7935013\ttotal: 13.8s\tremaining: 51.5s\n",
      "971:\tlearn: 2.7924291\ttotal: 13.8s\tremaining: 51.5s\n",
      "972:\tlearn: 2.7918563\ttotal: 13.8s\tremaining: 51.5s\n",
      "973:\tlearn: 2.7907568\ttotal: 13.8s\tremaining: 51.5s\n",
      "974:\tlearn: 2.7903995\ttotal: 13.8s\tremaining: 51.4s\n",
      "975:\tlearn: 2.7893071\ttotal: 13.9s\tremaining: 51.4s\n",
      "976:\tlearn: 2.7888757\ttotal: 13.9s\tremaining: 51.4s\n",
      "977:\tlearn: 2.7879744\ttotal: 13.9s\tremaining: 51.4s\n",
      "978:\tlearn: 2.7867759\ttotal: 13.9s\tremaining: 51.4s\n",
      "979:\tlearn: 2.7861970\ttotal: 13.9s\tremaining: 51.4s\n",
      "980:\tlearn: 2.7855591\ttotal: 13.9s\tremaining: 51.3s\n",
      "981:\tlearn: 2.7847343\ttotal: 13.9s\tremaining: 51.3s\n",
      "982:\tlearn: 2.7841090\ttotal: 14s\tremaining: 51.3s\n",
      "983:\tlearn: 2.7834048\ttotal: 14s\tremaining: 51.3s\n",
      "984:\tlearn: 2.7822581\ttotal: 14s\tremaining: 51.3s\n",
      "985:\tlearn: 2.7817118\ttotal: 14s\tremaining: 51.3s\n",
      "986:\tlearn: 2.7808561\ttotal: 14s\tremaining: 51.3s\n",
      "987:\tlearn: 2.7801253\ttotal: 14s\tremaining: 51.3s\n",
      "988:\tlearn: 2.7794101\ttotal: 14s\tremaining: 51.2s\n",
      "989:\tlearn: 2.7787056\ttotal: 14.1s\tremaining: 51.2s\n",
      "990:\tlearn: 2.7782770\ttotal: 14.1s\tremaining: 51.2s\n",
      "991:\tlearn: 2.7776338\ttotal: 14.1s\tremaining: 51.2s\n",
      "992:\tlearn: 2.7771493\ttotal: 14.1s\tremaining: 51.2s\n",
      "993:\tlearn: 2.7760480\ttotal: 14.1s\tremaining: 51.2s\n",
      "994:\tlearn: 2.7750957\ttotal: 14.1s\tremaining: 51.1s\n",
      "995:\tlearn: 2.7742977\ttotal: 14.1s\tremaining: 51.1s\n",
      "996:\tlearn: 2.7734506\ttotal: 14.2s\tremaining: 51.1s\n",
      "997:\tlearn: 2.7729047\ttotal: 14.2s\tremaining: 51.1s\n",
      "998:\tlearn: 2.7725592\ttotal: 14.2s\tremaining: 51.1s\n",
      "999:\tlearn: 2.7717424\ttotal: 14.2s\tremaining: 51.1s\n",
      "1000:\tlearn: 2.7710322\ttotal: 14.2s\tremaining: 51.1s\n",
      "1001:\tlearn: 2.7701950\ttotal: 14.2s\tremaining: 51s\n",
      "1002:\tlearn: 2.7698500\ttotal: 14.2s\tremaining: 51s\n",
      "1003:\tlearn: 2.7695188\ttotal: 14.3s\tremaining: 51s\n",
      "1004:\tlearn: 2.7684812\ttotal: 14.3s\tremaining: 51s\n",
      "1005:\tlearn: 2.7678495\ttotal: 14.3s\tremaining: 51s\n",
      "1006:\tlearn: 2.7676627\ttotal: 14.3s\tremaining: 51s\n",
      "1007:\tlearn: 2.7671480\ttotal: 14.3s\tremaining: 51s\n",
      "1008:\tlearn: 2.7664679\ttotal: 14.3s\tremaining: 50.9s\n",
      "1009:\tlearn: 2.7657911\ttotal: 14.3s\tremaining: 50.9s\n",
      "1010:\tlearn: 2.7652574\ttotal: 14.3s\tremaining: 50.9s\n",
      "1011:\tlearn: 2.7644863\ttotal: 14.4s\tremaining: 50.9s\n",
      "1012:\tlearn: 2.7639899\ttotal: 14.4s\tremaining: 50.9s\n",
      "1013:\tlearn: 2.7634287\ttotal: 14.4s\tremaining: 50.9s\n",
      "1014:\tlearn: 2.7630976\ttotal: 14.4s\tremaining: 50.8s\n",
      "1015:\tlearn: 2.7626250\ttotal: 14.4s\tremaining: 50.8s\n",
      "1016:\tlearn: 2.7621405\ttotal: 14.4s\tremaining: 50.8s\n",
      "1017:\tlearn: 2.7614107\ttotal: 14.4s\tremaining: 50.8s\n",
      "1018:\tlearn: 2.7607550\ttotal: 14.5s\tremaining: 50.8s\n",
      "1019:\tlearn: 2.7597913\ttotal: 14.5s\tremaining: 50.8s\n",
      "1020:\tlearn: 2.7594864\ttotal: 14.5s\tremaining: 50.8s\n",
      "1021:\tlearn: 2.7584222\ttotal: 14.5s\tremaining: 50.8s\n",
      "1022:\tlearn: 2.7579799\ttotal: 14.5s\tremaining: 50.7s\n",
      "1023:\tlearn: 2.7567426\ttotal: 14.5s\tremaining: 50.7s\n",
      "1024:\tlearn: 2.7561373\ttotal: 14.6s\tremaining: 50.7s\n",
      "1025:\tlearn: 2.7551302\ttotal: 14.6s\tremaining: 50.7s\n",
      "1026:\tlearn: 2.7542860\ttotal: 14.6s\tremaining: 50.7s\n",
      "1027:\tlearn: 2.7537317\ttotal: 14.6s\tremaining: 50.7s\n",
      "1028:\tlearn: 2.7533335\ttotal: 14.6s\tremaining: 50.7s\n",
      "1029:\tlearn: 2.7523849\ttotal: 14.6s\tremaining: 50.6s\n",
      "1030:\tlearn: 2.7514466\ttotal: 14.6s\tremaining: 50.6s\n",
      "1031:\tlearn: 2.7509056\ttotal: 14.7s\tremaining: 50.6s\n",
      "1032:\tlearn: 2.7503473\ttotal: 14.7s\tremaining: 50.6s\n",
      "1033:\tlearn: 2.7493878\ttotal: 14.7s\tremaining: 50.6s\n",
      "1034:\tlearn: 2.7488810\ttotal: 14.7s\tremaining: 50.6s\n",
      "1035:\tlearn: 2.7484532\ttotal: 14.7s\tremaining: 50.6s\n",
      "1036:\tlearn: 2.7480065\ttotal: 14.7s\tremaining: 50.6s\n",
      "1037:\tlearn: 2.7474862\ttotal: 14.7s\tremaining: 50.5s\n",
      "1038:\tlearn: 2.7467977\ttotal: 14.7s\tremaining: 50.5s\n",
      "1039:\tlearn: 2.7460157\ttotal: 14.8s\tremaining: 50.5s\n",
      "1040:\tlearn: 2.7452436\ttotal: 14.8s\tremaining: 50.5s\n",
      "1041:\tlearn: 2.7443763\ttotal: 14.8s\tremaining: 50.5s\n",
      "1042:\tlearn: 2.7435472\ttotal: 14.8s\tremaining: 50.5s\n",
      "1043:\tlearn: 2.7426228\ttotal: 14.8s\tremaining: 50.5s\n",
      "1044:\tlearn: 2.7407521\ttotal: 14.8s\tremaining: 50.4s\n",
      "1045:\tlearn: 2.7400463\ttotal: 14.8s\tremaining: 50.4s\n",
      "1046:\tlearn: 2.7394781\ttotal: 14.9s\tremaining: 50.4s\n",
      "1047:\tlearn: 2.7392297\ttotal: 14.9s\tremaining: 50.4s\n",
      "1048:\tlearn: 2.7392255\ttotal: 14.9s\tremaining: 50.4s\n",
      "1049:\tlearn: 2.7384415\ttotal: 14.9s\tremaining: 50.4s\n",
      "1050:\tlearn: 2.7376781\ttotal: 14.9s\tremaining: 50.4s\n",
      "1051:\tlearn: 2.7370424\ttotal: 14.9s\tremaining: 50.3s\n",
      "1052:\tlearn: 2.7363756\ttotal: 14.9s\tremaining: 50.3s\n",
      "1053:\tlearn: 2.7356937\ttotal: 15s\tremaining: 50.3s\n",
      "1054:\tlearn: 2.7353572\ttotal: 15s\tremaining: 50.3s\n",
      "1055:\tlearn: 2.7346661\ttotal: 15s\tremaining: 50.3s\n",
      "1056:\tlearn: 2.7342378\ttotal: 15s\tremaining: 50.3s\n",
      "1057:\tlearn: 2.7337976\ttotal: 15s\tremaining: 50.2s\n",
      "1058:\tlearn: 2.7329216\ttotal: 15s\tremaining: 50.2s\n",
      "1059:\tlearn: 2.7323926\ttotal: 15s\tremaining: 50.2s\n",
      "1060:\tlearn: 2.7317108\ttotal: 15.1s\tremaining: 50.2s\n",
      "1061:\tlearn: 2.7304176\ttotal: 15.1s\tremaining: 50.2s\n",
      "1062:\tlearn: 2.7295539\ttotal: 15.1s\tremaining: 50.2s\n",
      "1063:\tlearn: 2.7292950\ttotal: 15.1s\tremaining: 50.2s\n",
      "1064:\tlearn: 2.7288717\ttotal: 15.1s\tremaining: 50.2s\n",
      "1065:\tlearn: 2.7280509\ttotal: 15.1s\tremaining: 50.1s\n",
      "1066:\tlearn: 2.7277927\ttotal: 15.1s\tremaining: 50.1s\n",
      "1067:\tlearn: 2.7269129\ttotal: 15.2s\tremaining: 50.1s\n",
      "1068:\tlearn: 2.7261415\ttotal: 15.2s\tremaining: 50.1s\n",
      "1069:\tlearn: 2.7251831\ttotal: 15.2s\tremaining: 50.1s\n",
      "1070:\tlearn: 2.7246929\ttotal: 15.2s\tremaining: 50.1s\n",
      "1071:\tlearn: 2.7239258\ttotal: 15.2s\tremaining: 50.1s\n",
      "1072:\tlearn: 2.7231272\ttotal: 15.2s\tremaining: 50s\n",
      "1073:\tlearn: 2.7219059\ttotal: 15.2s\tremaining: 50s\n",
      "1074:\tlearn: 2.7214648\ttotal: 15.3s\tremaining: 50s\n",
      "1075:\tlearn: 2.7210734\ttotal: 15.3s\tremaining: 50s\n",
      "1076:\tlearn: 2.7206877\ttotal: 15.3s\tremaining: 50s\n",
      "1077:\tlearn: 2.7198511\ttotal: 15.3s\tremaining: 50s\n",
      "1078:\tlearn: 2.7195066\ttotal: 15.3s\tremaining: 50s\n",
      "1079:\tlearn: 2.7192303\ttotal: 15.3s\tremaining: 49.9s\n",
      "1080:\tlearn: 2.7186470\ttotal: 15.3s\tremaining: 49.9s\n",
      "1081:\tlearn: 2.7179308\ttotal: 15.4s\tremaining: 49.9s\n",
      "1082:\tlearn: 2.7170126\ttotal: 15.4s\tremaining: 49.9s\n",
      "1083:\tlearn: 2.7163298\ttotal: 15.4s\tremaining: 49.9s\n",
      "1084:\tlearn: 2.7155855\ttotal: 15.4s\tremaining: 49.9s\n",
      "1085:\tlearn: 2.7145684\ttotal: 15.4s\tremaining: 49.9s\n",
      "1086:\tlearn: 2.7139949\ttotal: 15.4s\tremaining: 49.8s\n",
      "1087:\tlearn: 2.7129551\ttotal: 15.4s\tremaining: 49.8s\n",
      "1088:\tlearn: 2.7120300\ttotal: 15.5s\tremaining: 49.8s\n",
      "1089:\tlearn: 2.7110973\ttotal: 15.5s\tremaining: 49.8s\n",
      "1090:\tlearn: 2.7107427\ttotal: 15.5s\tremaining: 49.8s\n",
      "1091:\tlearn: 2.7097978\ttotal: 15.5s\tremaining: 49.8s\n",
      "1092:\tlearn: 2.7088828\ttotal: 15.5s\tremaining: 49.8s\n",
      "1093:\tlearn: 2.7084064\ttotal: 15.5s\tremaining: 49.8s\n",
      "1094:\tlearn: 2.7077113\ttotal: 15.5s\tremaining: 49.7s\n",
      "1095:\tlearn: 2.7067667\ttotal: 15.6s\tremaining: 49.7s\n",
      "1096:\tlearn: 2.7056192\ttotal: 15.6s\tremaining: 49.7s\n",
      "1097:\tlearn: 2.7047176\ttotal: 15.6s\tremaining: 49.7s\n",
      "1098:\tlearn: 2.7043646\ttotal: 15.6s\tremaining: 49.7s\n",
      "1099:\tlearn: 2.7036472\ttotal: 15.6s\tremaining: 49.7s\n",
      "1100:\tlearn: 2.7029635\ttotal: 15.6s\tremaining: 49.7s\n",
      "1101:\tlearn: 2.7022684\ttotal: 15.6s\tremaining: 49.6s\n",
      "1102:\tlearn: 2.7016813\ttotal: 15.7s\tremaining: 49.6s\n",
      "1103:\tlearn: 2.7013021\ttotal: 15.7s\tremaining: 49.6s\n",
      "1104:\tlearn: 2.7007392\ttotal: 15.7s\tremaining: 49.6s\n",
      "1105:\tlearn: 2.7001756\ttotal: 15.7s\tremaining: 49.6s\n",
      "1106:\tlearn: 2.6982123\ttotal: 15.7s\tremaining: 49.6s\n",
      "1107:\tlearn: 2.6975149\ttotal: 15.7s\tremaining: 49.6s\n",
      "1108:\tlearn: 2.6969659\ttotal: 15.7s\tremaining: 49.5s\n",
      "1109:\tlearn: 2.6957599\ttotal: 15.8s\tremaining: 49.5s\n",
      "1110:\tlearn: 2.6946670\ttotal: 15.8s\tremaining: 49.5s\n",
      "1111:\tlearn: 2.6933963\ttotal: 15.8s\tremaining: 49.5s\n",
      "1112:\tlearn: 2.6924968\ttotal: 15.8s\tremaining: 49.5s\n",
      "1113:\tlearn: 2.6919609\ttotal: 15.8s\tremaining: 49.5s\n",
      "1114:\tlearn: 2.6912445\ttotal: 15.8s\tremaining: 49.5s\n",
      "1115:\tlearn: 2.6901203\ttotal: 15.9s\tremaining: 49.5s\n",
      "1116:\tlearn: 2.6893489\ttotal: 15.9s\tremaining: 49.4s\n",
      "1117:\tlearn: 2.6881886\ttotal: 15.9s\tremaining: 49.5s\n",
      "1118:\tlearn: 2.6879399\ttotal: 15.9s\tremaining: 49.4s\n",
      "1119:\tlearn: 2.6871522\ttotal: 15.9s\tremaining: 49.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1120:\tlearn: 2.6863437\ttotal: 15.9s\tremaining: 49.4s\n",
      "1121:\tlearn: 2.6850522\ttotal: 15.9s\tremaining: 49.4s\n",
      "1122:\tlearn: 2.6844951\ttotal: 16s\tremaining: 49.4s\n",
      "1123:\tlearn: 2.6839948\ttotal: 16s\tremaining: 49.4s\n",
      "1124:\tlearn: 2.6835271\ttotal: 16s\tremaining: 49.4s\n",
      "1125:\tlearn: 2.6827785\ttotal: 16s\tremaining: 49.4s\n",
      "1126:\tlearn: 2.6820088\ttotal: 16s\tremaining: 49.3s\n",
      "1127:\tlearn: 2.6816331\ttotal: 16s\tremaining: 49.3s\n",
      "1128:\tlearn: 2.6809632\ttotal: 16s\tremaining: 49.3s\n",
      "1129:\tlearn: 2.6806285\ttotal: 16.1s\tremaining: 49.3s\n",
      "1130:\tlearn: 2.6799605\ttotal: 16.1s\tremaining: 49.3s\n",
      "1131:\tlearn: 2.6794356\ttotal: 16.1s\tremaining: 49.3s\n",
      "1132:\tlearn: 2.6785837\ttotal: 16.1s\tremaining: 49.3s\n",
      "1133:\tlearn: 2.6780911\ttotal: 16.1s\tremaining: 49.2s\n",
      "1134:\tlearn: 2.6775079\ttotal: 16.1s\tremaining: 49.2s\n",
      "1135:\tlearn: 2.6771638\ttotal: 16.1s\tremaining: 49.2s\n",
      "1136:\tlearn: 2.6765589\ttotal: 16.2s\tremaining: 49.2s\n",
      "1137:\tlearn: 2.6758403\ttotal: 16.2s\tremaining: 49.2s\n",
      "1138:\tlearn: 2.6753524\ttotal: 16.2s\tremaining: 49.2s\n",
      "1139:\tlearn: 2.6746432\ttotal: 16.2s\tremaining: 49.1s\n",
      "1140:\tlearn: 2.6738947\ttotal: 16.2s\tremaining: 49.1s\n",
      "1141:\tlearn: 2.6731995\ttotal: 16.2s\tremaining: 49.1s\n",
      "1142:\tlearn: 2.6726318\ttotal: 16.2s\tremaining: 49.1s\n",
      "1143:\tlearn: 2.6714558\ttotal: 16.3s\tremaining: 49.1s\n",
      "1144:\tlearn: 2.6709275\ttotal: 16.3s\tremaining: 49.1s\n",
      "1145:\tlearn: 2.6706432\ttotal: 16.3s\tremaining: 49.1s\n",
      "1146:\tlearn: 2.6701771\ttotal: 16.3s\tremaining: 49s\n",
      "1147:\tlearn: 2.6690496\ttotal: 16.3s\tremaining: 49s\n",
      "1148:\tlearn: 2.6677810\ttotal: 16.3s\tremaining: 49s\n",
      "1149:\tlearn: 2.6676328\ttotal: 16.3s\tremaining: 49s\n",
      "1150:\tlearn: 2.6673029\ttotal: 16.4s\tremaining: 49s\n",
      "1151:\tlearn: 2.6668453\ttotal: 16.4s\tremaining: 49s\n",
      "1152:\tlearn: 2.6660927\ttotal: 16.4s\tremaining: 49s\n",
      "1153:\tlearn: 2.6655481\ttotal: 16.4s\tremaining: 49s\n",
      "1154:\tlearn: 2.6653280\ttotal: 16.4s\tremaining: 48.9s\n",
      "1155:\tlearn: 2.6647200\ttotal: 16.4s\tremaining: 48.9s\n",
      "1156:\tlearn: 2.6633188\ttotal: 16.4s\tremaining: 48.9s\n",
      "1157:\tlearn: 2.6629965\ttotal: 16.5s\tremaining: 48.9s\n",
      "1158:\tlearn: 2.6627020\ttotal: 16.5s\tremaining: 48.9s\n",
      "1159:\tlearn: 2.6622912\ttotal: 16.5s\tremaining: 48.9s\n",
      "1160:\tlearn: 2.6616757\ttotal: 16.5s\tremaining: 48.8s\n",
      "1161:\tlearn: 2.6612817\ttotal: 16.5s\tremaining: 48.8s\n",
      "1162:\tlearn: 2.6606089\ttotal: 16.5s\tremaining: 48.8s\n",
      "1163:\tlearn: 2.6599865\ttotal: 16.5s\tremaining: 48.8s\n",
      "1164:\tlearn: 2.6597492\ttotal: 16.6s\tremaining: 48.8s\n",
      "1165:\tlearn: 2.6589083\ttotal: 16.6s\tremaining: 48.8s\n",
      "1166:\tlearn: 2.6582088\ttotal: 16.6s\tremaining: 48.8s\n",
      "1167:\tlearn: 2.6576458\ttotal: 16.6s\tremaining: 48.8s\n",
      "1168:\tlearn: 2.6566596\ttotal: 16.6s\tremaining: 48.7s\n",
      "1169:\tlearn: 2.6560748\ttotal: 16.6s\tremaining: 48.7s\n",
      "1170:\tlearn: 2.6558612\ttotal: 16.6s\tremaining: 48.7s\n",
      "1171:\tlearn: 2.6551251\ttotal: 16.7s\tremaining: 48.7s\n",
      "1172:\tlearn: 2.6546087\ttotal: 16.7s\tremaining: 48.7s\n",
      "1173:\tlearn: 2.6540945\ttotal: 16.7s\tremaining: 48.7s\n",
      "1174:\tlearn: 2.6539887\ttotal: 16.7s\tremaining: 48.7s\n",
      "1175:\tlearn: 2.6533290\ttotal: 16.7s\tremaining: 48.6s\n",
      "1176:\tlearn: 2.6525135\ttotal: 16.7s\tremaining: 48.6s\n",
      "1177:\tlearn: 2.6524361\ttotal: 16.8s\tremaining: 48.6s\n",
      "1178:\tlearn: 2.6520628\ttotal: 16.8s\tremaining: 48.6s\n",
      "1179:\tlearn: 2.6514621\ttotal: 16.8s\tremaining: 48.6s\n",
      "1180:\tlearn: 2.6513611\ttotal: 16.8s\tremaining: 48.6s\n",
      "1181:\tlearn: 2.6507986\ttotal: 16.8s\tremaining: 48.6s\n",
      "1182:\tlearn: 2.6501390\ttotal: 16.8s\tremaining: 48.6s\n",
      "1183:\tlearn: 2.6496508\ttotal: 16.8s\tremaining: 48.6s\n",
      "1184:\tlearn: 2.6491942\ttotal: 16.9s\tremaining: 48.5s\n",
      "1185:\tlearn: 2.6488325\ttotal: 16.9s\tremaining: 48.5s\n",
      "1186:\tlearn: 2.6481815\ttotal: 16.9s\tremaining: 48.5s\n",
      "1187:\tlearn: 2.6477956\ttotal: 16.9s\tremaining: 48.5s\n",
      "1188:\tlearn: 2.6470927\ttotal: 16.9s\tremaining: 48.5s\n",
      "1189:\tlearn: 2.6463655\ttotal: 16.9s\tremaining: 48.5s\n",
      "1190:\tlearn: 2.6458128\ttotal: 16.9s\tremaining: 48.5s\n",
      "1191:\tlearn: 2.6454824\ttotal: 17s\tremaining: 48.5s\n",
      "1192:\tlearn: 2.6445402\ttotal: 17s\tremaining: 48.4s\n",
      "1193:\tlearn: 2.6439810\ttotal: 17s\tremaining: 48.4s\n",
      "1194:\tlearn: 2.6436992\ttotal: 17s\tremaining: 48.4s\n",
      "1195:\tlearn: 2.6427695\ttotal: 17s\tremaining: 48.4s\n",
      "1196:\tlearn: 2.6421136\ttotal: 17s\tremaining: 48.4s\n",
      "1197:\tlearn: 2.6416353\ttotal: 17s\tremaining: 48.4s\n",
      "1198:\tlearn: 2.6411009\ttotal: 17.1s\tremaining: 48.4s\n",
      "1199:\tlearn: 2.6401879\ttotal: 17.1s\tremaining: 48.3s\n",
      "1200:\tlearn: 2.6398644\ttotal: 17.1s\tremaining: 48.3s\n",
      "1201:\tlearn: 2.6396269\ttotal: 17.1s\tremaining: 48.3s\n",
      "1202:\tlearn: 2.6392740\ttotal: 17.1s\tremaining: 48.3s\n",
      "1203:\tlearn: 2.6387823\ttotal: 17.1s\tremaining: 48.3s\n",
      "1204:\tlearn: 2.6381167\ttotal: 17.1s\tremaining: 48.3s\n",
      "1205:\tlearn: 2.6370138\ttotal: 17.2s\tremaining: 48.3s\n",
      "1206:\tlearn: 2.6360595\ttotal: 17.2s\tremaining: 48.2s\n",
      "1207:\tlearn: 2.6355268\ttotal: 17.2s\tremaining: 48.2s\n",
      "1208:\tlearn: 2.6348336\ttotal: 17.2s\tremaining: 48.2s\n",
      "1209:\tlearn: 2.6342728\ttotal: 17.2s\tremaining: 48.2s\n",
      "1210:\tlearn: 2.6341753\ttotal: 17.2s\tremaining: 48.2s\n",
      "1211:\tlearn: 2.6337125\ttotal: 17.2s\tremaining: 48.2s\n",
      "1212:\tlearn: 2.6331269\ttotal: 17.3s\tremaining: 48.1s\n",
      "1213:\tlearn: 2.6324072\ttotal: 17.3s\tremaining: 48.1s\n",
      "1214:\tlearn: 2.6319506\ttotal: 17.3s\tremaining: 48.1s\n",
      "1215:\tlearn: 2.6313424\ttotal: 17.3s\tremaining: 48.1s\n",
      "1216:\tlearn: 2.6309881\ttotal: 17.3s\tremaining: 48.1s\n",
      "1217:\tlearn: 2.6305542\ttotal: 17.3s\tremaining: 48.1s\n",
      "1218:\tlearn: 2.6301564\ttotal: 17.3s\tremaining: 48s\n",
      "1219:\tlearn: 2.6297287\ttotal: 17.3s\tremaining: 48s\n",
      "1220:\tlearn: 2.6297248\ttotal: 17.4s\tremaining: 48s\n",
      "1221:\tlearn: 2.6292428\ttotal: 17.4s\tremaining: 48s\n",
      "1222:\tlearn: 2.6280689\ttotal: 17.4s\tremaining: 48s\n",
      "1223:\tlearn: 2.6277288\ttotal: 17.4s\tremaining: 48s\n",
      "1224:\tlearn: 2.6272428\ttotal: 17.4s\tremaining: 47.9s\n",
      "1225:\tlearn: 2.6272150\ttotal: 17.4s\tremaining: 47.9s\n",
      "1226:\tlearn: 2.6265047\ttotal: 17.4s\tremaining: 47.9s\n",
      "1227:\tlearn: 2.6259278\ttotal: 17.5s\tremaining: 47.9s\n",
      "1228:\tlearn: 2.6255464\ttotal: 17.5s\tremaining: 47.9s\n",
      "1229:\tlearn: 2.6248041\ttotal: 17.5s\tremaining: 47.9s\n",
      "1230:\tlearn: 2.6240806\ttotal: 17.5s\tremaining: 47.8s\n",
      "1231:\tlearn: 2.6239790\ttotal: 17.5s\tremaining: 47.8s\n",
      "1232:\tlearn: 2.6236297\ttotal: 17.5s\tremaining: 47.8s\n",
      "1233:\tlearn: 2.6235071\ttotal: 17.5s\tremaining: 47.8s\n",
      "1234:\tlearn: 2.6226026\ttotal: 17.5s\tremaining: 47.8s\n",
      "1235:\tlearn: 2.6207134\ttotal: 17.6s\tremaining: 47.8s\n",
      "1236:\tlearn: 2.6199532\ttotal: 17.6s\tremaining: 47.8s\n",
      "1237:\tlearn: 2.6192064\ttotal: 17.6s\tremaining: 47.7s\n",
      "1238:\tlearn: 2.6185773\ttotal: 17.6s\tremaining: 47.7s\n",
      "1239:\tlearn: 2.6180784\ttotal: 17.6s\tremaining: 47.7s\n",
      "1240:\tlearn: 2.6173563\ttotal: 17.6s\tremaining: 47.7s\n",
      "1241:\tlearn: 2.6167047\ttotal: 17.6s\tremaining: 47.7s\n",
      "1242:\tlearn: 2.6160544\ttotal: 17.7s\tremaining: 47.7s\n",
      "1243:\tlearn: 2.6157680\ttotal: 17.7s\tremaining: 47.6s\n",
      "1244:\tlearn: 2.6150856\ttotal: 17.7s\tremaining: 47.6s\n",
      "1245:\tlearn: 2.6145385\ttotal: 17.7s\tremaining: 47.6s\n",
      "1246:\tlearn: 2.6137748\ttotal: 17.7s\tremaining: 47.6s\n",
      "1247:\tlearn: 2.6136422\ttotal: 17.7s\tremaining: 47.6s\n",
      "1248:\tlearn: 2.6132153\ttotal: 17.7s\tremaining: 47.6s\n",
      "1249:\tlearn: 2.6125935\ttotal: 17.8s\tremaining: 47.6s\n",
      "1250:\tlearn: 2.6121758\ttotal: 17.8s\tremaining: 47.5s\n",
      "1251:\tlearn: 2.6116647\ttotal: 17.8s\tremaining: 47.5s\n",
      "1252:\tlearn: 2.6108598\ttotal: 17.8s\tremaining: 47.5s\n",
      "1253:\tlearn: 2.6103958\ttotal: 17.8s\tremaining: 47.5s\n",
      "1254:\tlearn: 2.6099223\ttotal: 17.8s\tremaining: 47.5s\n",
      "1255:\tlearn: 2.6094281\ttotal: 17.8s\tremaining: 47.5s\n",
      "1256:\tlearn: 2.6087990\ttotal: 17.9s\tremaining: 47.5s\n",
      "1257:\tlearn: 2.6087959\ttotal: 17.9s\tremaining: 47.5s\n",
      "1258:\tlearn: 2.6083256\ttotal: 17.9s\tremaining: 47.5s\n",
      "1259:\tlearn: 2.6080876\ttotal: 17.9s\tremaining: 47.4s\n",
      "1260:\tlearn: 2.6076820\ttotal: 17.9s\tremaining: 47.4s\n",
      "1261:\tlearn: 2.6071051\ttotal: 17.9s\tremaining: 47.4s\n",
      "1262:\tlearn: 2.6067163\ttotal: 18s\tremaining: 47.4s\n",
      "1263:\tlearn: 2.6060718\ttotal: 18s\tremaining: 47.4s\n",
      "1264:\tlearn: 2.6056834\ttotal: 18s\tremaining: 47.4s\n",
      "1265:\tlearn: 2.6053460\ttotal: 18s\tremaining: 47.4s\n",
      "1266:\tlearn: 2.6042348\ttotal: 18s\tremaining: 47.4s\n",
      "1267:\tlearn: 2.6035601\ttotal: 18s\tremaining: 47.3s\n",
      "1268:\tlearn: 2.6029634\ttotal: 18s\tremaining: 47.3s\n",
      "1269:\tlearn: 2.6026013\ttotal: 18.1s\tremaining: 47.3s\n",
      "1270:\tlearn: 2.6023802\ttotal: 18.1s\tremaining: 47.3s\n",
      "1271:\tlearn: 2.6023773\ttotal: 18.1s\tremaining: 47.3s\n",
      "1272:\tlearn: 2.6019548\ttotal: 18.1s\tremaining: 47.3s\n",
      "1273:\tlearn: 2.6014684\ttotal: 18.1s\tremaining: 47.2s\n",
      "1274:\tlearn: 2.6011916\ttotal: 18.1s\tremaining: 47.2s\n",
      "1275:\tlearn: 2.6007209\ttotal: 18.1s\tremaining: 47.2s\n",
      "1276:\tlearn: 2.6001776\ttotal: 18.1s\tremaining: 47.2s\n",
      "1277:\tlearn: 2.5996880\ttotal: 18.2s\tremaining: 47.2s\n",
      "1278:\tlearn: 2.5991266\ttotal: 18.2s\tremaining: 47.2s\n",
      "1279:\tlearn: 2.5982422\ttotal: 18.2s\tremaining: 47.2s\n",
      "1280:\tlearn: 2.5979241\ttotal: 18.2s\tremaining: 47.1s\n",
      "1281:\tlearn: 2.5975255\ttotal: 18.2s\tremaining: 47.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1282:\tlearn: 2.5970576\ttotal: 18.2s\tremaining: 47.1s\n",
      "1283:\tlearn: 2.5964387\ttotal: 18.3s\tremaining: 47.1s\n",
      "1284:\tlearn: 2.5959975\ttotal: 18.3s\tremaining: 47.1s\n",
      "1285:\tlearn: 2.5952115\ttotal: 18.3s\tremaining: 47.1s\n",
      "1286:\tlearn: 2.5944189\ttotal: 18.3s\tremaining: 47.1s\n",
      "1287:\tlearn: 2.5935948\ttotal: 18.3s\tremaining: 47s\n",
      "1288:\tlearn: 2.5932914\ttotal: 18.3s\tremaining: 47s\n",
      "1289:\tlearn: 2.5927147\ttotal: 18.3s\tremaining: 47s\n",
      "1290:\tlearn: 2.5922972\ttotal: 18.3s\tremaining: 47s\n",
      "1291:\tlearn: 2.5919575\ttotal: 18.4s\tremaining: 47s\n",
      "1292:\tlearn: 2.5915301\ttotal: 18.4s\tremaining: 47s\n",
      "1293:\tlearn: 2.5910525\ttotal: 18.4s\tremaining: 46.9s\n",
      "1294:\tlearn: 2.5907236\ttotal: 18.4s\tremaining: 46.9s\n",
      "1295:\tlearn: 2.5897322\ttotal: 18.4s\tremaining: 46.9s\n",
      "1296:\tlearn: 2.5894612\ttotal: 18.4s\tremaining: 46.9s\n",
      "1297:\tlearn: 2.5890270\ttotal: 18.4s\tremaining: 46.9s\n",
      "1298:\tlearn: 2.5887703\ttotal: 18.4s\tremaining: 46.9s\n",
      "1299:\tlearn: 2.5877290\ttotal: 18.5s\tremaining: 46.8s\n",
      "1300:\tlearn: 2.5869269\ttotal: 18.5s\tremaining: 46.8s\n",
      "1301:\tlearn: 2.5865540\ttotal: 18.5s\tremaining: 46.8s\n",
      "1302:\tlearn: 2.5860285\ttotal: 18.5s\tremaining: 46.8s\n",
      "1303:\tlearn: 2.5853074\ttotal: 18.5s\tremaining: 46.8s\n",
      "1304:\tlearn: 2.5847529\ttotal: 18.5s\tremaining: 46.8s\n",
      "1305:\tlearn: 2.5842832\ttotal: 18.5s\tremaining: 46.7s\n",
      "1306:\tlearn: 2.5838180\ttotal: 18.6s\tremaining: 46.7s\n",
      "1307:\tlearn: 2.5830282\ttotal: 18.6s\tremaining: 46.7s\n",
      "1308:\tlearn: 2.5826701\ttotal: 18.6s\tremaining: 46.7s\n",
      "1309:\tlearn: 2.5824590\ttotal: 18.6s\tremaining: 46.7s\n",
      "1310:\tlearn: 2.5815151\ttotal: 18.6s\tremaining: 46.7s\n",
      "1311:\tlearn: 2.5809008\ttotal: 18.6s\tremaining: 46.6s\n",
      "1312:\tlearn: 2.5804184\ttotal: 18.6s\tremaining: 46.6s\n",
      "1313:\tlearn: 2.5796061\ttotal: 18.7s\tremaining: 46.6s\n",
      "1314:\tlearn: 2.5792364\ttotal: 18.7s\tremaining: 46.6s\n",
      "1315:\tlearn: 2.5789778\ttotal: 18.7s\tremaining: 46.6s\n",
      "1316:\tlearn: 2.5785233\ttotal: 18.7s\tremaining: 46.6s\n",
      "1317:\tlearn: 2.5779318\ttotal: 18.7s\tremaining: 46.6s\n",
      "1318:\tlearn: 2.5775072\ttotal: 18.7s\tremaining: 46.5s\n",
      "1319:\tlearn: 2.5773259\ttotal: 18.7s\tremaining: 46.5s\n",
      "1320:\tlearn: 2.5770723\ttotal: 18.7s\tremaining: 46.5s\n",
      "1321:\tlearn: 2.5768235\ttotal: 18.8s\tremaining: 46.5s\n",
      "1322:\tlearn: 2.5760534\ttotal: 18.8s\tremaining: 46.5s\n",
      "1323:\tlearn: 2.5758393\ttotal: 18.8s\tremaining: 46.5s\n",
      "1324:\tlearn: 2.5750206\ttotal: 18.8s\tremaining: 46.4s\n",
      "1325:\tlearn: 2.5747980\ttotal: 18.8s\tremaining: 46.4s\n",
      "1326:\tlearn: 2.5746327\ttotal: 18.8s\tremaining: 46.4s\n",
      "1327:\tlearn: 2.5743735\ttotal: 18.8s\tremaining: 46.4s\n",
      "1328:\tlearn: 2.5740164\ttotal: 18.9s\tremaining: 46.4s\n",
      "1329:\tlearn: 2.5734166\ttotal: 18.9s\tremaining: 46.4s\n",
      "1330:\tlearn: 2.5730557\ttotal: 18.9s\tremaining: 46.4s\n",
      "1331:\tlearn: 2.5728770\ttotal: 18.9s\tremaining: 46.3s\n",
      "1332:\tlearn: 2.5723773\ttotal: 18.9s\tremaining: 46.3s\n",
      "1333:\tlearn: 2.5720355\ttotal: 18.9s\tremaining: 46.3s\n",
      "1334:\tlearn: 2.5714713\ttotal: 18.9s\tremaining: 46.3s\n",
      "1335:\tlearn: 2.5710303\ttotal: 19s\tremaining: 46.3s\n",
      "1336:\tlearn: 2.5702031\ttotal: 19s\tremaining: 46.3s\n",
      "1337:\tlearn: 2.5694423\ttotal: 19s\tremaining: 46.2s\n",
      "1338:\tlearn: 2.5688871\ttotal: 19s\tremaining: 46.2s\n",
      "1339:\tlearn: 2.5685992\ttotal: 19s\tremaining: 46.2s\n",
      "1340:\tlearn: 2.5682267\ttotal: 19s\tremaining: 46.2s\n",
      "1341:\tlearn: 2.5677734\ttotal: 19s\tremaining: 46.2s\n",
      "1342:\tlearn: 2.5675017\ttotal: 19.1s\tremaining: 46.2s\n",
      "1343:\tlearn: 2.5666032\ttotal: 19.1s\tremaining: 46.2s\n",
      "1344:\tlearn: 2.5660404\ttotal: 19.1s\tremaining: 46.2s\n",
      "1345:\tlearn: 2.5653680\ttotal: 19.1s\tremaining: 46.1s\n",
      "1346:\tlearn: 2.5648019\ttotal: 19.1s\tremaining: 46.1s\n",
      "1347:\tlearn: 2.5643615\ttotal: 19.1s\tremaining: 46.1s\n",
      "1348:\tlearn: 2.5638353\ttotal: 19.1s\tremaining: 46.1s\n",
      "1349:\tlearn: 2.5631850\ttotal: 19.2s\tremaining: 46.1s\n",
      "1350:\tlearn: 2.5627933\ttotal: 19.2s\tremaining: 46.1s\n",
      "1351:\tlearn: 2.5624923\ttotal: 19.2s\tremaining: 46.1s\n",
      "1352:\tlearn: 2.5622707\ttotal: 19.2s\tremaining: 46s\n",
      "1353:\tlearn: 2.5618715\ttotal: 19.2s\tremaining: 46s\n",
      "1354:\tlearn: 2.5614878\ttotal: 19.2s\tremaining: 46s\n",
      "1355:\tlearn: 2.5600285\ttotal: 19.2s\tremaining: 46s\n",
      "1356:\tlearn: 2.5590445\ttotal: 19.3s\tremaining: 46s\n",
      "1357:\tlearn: 2.5581589\ttotal: 19.3s\tremaining: 46s\n",
      "1358:\tlearn: 2.5576455\ttotal: 19.3s\tremaining: 46s\n",
      "1359:\tlearn: 2.5569172\ttotal: 19.3s\tremaining: 46s\n",
      "1360:\tlearn: 2.5564698\ttotal: 19.3s\tremaining: 45.9s\n",
      "1361:\tlearn: 2.5556420\ttotal: 19.3s\tremaining: 45.9s\n",
      "1362:\tlearn: 2.5553828\ttotal: 19.3s\tremaining: 45.9s\n",
      "1363:\tlearn: 2.5546615\ttotal: 19.4s\tremaining: 45.9s\n",
      "1364:\tlearn: 2.5542524\ttotal: 19.4s\tremaining: 45.9s\n",
      "1365:\tlearn: 2.5539543\ttotal: 19.4s\tremaining: 45.9s\n",
      "1366:\tlearn: 2.5534702\ttotal: 19.4s\tremaining: 45.9s\n",
      "1367:\tlearn: 2.5533552\ttotal: 19.4s\tremaining: 45.8s\n",
      "1368:\tlearn: 2.5531739\ttotal: 19.4s\tremaining: 45.8s\n",
      "1369:\tlearn: 2.5528467\ttotal: 19.4s\tremaining: 45.8s\n",
      "1370:\tlearn: 2.5520883\ttotal: 19.5s\tremaining: 45.8s\n",
      "1371:\tlearn: 2.5512150\ttotal: 19.5s\tremaining: 45.8s\n",
      "1372:\tlearn: 2.5506816\ttotal: 19.5s\tremaining: 45.8s\n",
      "1373:\tlearn: 2.5502568\ttotal: 19.5s\tremaining: 45.8s\n",
      "1374:\tlearn: 2.5499625\ttotal: 19.5s\tremaining: 45.7s\n",
      "1375:\tlearn: 2.5492911\ttotal: 19.5s\tremaining: 45.7s\n",
      "1376:\tlearn: 2.5487458\ttotal: 19.5s\tremaining: 45.7s\n",
      "1377:\tlearn: 2.5481957\ttotal: 19.6s\tremaining: 45.7s\n",
      "1378:\tlearn: 2.5477275\ttotal: 19.6s\tremaining: 45.7s\n",
      "1379:\tlearn: 2.5472081\ttotal: 19.6s\tremaining: 45.7s\n",
      "1380:\tlearn: 2.5466475\ttotal: 19.6s\tremaining: 45.7s\n",
      "1381:\tlearn: 2.5463581\ttotal: 19.6s\tremaining: 45.6s\n",
      "1382:\tlearn: 2.5457903\ttotal: 19.6s\tremaining: 45.6s\n",
      "1383:\tlearn: 2.5453862\ttotal: 19.6s\tremaining: 45.6s\n",
      "1384:\tlearn: 2.5447471\ttotal: 19.7s\tremaining: 45.6s\n",
      "1385:\tlearn: 2.5439058\ttotal: 19.7s\tremaining: 45.6s\n",
      "1386:\tlearn: 2.5436390\ttotal: 19.7s\tremaining: 45.6s\n",
      "1387:\tlearn: 2.5430235\ttotal: 19.7s\tremaining: 45.6s\n",
      "1388:\tlearn: 2.5423093\ttotal: 19.7s\tremaining: 45.5s\n",
      "1389:\tlearn: 2.5423068\ttotal: 19.7s\tremaining: 45.5s\n",
      "1390:\tlearn: 2.5416180\ttotal: 19.7s\tremaining: 45.5s\n",
      "1391:\tlearn: 2.5410537\ttotal: 19.8s\tremaining: 45.5s\n",
      "1392:\tlearn: 2.5407358\ttotal: 19.8s\tremaining: 45.5s\n",
      "1393:\tlearn: 2.5401964\ttotal: 19.8s\tremaining: 45.5s\n",
      "1394:\tlearn: 2.5395871\ttotal: 19.8s\tremaining: 45.5s\n",
      "1395:\tlearn: 2.5390162\ttotal: 19.8s\tremaining: 45.4s\n",
      "1396:\tlearn: 2.5385901\ttotal: 19.8s\tremaining: 45.4s\n",
      "1397:\tlearn: 2.5383445\ttotal: 19.8s\tremaining: 45.4s\n",
      "1398:\tlearn: 2.5375214\ttotal: 19.9s\tremaining: 45.4s\n",
      "1399:\tlearn: 2.5370849\ttotal: 19.9s\tremaining: 45.4s\n",
      "1400:\tlearn: 2.5366093\ttotal: 19.9s\tremaining: 45.4s\n",
      "1401:\tlearn: 2.5358628\ttotal: 19.9s\tremaining: 45.4s\n",
      "1402:\tlearn: 2.5353848\ttotal: 19.9s\tremaining: 45.3s\n",
      "1403:\tlearn: 2.5346760\ttotal: 19.9s\tremaining: 45.3s\n",
      "1404:\tlearn: 2.5345753\ttotal: 19.9s\tremaining: 45.3s\n",
      "1405:\tlearn: 2.5340072\ttotal: 20s\tremaining: 45.3s\n",
      "1406:\tlearn: 2.5336668\ttotal: 20s\tremaining: 45.3s\n",
      "1407:\tlearn: 2.5325858\ttotal: 20s\tremaining: 45.3s\n",
      "1408:\tlearn: 2.5318557\ttotal: 20s\tremaining: 45.3s\n",
      "1409:\tlearn: 2.5309245\ttotal: 20s\tremaining: 45.2s\n",
      "1410:\tlearn: 2.5304051\ttotal: 20s\tremaining: 45.2s\n",
      "1411:\tlearn: 2.5294372\ttotal: 20s\tremaining: 45.2s\n",
      "1412:\tlearn: 2.5290458\ttotal: 20.1s\tremaining: 45.2s\n",
      "1413:\tlearn: 2.5284945\ttotal: 20.1s\tremaining: 45.2s\n",
      "1414:\tlearn: 2.5277672\ttotal: 20.1s\tremaining: 45.2s\n",
      "1415:\tlearn: 2.5276303\ttotal: 20.1s\tremaining: 45.2s\n",
      "1416:\tlearn: 2.5270840\ttotal: 20.1s\tremaining: 45.1s\n",
      "1417:\tlearn: 2.5263335\ttotal: 20.1s\tremaining: 45.1s\n",
      "1418:\tlearn: 2.5255531\ttotal: 20.1s\tremaining: 45.1s\n",
      "1419:\tlearn: 2.5251864\ttotal: 20.1s\tremaining: 45.1s\n",
      "1420:\tlearn: 2.5244162\ttotal: 20.2s\tremaining: 45.1s\n",
      "1421:\tlearn: 2.5238986\ttotal: 20.2s\tremaining: 45.1s\n",
      "1422:\tlearn: 2.5227891\ttotal: 20.2s\tremaining: 45.1s\n",
      "1423:\tlearn: 2.5223188\ttotal: 20.2s\tremaining: 45s\n",
      "1424:\tlearn: 2.5214303\ttotal: 20.2s\tremaining: 45s\n",
      "1425:\tlearn: 2.5209733\ttotal: 20.2s\tremaining: 45s\n",
      "1426:\tlearn: 2.5203766\ttotal: 20.3s\tremaining: 45s\n",
      "1427:\tlearn: 2.5198038\ttotal: 20.3s\tremaining: 45s\n",
      "1428:\tlearn: 2.5191378\ttotal: 20.3s\tremaining: 45s\n",
      "1429:\tlearn: 2.5186424\ttotal: 20.3s\tremaining: 45s\n",
      "1430:\tlearn: 2.5181588\ttotal: 20.3s\tremaining: 44.9s\n",
      "1431:\tlearn: 2.5179065\ttotal: 20.3s\tremaining: 44.9s\n",
      "1432:\tlearn: 2.5175838\ttotal: 20.3s\tremaining: 44.9s\n",
      "1433:\tlearn: 2.5167267\ttotal: 20.4s\tremaining: 44.9s\n",
      "1434:\tlearn: 2.5163011\ttotal: 20.4s\tremaining: 44.9s\n",
      "1435:\tlearn: 2.5158368\ttotal: 20.4s\tremaining: 44.9s\n",
      "1436:\tlearn: 2.5150818\ttotal: 20.4s\tremaining: 44.9s\n",
      "1437:\tlearn: 2.5146498\ttotal: 20.4s\tremaining: 44.9s\n",
      "1438:\tlearn: 2.5140462\ttotal: 20.4s\tremaining: 44.8s\n",
      "1439:\tlearn: 2.5135106\ttotal: 20.4s\tremaining: 44.8s\n",
      "1440:\tlearn: 2.5131396\ttotal: 20.4s\tremaining: 44.8s\n",
      "1441:\tlearn: 2.5127539\ttotal: 20.5s\tremaining: 44.8s\n",
      "1442:\tlearn: 2.5123789\ttotal: 20.5s\tremaining: 44.8s\n",
      "1443:\tlearn: 2.5119803\ttotal: 20.5s\tremaining: 44.8s\n",
      "1444:\tlearn: 2.5115076\ttotal: 20.5s\tremaining: 44.7s\n",
      "1445:\tlearn: 2.5111453\ttotal: 20.5s\tremaining: 44.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1446:\tlearn: 2.5103610\ttotal: 20.5s\tremaining: 44.7s\n",
      "1447:\tlearn: 2.5098321\ttotal: 20.5s\tremaining: 44.7s\n",
      "1448:\tlearn: 2.5093475\ttotal: 20.6s\tremaining: 44.7s\n",
      "1449:\tlearn: 2.5090906\ttotal: 20.6s\tremaining: 44.7s\n",
      "1450:\tlearn: 2.5084609\ttotal: 20.6s\tremaining: 44.7s\n",
      "1451:\tlearn: 2.5079960\ttotal: 20.6s\tremaining: 44.6s\n",
      "1452:\tlearn: 2.5071570\ttotal: 20.6s\tremaining: 44.6s\n",
      "1453:\tlearn: 2.5065935\ttotal: 20.6s\tremaining: 44.6s\n",
      "1454:\tlearn: 2.5064012\ttotal: 20.6s\tremaining: 44.6s\n",
      "1455:\tlearn: 2.5062879\ttotal: 20.7s\tremaining: 44.6s\n",
      "1456:\tlearn: 2.5056879\ttotal: 20.7s\tremaining: 44.6s\n",
      "1457:\tlearn: 2.5049288\ttotal: 20.7s\tremaining: 44.6s\n",
      "1458:\tlearn: 2.5038377\ttotal: 20.7s\tremaining: 44.5s\n",
      "1459:\tlearn: 2.5035676\ttotal: 20.7s\tremaining: 44.5s\n",
      "1460:\tlearn: 2.5035655\ttotal: 20.7s\tremaining: 44.5s\n",
      "1461:\tlearn: 2.5029669\ttotal: 20.7s\tremaining: 44.5s\n",
      "1462:\tlearn: 2.5019976\ttotal: 20.8s\tremaining: 44.5s\n",
      "1463:\tlearn: 2.5014457\ttotal: 20.8s\tremaining: 44.5s\n",
      "1464:\tlearn: 2.5006013\ttotal: 20.8s\tremaining: 44.5s\n",
      "1465:\tlearn: 2.5003496\ttotal: 20.8s\tremaining: 44.4s\n",
      "1466:\tlearn: 2.4999783\ttotal: 20.8s\tremaining: 44.4s\n",
      "1467:\tlearn: 2.4994446\ttotal: 20.8s\tremaining: 44.4s\n",
      "1468:\tlearn: 2.4986548\ttotal: 20.8s\tremaining: 44.4s\n",
      "1469:\tlearn: 2.4984263\ttotal: 20.9s\tremaining: 44.4s\n",
      "1470:\tlearn: 2.4981781\ttotal: 20.9s\tremaining: 44.4s\n",
      "1471:\tlearn: 2.4976232\ttotal: 20.9s\tremaining: 44.4s\n",
      "1472:\tlearn: 2.4972614\ttotal: 20.9s\tremaining: 44.3s\n",
      "1473:\tlearn: 2.4969095\ttotal: 20.9s\tremaining: 44.3s\n",
      "1474:\tlearn: 2.4962725\ttotal: 20.9s\tremaining: 44.3s\n",
      "1475:\tlearn: 2.4956061\ttotal: 20.9s\tremaining: 44.3s\n",
      "1476:\tlearn: 2.4949398\ttotal: 21s\tremaining: 44.3s\n",
      "1477:\tlearn: 2.4944434\ttotal: 21s\tremaining: 44.3s\n",
      "1478:\tlearn: 2.4939292\ttotal: 21s\tremaining: 44.3s\n",
      "1479:\tlearn: 2.4932414\ttotal: 21s\tremaining: 44.2s\n",
      "1480:\tlearn: 2.4923646\ttotal: 21s\tremaining: 44.2s\n",
      "1481:\tlearn: 2.4912488\ttotal: 21s\tremaining: 44.2s\n",
      "1482:\tlearn: 2.4908091\ttotal: 21s\tremaining: 44.2s\n",
      "1483:\tlearn: 2.4901257\ttotal: 21.1s\tremaining: 44.2s\n",
      "1484:\tlearn: 2.4895743\ttotal: 21.1s\tremaining: 44.2s\n",
      "1485:\tlearn: 2.4890041\ttotal: 21.1s\tremaining: 44.2s\n",
      "1486:\tlearn: 2.4886061\ttotal: 21.1s\tremaining: 44.1s\n",
      "1487:\tlearn: 2.4882961\ttotal: 21.1s\tremaining: 44.1s\n",
      "1488:\tlearn: 2.4878690\ttotal: 21.1s\tremaining: 44.1s\n",
      "1489:\tlearn: 2.4874232\ttotal: 21.1s\tremaining: 44.1s\n",
      "1490:\tlearn: 2.4868517\ttotal: 21.2s\tremaining: 44.1s\n",
      "1491:\tlearn: 2.4868493\ttotal: 21.2s\tremaining: 44.1s\n",
      "1492:\tlearn: 2.4862498\ttotal: 21.2s\tremaining: 44.1s\n",
      "1493:\tlearn: 2.4858684\ttotal: 21.2s\tremaining: 44s\n",
      "1494:\tlearn: 2.4853277\ttotal: 21.2s\tremaining: 44s\n",
      "1495:\tlearn: 2.4847803\ttotal: 21.2s\tremaining: 44s\n",
      "1496:\tlearn: 2.4844382\ttotal: 21.2s\tremaining: 44s\n",
      "1497:\tlearn: 2.4840895\ttotal: 21.3s\tremaining: 44s\n",
      "1498:\tlearn: 2.4837351\ttotal: 21.3s\tremaining: 44s\n",
      "1499:\tlearn: 2.4832650\ttotal: 21.3s\tremaining: 43.9s\n",
      "1500:\tlearn: 2.4830413\ttotal: 21.3s\tremaining: 43.9s\n",
      "1501:\tlearn: 2.4829839\ttotal: 21.3s\tremaining: 43.9s\n",
      "1502:\tlearn: 2.4826325\ttotal: 21.3s\tremaining: 43.9s\n",
      "1503:\tlearn: 2.4821008\ttotal: 21.3s\tremaining: 43.9s\n",
      "1504:\tlearn: 2.4813802\ttotal: 21.3s\tremaining: 43.9s\n",
      "1505:\tlearn: 2.4807429\ttotal: 21.4s\tremaining: 43.9s\n",
      "1506:\tlearn: 2.4803135\ttotal: 21.4s\tremaining: 43.8s\n",
      "1507:\tlearn: 2.4798224\ttotal: 21.4s\tremaining: 43.8s\n",
      "1508:\tlearn: 2.4795015\ttotal: 21.4s\tremaining: 43.8s\n",
      "1509:\tlearn: 2.4787429\ttotal: 21.4s\tremaining: 43.8s\n",
      "1510:\tlearn: 2.4782670\ttotal: 21.4s\tremaining: 43.8s\n",
      "1511:\tlearn: 2.4775788\ttotal: 21.4s\tremaining: 43.8s\n",
      "1512:\tlearn: 2.4772894\ttotal: 21.5s\tremaining: 43.8s\n",
      "1513:\tlearn: 2.4769794\ttotal: 21.5s\tremaining: 43.7s\n",
      "1514:\tlearn: 2.4764484\ttotal: 21.5s\tremaining: 43.7s\n",
      "1515:\tlearn: 2.4760490\ttotal: 21.5s\tremaining: 43.7s\n",
      "1516:\tlearn: 2.4756503\ttotal: 21.5s\tremaining: 43.7s\n",
      "1517:\tlearn: 2.4749979\ttotal: 21.5s\tremaining: 43.7s\n",
      "1518:\tlearn: 2.4742286\ttotal: 21.5s\tremaining: 43.7s\n",
      "1519:\tlearn: 2.4737220\ttotal: 21.6s\tremaining: 43.7s\n",
      "1520:\tlearn: 2.4731031\ttotal: 21.6s\tremaining: 43.7s\n",
      "1521:\tlearn: 2.4723930\ttotal: 21.6s\tremaining: 43.6s\n",
      "1522:\tlearn: 2.4718702\ttotal: 21.6s\tremaining: 43.6s\n",
      "1523:\tlearn: 2.4710647\ttotal: 21.6s\tremaining: 43.6s\n",
      "1524:\tlearn: 2.4705210\ttotal: 21.6s\tremaining: 43.6s\n",
      "1525:\tlearn: 2.4694925\ttotal: 21.7s\tremaining: 43.6s\n",
      "1526:\tlearn: 2.4692769\ttotal: 21.7s\tremaining: 43.6s\n",
      "1527:\tlearn: 2.4687198\ttotal: 21.7s\tremaining: 43.6s\n",
      "1528:\tlearn: 2.4683522\ttotal: 21.7s\tremaining: 43.6s\n",
      "1529:\tlearn: 2.4679934\ttotal: 21.7s\tremaining: 43.5s\n",
      "1530:\tlearn: 2.4676448\ttotal: 21.7s\tremaining: 43.5s\n",
      "1531:\tlearn: 2.4671345\ttotal: 21.7s\tremaining: 43.5s\n",
      "1532:\tlearn: 2.4665750\ttotal: 21.8s\tremaining: 43.5s\n",
      "1533:\tlearn: 2.4661194\ttotal: 21.8s\tremaining: 43.5s\n",
      "1534:\tlearn: 2.4659159\ttotal: 21.8s\tremaining: 43.5s\n",
      "1535:\tlearn: 2.4654087\ttotal: 21.8s\tremaining: 43.5s\n",
      "1536:\tlearn: 2.4651924\ttotal: 21.8s\tremaining: 43.4s\n",
      "1537:\tlearn: 2.4647213\ttotal: 21.8s\tremaining: 43.4s\n",
      "1538:\tlearn: 2.4643973\ttotal: 21.8s\tremaining: 43.4s\n",
      "1539:\tlearn: 2.4640243\ttotal: 21.9s\tremaining: 43.4s\n",
      "1540:\tlearn: 2.4634060\ttotal: 21.9s\tremaining: 43.4s\n",
      "1541:\tlearn: 2.4628802\ttotal: 21.9s\tremaining: 43.4s\n",
      "1542:\tlearn: 2.4622426\ttotal: 21.9s\tremaining: 43.4s\n",
      "1543:\tlearn: 2.4618731\ttotal: 21.9s\tremaining: 43.3s\n",
      "1544:\tlearn: 2.4616416\ttotal: 21.9s\tremaining: 43.3s\n",
      "1545:\tlearn: 2.4612749\ttotal: 21.9s\tremaining: 43.3s\n",
      "1546:\tlearn: 2.4607801\ttotal: 22s\tremaining: 43.3s\n",
      "1547:\tlearn: 2.4605350\ttotal: 22s\tremaining: 43.3s\n",
      "1548:\tlearn: 2.4603231\ttotal: 22s\tremaining: 43.3s\n",
      "1549:\tlearn: 2.4597622\ttotal: 22s\tremaining: 43.3s\n",
      "1550:\tlearn: 2.4593755\ttotal: 22s\tremaining: 43.2s\n",
      "1551:\tlearn: 2.4591079\ttotal: 22s\tremaining: 43.2s\n",
      "1552:\tlearn: 2.4585609\ttotal: 22s\tremaining: 43.2s\n",
      "1553:\tlearn: 2.4581626\ttotal: 22.1s\tremaining: 43.2s\n",
      "1554:\tlearn: 2.4575641\ttotal: 22.1s\tremaining: 43.2s\n",
      "1555:\tlearn: 2.4575071\ttotal: 22.1s\tremaining: 43.2s\n",
      "1556:\tlearn: 2.4573535\ttotal: 22.1s\tremaining: 43.1s\n",
      "1557:\tlearn: 2.4567987\ttotal: 22.1s\tremaining: 43.1s\n",
      "1558:\tlearn: 2.4559650\ttotal: 22.1s\tremaining: 43.1s\n",
      "1559:\tlearn: 2.4556498\ttotal: 22.1s\tremaining: 43.1s\n",
      "1560:\tlearn: 2.4550751\ttotal: 22.1s\tremaining: 43.1s\n",
      "1561:\tlearn: 2.4548483\ttotal: 22.2s\tremaining: 43.1s\n",
      "1562:\tlearn: 2.4540290\ttotal: 22.2s\tremaining: 43.1s\n",
      "1563:\tlearn: 2.4533400\ttotal: 22.2s\tremaining: 43s\n",
      "1564:\tlearn: 2.4526865\ttotal: 22.2s\tremaining: 43s\n",
      "1565:\tlearn: 2.4522898\ttotal: 22.2s\tremaining: 43s\n",
      "1566:\tlearn: 2.4518829\ttotal: 22.2s\tremaining: 43s\n",
      "1567:\tlearn: 2.4516156\ttotal: 22.2s\tremaining: 43s\n",
      "1568:\tlearn: 2.4510952\ttotal: 22.3s\tremaining: 43s\n",
      "1569:\tlearn: 2.4505582\ttotal: 22.3s\tremaining: 43s\n",
      "1570:\tlearn: 2.4500320\ttotal: 22.3s\tremaining: 42.9s\n",
      "1571:\tlearn: 2.4498399\ttotal: 22.3s\tremaining: 42.9s\n",
      "1572:\tlearn: 2.4494990\ttotal: 22.3s\tremaining: 42.9s\n",
      "1573:\tlearn: 2.4493368\ttotal: 22.3s\tremaining: 42.9s\n",
      "1574:\tlearn: 2.4490905\ttotal: 22.3s\tremaining: 42.9s\n",
      "1575:\tlearn: 2.4486215\ttotal: 22.4s\tremaining: 42.9s\n",
      "1576:\tlearn: 2.4481398\ttotal: 22.4s\tremaining: 42.9s\n",
      "1577:\tlearn: 2.4476248\ttotal: 22.4s\tremaining: 42.8s\n",
      "1578:\tlearn: 2.4473375\ttotal: 22.4s\tremaining: 42.8s\n",
      "1579:\tlearn: 2.4469468\ttotal: 22.4s\tremaining: 42.8s\n",
      "1580:\tlearn: 2.4465026\ttotal: 22.4s\tremaining: 42.8s\n",
      "1581:\tlearn: 2.4459259\ttotal: 22.4s\tremaining: 42.8s\n",
      "1582:\tlearn: 2.4455654\ttotal: 22.4s\tremaining: 42.8s\n",
      "1583:\tlearn: 2.4448282\ttotal: 22.5s\tremaining: 42.7s\n",
      "1584:\tlearn: 2.4442689\ttotal: 22.5s\tremaining: 42.7s\n",
      "1585:\tlearn: 2.4433831\ttotal: 22.5s\tremaining: 42.7s\n",
      "1586:\tlearn: 2.4431315\ttotal: 22.5s\tremaining: 42.7s\n",
      "1587:\tlearn: 2.4422684\ttotal: 22.5s\tremaining: 42.7s\n",
      "1588:\tlearn: 2.4416560\ttotal: 22.5s\tremaining: 42.7s\n",
      "1589:\tlearn: 2.4413403\ttotal: 22.6s\tremaining: 42.7s\n",
      "1590:\tlearn: 2.4407429\ttotal: 22.6s\tremaining: 42.6s\n",
      "1591:\tlearn: 2.4403159\ttotal: 22.6s\tremaining: 42.6s\n",
      "1592:\tlearn: 2.4396802\ttotal: 22.6s\tremaining: 42.6s\n",
      "1593:\tlearn: 2.4392298\ttotal: 22.6s\tremaining: 42.6s\n",
      "1594:\tlearn: 2.4388577\ttotal: 22.6s\tremaining: 42.6s\n",
      "1595:\tlearn: 2.4385125\ttotal: 22.6s\tremaining: 42.6s\n",
      "1596:\tlearn: 2.4378744\ttotal: 22.6s\tremaining: 42.6s\n",
      "1597:\tlearn: 2.4377264\ttotal: 22.7s\tremaining: 42.5s\n",
      "1598:\tlearn: 2.4373945\ttotal: 22.7s\tremaining: 42.5s\n",
      "1599:\tlearn: 2.4370317\ttotal: 22.7s\tremaining: 42.5s\n",
      "1600:\tlearn: 2.4367143\ttotal: 22.7s\tremaining: 42.5s\n",
      "1601:\tlearn: 2.4358632\ttotal: 22.7s\tremaining: 42.5s\n",
      "1602:\tlearn: 2.4356281\ttotal: 22.7s\tremaining: 42.5s\n",
      "1603:\tlearn: 2.4352848\ttotal: 22.7s\tremaining: 42.5s\n",
      "1604:\tlearn: 2.4344785\ttotal: 22.8s\tremaining: 42.5s\n",
      "1605:\tlearn: 2.4340720\ttotal: 22.8s\tremaining: 42.4s\n",
      "1606:\tlearn: 2.4334310\ttotal: 22.8s\tremaining: 42.4s\n",
      "1607:\tlearn: 2.4330624\ttotal: 22.8s\tremaining: 42.4s\n",
      "1608:\tlearn: 2.4326358\ttotal: 22.8s\tremaining: 42.4s\n",
      "1609:\tlearn: 2.4322608\ttotal: 22.8s\tremaining: 42.4s\n",
      "1610:\tlearn: 2.4315913\ttotal: 22.9s\tremaining: 42.4s\n",
      "1611:\tlearn: 2.4310327\ttotal: 22.9s\tremaining: 42.4s\n",
      "1612:\tlearn: 2.4302412\ttotal: 22.9s\tremaining: 42.3s\n",
      "1613:\tlearn: 2.4294206\ttotal: 22.9s\tremaining: 42.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1614:\tlearn: 2.4289474\ttotal: 22.9s\tremaining: 42.3s\n",
      "1615:\tlearn: 2.4284922\ttotal: 22.9s\tremaining: 42.3s\n",
      "1616:\tlearn: 2.4279800\ttotal: 22.9s\tremaining: 42.3s\n",
      "1617:\tlearn: 2.4272865\ttotal: 23s\tremaining: 42.3s\n",
      "1618:\tlearn: 2.4267182\ttotal: 23s\tremaining: 42.3s\n",
      "1619:\tlearn: 2.4260458\ttotal: 23s\tremaining: 42.3s\n",
      "1620:\tlearn: 2.4253881\ttotal: 23s\tremaining: 42.2s\n",
      "1621:\tlearn: 2.4251203\ttotal: 23s\tremaining: 42.2s\n",
      "1622:\tlearn: 2.4248666\ttotal: 23s\tremaining: 42.2s\n",
      "1623:\tlearn: 2.4245374\ttotal: 23s\tremaining: 42.2s\n",
      "1624:\tlearn: 2.4240128\ttotal: 23.1s\tremaining: 42.2s\n",
      "1625:\tlearn: 2.4236165\ttotal: 23.1s\tremaining: 42.2s\n",
      "1626:\tlearn: 2.4229454\ttotal: 23.1s\tremaining: 42.1s\n",
      "1627:\tlearn: 2.4226228\ttotal: 23.1s\tremaining: 42.1s\n",
      "1628:\tlearn: 2.4220782\ttotal: 23.1s\tremaining: 42.1s\n",
      "1629:\tlearn: 2.4217140\ttotal: 23.1s\tremaining: 42.1s\n",
      "1630:\tlearn: 2.4212556\ttotal: 23.1s\tremaining: 42.1s\n",
      "1631:\tlearn: 2.4206030\ttotal: 23.2s\tremaining: 42.1s\n",
      "1632:\tlearn: 2.4199799\ttotal: 23.2s\tremaining: 42.1s\n",
      "1633:\tlearn: 2.4194977\ttotal: 23.2s\tremaining: 42.1s\n",
      "1634:\tlearn: 2.4192275\ttotal: 23.2s\tremaining: 42s\n",
      "1635:\tlearn: 2.4183499\ttotal: 23.2s\tremaining: 42s\n",
      "1636:\tlearn: 2.4178121\ttotal: 23.2s\tremaining: 42s\n",
      "1637:\tlearn: 2.4176300\ttotal: 23.2s\tremaining: 42s\n",
      "1638:\tlearn: 2.4173227\ttotal: 23.3s\tremaining: 42s\n",
      "1639:\tlearn: 2.4169623\ttotal: 23.3s\tremaining: 42s\n",
      "1640:\tlearn: 2.4167422\ttotal: 23.3s\tremaining: 42s\n",
      "1641:\tlearn: 2.4157379\ttotal: 23.3s\tremaining: 41.9s\n",
      "1642:\tlearn: 2.4155873\ttotal: 23.3s\tremaining: 41.9s\n",
      "1643:\tlearn: 2.4151598\ttotal: 23.3s\tremaining: 41.9s\n",
      "1644:\tlearn: 2.4145141\ttotal: 23.3s\tremaining: 41.9s\n",
      "1645:\tlearn: 2.4140192\ttotal: 23.4s\tremaining: 41.9s\n",
      "1646:\tlearn: 2.4135998\ttotal: 23.4s\tremaining: 41.9s\n",
      "1647:\tlearn: 2.4134235\ttotal: 23.4s\tremaining: 41.8s\n",
      "1648:\tlearn: 2.4128989\ttotal: 23.4s\tremaining: 41.8s\n",
      "1649:\tlearn: 2.4126084\ttotal: 23.4s\tremaining: 41.8s\n",
      "1650:\tlearn: 2.4125661\ttotal: 23.4s\tremaining: 41.8s\n",
      "1651:\tlearn: 2.4123174\ttotal: 23.4s\tremaining: 41.8s\n",
      "1652:\tlearn: 2.4120412\ttotal: 23.4s\tremaining: 41.8s\n",
      "1653:\tlearn: 2.4117392\ttotal: 23.5s\tremaining: 41.8s\n",
      "1654:\tlearn: 2.4112855\ttotal: 23.5s\tremaining: 41.7s\n",
      "1655:\tlearn: 2.4105806\ttotal: 23.5s\tremaining: 41.7s\n",
      "1656:\tlearn: 2.4101065\ttotal: 23.5s\tremaining: 41.7s\n",
      "1657:\tlearn: 2.4099508\ttotal: 23.5s\tremaining: 41.7s\n",
      "1658:\tlearn: 2.4094694\ttotal: 23.5s\tremaining: 41.7s\n",
      "1659:\tlearn: 2.4091407\ttotal: 23.5s\tremaining: 41.7s\n",
      "1660:\tlearn: 2.4089413\ttotal: 23.6s\tremaining: 41.7s\n",
      "1661:\tlearn: 2.4085477\ttotal: 23.6s\tremaining: 41.6s\n",
      "1662:\tlearn: 2.4079958\ttotal: 23.6s\tremaining: 41.6s\n",
      "1663:\tlearn: 2.4076374\ttotal: 23.6s\tremaining: 41.6s\n",
      "1664:\tlearn: 2.4072356\ttotal: 23.6s\tremaining: 41.6s\n",
      "1665:\tlearn: 2.4069382\ttotal: 23.6s\tremaining: 41.6s\n",
      "1666:\tlearn: 2.4065479\ttotal: 23.6s\tremaining: 41.6s\n",
      "1667:\tlearn: 2.4059338\ttotal: 23.7s\tremaining: 41.6s\n",
      "1668:\tlearn: 2.4052458\ttotal: 23.7s\tremaining: 41.5s\n",
      "1669:\tlearn: 2.4047768\ttotal: 23.7s\tremaining: 41.5s\n",
      "1670:\tlearn: 2.4041860\ttotal: 23.7s\tremaining: 41.5s\n",
      "1671:\tlearn: 2.4036128\ttotal: 23.7s\tremaining: 41.5s\n",
      "1672:\tlearn: 2.4032604\ttotal: 23.7s\tremaining: 41.5s\n",
      "1673:\tlearn: 2.4026159\ttotal: 23.7s\tremaining: 41.5s\n",
      "1674:\tlearn: 2.4022222\ttotal: 23.8s\tremaining: 41.5s\n",
      "1675:\tlearn: 2.4019425\ttotal: 23.8s\tremaining: 41.4s\n",
      "1676:\tlearn: 2.4018571\ttotal: 23.8s\tremaining: 41.4s\n",
      "1677:\tlearn: 2.4015963\ttotal: 23.8s\tremaining: 41.4s\n",
      "1678:\tlearn: 2.4012782\ttotal: 23.8s\tremaining: 41.4s\n",
      "1679:\tlearn: 2.4006791\ttotal: 23.8s\tremaining: 41.4s\n",
      "1680:\tlearn: 2.3998695\ttotal: 23.8s\tremaining: 41.4s\n",
      "1681:\tlearn: 2.3994766\ttotal: 23.9s\tremaining: 41.4s\n",
      "1682:\tlearn: 2.3990506\ttotal: 23.9s\tremaining: 41.3s\n",
      "1683:\tlearn: 2.3984838\ttotal: 23.9s\tremaining: 41.3s\n",
      "1684:\tlearn: 2.3983719\ttotal: 23.9s\tremaining: 41.3s\n",
      "1685:\tlearn: 2.3978331\ttotal: 23.9s\tremaining: 41.3s\n",
      "1686:\tlearn: 2.3976862\ttotal: 23.9s\tremaining: 41.3s\n",
      "1687:\tlearn: 2.3972331\ttotal: 23.9s\tremaining: 41.3s\n",
      "1688:\tlearn: 2.3965951\ttotal: 24s\tremaining: 41.3s\n",
      "1689:\tlearn: 2.3960456\ttotal: 24s\tremaining: 41.2s\n",
      "1690:\tlearn: 2.3955581\ttotal: 24s\tremaining: 41.2s\n",
      "1691:\tlearn: 2.3952797\ttotal: 24s\tremaining: 41.2s\n",
      "1692:\tlearn: 2.3949418\ttotal: 24s\tremaining: 41.2s\n",
      "1693:\tlearn: 2.3945931\ttotal: 24s\tremaining: 41.2s\n",
      "1694:\tlearn: 2.3941700\ttotal: 24s\tremaining: 41.2s\n",
      "1695:\tlearn: 2.3937186\ttotal: 24.1s\tremaining: 41.2s\n",
      "1696:\tlearn: 2.3931035\ttotal: 24.1s\tremaining: 41.1s\n",
      "1697:\tlearn: 2.3928927\ttotal: 24.1s\tremaining: 41.1s\n",
      "1698:\tlearn: 2.3923192\ttotal: 24.1s\tremaining: 41.1s\n",
      "1699:\tlearn: 2.3914693\ttotal: 24.1s\tremaining: 41.1s\n",
      "1700:\tlearn: 2.3912443\ttotal: 24.1s\tremaining: 41.1s\n",
      "1701:\tlearn: 2.3908715\ttotal: 24.1s\tremaining: 41.1s\n",
      "1702:\tlearn: 2.3906163\ttotal: 24.1s\tremaining: 41s\n",
      "1703:\tlearn: 2.3900592\ttotal: 24.2s\tremaining: 41s\n",
      "1704:\tlearn: 2.3898217\ttotal: 24.2s\tremaining: 41s\n",
      "1705:\tlearn: 2.3895246\ttotal: 24.2s\tremaining: 41s\n",
      "1706:\tlearn: 2.3893144\ttotal: 24.2s\tremaining: 41s\n",
      "1707:\tlearn: 2.3888055\ttotal: 24.2s\tremaining: 41s\n",
      "1708:\tlearn: 2.3880534\ttotal: 24.2s\tremaining: 41s\n",
      "1709:\tlearn: 2.3875375\ttotal: 24.3s\tremaining: 41s\n",
      "1710:\tlearn: 2.3873863\ttotal: 24.3s\tremaining: 40.9s\n",
      "1711:\tlearn: 2.3867906\ttotal: 24.3s\tremaining: 40.9s\n",
      "1712:\tlearn: 2.3864214\ttotal: 24.3s\tremaining: 40.9s\n",
      "1713:\tlearn: 2.3859636\ttotal: 24.3s\tremaining: 40.9s\n",
      "1714:\tlearn: 2.3858476\ttotal: 24.3s\tremaining: 40.9s\n",
      "1715:\tlearn: 2.3855876\ttotal: 24.3s\tremaining: 40.9s\n",
      "1716:\tlearn: 2.3853423\ttotal: 24.3s\tremaining: 40.9s\n",
      "1717:\tlearn: 2.3850656\ttotal: 24.4s\tremaining: 40.8s\n",
      "1718:\tlearn: 2.3845915\ttotal: 24.4s\tremaining: 40.8s\n",
      "1719:\tlearn: 2.3841017\ttotal: 24.4s\tremaining: 40.8s\n",
      "1720:\tlearn: 2.3836382\ttotal: 24.4s\tremaining: 40.8s\n",
      "1721:\tlearn: 2.3831223\ttotal: 24.4s\tremaining: 40.8s\n",
      "1722:\tlearn: 2.3827773\ttotal: 24.4s\tremaining: 40.8s\n",
      "1723:\tlearn: 2.3822940\ttotal: 24.5s\tremaining: 40.8s\n",
      "1724:\tlearn: 2.3816964\ttotal: 24.5s\tremaining: 40.8s\n",
      "1725:\tlearn: 2.3812669\ttotal: 24.5s\tremaining: 40.7s\n",
      "1726:\tlearn: 2.3807549\ttotal: 24.5s\tremaining: 40.7s\n",
      "1727:\tlearn: 2.3799978\ttotal: 24.5s\tremaining: 40.7s\n",
      "1728:\tlearn: 2.3794307\ttotal: 24.5s\tremaining: 40.7s\n",
      "1729:\tlearn: 2.3789165\ttotal: 24.5s\tremaining: 40.7s\n",
      "1730:\tlearn: 2.3786417\ttotal: 24.6s\tremaining: 40.7s\n",
      "1731:\tlearn: 2.3784054\ttotal: 24.6s\tremaining: 40.7s\n",
      "1732:\tlearn: 2.3775446\ttotal: 24.6s\tremaining: 40.7s\n",
      "1733:\tlearn: 2.3775435\ttotal: 24.6s\tremaining: 40.6s\n",
      "1734:\tlearn: 2.3773847\ttotal: 24.6s\tremaining: 40.6s\n",
      "1735:\tlearn: 2.3768530\ttotal: 24.6s\tremaining: 40.6s\n",
      "1736:\tlearn: 2.3764598\ttotal: 24.6s\tremaining: 40.6s\n",
      "1737:\tlearn: 2.3759667\ttotal: 24.7s\tremaining: 40.6s\n",
      "1738:\tlearn: 2.3756581\ttotal: 24.7s\tremaining: 40.6s\n",
      "1739:\tlearn: 2.3750033\ttotal: 24.7s\tremaining: 40.5s\n",
      "1740:\tlearn: 2.3744610\ttotal: 24.7s\tremaining: 40.5s\n",
      "1741:\tlearn: 2.3742404\ttotal: 24.7s\tremaining: 40.5s\n",
      "1742:\tlearn: 2.3737590\ttotal: 24.7s\tremaining: 40.5s\n",
      "1743:\tlearn: 2.3734662\ttotal: 24.7s\tremaining: 40.5s\n",
      "1744:\tlearn: 2.3732414\ttotal: 24.8s\tremaining: 40.5s\n",
      "1745:\tlearn: 2.3728641\ttotal: 24.8s\tremaining: 40.5s\n",
      "1746:\tlearn: 2.3724642\ttotal: 24.8s\tremaining: 40.4s\n",
      "1747:\tlearn: 2.3719747\ttotal: 24.8s\tremaining: 40.4s\n",
      "1748:\tlearn: 2.3717242\ttotal: 24.8s\tremaining: 40.4s\n",
      "1749:\tlearn: 2.3709922\ttotal: 24.8s\tremaining: 40.4s\n",
      "1750:\tlearn: 2.3705108\ttotal: 24.8s\tremaining: 40.4s\n",
      "1751:\tlearn: 2.3696763\ttotal: 24.9s\tremaining: 40.4s\n",
      "1752:\tlearn: 2.3689575\ttotal: 24.9s\tremaining: 40.4s\n",
      "1753:\tlearn: 2.3684692\ttotal: 24.9s\tremaining: 40.3s\n",
      "1754:\tlearn: 2.3682967\ttotal: 24.9s\tremaining: 40.3s\n",
      "1755:\tlearn: 2.3677471\ttotal: 24.9s\tremaining: 40.3s\n",
      "1756:\tlearn: 2.3670952\ttotal: 24.9s\tremaining: 40.3s\n",
      "1757:\tlearn: 2.3665022\ttotal: 24.9s\tremaining: 40.3s\n",
      "1758:\tlearn: 2.3661786\ttotal: 24.9s\tremaining: 40.3s\n",
      "1759:\tlearn: 2.3655591\ttotal: 25s\tremaining: 40.3s\n",
      "1760:\tlearn: 2.3649418\ttotal: 25s\tremaining: 40.2s\n",
      "1761:\tlearn: 2.3641945\ttotal: 25s\tremaining: 40.2s\n",
      "1762:\tlearn: 2.3635402\ttotal: 25s\tremaining: 40.2s\n",
      "1763:\tlearn: 2.3629586\ttotal: 25s\tremaining: 40.2s\n",
      "1764:\tlearn: 2.3626262\ttotal: 25s\tremaining: 40.2s\n",
      "1765:\tlearn: 2.3617515\ttotal: 25.1s\tremaining: 40.2s\n",
      "1766:\tlearn: 2.3605294\ttotal: 25.1s\tremaining: 40.2s\n",
      "1767:\tlearn: 2.3601940\ttotal: 25.1s\tremaining: 40.1s\n",
      "1768:\tlearn: 2.3595834\ttotal: 25.1s\tremaining: 40.1s\n",
      "1769:\tlearn: 2.3592109\ttotal: 25.1s\tremaining: 40.1s\n",
      "1770:\tlearn: 2.3586707\ttotal: 25.1s\tremaining: 40.1s\n",
      "1771:\tlearn: 2.3583068\ttotal: 25.1s\tremaining: 40.1s\n",
      "1772:\tlearn: 2.3577153\ttotal: 25.1s\tremaining: 40.1s\n",
      "1773:\tlearn: 2.3573412\ttotal: 25.2s\tremaining: 40.1s\n",
      "1774:\tlearn: 2.3568491\ttotal: 25.2s\tremaining: 40s\n",
      "1775:\tlearn: 2.3563877\ttotal: 25.2s\tremaining: 40s\n",
      "1776:\tlearn: 2.3559199\ttotal: 25.2s\tremaining: 40s\n",
      "1777:\tlearn: 2.3556419\ttotal: 25.2s\tremaining: 40s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1778:\tlearn: 2.3549408\ttotal: 25.2s\tremaining: 40s\n",
      "1779:\tlearn: 2.3544797\ttotal: 25.3s\tremaining: 40s\n",
      "1780:\tlearn: 2.3538111\ttotal: 25.3s\tremaining: 40s\n",
      "1781:\tlearn: 2.3530707\ttotal: 25.3s\tremaining: 40s\n",
      "1782:\tlearn: 2.3526836\ttotal: 25.3s\tremaining: 39.9s\n",
      "1783:\tlearn: 2.3523588\ttotal: 25.3s\tremaining: 39.9s\n",
      "1784:\tlearn: 2.3521106\ttotal: 25.3s\tremaining: 39.9s\n",
      "1785:\tlearn: 2.3517257\ttotal: 25.3s\tremaining: 39.9s\n",
      "1786:\tlearn: 2.3511740\ttotal: 25.4s\tremaining: 39.9s\n",
      "1787:\tlearn: 2.3505934\ttotal: 25.4s\tremaining: 39.9s\n",
      "1788:\tlearn: 2.3500435\ttotal: 25.4s\tremaining: 39.9s\n",
      "1789:\tlearn: 2.3496203\ttotal: 25.4s\tremaining: 39.8s\n",
      "1790:\tlearn: 2.3488942\ttotal: 25.4s\tremaining: 39.8s\n",
      "1791:\tlearn: 2.3480959\ttotal: 25.4s\tremaining: 39.8s\n",
      "1792:\tlearn: 2.3475808\ttotal: 25.4s\tremaining: 39.8s\n",
      "1793:\tlearn: 2.3471407\ttotal: 25.5s\tremaining: 39.8s\n",
      "1794:\tlearn: 2.3466782\ttotal: 25.5s\tremaining: 39.8s\n",
      "1795:\tlearn: 2.3462415\ttotal: 25.5s\tremaining: 39.8s\n",
      "1796:\tlearn: 2.3455219\ttotal: 25.5s\tremaining: 39.8s\n",
      "1797:\tlearn: 2.3451335\ttotal: 25.5s\tremaining: 39.7s\n",
      "1798:\tlearn: 2.3445519\ttotal: 25.5s\tremaining: 39.7s\n",
      "1799:\tlearn: 2.3444050\ttotal: 25.5s\tremaining: 39.7s\n",
      "1800:\tlearn: 2.3438489\ttotal: 25.6s\tremaining: 39.7s\n",
      "1801:\tlearn: 2.3433455\ttotal: 25.6s\tremaining: 39.7s\n",
      "1802:\tlearn: 2.3428534\ttotal: 25.6s\tremaining: 39.7s\n",
      "1803:\tlearn: 2.3424290\ttotal: 25.6s\tremaining: 39.7s\n",
      "1804:\tlearn: 2.3417557\ttotal: 25.6s\tremaining: 39.6s\n",
      "1805:\tlearn: 2.3410639\ttotal: 25.6s\tremaining: 39.6s\n",
      "1806:\tlearn: 2.3405708\ttotal: 25.6s\tremaining: 39.6s\n",
      "1807:\tlearn: 2.3398902\ttotal: 25.7s\tremaining: 39.6s\n",
      "1808:\tlearn: 2.3395192\ttotal: 25.7s\tremaining: 39.6s\n",
      "1809:\tlearn: 2.3390935\ttotal: 25.7s\tremaining: 39.6s\n",
      "1810:\tlearn: 2.3387811\ttotal: 25.7s\tremaining: 39.6s\n",
      "1811:\tlearn: 2.3385709\ttotal: 25.7s\tremaining: 39.5s\n",
      "1812:\tlearn: 2.3382638\ttotal: 25.7s\tremaining: 39.5s\n",
      "1813:\tlearn: 2.3377896\ttotal: 25.8s\tremaining: 39.5s\n",
      "1814:\tlearn: 2.3375329\ttotal: 25.8s\tremaining: 39.5s\n",
      "1815:\tlearn: 2.3372787\ttotal: 25.8s\tremaining: 39.5s\n",
      "1816:\tlearn: 2.3369163\ttotal: 25.8s\tremaining: 39.5s\n",
      "1817:\tlearn: 2.3367043\ttotal: 25.8s\tremaining: 39.5s\n",
      "1818:\tlearn: 2.3362296\ttotal: 25.8s\tremaining: 39.4s\n",
      "1819:\tlearn: 2.3358806\ttotal: 25.8s\tremaining: 39.4s\n",
      "1820:\tlearn: 2.3351936\ttotal: 25.8s\tremaining: 39.4s\n",
      "1821:\tlearn: 2.3348207\ttotal: 25.9s\tremaining: 39.4s\n",
      "1822:\tlearn: 2.3344078\ttotal: 25.9s\tremaining: 39.4s\n",
      "1823:\tlearn: 2.3339483\ttotal: 25.9s\tremaining: 39.4s\n",
      "1824:\tlearn: 2.3337288\ttotal: 25.9s\tremaining: 39.4s\n",
      "1825:\tlearn: 2.3333758\ttotal: 25.9s\tremaining: 39.4s\n",
      "1826:\tlearn: 2.3325946\ttotal: 25.9s\tremaining: 39.3s\n",
      "1827:\tlearn: 2.3323151\ttotal: 25.9s\tremaining: 39.3s\n",
      "1828:\tlearn: 2.3318727\ttotal: 26s\tremaining: 39.3s\n",
      "1829:\tlearn: 2.3313553\ttotal: 26s\tremaining: 39.3s\n",
      "1830:\tlearn: 2.3308936\ttotal: 26s\tremaining: 39.3s\n",
      "1831:\tlearn: 2.3304946\ttotal: 26s\tremaining: 39.3s\n",
      "1832:\tlearn: 2.3301005\ttotal: 26s\tremaining: 39.2s\n",
      "1833:\tlearn: 2.3295549\ttotal: 26s\tremaining: 39.2s\n",
      "1834:\tlearn: 2.3293155\ttotal: 26s\tremaining: 39.2s\n",
      "1835:\tlearn: 2.3285272\ttotal: 26.1s\tremaining: 39.2s\n",
      "1836:\tlearn: 2.3282374\ttotal: 26.1s\tremaining: 39.2s\n",
      "1837:\tlearn: 2.3277402\ttotal: 26.1s\tremaining: 39.2s\n",
      "1838:\tlearn: 2.3273413\ttotal: 26.1s\tremaining: 39.2s\n",
      "1839:\tlearn: 2.3269509\ttotal: 26.1s\tremaining: 39.2s\n",
      "1840:\tlearn: 2.3264464\ttotal: 26.1s\tremaining: 39.1s\n",
      "1841:\tlearn: 2.3260083\ttotal: 26.1s\tremaining: 39.1s\n",
      "1842:\tlearn: 2.3256177\ttotal: 26.2s\tremaining: 39.1s\n",
      "1843:\tlearn: 2.3250837\ttotal: 26.2s\tremaining: 39.1s\n",
      "1844:\tlearn: 2.3246292\ttotal: 26.2s\tremaining: 39.1s\n",
      "1845:\tlearn: 2.3242184\ttotal: 26.2s\tremaining: 39.1s\n",
      "1846:\tlearn: 2.3238709\ttotal: 26.2s\tremaining: 39.1s\n",
      "1847:\tlearn: 2.3235355\ttotal: 26.2s\tremaining: 39s\n",
      "1848:\tlearn: 2.3230966\ttotal: 26.2s\tremaining: 39s\n",
      "1849:\tlearn: 2.3227998\ttotal: 26.3s\tremaining: 39s\n",
      "1850:\tlearn: 2.3223124\ttotal: 26.3s\tremaining: 39s\n",
      "1851:\tlearn: 2.3213939\ttotal: 26.3s\tremaining: 39s\n",
      "1852:\tlearn: 2.3210466\ttotal: 26.3s\tremaining: 39s\n",
      "1853:\tlearn: 2.3208099\ttotal: 26.3s\tremaining: 39s\n",
      "1854:\tlearn: 2.3203780\ttotal: 26.3s\tremaining: 38.9s\n",
      "1855:\tlearn: 2.3199313\ttotal: 26.4s\tremaining: 38.9s\n",
      "1856:\tlearn: 2.3192194\ttotal: 26.4s\tremaining: 38.9s\n",
      "1857:\tlearn: 2.3188955\ttotal: 26.4s\tremaining: 38.9s\n",
      "1858:\tlearn: 2.3186914\ttotal: 26.4s\tremaining: 38.9s\n",
      "1859:\tlearn: 2.3184454\ttotal: 26.4s\tremaining: 38.9s\n",
      "1860:\tlearn: 2.3179653\ttotal: 26.4s\tremaining: 38.9s\n",
      "1861:\tlearn: 2.3173516\ttotal: 26.4s\tremaining: 38.8s\n",
      "1862:\tlearn: 2.3171306\ttotal: 26.4s\tremaining: 38.8s\n",
      "1863:\tlearn: 2.3164554\ttotal: 26.5s\tremaining: 38.8s\n",
      "1864:\tlearn: 2.3159344\ttotal: 26.5s\tremaining: 38.8s\n",
      "1865:\tlearn: 2.3153356\ttotal: 26.5s\tremaining: 38.8s\n",
      "1866:\tlearn: 2.3148420\ttotal: 26.5s\tremaining: 38.8s\n",
      "1867:\tlearn: 2.3144170\ttotal: 26.5s\tremaining: 38.8s\n",
      "1868:\tlearn: 2.3139046\ttotal: 26.5s\tremaining: 38.7s\n",
      "1869:\tlearn: 2.3135255\ttotal: 26.6s\tremaining: 38.7s\n",
      "1870:\tlearn: 2.3133643\ttotal: 26.6s\tremaining: 38.7s\n",
      "1871:\tlearn: 2.3129221\ttotal: 26.6s\tremaining: 38.7s\n",
      "1872:\tlearn: 2.3126555\ttotal: 26.6s\tremaining: 38.7s\n",
      "1873:\tlearn: 2.3122753\ttotal: 26.6s\tremaining: 38.7s\n",
      "1874:\tlearn: 2.3117029\ttotal: 26.6s\tremaining: 38.7s\n",
      "1875:\tlearn: 2.3114320\ttotal: 26.6s\tremaining: 38.6s\n",
      "1876:\tlearn: 2.3110442\ttotal: 26.6s\tremaining: 38.6s\n",
      "1877:\tlearn: 2.3106022\ttotal: 26.7s\tremaining: 38.6s\n",
      "1878:\tlearn: 2.3099370\ttotal: 26.7s\tremaining: 38.6s\n",
      "1879:\tlearn: 2.3096646\ttotal: 26.7s\tremaining: 38.6s\n",
      "1880:\tlearn: 2.3093118\ttotal: 26.7s\tremaining: 38.6s\n",
      "1881:\tlearn: 2.3090280\ttotal: 26.7s\tremaining: 38.6s\n",
      "1882:\tlearn: 2.3082054\ttotal: 26.7s\tremaining: 38.5s\n",
      "1883:\tlearn: 2.3077318\ttotal: 26.7s\tremaining: 38.5s\n",
      "1884:\tlearn: 2.3074786\ttotal: 26.8s\tremaining: 38.5s\n",
      "1885:\tlearn: 2.3068442\ttotal: 26.8s\tremaining: 38.5s\n",
      "1886:\tlearn: 2.3065451\ttotal: 26.8s\tremaining: 38.5s\n",
      "1887:\tlearn: 2.3063671\ttotal: 26.8s\tremaining: 38.5s\n",
      "1888:\tlearn: 2.3059326\ttotal: 26.8s\tremaining: 38.5s\n",
      "1889:\tlearn: 2.3055663\ttotal: 26.8s\tremaining: 38.4s\n",
      "1890:\tlearn: 2.3050397\ttotal: 26.8s\tremaining: 38.4s\n",
      "1891:\tlearn: 2.3046071\ttotal: 26.9s\tremaining: 38.4s\n",
      "1892:\tlearn: 2.3041159\ttotal: 26.9s\tremaining: 38.4s\n",
      "1893:\tlearn: 2.3037840\ttotal: 26.9s\tremaining: 38.4s\n",
      "1894:\tlearn: 2.3032078\ttotal: 26.9s\tremaining: 38.4s\n",
      "1895:\tlearn: 2.3028493\ttotal: 26.9s\tremaining: 38.4s\n",
      "1896:\tlearn: 2.3022862\ttotal: 26.9s\tremaining: 38.4s\n",
      "1897:\tlearn: 2.3019091\ttotal: 27s\tremaining: 38.4s\n",
      "1898:\tlearn: 2.3015676\ttotal: 27s\tremaining: 38.3s\n",
      "1899:\tlearn: 2.3011092\ttotal: 27s\tremaining: 38.3s\n",
      "1900:\tlearn: 2.3007907\ttotal: 27s\tremaining: 38.3s\n",
      "1901:\tlearn: 2.3002964\ttotal: 27s\tremaining: 38.3s\n",
      "1902:\tlearn: 2.2996577\ttotal: 27s\tremaining: 38.3s\n",
      "1903:\tlearn: 2.2992991\ttotal: 27s\tremaining: 38.3s\n",
      "1904:\tlearn: 2.2983149\ttotal: 27.1s\tremaining: 38.3s\n",
      "1905:\tlearn: 2.2982041\ttotal: 27.1s\tremaining: 38.2s\n",
      "1906:\tlearn: 2.2980243\ttotal: 27.1s\tremaining: 38.2s\n",
      "1907:\tlearn: 2.2976139\ttotal: 27.1s\tremaining: 38.2s\n",
      "1908:\tlearn: 2.2975069\ttotal: 27.1s\tremaining: 38.2s\n",
      "1909:\tlearn: 2.2971765\ttotal: 27.1s\tremaining: 38.2s\n",
      "1910:\tlearn: 2.2968893\ttotal: 27.1s\tremaining: 38.2s\n",
      "1911:\tlearn: 2.2967774\ttotal: 27.2s\tremaining: 38.1s\n",
      "1912:\tlearn: 2.2963440\ttotal: 27.2s\tremaining: 38.1s\n",
      "1913:\tlearn: 2.2960057\ttotal: 27.2s\tremaining: 38.1s\n",
      "1914:\tlearn: 2.2957813\ttotal: 27.2s\tremaining: 38.1s\n",
      "1915:\tlearn: 2.2955436\ttotal: 27.2s\tremaining: 38.1s\n",
      "1916:\tlearn: 2.2951832\ttotal: 27.2s\tremaining: 38.1s\n",
      "1917:\tlearn: 2.2949078\ttotal: 27.2s\tremaining: 38.1s\n",
      "1918:\tlearn: 2.2944681\ttotal: 27.3s\tremaining: 38s\n",
      "1919:\tlearn: 2.2942075\ttotal: 27.3s\tremaining: 38s\n",
      "1920:\tlearn: 2.2940071\ttotal: 27.3s\tremaining: 38s\n",
      "1921:\tlearn: 2.2934871\ttotal: 27.3s\tremaining: 38s\n",
      "1922:\tlearn: 2.2929490\ttotal: 27.3s\tremaining: 38s\n",
      "1923:\tlearn: 2.2926745\ttotal: 27.3s\tremaining: 38s\n",
      "1924:\tlearn: 2.2921316\ttotal: 27.3s\tremaining: 38s\n",
      "1925:\tlearn: 2.2918564\ttotal: 27.4s\tremaining: 37.9s\n",
      "1926:\tlearn: 2.2914253\ttotal: 27.4s\tremaining: 37.9s\n",
      "1927:\tlearn: 2.2910130\ttotal: 27.4s\tremaining: 37.9s\n",
      "1928:\tlearn: 2.2906119\ttotal: 27.4s\tremaining: 37.9s\n",
      "1929:\tlearn: 2.2902539\ttotal: 27.4s\tremaining: 37.9s\n",
      "1930:\tlearn: 2.2899661\ttotal: 27.4s\tremaining: 37.9s\n",
      "1931:\tlearn: 2.2897117\ttotal: 27.4s\tremaining: 37.9s\n",
      "1932:\tlearn: 2.2895013\ttotal: 27.5s\tremaining: 37.9s\n",
      "1933:\tlearn: 2.2890753\ttotal: 27.5s\tremaining: 37.8s\n",
      "1934:\tlearn: 2.2886080\ttotal: 27.5s\tremaining: 37.8s\n",
      "1935:\tlearn: 2.2882642\ttotal: 27.5s\tremaining: 37.8s\n",
      "1936:\tlearn: 2.2880211\ttotal: 27.5s\tremaining: 37.8s\n",
      "1937:\tlearn: 2.2878635\ttotal: 27.5s\tremaining: 37.8s\n",
      "1938:\tlearn: 2.2874864\ttotal: 27.5s\tremaining: 37.8s\n",
      "1939:\tlearn: 2.2872411\ttotal: 27.6s\tremaining: 37.8s\n",
      "1940:\tlearn: 2.2867690\ttotal: 27.6s\tremaining: 37.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1941:\tlearn: 2.2860739\ttotal: 27.6s\tremaining: 37.7s\n",
      "1942:\tlearn: 2.2856143\ttotal: 27.6s\tremaining: 37.7s\n",
      "1943:\tlearn: 2.2854844\ttotal: 27.6s\tremaining: 37.7s\n",
      "1944:\tlearn: 2.2852289\ttotal: 27.6s\tremaining: 37.7s\n",
      "1945:\tlearn: 2.2849824\ttotal: 27.6s\tremaining: 37.7s\n",
      "1946:\tlearn: 2.2845256\ttotal: 27.7s\tremaining: 37.7s\n",
      "1947:\tlearn: 2.2842406\ttotal: 27.7s\tremaining: 37.7s\n",
      "1948:\tlearn: 2.2839577\ttotal: 27.7s\tremaining: 37.6s\n",
      "1949:\tlearn: 2.2836801\ttotal: 27.7s\tremaining: 37.6s\n",
      "1950:\tlearn: 2.2830857\ttotal: 27.7s\tremaining: 37.6s\n",
      "1951:\tlearn: 2.2827548\ttotal: 27.7s\tremaining: 37.6s\n",
      "1952:\tlearn: 2.2824152\ttotal: 27.7s\tremaining: 37.6s\n",
      "1953:\tlearn: 2.2821785\ttotal: 27.8s\tremaining: 37.6s\n",
      "1954:\tlearn: 2.2815774\ttotal: 27.8s\tremaining: 37.5s\n",
      "1955:\tlearn: 2.2811851\ttotal: 27.8s\tremaining: 37.5s\n",
      "1956:\tlearn: 2.2808751\ttotal: 27.8s\tremaining: 37.5s\n",
      "1957:\tlearn: 2.2804646\ttotal: 27.8s\tremaining: 37.5s\n",
      "1958:\tlearn: 2.2800147\ttotal: 27.8s\tremaining: 37.5s\n",
      "1959:\tlearn: 2.2795454\ttotal: 27.9s\tremaining: 37.5s\n",
      "1960:\tlearn: 2.2789329\ttotal: 27.9s\tremaining: 37.5s\n",
      "1961:\tlearn: 2.2787188\ttotal: 27.9s\tremaining: 37.5s\n",
      "1962:\tlearn: 2.2784750\ttotal: 27.9s\tremaining: 37.4s\n",
      "1963:\tlearn: 2.2780196\ttotal: 27.9s\tremaining: 37.4s\n",
      "1964:\tlearn: 2.2776686\ttotal: 27.9s\tremaining: 37.4s\n",
      "1965:\tlearn: 2.2773952\ttotal: 27.9s\tremaining: 37.4s\n",
      "1966:\tlearn: 2.2770763\ttotal: 28s\tremaining: 37.4s\n",
      "1967:\tlearn: 2.2769217\ttotal: 28s\tremaining: 37.4s\n",
      "1968:\tlearn: 2.2766327\ttotal: 28s\tremaining: 37.4s\n",
      "1969:\tlearn: 2.2763526\ttotal: 28s\tremaining: 37.3s\n",
      "1970:\tlearn: 2.2760870\ttotal: 28s\tremaining: 37.3s\n",
      "1971:\tlearn: 2.2759884\ttotal: 28s\tremaining: 37.3s\n",
      "1972:\tlearn: 2.2756647\ttotal: 28s\tremaining: 37.3s\n",
      "1973:\tlearn: 2.2753033\ttotal: 28s\tremaining: 37.3s\n",
      "1974:\tlearn: 2.2749071\ttotal: 28.1s\tremaining: 37.3s\n",
      "1975:\tlearn: 2.2745089\ttotal: 28.1s\tremaining: 37.3s\n",
      "1976:\tlearn: 2.2741189\ttotal: 28.1s\tremaining: 37.2s\n",
      "1977:\tlearn: 2.2737767\ttotal: 28.1s\tremaining: 37.2s\n",
      "1978:\tlearn: 2.2734501\ttotal: 28.1s\tremaining: 37.2s\n",
      "1979:\tlearn: 2.2731080\ttotal: 28.1s\tremaining: 37.2s\n",
      "1980:\tlearn: 2.2728599\ttotal: 28.1s\tremaining: 37.2s\n",
      "1981:\tlearn: 2.2724989\ttotal: 28.2s\tremaining: 37.2s\n",
      "1982:\tlearn: 2.2720756\ttotal: 28.2s\tremaining: 37.2s\n",
      "1983:\tlearn: 2.2717907\ttotal: 28.2s\tremaining: 37.1s\n",
      "1984:\tlearn: 2.2713698\ttotal: 28.2s\tremaining: 37.1s\n",
      "1985:\tlearn: 2.2708920\ttotal: 28.2s\tremaining: 37.1s\n",
      "1986:\tlearn: 2.2705189\ttotal: 28.2s\tremaining: 37.1s\n",
      "1987:\tlearn: 2.2701874\ttotal: 28.2s\tremaining: 37.1s\n",
      "1988:\tlearn: 2.2696943\ttotal: 28.3s\tremaining: 37.1s\n",
      "1989:\tlearn: 2.2693714\ttotal: 28.3s\tremaining: 37.1s\n",
      "1990:\tlearn: 2.2690563\ttotal: 28.3s\tremaining: 37s\n",
      "1991:\tlearn: 2.2688438\ttotal: 28.3s\tremaining: 37s\n",
      "1992:\tlearn: 2.2684467\ttotal: 28.3s\tremaining: 37s\n",
      "1993:\tlearn: 2.2680765\ttotal: 28.3s\tremaining: 37s\n",
      "1994:\tlearn: 2.2678698\ttotal: 28.3s\tremaining: 37s\n",
      "1995:\tlearn: 2.2675443\ttotal: 28.4s\tremaining: 37s\n",
      "1996:\tlearn: 2.2672982\ttotal: 28.4s\tremaining: 37s\n",
      "1997:\tlearn: 2.2668806\ttotal: 28.4s\tremaining: 36.9s\n",
      "1998:\tlearn: 2.2666611\ttotal: 28.4s\tremaining: 36.9s\n",
      "1999:\tlearn: 2.2665893\ttotal: 28.4s\tremaining: 36.9s\n",
      "2000:\tlearn: 2.2659536\ttotal: 28.4s\tremaining: 36.9s\n",
      "2001:\tlearn: 2.2657474\ttotal: 28.4s\tremaining: 36.9s\n",
      "2002:\tlearn: 2.2653562\ttotal: 28.5s\tremaining: 36.9s\n",
      "2003:\tlearn: 2.2650800\ttotal: 28.5s\tremaining: 36.9s\n",
      "2004:\tlearn: 2.2647094\ttotal: 28.5s\tremaining: 36.8s\n",
      "2005:\tlearn: 2.2644210\ttotal: 28.5s\tremaining: 36.8s\n",
      "2006:\tlearn: 2.2641276\ttotal: 28.5s\tremaining: 36.8s\n",
      "2007:\tlearn: 2.2636427\ttotal: 28.5s\tremaining: 36.8s\n",
      "2008:\tlearn: 2.2634009\ttotal: 28.5s\tremaining: 36.8s\n",
      "2009:\tlearn: 2.2630040\ttotal: 28.6s\tremaining: 36.8s\n",
      "2010:\tlearn: 2.2626336\ttotal: 28.6s\tremaining: 36.8s\n",
      "2011:\tlearn: 2.2624282\ttotal: 28.6s\tremaining: 36.7s\n",
      "2012:\tlearn: 2.2622044\ttotal: 28.6s\tremaining: 36.7s\n",
      "2013:\tlearn: 2.2619644\ttotal: 28.6s\tremaining: 36.7s\n",
      "2014:\tlearn: 2.2616526\ttotal: 28.6s\tremaining: 36.7s\n",
      "2015:\tlearn: 2.2611157\ttotal: 28.6s\tremaining: 36.7s\n",
      "2016:\tlearn: 2.2607348\ttotal: 28.7s\tremaining: 36.7s\n",
      "2017:\tlearn: 2.2603632\ttotal: 28.7s\tremaining: 36.6s\n",
      "2018:\tlearn: 2.2600802\ttotal: 28.7s\tremaining: 36.6s\n",
      "2019:\tlearn: 2.2600794\ttotal: 28.7s\tremaining: 36.6s\n",
      "2020:\tlearn: 2.2596369\ttotal: 28.7s\tremaining: 36.6s\n",
      "2021:\tlearn: 2.2590859\ttotal: 28.7s\tremaining: 36.6s\n",
      "2022:\tlearn: 2.2585321\ttotal: 28.7s\tremaining: 36.6s\n",
      "2023:\tlearn: 2.2580944\ttotal: 28.7s\tremaining: 36.6s\n",
      "2024:\tlearn: 2.2578409\ttotal: 28.8s\tremaining: 36.5s\n",
      "2025:\tlearn: 2.2576490\ttotal: 28.8s\tremaining: 36.5s\n",
      "2026:\tlearn: 2.2572113\ttotal: 28.8s\tremaining: 36.5s\n",
      "2027:\tlearn: 2.2570605\ttotal: 28.8s\tremaining: 36.5s\n",
      "2028:\tlearn: 2.2566237\ttotal: 28.8s\tremaining: 36.5s\n",
      "2029:\tlearn: 2.2563856\ttotal: 28.8s\tremaining: 36.5s\n",
      "2030:\tlearn: 2.2559839\ttotal: 28.8s\tremaining: 36.5s\n",
      "2031:\tlearn: 2.2557161\ttotal: 28.9s\tremaining: 36.4s\n",
      "2032:\tlearn: 2.2551411\ttotal: 28.9s\tremaining: 36.4s\n",
      "2033:\tlearn: 2.2548583\ttotal: 28.9s\tremaining: 36.4s\n",
      "2034:\tlearn: 2.2543607\ttotal: 28.9s\tremaining: 36.4s\n",
      "2035:\tlearn: 2.2538238\ttotal: 28.9s\tremaining: 36.4s\n",
      "2036:\tlearn: 2.2533683\ttotal: 28.9s\tremaining: 36.4s\n",
      "2037:\tlearn: 2.2530649\ttotal: 28.9s\tremaining: 36.4s\n",
      "2038:\tlearn: 2.2526365\ttotal: 29s\tremaining: 36.3s\n",
      "2039:\tlearn: 2.2525006\ttotal: 29s\tremaining: 36.3s\n",
      "2040:\tlearn: 2.2522267\ttotal: 29s\tremaining: 36.3s\n",
      "2041:\tlearn: 2.2518065\ttotal: 29s\tremaining: 36.3s\n",
      "2042:\tlearn: 2.2515380\ttotal: 29s\tremaining: 36.3s\n",
      "2043:\tlearn: 2.2510208\ttotal: 29s\tremaining: 36.3s\n",
      "2044:\tlearn: 2.2504727\ttotal: 29s\tremaining: 36.2s\n",
      "2045:\tlearn: 2.2500587\ttotal: 29.1s\tremaining: 36.2s\n",
      "2046:\tlearn: 2.2496880\ttotal: 29.1s\tremaining: 36.2s\n",
      "2047:\tlearn: 2.2492365\ttotal: 29.1s\tremaining: 36.2s\n",
      "2048:\tlearn: 2.2488905\ttotal: 29.1s\tremaining: 36.2s\n",
      "2049:\tlearn: 2.2487144\ttotal: 29.1s\tremaining: 36.2s\n",
      "2050:\tlearn: 2.2481726\ttotal: 29.1s\tremaining: 36.2s\n",
      "2051:\tlearn: 2.2480219\ttotal: 29.1s\tremaining: 36.2s\n",
      "2052:\tlearn: 2.2476637\ttotal: 29.2s\tremaining: 36.1s\n",
      "2053:\tlearn: 2.2473938\ttotal: 29.2s\tremaining: 36.1s\n",
      "2054:\tlearn: 2.2470286\ttotal: 29.2s\tremaining: 36.1s\n",
      "2055:\tlearn: 2.2465691\ttotal: 29.2s\tremaining: 36.1s\n",
      "2056:\tlearn: 2.2459839\ttotal: 29.2s\tremaining: 36.1s\n",
      "2057:\tlearn: 2.2455471\ttotal: 29.2s\tremaining: 36.1s\n",
      "2058:\tlearn: 2.2452525\ttotal: 29.2s\tremaining: 36.1s\n",
      "2059:\tlearn: 2.2450729\ttotal: 29.3s\tremaining: 36s\n",
      "2060:\tlearn: 2.2445079\ttotal: 29.3s\tremaining: 36s\n",
      "2061:\tlearn: 2.2438431\ttotal: 29.3s\tremaining: 36s\n",
      "2062:\tlearn: 2.2434923\ttotal: 29.3s\tremaining: 36s\n",
      "2063:\tlearn: 2.2432476\ttotal: 29.3s\tremaining: 36s\n",
      "2064:\tlearn: 2.2430984\ttotal: 29.3s\tremaining: 36s\n",
      "2065:\tlearn: 2.2428663\ttotal: 29.3s\tremaining: 36s\n",
      "2066:\tlearn: 2.2424752\ttotal: 29.4s\tremaining: 35.9s\n",
      "2067:\tlearn: 2.2423233\ttotal: 29.4s\tremaining: 35.9s\n",
      "2068:\tlearn: 2.2419293\ttotal: 29.4s\tremaining: 35.9s\n",
      "2069:\tlearn: 2.2413052\ttotal: 29.4s\tremaining: 35.9s\n",
      "2070:\tlearn: 2.2410903\ttotal: 29.4s\tremaining: 35.9s\n",
      "2071:\tlearn: 2.2406721\ttotal: 29.4s\tremaining: 35.9s\n",
      "2072:\tlearn: 2.2402370\ttotal: 29.4s\tremaining: 35.9s\n",
      "2073:\tlearn: 2.2396760\ttotal: 29.5s\tremaining: 35.8s\n",
      "2074:\tlearn: 2.2395800\ttotal: 29.5s\tremaining: 35.8s\n",
      "2075:\tlearn: 2.2390666\ttotal: 29.5s\tremaining: 35.8s\n",
      "2076:\tlearn: 2.2388551\ttotal: 29.5s\tremaining: 35.8s\n",
      "2077:\tlearn: 2.2386017\ttotal: 29.5s\tremaining: 35.8s\n",
      "2078:\tlearn: 2.2382960\ttotal: 29.5s\tremaining: 35.8s\n",
      "2079:\tlearn: 2.2380775\ttotal: 29.5s\tremaining: 35.8s\n",
      "2080:\tlearn: 2.2376511\ttotal: 29.5s\tremaining: 35.7s\n",
      "2081:\tlearn: 2.2373892\ttotal: 29.6s\tremaining: 35.7s\n",
      "2082:\tlearn: 2.2371799\ttotal: 29.6s\tremaining: 35.7s\n",
      "2083:\tlearn: 2.2369356\ttotal: 29.6s\tremaining: 35.7s\n",
      "2084:\tlearn: 2.2366215\ttotal: 29.6s\tremaining: 35.7s\n",
      "2085:\tlearn: 2.2363575\ttotal: 29.6s\tremaining: 35.7s\n",
      "2086:\tlearn: 2.2360059\ttotal: 29.6s\tremaining: 35.7s\n",
      "2087:\tlearn: 2.2354164\ttotal: 29.6s\tremaining: 35.6s\n",
      "2088:\tlearn: 2.2348463\ttotal: 29.7s\tremaining: 35.6s\n",
      "2089:\tlearn: 2.2341373\ttotal: 29.7s\tremaining: 35.6s\n",
      "2090:\tlearn: 2.2338221\ttotal: 29.7s\tremaining: 35.6s\n",
      "2091:\tlearn: 2.2335918\ttotal: 29.7s\tremaining: 35.6s\n",
      "2092:\tlearn: 2.2333451\ttotal: 29.7s\tremaining: 35.6s\n",
      "2093:\tlearn: 2.2327326\ttotal: 29.8s\tremaining: 35.6s\n",
      "2094:\tlearn: 2.2323828\ttotal: 29.8s\tremaining: 35.6s\n",
      "2095:\tlearn: 2.2320221\ttotal: 29.8s\tremaining: 35.6s\n",
      "2096:\tlearn: 2.2319819\ttotal: 29.8s\tremaining: 35.5s\n",
      "2097:\tlearn: 2.2316316\ttotal: 29.8s\tremaining: 35.5s\n",
      "2098:\tlearn: 2.2313807\ttotal: 29.8s\tremaining: 35.5s\n",
      "2099:\tlearn: 2.2308652\ttotal: 29.8s\tremaining: 35.5s\n",
      "2100:\tlearn: 2.2305841\ttotal: 29.9s\tremaining: 35.5s\n",
      "2101:\tlearn: 2.2303284\ttotal: 29.9s\tremaining: 35.5s\n",
      "2102:\tlearn: 2.2295966\ttotal: 29.9s\tremaining: 35.5s\n",
      "2103:\tlearn: 2.2291685\ttotal: 29.9s\tremaining: 35.4s\n",
      "2104:\tlearn: 2.2286778\ttotal: 29.9s\tremaining: 35.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2105:\tlearn: 2.2283392\ttotal: 29.9s\tremaining: 35.4s\n",
      "2106:\tlearn: 2.2280949\ttotal: 29.9s\tremaining: 35.4s\n",
      "2107:\tlearn: 2.2275320\ttotal: 30s\tremaining: 35.4s\n",
      "2108:\tlearn: 2.2271437\ttotal: 30s\tremaining: 35.4s\n",
      "2109:\tlearn: 2.2269771\ttotal: 30s\tremaining: 35.4s\n",
      "2110:\tlearn: 2.2266969\ttotal: 30s\tremaining: 35.3s\n",
      "2111:\tlearn: 2.2263341\ttotal: 30s\tremaining: 35.3s\n",
      "2112:\tlearn: 2.2259835\ttotal: 30s\tremaining: 35.3s\n",
      "2113:\tlearn: 2.2256867\ttotal: 30s\tremaining: 35.3s\n",
      "2114:\tlearn: 2.2253039\ttotal: 30.1s\tremaining: 35.3s\n",
      "2115:\tlearn: 2.2249898\ttotal: 30.1s\tremaining: 35.3s\n",
      "2116:\tlearn: 2.2245748\ttotal: 30.1s\tremaining: 35.3s\n",
      "2117:\tlearn: 2.2243979\ttotal: 30.1s\tremaining: 35.2s\n",
      "2118:\tlearn: 2.2240253\ttotal: 30.1s\tremaining: 35.2s\n",
      "2119:\tlearn: 2.2237504\ttotal: 30.1s\tremaining: 35.2s\n",
      "2120:\tlearn: 2.2234072\ttotal: 30.1s\tremaining: 35.2s\n",
      "2121:\tlearn: 2.2229533\ttotal: 30.2s\tremaining: 35.2s\n",
      "2122:\tlearn: 2.2227558\ttotal: 30.2s\tremaining: 35.2s\n",
      "2123:\tlearn: 2.2224278\ttotal: 30.2s\tremaining: 35.2s\n",
      "2124:\tlearn: 2.2217789\ttotal: 30.2s\tremaining: 35.1s\n",
      "2125:\tlearn: 2.2215377\ttotal: 30.2s\tremaining: 35.1s\n",
      "2126:\tlearn: 2.2209890\ttotal: 30.2s\tremaining: 35.1s\n",
      "2127:\tlearn: 2.2204261\ttotal: 30.2s\tremaining: 35.1s\n",
      "2128:\tlearn: 2.2199865\ttotal: 30.2s\tremaining: 35.1s\n",
      "2129:\tlearn: 2.2198433\ttotal: 30.3s\tremaining: 35.1s\n",
      "2130:\tlearn: 2.2195195\ttotal: 30.3s\tremaining: 35s\n",
      "2131:\tlearn: 2.2192848\ttotal: 30.3s\tremaining: 35s\n",
      "2132:\tlearn: 2.2187315\ttotal: 30.3s\tremaining: 35s\n",
      "2133:\tlearn: 2.2183932\ttotal: 30.3s\tremaining: 35s\n",
      "2134:\tlearn: 2.2181164\ttotal: 30.3s\tremaining: 35s\n",
      "2135:\tlearn: 2.2175312\ttotal: 30.3s\tremaining: 35s\n",
      "2136:\tlearn: 2.2173299\ttotal: 30.4s\tremaining: 35s\n",
      "2137:\tlearn: 2.2172379\ttotal: 30.4s\tremaining: 34.9s\n",
      "2138:\tlearn: 2.2168176\ttotal: 30.4s\tremaining: 34.9s\n",
      "2139:\tlearn: 2.2164324\ttotal: 30.4s\tremaining: 34.9s\n",
      "2140:\tlearn: 2.2160644\ttotal: 30.4s\tremaining: 34.9s\n",
      "2141:\tlearn: 2.2160637\ttotal: 30.4s\tremaining: 34.9s\n",
      "2142:\tlearn: 2.2154655\ttotal: 30.4s\tremaining: 34.9s\n",
      "2143:\tlearn: 2.2152816\ttotal: 30.5s\tremaining: 34.9s\n",
      "2144:\tlearn: 2.2152038\ttotal: 30.5s\tremaining: 34.8s\n",
      "2145:\tlearn: 2.2148576\ttotal: 30.5s\tremaining: 34.8s\n",
      "2146:\tlearn: 2.2144265\ttotal: 30.5s\tremaining: 34.8s\n",
      "2147:\tlearn: 2.2138309\ttotal: 30.5s\tremaining: 34.8s\n",
      "2148:\tlearn: 2.2132594\ttotal: 30.5s\tremaining: 34.8s\n",
      "2149:\tlearn: 2.2129758\ttotal: 30.5s\tremaining: 34.8s\n",
      "2150:\tlearn: 2.2126110\ttotal: 30.6s\tremaining: 34.8s\n",
      "2151:\tlearn: 2.2121991\ttotal: 30.6s\tremaining: 34.8s\n",
      "2152:\tlearn: 2.2118173\ttotal: 30.6s\tremaining: 34.8s\n",
      "2153:\tlearn: 2.2116379\ttotal: 30.6s\tremaining: 34.7s\n",
      "2154:\tlearn: 2.2112984\ttotal: 30.6s\tremaining: 34.7s\n",
      "2155:\tlearn: 2.2107625\ttotal: 30.6s\tremaining: 34.7s\n",
      "2156:\tlearn: 2.2105283\ttotal: 30.7s\tremaining: 34.7s\n",
      "2157:\tlearn: 2.2103661\ttotal: 30.7s\tremaining: 34.7s\n",
      "2158:\tlearn: 2.2098370\ttotal: 30.7s\tremaining: 34.7s\n",
      "2159:\tlearn: 2.2095627\ttotal: 30.7s\tremaining: 34.7s\n",
      "2160:\tlearn: 2.2092331\ttotal: 30.7s\tremaining: 34.6s\n",
      "2161:\tlearn: 2.2089900\ttotal: 30.7s\tremaining: 34.6s\n",
      "2162:\tlearn: 2.2087899\ttotal: 30.7s\tremaining: 34.6s\n",
      "2163:\tlearn: 2.2080560\ttotal: 30.8s\tremaining: 34.6s\n",
      "2164:\tlearn: 2.2077749\ttotal: 30.8s\tremaining: 34.6s\n",
      "2165:\tlearn: 2.2072467\ttotal: 30.8s\tremaining: 34.6s\n",
      "2166:\tlearn: 2.2069349\ttotal: 30.8s\tremaining: 34.5s\n",
      "2167:\tlearn: 2.2066558\ttotal: 30.8s\tremaining: 34.5s\n",
      "2168:\tlearn: 2.2062783\ttotal: 30.8s\tremaining: 34.5s\n",
      "2169:\tlearn: 2.2058976\ttotal: 30.8s\tremaining: 34.5s\n",
      "2170:\tlearn: 2.2054370\ttotal: 30.9s\tremaining: 34.5s\n",
      "2171:\tlearn: 2.2049511\ttotal: 30.9s\tremaining: 34.5s\n",
      "2172:\tlearn: 2.2045569\ttotal: 30.9s\tremaining: 34.5s\n",
      "2173:\tlearn: 2.2041823\ttotal: 30.9s\tremaining: 34.5s\n",
      "2174:\tlearn: 2.2040016\ttotal: 30.9s\tremaining: 34.4s\n",
      "2175:\tlearn: 2.2037203\ttotal: 30.9s\tremaining: 34.4s\n",
      "2176:\tlearn: 2.2033457\ttotal: 30.9s\tremaining: 34.4s\n",
      "2177:\tlearn: 2.2027598\ttotal: 31s\tremaining: 34.4s\n",
      "2178:\tlearn: 2.2024147\ttotal: 31s\tremaining: 34.4s\n",
      "2179:\tlearn: 2.2019845\ttotal: 31s\tremaining: 34.4s\n",
      "2180:\tlearn: 2.2014762\ttotal: 31s\tremaining: 34.4s\n",
      "2181:\tlearn: 2.2010679\ttotal: 31s\tremaining: 34.3s\n",
      "2182:\tlearn: 2.2006952\ttotal: 31s\tremaining: 34.3s\n",
      "2183:\tlearn: 2.2003229\ttotal: 31s\tremaining: 34.3s\n",
      "2184:\tlearn: 2.1997951\ttotal: 31.1s\tremaining: 34.3s\n",
      "2185:\tlearn: 2.1995177\ttotal: 31.1s\tremaining: 34.3s\n",
      "2186:\tlearn: 2.1988778\ttotal: 31.1s\tremaining: 34.3s\n",
      "2187:\tlearn: 2.1984509\ttotal: 31.1s\tremaining: 34.3s\n",
      "2188:\tlearn: 2.1980346\ttotal: 31.1s\tremaining: 34.2s\n",
      "2189:\tlearn: 2.1978723\ttotal: 31.1s\tremaining: 34.2s\n",
      "2190:\tlearn: 2.1976997\ttotal: 31.1s\tremaining: 34.2s\n",
      "2191:\tlearn: 2.1974345\ttotal: 31.2s\tremaining: 34.2s\n",
      "2192:\tlearn: 2.1972253\ttotal: 31.2s\tremaining: 34.2s\n",
      "2193:\tlearn: 2.1967707\ttotal: 31.2s\tremaining: 34.2s\n",
      "2194:\tlearn: 2.1966569\ttotal: 31.2s\tremaining: 34.2s\n",
      "2195:\tlearn: 2.1961358\ttotal: 31.2s\tremaining: 34.1s\n",
      "2196:\tlearn: 2.1958512\ttotal: 31.2s\tremaining: 34.1s\n",
      "2197:\tlearn: 2.1954739\ttotal: 31.2s\tremaining: 34.1s\n",
      "2198:\tlearn: 2.1950564\ttotal: 31.3s\tremaining: 34.1s\n",
      "2199:\tlearn: 2.1946315\ttotal: 31.3s\tremaining: 34.1s\n",
      "2200:\tlearn: 2.1943251\ttotal: 31.3s\tremaining: 34.1s\n",
      "2201:\tlearn: 2.1938571\ttotal: 31.3s\tremaining: 34.1s\n",
      "2202:\tlearn: 2.1934064\ttotal: 31.3s\tremaining: 34s\n",
      "2203:\tlearn: 2.1931825\ttotal: 31.3s\tremaining: 34s\n",
      "2204:\tlearn: 2.1927892\ttotal: 31.3s\tremaining: 34s\n",
      "2205:\tlearn: 2.1925243\ttotal: 31.4s\tremaining: 34s\n",
      "2206:\tlearn: 2.1921500\ttotal: 31.4s\tremaining: 34s\n",
      "2207:\tlearn: 2.1920781\ttotal: 31.4s\tremaining: 34s\n",
      "2208:\tlearn: 2.1914130\ttotal: 31.4s\tremaining: 34s\n",
      "2209:\tlearn: 2.1911613\ttotal: 31.4s\tremaining: 33.9s\n",
      "2210:\tlearn: 2.1908603\ttotal: 31.4s\tremaining: 33.9s\n",
      "2211:\tlearn: 2.1905082\ttotal: 31.4s\tremaining: 33.9s\n",
      "2212:\tlearn: 2.1901687\ttotal: 31.5s\tremaining: 33.9s\n",
      "2213:\tlearn: 2.1898646\ttotal: 31.5s\tremaining: 33.9s\n",
      "2214:\tlearn: 2.1894234\ttotal: 31.5s\tremaining: 33.9s\n",
      "2215:\tlearn: 2.1890576\ttotal: 31.5s\tremaining: 33.9s\n",
      "2216:\tlearn: 2.1887023\ttotal: 31.5s\tremaining: 33.8s\n",
      "2217:\tlearn: 2.1882040\ttotal: 31.5s\tremaining: 33.8s\n",
      "2218:\tlearn: 2.1876178\ttotal: 31.5s\tremaining: 33.8s\n",
      "2219:\tlearn: 2.1869815\ttotal: 31.6s\tremaining: 33.8s\n",
      "2220:\tlearn: 2.1866978\ttotal: 31.6s\tremaining: 33.8s\n",
      "2221:\tlearn: 2.1861693\ttotal: 31.6s\tremaining: 33.8s\n",
      "2222:\tlearn: 2.1858530\ttotal: 31.6s\tremaining: 33.8s\n",
      "2223:\tlearn: 2.1853703\ttotal: 31.6s\tremaining: 33.7s\n",
      "2224:\tlearn: 2.1851034\ttotal: 31.6s\tremaining: 33.7s\n",
      "2225:\tlearn: 2.1842696\ttotal: 31.6s\tremaining: 33.7s\n",
      "2226:\tlearn: 2.1840460\ttotal: 31.7s\tremaining: 33.7s\n",
      "2227:\tlearn: 2.1838192\ttotal: 31.7s\tremaining: 33.7s\n",
      "2228:\tlearn: 2.1832681\ttotal: 31.7s\tremaining: 33.7s\n",
      "2229:\tlearn: 2.1829809\ttotal: 31.7s\tremaining: 33.7s\n",
      "2230:\tlearn: 2.1826943\ttotal: 31.7s\tremaining: 33.6s\n",
      "2231:\tlearn: 2.1824072\ttotal: 31.7s\tremaining: 33.6s\n",
      "2232:\tlearn: 2.1820841\ttotal: 31.7s\tremaining: 33.6s\n",
      "2233:\tlearn: 2.1818563\ttotal: 31.8s\tremaining: 33.6s\n",
      "2234:\tlearn: 2.1814750\ttotal: 31.8s\tremaining: 33.6s\n",
      "2235:\tlearn: 2.1811323\ttotal: 31.8s\tremaining: 33.6s\n",
      "2236:\tlearn: 2.1808956\ttotal: 31.8s\tremaining: 33.6s\n",
      "2237:\tlearn: 2.1805234\ttotal: 31.8s\tremaining: 33.5s\n",
      "2238:\tlearn: 2.1801873\ttotal: 31.8s\tremaining: 33.5s\n",
      "2239:\tlearn: 2.1798776\ttotal: 31.8s\tremaining: 33.5s\n",
      "2240:\tlearn: 2.1794640\ttotal: 31.9s\tremaining: 33.5s\n",
      "2241:\tlearn: 2.1792237\ttotal: 31.9s\tremaining: 33.5s\n",
      "2242:\tlearn: 2.1787452\ttotal: 31.9s\tremaining: 33.5s\n",
      "2243:\tlearn: 2.1784540\ttotal: 31.9s\tremaining: 33.5s\n",
      "2244:\tlearn: 2.1781543\ttotal: 31.9s\tremaining: 33.4s\n",
      "2245:\tlearn: 2.1779184\ttotal: 31.9s\tremaining: 33.4s\n",
      "2246:\tlearn: 2.1775132\ttotal: 31.9s\tremaining: 33.4s\n",
      "2247:\tlearn: 2.1773159\ttotal: 32s\tremaining: 33.4s\n",
      "2248:\tlearn: 2.1769495\ttotal: 32s\tremaining: 33.4s\n",
      "2249:\tlearn: 2.1768078\ttotal: 32s\tremaining: 33.4s\n",
      "2250:\tlearn: 2.1761960\ttotal: 32s\tremaining: 33.4s\n",
      "2251:\tlearn: 2.1759170\ttotal: 32s\tremaining: 33.3s\n",
      "2252:\tlearn: 2.1754334\ttotal: 32s\tremaining: 33.3s\n",
      "2253:\tlearn: 2.1749350\ttotal: 32s\tremaining: 33.3s\n",
      "2254:\tlearn: 2.1747008\ttotal: 32.1s\tremaining: 33.3s\n",
      "2255:\tlearn: 2.1742621\ttotal: 32.1s\tremaining: 33.3s\n",
      "2256:\tlearn: 2.1738017\ttotal: 32.1s\tremaining: 33.3s\n",
      "2257:\tlearn: 2.1735555\ttotal: 32.1s\tremaining: 33.3s\n",
      "2258:\tlearn: 2.1732498\ttotal: 32.1s\tremaining: 33.2s\n",
      "2259:\tlearn: 2.1730016\ttotal: 32.1s\tremaining: 33.2s\n",
      "2260:\tlearn: 2.1726005\ttotal: 32.1s\tremaining: 33.2s\n",
      "2261:\tlearn: 2.1720611\ttotal: 32.2s\tremaining: 33.2s\n",
      "2262:\tlearn: 2.1714995\ttotal: 32.2s\tremaining: 33.2s\n",
      "2263:\tlearn: 2.1712509\ttotal: 32.2s\tremaining: 33.2s\n",
      "2264:\tlearn: 2.1711234\ttotal: 32.2s\tremaining: 33.2s\n",
      "2265:\tlearn: 2.1709424\ttotal: 32.2s\tremaining: 33.1s\n",
      "2266:\tlearn: 2.1706655\ttotal: 32.2s\tremaining: 33.1s\n",
      "2267:\tlearn: 2.1703908\ttotal: 32.2s\tremaining: 33.1s\n",
      "2268:\tlearn: 2.1699466\ttotal: 32.2s\tremaining: 33.1s\n",
      "2269:\tlearn: 2.1694363\ttotal: 32.3s\tremaining: 33.1s\n",
      "2270:\tlearn: 2.1690885\ttotal: 32.3s\tremaining: 33.1s\n",
      "2271:\tlearn: 2.1688699\ttotal: 32.3s\tremaining: 33.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2272:\tlearn: 2.1684279\ttotal: 32.3s\tremaining: 33s\n",
      "2273:\tlearn: 2.1682008\ttotal: 32.3s\tremaining: 33s\n",
      "2274:\tlearn: 2.1678512\ttotal: 32.3s\tremaining: 33s\n",
      "2275:\tlearn: 2.1676215\ttotal: 32.3s\tremaining: 33s\n",
      "2276:\tlearn: 2.1672252\ttotal: 32.4s\tremaining: 33s\n",
      "2277:\tlearn: 2.1667565\ttotal: 32.4s\tremaining: 33s\n",
      "2278:\tlearn: 2.1663651\ttotal: 32.4s\tremaining: 33s\n",
      "2279:\tlearn: 2.1659322\ttotal: 32.4s\tremaining: 32.9s\n",
      "2280:\tlearn: 2.1655166\ttotal: 32.4s\tremaining: 32.9s\n",
      "2281:\tlearn: 2.1647268\ttotal: 32.4s\tremaining: 32.9s\n",
      "2282:\tlearn: 2.1643237\ttotal: 32.4s\tremaining: 32.9s\n",
      "2283:\tlearn: 2.1639442\ttotal: 32.5s\tremaining: 32.9s\n",
      "2284:\tlearn: 2.1635641\ttotal: 32.5s\tremaining: 32.9s\n",
      "2285:\tlearn: 2.1633478\ttotal: 32.5s\tremaining: 32.9s\n",
      "2286:\tlearn: 2.1628765\ttotal: 32.5s\tremaining: 32.8s\n",
      "2287:\tlearn: 2.1623708\ttotal: 32.5s\tremaining: 32.8s\n",
      "2288:\tlearn: 2.1615054\ttotal: 32.5s\tremaining: 32.8s\n",
      "2289:\tlearn: 2.1610810\ttotal: 32.5s\tremaining: 32.8s\n",
      "2290:\tlearn: 2.1609058\ttotal: 32.6s\tremaining: 32.8s\n",
      "2291:\tlearn: 2.1606888\ttotal: 32.6s\tremaining: 32.8s\n",
      "2292:\tlearn: 2.1604486\ttotal: 32.6s\tremaining: 32.8s\n",
      "2293:\tlearn: 2.1601985\ttotal: 32.6s\tremaining: 32.7s\n",
      "2294:\tlearn: 2.1600761\ttotal: 32.6s\tremaining: 32.7s\n",
      "2295:\tlearn: 2.1597224\ttotal: 32.6s\tremaining: 32.7s\n",
      "2296:\tlearn: 2.1591697\ttotal: 32.6s\tremaining: 32.7s\n",
      "2297:\tlearn: 2.1589101\ttotal: 32.7s\tremaining: 32.7s\n",
      "2298:\tlearn: 2.1585314\ttotal: 32.7s\tremaining: 32.7s\n",
      "2299:\tlearn: 2.1582716\ttotal: 32.7s\tremaining: 32.7s\n",
      "2300:\tlearn: 2.1580514\ttotal: 32.7s\tremaining: 32.6s\n",
      "2301:\tlearn: 2.1579371\ttotal: 32.7s\tremaining: 32.6s\n",
      "2302:\tlearn: 2.1575560\ttotal: 32.7s\tremaining: 32.6s\n",
      "2303:\tlearn: 2.1573635\ttotal: 32.7s\tremaining: 32.6s\n",
      "2304:\tlearn: 2.1567486\ttotal: 32.8s\tremaining: 32.6s\n",
      "2305:\tlearn: 2.1561754\ttotal: 32.8s\tremaining: 32.6s\n",
      "2306:\tlearn: 2.1558738\ttotal: 32.8s\tremaining: 32.6s\n",
      "2307:\tlearn: 2.1553998\ttotal: 32.8s\tremaining: 32.5s\n",
      "2308:\tlearn: 2.1549448\ttotal: 32.8s\tremaining: 32.5s\n",
      "2309:\tlearn: 2.1545935\ttotal: 32.8s\tremaining: 32.5s\n",
      "2310:\tlearn: 2.1544305\ttotal: 32.8s\tremaining: 32.5s\n",
      "2311:\tlearn: 2.1542158\ttotal: 32.9s\tremaining: 32.5s\n",
      "2312:\tlearn: 2.1534700\ttotal: 32.9s\tremaining: 32.5s\n",
      "2313:\tlearn: 2.1532378\ttotal: 32.9s\tremaining: 32.5s\n",
      "2314:\tlearn: 2.1528295\ttotal: 32.9s\tremaining: 32.4s\n",
      "2315:\tlearn: 2.1525105\ttotal: 32.9s\tremaining: 32.4s\n",
      "2316:\tlearn: 2.1517345\ttotal: 32.9s\tremaining: 32.4s\n",
      "2317:\tlearn: 2.1512087\ttotal: 32.9s\tremaining: 32.4s\n",
      "2318:\tlearn: 2.1508950\ttotal: 33s\tremaining: 32.4s\n",
      "2319:\tlearn: 2.1503794\ttotal: 33s\tremaining: 32.4s\n",
      "2320:\tlearn: 2.1500248\ttotal: 33s\tremaining: 32.4s\n",
      "2321:\tlearn: 2.1496712\ttotal: 33s\tremaining: 32.4s\n",
      "2322:\tlearn: 2.1494464\ttotal: 33s\tremaining: 32.3s\n",
      "2323:\tlearn: 2.1490139\ttotal: 33s\tremaining: 32.3s\n",
      "2324:\tlearn: 2.1485549\ttotal: 33s\tremaining: 32.3s\n",
      "2325:\tlearn: 2.1481361\ttotal: 33.1s\tremaining: 32.3s\n",
      "2326:\tlearn: 2.1476825\ttotal: 33.1s\tremaining: 32.3s\n",
      "2327:\tlearn: 2.1472744\ttotal: 33.1s\tremaining: 32.3s\n",
      "2328:\tlearn: 2.1468147\ttotal: 33.1s\tremaining: 32.3s\n",
      "2329:\tlearn: 2.1463121\ttotal: 33.1s\tremaining: 32.2s\n",
      "2330:\tlearn: 2.1458797\ttotal: 33.1s\tremaining: 32.2s\n",
      "2331:\tlearn: 2.1455029\ttotal: 33.2s\tremaining: 32.2s\n",
      "2332:\tlearn: 2.1449876\ttotal: 33.2s\tremaining: 32.2s\n",
      "2333:\tlearn: 2.1446441\ttotal: 33.2s\tremaining: 32.2s\n",
      "2334:\tlearn: 2.1443872\ttotal: 33.2s\tremaining: 32.2s\n",
      "2335:\tlearn: 2.1440741\ttotal: 33.2s\tremaining: 32.2s\n",
      "2336:\tlearn: 2.1437954\ttotal: 33.2s\tremaining: 32.1s\n",
      "2337:\tlearn: 2.1434189\ttotal: 33.2s\tremaining: 32.1s\n",
      "2338:\tlearn: 2.1429437\ttotal: 33.3s\tremaining: 32.1s\n",
      "2339:\tlearn: 2.1425648\ttotal: 33.3s\tremaining: 32.1s\n",
      "2340:\tlearn: 2.1420817\ttotal: 33.3s\tremaining: 32.1s\n",
      "2341:\tlearn: 2.1419192\ttotal: 33.3s\tremaining: 32.1s\n",
      "2342:\tlearn: 2.1414450\ttotal: 33.3s\tremaining: 32.1s\n",
      "2343:\tlearn: 2.1411159\ttotal: 33.3s\tremaining: 32s\n",
      "2344:\tlearn: 2.1408822\ttotal: 33.3s\tremaining: 32s\n",
      "2345:\tlearn: 2.1403997\ttotal: 33.4s\tremaining: 32s\n",
      "2346:\tlearn: 2.1403285\ttotal: 33.4s\tremaining: 32s\n",
      "2347:\tlearn: 2.1394567\ttotal: 33.4s\tremaining: 32s\n",
      "2348:\tlearn: 2.1392844\ttotal: 33.4s\tremaining: 32s\n",
      "2349:\tlearn: 2.1390507\ttotal: 33.4s\tremaining: 32s\n",
      "2350:\tlearn: 2.1386900\ttotal: 33.4s\tremaining: 31.9s\n",
      "2351:\tlearn: 2.1384043\ttotal: 33.4s\tremaining: 31.9s\n",
      "2352:\tlearn: 2.1378412\ttotal: 33.5s\tremaining: 31.9s\n",
      "2353:\tlearn: 2.1375885\ttotal: 33.5s\tremaining: 31.9s\n",
      "2354:\tlearn: 2.1371549\ttotal: 33.5s\tremaining: 31.9s\n",
      "2355:\tlearn: 2.1368880\ttotal: 33.5s\tremaining: 31.9s\n",
      "2356:\tlearn: 2.1366679\ttotal: 33.5s\tremaining: 31.9s\n",
      "2357:\tlearn: 2.1364282\ttotal: 33.5s\tremaining: 31.8s\n",
      "2358:\tlearn: 2.1360186\ttotal: 33.5s\tremaining: 31.8s\n",
      "2359:\tlearn: 2.1356779\ttotal: 33.6s\tremaining: 31.8s\n",
      "2360:\tlearn: 2.1355401\ttotal: 33.6s\tremaining: 31.8s\n",
      "2361:\tlearn: 2.1352410\ttotal: 33.6s\tremaining: 31.8s\n",
      "2362:\tlearn: 2.1349760\ttotal: 33.6s\tremaining: 31.8s\n",
      "2363:\tlearn: 2.1345125\ttotal: 33.6s\tremaining: 31.8s\n",
      "2364:\tlearn: 2.1341042\ttotal: 33.6s\tremaining: 31.7s\n",
      "2365:\tlearn: 2.1339197\ttotal: 33.6s\tremaining: 31.7s\n",
      "2366:\tlearn: 2.1335564\ttotal: 33.6s\tremaining: 31.7s\n",
      "2367:\tlearn: 2.1331550\ttotal: 33.7s\tremaining: 31.7s\n",
      "2368:\tlearn: 2.1321602\ttotal: 33.7s\tremaining: 31.7s\n",
      "2369:\tlearn: 2.1319634\ttotal: 33.7s\tremaining: 31.7s\n",
      "2370:\tlearn: 2.1314832\ttotal: 33.7s\tremaining: 31.7s\n",
      "2371:\tlearn: 2.1310771\ttotal: 33.7s\tremaining: 31.6s\n",
      "2372:\tlearn: 2.1306730\ttotal: 33.7s\tremaining: 31.6s\n",
      "2373:\tlearn: 2.1302590\ttotal: 33.7s\tremaining: 31.6s\n",
      "2374:\tlearn: 2.1295273\ttotal: 33.8s\tremaining: 31.6s\n",
      "2375:\tlearn: 2.1290604\ttotal: 33.8s\tremaining: 31.6s\n",
      "2376:\tlearn: 2.1289268\ttotal: 33.8s\tremaining: 31.6s\n",
      "2377:\tlearn: 2.1284763\ttotal: 33.8s\tremaining: 31.6s\n",
      "2378:\tlearn: 2.1280486\ttotal: 33.8s\tremaining: 31.5s\n",
      "2379:\tlearn: 2.1278858\ttotal: 33.8s\tremaining: 31.5s\n",
      "2380:\tlearn: 2.1274180\ttotal: 33.8s\tremaining: 31.5s\n",
      "2381:\tlearn: 2.1269753\ttotal: 33.9s\tremaining: 31.5s\n",
      "2382:\tlearn: 2.1264085\ttotal: 33.9s\tremaining: 31.5s\n",
      "2383:\tlearn: 2.1261664\ttotal: 33.9s\tremaining: 31.5s\n",
      "2384:\tlearn: 2.1256718\ttotal: 33.9s\tremaining: 31.5s\n",
      "2385:\tlearn: 2.1251701\ttotal: 33.9s\tremaining: 31.4s\n",
      "2386:\tlearn: 2.1248528\ttotal: 33.9s\tremaining: 31.4s\n",
      "2387:\tlearn: 2.1248498\ttotal: 33.9s\tremaining: 31.4s\n",
      "2388:\tlearn: 2.1244452\ttotal: 34s\tremaining: 31.4s\n",
      "2389:\tlearn: 2.1240909\ttotal: 34s\tremaining: 31.4s\n",
      "2390:\tlearn: 2.1235246\ttotal: 34s\tremaining: 31.4s\n",
      "2391:\tlearn: 2.1231338\ttotal: 34s\tremaining: 31.4s\n",
      "2392:\tlearn: 2.1229041\ttotal: 34s\tremaining: 31.3s\n",
      "2393:\tlearn: 2.1224674\ttotal: 34s\tremaining: 31.3s\n",
      "2394:\tlearn: 2.1222142\ttotal: 34s\tremaining: 31.3s\n",
      "2395:\tlearn: 2.1219908\ttotal: 34.1s\tremaining: 31.3s\n",
      "2396:\tlearn: 2.1214606\ttotal: 34.1s\tremaining: 31.3s\n",
      "2397:\tlearn: 2.1209617\ttotal: 34.1s\tremaining: 31.3s\n",
      "2398:\tlearn: 2.1205230\ttotal: 34.1s\tremaining: 31.3s\n",
      "2399:\tlearn: 2.1201376\ttotal: 34.1s\tremaining: 31.2s\n",
      "2400:\tlearn: 2.1199230\ttotal: 34.1s\tremaining: 31.2s\n",
      "2401:\tlearn: 2.1197381\ttotal: 34.1s\tremaining: 31.2s\n",
      "2402:\tlearn: 2.1191575\ttotal: 34.2s\tremaining: 31.2s\n",
      "2403:\tlearn: 2.1189933\ttotal: 34.2s\tremaining: 31.2s\n",
      "2404:\tlearn: 2.1184857\ttotal: 34.2s\tremaining: 31.2s\n",
      "2405:\tlearn: 2.1181770\ttotal: 34.2s\tremaining: 31.2s\n",
      "2406:\tlearn: 2.1178890\ttotal: 34.2s\tremaining: 31.1s\n",
      "2407:\tlearn: 2.1173332\ttotal: 34.2s\tremaining: 31.1s\n",
      "2408:\tlearn: 2.1167597\ttotal: 34.2s\tremaining: 31.1s\n",
      "2409:\tlearn: 2.1164415\ttotal: 34.3s\tremaining: 31.1s\n",
      "2410:\tlearn: 2.1163762\ttotal: 34.3s\tremaining: 31.1s\n",
      "2411:\tlearn: 2.1160442\ttotal: 34.3s\tremaining: 31.1s\n",
      "2412:\tlearn: 2.1156347\ttotal: 34.3s\tremaining: 31.1s\n",
      "2413:\tlearn: 2.1152052\ttotal: 34.3s\tremaining: 31s\n",
      "2414:\tlearn: 2.1148461\ttotal: 34.3s\tremaining: 31s\n",
      "2415:\tlearn: 2.1142312\ttotal: 34.3s\tremaining: 31s\n",
      "2416:\tlearn: 2.1140499\ttotal: 34.4s\tremaining: 31s\n",
      "2417:\tlearn: 2.1139101\ttotal: 34.4s\tremaining: 31s\n",
      "2418:\tlearn: 2.1139075\ttotal: 34.4s\tremaining: 31s\n",
      "2419:\tlearn: 2.1138433\ttotal: 34.4s\tremaining: 31s\n",
      "2420:\tlearn: 2.1135798\ttotal: 34.4s\tremaining: 30.9s\n",
      "2421:\tlearn: 2.1133105\ttotal: 34.4s\tremaining: 30.9s\n",
      "2422:\tlearn: 2.1129983\ttotal: 34.4s\tremaining: 30.9s\n",
      "2423:\tlearn: 2.1126713\ttotal: 34.4s\tremaining: 30.9s\n",
      "2424:\tlearn: 2.1121800\ttotal: 34.5s\tremaining: 30.9s\n",
      "2425:\tlearn: 2.1118957\ttotal: 34.5s\tremaining: 30.9s\n",
      "2426:\tlearn: 2.1118439\ttotal: 34.5s\tremaining: 30.9s\n",
      "2427:\tlearn: 2.1116117\ttotal: 34.5s\tremaining: 30.8s\n",
      "2428:\tlearn: 2.1112354\ttotal: 34.5s\tremaining: 30.8s\n",
      "2429:\tlearn: 2.1109689\ttotal: 34.5s\tremaining: 30.8s\n",
      "2430:\tlearn: 2.1106391\ttotal: 34.5s\tremaining: 30.8s\n",
      "2431:\tlearn: 2.1103925\ttotal: 34.6s\tremaining: 30.8s\n",
      "2432:\tlearn: 2.1101559\ttotal: 34.6s\tremaining: 30.8s\n",
      "2433:\tlearn: 2.1099563\ttotal: 34.6s\tremaining: 30.7s\n",
      "2434:\tlearn: 2.1096286\ttotal: 34.6s\tremaining: 30.7s\n",
      "2435:\tlearn: 2.1092431\ttotal: 34.6s\tremaining: 30.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2436:\tlearn: 2.1088737\ttotal: 34.6s\tremaining: 30.7s\n",
      "2437:\tlearn: 2.1086741\ttotal: 34.6s\tremaining: 30.7s\n",
      "2438:\tlearn: 2.1084560\ttotal: 34.7s\tremaining: 30.7s\n",
      "2439:\tlearn: 2.1082073\ttotal: 34.7s\tremaining: 30.7s\n",
      "2440:\tlearn: 2.1077226\ttotal: 34.7s\tremaining: 30.7s\n",
      "2441:\tlearn: 2.1075843\ttotal: 34.7s\tremaining: 30.6s\n",
      "2442:\tlearn: 2.1070549\ttotal: 34.7s\tremaining: 30.6s\n",
      "2443:\tlearn: 2.1068867\ttotal: 34.7s\tremaining: 30.6s\n",
      "2444:\tlearn: 2.1062463\ttotal: 34.7s\tremaining: 30.6s\n",
      "2445:\tlearn: 2.1061219\ttotal: 34.8s\tremaining: 30.6s\n",
      "2446:\tlearn: 2.1055990\ttotal: 34.8s\tremaining: 30.6s\n",
      "2447:\tlearn: 2.1053033\ttotal: 34.8s\tremaining: 30.5s\n",
      "2448:\tlearn: 2.1048995\ttotal: 34.8s\tremaining: 30.5s\n",
      "2449:\tlearn: 2.1045593\ttotal: 34.8s\tremaining: 30.5s\n",
      "2450:\tlearn: 2.1042039\ttotal: 34.8s\tremaining: 30.5s\n",
      "2451:\tlearn: 2.1038185\ttotal: 34.8s\tremaining: 30.5s\n",
      "2452:\tlearn: 2.1032929\ttotal: 34.9s\tremaining: 30.5s\n",
      "2453:\tlearn: 2.1031014\ttotal: 34.9s\tremaining: 30.5s\n",
      "2454:\tlearn: 2.1030328\ttotal: 34.9s\tremaining: 30.4s\n",
      "2455:\tlearn: 2.1024651\ttotal: 34.9s\tremaining: 30.4s\n",
      "2456:\tlearn: 2.1022470\ttotal: 34.9s\tremaining: 30.4s\n",
      "2457:\tlearn: 2.1018485\ttotal: 34.9s\tremaining: 30.4s\n",
      "2458:\tlearn: 2.1016042\ttotal: 34.9s\tremaining: 30.4s\n",
      "2459:\tlearn: 2.1011417\ttotal: 35s\tremaining: 30.4s\n",
      "2460:\tlearn: 2.1007564\ttotal: 35s\tremaining: 30.4s\n",
      "2461:\tlearn: 2.1005037\ttotal: 35s\tremaining: 30.4s\n",
      "2462:\tlearn: 2.1001028\ttotal: 35s\tremaining: 30.3s\n",
      "2463:\tlearn: 2.0997748\ttotal: 35s\tremaining: 30.3s\n",
      "2464:\tlearn: 2.0996223\ttotal: 35s\tremaining: 30.3s\n",
      "2465:\tlearn: 2.0992206\ttotal: 35s\tremaining: 30.3s\n",
      "2466:\tlearn: 2.0989118\ttotal: 35.1s\tremaining: 30.3s\n",
      "2467:\tlearn: 2.0983352\ttotal: 35.1s\tremaining: 30.3s\n",
      "2468:\tlearn: 2.0976352\ttotal: 35.1s\tremaining: 30.3s\n",
      "2469:\tlearn: 2.0971251\ttotal: 35.1s\tremaining: 30.2s\n",
      "2470:\tlearn: 2.0967872\ttotal: 35.1s\tremaining: 30.2s\n",
      "2471:\tlearn: 2.0962010\ttotal: 35.1s\tremaining: 30.2s\n",
      "2472:\tlearn: 2.0960657\ttotal: 35.1s\tremaining: 30.2s\n",
      "2473:\tlearn: 2.0958117\ttotal: 35.2s\tremaining: 30.2s\n",
      "2474:\tlearn: 2.0956418\ttotal: 35.2s\tremaining: 30.2s\n",
      "2475:\tlearn: 2.0954396\ttotal: 35.2s\tremaining: 30.2s\n",
      "2476:\tlearn: 2.0952301\ttotal: 35.2s\tremaining: 30.1s\n",
      "2477:\tlearn: 2.0948631\ttotal: 35.2s\tremaining: 30.1s\n",
      "2478:\tlearn: 2.0942079\ttotal: 35.2s\tremaining: 30.1s\n",
      "2479:\tlearn: 2.0939673\ttotal: 35.2s\tremaining: 30.1s\n",
      "2480:\tlearn: 2.0937191\ttotal: 35.3s\tremaining: 30.1s\n",
      "2481:\tlearn: 2.0934132\ttotal: 35.3s\tremaining: 30.1s\n",
      "2482:\tlearn: 2.0928215\ttotal: 35.3s\tremaining: 30.1s\n",
      "2483:\tlearn: 2.0923921\ttotal: 35.3s\tremaining: 30s\n",
      "2484:\tlearn: 2.0918503\ttotal: 35.3s\tremaining: 30s\n",
      "2485:\tlearn: 2.0917452\ttotal: 35.3s\tremaining: 30s\n",
      "2486:\tlearn: 2.0914187\ttotal: 35.3s\tremaining: 30s\n",
      "2487:\tlearn: 2.0910338\ttotal: 35.4s\tremaining: 30s\n",
      "2488:\tlearn: 2.0907393\ttotal: 35.4s\tremaining: 30s\n",
      "2489:\tlearn: 2.0906597\ttotal: 35.4s\tremaining: 30s\n",
      "2490:\tlearn: 2.0904195\ttotal: 35.4s\tremaining: 29.9s\n",
      "2491:\tlearn: 2.0899616\ttotal: 35.4s\tremaining: 29.9s\n",
      "2492:\tlearn: 2.0893500\ttotal: 35.4s\tremaining: 29.9s\n",
      "2493:\tlearn: 2.0889531\ttotal: 35.4s\tremaining: 29.9s\n",
      "2494:\tlearn: 2.0886624\ttotal: 35.5s\tremaining: 29.9s\n",
      "2495:\tlearn: 2.0885119\ttotal: 35.5s\tremaining: 29.9s\n",
      "2496:\tlearn: 2.0875074\ttotal: 35.5s\tremaining: 29.9s\n",
      "2497:\tlearn: 2.0869247\ttotal: 35.5s\tremaining: 29.8s\n",
      "2498:\tlearn: 2.0867663\ttotal: 35.5s\tremaining: 29.8s\n",
      "2499:\tlearn: 2.0864082\ttotal: 35.5s\tremaining: 29.8s\n",
      "2500:\tlearn: 2.0862076\ttotal: 35.5s\tremaining: 29.8s\n",
      "2501:\tlearn: 2.0857485\ttotal: 35.6s\tremaining: 29.8s\n",
      "2502:\tlearn: 2.0854327\ttotal: 35.6s\tremaining: 29.8s\n",
      "2503:\tlearn: 2.0849660\ttotal: 35.6s\tremaining: 29.8s\n",
      "2504:\tlearn: 2.0847170\ttotal: 35.6s\tremaining: 29.7s\n",
      "2505:\tlearn: 2.0846467\ttotal: 35.6s\tremaining: 29.7s\n",
      "2506:\tlearn: 2.0844957\ttotal: 35.6s\tremaining: 29.7s\n",
      "2507:\tlearn: 2.0837214\ttotal: 35.6s\tremaining: 29.7s\n",
      "2508:\tlearn: 2.0831599\ttotal: 35.7s\tremaining: 29.7s\n",
      "2509:\tlearn: 2.0830232\ttotal: 35.7s\tremaining: 29.7s\n",
      "2510:\tlearn: 2.0827913\ttotal: 35.7s\tremaining: 29.7s\n",
      "2511:\tlearn: 2.0824404\ttotal: 35.7s\tremaining: 29.6s\n",
      "2512:\tlearn: 2.0820725\ttotal: 35.7s\tremaining: 29.6s\n",
      "2513:\tlearn: 2.0817692\ttotal: 35.7s\tremaining: 29.6s\n",
      "2514:\tlearn: 2.0813702\ttotal: 35.7s\tremaining: 29.6s\n",
      "2515:\tlearn: 2.0811160\ttotal: 35.8s\tremaining: 29.6s\n",
      "2516:\tlearn: 2.0807604\ttotal: 35.8s\tremaining: 29.6s\n",
      "2517:\tlearn: 2.0804181\ttotal: 35.8s\tremaining: 29.6s\n",
      "2518:\tlearn: 2.0799761\ttotal: 35.8s\tremaining: 29.5s\n",
      "2519:\tlearn: 2.0797178\ttotal: 35.8s\tremaining: 29.5s\n",
      "2520:\tlearn: 2.0794454\ttotal: 35.8s\tremaining: 29.5s\n",
      "2521:\tlearn: 2.0792600\ttotal: 35.8s\tremaining: 29.5s\n",
      "2522:\tlearn: 2.0790247\ttotal: 35.9s\tremaining: 29.5s\n",
      "2523:\tlearn: 2.0787872\ttotal: 35.9s\tremaining: 29.5s\n",
      "2524:\tlearn: 2.0786665\ttotal: 35.9s\tremaining: 29.5s\n",
      "2525:\tlearn: 2.0779936\ttotal: 35.9s\tremaining: 29.4s\n",
      "2526:\tlearn: 2.0776182\ttotal: 35.9s\tremaining: 29.4s\n",
      "2527:\tlearn: 2.0774302\ttotal: 35.9s\tremaining: 29.4s\n",
      "2528:\tlearn: 2.0769894\ttotal: 35.9s\tremaining: 29.4s\n",
      "2529:\tlearn: 2.0767421\ttotal: 36s\tremaining: 29.4s\n",
      "2530:\tlearn: 2.0766310\ttotal: 36s\tremaining: 29.4s\n",
      "2531:\tlearn: 2.0762256\ttotal: 36s\tremaining: 29.4s\n",
      "2532:\tlearn: 2.0758554\ttotal: 36s\tremaining: 29.3s\n",
      "2533:\tlearn: 2.0756832\ttotal: 36s\tremaining: 29.3s\n",
      "2534:\tlearn: 2.0754577\ttotal: 36s\tremaining: 29.3s\n",
      "2535:\tlearn: 2.0751100\ttotal: 36s\tremaining: 29.3s\n",
      "2536:\tlearn: 2.0747238\ttotal: 36.1s\tremaining: 29.3s\n",
      "2537:\tlearn: 2.0742820\ttotal: 36.1s\tremaining: 29.3s\n",
      "2538:\tlearn: 2.0740501\ttotal: 36.1s\tremaining: 29.3s\n",
      "2539:\tlearn: 2.0740493\ttotal: 36.1s\tremaining: 29.2s\n",
      "2540:\tlearn: 2.0737726\ttotal: 36.1s\tremaining: 29.2s\n",
      "2541:\tlearn: 2.0734733\ttotal: 36.1s\tremaining: 29.2s\n",
      "2542:\tlearn: 2.0732912\ttotal: 36.1s\tremaining: 29.2s\n",
      "2543:\tlearn: 2.0727274\ttotal: 36.1s\tremaining: 29.2s\n",
      "2544:\tlearn: 2.0725197\ttotal: 36.2s\tremaining: 29.2s\n",
      "2545:\tlearn: 2.0724981\ttotal: 36.2s\tremaining: 29.2s\n",
      "2546:\tlearn: 2.0722630\ttotal: 36.2s\tremaining: 29.1s\n",
      "2547:\tlearn: 2.0717988\ttotal: 36.2s\tremaining: 29.1s\n",
      "2548:\tlearn: 2.0717971\ttotal: 36.2s\tremaining: 29.1s\n",
      "2549:\tlearn: 2.0715907\ttotal: 36.2s\tremaining: 29.1s\n",
      "2550:\tlearn: 2.0711445\ttotal: 36.2s\tremaining: 29.1s\n",
      "2551:\tlearn: 2.0708279\ttotal: 36.3s\tremaining: 29.1s\n",
      "2552:\tlearn: 2.0706317\ttotal: 36.3s\tremaining: 29.1s\n",
      "2553:\tlearn: 2.0700988\ttotal: 36.3s\tremaining: 29s\n",
      "2554:\tlearn: 2.0697571\ttotal: 36.3s\tremaining: 29s\n",
      "2555:\tlearn: 2.0695627\ttotal: 36.3s\tremaining: 29s\n",
      "2556:\tlearn: 2.0693846\ttotal: 36.3s\tremaining: 29s\n",
      "2557:\tlearn: 2.0690689\ttotal: 36.3s\tremaining: 29s\n",
      "2558:\tlearn: 2.0687810\ttotal: 36.4s\tremaining: 29s\n",
      "2559:\tlearn: 2.0683589\ttotal: 36.4s\tremaining: 29s\n",
      "2560:\tlearn: 2.0681568\ttotal: 36.4s\tremaining: 28.9s\n",
      "2561:\tlearn: 2.0677360\ttotal: 36.4s\tremaining: 28.9s\n",
      "2562:\tlearn: 2.0675427\ttotal: 36.4s\tremaining: 28.9s\n",
      "2563:\tlearn: 2.0672084\ttotal: 36.4s\tremaining: 28.9s\n",
      "2564:\tlearn: 2.0669182\ttotal: 36.4s\tremaining: 28.9s\n",
      "2565:\tlearn: 2.0665571\ttotal: 36.5s\tremaining: 28.9s\n",
      "2566:\tlearn: 2.0663964\ttotal: 36.5s\tremaining: 28.9s\n",
      "2567:\tlearn: 2.0661557\ttotal: 36.5s\tremaining: 28.8s\n",
      "2568:\tlearn: 2.0659632\ttotal: 36.5s\tremaining: 28.8s\n",
      "2569:\tlearn: 2.0655472\ttotal: 36.5s\tremaining: 28.8s\n",
      "2570:\tlearn: 2.0653528\ttotal: 36.5s\tremaining: 28.8s\n",
      "2571:\tlearn: 2.0650686\ttotal: 36.5s\tremaining: 28.8s\n",
      "2572:\tlearn: 2.0648691\ttotal: 36.6s\tremaining: 28.8s\n",
      "2573:\tlearn: 2.0647543\ttotal: 36.6s\tremaining: 28.8s\n",
      "2574:\tlearn: 2.0643325\ttotal: 36.6s\tremaining: 28.7s\n",
      "2575:\tlearn: 2.0636805\ttotal: 36.6s\tremaining: 28.7s\n",
      "2576:\tlearn: 2.0634985\ttotal: 36.6s\tremaining: 28.7s\n",
      "2577:\tlearn: 2.0632984\ttotal: 36.6s\tremaining: 28.7s\n",
      "2578:\tlearn: 2.0628895\ttotal: 36.6s\tremaining: 28.7s\n",
      "2579:\tlearn: 2.0625858\ttotal: 36.7s\tremaining: 28.7s\n",
      "2580:\tlearn: 2.0623256\ttotal: 36.7s\tremaining: 28.7s\n",
      "2581:\tlearn: 2.0620258\ttotal: 36.7s\tremaining: 28.6s\n",
      "2582:\tlearn: 2.0617033\ttotal: 36.7s\tremaining: 28.6s\n",
      "2583:\tlearn: 2.0612929\ttotal: 36.7s\tremaining: 28.6s\n",
      "2584:\tlearn: 2.0609782\ttotal: 36.7s\tremaining: 28.6s\n",
      "2585:\tlearn: 2.0606382\ttotal: 36.7s\tremaining: 28.6s\n",
      "2586:\tlearn: 2.0604379\ttotal: 36.8s\tremaining: 28.6s\n",
      "2587:\tlearn: 2.0601372\ttotal: 36.8s\tremaining: 28.6s\n",
      "2588:\tlearn: 2.0600435\ttotal: 36.8s\tremaining: 28.5s\n",
      "2589:\tlearn: 2.0597565\ttotal: 36.8s\tremaining: 28.5s\n",
      "2590:\tlearn: 2.0595534\ttotal: 36.8s\tremaining: 28.5s\n",
      "2591:\tlearn: 2.0589990\ttotal: 36.8s\tremaining: 28.5s\n",
      "2592:\tlearn: 2.0587944\ttotal: 36.8s\tremaining: 28.5s\n",
      "2593:\tlearn: 2.0583796\ttotal: 36.9s\tremaining: 28.5s\n",
      "2594:\tlearn: 2.0581237\ttotal: 36.9s\tremaining: 28.5s\n",
      "2595:\tlearn: 2.0577937\ttotal: 36.9s\tremaining: 28.4s\n",
      "2596:\tlearn: 2.0573733\ttotal: 36.9s\tremaining: 28.4s\n",
      "2597:\tlearn: 2.0570486\ttotal: 36.9s\tremaining: 28.4s\n",
      "2598:\tlearn: 2.0568991\ttotal: 36.9s\tremaining: 28.4s\n",
      "2599:\tlearn: 2.0566286\ttotal: 36.9s\tremaining: 28.4s\n",
      "2600:\tlearn: 2.0561349\ttotal: 37s\tremaining: 28.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2601:\tlearn: 2.0559033\ttotal: 37s\tremaining: 28.4s\n",
      "2602:\tlearn: 2.0554879\ttotal: 37s\tremaining: 28.3s\n",
      "2603:\tlearn: 2.0548687\ttotal: 37s\tremaining: 28.3s\n",
      "2604:\tlearn: 2.0546462\ttotal: 37s\tremaining: 28.3s\n",
      "2605:\tlearn: 2.0542286\ttotal: 37s\tremaining: 28.3s\n",
      "2606:\tlearn: 2.0536950\ttotal: 37s\tremaining: 28.3s\n",
      "2607:\tlearn: 2.0526349\ttotal: 37.1s\tremaining: 28.3s\n",
      "2608:\tlearn: 2.0521495\ttotal: 37.1s\tremaining: 28.3s\n",
      "2609:\tlearn: 2.0518496\ttotal: 37.1s\tremaining: 28.2s\n",
      "2610:\tlearn: 2.0515144\ttotal: 37.1s\tremaining: 28.2s\n",
      "2611:\tlearn: 2.0511599\ttotal: 37.1s\tremaining: 28.2s\n",
      "2612:\tlearn: 2.0510322\ttotal: 37.1s\tremaining: 28.2s\n",
      "2613:\tlearn: 2.0507208\ttotal: 37.1s\tremaining: 28.2s\n",
      "2614:\tlearn: 2.0505704\ttotal: 37.2s\tremaining: 28.2s\n",
      "2615:\tlearn: 2.0503946\ttotal: 37.2s\tremaining: 28.2s\n",
      "2616:\tlearn: 2.0500010\ttotal: 37.2s\tremaining: 28.1s\n",
      "2617:\tlearn: 2.0498153\ttotal: 37.2s\tremaining: 28.1s\n",
      "2618:\tlearn: 2.0495730\ttotal: 37.2s\tremaining: 28.1s\n",
      "2619:\tlearn: 2.0490539\ttotal: 37.2s\tremaining: 28.1s\n",
      "2620:\tlearn: 2.0489350\ttotal: 37.2s\tremaining: 28.1s\n",
      "2621:\tlearn: 2.0488305\ttotal: 37.3s\tremaining: 28.1s\n",
      "2622:\tlearn: 2.0486091\ttotal: 37.3s\tremaining: 28.1s\n",
      "2623:\tlearn: 2.0483535\ttotal: 37.3s\tremaining: 28s\n",
      "2624:\tlearn: 2.0481582\ttotal: 37.3s\tremaining: 28s\n",
      "2625:\tlearn: 2.0479082\ttotal: 37.3s\tremaining: 28s\n",
      "2626:\tlearn: 2.0478265\ttotal: 37.3s\tremaining: 28s\n",
      "2627:\tlearn: 2.0477005\ttotal: 37.3s\tremaining: 28s\n",
      "2628:\tlearn: 2.0474181\ttotal: 37.3s\tremaining: 28s\n",
      "2629:\tlearn: 2.0472161\ttotal: 37.4s\tremaining: 28s\n",
      "2630:\tlearn: 2.0469700\ttotal: 37.4s\tremaining: 27.9s\n",
      "2631:\tlearn: 2.0465773\ttotal: 37.4s\tremaining: 27.9s\n",
      "2632:\tlearn: 2.0461424\ttotal: 37.4s\tremaining: 27.9s\n",
      "2633:\tlearn: 2.0455537\ttotal: 37.4s\tremaining: 27.9s\n",
      "2634:\tlearn: 2.0453534\ttotal: 37.4s\tremaining: 27.9s\n",
      "2635:\tlearn: 2.0450037\ttotal: 37.5s\tremaining: 27.9s\n",
      "2636:\tlearn: 2.0446714\ttotal: 37.5s\tremaining: 27.9s\n",
      "2637:\tlearn: 2.0443058\ttotal: 37.5s\tremaining: 27.8s\n",
      "2638:\tlearn: 2.0441562\ttotal: 37.5s\tremaining: 27.8s\n",
      "2639:\tlearn: 2.0438385\ttotal: 37.5s\tremaining: 27.8s\n",
      "2640:\tlearn: 2.0437743\ttotal: 37.5s\tremaining: 27.8s\n",
      "2641:\tlearn: 2.0435186\ttotal: 37.5s\tremaining: 27.8s\n",
      "2642:\tlearn: 2.0433402\ttotal: 37.5s\tremaining: 27.8s\n",
      "2643:\tlearn: 2.0431580\ttotal: 37.6s\tremaining: 27.8s\n",
      "2644:\tlearn: 2.0426633\ttotal: 37.6s\tremaining: 27.7s\n",
      "2645:\tlearn: 2.0423003\ttotal: 37.6s\tremaining: 27.7s\n",
      "2646:\tlearn: 2.0418807\ttotal: 37.6s\tremaining: 27.7s\n",
      "2647:\tlearn: 2.0415007\ttotal: 37.6s\tremaining: 27.7s\n",
      "2648:\tlearn: 2.0413532\ttotal: 37.6s\tremaining: 27.7s\n",
      "2649:\tlearn: 2.0409679\ttotal: 37.7s\tremaining: 27.7s\n",
      "2650:\tlearn: 2.0407064\ttotal: 37.7s\tremaining: 27.7s\n",
      "2651:\tlearn: 2.0404533\ttotal: 37.7s\tremaining: 27.7s\n",
      "2652:\tlearn: 2.0400182\ttotal: 37.7s\tremaining: 27.6s\n",
      "2653:\tlearn: 2.0398233\ttotal: 37.7s\tremaining: 27.6s\n",
      "2654:\tlearn: 2.0396834\ttotal: 37.7s\tremaining: 27.6s\n",
      "2655:\tlearn: 2.0393348\ttotal: 37.7s\tremaining: 27.6s\n",
      "2656:\tlearn: 2.0389440\ttotal: 37.8s\tremaining: 27.6s\n",
      "2657:\tlearn: 2.0388072\ttotal: 37.8s\tremaining: 27.6s\n",
      "2658:\tlearn: 2.0385483\ttotal: 37.8s\tremaining: 27.6s\n",
      "2659:\tlearn: 2.0382071\ttotal: 37.8s\tremaining: 27.5s\n",
      "2660:\tlearn: 2.0379428\ttotal: 37.8s\tremaining: 27.5s\n",
      "2661:\tlearn: 2.0378109\ttotal: 37.8s\tremaining: 27.5s\n",
      "2662:\tlearn: 2.0374679\ttotal: 37.8s\tremaining: 27.5s\n",
      "2663:\tlearn: 2.0372624\ttotal: 37.9s\tremaining: 27.5s\n",
      "2664:\tlearn: 2.0370277\ttotal: 37.9s\tremaining: 27.5s\n",
      "2665:\tlearn: 2.0369972\ttotal: 37.9s\tremaining: 27.4s\n",
      "2666:\tlearn: 2.0367522\ttotal: 37.9s\tremaining: 27.4s\n",
      "2667:\tlearn: 2.0363441\ttotal: 37.9s\tremaining: 27.4s\n",
      "2668:\tlearn: 2.0360631\ttotal: 37.9s\tremaining: 27.4s\n",
      "2669:\tlearn: 2.0357198\ttotal: 37.9s\tremaining: 27.4s\n",
      "2670:\tlearn: 2.0351894\ttotal: 38s\tremaining: 27.4s\n",
      "2671:\tlearn: 2.0349599\ttotal: 38s\tremaining: 27.4s\n",
      "2672:\tlearn: 2.0349160\ttotal: 38s\tremaining: 27.3s\n",
      "2673:\tlearn: 2.0346501\ttotal: 38s\tremaining: 27.3s\n",
      "2674:\tlearn: 2.0344277\ttotal: 38s\tremaining: 27.3s\n",
      "2675:\tlearn: 2.0337628\ttotal: 38s\tremaining: 27.3s\n",
      "2676:\tlearn: 2.0335714\ttotal: 38s\tremaining: 27.3s\n",
      "2677:\tlearn: 2.0331636\ttotal: 38s\tremaining: 27.3s\n",
      "2678:\tlearn: 2.0327330\ttotal: 38.1s\tremaining: 27.3s\n",
      "2679:\tlearn: 2.0325461\ttotal: 38.1s\tremaining: 27.2s\n",
      "2680:\tlearn: 2.0320183\ttotal: 38.1s\tremaining: 27.2s\n",
      "2681:\tlearn: 2.0317329\ttotal: 38.1s\tremaining: 27.2s\n",
      "2682:\tlearn: 2.0312830\ttotal: 38.1s\tremaining: 27.2s\n",
      "2683:\tlearn: 2.0311508\ttotal: 38.1s\tremaining: 27.2s\n",
      "2684:\tlearn: 2.0308512\ttotal: 38.1s\tremaining: 27.2s\n",
      "2685:\tlearn: 2.0306008\ttotal: 38.2s\tremaining: 27.2s\n",
      "2686:\tlearn: 2.0303692\ttotal: 38.2s\tremaining: 27.1s\n",
      "2687:\tlearn: 2.0297414\ttotal: 38.2s\tremaining: 27.1s\n",
      "2688:\tlearn: 2.0294352\ttotal: 38.2s\tremaining: 27.1s\n",
      "2689:\tlearn: 2.0289613\ttotal: 38.2s\tremaining: 27.1s\n",
      "2690:\tlearn: 2.0285732\ttotal: 38.3s\tremaining: 27.1s\n",
      "2691:\tlearn: 2.0281133\ttotal: 38.3s\tremaining: 27.1s\n",
      "2692:\tlearn: 2.0278346\ttotal: 38.3s\tremaining: 27.1s\n",
      "2693:\tlearn: 2.0275043\ttotal: 38.3s\tremaining: 27.1s\n",
      "2694:\tlearn: 2.0270856\ttotal: 38.3s\tremaining: 27.1s\n",
      "2695:\tlearn: 2.0268063\ttotal: 38.3s\tremaining: 27s\n",
      "2696:\tlearn: 2.0265941\ttotal: 38.3s\tremaining: 27s\n",
      "2697:\tlearn: 2.0262151\ttotal: 38.4s\tremaining: 27s\n",
      "2698:\tlearn: 2.0259476\ttotal: 38.4s\tremaining: 27s\n",
      "2699:\tlearn: 2.0255630\ttotal: 38.4s\tremaining: 27s\n",
      "2700:\tlearn: 2.0251081\ttotal: 38.4s\tremaining: 27s\n",
      "2701:\tlearn: 2.0246568\ttotal: 38.4s\tremaining: 27s\n",
      "2702:\tlearn: 2.0244131\ttotal: 38.4s\tremaining: 26.9s\n",
      "2703:\tlearn: 2.0242435\ttotal: 38.4s\tremaining: 26.9s\n",
      "2704:\tlearn: 2.0240629\ttotal: 38.5s\tremaining: 26.9s\n",
      "2705:\tlearn: 2.0238239\ttotal: 38.5s\tremaining: 26.9s\n",
      "2706:\tlearn: 2.0235546\ttotal: 38.5s\tremaining: 26.9s\n",
      "2707:\tlearn: 2.0231481\ttotal: 38.5s\tremaining: 26.9s\n",
      "2708:\tlearn: 2.0229381\ttotal: 38.5s\tremaining: 26.9s\n",
      "2709:\tlearn: 2.0227528\ttotal: 38.5s\tremaining: 26.8s\n",
      "2710:\tlearn: 2.0225394\ttotal: 38.5s\tremaining: 26.8s\n",
      "2711:\tlearn: 2.0221943\ttotal: 38.6s\tremaining: 26.8s\n",
      "2712:\tlearn: 2.0218819\ttotal: 38.6s\tremaining: 26.8s\n",
      "2713:\tlearn: 2.0217900\ttotal: 38.6s\tremaining: 26.8s\n",
      "2714:\tlearn: 2.0213599\ttotal: 38.6s\tremaining: 26.8s\n",
      "2715:\tlearn: 2.0211323\ttotal: 38.6s\tremaining: 26.8s\n",
      "2716:\tlearn: 2.0208382\ttotal: 38.6s\tremaining: 26.7s\n",
      "2717:\tlearn: 2.0206070\ttotal: 38.6s\tremaining: 26.7s\n",
      "2718:\tlearn: 2.0201547\ttotal: 38.7s\tremaining: 26.7s\n",
      "2719:\tlearn: 2.0199115\ttotal: 38.7s\tremaining: 26.7s\n",
      "2720:\tlearn: 2.0196799\ttotal: 38.7s\tremaining: 26.7s\n",
      "2721:\tlearn: 2.0193464\ttotal: 38.7s\tremaining: 26.7s\n",
      "2722:\tlearn: 2.0192105\ttotal: 38.7s\tremaining: 26.7s\n",
      "2723:\tlearn: 2.0188210\ttotal: 38.7s\tremaining: 26.6s\n",
      "2724:\tlearn: 2.0185359\ttotal: 38.7s\tremaining: 26.6s\n",
      "2725:\tlearn: 2.0182964\ttotal: 38.8s\tremaining: 26.6s\n",
      "2726:\tlearn: 2.0179607\ttotal: 38.8s\tremaining: 26.6s\n",
      "2727:\tlearn: 2.0176771\ttotal: 38.8s\tremaining: 26.6s\n",
      "2728:\tlearn: 2.0174761\ttotal: 38.8s\tremaining: 26.6s\n",
      "2729:\tlearn: 2.0171469\ttotal: 38.8s\tremaining: 26.6s\n",
      "2730:\tlearn: 2.0168984\ttotal: 38.8s\tremaining: 26.5s\n",
      "2731:\tlearn: 2.0163487\ttotal: 38.8s\tremaining: 26.5s\n",
      "2732:\tlearn: 2.0161168\ttotal: 38.9s\tremaining: 26.5s\n",
      "2733:\tlearn: 2.0159311\ttotal: 38.9s\tremaining: 26.5s\n",
      "2734:\tlearn: 2.0153659\ttotal: 38.9s\tremaining: 26.5s\n",
      "2735:\tlearn: 2.0149769\ttotal: 38.9s\tremaining: 26.5s\n",
      "2736:\tlearn: 2.0146648\ttotal: 38.9s\tremaining: 26.5s\n",
      "2737:\tlearn: 2.0140134\ttotal: 38.9s\tremaining: 26.4s\n",
      "2738:\tlearn: 2.0138420\ttotal: 38.9s\tremaining: 26.4s\n",
      "2739:\tlearn: 2.0136175\ttotal: 39s\tremaining: 26.4s\n",
      "2740:\tlearn: 2.0134197\ttotal: 39s\tremaining: 26.4s\n",
      "2741:\tlearn: 2.0130999\ttotal: 39s\tremaining: 26.4s\n",
      "2742:\tlearn: 2.0127042\ttotal: 39s\tremaining: 26.4s\n",
      "2743:\tlearn: 2.0125881\ttotal: 39s\tremaining: 26.4s\n",
      "2744:\tlearn: 2.0123086\ttotal: 39s\tremaining: 26.3s\n",
      "2745:\tlearn: 2.0118914\ttotal: 39s\tremaining: 26.3s\n",
      "2746:\tlearn: 2.0115594\ttotal: 39s\tremaining: 26.3s\n",
      "2747:\tlearn: 2.0110390\ttotal: 39.1s\tremaining: 26.3s\n",
      "2748:\tlearn: 2.0107031\ttotal: 39.1s\tremaining: 26.3s\n",
      "2749:\tlearn: 2.0104772\ttotal: 39.1s\tremaining: 26.3s\n",
      "2750:\tlearn: 2.0100912\ttotal: 39.1s\tremaining: 26.3s\n",
      "2751:\tlearn: 2.0097539\ttotal: 39.1s\tremaining: 26.2s\n",
      "2752:\tlearn: 2.0093510\ttotal: 39.1s\tremaining: 26.2s\n",
      "2753:\tlearn: 2.0092788\ttotal: 39.2s\tremaining: 26.2s\n",
      "2754:\tlearn: 2.0091025\ttotal: 39.2s\tremaining: 26.2s\n",
      "2755:\tlearn: 2.0087686\ttotal: 39.2s\tremaining: 26.2s\n",
      "2756:\tlearn: 2.0082832\ttotal: 39.2s\tremaining: 26.2s\n",
      "2757:\tlearn: 2.0080868\ttotal: 39.2s\tremaining: 26.2s\n",
      "2758:\tlearn: 2.0076324\ttotal: 39.2s\tremaining: 26.1s\n",
      "2759:\tlearn: 2.0073283\ttotal: 39.2s\tremaining: 26.1s\n",
      "2760:\tlearn: 2.0071072\ttotal: 39.3s\tremaining: 26.1s\n",
      "2761:\tlearn: 2.0069409\ttotal: 39.3s\tremaining: 26.1s\n",
      "2762:\tlearn: 2.0068968\ttotal: 39.3s\tremaining: 26.1s\n",
      "2763:\tlearn: 2.0066231\ttotal: 39.3s\tremaining: 26.1s\n",
      "2764:\tlearn: 2.0061984\ttotal: 39.3s\tremaining: 26.1s\n",
      "2765:\tlearn: 2.0060385\ttotal: 39.3s\tremaining: 26s\n",
      "2766:\tlearn: 2.0058066\ttotal: 39.3s\tremaining: 26s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2767:\tlearn: 2.0053991\ttotal: 39.4s\tremaining: 26s\n",
      "2768:\tlearn: 2.0048990\ttotal: 39.4s\tremaining: 26s\n",
      "2769:\tlearn: 2.0043886\ttotal: 39.4s\tremaining: 26s\n",
      "2770:\tlearn: 2.0041651\ttotal: 39.4s\tremaining: 26s\n",
      "2771:\tlearn: 2.0040001\ttotal: 39.4s\tremaining: 26s\n",
      "2772:\tlearn: 2.0037639\ttotal: 39.4s\tremaining: 25.9s\n",
      "2773:\tlearn: 2.0033609\ttotal: 39.4s\tremaining: 25.9s\n",
      "2774:\tlearn: 2.0031016\ttotal: 39.5s\tremaining: 25.9s\n",
      "2775:\tlearn: 2.0026394\ttotal: 39.5s\tremaining: 25.9s\n",
      "2776:\tlearn: 2.0024432\ttotal: 39.5s\tremaining: 25.9s\n",
      "2777:\tlearn: 2.0021192\ttotal: 39.5s\tremaining: 25.9s\n",
      "2778:\tlearn: 2.0019634\ttotal: 39.5s\tremaining: 25.9s\n",
      "2779:\tlearn: 2.0017280\ttotal: 39.5s\tremaining: 25.8s\n",
      "2780:\tlearn: 2.0012753\ttotal: 39.5s\tremaining: 25.8s\n",
      "2781:\tlearn: 2.0009693\ttotal: 39.6s\tremaining: 25.8s\n",
      "2782:\tlearn: 2.0009219\ttotal: 39.6s\tremaining: 25.8s\n",
      "2783:\tlearn: 2.0005467\ttotal: 39.6s\tremaining: 25.8s\n",
      "2784:\tlearn: 2.0003092\ttotal: 39.6s\tremaining: 25.8s\n",
      "2785:\tlearn: 2.0001407\ttotal: 39.6s\tremaining: 25.8s\n",
      "2786:\tlearn: 1.9999964\ttotal: 39.6s\tremaining: 25.7s\n",
      "2787:\tlearn: 1.9998038\ttotal: 39.6s\tremaining: 25.7s\n",
      "2788:\tlearn: 1.9997071\ttotal: 39.7s\tremaining: 25.7s\n",
      "2789:\tlearn: 1.9993942\ttotal: 39.7s\tremaining: 25.7s\n",
      "2790:\tlearn: 1.9991013\ttotal: 39.7s\tremaining: 25.7s\n",
      "2791:\tlearn: 1.9989124\ttotal: 39.7s\tremaining: 25.7s\n",
      "2792:\tlearn: 1.9985988\ttotal: 39.7s\tremaining: 25.7s\n",
      "2793:\tlearn: 1.9982505\ttotal: 39.7s\tremaining: 25.6s\n",
      "2794:\tlearn: 1.9979361\ttotal: 39.7s\tremaining: 25.6s\n",
      "2795:\tlearn: 1.9975318\ttotal: 39.8s\tremaining: 25.6s\n",
      "2796:\tlearn: 1.9972775\ttotal: 39.8s\tremaining: 25.6s\n",
      "2797:\tlearn: 1.9969675\ttotal: 39.8s\tremaining: 25.6s\n",
      "2798:\tlearn: 1.9968199\ttotal: 39.8s\tremaining: 25.6s\n",
      "2799:\tlearn: 1.9964587\ttotal: 39.8s\tremaining: 25.6s\n",
      "2800:\tlearn: 1.9960262\ttotal: 39.8s\tremaining: 25.5s\n",
      "2801:\tlearn: 1.9956369\ttotal: 39.8s\tremaining: 25.5s\n",
      "2802:\tlearn: 1.9953176\ttotal: 39.8s\tremaining: 25.5s\n",
      "2803:\tlearn: 1.9950228\ttotal: 39.9s\tremaining: 25.5s\n",
      "2804:\tlearn: 1.9948661\ttotal: 39.9s\tremaining: 25.5s\n",
      "2805:\tlearn: 1.9944236\ttotal: 39.9s\tremaining: 25.5s\n",
      "2806:\tlearn: 1.9943008\ttotal: 39.9s\tremaining: 25.5s\n",
      "2807:\tlearn: 1.9938860\ttotal: 39.9s\tremaining: 25.4s\n",
      "2808:\tlearn: 1.9937136\ttotal: 39.9s\tremaining: 25.4s\n",
      "2809:\tlearn: 1.9935147\ttotal: 39.9s\tremaining: 25.4s\n",
      "2810:\tlearn: 1.9933453\ttotal: 40s\tremaining: 25.4s\n",
      "2811:\tlearn: 1.9929348\ttotal: 40s\tremaining: 25.4s\n",
      "2812:\tlearn: 1.9924243\ttotal: 40s\tremaining: 25.4s\n",
      "2813:\tlearn: 1.9919647\ttotal: 40s\tremaining: 25.4s\n",
      "2814:\tlearn: 1.9916565\ttotal: 40s\tremaining: 25.4s\n",
      "2815:\tlearn: 1.9913732\ttotal: 40s\tremaining: 25.3s\n",
      "2816:\tlearn: 1.9912299\ttotal: 40.1s\tremaining: 25.3s\n",
      "2817:\tlearn: 1.9910856\ttotal: 40.1s\tremaining: 25.3s\n",
      "2818:\tlearn: 1.9907497\ttotal: 40.1s\tremaining: 25.3s\n",
      "2819:\tlearn: 1.9903985\ttotal: 40.1s\tremaining: 25.3s\n",
      "2820:\tlearn: 1.9902346\ttotal: 40.1s\tremaining: 25.3s\n",
      "2821:\tlearn: 1.9899370\ttotal: 40.1s\tremaining: 25.3s\n",
      "2822:\tlearn: 1.9894652\ttotal: 40.1s\tremaining: 25.2s\n",
      "2823:\tlearn: 1.9891287\ttotal: 40.2s\tremaining: 25.2s\n",
      "2824:\tlearn: 1.9885277\ttotal: 40.2s\tremaining: 25.2s\n",
      "2825:\tlearn: 1.9882108\ttotal: 40.2s\tremaining: 25.2s\n",
      "2826:\tlearn: 1.9876865\ttotal: 40.2s\tremaining: 25.2s\n",
      "2827:\tlearn: 1.9873647\ttotal: 40.2s\tremaining: 25.2s\n",
      "2828:\tlearn: 1.9867517\ttotal: 40.2s\tremaining: 25.2s\n",
      "2829:\tlearn: 1.9865039\ttotal: 40.2s\tremaining: 25.1s\n",
      "2830:\tlearn: 1.9862416\ttotal: 40.3s\tremaining: 25.1s\n",
      "2831:\tlearn: 1.9858524\ttotal: 40.3s\tremaining: 25.1s\n",
      "2832:\tlearn: 1.9856593\ttotal: 40.3s\tremaining: 25.1s\n",
      "2833:\tlearn: 1.9852859\ttotal: 40.3s\tremaining: 25.1s\n",
      "2834:\tlearn: 1.9849806\ttotal: 40.3s\tremaining: 25.1s\n",
      "2835:\tlearn: 1.9848184\ttotal: 40.3s\tremaining: 25.1s\n",
      "2836:\tlearn: 1.9844891\ttotal: 40.3s\tremaining: 25s\n",
      "2837:\tlearn: 1.9842472\ttotal: 40.4s\tremaining: 25s\n",
      "2838:\tlearn: 1.9837825\ttotal: 40.4s\tremaining: 25s\n",
      "2839:\tlearn: 1.9833252\ttotal: 40.4s\tremaining: 25s\n",
      "2840:\tlearn: 1.9832494\ttotal: 40.4s\tremaining: 25s\n",
      "2841:\tlearn: 1.9827839\ttotal: 40.4s\tremaining: 25s\n",
      "2842:\tlearn: 1.9824418\ttotal: 40.4s\tremaining: 25s\n",
      "2843:\tlearn: 1.9822853\ttotal: 40.4s\tremaining: 24.9s\n",
      "2844:\tlearn: 1.9821498\ttotal: 40.5s\tremaining: 24.9s\n",
      "2845:\tlearn: 1.9816606\ttotal: 40.5s\tremaining: 24.9s\n",
      "2846:\tlearn: 1.9816417\ttotal: 40.5s\tremaining: 24.9s\n",
      "2847:\tlearn: 1.9814669\ttotal: 40.5s\tremaining: 24.9s\n",
      "2848:\tlearn: 1.9813100\ttotal: 40.5s\tremaining: 24.9s\n",
      "2849:\tlearn: 1.9811757\ttotal: 40.5s\tremaining: 24.9s\n",
      "2850:\tlearn: 1.9807891\ttotal: 40.5s\tremaining: 24.8s\n",
      "2851:\tlearn: 1.9807129\ttotal: 40.6s\tremaining: 24.8s\n",
      "2852:\tlearn: 1.9804598\ttotal: 40.6s\tremaining: 24.8s\n",
      "2853:\tlearn: 1.9801688\ttotal: 40.6s\tremaining: 24.8s\n",
      "2854:\tlearn: 1.9796959\ttotal: 40.6s\tremaining: 24.8s\n",
      "2855:\tlearn: 1.9796201\ttotal: 40.6s\tremaining: 24.8s\n",
      "2856:\tlearn: 1.9794479\ttotal: 40.6s\tremaining: 24.8s\n",
      "2857:\tlearn: 1.9791597\ttotal: 40.6s\tremaining: 24.7s\n",
      "2858:\tlearn: 1.9788059\ttotal: 40.7s\tremaining: 24.7s\n",
      "2859:\tlearn: 1.9785068\ttotal: 40.7s\tremaining: 24.7s\n",
      "2860:\tlearn: 1.9782937\ttotal: 40.7s\tremaining: 24.7s\n",
      "2861:\tlearn: 1.9781897\ttotal: 40.7s\tremaining: 24.7s\n",
      "2862:\tlearn: 1.9779693\ttotal: 40.7s\tremaining: 24.7s\n",
      "2863:\tlearn: 1.9777890\ttotal: 40.7s\tremaining: 24.7s\n",
      "2864:\tlearn: 1.9774954\ttotal: 40.7s\tremaining: 24.6s\n",
      "2865:\tlearn: 1.9769164\ttotal: 40.8s\tremaining: 24.6s\n",
      "2866:\tlearn: 1.9766593\ttotal: 40.8s\tremaining: 24.6s\n",
      "2867:\tlearn: 1.9762814\ttotal: 40.8s\tremaining: 24.6s\n",
      "2868:\tlearn: 1.9758877\ttotal: 40.8s\tremaining: 24.6s\n",
      "2869:\tlearn: 1.9756025\ttotal: 40.8s\tremaining: 24.6s\n",
      "2870:\tlearn: 1.9751443\ttotal: 40.8s\tremaining: 24.6s\n",
      "2871:\tlearn: 1.9747876\ttotal: 40.8s\tremaining: 24.5s\n",
      "2872:\tlearn: 1.9741580\ttotal: 40.9s\tremaining: 24.5s\n",
      "2873:\tlearn: 1.9737887\ttotal: 40.9s\tremaining: 24.5s\n",
      "2874:\tlearn: 1.9735808\ttotal: 40.9s\tremaining: 24.5s\n",
      "2875:\tlearn: 1.9731808\ttotal: 40.9s\tremaining: 24.5s\n",
      "2876:\tlearn: 1.9727295\ttotal: 40.9s\tremaining: 24.5s\n",
      "2877:\tlearn: 1.9724726\ttotal: 40.9s\tremaining: 24.5s\n",
      "2878:\tlearn: 1.9721190\ttotal: 40.9s\tremaining: 24.4s\n",
      "2879:\tlearn: 1.9721149\ttotal: 41s\tremaining: 24.4s\n",
      "2880:\tlearn: 1.9719204\ttotal: 41s\tremaining: 24.4s\n",
      "2881:\tlearn: 1.9717023\ttotal: 41s\tremaining: 24.4s\n",
      "2882:\tlearn: 1.9715118\ttotal: 41s\tremaining: 24.4s\n",
      "2883:\tlearn: 1.9712320\ttotal: 41s\tremaining: 24.4s\n",
      "2884:\tlearn: 1.9709659\ttotal: 41s\tremaining: 24.4s\n",
      "2885:\tlearn: 1.9708955\ttotal: 41s\tremaining: 24.3s\n",
      "2886:\tlearn: 1.9705051\ttotal: 41.1s\tremaining: 24.3s\n",
      "2887:\tlearn: 1.9702554\ttotal: 41.1s\tremaining: 24.3s\n",
      "2888:\tlearn: 1.9695273\ttotal: 41.1s\tremaining: 24.3s\n",
      "2889:\tlearn: 1.9691033\ttotal: 41.1s\tremaining: 24.3s\n",
      "2890:\tlearn: 1.9689130\ttotal: 41.1s\tremaining: 24.3s\n",
      "2891:\tlearn: 1.9685604\ttotal: 41.1s\tremaining: 24.3s\n",
      "2892:\tlearn: 1.9684663\ttotal: 41.1s\tremaining: 24.2s\n",
      "2893:\tlearn: 1.9683029\ttotal: 41.2s\tremaining: 24.2s\n",
      "2894:\tlearn: 1.9680053\ttotal: 41.2s\tremaining: 24.2s\n",
      "2895:\tlearn: 1.9678499\ttotal: 41.2s\tremaining: 24.2s\n",
      "2896:\tlearn: 1.9676377\ttotal: 41.2s\tremaining: 24.2s\n",
      "2897:\tlearn: 1.9670902\ttotal: 41.2s\tremaining: 24.2s\n",
      "2898:\tlearn: 1.9666233\ttotal: 41.2s\tremaining: 24.2s\n",
      "2899:\tlearn: 1.9661409\ttotal: 41.2s\tremaining: 24.1s\n",
      "2900:\tlearn: 1.9659587\ttotal: 41.3s\tremaining: 24.1s\n",
      "2901:\tlearn: 1.9656354\ttotal: 41.3s\tremaining: 24.1s\n",
      "2902:\tlearn: 1.9654021\ttotal: 41.3s\tremaining: 24.1s\n",
      "2903:\tlearn: 1.9652977\ttotal: 41.3s\tremaining: 24.1s\n",
      "2904:\tlearn: 1.9651483\ttotal: 41.3s\tremaining: 24.1s\n",
      "2905:\tlearn: 1.9647907\ttotal: 41.3s\tremaining: 24.1s\n",
      "2906:\tlearn: 1.9646224\ttotal: 41.4s\tremaining: 24.1s\n",
      "2907:\tlearn: 1.9638612\ttotal: 41.4s\tremaining: 24s\n",
      "2908:\tlearn: 1.9636263\ttotal: 41.4s\tremaining: 24s\n",
      "2909:\tlearn: 1.9633423\ttotal: 41.4s\tremaining: 24s\n",
      "2910:\tlearn: 1.9630572\ttotal: 41.4s\tremaining: 24s\n",
      "2911:\tlearn: 1.9625668\ttotal: 41.4s\tremaining: 24s\n",
      "2912:\tlearn: 1.9621516\ttotal: 41.4s\tremaining: 24s\n",
      "2913:\tlearn: 1.9618759\ttotal: 41.5s\tremaining: 24s\n",
      "2914:\tlearn: 1.9616679\ttotal: 41.5s\tremaining: 23.9s\n",
      "2915:\tlearn: 1.9614428\ttotal: 41.5s\tremaining: 23.9s\n",
      "2916:\tlearn: 1.9610263\ttotal: 41.5s\tremaining: 23.9s\n",
      "2917:\tlearn: 1.9604968\ttotal: 41.5s\tremaining: 23.9s\n",
      "2918:\tlearn: 1.9603907\ttotal: 41.5s\tremaining: 23.9s\n",
      "2919:\tlearn: 1.9601671\ttotal: 41.5s\tremaining: 23.9s\n",
      "2920:\tlearn: 1.9598293\ttotal: 41.6s\tremaining: 23.9s\n",
      "2921:\tlearn: 1.9592544\ttotal: 41.6s\tremaining: 23.8s\n",
      "2922:\tlearn: 1.9590388\ttotal: 41.6s\tremaining: 23.8s\n",
      "2923:\tlearn: 1.9583947\ttotal: 41.6s\tremaining: 23.8s\n",
      "2924:\tlearn: 1.9579941\ttotal: 41.6s\tremaining: 23.8s\n",
      "2925:\tlearn: 1.9577671\ttotal: 41.6s\tremaining: 23.8s\n",
      "2926:\tlearn: 1.9572104\ttotal: 41.6s\tremaining: 23.8s\n",
      "2927:\tlearn: 1.9570860\ttotal: 41.7s\tremaining: 23.8s\n",
      "2928:\tlearn: 1.9569492\ttotal: 41.7s\tremaining: 23.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2929:\tlearn: 1.9566581\ttotal: 41.7s\tremaining: 23.7s\n",
      "2930:\tlearn: 1.9564628\ttotal: 41.7s\tremaining: 23.7s\n",
      "2931:\tlearn: 1.9562525\ttotal: 41.7s\tremaining: 23.7s\n",
      "2932:\tlearn: 1.9557021\ttotal: 41.7s\tremaining: 23.7s\n",
      "2933:\tlearn: 1.9554512\ttotal: 41.8s\tremaining: 23.7s\n",
      "2934:\tlearn: 1.9550803\ttotal: 41.8s\tremaining: 23.7s\n",
      "2935:\tlearn: 1.9546743\ttotal: 41.8s\tremaining: 23.6s\n",
      "2936:\tlearn: 1.9545348\ttotal: 41.8s\tremaining: 23.6s\n",
      "2937:\tlearn: 1.9543633\ttotal: 41.8s\tremaining: 23.6s\n",
      "2938:\tlearn: 1.9538347\ttotal: 41.8s\tremaining: 23.6s\n",
      "2939:\tlearn: 1.9535084\ttotal: 41.8s\tremaining: 23.6s\n",
      "2940:\tlearn: 1.9528500\ttotal: 41.8s\tremaining: 23.6s\n",
      "2941:\tlearn: 1.9525735\ttotal: 41.9s\tremaining: 23.6s\n",
      "2942:\tlearn: 1.9523453\ttotal: 41.9s\tremaining: 23.6s\n",
      "2943:\tlearn: 1.9519722\ttotal: 41.9s\tremaining: 23.5s\n",
      "2944:\tlearn: 1.9516377\ttotal: 41.9s\tremaining: 23.5s\n",
      "2945:\tlearn: 1.9512668\ttotal: 41.9s\tremaining: 23.5s\n",
      "2946:\tlearn: 1.9509462\ttotal: 41.9s\tremaining: 23.5s\n",
      "2947:\tlearn: 1.9504771\ttotal: 42s\tremaining: 23.5s\n",
      "2948:\tlearn: 1.9502244\ttotal: 42s\tremaining: 23.5s\n",
      "2949:\tlearn: 1.9498529\ttotal: 42s\tremaining: 23.5s\n",
      "2950:\tlearn: 1.9496906\ttotal: 42s\tremaining: 23.4s\n",
      "2951:\tlearn: 1.9493117\ttotal: 42s\tremaining: 23.4s\n",
      "2952:\tlearn: 1.9490469\ttotal: 42s\tremaining: 23.4s\n",
      "2953:\tlearn: 1.9487574\ttotal: 42s\tremaining: 23.4s\n",
      "2954:\tlearn: 1.9485866\ttotal: 42s\tremaining: 23.4s\n",
      "2955:\tlearn: 1.9482624\ttotal: 42.1s\tremaining: 23.4s\n",
      "2956:\tlearn: 1.9478905\ttotal: 42.1s\tremaining: 23.4s\n",
      "2957:\tlearn: 1.9475789\ttotal: 42.1s\tremaining: 23.3s\n",
      "2958:\tlearn: 1.9472401\ttotal: 42.1s\tremaining: 23.3s\n",
      "2959:\tlearn: 1.9471699\ttotal: 42.1s\tremaining: 23.3s\n",
      "2960:\tlearn: 1.9469965\ttotal: 42.1s\tremaining: 23.3s\n",
      "2961:\tlearn: 1.9466067\ttotal: 42.1s\tremaining: 23.3s\n",
      "2962:\tlearn: 1.9463407\ttotal: 42.2s\tremaining: 23.3s\n",
      "2963:\tlearn: 1.9459388\ttotal: 42.2s\tremaining: 23.3s\n",
      "2964:\tlearn: 1.9455316\ttotal: 42.2s\tremaining: 23.2s\n",
      "2965:\tlearn: 1.9450879\ttotal: 42.2s\tremaining: 23.2s\n",
      "2966:\tlearn: 1.9447954\ttotal: 42.2s\tremaining: 23.2s\n",
      "2967:\tlearn: 1.9443997\ttotal: 42.2s\tremaining: 23.2s\n",
      "2968:\tlearn: 1.9441022\ttotal: 42.3s\tremaining: 23.2s\n",
      "2969:\tlearn: 1.9434723\ttotal: 42.3s\tremaining: 23.2s\n",
      "2970:\tlearn: 1.9434168\ttotal: 42.3s\tremaining: 23.2s\n",
      "2971:\tlearn: 1.9426734\ttotal: 42.3s\tremaining: 23.1s\n",
      "2972:\tlearn: 1.9423808\ttotal: 42.3s\tremaining: 23.1s\n",
      "2973:\tlearn: 1.9421820\ttotal: 42.3s\tremaining: 23.1s\n",
      "2974:\tlearn: 1.9419038\ttotal: 42.3s\tremaining: 23.1s\n",
      "2975:\tlearn: 1.9411589\ttotal: 42.4s\tremaining: 23.1s\n",
      "2976:\tlearn: 1.9408648\ttotal: 42.4s\tremaining: 23.1s\n",
      "2977:\tlearn: 1.9404190\ttotal: 42.4s\tremaining: 23.1s\n",
      "2978:\tlearn: 1.9400935\ttotal: 42.4s\tremaining: 23s\n",
      "2979:\tlearn: 1.9399335\ttotal: 42.4s\tremaining: 23s\n",
      "2980:\tlearn: 1.9396317\ttotal: 42.4s\tremaining: 23s\n",
      "2981:\tlearn: 1.9392502\ttotal: 42.4s\tremaining: 23s\n",
      "2982:\tlearn: 1.9391866\ttotal: 42.5s\tremaining: 23s\n",
      "2983:\tlearn: 1.9390715\ttotal: 42.5s\tremaining: 23s\n",
      "2984:\tlearn: 1.9386697\ttotal: 42.5s\tremaining: 23s\n",
      "2985:\tlearn: 1.9384264\ttotal: 42.5s\tremaining: 22.9s\n",
      "2986:\tlearn: 1.9381629\ttotal: 42.5s\tremaining: 22.9s\n",
      "2987:\tlearn: 1.9377715\ttotal: 42.5s\tremaining: 22.9s\n",
      "2988:\tlearn: 1.9376163\ttotal: 42.5s\tremaining: 22.9s\n",
      "2989:\tlearn: 1.9373362\ttotal: 42.6s\tremaining: 22.9s\n",
      "2990:\tlearn: 1.9371830\ttotal: 42.6s\tremaining: 22.9s\n",
      "2991:\tlearn: 1.9369399\ttotal: 42.6s\tremaining: 22.9s\n",
      "2992:\tlearn: 1.9364833\ttotal: 42.6s\tremaining: 22.8s\n",
      "2993:\tlearn: 1.9364520\ttotal: 42.6s\tremaining: 22.8s\n",
      "2994:\tlearn: 1.9363794\ttotal: 42.6s\tremaining: 22.8s\n",
      "2995:\tlearn: 1.9358448\ttotal: 42.6s\tremaining: 22.8s\n",
      "2996:\tlearn: 1.9355603\ttotal: 42.7s\tremaining: 22.8s\n",
      "2997:\tlearn: 1.9353225\ttotal: 42.7s\tremaining: 22.8s\n",
      "2998:\tlearn: 1.9350843\ttotal: 42.7s\tremaining: 22.8s\n",
      "2999:\tlearn: 1.9350312\ttotal: 42.7s\tremaining: 22.7s\n",
      "3000:\tlearn: 1.9348494\ttotal: 42.7s\tremaining: 22.7s\n",
      "3001:\tlearn: 1.9347109\ttotal: 42.7s\tremaining: 22.7s\n",
      "3002:\tlearn: 1.9342961\ttotal: 42.7s\tremaining: 22.7s\n",
      "3003:\tlearn: 1.9340605\ttotal: 42.8s\tremaining: 22.7s\n",
      "3004:\tlearn: 1.9338029\ttotal: 42.8s\tremaining: 22.7s\n",
      "3005:\tlearn: 1.9336408\ttotal: 42.8s\tremaining: 22.7s\n",
      "3006:\tlearn: 1.9334495\ttotal: 42.8s\tremaining: 22.6s\n",
      "3007:\tlearn: 1.9332224\ttotal: 42.8s\tremaining: 22.6s\n",
      "3008:\tlearn: 1.9330253\ttotal: 42.8s\tremaining: 22.6s\n",
      "3009:\tlearn: 1.9326000\ttotal: 42.8s\tremaining: 22.6s\n",
      "3010:\tlearn: 1.9322816\ttotal: 42.9s\tremaining: 22.6s\n",
      "3011:\tlearn: 1.9319642\ttotal: 42.9s\tremaining: 22.6s\n",
      "3012:\tlearn: 1.9315060\ttotal: 42.9s\tremaining: 22.6s\n",
      "3013:\tlearn: 1.9312780\ttotal: 42.9s\tremaining: 22.5s\n",
      "3014:\tlearn: 1.9311290\ttotal: 42.9s\tremaining: 22.5s\n",
      "3015:\tlearn: 1.9308209\ttotal: 42.9s\tremaining: 22.5s\n",
      "3016:\tlearn: 1.9305496\ttotal: 42.9s\tremaining: 22.5s\n",
      "3017:\tlearn: 1.9303154\ttotal: 43s\tremaining: 22.5s\n",
      "3018:\tlearn: 1.9301876\ttotal: 43s\tremaining: 22.5s\n",
      "3019:\tlearn: 1.9299529\ttotal: 43s\tremaining: 22.5s\n",
      "3020:\tlearn: 1.9295490\ttotal: 43s\tremaining: 22.4s\n",
      "3021:\tlearn: 1.9291608\ttotal: 43s\tremaining: 22.4s\n",
      "3022:\tlearn: 1.9288396\ttotal: 43s\tremaining: 22.4s\n",
      "3023:\tlearn: 1.9283788\ttotal: 43s\tremaining: 22.4s\n",
      "3024:\tlearn: 1.9281451\ttotal: 43.1s\tremaining: 22.4s\n",
      "3025:\tlearn: 1.9275262\ttotal: 43.1s\tremaining: 22.4s\n",
      "3026:\tlearn: 1.9271099\ttotal: 43.1s\tremaining: 22.4s\n",
      "3027:\tlearn: 1.9266673\ttotal: 43.1s\tremaining: 22.3s\n",
      "3028:\tlearn: 1.9260891\ttotal: 43.1s\tremaining: 22.3s\n",
      "3029:\tlearn: 1.9258361\ttotal: 43.1s\tremaining: 22.3s\n",
      "3030:\tlearn: 1.9256448\ttotal: 43.1s\tremaining: 22.3s\n",
      "3031:\tlearn: 1.9254913\ttotal: 43.2s\tremaining: 22.3s\n",
      "3032:\tlearn: 1.9251268\ttotal: 43.2s\tremaining: 22.3s\n",
      "3033:\tlearn: 1.9250131\ttotal: 43.2s\tremaining: 22.3s\n",
      "3034:\tlearn: 1.9248335\ttotal: 43.2s\tremaining: 22.2s\n",
      "3035:\tlearn: 1.9246180\ttotal: 43.2s\tremaining: 22.2s\n",
      "3036:\tlearn: 1.9243025\ttotal: 43.2s\tremaining: 22.2s\n",
      "3037:\tlearn: 1.9240192\ttotal: 43.2s\tremaining: 22.2s\n",
      "3038:\tlearn: 1.9237948\ttotal: 43.3s\tremaining: 22.2s\n",
      "3039:\tlearn: 1.9235468\ttotal: 43.3s\tremaining: 22.2s\n",
      "3040:\tlearn: 1.9231386\ttotal: 43.3s\tremaining: 22.2s\n",
      "3041:\tlearn: 1.9228962\ttotal: 43.3s\tremaining: 22.1s\n",
      "3042:\tlearn: 1.9226009\ttotal: 43.3s\tremaining: 22.1s\n",
      "3043:\tlearn: 1.9223678\ttotal: 43.3s\tremaining: 22.1s\n",
      "3044:\tlearn: 1.9221682\ttotal: 43.3s\tremaining: 22.1s\n",
      "3045:\tlearn: 1.9217211\ttotal: 43.4s\tremaining: 22.1s\n",
      "3046:\tlearn: 1.9215556\ttotal: 43.4s\tremaining: 22.1s\n",
      "3047:\tlearn: 1.9211845\ttotal: 43.4s\tremaining: 22.1s\n",
      "3048:\tlearn: 1.9208953\ttotal: 43.4s\tremaining: 22s\n",
      "3049:\tlearn: 1.9207560\ttotal: 43.4s\tremaining: 22s\n",
      "3050:\tlearn: 1.9204848\ttotal: 43.4s\tremaining: 22s\n",
      "3051:\tlearn: 1.9203414\ttotal: 43.4s\tremaining: 22s\n",
      "3052:\tlearn: 1.9200256\ttotal: 43.5s\tremaining: 22s\n",
      "3053:\tlearn: 1.9198746\ttotal: 43.5s\tremaining: 22s\n",
      "3054:\tlearn: 1.9196043\ttotal: 43.5s\tremaining: 22s\n",
      "3055:\tlearn: 1.9191486\ttotal: 43.5s\tremaining: 21.9s\n",
      "3056:\tlearn: 1.9187334\ttotal: 43.5s\tremaining: 21.9s\n",
      "3057:\tlearn: 1.9186060\ttotal: 43.5s\tremaining: 21.9s\n",
      "3058:\tlearn: 1.9183208\ttotal: 43.5s\tremaining: 21.9s\n",
      "3059:\tlearn: 1.9179720\ttotal: 43.6s\tremaining: 21.9s\n",
      "3060:\tlearn: 1.9177905\ttotal: 43.6s\tremaining: 21.9s\n",
      "3061:\tlearn: 1.9175189\ttotal: 43.6s\tremaining: 21.9s\n",
      "3062:\tlearn: 1.9169784\ttotal: 43.6s\tremaining: 21.8s\n",
      "3063:\tlearn: 1.9167447\ttotal: 43.6s\tremaining: 21.8s\n",
      "3064:\tlearn: 1.9165610\ttotal: 43.6s\tremaining: 21.8s\n",
      "3065:\tlearn: 1.9162375\ttotal: 43.6s\tremaining: 21.8s\n",
      "3066:\tlearn: 1.9160636\ttotal: 43.7s\tremaining: 21.8s\n",
      "3067:\tlearn: 1.9158854\ttotal: 43.7s\tremaining: 21.8s\n",
      "3068:\tlearn: 1.9156481\ttotal: 43.7s\tremaining: 21.8s\n",
      "3069:\tlearn: 1.9153619\ttotal: 43.7s\tremaining: 21.8s\n",
      "3070:\tlearn: 1.9150900\ttotal: 43.7s\tremaining: 21.7s\n",
      "3071:\tlearn: 1.9149569\ttotal: 43.7s\tremaining: 21.7s\n",
      "3072:\tlearn: 1.9148748\ttotal: 43.7s\tremaining: 21.7s\n",
      "3073:\tlearn: 1.9146137\ttotal: 43.8s\tremaining: 21.7s\n",
      "3074:\tlearn: 1.9142121\ttotal: 43.8s\tremaining: 21.7s\n",
      "3075:\tlearn: 1.9139562\ttotal: 43.8s\tremaining: 21.7s\n",
      "3076:\tlearn: 1.9136343\ttotal: 43.8s\tremaining: 21.7s\n",
      "3077:\tlearn: 1.9134982\ttotal: 43.8s\tremaining: 21.6s\n",
      "3078:\tlearn: 1.9134166\ttotal: 43.8s\tremaining: 21.6s\n",
      "3079:\tlearn: 1.9132137\ttotal: 43.8s\tremaining: 21.6s\n",
      "3080:\tlearn: 1.9130418\ttotal: 43.9s\tremaining: 21.6s\n",
      "3081:\tlearn: 1.9129045\ttotal: 43.9s\tremaining: 21.6s\n",
      "3082:\tlearn: 1.9122101\ttotal: 43.9s\tremaining: 21.6s\n",
      "3083:\tlearn: 1.9119183\ttotal: 43.9s\tremaining: 21.6s\n",
      "3084:\tlearn: 1.9117208\ttotal: 43.9s\tremaining: 21.5s\n",
      "3085:\tlearn: 1.9114875\ttotal: 43.9s\tremaining: 21.5s\n",
      "3086:\tlearn: 1.9113176\ttotal: 43.9s\tremaining: 21.5s\n",
      "3087:\tlearn: 1.9108136\ttotal: 44s\tremaining: 21.5s\n",
      "3088:\tlearn: 1.9106482\ttotal: 44s\tremaining: 21.5s\n",
      "3089:\tlearn: 1.9101642\ttotal: 44s\tremaining: 21.5s\n",
      "3090:\tlearn: 1.9098615\ttotal: 44s\tremaining: 21.5s\n",
      "3091:\tlearn: 1.9097429\ttotal: 44s\tremaining: 21.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3092:\tlearn: 1.9094117\ttotal: 44s\tremaining: 21.4s\n",
      "3093:\tlearn: 1.9091675\ttotal: 44.1s\tremaining: 21.4s\n",
      "3094:\tlearn: 1.9089419\ttotal: 44.1s\tremaining: 21.4s\n",
      "3095:\tlearn: 1.9085364\ttotal: 44.1s\tremaining: 21.4s\n",
      "3096:\tlearn: 1.9083373\ttotal: 44.1s\tremaining: 21.4s\n",
      "3097:\tlearn: 1.9079818\ttotal: 44.1s\tremaining: 21.4s\n",
      "3098:\tlearn: 1.9076183\ttotal: 44.1s\tremaining: 21.3s\n",
      "3099:\tlearn: 1.9069821\ttotal: 44.1s\tremaining: 21.3s\n",
      "3100:\tlearn: 1.9066485\ttotal: 44.2s\tremaining: 21.3s\n",
      "3101:\tlearn: 1.9063111\ttotal: 44.2s\tremaining: 21.3s\n",
      "3102:\tlearn: 1.9060828\ttotal: 44.2s\tremaining: 21.3s\n",
      "3103:\tlearn: 1.9055980\ttotal: 44.2s\tremaining: 21.3s\n",
      "3104:\tlearn: 1.9051985\ttotal: 44.2s\tremaining: 21.3s\n",
      "3105:\tlearn: 1.9048878\ttotal: 44.2s\tremaining: 21.2s\n",
      "3106:\tlearn: 1.9046916\ttotal: 44.2s\tremaining: 21.2s\n",
      "3107:\tlearn: 1.9043730\ttotal: 44.3s\tremaining: 21.2s\n",
      "3108:\tlearn: 1.9042570\ttotal: 44.3s\tremaining: 21.2s\n",
      "3109:\tlearn: 1.9038414\ttotal: 44.3s\tremaining: 21.2s\n",
      "3110:\tlearn: 1.9037472\ttotal: 44.3s\tremaining: 21.2s\n",
      "3111:\tlearn: 1.9034920\ttotal: 44.3s\tremaining: 21.2s\n",
      "3112:\tlearn: 1.9032884\ttotal: 44.3s\tremaining: 21.1s\n",
      "3113:\tlearn: 1.9029667\ttotal: 44.3s\tremaining: 21.1s\n",
      "3114:\tlearn: 1.9027917\ttotal: 44.4s\tremaining: 21.1s\n",
      "3115:\tlearn: 1.9024915\ttotal: 44.4s\tremaining: 21.1s\n",
      "3116:\tlearn: 1.9022969\ttotal: 44.4s\tremaining: 21.1s\n",
      "3117:\tlearn: 1.9022049\ttotal: 44.4s\tremaining: 21.1s\n",
      "3118:\tlearn: 1.9018900\ttotal: 44.4s\tremaining: 21.1s\n",
      "3119:\tlearn: 1.9013999\ttotal: 44.4s\tremaining: 21s\n",
      "3120:\tlearn: 1.9009975\ttotal: 44.4s\tremaining: 21s\n",
      "3121:\tlearn: 1.9007554\ttotal: 44.5s\tremaining: 21s\n",
      "3122:\tlearn: 1.9005347\ttotal: 44.5s\tremaining: 21s\n",
      "3123:\tlearn: 1.9002772\ttotal: 44.5s\tremaining: 21s\n",
      "3124:\tlearn: 1.9000691\ttotal: 44.5s\tremaining: 21s\n",
      "3125:\tlearn: 1.8998414\ttotal: 44.5s\tremaining: 21s\n",
      "3126:\tlearn: 1.8995189\ttotal: 44.5s\tremaining: 20.9s\n",
      "3127:\tlearn: 1.8993410\ttotal: 44.5s\tremaining: 20.9s\n",
      "3128:\tlearn: 1.8992203\ttotal: 44.6s\tremaining: 20.9s\n",
      "3129:\tlearn: 1.8988152\ttotal: 44.6s\tremaining: 20.9s\n",
      "3130:\tlearn: 1.8987555\ttotal: 44.6s\tremaining: 20.9s\n",
      "3131:\tlearn: 1.8983148\ttotal: 44.6s\tremaining: 20.9s\n",
      "3132:\tlearn: 1.8981875\ttotal: 44.6s\tremaining: 20.9s\n",
      "3133:\tlearn: 1.8980155\ttotal: 44.6s\tremaining: 20.8s\n",
      "3134:\tlearn: 1.8977874\ttotal: 44.6s\tremaining: 20.8s\n",
      "3135:\tlearn: 1.8977312\ttotal: 44.6s\tremaining: 20.8s\n",
      "3136:\tlearn: 1.8975466\ttotal: 44.7s\tremaining: 20.8s\n",
      "3137:\tlearn: 1.8972324\ttotal: 44.7s\tremaining: 20.8s\n",
      "3138:\tlearn: 1.8971298\ttotal: 44.7s\tremaining: 20.8s\n",
      "3139:\tlearn: 1.8969024\ttotal: 44.7s\tremaining: 20.8s\n",
      "3140:\tlearn: 1.8962607\ttotal: 44.7s\tremaining: 20.7s\n",
      "3141:\tlearn: 1.8958308\ttotal: 44.7s\tremaining: 20.7s\n",
      "3142:\tlearn: 1.8955586\ttotal: 44.7s\tremaining: 20.7s\n",
      "3143:\tlearn: 1.8953682\ttotal: 44.8s\tremaining: 20.7s\n",
      "3144:\tlearn: 1.8951901\ttotal: 44.8s\tremaining: 20.7s\n",
      "3145:\tlearn: 1.8947937\ttotal: 44.8s\tremaining: 20.7s\n",
      "3146:\tlearn: 1.8943476\ttotal: 44.8s\tremaining: 20.7s\n",
      "3147:\tlearn: 1.8939469\ttotal: 44.8s\tremaining: 20.6s\n",
      "3148:\tlearn: 1.8938361\ttotal: 44.8s\tremaining: 20.6s\n",
      "3149:\tlearn: 1.8935633\ttotal: 44.8s\tremaining: 20.6s\n",
      "3150:\tlearn: 1.8932386\ttotal: 44.9s\tremaining: 20.6s\n",
      "3151:\tlearn: 1.8929449\ttotal: 44.9s\tremaining: 20.6s\n",
      "3152:\tlearn: 1.8924141\ttotal: 44.9s\tremaining: 20.6s\n",
      "3153:\tlearn: 1.8921350\ttotal: 44.9s\tremaining: 20.6s\n",
      "3154:\tlearn: 1.8918485\ttotal: 44.9s\tremaining: 20.5s\n",
      "3155:\tlearn: 1.8917092\ttotal: 44.9s\tremaining: 20.5s\n",
      "3156:\tlearn: 1.8915297\ttotal: 44.9s\tremaining: 20.5s\n",
      "3157:\tlearn: 1.8913046\ttotal: 45s\tremaining: 20.5s\n",
      "3158:\tlearn: 1.8912404\ttotal: 45s\tremaining: 20.5s\n",
      "3159:\tlearn: 1.8910785\ttotal: 45s\tremaining: 20.5s\n",
      "3160:\tlearn: 1.8908646\ttotal: 45s\tremaining: 20.5s\n",
      "3161:\tlearn: 1.8907004\ttotal: 45s\tremaining: 20.4s\n",
      "3162:\tlearn: 1.8901124\ttotal: 45s\tremaining: 20.4s\n",
      "3163:\tlearn: 1.8898058\ttotal: 45s\tremaining: 20.4s\n",
      "3164:\tlearn: 1.8894629\ttotal: 45.1s\tremaining: 20.4s\n",
      "3165:\tlearn: 1.8893314\ttotal: 45.1s\tremaining: 20.4s\n",
      "3166:\tlearn: 1.8889417\ttotal: 45.1s\tremaining: 20.4s\n",
      "3167:\tlearn: 1.8885259\ttotal: 45.1s\tremaining: 20.4s\n",
      "3168:\tlearn: 1.8883254\ttotal: 45.1s\tremaining: 20.3s\n",
      "3169:\tlearn: 1.8879847\ttotal: 45.1s\tremaining: 20.3s\n",
      "3170:\tlearn: 1.8877018\ttotal: 45.2s\tremaining: 20.3s\n",
      "3171:\tlearn: 1.8874900\ttotal: 45.2s\tremaining: 20.3s\n",
      "3172:\tlearn: 1.8870637\ttotal: 45.2s\tremaining: 20.3s\n",
      "3173:\tlearn: 1.8867478\ttotal: 45.2s\tremaining: 20.3s\n",
      "3174:\tlearn: 1.8863344\ttotal: 45.2s\tremaining: 20.3s\n",
      "3175:\tlearn: 1.8859631\ttotal: 45.2s\tremaining: 20.2s\n",
      "3176:\tlearn: 1.8857253\ttotal: 45.2s\tremaining: 20.2s\n",
      "3177:\tlearn: 1.8853093\ttotal: 45.3s\tremaining: 20.2s\n",
      "3178:\tlearn: 1.8850808\ttotal: 45.3s\tremaining: 20.2s\n",
      "3179:\tlearn: 1.8848744\ttotal: 45.3s\tremaining: 20.2s\n",
      "3180:\tlearn: 1.8846620\ttotal: 45.3s\tremaining: 20.2s\n",
      "3181:\tlearn: 1.8842640\ttotal: 45.3s\tremaining: 20.2s\n",
      "3182:\tlearn: 1.8840370\ttotal: 45.3s\tremaining: 20.2s\n",
      "3183:\tlearn: 1.8837430\ttotal: 45.3s\tremaining: 20.1s\n",
      "3184:\tlearn: 1.8833795\ttotal: 45.4s\tremaining: 20.1s\n",
      "3185:\tlearn: 1.8829963\ttotal: 45.4s\tremaining: 20.1s\n",
      "3186:\tlearn: 1.8826370\ttotal: 45.4s\tremaining: 20.1s\n",
      "3187:\tlearn: 1.8825872\ttotal: 45.4s\tremaining: 20.1s\n",
      "3188:\tlearn: 1.8823246\ttotal: 45.4s\tremaining: 20.1s\n",
      "3189:\tlearn: 1.8822072\ttotal: 45.4s\tremaining: 20.1s\n",
      "3190:\tlearn: 1.8817920\ttotal: 45.4s\tremaining: 20s\n",
      "3191:\tlearn: 1.8815979\ttotal: 45.5s\tremaining: 20s\n",
      "3192:\tlearn: 1.8812683\ttotal: 45.5s\tremaining: 20s\n",
      "3193:\tlearn: 1.8807740\ttotal: 45.5s\tremaining: 20s\n",
      "3194:\tlearn: 1.8806243\ttotal: 45.5s\tremaining: 20s\n",
      "3195:\tlearn: 1.8803500\ttotal: 45.5s\tremaining: 20s\n",
      "3196:\tlearn: 1.8801929\ttotal: 45.5s\tremaining: 20s\n",
      "3197:\tlearn: 1.8798358\ttotal: 45.6s\tremaining: 19.9s\n",
      "3198:\tlearn: 1.8794670\ttotal: 45.6s\tremaining: 19.9s\n",
      "3199:\tlearn: 1.8791035\ttotal: 45.6s\tremaining: 19.9s\n",
      "3200:\tlearn: 1.8787802\ttotal: 45.6s\tremaining: 19.9s\n",
      "3201:\tlearn: 1.8786071\ttotal: 45.6s\tremaining: 19.9s\n",
      "3202:\tlearn: 1.8783184\ttotal: 45.6s\tremaining: 19.9s\n",
      "3203:\tlearn: 1.8779523\ttotal: 45.6s\tremaining: 19.9s\n",
      "3204:\tlearn: 1.8779215\ttotal: 45.7s\tremaining: 19.8s\n",
      "3205:\tlearn: 1.8777740\ttotal: 45.7s\tremaining: 19.8s\n",
      "3206:\tlearn: 1.8775513\ttotal: 45.7s\tremaining: 19.8s\n",
      "3207:\tlearn: 1.8772901\ttotal: 45.7s\tremaining: 19.8s\n",
      "3208:\tlearn: 1.8770330\ttotal: 45.7s\tremaining: 19.8s\n",
      "3209:\tlearn: 1.8768886\ttotal: 45.7s\tremaining: 19.8s\n",
      "3210:\tlearn: 1.8767173\ttotal: 45.7s\tremaining: 19.8s\n",
      "3211:\tlearn: 1.8763379\ttotal: 45.8s\tremaining: 19.7s\n",
      "3212:\tlearn: 1.8756486\ttotal: 45.8s\tremaining: 19.7s\n",
      "3213:\tlearn: 1.8752997\ttotal: 45.8s\tremaining: 19.7s\n",
      "3214:\tlearn: 1.8748714\ttotal: 45.8s\tremaining: 19.7s\n",
      "3215:\tlearn: 1.8745076\ttotal: 45.8s\tremaining: 19.7s\n",
      "3216:\tlearn: 1.8744631\ttotal: 45.8s\tremaining: 19.7s\n",
      "3217:\tlearn: 1.8738788\ttotal: 45.8s\tremaining: 19.7s\n",
      "3218:\tlearn: 1.8736110\ttotal: 45.9s\tremaining: 19.6s\n",
      "3219:\tlearn: 1.8732926\ttotal: 45.9s\tremaining: 19.6s\n",
      "3220:\tlearn: 1.8732562\ttotal: 45.9s\tremaining: 19.6s\n",
      "3221:\tlearn: 1.8730807\ttotal: 45.9s\tremaining: 19.6s\n",
      "3222:\tlearn: 1.8728368\ttotal: 45.9s\tremaining: 19.6s\n",
      "3223:\tlearn: 1.8725979\ttotal: 45.9s\tremaining: 19.6s\n",
      "3224:\tlearn: 1.8723350\ttotal: 45.9s\tremaining: 19.6s\n",
      "3225:\tlearn: 1.8719701\ttotal: 46s\tremaining: 19.5s\n",
      "3226:\tlearn: 1.8719068\ttotal: 46s\tremaining: 19.5s\n",
      "3227:\tlearn: 1.8717009\ttotal: 46s\tremaining: 19.5s\n",
      "3228:\tlearn: 1.8716444\ttotal: 46s\tremaining: 19.5s\n",
      "3229:\tlearn: 1.8712954\ttotal: 46s\tremaining: 19.5s\n",
      "3230:\tlearn: 1.8709698\ttotal: 46s\tremaining: 19.5s\n",
      "3231:\tlearn: 1.8706509\ttotal: 46s\tremaining: 19.5s\n",
      "3232:\tlearn: 1.8703805\ttotal: 46s\tremaining: 19.4s\n",
      "3233:\tlearn: 1.8699114\ttotal: 46.1s\tremaining: 19.4s\n",
      "3234:\tlearn: 1.8697247\ttotal: 46.1s\tremaining: 19.4s\n",
      "3235:\tlearn: 1.8693948\ttotal: 46.1s\tremaining: 19.4s\n",
      "3236:\tlearn: 1.8691983\ttotal: 46.1s\tremaining: 19.4s\n",
      "3237:\tlearn: 1.8688960\ttotal: 46.1s\tremaining: 19.4s\n",
      "3238:\tlearn: 1.8686836\ttotal: 46.1s\tremaining: 19.4s\n",
      "3239:\tlearn: 1.8685400\ttotal: 46.1s\tremaining: 19.3s\n",
      "3240:\tlearn: 1.8681845\ttotal: 46.2s\tremaining: 19.3s\n",
      "3241:\tlearn: 1.8677873\ttotal: 46.2s\tremaining: 19.3s\n",
      "3242:\tlearn: 1.8672695\ttotal: 46.2s\tremaining: 19.3s\n",
      "3243:\tlearn: 1.8668365\ttotal: 46.2s\tremaining: 19.3s\n",
      "3244:\tlearn: 1.8666384\ttotal: 46.2s\tremaining: 19.3s\n",
      "3245:\tlearn: 1.8664114\ttotal: 46.2s\tremaining: 19.3s\n",
      "3246:\tlearn: 1.8659880\ttotal: 46.3s\tremaining: 19.2s\n",
      "3247:\tlearn: 1.8657407\ttotal: 46.3s\tremaining: 19.2s\n",
      "3248:\tlearn: 1.8654926\ttotal: 46.3s\tremaining: 19.2s\n",
      "3249:\tlearn: 1.8653675\ttotal: 46.3s\tremaining: 19.2s\n",
      "3250:\tlearn: 1.8650720\ttotal: 46.3s\tremaining: 19.2s\n",
      "3251:\tlearn: 1.8648047\ttotal: 46.3s\tremaining: 19.2s\n",
      "3252:\tlearn: 1.8645747\ttotal: 46.3s\tremaining: 19.2s\n",
      "3253:\tlearn: 1.8640411\ttotal: 46.4s\tremaining: 19.1s\n",
      "3254:\tlearn: 1.8638957\ttotal: 46.4s\tremaining: 19.1s\n",
      "3255:\tlearn: 1.8634601\ttotal: 46.4s\tremaining: 19.1s\n",
      "3256:\tlearn: 1.8632054\ttotal: 46.4s\tremaining: 19.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3257:\tlearn: 1.8629157\ttotal: 46.4s\tremaining: 19.1s\n",
      "3258:\tlearn: 1.8626560\ttotal: 46.4s\tremaining: 19.1s\n",
      "3259:\tlearn: 1.8620611\ttotal: 46.4s\tremaining: 19.1s\n",
      "3260:\tlearn: 1.8618641\ttotal: 46.5s\tremaining: 19s\n",
      "3261:\tlearn: 1.8615655\ttotal: 46.5s\tremaining: 19s\n",
      "3262:\tlearn: 1.8614048\ttotal: 46.5s\tremaining: 19s\n",
      "3263:\tlearn: 1.8612564\ttotal: 46.5s\tremaining: 19s\n",
      "3264:\tlearn: 1.8611127\ttotal: 46.5s\tremaining: 19s\n",
      "3265:\tlearn: 1.8608737\ttotal: 46.5s\tremaining: 19s\n",
      "3266:\tlearn: 1.8607665\ttotal: 46.5s\tremaining: 19s\n",
      "3267:\tlearn: 1.8604928\ttotal: 46.5s\tremaining: 18.9s\n",
      "3268:\tlearn: 1.8604272\ttotal: 46.6s\tremaining: 18.9s\n",
      "3269:\tlearn: 1.8601223\ttotal: 46.6s\tremaining: 18.9s\n",
      "3270:\tlearn: 1.8598494\ttotal: 46.6s\tremaining: 18.9s\n",
      "3271:\tlearn: 1.8596700\ttotal: 46.6s\tremaining: 18.9s\n",
      "3272:\tlearn: 1.8591746\ttotal: 46.6s\tremaining: 18.9s\n",
      "3273:\tlearn: 1.8589800\ttotal: 46.6s\tremaining: 18.9s\n",
      "3274:\tlearn: 1.8584714\ttotal: 46.7s\tremaining: 18.8s\n",
      "3275:\tlearn: 1.8582174\ttotal: 46.7s\tremaining: 18.8s\n",
      "3276:\tlearn: 1.8578437\ttotal: 46.7s\tremaining: 18.8s\n",
      "3277:\tlearn: 1.8575198\ttotal: 46.7s\tremaining: 18.8s\n",
      "3278:\tlearn: 1.8573313\ttotal: 46.7s\tremaining: 18.8s\n",
      "3279:\tlearn: 1.8569782\ttotal: 46.7s\tremaining: 18.8s\n",
      "3280:\tlearn: 1.8567689\ttotal: 46.7s\tremaining: 18.8s\n",
      "3281:\tlearn: 1.8564965\ttotal: 46.8s\tremaining: 18.7s\n",
      "3282:\tlearn: 1.8562397\ttotal: 46.8s\tremaining: 18.7s\n",
      "3283:\tlearn: 1.8560793\ttotal: 46.8s\tremaining: 18.7s\n",
      "3284:\tlearn: 1.8558814\ttotal: 46.8s\tremaining: 18.7s\n",
      "3285:\tlearn: 1.8555476\ttotal: 46.8s\tremaining: 18.7s\n",
      "3286:\tlearn: 1.8551991\ttotal: 46.8s\tremaining: 18.7s\n",
      "3287:\tlearn: 1.8547992\ttotal: 46.8s\tremaining: 18.7s\n",
      "3288:\tlearn: 1.8545802\ttotal: 46.9s\tremaining: 18.6s\n",
      "3289:\tlearn: 1.8544427\ttotal: 46.9s\tremaining: 18.6s\n",
      "3290:\tlearn: 1.8543491\ttotal: 46.9s\tremaining: 18.6s\n",
      "3291:\tlearn: 1.8541831\ttotal: 46.9s\tremaining: 18.6s\n",
      "3292:\tlearn: 1.8540221\ttotal: 46.9s\tremaining: 18.6s\n",
      "3293:\tlearn: 1.8538119\ttotal: 46.9s\tremaining: 18.6s\n",
      "3294:\tlearn: 1.8535059\ttotal: 46.9s\tremaining: 18.6s\n",
      "3295:\tlearn: 1.8532982\ttotal: 46.9s\tremaining: 18.5s\n",
      "3296:\tlearn: 1.8529059\ttotal: 47s\tremaining: 18.5s\n",
      "3297:\tlearn: 1.8525146\ttotal: 47s\tremaining: 18.5s\n",
      "3298:\tlearn: 1.8522430\ttotal: 47s\tremaining: 18.5s\n",
      "3299:\tlearn: 1.8517199\ttotal: 47s\tremaining: 18.5s\n",
      "3300:\tlearn: 1.8515923\ttotal: 47s\tremaining: 18.5s\n",
      "3301:\tlearn: 1.8513898\ttotal: 47s\tremaining: 18.5s\n",
      "3302:\tlearn: 1.8508162\ttotal: 47s\tremaining: 18.4s\n",
      "3303:\tlearn: 1.8504826\ttotal: 47.1s\tremaining: 18.4s\n",
      "3304:\tlearn: 1.8500448\ttotal: 47.1s\tremaining: 18.4s\n",
      "3305:\tlearn: 1.8496256\ttotal: 47.1s\tremaining: 18.4s\n",
      "3306:\tlearn: 1.8494105\ttotal: 47.1s\tremaining: 18.4s\n",
      "3307:\tlearn: 1.8491681\ttotal: 47.1s\tremaining: 18.4s\n",
      "3308:\tlearn: 1.8489495\ttotal: 47.1s\tremaining: 18.4s\n",
      "3309:\tlearn: 1.8485514\ttotal: 47.1s\tremaining: 18.3s\n",
      "3310:\tlearn: 1.8482111\ttotal: 47.2s\tremaining: 18.3s\n",
      "3311:\tlearn: 1.8480905\ttotal: 47.2s\tremaining: 18.3s\n",
      "3312:\tlearn: 1.8478514\ttotal: 47.2s\tremaining: 18.3s\n",
      "3313:\tlearn: 1.8476653\ttotal: 47.2s\tremaining: 18.3s\n",
      "3314:\tlearn: 1.8473750\ttotal: 47.2s\tremaining: 18.3s\n",
      "3315:\tlearn: 1.8471867\ttotal: 47.2s\tremaining: 18.3s\n",
      "3316:\tlearn: 1.8469157\ttotal: 47.2s\tremaining: 18.2s\n",
      "3317:\tlearn: 1.8465813\ttotal: 47.3s\tremaining: 18.2s\n",
      "3318:\tlearn: 1.8463237\ttotal: 47.3s\tremaining: 18.2s\n",
      "3319:\tlearn: 1.8461537\ttotal: 47.3s\tremaining: 18.2s\n",
      "3320:\tlearn: 1.8459503\ttotal: 47.3s\tremaining: 18.2s\n",
      "3321:\tlearn: 1.8457784\ttotal: 47.3s\tremaining: 18.2s\n",
      "3322:\tlearn: 1.8455684\ttotal: 47.3s\tremaining: 18.2s\n",
      "3323:\tlearn: 1.8451486\ttotal: 47.4s\tremaining: 18.1s\n",
      "3324:\tlearn: 1.8449298\ttotal: 47.4s\tremaining: 18.1s\n",
      "3325:\tlearn: 1.8446767\ttotal: 47.4s\tremaining: 18.1s\n",
      "3326:\tlearn: 1.8443867\ttotal: 47.4s\tremaining: 18.1s\n",
      "3327:\tlearn: 1.8441299\ttotal: 47.4s\tremaining: 18.1s\n",
      "3328:\tlearn: 1.8438796\ttotal: 47.4s\tremaining: 18.1s\n",
      "3329:\tlearn: 1.8435494\ttotal: 47.4s\tremaining: 18.1s\n",
      "3330:\tlearn: 1.8434083\ttotal: 47.4s\tremaining: 18s\n",
      "3331:\tlearn: 1.8432784\ttotal: 47.5s\tremaining: 18s\n",
      "3332:\tlearn: 1.8430549\ttotal: 47.5s\tremaining: 18s\n",
      "3333:\tlearn: 1.8428320\ttotal: 47.5s\tremaining: 18s\n",
      "3334:\tlearn: 1.8425473\ttotal: 47.5s\tremaining: 18s\n",
      "3335:\tlearn: 1.8421199\ttotal: 47.5s\tremaining: 18s\n",
      "3336:\tlearn: 1.8418068\ttotal: 47.5s\tremaining: 18s\n",
      "3337:\tlearn: 1.8415438\ttotal: 47.6s\tremaining: 17.9s\n",
      "3338:\tlearn: 1.8413477\ttotal: 47.6s\tremaining: 17.9s\n",
      "3339:\tlearn: 1.8410830\ttotal: 47.6s\tremaining: 17.9s\n",
      "3340:\tlearn: 1.8407000\ttotal: 47.6s\tremaining: 17.9s\n",
      "3341:\tlearn: 1.8403951\ttotal: 47.6s\tremaining: 17.9s\n",
      "3342:\tlearn: 1.8401017\ttotal: 47.6s\tremaining: 17.9s\n",
      "3343:\tlearn: 1.8397390\ttotal: 47.6s\tremaining: 17.9s\n",
      "3344:\tlearn: 1.8395769\ttotal: 47.7s\tremaining: 17.9s\n",
      "3345:\tlearn: 1.8393195\ttotal: 47.7s\tremaining: 17.8s\n",
      "3346:\tlearn: 1.8390766\ttotal: 47.7s\tremaining: 17.8s\n",
      "3347:\tlearn: 1.8388715\ttotal: 47.7s\tremaining: 17.8s\n",
      "3348:\tlearn: 1.8386978\ttotal: 47.7s\tremaining: 17.8s\n",
      "3349:\tlearn: 1.8384709\ttotal: 47.7s\tremaining: 17.8s\n",
      "3350:\tlearn: 1.8382429\ttotal: 47.7s\tremaining: 17.8s\n",
      "3351:\tlearn: 1.8380018\ttotal: 47.8s\tremaining: 17.8s\n",
      "3352:\tlearn: 1.8377914\ttotal: 47.8s\tremaining: 17.7s\n",
      "3353:\tlearn: 1.8375474\ttotal: 47.8s\tremaining: 17.7s\n",
      "3354:\tlearn: 1.8373919\ttotal: 47.8s\tremaining: 17.7s\n",
      "3355:\tlearn: 1.8371925\ttotal: 47.8s\tremaining: 17.7s\n",
      "3356:\tlearn: 1.8370016\ttotal: 47.8s\tremaining: 17.7s\n",
      "3357:\tlearn: 1.8366752\ttotal: 47.8s\tremaining: 17.7s\n",
      "3358:\tlearn: 1.8362933\ttotal: 47.9s\tremaining: 17.7s\n",
      "3359:\tlearn: 1.8360229\ttotal: 47.9s\tremaining: 17.6s\n",
      "3360:\tlearn: 1.8358523\ttotal: 47.9s\tremaining: 17.6s\n",
      "3361:\tlearn: 1.8355084\ttotal: 47.9s\tremaining: 17.6s\n",
      "3362:\tlearn: 1.8352131\ttotal: 47.9s\tremaining: 17.6s\n",
      "3363:\tlearn: 1.8350441\ttotal: 47.9s\tremaining: 17.6s\n",
      "3364:\tlearn: 1.8346354\ttotal: 47.9s\tremaining: 17.6s\n",
      "3365:\tlearn: 1.8344605\ttotal: 48s\tremaining: 17.6s\n",
      "3366:\tlearn: 1.8343125\ttotal: 48s\tremaining: 17.5s\n",
      "3367:\tlearn: 1.8340868\ttotal: 48s\tremaining: 17.5s\n",
      "3368:\tlearn: 1.8337996\ttotal: 48s\tremaining: 17.5s\n",
      "3369:\tlearn: 1.8335350\ttotal: 48s\tremaining: 17.5s\n",
      "3370:\tlearn: 1.8333569\ttotal: 48s\tremaining: 17.5s\n",
      "3371:\tlearn: 1.8330378\ttotal: 48s\tremaining: 17.5s\n",
      "3372:\tlearn: 1.8328770\ttotal: 48.1s\tremaining: 17.5s\n",
      "3373:\tlearn: 1.8326605\ttotal: 48.1s\tremaining: 17.4s\n",
      "3374:\tlearn: 1.8323487\ttotal: 48.1s\tremaining: 17.4s\n",
      "3375:\tlearn: 1.8318461\ttotal: 48.1s\tremaining: 17.4s\n",
      "3376:\tlearn: 1.8317582\ttotal: 48.1s\tremaining: 17.4s\n",
      "3377:\tlearn: 1.8313586\ttotal: 48.1s\tremaining: 17.4s\n",
      "3378:\tlearn: 1.8310916\ttotal: 48.1s\tremaining: 17.4s\n",
      "3379:\tlearn: 1.8309536\ttotal: 48.2s\tremaining: 17.4s\n",
      "3380:\tlearn: 1.8308028\ttotal: 48.2s\tremaining: 17.3s\n",
      "3381:\tlearn: 1.8305593\ttotal: 48.2s\tremaining: 17.3s\n",
      "3382:\tlearn: 1.8302828\ttotal: 48.2s\tremaining: 17.3s\n",
      "3383:\tlearn: 1.8300799\ttotal: 48.2s\tremaining: 17.3s\n",
      "3384:\tlearn: 1.8298154\ttotal: 48.2s\tremaining: 17.3s\n",
      "3385:\tlearn: 1.8297291\ttotal: 48.2s\tremaining: 17.3s\n",
      "3386:\tlearn: 1.8295505\ttotal: 48.3s\tremaining: 17.3s\n",
      "3387:\tlearn: 1.8293408\ttotal: 48.3s\tremaining: 17.2s\n",
      "3388:\tlearn: 1.8287709\ttotal: 48.3s\tremaining: 17.2s\n",
      "3389:\tlearn: 1.8285644\ttotal: 48.3s\tremaining: 17.2s\n",
      "3390:\tlearn: 1.8282920\ttotal: 48.3s\tremaining: 17.2s\n",
      "3391:\tlearn: 1.8281206\ttotal: 48.3s\tremaining: 17.2s\n",
      "3392:\tlearn: 1.8279815\ttotal: 48.3s\tremaining: 17.2s\n",
      "3393:\tlearn: 1.8277302\ttotal: 48.4s\tremaining: 17.2s\n",
      "3394:\tlearn: 1.8274148\ttotal: 48.4s\tremaining: 17.1s\n",
      "3395:\tlearn: 1.8271007\ttotal: 48.4s\tremaining: 17.1s\n",
      "3396:\tlearn: 1.8268973\ttotal: 48.4s\tremaining: 17.1s\n",
      "3397:\tlearn: 1.8266280\ttotal: 48.4s\tremaining: 17.1s\n",
      "3398:\tlearn: 1.8265768\ttotal: 48.4s\tremaining: 17.1s\n",
      "3399:\tlearn: 1.8264534\ttotal: 48.4s\tremaining: 17.1s\n",
      "3400:\tlearn: 1.8262919\ttotal: 48.5s\tremaining: 17.1s\n",
      "3401:\tlearn: 1.8259852\ttotal: 48.5s\tremaining: 17s\n",
      "3402:\tlearn: 1.8257253\ttotal: 48.5s\tremaining: 17s\n",
      "3403:\tlearn: 1.8255963\ttotal: 48.5s\tremaining: 17s\n",
      "3404:\tlearn: 1.8252790\ttotal: 48.5s\tremaining: 17s\n",
      "3405:\tlearn: 1.8249127\ttotal: 48.5s\tremaining: 17s\n",
      "3406:\tlearn: 1.8246322\ttotal: 48.5s\tremaining: 17s\n",
      "3407:\tlearn: 1.8243373\ttotal: 48.6s\tremaining: 17s\n",
      "3408:\tlearn: 1.8239783\ttotal: 48.6s\tremaining: 16.9s\n",
      "3409:\tlearn: 1.8237765\ttotal: 48.6s\tremaining: 16.9s\n",
      "3410:\tlearn: 1.8236783\ttotal: 48.6s\tremaining: 16.9s\n",
      "3411:\tlearn: 1.8235290\ttotal: 48.6s\tremaining: 16.9s\n",
      "3412:\tlearn: 1.8232357\ttotal: 48.6s\tremaining: 16.9s\n",
      "3413:\tlearn: 1.8229293\ttotal: 48.6s\tremaining: 16.9s\n",
      "3414:\tlearn: 1.8227247\ttotal: 48.7s\tremaining: 16.9s\n",
      "3415:\tlearn: 1.8225329\ttotal: 48.7s\tremaining: 16.8s\n",
      "3416:\tlearn: 1.8223959\ttotal: 48.7s\tremaining: 16.8s\n",
      "3417:\tlearn: 1.8221940\ttotal: 48.7s\tremaining: 16.8s\n",
      "3418:\tlearn: 1.8219437\ttotal: 48.7s\tremaining: 16.8s\n",
      "3419:\tlearn: 1.8217787\ttotal: 48.7s\tremaining: 16.8s\n",
      "3420:\tlearn: 1.8216311\ttotal: 48.7s\tremaining: 16.8s\n",
      "3421:\tlearn: 1.8214906\ttotal: 48.8s\tremaining: 16.8s\n",
      "3422:\tlearn: 1.8212975\ttotal: 48.8s\tremaining: 16.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423:\tlearn: 1.8210859\ttotal: 48.8s\tremaining: 16.7s\n",
      "3424:\tlearn: 1.8208172\ttotal: 48.8s\tremaining: 16.7s\n",
      "3425:\tlearn: 1.8205133\ttotal: 48.8s\tremaining: 16.7s\n",
      "3426:\tlearn: 1.8202914\ttotal: 48.8s\tremaining: 16.7s\n",
      "3427:\tlearn: 1.8200511\ttotal: 48.8s\tremaining: 16.7s\n",
      "3428:\tlearn: 1.8198629\ttotal: 48.9s\tremaining: 16.7s\n",
      "3429:\tlearn: 1.8197279\ttotal: 48.9s\tremaining: 16.6s\n",
      "3430:\tlearn: 1.8195671\ttotal: 48.9s\tremaining: 16.6s\n",
      "3431:\tlearn: 1.8192999\ttotal: 48.9s\tremaining: 16.6s\n",
      "3432:\tlearn: 1.8187798\ttotal: 48.9s\tremaining: 16.6s\n",
      "3433:\tlearn: 1.8185012\ttotal: 48.9s\tremaining: 16.6s\n",
      "3434:\tlearn: 1.8182740\ttotal: 48.9s\tremaining: 16.6s\n",
      "3435:\tlearn: 1.8180045\ttotal: 49s\tremaining: 16.6s\n",
      "3436:\tlearn: 1.8178152\ttotal: 49s\tremaining: 16.5s\n",
      "3437:\tlearn: 1.8176422\ttotal: 49s\tremaining: 16.5s\n",
      "3438:\tlearn: 1.8172200\ttotal: 49s\tremaining: 16.5s\n",
      "3439:\tlearn: 1.8169189\ttotal: 49s\tremaining: 16.5s\n",
      "3440:\tlearn: 1.8167345\ttotal: 49s\tremaining: 16.5s\n",
      "3441:\tlearn: 1.8165203\ttotal: 49s\tremaining: 16.5s\n",
      "3442:\tlearn: 1.8164155\ttotal: 49s\tremaining: 16.5s\n",
      "3443:\tlearn: 1.8162915\ttotal: 49.1s\tremaining: 16.4s\n",
      "3444:\tlearn: 1.8159215\ttotal: 49.1s\tremaining: 16.4s\n",
      "3445:\tlearn: 1.8157417\ttotal: 49.1s\tremaining: 16.4s\n",
      "3446:\tlearn: 1.8154763\ttotal: 49.1s\tremaining: 16.4s\n",
      "3447:\tlearn: 1.8151769\ttotal: 49.1s\tremaining: 16.4s\n",
      "3448:\tlearn: 1.8146757\ttotal: 49.1s\tremaining: 16.4s\n",
      "3449:\tlearn: 1.8145726\ttotal: 49.1s\tremaining: 16.4s\n",
      "3450:\tlearn: 1.8144067\ttotal: 49.2s\tremaining: 16.3s\n",
      "3451:\tlearn: 1.8141697\ttotal: 49.2s\tremaining: 16.3s\n",
      "3452:\tlearn: 1.8139301\ttotal: 49.2s\tremaining: 16.3s\n",
      "3453:\tlearn: 1.8136897\ttotal: 49.2s\tremaining: 16.3s\n",
      "3454:\tlearn: 1.8134962\ttotal: 49.2s\tremaining: 16.3s\n",
      "3455:\tlearn: 1.8132977\ttotal: 49.2s\tremaining: 16.3s\n",
      "3456:\tlearn: 1.8130216\ttotal: 49.2s\tremaining: 16.3s\n",
      "3457:\tlearn: 1.8126866\ttotal: 49.3s\tremaining: 16.2s\n",
      "3458:\tlearn: 1.8123729\ttotal: 49.3s\tremaining: 16.2s\n",
      "3459:\tlearn: 1.8121068\ttotal: 49.3s\tremaining: 16.2s\n",
      "3460:\tlearn: 1.8117230\ttotal: 49.3s\tremaining: 16.2s\n",
      "3461:\tlearn: 1.8115681\ttotal: 49.3s\tremaining: 16.2s\n",
      "3462:\tlearn: 1.8114649\ttotal: 49.3s\tremaining: 16.2s\n",
      "3463:\tlearn: 1.8112570\ttotal: 49.3s\tremaining: 16.2s\n",
      "3464:\tlearn: 1.8110604\ttotal: 49.4s\tremaining: 16.1s\n",
      "3465:\tlearn: 1.8108650\ttotal: 49.4s\tremaining: 16.1s\n",
      "3466:\tlearn: 1.8107035\ttotal: 49.4s\tremaining: 16.1s\n",
      "3467:\tlearn: 1.8103980\ttotal: 49.4s\tremaining: 16.1s\n",
      "3468:\tlearn: 1.8102140\ttotal: 49.4s\tremaining: 16.1s\n",
      "3469:\tlearn: 1.8099146\ttotal: 49.4s\tremaining: 16.1s\n",
      "3470:\tlearn: 1.8097497\ttotal: 49.4s\tremaining: 16.1s\n",
      "3471:\tlearn: 1.8096197\ttotal: 49.5s\tremaining: 16s\n",
      "3472:\tlearn: 1.8093532\ttotal: 49.5s\tremaining: 16s\n",
      "3473:\tlearn: 1.8090528\ttotal: 49.5s\tremaining: 16s\n",
      "3474:\tlearn: 1.8089774\ttotal: 49.5s\tremaining: 16s\n",
      "3475:\tlearn: 1.8087214\ttotal: 49.5s\tremaining: 16s\n",
      "3476:\tlearn: 1.8083482\ttotal: 49.5s\tremaining: 16s\n",
      "3477:\tlearn: 1.8081797\ttotal: 49.5s\tremaining: 16s\n",
      "3478:\tlearn: 1.8078431\ttotal: 49.6s\tremaining: 15.9s\n",
      "3479:\tlearn: 1.8076575\ttotal: 49.6s\tremaining: 15.9s\n",
      "3480:\tlearn: 1.8074340\ttotal: 49.6s\tremaining: 15.9s\n",
      "3481:\tlearn: 1.8070958\ttotal: 49.6s\tremaining: 15.9s\n",
      "3482:\tlearn: 1.8069698\ttotal: 49.6s\tremaining: 15.9s\n",
      "3483:\tlearn: 1.8068087\ttotal: 49.6s\tremaining: 15.9s\n",
      "3484:\tlearn: 1.8065865\ttotal: 49.6s\tremaining: 15.9s\n",
      "3485:\tlearn: 1.8065116\ttotal: 49.7s\tremaining: 15.8s\n",
      "3486:\tlearn: 1.8062550\ttotal: 49.7s\tremaining: 15.8s\n",
      "3487:\tlearn: 1.8060267\ttotal: 49.7s\tremaining: 15.8s\n",
      "3488:\tlearn: 1.8059915\ttotal: 49.7s\tremaining: 15.8s\n",
      "3489:\tlearn: 1.8056504\ttotal: 49.7s\tremaining: 15.8s\n",
      "3490:\tlearn: 1.8054866\ttotal: 49.7s\tremaining: 15.8s\n",
      "3491:\tlearn: 1.8051285\ttotal: 49.7s\tremaining: 15.8s\n",
      "3492:\tlearn: 1.8048974\ttotal: 49.7s\tremaining: 15.7s\n",
      "3493:\tlearn: 1.8047010\ttotal: 49.8s\tremaining: 15.7s\n",
      "3494:\tlearn: 1.8044489\ttotal: 49.8s\tremaining: 15.7s\n",
      "3495:\tlearn: 1.8042883\ttotal: 49.8s\tremaining: 15.7s\n",
      "3496:\tlearn: 1.8041417\ttotal: 49.8s\tremaining: 15.7s\n",
      "3497:\tlearn: 1.8039367\ttotal: 49.8s\tremaining: 15.7s\n",
      "3498:\tlearn: 1.8035670\ttotal: 49.8s\tremaining: 15.7s\n",
      "3499:\tlearn: 1.8034137\ttotal: 49.8s\tremaining: 15.6s\n",
      "3500:\tlearn: 1.8032627\ttotal: 49.9s\tremaining: 15.6s\n",
      "3501:\tlearn: 1.8030318\ttotal: 49.9s\tremaining: 15.6s\n",
      "3502:\tlearn: 1.8030024\ttotal: 49.9s\tremaining: 15.6s\n",
      "3503:\tlearn: 1.8028039\ttotal: 49.9s\tremaining: 15.6s\n",
      "3504:\tlearn: 1.8026527\ttotal: 49.9s\tremaining: 15.6s\n",
      "3505:\tlearn: 1.8023872\ttotal: 49.9s\tremaining: 15.6s\n",
      "3506:\tlearn: 1.8020999\ttotal: 49.9s\tremaining: 15.5s\n",
      "3507:\tlearn: 1.8019486\ttotal: 50s\tremaining: 15.5s\n",
      "3508:\tlearn: 1.8017942\ttotal: 50s\tremaining: 15.5s\n",
      "3509:\tlearn: 1.8016579\ttotal: 50s\tremaining: 15.5s\n",
      "3510:\tlearn: 1.8015222\ttotal: 50s\tremaining: 15.5s\n",
      "3511:\tlearn: 1.8013187\ttotal: 50s\tremaining: 15.5s\n",
      "3512:\tlearn: 1.8010944\ttotal: 50s\tremaining: 15.5s\n",
      "3513:\tlearn: 1.8006582\ttotal: 50s\tremaining: 15.4s\n",
      "3514:\tlearn: 1.8003351\ttotal: 50.1s\tremaining: 15.4s\n",
      "3515:\tlearn: 1.8000444\ttotal: 50.1s\tremaining: 15.4s\n",
      "3516:\tlearn: 1.7996126\ttotal: 50.1s\tremaining: 15.4s\n",
      "3517:\tlearn: 1.7994293\ttotal: 50.1s\tremaining: 15.4s\n",
      "3518:\tlearn: 1.7993453\ttotal: 50.1s\tremaining: 15.4s\n",
      "3519:\tlearn: 1.7990507\ttotal: 50.1s\tremaining: 15.4s\n",
      "3520:\tlearn: 1.7987614\ttotal: 50.1s\tremaining: 15.3s\n",
      "3521:\tlearn: 1.7983212\ttotal: 50.2s\tremaining: 15.3s\n",
      "3522:\tlearn: 1.7980661\ttotal: 50.2s\tremaining: 15.3s\n",
      "3523:\tlearn: 1.7978821\ttotal: 50.2s\tremaining: 15.3s\n",
      "3524:\tlearn: 1.7977275\ttotal: 50.2s\tremaining: 15.3s\n",
      "3525:\tlearn: 1.7974233\ttotal: 50.2s\tremaining: 15.3s\n",
      "3526:\tlearn: 1.7972645\ttotal: 50.2s\tremaining: 15.3s\n",
      "3527:\tlearn: 1.7972129\ttotal: 50.2s\tremaining: 15.2s\n",
      "3528:\tlearn: 1.7967054\ttotal: 50.3s\tremaining: 15.2s\n",
      "3529:\tlearn: 1.7964300\ttotal: 50.3s\tremaining: 15.2s\n",
      "3530:\tlearn: 1.7960490\ttotal: 50.3s\tremaining: 15.2s\n",
      "3531:\tlearn: 1.7957301\ttotal: 50.3s\tremaining: 15.2s\n",
      "3532:\tlearn: 1.7956111\ttotal: 50.3s\tremaining: 15.2s\n",
      "3533:\tlearn: 1.7954933\ttotal: 50.3s\tremaining: 15.2s\n",
      "3534:\tlearn: 1.7952816\ttotal: 50.3s\tremaining: 15.1s\n",
      "3535:\tlearn: 1.7950179\ttotal: 50.4s\tremaining: 15.1s\n",
      "3536:\tlearn: 1.7948195\ttotal: 50.4s\tremaining: 15.1s\n",
      "3537:\tlearn: 1.7946555\ttotal: 50.4s\tremaining: 15.1s\n",
      "3538:\tlearn: 1.7943434\ttotal: 50.4s\tremaining: 15.1s\n",
      "3539:\tlearn: 1.7939503\ttotal: 50.4s\tremaining: 15.1s\n",
      "3540:\tlearn: 1.7939280\ttotal: 50.4s\tremaining: 15.1s\n",
      "3541:\tlearn: 1.7934048\ttotal: 50.4s\tremaining: 15s\n",
      "3542:\tlearn: 1.7932489\ttotal: 50.4s\tremaining: 15s\n",
      "3543:\tlearn: 1.7929654\ttotal: 50.5s\tremaining: 15s\n",
      "3544:\tlearn: 1.7927765\ttotal: 50.5s\tremaining: 15s\n",
      "3545:\tlearn: 1.7924602\ttotal: 50.5s\tremaining: 15s\n",
      "3546:\tlearn: 1.7921903\ttotal: 50.5s\tremaining: 15s\n",
      "3547:\tlearn: 1.7919660\ttotal: 50.5s\tremaining: 15s\n",
      "3548:\tlearn: 1.7917544\ttotal: 50.5s\tremaining: 14.9s\n",
      "3549:\tlearn: 1.7915995\ttotal: 50.5s\tremaining: 14.9s\n",
      "3550:\tlearn: 1.7913837\ttotal: 50.6s\tremaining: 14.9s\n",
      "3551:\tlearn: 1.7911334\ttotal: 50.6s\tremaining: 14.9s\n",
      "3552:\tlearn: 1.7909448\ttotal: 50.6s\tremaining: 14.9s\n",
      "3553:\tlearn: 1.7907884\ttotal: 50.6s\tremaining: 14.9s\n",
      "3554:\tlearn: 1.7906744\ttotal: 50.6s\tremaining: 14.9s\n",
      "3555:\tlearn: 1.7904205\ttotal: 50.6s\tremaining: 14.8s\n",
      "3556:\tlearn: 1.7903417\ttotal: 50.6s\tremaining: 14.8s\n",
      "3557:\tlearn: 1.7899970\ttotal: 50.7s\tremaining: 14.8s\n",
      "3558:\tlearn: 1.7898650\ttotal: 50.7s\tremaining: 14.8s\n",
      "3559:\tlearn: 1.7895996\ttotal: 50.7s\tremaining: 14.8s\n",
      "3560:\tlearn: 1.7894204\ttotal: 50.7s\tremaining: 14.8s\n",
      "3561:\tlearn: 1.7890612\ttotal: 50.7s\tremaining: 14.8s\n",
      "3562:\tlearn: 1.7885689\ttotal: 50.7s\tremaining: 14.7s\n",
      "3563:\tlearn: 1.7880935\ttotal: 50.8s\tremaining: 14.7s\n",
      "3564:\tlearn: 1.7878735\ttotal: 50.8s\tremaining: 14.7s\n",
      "3565:\tlearn: 1.7876495\ttotal: 50.8s\tremaining: 14.7s\n",
      "3566:\tlearn: 1.7874193\ttotal: 50.8s\tremaining: 14.7s\n",
      "3567:\tlearn: 1.7871926\ttotal: 50.8s\tremaining: 14.7s\n",
      "3568:\tlearn: 1.7871520\ttotal: 50.8s\tremaining: 14.7s\n",
      "3569:\tlearn: 1.7868738\ttotal: 50.8s\tremaining: 14.6s\n",
      "3570:\tlearn: 1.7865230\ttotal: 50.9s\tremaining: 14.6s\n",
      "3571:\tlearn: 1.7865153\ttotal: 50.9s\tremaining: 14.6s\n",
      "3572:\tlearn: 1.7862988\ttotal: 50.9s\tremaining: 14.6s\n",
      "3573:\tlearn: 1.7860596\ttotal: 50.9s\tremaining: 14.6s\n",
      "3574:\tlearn: 1.7858849\ttotal: 50.9s\tremaining: 14.6s\n",
      "3575:\tlearn: 1.7856437\ttotal: 50.9s\tremaining: 14.6s\n",
      "3576:\tlearn: 1.7855908\ttotal: 50.9s\tremaining: 14.5s\n",
      "3577:\tlearn: 1.7854013\ttotal: 51s\tremaining: 14.5s\n",
      "3578:\tlearn: 1.7852273\ttotal: 51s\tremaining: 14.5s\n",
      "3579:\tlearn: 1.7848953\ttotal: 51s\tremaining: 14.5s\n",
      "3580:\tlearn: 1.7845991\ttotal: 51s\tremaining: 14.5s\n",
      "3581:\tlearn: 1.7843340\ttotal: 51s\tremaining: 14.5s\n",
      "3582:\tlearn: 1.7840832\ttotal: 51s\tremaining: 14.5s\n",
      "3583:\tlearn: 1.7838119\ttotal: 51s\tremaining: 14.4s\n",
      "3584:\tlearn: 1.7836969\ttotal: 51.1s\tremaining: 14.4s\n",
      "3585:\tlearn: 1.7834058\ttotal: 51.1s\tremaining: 14.4s\n",
      "3586:\tlearn: 1.7830545\ttotal: 51.1s\tremaining: 14.4s\n",
      "3587:\tlearn: 1.7828415\ttotal: 51.1s\tremaining: 14.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588:\tlearn: 1.7824138\ttotal: 51.1s\tremaining: 14.4s\n",
      "3589:\tlearn: 1.7821923\ttotal: 51.1s\tremaining: 14.4s\n",
      "3590:\tlearn: 1.7819640\ttotal: 51.2s\tremaining: 14.3s\n",
      "3591:\tlearn: 1.7817640\ttotal: 51.2s\tremaining: 14.3s\n",
      "3592:\tlearn: 1.7813752\ttotal: 51.2s\tremaining: 14.3s\n",
      "3593:\tlearn: 1.7811608\ttotal: 51.2s\tremaining: 14.3s\n",
      "3594:\tlearn: 1.7807417\ttotal: 51.2s\tremaining: 14.3s\n",
      "3595:\tlearn: 1.7806097\ttotal: 51.3s\tremaining: 14.3s\n",
      "3596:\tlearn: 1.7803817\ttotal: 51.3s\tremaining: 14.3s\n",
      "3597:\tlearn: 1.7803061\ttotal: 51.3s\tremaining: 14.3s\n",
      "3598:\tlearn: 1.7800373\ttotal: 51.3s\tremaining: 14.2s\n",
      "3599:\tlearn: 1.7798178\ttotal: 51.3s\tremaining: 14.2s\n",
      "3600:\tlearn: 1.7797599\ttotal: 51.3s\tremaining: 14.2s\n",
      "3601:\tlearn: 1.7796518\ttotal: 51.3s\tremaining: 14.2s\n",
      "3602:\tlearn: 1.7793535\ttotal: 51.4s\tremaining: 14.2s\n",
      "3603:\tlearn: 1.7792922\ttotal: 51.4s\tremaining: 14.2s\n",
      "3604:\tlearn: 1.7792491\ttotal: 51.4s\tremaining: 14.2s\n",
      "3605:\tlearn: 1.7789798\ttotal: 51.4s\tremaining: 14.1s\n",
      "3606:\tlearn: 1.7787652\ttotal: 51.4s\tremaining: 14.1s\n",
      "3607:\tlearn: 1.7785083\ttotal: 51.4s\tremaining: 14.1s\n",
      "3608:\tlearn: 1.7782227\ttotal: 51.4s\tremaining: 14.1s\n",
      "3609:\tlearn: 1.7781601\ttotal: 51.5s\tremaining: 14.1s\n",
      "3610:\tlearn: 1.7780368\ttotal: 51.5s\tremaining: 14.1s\n",
      "3611:\tlearn: 1.7777560\ttotal: 51.5s\tremaining: 14.1s\n",
      "3612:\tlearn: 1.7773334\ttotal: 51.5s\tremaining: 14s\n",
      "3613:\tlearn: 1.7769582\ttotal: 51.5s\tremaining: 14s\n",
      "3614:\tlearn: 1.7767225\ttotal: 51.5s\tremaining: 14s\n",
      "3615:\tlearn: 1.7759519\ttotal: 51.5s\tremaining: 14s\n",
      "3616:\tlearn: 1.7757509\ttotal: 51.6s\tremaining: 14s\n",
      "3617:\tlearn: 1.7756821\ttotal: 51.6s\tremaining: 14s\n",
      "3618:\tlearn: 1.7754270\ttotal: 51.6s\tremaining: 14s\n",
      "3619:\tlearn: 1.7750785\ttotal: 51.6s\tremaining: 13.9s\n",
      "3620:\tlearn: 1.7750388\ttotal: 51.6s\tremaining: 13.9s\n",
      "3621:\tlearn: 1.7748592\ttotal: 51.6s\tremaining: 13.9s\n",
      "3622:\tlearn: 1.7744186\ttotal: 51.6s\tremaining: 13.9s\n",
      "3623:\tlearn: 1.7741056\ttotal: 51.6s\tremaining: 13.9s\n",
      "3624:\tlearn: 1.7738788\ttotal: 51.7s\tremaining: 13.9s\n",
      "3625:\tlearn: 1.7736090\ttotal: 51.7s\tremaining: 13.9s\n",
      "3626:\tlearn: 1.7734556\ttotal: 51.7s\tremaining: 13.8s\n",
      "3627:\tlearn: 1.7732006\ttotal: 51.7s\tremaining: 13.8s\n",
      "3628:\tlearn: 1.7727990\ttotal: 51.7s\tremaining: 13.8s\n",
      "3629:\tlearn: 1.7726458\ttotal: 51.7s\tremaining: 13.8s\n",
      "3630:\tlearn: 1.7723818\ttotal: 51.7s\tremaining: 13.8s\n",
      "3631:\tlearn: 1.7722502\ttotal: 51.8s\tremaining: 13.8s\n",
      "3632:\tlearn: 1.7721651\ttotal: 51.8s\tremaining: 13.8s\n",
      "3633:\tlearn: 1.7719128\ttotal: 51.8s\tremaining: 13.7s\n",
      "3634:\tlearn: 1.7717915\ttotal: 51.8s\tremaining: 13.7s\n",
      "3635:\tlearn: 1.7715813\ttotal: 51.8s\tremaining: 13.7s\n",
      "3636:\tlearn: 1.7711592\ttotal: 51.8s\tremaining: 13.7s\n",
      "3637:\tlearn: 1.7708351\ttotal: 51.8s\tremaining: 13.7s\n",
      "3638:\tlearn: 1.7707611\ttotal: 51.9s\tremaining: 13.7s\n",
      "3639:\tlearn: 1.7705984\ttotal: 51.9s\tremaining: 13.7s\n",
      "3640:\tlearn: 1.7702472\ttotal: 51.9s\tremaining: 13.6s\n",
      "3641:\tlearn: 1.7701012\ttotal: 51.9s\tremaining: 13.6s\n",
      "3642:\tlearn: 1.7699000\ttotal: 51.9s\tremaining: 13.6s\n",
      "3643:\tlearn: 1.7697963\ttotal: 51.9s\tremaining: 13.6s\n",
      "3644:\tlearn: 1.7695086\ttotal: 51.9s\tremaining: 13.6s\n",
      "3645:\tlearn: 1.7692844\ttotal: 52s\tremaining: 13.6s\n",
      "3646:\tlearn: 1.7690909\ttotal: 52s\tremaining: 13.6s\n",
      "3647:\tlearn: 1.7688495\ttotal: 52s\tremaining: 13.5s\n",
      "3648:\tlearn: 1.7686508\ttotal: 52s\tremaining: 13.5s\n",
      "3649:\tlearn: 1.7683828\ttotal: 52s\tremaining: 13.5s\n",
      "3650:\tlearn: 1.7682985\ttotal: 52s\tremaining: 13.5s\n",
      "3651:\tlearn: 1.7680733\ttotal: 52s\tremaining: 13.5s\n",
      "3652:\tlearn: 1.7676918\ttotal: 52.1s\tremaining: 13.5s\n",
      "3653:\tlearn: 1.7674839\ttotal: 52.1s\tremaining: 13.5s\n",
      "3654:\tlearn: 1.7673532\ttotal: 52.1s\tremaining: 13.4s\n",
      "3655:\tlearn: 1.7671223\ttotal: 52.1s\tremaining: 13.4s\n",
      "3656:\tlearn: 1.7666850\ttotal: 52.1s\tremaining: 13.4s\n",
      "3657:\tlearn: 1.7663123\ttotal: 52.1s\tremaining: 13.4s\n",
      "3658:\tlearn: 1.7661243\ttotal: 52.1s\tremaining: 13.4s\n",
      "3659:\tlearn: 1.7658457\ttotal: 52.2s\tremaining: 13.4s\n",
      "3660:\tlearn: 1.7656646\ttotal: 52.2s\tremaining: 13.4s\n",
      "3661:\tlearn: 1.7655224\ttotal: 52.2s\tremaining: 13.3s\n",
      "3662:\tlearn: 1.7652520\ttotal: 52.2s\tremaining: 13.3s\n",
      "3663:\tlearn: 1.7649273\ttotal: 52.2s\tremaining: 13.3s\n",
      "3664:\tlearn: 1.7646941\ttotal: 52.2s\tremaining: 13.3s\n",
      "3665:\tlearn: 1.7645768\ttotal: 52.3s\tremaining: 13.3s\n",
      "3666:\tlearn: 1.7644171\ttotal: 52.3s\tremaining: 13.3s\n",
      "3667:\tlearn: 1.7642339\ttotal: 52.3s\tremaining: 13.3s\n",
      "3668:\tlearn: 1.7638652\ttotal: 52.3s\tremaining: 13.2s\n",
      "3669:\tlearn: 1.7635779\ttotal: 52.3s\tremaining: 13.2s\n",
      "3670:\tlearn: 1.7633885\ttotal: 52.3s\tremaining: 13.2s\n",
      "3671:\tlearn: 1.7632074\ttotal: 52.3s\tremaining: 13.2s\n",
      "3672:\tlearn: 1.7630488\ttotal: 52.4s\tremaining: 13.2s\n",
      "3673:\tlearn: 1.7626917\ttotal: 52.4s\tremaining: 13.2s\n",
      "3674:\tlearn: 1.7625103\ttotal: 52.4s\tremaining: 13.2s\n",
      "3675:\tlearn: 1.7624062\ttotal: 52.4s\tremaining: 13.1s\n",
      "3676:\tlearn: 1.7622894\ttotal: 52.4s\tremaining: 13.1s\n",
      "3677:\tlearn: 1.7619426\ttotal: 52.4s\tremaining: 13.1s\n",
      "3678:\tlearn: 1.7616722\ttotal: 52.5s\tremaining: 13.1s\n",
      "3679:\tlearn: 1.7615217\ttotal: 52.5s\tremaining: 13.1s\n",
      "3680:\tlearn: 1.7613367\ttotal: 52.5s\tremaining: 13.1s\n",
      "3681:\tlearn: 1.7610622\ttotal: 52.5s\tremaining: 13.1s\n",
      "3682:\tlearn: 1.7607674\ttotal: 52.5s\tremaining: 13s\n",
      "3683:\tlearn: 1.7606396\ttotal: 52.5s\tremaining: 13s\n",
      "3684:\tlearn: 1.7604320\ttotal: 52.5s\tremaining: 13s\n",
      "3685:\tlearn: 1.7602690\ttotal: 52.6s\tremaining: 13s\n",
      "3686:\tlearn: 1.7600955\ttotal: 52.6s\tremaining: 13s\n",
      "3687:\tlearn: 1.7599104\ttotal: 52.6s\tremaining: 13s\n",
      "3688:\tlearn: 1.7594923\ttotal: 52.6s\tremaining: 13s\n",
      "3689:\tlearn: 1.7594057\ttotal: 52.6s\tremaining: 12.9s\n",
      "3690:\tlearn: 1.7592297\ttotal: 52.6s\tremaining: 12.9s\n",
      "3691:\tlearn: 1.7589909\ttotal: 52.6s\tremaining: 12.9s\n",
      "3692:\tlearn: 1.7588239\ttotal: 52.7s\tremaining: 12.9s\n",
      "3693:\tlearn: 1.7586291\ttotal: 52.7s\tremaining: 12.9s\n",
      "3694:\tlearn: 1.7585680\ttotal: 52.7s\tremaining: 12.9s\n",
      "3695:\tlearn: 1.7580836\ttotal: 52.7s\tremaining: 12.9s\n",
      "3696:\tlearn: 1.7578728\ttotal: 52.7s\tremaining: 12.8s\n",
      "3697:\tlearn: 1.7577922\ttotal: 52.7s\tremaining: 12.8s\n",
      "3698:\tlearn: 1.7573457\ttotal: 52.7s\tremaining: 12.8s\n",
      "3699:\tlearn: 1.7571323\ttotal: 52.7s\tremaining: 12.8s\n",
      "3700:\tlearn: 1.7570684\ttotal: 52.8s\tremaining: 12.8s\n",
      "3701:\tlearn: 1.7568477\ttotal: 52.8s\tremaining: 12.8s\n",
      "3702:\tlearn: 1.7566387\ttotal: 52.8s\tremaining: 12.8s\n",
      "3703:\tlearn: 1.7564140\ttotal: 52.8s\tremaining: 12.7s\n",
      "3704:\tlearn: 1.7562282\ttotal: 52.8s\tremaining: 12.7s\n",
      "3705:\tlearn: 1.7558489\ttotal: 52.8s\tremaining: 12.7s\n",
      "3706:\tlearn: 1.7555951\ttotal: 52.8s\tremaining: 12.7s\n",
      "3707:\tlearn: 1.7554240\ttotal: 52.9s\tremaining: 12.7s\n",
      "3708:\tlearn: 1.7551888\ttotal: 52.9s\tremaining: 12.7s\n",
      "3709:\tlearn: 1.7550162\ttotal: 52.9s\tremaining: 12.7s\n",
      "3710:\tlearn: 1.7548221\ttotal: 52.9s\tremaining: 12.6s\n",
      "3711:\tlearn: 1.7545914\ttotal: 52.9s\tremaining: 12.6s\n",
      "3712:\tlearn: 1.7542786\ttotal: 52.9s\tremaining: 12.6s\n",
      "3713:\tlearn: 1.7539892\ttotal: 52.9s\tremaining: 12.6s\n",
      "3714:\tlearn: 1.7538560\ttotal: 53s\tremaining: 12.6s\n",
      "3715:\tlearn: 1.7536747\ttotal: 53s\tremaining: 12.6s\n",
      "3716:\tlearn: 1.7533007\ttotal: 53s\tremaining: 12.6s\n",
      "3717:\tlearn: 1.7532146\ttotal: 53s\tremaining: 12.5s\n",
      "3718:\tlearn: 1.7531772\ttotal: 53s\tremaining: 12.5s\n",
      "3719:\tlearn: 1.7528000\ttotal: 53s\tremaining: 12.5s\n",
      "3720:\tlearn: 1.7527395\ttotal: 53s\tremaining: 12.5s\n",
      "3721:\tlearn: 1.7525737\ttotal: 53s\tremaining: 12.5s\n",
      "3722:\tlearn: 1.7523462\ttotal: 53.1s\tremaining: 12.5s\n",
      "3723:\tlearn: 1.7520980\ttotal: 53.1s\tremaining: 12.5s\n",
      "3724:\tlearn: 1.7518057\ttotal: 53.1s\tremaining: 12.4s\n",
      "3725:\tlearn: 1.7516759\ttotal: 53.1s\tremaining: 12.4s\n",
      "3726:\tlearn: 1.7515228\ttotal: 53.1s\tremaining: 12.4s\n",
      "3727:\tlearn: 1.7513513\ttotal: 53.1s\tremaining: 12.4s\n",
      "3728:\tlearn: 1.7512341\ttotal: 53.1s\tremaining: 12.4s\n",
      "3729:\tlearn: 1.7510981\ttotal: 53.2s\tremaining: 12.4s\n",
      "3730:\tlearn: 1.7508204\ttotal: 53.2s\tremaining: 12.4s\n",
      "3731:\tlearn: 1.7506645\ttotal: 53.2s\tremaining: 12.3s\n",
      "3732:\tlearn: 1.7504915\ttotal: 53.2s\tremaining: 12.3s\n",
      "3733:\tlearn: 1.7503769\ttotal: 53.2s\tremaining: 12.3s\n",
      "3734:\tlearn: 1.7502686\ttotal: 53.2s\tremaining: 12.3s\n",
      "3735:\tlearn: 1.7501000\ttotal: 53.2s\tremaining: 12.3s\n",
      "3736:\tlearn: 1.7499304\ttotal: 53.3s\tremaining: 12.3s\n",
      "3737:\tlearn: 1.7496010\ttotal: 53.3s\tremaining: 12.3s\n",
      "3738:\tlearn: 1.7492349\ttotal: 53.3s\tremaining: 12.2s\n",
      "3739:\tlearn: 1.7488618\ttotal: 53.3s\tremaining: 12.2s\n",
      "3740:\tlearn: 1.7486746\ttotal: 53.3s\tremaining: 12.2s\n",
      "3741:\tlearn: 1.7482999\ttotal: 53.3s\tremaining: 12.2s\n",
      "3742:\tlearn: 1.7481551\ttotal: 53.3s\tremaining: 12.2s\n",
      "3743:\tlearn: 1.7479549\ttotal: 53.4s\tremaining: 12.2s\n",
      "3744:\tlearn: 1.7477372\ttotal: 53.4s\tremaining: 12.2s\n",
      "3745:\tlearn: 1.7474822\ttotal: 53.4s\tremaining: 12.1s\n",
      "3746:\tlearn: 1.7473002\ttotal: 53.4s\tremaining: 12.1s\n",
      "3747:\tlearn: 1.7469435\ttotal: 53.4s\tremaining: 12.1s\n",
      "3748:\tlearn: 1.7468510\ttotal: 53.4s\tremaining: 12.1s\n",
      "3749:\tlearn: 1.7465880\ttotal: 53.4s\tremaining: 12.1s\n",
      "3750:\tlearn: 1.7464011\ttotal: 53.5s\tremaining: 12.1s\n",
      "3751:\tlearn: 1.7460737\ttotal: 53.5s\tremaining: 12.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3752:\tlearn: 1.7459796\ttotal: 53.5s\tremaining: 12s\n",
      "3753:\tlearn: 1.7458265\ttotal: 53.5s\tremaining: 12s\n",
      "3754:\tlearn: 1.7456840\ttotal: 53.5s\tremaining: 12s\n",
      "3755:\tlearn: 1.7455422\ttotal: 53.5s\tremaining: 12s\n",
      "3756:\tlearn: 1.7452551\ttotal: 53.5s\tremaining: 12s\n",
      "3757:\tlearn: 1.7450529\ttotal: 53.6s\tremaining: 12s\n",
      "3758:\tlearn: 1.7449414\ttotal: 53.6s\tremaining: 12s\n",
      "3759:\tlearn: 1.7447855\ttotal: 53.6s\tremaining: 11.9s\n",
      "3760:\tlearn: 1.7445841\ttotal: 53.6s\tremaining: 11.9s\n",
      "3761:\tlearn: 1.7444551\ttotal: 53.6s\tremaining: 11.9s\n",
      "3762:\tlearn: 1.7444216\ttotal: 53.6s\tremaining: 11.9s\n",
      "3763:\tlearn: 1.7441153\ttotal: 53.6s\tremaining: 11.9s\n",
      "3764:\tlearn: 1.7437785\ttotal: 53.7s\tremaining: 11.9s\n",
      "3765:\tlearn: 1.7435991\ttotal: 53.7s\tremaining: 11.9s\n",
      "3766:\tlearn: 1.7434461\ttotal: 53.7s\tremaining: 11.8s\n",
      "3767:\tlearn: 1.7430661\ttotal: 53.7s\tremaining: 11.8s\n",
      "3768:\tlearn: 1.7428727\ttotal: 53.7s\tremaining: 11.8s\n",
      "3769:\tlearn: 1.7426439\ttotal: 53.7s\tremaining: 11.8s\n",
      "3770:\tlearn: 1.7424376\ttotal: 53.7s\tremaining: 11.8s\n",
      "3771:\tlearn: 1.7422183\ttotal: 53.8s\tremaining: 11.8s\n",
      "3772:\tlearn: 1.7420291\ttotal: 53.8s\tremaining: 11.8s\n",
      "3773:\tlearn: 1.7417887\ttotal: 53.8s\tremaining: 11.7s\n",
      "3774:\tlearn: 1.7415587\ttotal: 53.8s\tremaining: 11.7s\n",
      "3775:\tlearn: 1.7414467\ttotal: 53.8s\tremaining: 11.7s\n",
      "3776:\tlearn: 1.7412775\ttotal: 53.8s\tremaining: 11.7s\n",
      "3777:\tlearn: 1.7409680\ttotal: 53.8s\tremaining: 11.7s\n",
      "3778:\tlearn: 1.7407904\ttotal: 53.8s\tremaining: 11.7s\n",
      "3779:\tlearn: 1.7404790\ttotal: 53.9s\tremaining: 11.7s\n",
      "3780:\tlearn: 1.7402424\ttotal: 53.9s\tremaining: 11.6s\n",
      "3781:\tlearn: 1.7399726\ttotal: 53.9s\tremaining: 11.6s\n",
      "3782:\tlearn: 1.7395763\ttotal: 53.9s\tremaining: 11.6s\n",
      "3783:\tlearn: 1.7393980\ttotal: 53.9s\tremaining: 11.6s\n",
      "3784:\tlearn: 1.7391473\ttotal: 53.9s\tremaining: 11.6s\n",
      "3785:\tlearn: 1.7388580\ttotal: 53.9s\tremaining: 11.6s\n",
      "3786:\tlearn: 1.7385780\ttotal: 54s\tremaining: 11.6s\n",
      "3787:\tlearn: 1.7384146\ttotal: 54s\tremaining: 11.5s\n",
      "3788:\tlearn: 1.7378724\ttotal: 54s\tremaining: 11.5s\n",
      "3789:\tlearn: 1.7376449\ttotal: 54s\tremaining: 11.5s\n",
      "3790:\tlearn: 1.7374924\ttotal: 54s\tremaining: 11.5s\n",
      "3791:\tlearn: 1.7373565\ttotal: 54s\tremaining: 11.5s\n",
      "3792:\tlearn: 1.7370817\ttotal: 54s\tremaining: 11.5s\n",
      "3793:\tlearn: 1.7368255\ttotal: 54.1s\tremaining: 11.5s\n",
      "3794:\tlearn: 1.7364520\ttotal: 54.1s\tremaining: 11.4s\n",
      "3795:\tlearn: 1.7361799\ttotal: 54.1s\tremaining: 11.4s\n",
      "3796:\tlearn: 1.7359806\ttotal: 54.1s\tremaining: 11.4s\n",
      "3797:\tlearn: 1.7356334\ttotal: 54.1s\tremaining: 11.4s\n",
      "3798:\tlearn: 1.7354563\ttotal: 54.1s\tremaining: 11.4s\n",
      "3799:\tlearn: 1.7352071\ttotal: 54.1s\tremaining: 11.4s\n",
      "3800:\tlearn: 1.7349071\ttotal: 54.2s\tremaining: 11.4s\n",
      "3801:\tlearn: 1.7345006\ttotal: 54.2s\tremaining: 11.3s\n",
      "3802:\tlearn: 1.7341753\ttotal: 54.2s\tremaining: 11.3s\n",
      "3803:\tlearn: 1.7340586\ttotal: 54.2s\tremaining: 11.3s\n",
      "3804:\tlearn: 1.7339191\ttotal: 54.2s\tremaining: 11.3s\n",
      "3805:\tlearn: 1.7338911\ttotal: 54.2s\tremaining: 11.3s\n",
      "3806:\tlearn: 1.7336511\ttotal: 54.2s\tremaining: 11.3s\n",
      "3807:\tlearn: 1.7336249\ttotal: 54.3s\tremaining: 11.3s\n",
      "3808:\tlearn: 1.7334297\ttotal: 54.3s\tremaining: 11.2s\n",
      "3809:\tlearn: 1.7332044\ttotal: 54.3s\tremaining: 11.2s\n",
      "3810:\tlearn: 1.7331224\ttotal: 54.3s\tremaining: 11.2s\n",
      "3811:\tlearn: 1.7329890\ttotal: 54.3s\tremaining: 11.2s\n",
      "3812:\tlearn: 1.7327104\ttotal: 54.3s\tremaining: 11.2s\n",
      "3813:\tlearn: 1.7323339\ttotal: 54.3s\tremaining: 11.2s\n",
      "3814:\tlearn: 1.7322729\ttotal: 54.4s\tremaining: 11.2s\n",
      "3815:\tlearn: 1.7320383\ttotal: 54.4s\tremaining: 11.1s\n",
      "3816:\tlearn: 1.7317773\ttotal: 54.4s\tremaining: 11.1s\n",
      "3817:\tlearn: 1.7314077\ttotal: 54.4s\tremaining: 11.1s\n",
      "3818:\tlearn: 1.7312059\ttotal: 54.4s\tremaining: 11.1s\n",
      "3819:\tlearn: 1.7310721\ttotal: 54.4s\tremaining: 11.1s\n",
      "3820:\tlearn: 1.7309635\ttotal: 54.4s\tremaining: 11.1s\n",
      "3821:\tlearn: 1.7307330\ttotal: 54.5s\tremaining: 11.1s\n",
      "3822:\tlearn: 1.7305229\ttotal: 54.5s\tremaining: 11s\n",
      "3823:\tlearn: 1.7302039\ttotal: 54.5s\tremaining: 11s\n",
      "3824:\tlearn: 1.7300150\ttotal: 54.5s\tremaining: 11s\n",
      "3825:\tlearn: 1.7295363\ttotal: 54.5s\tremaining: 11s\n",
      "3826:\tlearn: 1.7290230\ttotal: 54.5s\tremaining: 11s\n",
      "3827:\tlearn: 1.7287312\ttotal: 54.5s\tremaining: 11s\n",
      "3828:\tlearn: 1.7285991\ttotal: 54.6s\tremaining: 11s\n",
      "3829:\tlearn: 1.7283851\ttotal: 54.6s\tremaining: 10.9s\n",
      "3830:\tlearn: 1.7282727\ttotal: 54.6s\tremaining: 10.9s\n",
      "3831:\tlearn: 1.7279831\ttotal: 54.6s\tremaining: 10.9s\n",
      "3832:\tlearn: 1.7277571\ttotal: 54.6s\tremaining: 10.9s\n",
      "3833:\tlearn: 1.7276299\ttotal: 54.6s\tremaining: 10.9s\n",
      "3834:\tlearn: 1.7272648\ttotal: 54.6s\tremaining: 10.9s\n",
      "3835:\tlearn: 1.7270658\ttotal: 54.7s\tremaining: 10.9s\n",
      "3836:\tlearn: 1.7268924\ttotal: 54.7s\tremaining: 10.8s\n",
      "3837:\tlearn: 1.7266910\ttotal: 54.7s\tremaining: 10.8s\n",
      "3838:\tlearn: 1.7265043\ttotal: 54.7s\tremaining: 10.8s\n",
      "3839:\tlearn: 1.7261369\ttotal: 54.7s\tremaining: 10.8s\n",
      "3840:\tlearn: 1.7258890\ttotal: 54.7s\tremaining: 10.8s\n",
      "3841:\tlearn: 1.7255761\ttotal: 54.7s\tremaining: 10.8s\n",
      "3842:\tlearn: 1.7252796\ttotal: 54.8s\tremaining: 10.8s\n",
      "3843:\tlearn: 1.7251638\ttotal: 54.8s\tremaining: 10.7s\n",
      "3844:\tlearn: 1.7249755\ttotal: 54.8s\tremaining: 10.7s\n",
      "3845:\tlearn: 1.7247511\ttotal: 54.8s\tremaining: 10.7s\n",
      "3846:\tlearn: 1.7244745\ttotal: 54.8s\tremaining: 10.7s\n",
      "3847:\tlearn: 1.7244124\ttotal: 54.8s\tremaining: 10.7s\n",
      "3848:\tlearn: 1.7242864\ttotal: 54.8s\tremaining: 10.7s\n",
      "3849:\tlearn: 1.7241072\ttotal: 54.9s\tremaining: 10.7s\n",
      "3850:\tlearn: 1.7239911\ttotal: 54.9s\tremaining: 10.6s\n",
      "3851:\tlearn: 1.7238122\ttotal: 54.9s\tremaining: 10.6s\n",
      "3852:\tlearn: 1.7236943\ttotal: 54.9s\tremaining: 10.6s\n",
      "3853:\tlearn: 1.7234828\ttotal: 54.9s\tremaining: 10.6s\n",
      "3854:\tlearn: 1.7233708\ttotal: 54.9s\tremaining: 10.6s\n",
      "3855:\tlearn: 1.7230318\ttotal: 54.9s\tremaining: 10.6s\n",
      "3856:\tlearn: 1.7228397\ttotal: 55s\tremaining: 10.6s\n",
      "3857:\tlearn: 1.7227670\ttotal: 55s\tremaining: 10.5s\n",
      "3858:\tlearn: 1.7226026\ttotal: 55s\tremaining: 10.5s\n",
      "3859:\tlearn: 1.7222843\ttotal: 55s\tremaining: 10.5s\n",
      "3860:\tlearn: 1.7218509\ttotal: 55s\tremaining: 10.5s\n",
      "3861:\tlearn: 1.7215327\ttotal: 55s\tremaining: 10.5s\n",
      "3862:\tlearn: 1.7214871\ttotal: 55s\tremaining: 10.5s\n",
      "3863:\tlearn: 1.7212923\ttotal: 55.1s\tremaining: 10.5s\n",
      "3864:\tlearn: 1.7212000\ttotal: 55.1s\tremaining: 10.4s\n",
      "3865:\tlearn: 1.7209712\ttotal: 55.1s\tremaining: 10.4s\n",
      "3866:\tlearn: 1.7208669\ttotal: 55.1s\tremaining: 10.4s\n",
      "3867:\tlearn: 1.7206461\ttotal: 55.1s\tremaining: 10.4s\n",
      "3868:\tlearn: 1.7205574\ttotal: 55.1s\tremaining: 10.4s\n",
      "3869:\tlearn: 1.7204446\ttotal: 55.1s\tremaining: 10.4s\n",
      "3870:\tlearn: 1.7203505\ttotal: 55.2s\tremaining: 10.4s\n",
      "3871:\tlearn: 1.7201540\ttotal: 55.2s\tremaining: 10.3s\n",
      "3872:\tlearn: 1.7195615\ttotal: 55.2s\tremaining: 10.3s\n",
      "3873:\tlearn: 1.7194528\ttotal: 55.2s\tremaining: 10.3s\n",
      "3874:\tlearn: 1.7192109\ttotal: 55.2s\tremaining: 10.3s\n",
      "3875:\tlearn: 1.7189083\ttotal: 55.2s\tremaining: 10.3s\n",
      "3876:\tlearn: 1.7188243\ttotal: 55.2s\tremaining: 10.3s\n",
      "3877:\tlearn: 1.7186305\ttotal: 55.3s\tremaining: 10.3s\n",
      "3878:\tlearn: 1.7184489\ttotal: 55.3s\tremaining: 10.2s\n",
      "3879:\tlearn: 1.7182745\ttotal: 55.3s\tremaining: 10.2s\n",
      "3880:\tlearn: 1.7179367\ttotal: 55.3s\tremaining: 10.2s\n",
      "3881:\tlearn: 1.7175650\ttotal: 55.3s\tremaining: 10.2s\n",
      "3882:\tlearn: 1.7172105\ttotal: 55.3s\tremaining: 10.2s\n",
      "3883:\tlearn: 1.7165838\ttotal: 55.3s\tremaining: 10.2s\n",
      "3884:\tlearn: 1.7161669\ttotal: 55.4s\tremaining: 10.2s\n",
      "3885:\tlearn: 1.7159332\ttotal: 55.4s\tremaining: 10.1s\n",
      "3886:\tlearn: 1.7157672\ttotal: 55.4s\tremaining: 10.1s\n",
      "3887:\tlearn: 1.7156540\ttotal: 55.4s\tremaining: 10.1s\n",
      "3888:\tlearn: 1.7155675\ttotal: 55.4s\tremaining: 10.1s\n",
      "3889:\tlearn: 1.7152828\ttotal: 55.4s\tremaining: 10.1s\n",
      "3890:\tlearn: 1.7150392\ttotal: 55.4s\tremaining: 10.1s\n",
      "3891:\tlearn: 1.7147859\ttotal: 55.5s\tremaining: 10.1s\n",
      "3892:\tlearn: 1.7145305\ttotal: 55.5s\tremaining: 10s\n",
      "3893:\tlearn: 1.7144447\ttotal: 55.5s\tremaining: 10s\n",
      "3894:\tlearn: 1.7141414\ttotal: 55.5s\tremaining: 10s\n",
      "3895:\tlearn: 1.7139593\ttotal: 55.5s\tremaining: 10s\n",
      "3896:\tlearn: 1.7137909\ttotal: 55.5s\tremaining: 9.99s\n",
      "3897:\tlearn: 1.7135737\ttotal: 55.5s\tremaining: 9.97s\n",
      "3898:\tlearn: 1.7134446\ttotal: 55.6s\tremaining: 9.96s\n",
      "3899:\tlearn: 1.7130944\ttotal: 55.6s\tremaining: 9.95s\n",
      "3900:\tlearn: 1.7128350\ttotal: 55.6s\tremaining: 9.93s\n",
      "3901:\tlearn: 1.7126391\ttotal: 55.6s\tremaining: 9.92s\n",
      "3902:\tlearn: 1.7124327\ttotal: 55.6s\tremaining: 9.9s\n",
      "3903:\tlearn: 1.7121792\ttotal: 55.6s\tremaining: 9.89s\n",
      "3904:\tlearn: 1.7119738\ttotal: 55.6s\tremaining: 9.88s\n",
      "3905:\tlearn: 1.7117186\ttotal: 55.7s\tremaining: 9.86s\n",
      "3906:\tlearn: 1.7114367\ttotal: 55.7s\tremaining: 9.85s\n",
      "3907:\tlearn: 1.7112982\ttotal: 55.7s\tremaining: 9.83s\n",
      "3908:\tlearn: 1.7110972\ttotal: 55.7s\tremaining: 9.82s\n",
      "3909:\tlearn: 1.7107168\ttotal: 55.7s\tremaining: 9.8s\n",
      "3910:\tlearn: 1.7103055\ttotal: 55.7s\tremaining: 9.79s\n",
      "3911:\tlearn: 1.7098747\ttotal: 55.7s\tremaining: 9.78s\n",
      "3912:\tlearn: 1.7097514\ttotal: 55.8s\tremaining: 9.76s\n",
      "3913:\tlearn: 1.7095464\ttotal: 55.8s\tremaining: 9.75s\n",
      "3914:\tlearn: 1.7093407\ttotal: 55.8s\tremaining: 9.73s\n",
      "3915:\tlearn: 1.7092233\ttotal: 55.8s\tremaining: 9.72s\n",
      "3916:\tlearn: 1.7090636\ttotal: 55.8s\tremaining: 9.7s\n",
      "3917:\tlearn: 1.7087434\ttotal: 55.8s\tremaining: 9.69s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3918:\tlearn: 1.7084077\ttotal: 55.8s\tremaining: 9.68s\n",
      "3919:\tlearn: 1.7081868\ttotal: 55.9s\tremaining: 9.66s\n",
      "3920:\tlearn: 1.7079658\ttotal: 55.9s\tremaining: 9.65s\n",
      "3921:\tlearn: 1.7078886\ttotal: 55.9s\tremaining: 9.63s\n",
      "3922:\tlearn: 1.7075964\ttotal: 55.9s\tremaining: 9.62s\n",
      "3923:\tlearn: 1.7071462\ttotal: 55.9s\tremaining: 9.61s\n",
      "3924:\tlearn: 1.7066210\ttotal: 55.9s\tremaining: 9.59s\n",
      "3925:\tlearn: 1.7064906\ttotal: 55.9s\tremaining: 9.58s\n",
      "3926:\tlearn: 1.7062635\ttotal: 56s\tremaining: 9.56s\n",
      "3927:\tlearn: 1.7061455\ttotal: 56s\tremaining: 9.55s\n",
      "3928:\tlearn: 1.7058926\ttotal: 56s\tremaining: 9.53s\n",
      "3929:\tlearn: 1.7058499\ttotal: 56s\tremaining: 9.52s\n",
      "3930:\tlearn: 1.7056638\ttotal: 56s\tremaining: 9.51s\n",
      "3931:\tlearn: 1.7053256\ttotal: 56s\tremaining: 9.49s\n",
      "3932:\tlearn: 1.7052038\ttotal: 56s\tremaining: 9.48s\n",
      "3933:\tlearn: 1.7051118\ttotal: 56.1s\tremaining: 9.46s\n",
      "3934:\tlearn: 1.7049568\ttotal: 56.1s\tremaining: 9.45s\n",
      "3935:\tlearn: 1.7047033\ttotal: 56.1s\tremaining: 9.43s\n",
      "3936:\tlearn: 1.7044812\ttotal: 56.1s\tremaining: 9.42s\n",
      "3937:\tlearn: 1.7042415\ttotal: 56.1s\tremaining: 9.4s\n",
      "3938:\tlearn: 1.7038755\ttotal: 56.1s\tremaining: 9.39s\n",
      "3939:\tlearn: 1.7037071\ttotal: 56.1s\tremaining: 9.38s\n",
      "3940:\tlearn: 1.7032762\ttotal: 56.2s\tremaining: 9.36s\n",
      "3941:\tlearn: 1.7030936\ttotal: 56.2s\tremaining: 9.35s\n",
      "3942:\tlearn: 1.7029954\ttotal: 56.2s\tremaining: 9.33s\n",
      "3943:\tlearn: 1.7027602\ttotal: 56.2s\tremaining: 9.32s\n",
      "3944:\tlearn: 1.7025818\ttotal: 56.2s\tremaining: 9.31s\n",
      "3945:\tlearn: 1.7025488\ttotal: 56.2s\tremaining: 9.29s\n",
      "3946:\tlearn: 1.7024568\ttotal: 56.2s\tremaining: 9.28s\n",
      "3947:\tlearn: 1.7023318\ttotal: 56.3s\tremaining: 9.26s\n",
      "3948:\tlearn: 1.7019454\ttotal: 56.3s\tremaining: 9.25s\n",
      "3949:\tlearn: 1.7016547\ttotal: 56.3s\tremaining: 9.23s\n",
      "3950:\tlearn: 1.7015298\ttotal: 56.3s\tremaining: 9.22s\n",
      "3951:\tlearn: 1.7013553\ttotal: 56.3s\tremaining: 9.21s\n",
      "3952:\tlearn: 1.7011871\ttotal: 56.3s\tremaining: 9.19s\n",
      "3953:\tlearn: 1.7008894\ttotal: 56.4s\tremaining: 9.18s\n",
      "3954:\tlearn: 1.7007838\ttotal: 56.4s\tremaining: 9.16s\n",
      "3955:\tlearn: 1.7006096\ttotal: 56.4s\tremaining: 9.15s\n",
      "3956:\tlearn: 1.7003736\ttotal: 56.4s\tremaining: 9.13s\n",
      "3957:\tlearn: 1.7001091\ttotal: 56.4s\tremaining: 9.12s\n",
      "3958:\tlearn: 1.7000077\ttotal: 56.4s\tremaining: 9.11s\n",
      "3959:\tlearn: 1.6997950\ttotal: 56.4s\tremaining: 9.09s\n",
      "3960:\tlearn: 1.6996264\ttotal: 56.5s\tremaining: 9.08s\n",
      "3961:\tlearn: 1.6993547\ttotal: 56.5s\tremaining: 9.07s\n",
      "3962:\tlearn: 1.6991418\ttotal: 56.5s\tremaining: 9.05s\n",
      "3963:\tlearn: 1.6989730\ttotal: 56.5s\tremaining: 9.04s\n",
      "3964:\tlearn: 1.6987305\ttotal: 56.5s\tremaining: 9.03s\n",
      "3965:\tlearn: 1.6985931\ttotal: 56.6s\tremaining: 9.01s\n",
      "3966:\tlearn: 1.6982823\ttotal: 56.6s\tremaining: 9s\n",
      "3967:\tlearn: 1.6981974\ttotal: 56.6s\tremaining: 8.98s\n",
      "3968:\tlearn: 1.6978992\ttotal: 56.6s\tremaining: 8.97s\n",
      "3969:\tlearn: 1.6975811\ttotal: 56.6s\tremaining: 8.96s\n",
      "3970:\tlearn: 1.6973977\ttotal: 56.6s\tremaining: 8.94s\n",
      "3971:\tlearn: 1.6972354\ttotal: 56.6s\tremaining: 8.93s\n",
      "3972:\tlearn: 1.6969582\ttotal: 56.7s\tremaining: 8.91s\n",
      "3973:\tlearn: 1.6966203\ttotal: 56.7s\tremaining: 8.9s\n",
      "3974:\tlearn: 1.6964099\ttotal: 56.7s\tremaining: 8.88s\n",
      "3975:\tlearn: 1.6959956\ttotal: 56.7s\tremaining: 8.87s\n",
      "3976:\tlearn: 1.6958199\ttotal: 56.7s\tremaining: 8.86s\n",
      "3977:\tlearn: 1.6956445\ttotal: 56.7s\tremaining: 8.84s\n",
      "3978:\tlearn: 1.6955263\ttotal: 56.7s\tremaining: 8.83s\n",
      "3979:\tlearn: 1.6954711\ttotal: 56.8s\tremaining: 8.81s\n",
      "3980:\tlearn: 1.6952514\ttotal: 56.8s\tremaining: 8.8s\n",
      "3981:\tlearn: 1.6950678\ttotal: 56.8s\tremaining: 8.78s\n",
      "3982:\tlearn: 1.6949372\ttotal: 56.8s\tremaining: 8.77s\n",
      "3983:\tlearn: 1.6947668\ttotal: 56.8s\tremaining: 8.76s\n",
      "3984:\tlearn: 1.6945734\ttotal: 56.8s\tremaining: 8.74s\n",
      "3985:\tlearn: 1.6943048\ttotal: 56.8s\tremaining: 8.73s\n",
      "3986:\tlearn: 1.6941559\ttotal: 56.9s\tremaining: 8.71s\n",
      "3987:\tlearn: 1.6940003\ttotal: 56.9s\tremaining: 8.7s\n",
      "3988:\tlearn: 1.6937172\ttotal: 56.9s\tremaining: 8.68s\n",
      "3989:\tlearn: 1.6935113\ttotal: 56.9s\tremaining: 8.67s\n",
      "3990:\tlearn: 1.6931897\ttotal: 56.9s\tremaining: 8.66s\n",
      "3991:\tlearn: 1.6930487\ttotal: 56.9s\tremaining: 8.64s\n",
      "3992:\tlearn: 1.6927821\ttotal: 56.9s\tremaining: 8.63s\n",
      "3993:\tlearn: 1.6925170\ttotal: 57s\tremaining: 8.61s\n",
      "3994:\tlearn: 1.6924071\ttotal: 57s\tremaining: 8.6s\n",
      "3995:\tlearn: 1.6921533\ttotal: 57s\tremaining: 8.59s\n",
      "3996:\tlearn: 1.6918975\ttotal: 57s\tremaining: 8.57s\n",
      "3997:\tlearn: 1.6916137\ttotal: 57s\tremaining: 8.56s\n",
      "3998:\tlearn: 1.6913306\ttotal: 57s\tremaining: 8.54s\n",
      "3999:\tlearn: 1.6910128\ttotal: 57s\tremaining: 8.53s\n",
      "4000:\tlearn: 1.6907628\ttotal: 57.1s\tremaining: 8.51s\n",
      "4001:\tlearn: 1.6904709\ttotal: 57.1s\tremaining: 8.5s\n",
      "4002:\tlearn: 1.6903423\ttotal: 57.1s\tremaining: 8.48s\n",
      "4003:\tlearn: 1.6899949\ttotal: 57.1s\tremaining: 8.47s\n",
      "4004:\tlearn: 1.6897015\ttotal: 57.1s\tremaining: 8.46s\n",
      "4005:\tlearn: 1.6894672\ttotal: 57.1s\tremaining: 8.44s\n",
      "4006:\tlearn: 1.6892941\ttotal: 57.1s\tremaining: 8.43s\n",
      "4007:\tlearn: 1.6887617\ttotal: 57.2s\tremaining: 8.41s\n",
      "4008:\tlearn: 1.6882968\ttotal: 57.2s\tremaining: 8.4s\n",
      "4009:\tlearn: 1.6881203\ttotal: 57.2s\tremaining: 8.39s\n",
      "4010:\tlearn: 1.6877675\ttotal: 57.2s\tremaining: 8.37s\n",
      "4011:\tlearn: 1.6876060\ttotal: 57.2s\tremaining: 8.36s\n",
      "4012:\tlearn: 1.6874451\ttotal: 57.2s\tremaining: 8.34s\n",
      "4013:\tlearn: 1.6871188\ttotal: 57.3s\tremaining: 8.33s\n",
      "4014:\tlearn: 1.6869721\ttotal: 57.3s\tremaining: 8.31s\n",
      "4015:\tlearn: 1.6867210\ttotal: 57.3s\tremaining: 8.3s\n",
      "4016:\tlearn: 1.6864931\ttotal: 57.3s\tremaining: 8.29s\n",
      "4017:\tlearn: 1.6863612\ttotal: 57.3s\tremaining: 8.27s\n",
      "4018:\tlearn: 1.6861761\ttotal: 57.3s\tremaining: 8.26s\n",
      "4019:\tlearn: 1.6860274\ttotal: 57.3s\tremaining: 8.24s\n",
      "4020:\tlearn: 1.6859222\ttotal: 57.4s\tremaining: 8.23s\n",
      "4021:\tlearn: 1.6858161\ttotal: 57.4s\tremaining: 8.21s\n",
      "4022:\tlearn: 1.6856061\ttotal: 57.4s\tremaining: 8.2s\n",
      "4023:\tlearn: 1.6854077\ttotal: 57.4s\tremaining: 8.19s\n",
      "4024:\tlearn: 1.6852222\ttotal: 57.4s\tremaining: 8.17s\n",
      "4025:\tlearn: 1.6850708\ttotal: 57.4s\tremaining: 8.16s\n",
      "4026:\tlearn: 1.6847281\ttotal: 57.4s\tremaining: 8.14s\n",
      "4027:\tlearn: 1.6843815\ttotal: 57.5s\tremaining: 8.13s\n",
      "4028:\tlearn: 1.6842926\ttotal: 57.5s\tremaining: 8.12s\n",
      "4029:\tlearn: 1.6842032\ttotal: 57.5s\tremaining: 8.1s\n",
      "4030:\tlearn: 1.6841047\ttotal: 57.5s\tremaining: 8.09s\n",
      "4031:\tlearn: 1.6836824\ttotal: 57.5s\tremaining: 8.07s\n",
      "4032:\tlearn: 1.6834773\ttotal: 57.5s\tremaining: 8.06s\n",
      "4033:\tlearn: 1.6832658\ttotal: 57.5s\tremaining: 8.04s\n",
      "4034:\tlearn: 1.6831495\ttotal: 57.6s\tremaining: 8.03s\n",
      "4035:\tlearn: 1.6829861\ttotal: 57.6s\tremaining: 8.02s\n",
      "4036:\tlearn: 1.6827012\ttotal: 57.6s\tremaining: 8s\n",
      "4037:\tlearn: 1.6825155\ttotal: 57.6s\tremaining: 7.99s\n",
      "4038:\tlearn: 1.6824065\ttotal: 57.6s\tremaining: 7.97s\n",
      "4039:\tlearn: 1.6821349\ttotal: 57.6s\tremaining: 7.96s\n",
      "4040:\tlearn: 1.6818780\ttotal: 57.6s\tremaining: 7.94s\n",
      "4041:\tlearn: 1.6817338\ttotal: 57.7s\tremaining: 7.93s\n",
      "4042:\tlearn: 1.6815646\ttotal: 57.7s\tremaining: 7.92s\n",
      "4043:\tlearn: 1.6813725\ttotal: 57.7s\tremaining: 7.9s\n",
      "4044:\tlearn: 1.6813410\ttotal: 57.7s\tremaining: 7.89s\n",
      "4045:\tlearn: 1.6810837\ttotal: 57.7s\tremaining: 7.87s\n",
      "4046:\tlearn: 1.6810161\ttotal: 57.7s\tremaining: 7.86s\n",
      "4047:\tlearn: 1.6808653\ttotal: 57.7s\tremaining: 7.84s\n",
      "4048:\tlearn: 1.6805965\ttotal: 57.7s\tremaining: 7.83s\n",
      "4049:\tlearn: 1.6804034\ttotal: 57.8s\tremaining: 7.82s\n",
      "4050:\tlearn: 1.6801666\ttotal: 57.8s\tremaining: 7.8s\n",
      "4051:\tlearn: 1.6798460\ttotal: 57.8s\tremaining: 7.79s\n",
      "4052:\tlearn: 1.6795961\ttotal: 57.8s\tremaining: 7.77s\n",
      "4053:\tlearn: 1.6794816\ttotal: 57.8s\tremaining: 7.76s\n",
      "4054:\tlearn: 1.6791361\ttotal: 57.8s\tremaining: 7.74s\n",
      "4055:\tlearn: 1.6789581\ttotal: 57.8s\tremaining: 7.73s\n",
      "4056:\tlearn: 1.6787531\ttotal: 57.9s\tremaining: 7.72s\n",
      "4057:\tlearn: 1.6786149\ttotal: 57.9s\tremaining: 7.7s\n",
      "4058:\tlearn: 1.6784670\ttotal: 57.9s\tremaining: 7.69s\n",
      "4059:\tlearn: 1.6783625\ttotal: 57.9s\tremaining: 7.67s\n",
      "4060:\tlearn: 1.6781541\ttotal: 57.9s\tremaining: 7.66s\n",
      "4061:\tlearn: 1.6779809\ttotal: 57.9s\tremaining: 7.64s\n",
      "4062:\tlearn: 1.6778671\ttotal: 57.9s\tremaining: 7.63s\n",
      "4063:\tlearn: 1.6777733\ttotal: 58s\tremaining: 7.62s\n",
      "4064:\tlearn: 1.6775918\ttotal: 58s\tremaining: 7.6s\n",
      "4065:\tlearn: 1.6774663\ttotal: 58s\tremaining: 7.59s\n",
      "4066:\tlearn: 1.6771699\ttotal: 58s\tremaining: 7.57s\n",
      "4067:\tlearn: 1.6771311\ttotal: 58s\tremaining: 7.56s\n",
      "4068:\tlearn: 1.6770146\ttotal: 58s\tremaining: 7.54s\n",
      "4069:\tlearn: 1.6768935\ttotal: 58s\tremaining: 7.53s\n",
      "4070:\tlearn: 1.6768369\ttotal: 58.1s\tremaining: 7.52s\n",
      "4071:\tlearn: 1.6767901\ttotal: 58.1s\tremaining: 7.5s\n",
      "4072:\tlearn: 1.6766800\ttotal: 58.1s\tremaining: 7.49s\n",
      "4073:\tlearn: 1.6763445\ttotal: 58.1s\tremaining: 7.47s\n",
      "4074:\tlearn: 1.6761051\ttotal: 58.1s\tremaining: 7.46s\n",
      "4075:\tlearn: 1.6759205\ttotal: 58.1s\tremaining: 7.44s\n",
      "4076:\tlearn: 1.6757749\ttotal: 58.1s\tremaining: 7.43s\n",
      "4077:\tlearn: 1.6756637\ttotal: 58.2s\tremaining: 7.42s\n",
      "4078:\tlearn: 1.6755087\ttotal: 58.2s\tremaining: 7.4s\n",
      "4079:\tlearn: 1.6753047\ttotal: 58.2s\tremaining: 7.39s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4080:\tlearn: 1.6751189\ttotal: 58.2s\tremaining: 7.37s\n",
      "4081:\tlearn: 1.6748153\ttotal: 58.2s\tremaining: 7.36s\n",
      "4082:\tlearn: 1.6745151\ttotal: 58.2s\tremaining: 7.34s\n",
      "4083:\tlearn: 1.6742686\ttotal: 58.2s\tremaining: 7.33s\n",
      "4084:\tlearn: 1.6740268\ttotal: 58.3s\tremaining: 7.32s\n",
      "4085:\tlearn: 1.6737018\ttotal: 58.3s\tremaining: 7.3s\n",
      "4086:\tlearn: 1.6735337\ttotal: 58.3s\tremaining: 7.29s\n",
      "4087:\tlearn: 1.6732824\ttotal: 58.3s\tremaining: 7.27s\n",
      "4088:\tlearn: 1.6730884\ttotal: 58.3s\tremaining: 7.26s\n",
      "4089:\tlearn: 1.6728893\ttotal: 58.3s\tremaining: 7.24s\n",
      "4090:\tlearn: 1.6726701\ttotal: 58.3s\tremaining: 7.23s\n",
      "4091:\tlearn: 1.6724837\ttotal: 58.4s\tremaining: 7.22s\n",
      "4092:\tlearn: 1.6721601\ttotal: 58.4s\tremaining: 7.2s\n",
      "4093:\tlearn: 1.6719213\ttotal: 58.4s\tremaining: 7.19s\n",
      "4094:\tlearn: 1.6717379\ttotal: 58.4s\tremaining: 7.17s\n",
      "4095:\tlearn: 1.6714385\ttotal: 58.4s\tremaining: 7.16s\n",
      "4096:\tlearn: 1.6712998\ttotal: 58.4s\tremaining: 7.14s\n",
      "4097:\tlearn: 1.6712142\ttotal: 58.4s\tremaining: 7.13s\n",
      "4098:\tlearn: 1.6709761\ttotal: 58.5s\tremaining: 7.12s\n",
      "4099:\tlearn: 1.6708339\ttotal: 58.5s\tremaining: 7.1s\n",
      "4100:\tlearn: 1.6705058\ttotal: 58.5s\tremaining: 7.09s\n",
      "4101:\tlearn: 1.6703938\ttotal: 58.5s\tremaining: 7.07s\n",
      "4102:\tlearn: 1.6702288\ttotal: 58.5s\tremaining: 7.06s\n",
      "4103:\tlearn: 1.6701335\ttotal: 58.5s\tremaining: 7.04s\n",
      "4104:\tlearn: 1.6698145\ttotal: 58.5s\tremaining: 7.03s\n",
      "4105:\tlearn: 1.6696136\ttotal: 58.6s\tremaining: 7.02s\n",
      "4106:\tlearn: 1.6694478\ttotal: 58.6s\tremaining: 7s\n",
      "4107:\tlearn: 1.6690789\ttotal: 58.6s\tremaining: 6.99s\n",
      "4108:\tlearn: 1.6687872\ttotal: 58.6s\tremaining: 6.97s\n",
      "4109:\tlearn: 1.6686490\ttotal: 58.6s\tremaining: 6.96s\n",
      "4110:\tlearn: 1.6685356\ttotal: 58.6s\tremaining: 6.94s\n",
      "4111:\tlearn: 1.6683275\ttotal: 58.6s\tremaining: 6.93s\n",
      "4112:\tlearn: 1.6680993\ttotal: 58.7s\tremaining: 6.92s\n",
      "4113:\tlearn: 1.6679048\ttotal: 58.7s\tremaining: 6.9s\n",
      "4114:\tlearn: 1.6676870\ttotal: 58.7s\tremaining: 6.89s\n",
      "4115:\tlearn: 1.6675137\ttotal: 58.7s\tremaining: 6.87s\n",
      "4116:\tlearn: 1.6673186\ttotal: 58.7s\tremaining: 6.86s\n",
      "4117:\tlearn: 1.6671520\ttotal: 58.7s\tremaining: 6.84s\n",
      "4118:\tlearn: 1.6669534\ttotal: 58.7s\tremaining: 6.83s\n",
      "4119:\tlearn: 1.6666285\ttotal: 58.8s\tremaining: 6.82s\n",
      "4120:\tlearn: 1.6664758\ttotal: 58.8s\tremaining: 6.8s\n",
      "4121:\tlearn: 1.6661639\ttotal: 58.8s\tremaining: 6.79s\n",
      "4122:\tlearn: 1.6661107\ttotal: 58.8s\tremaining: 6.77s\n",
      "4123:\tlearn: 1.6658760\ttotal: 58.8s\tremaining: 6.76s\n",
      "4124:\tlearn: 1.6656961\ttotal: 58.8s\tremaining: 6.74s\n",
      "4125:\tlearn: 1.6654686\ttotal: 58.8s\tremaining: 6.73s\n",
      "4126:\tlearn: 1.6652707\ttotal: 58.9s\tremaining: 6.72s\n",
      "4127:\tlearn: 1.6649691\ttotal: 58.9s\tremaining: 6.7s\n",
      "4128:\tlearn: 1.6646084\ttotal: 58.9s\tremaining: 6.69s\n",
      "4129:\tlearn: 1.6645061\ttotal: 58.9s\tremaining: 6.67s\n",
      "4130:\tlearn: 1.6643029\ttotal: 58.9s\tremaining: 6.66s\n",
      "4131:\tlearn: 1.6641258\ttotal: 58.9s\tremaining: 6.64s\n",
      "4132:\tlearn: 1.6638573\ttotal: 58.9s\tremaining: 6.63s\n",
      "4133:\tlearn: 1.6636664\ttotal: 59s\tremaining: 6.62s\n",
      "4134:\tlearn: 1.6633817\ttotal: 59s\tremaining: 6.6s\n",
      "4135:\tlearn: 1.6632082\ttotal: 59s\tremaining: 6.59s\n",
      "4136:\tlearn: 1.6630943\ttotal: 59s\tremaining: 6.57s\n",
      "4137:\tlearn: 1.6629618\ttotal: 59s\tremaining: 6.56s\n",
      "4138:\tlearn: 1.6626609\ttotal: 59s\tremaining: 6.54s\n",
      "4139:\tlearn: 1.6625485\ttotal: 59s\tremaining: 6.53s\n",
      "4140:\tlearn: 1.6622293\ttotal: 59.1s\tremaining: 6.52s\n",
      "4141:\tlearn: 1.6621481\ttotal: 59.1s\tremaining: 6.5s\n",
      "4142:\tlearn: 1.6618647\ttotal: 59.1s\tremaining: 6.49s\n",
      "4143:\tlearn: 1.6617506\ttotal: 59.1s\tremaining: 6.47s\n",
      "4144:\tlearn: 1.6615372\ttotal: 59.1s\tremaining: 6.46s\n",
      "4145:\tlearn: 1.6613304\ttotal: 59.1s\tremaining: 6.45s\n",
      "4146:\tlearn: 1.6611737\ttotal: 59.1s\tremaining: 6.43s\n",
      "4147:\tlearn: 1.6610048\ttotal: 59.1s\tremaining: 6.42s\n",
      "4148:\tlearn: 1.6607447\ttotal: 59.2s\tremaining: 6.4s\n",
      "4149:\tlearn: 1.6605450\ttotal: 59.2s\tremaining: 6.39s\n",
      "4150:\tlearn: 1.6604236\ttotal: 59.2s\tremaining: 6.37s\n",
      "4151:\tlearn: 1.6602456\ttotal: 59.2s\tremaining: 6.36s\n",
      "4152:\tlearn: 1.6600720\ttotal: 59.2s\tremaining: 6.34s\n",
      "4153:\tlearn: 1.6599132\ttotal: 59.2s\tremaining: 6.33s\n",
      "4154:\tlearn: 1.6597049\ttotal: 59.2s\tremaining: 6.32s\n",
      "4155:\tlearn: 1.6595329\ttotal: 59.3s\tremaining: 6.3s\n",
      "4156:\tlearn: 1.6592668\ttotal: 59.3s\tremaining: 6.29s\n",
      "4157:\tlearn: 1.6588494\ttotal: 59.3s\tremaining: 6.27s\n",
      "4158:\tlearn: 1.6586712\ttotal: 59.3s\tremaining: 6.26s\n",
      "4159:\tlearn: 1.6584735\ttotal: 59.3s\tremaining: 6.25s\n",
      "4160:\tlearn: 1.6582421\ttotal: 59.3s\tremaining: 6.23s\n",
      "4161:\tlearn: 1.6581795\ttotal: 59.3s\tremaining: 6.22s\n",
      "4162:\tlearn: 1.6580885\ttotal: 59.4s\tremaining: 6.2s\n",
      "4163:\tlearn: 1.6579239\ttotal: 59.4s\tremaining: 6.19s\n",
      "4164:\tlearn: 1.6578264\ttotal: 59.4s\tremaining: 6.17s\n",
      "4165:\tlearn: 1.6576991\ttotal: 59.4s\tremaining: 6.16s\n",
      "4166:\tlearn: 1.6575774\ttotal: 59.4s\tremaining: 6.14s\n",
      "4167:\tlearn: 1.6573740\ttotal: 59.4s\tremaining: 6.13s\n",
      "4168:\tlearn: 1.6571348\ttotal: 59.4s\tremaining: 6.12s\n",
      "4169:\tlearn: 1.6568760\ttotal: 59.5s\tremaining: 6.1s\n",
      "4170:\tlearn: 1.6567216\ttotal: 59.5s\tremaining: 6.09s\n",
      "4171:\tlearn: 1.6565876\ttotal: 59.5s\tremaining: 6.07s\n",
      "4172:\tlearn: 1.6562873\ttotal: 59.5s\tremaining: 6.06s\n",
      "4173:\tlearn: 1.6560609\ttotal: 59.5s\tremaining: 6.04s\n",
      "4174:\tlearn: 1.6558515\ttotal: 59.5s\tremaining: 6.03s\n",
      "4175:\tlearn: 1.6557240\ttotal: 59.5s\tremaining: 6.02s\n",
      "4176:\tlearn: 1.6555566\ttotal: 59.6s\tremaining: 6s\n",
      "4177:\tlearn: 1.6553125\ttotal: 59.6s\tremaining: 5.99s\n",
      "4178:\tlearn: 1.6550376\ttotal: 59.6s\tremaining: 5.97s\n",
      "4179:\tlearn: 1.6546506\ttotal: 59.6s\tremaining: 5.96s\n",
      "4180:\tlearn: 1.6545385\ttotal: 59.6s\tremaining: 5.95s\n",
      "4181:\tlearn: 1.6544601\ttotal: 59.6s\tremaining: 5.93s\n",
      "4182:\tlearn: 1.6540977\ttotal: 59.6s\tremaining: 5.92s\n",
      "4183:\tlearn: 1.6539418\ttotal: 59.7s\tremaining: 5.9s\n",
      "4184:\tlearn: 1.6538396\ttotal: 59.7s\tremaining: 5.89s\n",
      "4185:\tlearn: 1.6535659\ttotal: 59.7s\tremaining: 5.87s\n",
      "4186:\tlearn: 1.6531503\ttotal: 59.7s\tremaining: 5.86s\n",
      "4187:\tlearn: 1.6529941\ttotal: 59.7s\tremaining: 5.85s\n",
      "4188:\tlearn: 1.6528038\ttotal: 59.7s\tremaining: 5.83s\n",
      "4189:\tlearn: 1.6526752\ttotal: 59.7s\tremaining: 5.82s\n",
      "4190:\tlearn: 1.6525204\ttotal: 59.8s\tremaining: 5.8s\n",
      "4191:\tlearn: 1.6524028\ttotal: 59.8s\tremaining: 5.79s\n",
      "4192:\tlearn: 1.6521523\ttotal: 59.8s\tremaining: 5.77s\n",
      "4193:\tlearn: 1.6519812\ttotal: 59.8s\tremaining: 5.76s\n",
      "4194:\tlearn: 1.6519078\ttotal: 59.8s\tremaining: 5.75s\n",
      "4195:\tlearn: 1.6517466\ttotal: 59.8s\tremaining: 5.73s\n",
      "4196:\tlearn: 1.6516540\ttotal: 59.8s\tremaining: 5.72s\n",
      "4197:\tlearn: 1.6515531\ttotal: 59.9s\tremaining: 5.7s\n",
      "4198:\tlearn: 1.6513918\ttotal: 59.9s\tremaining: 5.69s\n",
      "4199:\tlearn: 1.6511535\ttotal: 59.9s\tremaining: 5.67s\n",
      "4200:\tlearn: 1.6509496\ttotal: 59.9s\tremaining: 5.66s\n",
      "4201:\tlearn: 1.6508026\ttotal: 59.9s\tremaining: 5.65s\n",
      "4202:\tlearn: 1.6505448\ttotal: 59.9s\tremaining: 5.63s\n",
      "4203:\tlearn: 1.6503471\ttotal: 59.9s\tremaining: 5.62s\n",
      "4204:\tlearn: 1.6501583\ttotal: 60s\tremaining: 5.6s\n",
      "4205:\tlearn: 1.6499054\ttotal: 60s\tremaining: 5.59s\n",
      "4206:\tlearn: 1.6497841\ttotal: 60s\tremaining: 5.58s\n",
      "4207:\tlearn: 1.6496237\ttotal: 1m\tremaining: 5.56s\n",
      "4208:\tlearn: 1.6494293\ttotal: 1m\tremaining: 5.55s\n",
      "4209:\tlearn: 1.6492414\ttotal: 1m\tremaining: 5.53s\n",
      "4210:\tlearn: 1.6490590\ttotal: 1m\tremaining: 5.52s\n",
      "4211:\tlearn: 1.6488960\ttotal: 1m\tremaining: 5.5s\n",
      "4212:\tlearn: 1.6487517\ttotal: 1m\tremaining: 5.49s\n",
      "4213:\tlearn: 1.6486873\ttotal: 1m\tremaining: 5.47s\n",
      "4214:\tlearn: 1.6485882\ttotal: 1m\tremaining: 5.46s\n",
      "4215:\tlearn: 1.6483857\ttotal: 1m\tremaining: 5.45s\n",
      "4216:\tlearn: 1.6481643\ttotal: 1m\tremaining: 5.43s\n",
      "4217:\tlearn: 1.6479760\ttotal: 1m\tremaining: 5.42s\n",
      "4218:\tlearn: 1.6479272\ttotal: 1m\tremaining: 5.4s\n",
      "4219:\tlearn: 1.6478875\ttotal: 1m\tremaining: 5.39s\n",
      "4220:\tlearn: 1.6478100\ttotal: 1m\tremaining: 5.38s\n",
      "4221:\tlearn: 1.6477037\ttotal: 1m\tremaining: 5.36s\n",
      "4222:\tlearn: 1.6472240\ttotal: 1m\tremaining: 5.35s\n",
      "4223:\tlearn: 1.6469296\ttotal: 1m\tremaining: 5.33s\n",
      "4224:\tlearn: 1.6467767\ttotal: 1m\tremaining: 5.32s\n",
      "4225:\tlearn: 1.6465469\ttotal: 1m\tremaining: 5.3s\n",
      "4226:\tlearn: 1.6463324\ttotal: 1m\tremaining: 5.29s\n",
      "4227:\tlearn: 1.6461442\ttotal: 1m\tremaining: 5.28s\n",
      "4228:\tlearn: 1.6460362\ttotal: 1m\tremaining: 5.26s\n",
      "4229:\tlearn: 1.6459547\ttotal: 1m\tremaining: 5.25s\n",
      "4230:\tlearn: 1.6458158\ttotal: 1m\tremaining: 5.23s\n",
      "4231:\tlearn: 1.6455422\ttotal: 1m\tremaining: 5.22s\n",
      "4232:\tlearn: 1.6454202\ttotal: 1m\tremaining: 5.2s\n",
      "4233:\tlearn: 1.6452937\ttotal: 1m\tremaining: 5.19s\n",
      "4234:\tlearn: 1.6448005\ttotal: 1m\tremaining: 5.17s\n",
      "4235:\tlearn: 1.6447006\ttotal: 1m\tremaining: 5.16s\n",
      "4236:\tlearn: 1.6444685\ttotal: 1m\tremaining: 5.15s\n",
      "4237:\tlearn: 1.6444283\ttotal: 1m\tremaining: 5.13s\n",
      "4238:\tlearn: 1.6439186\ttotal: 1m\tremaining: 5.12s\n",
      "4239:\tlearn: 1.6437002\ttotal: 1m\tremaining: 5.1s\n",
      "4240:\tlearn: 1.6436147\ttotal: 1m\tremaining: 5.09s\n",
      "4241:\tlearn: 1.6434781\ttotal: 1m\tremaining: 5.08s\n",
      "4242:\tlearn: 1.6432051\ttotal: 1m\tremaining: 5.06s\n",
      "4243:\tlearn: 1.6430681\ttotal: 1m\tremaining: 5.05s\n",
      "4244:\tlearn: 1.6429496\ttotal: 1m\tremaining: 5.03s\n",
      "4245:\tlearn: 1.6427173\ttotal: 1m\tremaining: 5.02s\n",
      "4246:\tlearn: 1.6424094\ttotal: 1m\tremaining: 5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4247:\tlearn: 1.6423109\ttotal: 1m\tremaining: 4.99s\n",
      "4248:\tlearn: 1.6419373\ttotal: 1m\tremaining: 4.97s\n",
      "4249:\tlearn: 1.6416803\ttotal: 1m\tremaining: 4.96s\n",
      "4250:\tlearn: 1.6416094\ttotal: 1m\tremaining: 4.95s\n",
      "4251:\tlearn: 1.6414376\ttotal: 1m\tremaining: 4.93s\n",
      "4252:\tlearn: 1.6411529\ttotal: 1m\tremaining: 4.92s\n",
      "4253:\tlearn: 1.6409515\ttotal: 1m\tremaining: 4.9s\n",
      "4254:\tlearn: 1.6406969\ttotal: 1m\tremaining: 4.89s\n",
      "4255:\tlearn: 1.6406241\ttotal: 1m\tremaining: 4.88s\n",
      "4256:\tlearn: 1.6403956\ttotal: 1m\tremaining: 4.86s\n",
      "4257:\tlearn: 1.6402559\ttotal: 1m\tremaining: 4.85s\n",
      "4258:\tlearn: 1.6399969\ttotal: 1m\tremaining: 4.83s\n",
      "4259:\tlearn: 1.6394955\ttotal: 1m\tremaining: 4.82s\n",
      "4260:\tlearn: 1.6393354\ttotal: 1m\tremaining: 4.8s\n",
      "4261:\tlearn: 1.6390283\ttotal: 1m\tremaining: 4.79s\n",
      "4262:\tlearn: 1.6388551\ttotal: 1m\tremaining: 4.78s\n",
      "4263:\tlearn: 1.6386772\ttotal: 1m\tremaining: 4.76s\n",
      "4264:\tlearn: 1.6384700\ttotal: 1m\tremaining: 4.75s\n",
      "4265:\tlearn: 1.6382798\ttotal: 1m\tremaining: 4.73s\n",
      "4266:\tlearn: 1.6381180\ttotal: 1m\tremaining: 4.72s\n",
      "4267:\tlearn: 1.6378304\ttotal: 1m\tremaining: 4.71s\n",
      "4268:\tlearn: 1.6374649\ttotal: 1m\tremaining: 4.69s\n",
      "4269:\tlearn: 1.6371462\ttotal: 1m\tremaining: 4.68s\n",
      "4270:\tlearn: 1.6370005\ttotal: 1m\tremaining: 4.66s\n",
      "4271:\tlearn: 1.6367382\ttotal: 1m\tremaining: 4.65s\n",
      "4272:\tlearn: 1.6364448\ttotal: 1m\tremaining: 4.63s\n",
      "4273:\tlearn: 1.6362369\ttotal: 1m\tremaining: 4.62s\n",
      "4274:\tlearn: 1.6360207\ttotal: 1m\tremaining: 4.61s\n",
      "4275:\tlearn: 1.6358065\ttotal: 1m\tremaining: 4.59s\n",
      "4276:\tlearn: 1.6357017\ttotal: 1m\tremaining: 4.58s\n",
      "4277:\tlearn: 1.6353889\ttotal: 1m 1s\tremaining: 4.56s\n",
      "4278:\tlearn: 1.6351857\ttotal: 1m 1s\tremaining: 4.55s\n",
      "4279:\tlearn: 1.6348888\ttotal: 1m 1s\tremaining: 4.53s\n",
      "4280:\tlearn: 1.6346834\ttotal: 1m 1s\tremaining: 4.52s\n",
      "4281:\tlearn: 1.6342722\ttotal: 1m 1s\tremaining: 4.5s\n",
      "4282:\tlearn: 1.6340283\ttotal: 1m 1s\tremaining: 4.49s\n",
      "4283:\tlearn: 1.6339123\ttotal: 1m 1s\tremaining: 4.48s\n",
      "4284:\tlearn: 1.6337302\ttotal: 1m 1s\tremaining: 4.46s\n",
      "4285:\tlearn: 1.6334731\ttotal: 1m 1s\tremaining: 4.45s\n",
      "4286:\tlearn: 1.6333105\ttotal: 1m 1s\tremaining: 4.43s\n",
      "4287:\tlearn: 1.6330485\ttotal: 1m 1s\tremaining: 4.42s\n",
      "4288:\tlearn: 1.6326722\ttotal: 1m 1s\tremaining: 4.41s\n",
      "4289:\tlearn: 1.6326344\ttotal: 1m 1s\tremaining: 4.39s\n",
      "4290:\tlearn: 1.6325008\ttotal: 1m 1s\tremaining: 4.38s\n",
      "4291:\tlearn: 1.6322307\ttotal: 1m 1s\tremaining: 4.36s\n",
      "4292:\tlearn: 1.6320923\ttotal: 1m 1s\tremaining: 4.35s\n",
      "4293:\tlearn: 1.6319303\ttotal: 1m 1s\tremaining: 4.33s\n",
      "4294:\tlearn: 1.6318213\ttotal: 1m 1s\tremaining: 4.32s\n",
      "4295:\tlearn: 1.6317483\ttotal: 1m 1s\tremaining: 4.31s\n",
      "4296:\tlearn: 1.6315159\ttotal: 1m 1s\tremaining: 4.29s\n",
      "4297:\tlearn: 1.6314152\ttotal: 1m 1s\tremaining: 4.28s\n",
      "4298:\tlearn: 1.6312262\ttotal: 1m 1s\tremaining: 4.26s\n",
      "4299:\tlearn: 1.6309925\ttotal: 1m 1s\tremaining: 4.25s\n",
      "4300:\tlearn: 1.6306998\ttotal: 1m 1s\tremaining: 4.23s\n",
      "4301:\tlearn: 1.6304016\ttotal: 1m 1s\tremaining: 4.22s\n",
      "4302:\tlearn: 1.6301273\ttotal: 1m 1s\tremaining: 4.21s\n",
      "4303:\tlearn: 1.6299460\ttotal: 1m 1s\tremaining: 4.19s\n",
      "4304:\tlearn: 1.6297083\ttotal: 1m 1s\tremaining: 4.18s\n",
      "4305:\tlearn: 1.6294540\ttotal: 1m 1s\tremaining: 4.16s\n",
      "4306:\tlearn: 1.6293991\ttotal: 1m 1s\tremaining: 4.15s\n",
      "4307:\tlearn: 1.6290325\ttotal: 1m 1s\tremaining: 4.13s\n",
      "4308:\tlearn: 1.6289722\ttotal: 1m 1s\tremaining: 4.12s\n",
      "4309:\tlearn: 1.6287765\ttotal: 1m 1s\tremaining: 4.11s\n",
      "4310:\tlearn: 1.6284154\ttotal: 1m 1s\tremaining: 4.09s\n",
      "4311:\tlearn: 1.6282269\ttotal: 1m 1s\tremaining: 4.08s\n",
      "4312:\tlearn: 1.6278648\ttotal: 1m 1s\tremaining: 4.06s\n",
      "4313:\tlearn: 1.6275993\ttotal: 1m 1s\tremaining: 4.05s\n",
      "4314:\tlearn: 1.6274422\ttotal: 1m 1s\tremaining: 4.03s\n",
      "4315:\tlearn: 1.6271882\ttotal: 1m 1s\tremaining: 4.02s\n",
      "4316:\tlearn: 1.6269360\ttotal: 1m 1s\tremaining: 4.01s\n",
      "4317:\tlearn: 1.6267827\ttotal: 1m 1s\tremaining: 3.99s\n",
      "4318:\tlearn: 1.6264950\ttotal: 1m 1s\tremaining: 3.98s\n",
      "4319:\tlearn: 1.6262187\ttotal: 1m 1s\tremaining: 3.96s\n",
      "4320:\tlearn: 1.6260087\ttotal: 1m 1s\tremaining: 3.95s\n",
      "4321:\tlearn: 1.6258676\ttotal: 1m 1s\tremaining: 3.93s\n",
      "4322:\tlearn: 1.6256344\ttotal: 1m 1s\tremaining: 3.92s\n",
      "4323:\tlearn: 1.6254368\ttotal: 1m 1s\tremaining: 3.91s\n",
      "4324:\tlearn: 1.6251095\ttotal: 1m 1s\tremaining: 3.89s\n",
      "4325:\tlearn: 1.6249447\ttotal: 1m 1s\tremaining: 3.88s\n",
      "4326:\tlearn: 1.6247528\ttotal: 1m 1s\tremaining: 3.86s\n",
      "4327:\tlearn: 1.6245669\ttotal: 1m 1s\tremaining: 3.85s\n",
      "4328:\tlearn: 1.6244138\ttotal: 1m 1s\tremaining: 3.83s\n",
      "4329:\tlearn: 1.6242444\ttotal: 1m 1s\tremaining: 3.82s\n",
      "4330:\tlearn: 1.6239357\ttotal: 1m 1s\tremaining: 3.81s\n",
      "4331:\tlearn: 1.6236135\ttotal: 1m 1s\tremaining: 3.79s\n",
      "4332:\tlearn: 1.6235236\ttotal: 1m 1s\tremaining: 3.78s\n",
      "4333:\tlearn: 1.6233390\ttotal: 1m 1s\tremaining: 3.76s\n",
      "4334:\tlearn: 1.6231796\ttotal: 1m 1s\tremaining: 3.75s\n",
      "4335:\tlearn: 1.6229271\ttotal: 1m 1s\tremaining: 3.73s\n",
      "4336:\tlearn: 1.6226941\ttotal: 1m 1s\tremaining: 3.72s\n",
      "4337:\tlearn: 1.6225432\ttotal: 1m 1s\tremaining: 3.71s\n",
      "4338:\tlearn: 1.6223174\ttotal: 1m 1s\tremaining: 3.69s\n",
      "4339:\tlearn: 1.6220868\ttotal: 1m 1s\tremaining: 3.68s\n",
      "4340:\tlearn: 1.6217931\ttotal: 1m 1s\tremaining: 3.66s\n",
      "4341:\tlearn: 1.6215857\ttotal: 1m 1s\tremaining: 3.65s\n",
      "4342:\tlearn: 1.6214385\ttotal: 1m 1s\tremaining: 3.63s\n",
      "4343:\tlearn: 1.6213442\ttotal: 1m 1s\tremaining: 3.62s\n",
      "4344:\tlearn: 1.6210940\ttotal: 1m 1s\tremaining: 3.61s\n",
      "4345:\tlearn: 1.6208341\ttotal: 1m 1s\tremaining: 3.59s\n",
      "4346:\tlearn: 1.6207258\ttotal: 1m 1s\tremaining: 3.58s\n",
      "4347:\tlearn: 1.6205726\ttotal: 1m 1s\tremaining: 3.56s\n",
      "4348:\tlearn: 1.6203406\ttotal: 1m 1s\tremaining: 3.55s\n",
      "4349:\tlearn: 1.6202981\ttotal: 1m 2s\tremaining: 3.54s\n",
      "4350:\tlearn: 1.6201047\ttotal: 1m 2s\tremaining: 3.52s\n",
      "4351:\tlearn: 1.6198978\ttotal: 1m 2s\tremaining: 3.51s\n",
      "4352:\tlearn: 1.6196751\ttotal: 1m 2s\tremaining: 3.49s\n",
      "4353:\tlearn: 1.6194802\ttotal: 1m 2s\tremaining: 3.48s\n",
      "4354:\tlearn: 1.6192345\ttotal: 1m 2s\tremaining: 3.46s\n",
      "4355:\tlearn: 1.6189300\ttotal: 1m 2s\tremaining: 3.45s\n",
      "4356:\tlearn: 1.6185833\ttotal: 1m 2s\tremaining: 3.44s\n",
      "4357:\tlearn: 1.6184888\ttotal: 1m 2s\tremaining: 3.42s\n",
      "4358:\tlearn: 1.6183563\ttotal: 1m 2s\tremaining: 3.41s\n",
      "4359:\tlearn: 1.6181271\ttotal: 1m 2s\tremaining: 3.39s\n",
      "4360:\tlearn: 1.6176478\ttotal: 1m 2s\tremaining: 3.38s\n",
      "4361:\tlearn: 1.6174990\ttotal: 1m 2s\tremaining: 3.36s\n",
      "4362:\tlearn: 1.6173307\ttotal: 1m 2s\tremaining: 3.35s\n",
      "4363:\tlearn: 1.6171612\ttotal: 1m 2s\tremaining: 3.33s\n",
      "4364:\tlearn: 1.6167156\ttotal: 1m 2s\tremaining: 3.32s\n",
      "4365:\tlearn: 1.6166569\ttotal: 1m 2s\tremaining: 3.31s\n",
      "4366:\tlearn: 1.6164613\ttotal: 1m 2s\tremaining: 3.29s\n",
      "4367:\tlearn: 1.6162060\ttotal: 1m 2s\tremaining: 3.28s\n",
      "4368:\tlearn: 1.6159439\ttotal: 1m 2s\tremaining: 3.26s\n",
      "4369:\tlearn: 1.6157119\ttotal: 1m 2s\tremaining: 3.25s\n",
      "4370:\tlearn: 1.6154647\ttotal: 1m 2s\tremaining: 3.23s\n",
      "4371:\tlearn: 1.6152360\ttotal: 1m 2s\tremaining: 3.22s\n",
      "4372:\tlearn: 1.6150817\ttotal: 1m 2s\tremaining: 3.21s\n",
      "4373:\tlearn: 1.6147804\ttotal: 1m 2s\tremaining: 3.19s\n",
      "4374:\tlearn: 1.6143940\ttotal: 1m 2s\tremaining: 3.18s\n",
      "4375:\tlearn: 1.6142642\ttotal: 1m 2s\tremaining: 3.16s\n",
      "4376:\tlearn: 1.6141897\ttotal: 1m 2s\tremaining: 3.15s\n",
      "4377:\tlearn: 1.6140537\ttotal: 1m 2s\tremaining: 3.14s\n",
      "4378:\tlearn: 1.6136280\ttotal: 1m 2s\tremaining: 3.12s\n",
      "4379:\tlearn: 1.6134585\ttotal: 1m 2s\tremaining: 3.11s\n",
      "4380:\tlearn: 1.6130691\ttotal: 1m 2s\tremaining: 3.09s\n",
      "4381:\tlearn: 1.6127853\ttotal: 1m 2s\tremaining: 3.08s\n",
      "4382:\tlearn: 1.6125313\ttotal: 1m 2s\tremaining: 3.06s\n",
      "4383:\tlearn: 1.6124539\ttotal: 1m 2s\tremaining: 3.05s\n",
      "4384:\tlearn: 1.6121828\ttotal: 1m 2s\tremaining: 3.04s\n",
      "4385:\tlearn: 1.6118553\ttotal: 1m 2s\tremaining: 3.02s\n",
      "4386:\tlearn: 1.6115426\ttotal: 1m 2s\tremaining: 3.01s\n",
      "4387:\tlearn: 1.6113495\ttotal: 1m 2s\tremaining: 2.99s\n",
      "4388:\tlearn: 1.6111411\ttotal: 1m 2s\tremaining: 2.98s\n",
      "4389:\tlearn: 1.6110258\ttotal: 1m 2s\tremaining: 2.96s\n",
      "4390:\tlearn: 1.6108510\ttotal: 1m 2s\tremaining: 2.95s\n",
      "4391:\tlearn: 1.6106310\ttotal: 1m 2s\tremaining: 2.94s\n",
      "4392:\tlearn: 1.6105215\ttotal: 1m 2s\tremaining: 2.92s\n",
      "4393:\tlearn: 1.6103226\ttotal: 1m 2s\tremaining: 2.91s\n",
      "4394:\tlearn: 1.6101201\ttotal: 1m 2s\tremaining: 2.89s\n",
      "4395:\tlearn: 1.6099579\ttotal: 1m 2s\tremaining: 2.88s\n",
      "4396:\tlearn: 1.6097472\ttotal: 1m 2s\tremaining: 2.87s\n",
      "4397:\tlearn: 1.6095286\ttotal: 1m 2s\tremaining: 2.85s\n",
      "4398:\tlearn: 1.6094059\ttotal: 1m 2s\tremaining: 2.84s\n",
      "4399:\tlearn: 1.6092303\ttotal: 1m 2s\tremaining: 2.82s\n",
      "4400:\tlearn: 1.6091055\ttotal: 1m 2s\tremaining: 2.81s\n",
      "4401:\tlearn: 1.6088837\ttotal: 1m 2s\tremaining: 2.79s\n",
      "4402:\tlearn: 1.6086693\ttotal: 1m 2s\tremaining: 2.78s\n",
      "4403:\tlearn: 1.6084717\ttotal: 1m 2s\tremaining: 2.77s\n",
      "4404:\tlearn: 1.6082805\ttotal: 1m 2s\tremaining: 2.75s\n",
      "4405:\tlearn: 1.6081871\ttotal: 1m 2s\tremaining: 2.74s\n",
      "4406:\tlearn: 1.6079889\ttotal: 1m 2s\tremaining: 2.72s\n",
      "4407:\tlearn: 1.6077273\ttotal: 1m 2s\tremaining: 2.71s\n",
      "4408:\tlearn: 1.6075302\ttotal: 1m 2s\tremaining: 2.69s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4409:\tlearn: 1.6073905\ttotal: 1m 2s\tremaining: 2.68s\n",
      "4410:\tlearn: 1.6072433\ttotal: 1m 2s\tremaining: 2.67s\n",
      "4411:\tlearn: 1.6070446\ttotal: 1m 2s\tremaining: 2.65s\n",
      "4412:\tlearn: 1.6067626\ttotal: 1m 2s\tremaining: 2.64s\n",
      "4413:\tlearn: 1.6066849\ttotal: 1m 2s\tremaining: 2.62s\n",
      "4414:\tlearn: 1.6063984\ttotal: 1m 2s\tremaining: 2.61s\n",
      "4415:\tlearn: 1.6062692\ttotal: 1m 2s\tremaining: 2.59s\n",
      "4416:\tlearn: 1.6061638\ttotal: 1m 2s\tremaining: 2.58s\n",
      "4417:\tlearn: 1.6060593\ttotal: 1m 2s\tremaining: 2.56s\n",
      "4418:\tlearn: 1.6059111\ttotal: 1m 2s\tremaining: 2.55s\n",
      "4419:\tlearn: 1.6058659\ttotal: 1m 2s\tremaining: 2.54s\n",
      "4420:\tlearn: 1.6054765\ttotal: 1m 3s\tremaining: 2.52s\n",
      "4421:\tlearn: 1.6052389\ttotal: 1m 3s\tremaining: 2.51s\n",
      "4422:\tlearn: 1.6049786\ttotal: 1m 3s\tremaining: 2.49s\n",
      "4423:\tlearn: 1.6047966\ttotal: 1m 3s\tremaining: 2.48s\n",
      "4424:\tlearn: 1.6045531\ttotal: 1m 3s\tremaining: 2.46s\n",
      "4425:\tlearn: 1.6042360\ttotal: 1m 3s\tremaining: 2.45s\n",
      "4426:\tlearn: 1.6039468\ttotal: 1m 3s\tremaining: 2.44s\n",
      "4427:\tlearn: 1.6036485\ttotal: 1m 3s\tremaining: 2.42s\n",
      "4428:\tlearn: 1.6034676\ttotal: 1m 3s\tremaining: 2.41s\n",
      "4429:\tlearn: 1.6032949\ttotal: 1m 3s\tremaining: 2.39s\n",
      "4430:\tlearn: 1.6030418\ttotal: 1m 3s\tremaining: 2.38s\n",
      "4431:\tlearn: 1.6027671\ttotal: 1m 3s\tremaining: 2.37s\n",
      "4432:\tlearn: 1.6027030\ttotal: 1m 3s\tremaining: 2.35s\n",
      "4433:\tlearn: 1.6024767\ttotal: 1m 3s\tremaining: 2.34s\n",
      "4434:\tlearn: 1.6021325\ttotal: 1m 3s\tremaining: 2.32s\n",
      "4435:\tlearn: 1.6019247\ttotal: 1m 3s\tremaining: 2.31s\n",
      "4436:\tlearn: 1.6017796\ttotal: 1m 3s\tremaining: 2.29s\n",
      "4437:\tlearn: 1.6015944\ttotal: 1m 3s\tremaining: 2.28s\n",
      "4438:\tlearn: 1.6014853\ttotal: 1m 3s\tremaining: 2.27s\n",
      "4439:\tlearn: 1.6011959\ttotal: 1m 3s\tremaining: 2.25s\n",
      "4440:\tlearn: 1.6010524\ttotal: 1m 3s\tremaining: 2.24s\n",
      "4441:\tlearn: 1.6008303\ttotal: 1m 3s\tremaining: 2.22s\n",
      "4442:\tlearn: 1.6003810\ttotal: 1m 3s\tremaining: 2.21s\n",
      "4443:\tlearn: 1.6002848\ttotal: 1m 3s\tremaining: 2.19s\n",
      "4444:\tlearn: 1.6001968\ttotal: 1m 3s\tremaining: 2.18s\n",
      "4445:\tlearn: 1.6000282\ttotal: 1m 3s\tremaining: 2.17s\n",
      "4446:\tlearn: 1.5997726\ttotal: 1m 3s\tremaining: 2.15s\n",
      "4447:\tlearn: 1.5997069\ttotal: 1m 3s\tremaining: 2.14s\n",
      "4448:\tlearn: 1.5994143\ttotal: 1m 3s\tremaining: 2.12s\n",
      "4449:\tlearn: 1.5992621\ttotal: 1m 3s\tremaining: 2.11s\n",
      "4450:\tlearn: 1.5991906\ttotal: 1m 3s\tremaining: 2.1s\n",
      "4451:\tlearn: 1.5989942\ttotal: 1m 3s\tremaining: 2.08s\n",
      "4452:\tlearn: 1.5985928\ttotal: 1m 3s\tremaining: 2.07s\n",
      "4453:\tlearn: 1.5983966\ttotal: 1m 3s\tremaining: 2.05s\n",
      "4454:\tlearn: 1.5982703\ttotal: 1m 3s\tremaining: 2.04s\n",
      "4455:\tlearn: 1.5982040\ttotal: 1m 3s\tremaining: 2.02s\n",
      "4456:\tlearn: 1.5980111\ttotal: 1m 3s\tremaining: 2.01s\n",
      "4457:\tlearn: 1.5978787\ttotal: 1m 3s\tremaining: 2s\n",
      "4458:\tlearn: 1.5976784\ttotal: 1m 3s\tremaining: 1.98s\n",
      "4459:\tlearn: 1.5973070\ttotal: 1m 3s\tremaining: 1.97s\n",
      "4460:\tlearn: 1.5971461\ttotal: 1m 3s\tremaining: 1.95s\n",
      "4461:\tlearn: 1.5967640\ttotal: 1m 3s\tremaining: 1.94s\n",
      "4462:\tlearn: 1.5965611\ttotal: 1m 3s\tremaining: 1.93s\n",
      "4463:\tlearn: 1.5963363\ttotal: 1m 3s\tremaining: 1.91s\n",
      "4464:\tlearn: 1.5960214\ttotal: 1m 3s\tremaining: 1.9s\n",
      "4465:\tlearn: 1.5958651\ttotal: 1m 3s\tremaining: 1.88s\n",
      "4466:\tlearn: 1.5955208\ttotal: 1m 3s\tremaining: 1.87s\n",
      "4467:\tlearn: 1.5954372\ttotal: 1m 3s\tremaining: 1.85s\n",
      "4468:\tlearn: 1.5952515\ttotal: 1m 3s\tremaining: 1.84s\n",
      "4469:\tlearn: 1.5950677\ttotal: 1m 3s\tremaining: 1.83s\n",
      "4470:\tlearn: 1.5949093\ttotal: 1m 3s\tremaining: 1.81s\n",
      "4471:\tlearn: 1.5947718\ttotal: 1m 3s\tremaining: 1.8s\n",
      "4472:\tlearn: 1.5944718\ttotal: 1m 3s\tremaining: 1.78s\n",
      "4473:\tlearn: 1.5943131\ttotal: 1m 3s\tremaining: 1.77s\n",
      "4474:\tlearn: 1.5940713\ttotal: 1m 3s\tremaining: 1.75s\n",
      "4475:\tlearn: 1.5939722\ttotal: 1m 3s\tremaining: 1.74s\n",
      "4476:\tlearn: 1.5939100\ttotal: 1m 3s\tremaining: 1.73s\n",
      "4477:\tlearn: 1.5936753\ttotal: 1m 3s\tremaining: 1.71s\n",
      "4478:\tlearn: 1.5934844\ttotal: 1m 3s\tremaining: 1.7s\n",
      "4479:\tlearn: 1.5931057\ttotal: 1m 3s\tremaining: 1.68s\n",
      "4480:\tlearn: 1.5929451\ttotal: 1m 3s\tremaining: 1.67s\n",
      "4481:\tlearn: 1.5927366\ttotal: 1m 3s\tremaining: 1.66s\n",
      "4482:\tlearn: 1.5924487\ttotal: 1m 3s\tremaining: 1.64s\n",
      "4483:\tlearn: 1.5922518\ttotal: 1m 3s\tremaining: 1.63s\n",
      "4484:\tlearn: 1.5920807\ttotal: 1m 3s\tremaining: 1.61s\n",
      "4485:\tlearn: 1.5919424\ttotal: 1m 4s\tremaining: 1.6s\n",
      "4486:\tlearn: 1.5916772\ttotal: 1m 4s\tremaining: 1.58s\n",
      "4487:\tlearn: 1.5915090\ttotal: 1m 4s\tremaining: 1.57s\n",
      "4488:\tlearn: 1.5913242\ttotal: 1m 4s\tremaining: 1.55s\n",
      "4489:\tlearn: 1.5910962\ttotal: 1m 4s\tremaining: 1.54s\n",
      "4490:\tlearn: 1.5909118\ttotal: 1m 4s\tremaining: 1.53s\n",
      "4491:\tlearn: 1.5907238\ttotal: 1m 4s\tremaining: 1.51s\n",
      "4492:\tlearn: 1.5905680\ttotal: 1m 4s\tremaining: 1.5s\n",
      "4493:\tlearn: 1.5903547\ttotal: 1m 4s\tremaining: 1.48s\n",
      "4494:\tlearn: 1.5901861\ttotal: 1m 4s\tremaining: 1.47s\n",
      "4495:\tlearn: 1.5901081\ttotal: 1m 4s\tremaining: 1.46s\n",
      "4496:\tlearn: 1.5899702\ttotal: 1m 4s\tremaining: 1.44s\n",
      "4497:\tlearn: 1.5897006\ttotal: 1m 4s\tremaining: 1.43s\n",
      "4498:\tlearn: 1.5895756\ttotal: 1m 4s\tremaining: 1.41s\n",
      "4499:\tlearn: 1.5892442\ttotal: 1m 4s\tremaining: 1.4s\n",
      "4500:\tlearn: 1.5891874\ttotal: 1m 4s\tremaining: 1.38s\n",
      "4501:\tlearn: 1.5889858\ttotal: 1m 4s\tremaining: 1.37s\n",
      "4502:\tlearn: 1.5886782\ttotal: 1m 4s\tremaining: 1.35s\n",
      "4503:\tlearn: 1.5883217\ttotal: 1m 4s\tremaining: 1.34s\n",
      "4504:\tlearn: 1.5880098\ttotal: 1m 4s\tremaining: 1.33s\n",
      "4505:\tlearn: 1.5878779\ttotal: 1m 4s\tremaining: 1.31s\n",
      "4506:\tlearn: 1.5876914\ttotal: 1m 4s\tremaining: 1.3s\n",
      "4507:\tlearn: 1.5875188\ttotal: 1m 4s\tremaining: 1.28s\n",
      "4508:\tlearn: 1.5873186\ttotal: 1m 4s\tremaining: 1.27s\n",
      "4509:\tlearn: 1.5872149\ttotal: 1m 4s\tremaining: 1.25s\n",
      "4510:\tlearn: 1.5868860\ttotal: 1m 4s\tremaining: 1.24s\n",
      "4511:\tlearn: 1.5867965\ttotal: 1m 4s\tremaining: 1.23s\n",
      "4512:\tlearn: 1.5866278\ttotal: 1m 4s\tremaining: 1.21s\n",
      "4513:\tlearn: 1.5864505\ttotal: 1m 4s\tremaining: 1.2s\n",
      "4514:\tlearn: 1.5858621\ttotal: 1m 4s\tremaining: 1.18s\n",
      "4515:\tlearn: 1.5856613\ttotal: 1m 4s\tremaining: 1.17s\n",
      "4516:\tlearn: 1.5854509\ttotal: 1m 4s\tremaining: 1.16s\n",
      "4517:\tlearn: 1.5853078\ttotal: 1m 4s\tremaining: 1.14s\n",
      "4518:\tlearn: 1.5852651\ttotal: 1m 4s\tremaining: 1.13s\n",
      "4519:\tlearn: 1.5851736\ttotal: 1m 4s\tremaining: 1.11s\n",
      "4520:\tlearn: 1.5850498\ttotal: 1m 4s\tremaining: 1.1s\n",
      "4521:\tlearn: 1.5849216\ttotal: 1m 4s\tremaining: 1.08s\n",
      "4522:\tlearn: 1.5847810\ttotal: 1m 4s\tremaining: 1.07s\n",
      "4523:\tlearn: 1.5845687\ttotal: 1m 4s\tremaining: 1.05s\n",
      "4524:\tlearn: 1.5843767\ttotal: 1m 4s\tremaining: 1.04s\n",
      "4525:\tlearn: 1.5842237\ttotal: 1m 4s\tremaining: 1.03s\n",
      "4526:\tlearn: 1.5841008\ttotal: 1m 4s\tremaining: 1.01s\n",
      "4527:\tlearn: 1.5838408\ttotal: 1m 4s\tremaining: 999ms\n",
      "4528:\tlearn: 1.5835840\ttotal: 1m 4s\tremaining: 984ms\n",
      "4529:\tlearn: 1.5835144\ttotal: 1m 4s\tremaining: 970ms\n",
      "4530:\tlearn: 1.5832152\ttotal: 1m 4s\tremaining: 956ms\n",
      "4531:\tlearn: 1.5830214\ttotal: 1m 4s\tremaining: 942ms\n",
      "4532:\tlearn: 1.5828025\ttotal: 1m 4s\tremaining: 927ms\n",
      "4533:\tlearn: 1.5826721\ttotal: 1m 4s\tremaining: 913ms\n",
      "4534:\tlearn: 1.5826310\ttotal: 1m 4s\tremaining: 899ms\n",
      "4535:\tlearn: 1.5824845\ttotal: 1m 4s\tremaining: 885ms\n",
      "4536:\tlearn: 1.5821798\ttotal: 1m 4s\tremaining: 870ms\n",
      "4537:\tlearn: 1.5818537\ttotal: 1m 4s\tremaining: 856ms\n",
      "4538:\tlearn: 1.5815548\ttotal: 1m 4s\tremaining: 842ms\n",
      "4539:\tlearn: 1.5814189\ttotal: 1m 4s\tremaining: 827ms\n",
      "4540:\tlearn: 1.5813052\ttotal: 1m 4s\tremaining: 813ms\n",
      "4541:\tlearn: 1.5810575\ttotal: 1m 4s\tremaining: 799ms\n",
      "4542:\tlearn: 1.5809496\ttotal: 1m 4s\tremaining: 785ms\n",
      "4543:\tlearn: 1.5808224\ttotal: 1m 4s\tremaining: 770ms\n",
      "4544:\tlearn: 1.5807353\ttotal: 1m 4s\tremaining: 756ms\n",
      "4545:\tlearn: 1.5803963\ttotal: 1m 4s\tremaining: 742ms\n",
      "4546:\tlearn: 1.5801762\ttotal: 1m 4s\tremaining: 728ms\n",
      "4547:\tlearn: 1.5800007\ttotal: 1m 4s\tremaining: 713ms\n",
      "4548:\tlearn: 1.5797551\ttotal: 1m 4s\tremaining: 699ms\n",
      "4549:\tlearn: 1.5797203\ttotal: 1m 4s\tremaining: 685ms\n",
      "4550:\tlearn: 1.5795766\ttotal: 1m 4s\tremaining: 671ms\n",
      "4551:\tlearn: 1.5794160\ttotal: 1m 4s\tremaining: 656ms\n",
      "4552:\tlearn: 1.5792446\ttotal: 1m 4s\tremaining: 642ms\n",
      "4553:\tlearn: 1.5791795\ttotal: 1m 4s\tremaining: 628ms\n",
      "4554:\tlearn: 1.5791377\ttotal: 1m 4s\tremaining: 613ms\n",
      "4555:\tlearn: 1.5789782\ttotal: 1m 4s\tremaining: 599ms\n",
      "4556:\tlearn: 1.5787908\ttotal: 1m 5s\tremaining: 585ms\n",
      "4557:\tlearn: 1.5786248\ttotal: 1m 5s\tremaining: 571ms\n",
      "4558:\tlearn: 1.5783908\ttotal: 1m 5s\tremaining: 556ms\n",
      "4559:\tlearn: 1.5781195\ttotal: 1m 5s\tremaining: 542ms\n",
      "4560:\tlearn: 1.5779634\ttotal: 1m 5s\tremaining: 528ms\n",
      "4561:\tlearn: 1.5776949\ttotal: 1m 5s\tremaining: 514ms\n",
      "4562:\tlearn: 1.5775843\ttotal: 1m 5s\tremaining: 499ms\n",
      "4563:\tlearn: 1.5772249\ttotal: 1m 5s\tremaining: 485ms\n",
      "4564:\tlearn: 1.5770166\ttotal: 1m 5s\tremaining: 471ms\n",
      "4565:\tlearn: 1.5768875\ttotal: 1m 5s\tremaining: 457ms\n",
      "4566:\tlearn: 1.5767622\ttotal: 1m 5s\tremaining: 442ms\n",
      "4567:\tlearn: 1.5762586\ttotal: 1m 5s\tremaining: 428ms\n",
      "4568:\tlearn: 1.5761300\ttotal: 1m 5s\tremaining: 414ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4569:\tlearn: 1.5760537\ttotal: 1m 5s\tremaining: 399ms\n",
      "4570:\tlearn: 1.5759156\ttotal: 1m 5s\tremaining: 385ms\n",
      "4571:\tlearn: 1.5758441\ttotal: 1m 5s\tremaining: 371ms\n",
      "4572:\tlearn: 1.5756406\ttotal: 1m 5s\tremaining: 357ms\n",
      "4573:\tlearn: 1.5753982\ttotal: 1m 5s\tremaining: 342ms\n",
      "4574:\tlearn: 1.5751911\ttotal: 1m 5s\tremaining: 328ms\n",
      "4575:\tlearn: 1.5750996\ttotal: 1m 5s\tremaining: 314ms\n",
      "4576:\tlearn: 1.5748777\ttotal: 1m 5s\tremaining: 300ms\n",
      "4577:\tlearn: 1.5747468\ttotal: 1m 5s\tremaining: 285ms\n",
      "4578:\tlearn: 1.5745124\ttotal: 1m 5s\tremaining: 271ms\n",
      "4579:\tlearn: 1.5743979\ttotal: 1m 5s\tremaining: 257ms\n",
      "4580:\tlearn: 1.5742174\ttotal: 1m 5s\tremaining: 243ms\n",
      "4581:\tlearn: 1.5739079\ttotal: 1m 5s\tremaining: 228ms\n",
      "4582:\tlearn: 1.5737286\ttotal: 1m 5s\tremaining: 214ms\n",
      "4583:\tlearn: 1.5734663\ttotal: 1m 5s\tremaining: 200ms\n",
      "4584:\tlearn: 1.5732721\ttotal: 1m 5s\tremaining: 185ms\n",
      "4585:\tlearn: 1.5730172\ttotal: 1m 5s\tremaining: 171ms\n",
      "4586:\tlearn: 1.5729323\ttotal: 1m 5s\tremaining: 157ms\n",
      "4587:\tlearn: 1.5726523\ttotal: 1m 5s\tremaining: 143ms\n",
      "4588:\tlearn: 1.5724804\ttotal: 1m 5s\tremaining: 128ms\n",
      "4589:\tlearn: 1.5723421\ttotal: 1m 5s\tremaining: 114ms\n",
      "4590:\tlearn: 1.5719744\ttotal: 1m 5s\tremaining: 99.9ms\n",
      "4591:\tlearn: 1.5718458\ttotal: 1m 5s\tremaining: 85.6ms\n",
      "4592:\tlearn: 1.5717378\ttotal: 1m 5s\tremaining: 71.3ms\n",
      "4593:\tlearn: 1.5715330\ttotal: 1m 5s\tremaining: 57.1ms\n",
      "4594:\tlearn: 1.5712991\ttotal: 1m 5s\tremaining: 42.8ms\n",
      "4595:\tlearn: 1.5710459\ttotal: 1m 5s\tremaining: 28.5ms\n",
      "4596:\tlearn: 1.5708724\ttotal: 1m 5s\tremaining: 14.3ms\n",
      "4597:\tlearn: 1.5706667\ttotal: 1m 5s\tremaining: 0us\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 337\n",
      "[LightGBM] [Info] Number of data points in the train set: 63374, number of used features: 54\n",
      "[LightGBM] [Info] Start training from score 8.848466\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 342\n",
      "[LightGBM] [Info] Number of data points in the train set: 63374, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 8.409162\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 346\n",
      "[LightGBM] [Info] Number of data points in the train set: 63374, number of used features: 54\n",
      "[LightGBM] [Info] Start training from score 10.510467\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 329\n",
      "[LightGBM] [Info] Number of data points in the train set: 63375, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 10.969636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Using too small ``bin_construct_sample_cnt`` may encounter unexpected errors and poor accuracy.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002818 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 321\n",
      "[LightGBM] [Info] Number of data points in the train set: 63375, number of used features: 45\n",
      "[LightGBM] [Info] Start training from score 10.882431\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "0:\tlearn: 8.1763373\ttotal: 16.3ms\tremaining: 16.3s\n",
      "1:\tlearn: 7.5836425\ttotal: 32.9ms\tremaining: 16.4s\n",
      "2:\tlearn: 7.0461478\ttotal: 50.1ms\tremaining: 16.7s\n",
      "3:\tlearn: 6.5649757\ttotal: 68.5ms\tremaining: 17s\n",
      "4:\tlearn: 6.0332550\ttotal: 88.8ms\tremaining: 17.7s\n",
      "5:\tlearn: 5.6687886\ttotal: 105ms\tremaining: 17.5s\n",
      "6:\tlearn: 5.2329079\ttotal: 122ms\tremaining: 17.4s\n",
      "7:\tlearn: 4.8376908\ttotal: 139ms\tremaining: 17.3s\n",
      "8:\tlearn: 4.4638830\ttotal: 155ms\tremaining: 17.1s\n",
      "9:\tlearn: 4.1391092\ttotal: 172ms\tremaining: 17s\n",
      "10:\tlearn: 3.8550104\ttotal: 188ms\tremaining: 16.9s\n",
      "11:\tlearn: 3.6660284\ttotal: 205ms\tremaining: 16.9s\n",
      "12:\tlearn: 3.4243658\ttotal: 221ms\tremaining: 16.7s\n",
      "13:\tlearn: 3.2266809\ttotal: 236ms\tremaining: 16.7s\n",
      "14:\tlearn: 3.0466553\ttotal: 253ms\tremaining: 16.6s\n",
      "15:\tlearn: 2.9363339\ttotal: 269ms\tremaining: 16.6s\n",
      "16:\tlearn: 2.8463279\ttotal: 285ms\tremaining: 16.5s\n",
      "17:\tlearn: 2.7227787\ttotal: 301ms\tremaining: 16.4s\n",
      "18:\tlearn: 2.6508875\ttotal: 318ms\tremaining: 16.4s\n",
      "19:\tlearn: 2.5392880\ttotal: 334ms\tremaining: 16.4s\n",
      "20:\tlearn: 2.4889679\ttotal: 350ms\tremaining: 16.3s\n",
      "21:\tlearn: 2.4422827\ttotal: 366ms\tremaining: 16.3s\n",
      "22:\tlearn: 2.4000894\ttotal: 383ms\tremaining: 16.2s\n",
      "23:\tlearn: 2.3319366\ttotal: 399ms\tremaining: 16.2s\n",
      "24:\tlearn: 2.2711496\ttotal: 415ms\tremaining: 16.2s\n",
      "25:\tlearn: 2.2164356\ttotal: 432ms\tremaining: 16.2s\n",
      "26:\tlearn: 2.1930910\ttotal: 447ms\tremaining: 16.1s\n",
      "27:\tlearn: 2.1665237\ttotal: 463ms\tremaining: 16.1s\n",
      "28:\tlearn: 2.1475267\ttotal: 479ms\tremaining: 16s\n",
      "29:\tlearn: 2.1130382\ttotal: 495ms\tremaining: 16s\n",
      "30:\tlearn: 2.0712086\ttotal: 511ms\tremaining: 16s\n",
      "31:\tlearn: 2.0572371\ttotal: 526ms\tremaining: 15.9s\n",
      "32:\tlearn: 2.0264774\ttotal: 544ms\tremaining: 16s\n",
      "33:\tlearn: 1.9984197\ttotal: 561ms\tremaining: 15.9s\n",
      "34:\tlearn: 1.9878476\ttotal: 577ms\tremaining: 15.9s\n",
      "35:\tlearn: 1.9791812\ttotal: 592ms\tremaining: 15.9s\n",
      "36:\tlearn: 1.9635189\ttotal: 608ms\tremaining: 15.8s\n",
      "37:\tlearn: 1.9517677\ttotal: 623ms\tremaining: 15.8s\n",
      "38:\tlearn: 1.9421914\ttotal: 638ms\tremaining: 15.7s\n",
      "39:\tlearn: 1.9405267\ttotal: 653ms\tremaining: 15.7s\n",
      "40:\tlearn: 1.9322093\ttotal: 668ms\tremaining: 15.6s\n",
      "41:\tlearn: 1.9194211\ttotal: 683ms\tremaining: 15.6s\n",
      "42:\tlearn: 1.9136387\ttotal: 697ms\tremaining: 15.5s\n",
      "43:\tlearn: 1.9101871\ttotal: 713ms\tremaining: 15.5s\n",
      "44:\tlearn: 1.9079664\ttotal: 728ms\tremaining: 15.4s\n",
      "45:\tlearn: 1.9051864\ttotal: 743ms\tremaining: 15.4s\n",
      "46:\tlearn: 1.8986454\ttotal: 760ms\tremaining: 15.4s\n",
      "47:\tlearn: 1.8948776\ttotal: 776ms\tremaining: 15.4s\n",
      "48:\tlearn: 1.8910938\ttotal: 792ms\tremaining: 15.4s\n",
      "49:\tlearn: 1.8888906\ttotal: 806ms\tremaining: 15.3s\n",
      "50:\tlearn: 1.8871133\ttotal: 821ms\tremaining: 15.3s\n",
      "51:\tlearn: 1.8846107\ttotal: 836ms\tremaining: 15.2s\n",
      "52:\tlearn: 1.8817426\ttotal: 851ms\tremaining: 15.2s\n",
      "53:\tlearn: 1.8804745\ttotal: 866ms\tremaining: 15.2s\n",
      "54:\tlearn: 1.8729157\ttotal: 880ms\tremaining: 15.1s\n",
      "55:\tlearn: 1.8613128\ttotal: 896ms\tremaining: 15.1s\n",
      "56:\tlearn: 1.8580366\ttotal: 912ms\tremaining: 15.1s\n",
      "57:\tlearn: 1.8572932\ttotal: 928ms\tremaining: 15.1s\n",
      "58:\tlearn: 1.8570772\ttotal: 942ms\tremaining: 15s\n",
      "59:\tlearn: 1.8559343\ttotal: 957ms\tremaining: 15s\n",
      "60:\tlearn: 1.8557464\ttotal: 973ms\tremaining: 15s\n",
      "61:\tlearn: 1.8550094\ttotal: 989ms\tremaining: 15s\n",
      "62:\tlearn: 1.8453168\ttotal: 1s\tremaining: 14.9s\n",
      "63:\tlearn: 1.8436991\ttotal: 1.02s\tremaining: 14.9s\n",
      "64:\tlearn: 1.8432293\ttotal: 1.03s\tremaining: 14.8s\n",
      "65:\tlearn: 1.8424969\ttotal: 1.04s\tremaining: 14.8s\n",
      "66:\tlearn: 1.8418318\ttotal: 1.06s\tremaining: 14.7s\n",
      "67:\tlearn: 1.8389614\ttotal: 1.07s\tremaining: 14.7s\n",
      "68:\tlearn: 1.8383194\ttotal: 1.08s\tremaining: 14.6s\n",
      "69:\tlearn: 1.8369019\ttotal: 1.1s\tremaining: 14.6s\n",
      "70:\tlearn: 1.8365826\ttotal: 1.11s\tremaining: 14.5s\n",
      "71:\tlearn: 1.8364750\ttotal: 1.12s\tremaining: 14.5s\n",
      "72:\tlearn: 1.8358158\ttotal: 1.14s\tremaining: 14.4s\n",
      "73:\tlearn: 1.8353055\ttotal: 1.15s\tremaining: 14.4s\n",
      "74:\tlearn: 1.8348008\ttotal: 1.16s\tremaining: 14.3s\n",
      "75:\tlearn: 1.8333896\ttotal: 1.18s\tremaining: 14.3s\n",
      "76:\tlearn: 1.8322245\ttotal: 1.19s\tremaining: 14.3s\n",
      "77:\tlearn: 1.8319302\ttotal: 1.21s\tremaining: 14.3s\n",
      "78:\tlearn: 1.8310917\ttotal: 1.22s\tremaining: 14.2s\n",
      "79:\tlearn: 1.8303461\ttotal: 1.23s\tremaining: 14.2s\n",
      "80:\tlearn: 1.8277953\ttotal: 1.25s\tremaining: 14.2s\n",
      "81:\tlearn: 1.8268455\ttotal: 1.26s\tremaining: 14.1s\n",
      "82:\tlearn: 1.8263264\ttotal: 1.27s\tremaining: 14.1s\n",
      "83:\tlearn: 1.8260386\ttotal: 1.29s\tremaining: 14s\n",
      "84:\tlearn: 1.8213846\ttotal: 1.3s\tremaining: 14s\n",
      "85:\tlearn: 1.8211084\ttotal: 1.31s\tremaining: 14s\n",
      "86:\tlearn: 1.8208848\ttotal: 1.33s\tremaining: 13.9s\n",
      "87:\tlearn: 1.8198992\ttotal: 1.34s\tremaining: 13.9s\n",
      "88:\tlearn: 1.8188455\ttotal: 1.35s\tremaining: 13.9s\n",
      "89:\tlearn: 1.8175407\ttotal: 1.37s\tremaining: 13.8s\n",
      "90:\tlearn: 1.8173503\ttotal: 1.38s\tremaining: 13.8s\n",
      "91:\tlearn: 1.8167180\ttotal: 1.4s\tremaining: 13.8s\n",
      "92:\tlearn: 1.8167146\ttotal: 1.41s\tremaining: 13.7s\n",
      "93:\tlearn: 1.8159614\ttotal: 1.42s\tremaining: 13.7s\n",
      "94:\tlearn: 1.8156456\ttotal: 1.43s\tremaining: 13.7s\n",
      "95:\tlearn: 1.8156305\ttotal: 1.45s\tremaining: 13.6s\n",
      "96:\tlearn: 1.8144875\ttotal: 1.46s\tremaining: 13.6s\n",
      "97:\tlearn: 1.8138491\ttotal: 1.48s\tremaining: 13.6s\n",
      "98:\tlearn: 1.8079010\ttotal: 1.49s\tremaining: 13.5s\n",
      "99:\tlearn: 1.8077337\ttotal: 1.5s\tremaining: 13.5s\n",
      "100:\tlearn: 1.8072877\ttotal: 1.51s\tremaining: 13.5s\n",
      "101:\tlearn: 1.8056487\ttotal: 1.53s\tremaining: 13.4s\n",
      "102:\tlearn: 1.8031277\ttotal: 1.54s\tremaining: 13.4s\n",
      "103:\tlearn: 1.7951203\ttotal: 1.55s\tremaining: 13.4s\n",
      "104:\tlearn: 1.7945629\ttotal: 1.57s\tremaining: 13.4s\n",
      "105:\tlearn: 1.7937082\ttotal: 1.58s\tremaining: 13.4s\n",
      "106:\tlearn: 1.7936835\ttotal: 1.6s\tremaining: 13.3s\n",
      "107:\tlearn: 1.7934366\ttotal: 1.61s\tremaining: 13.3s\n",
      "108:\tlearn: 1.7913378\ttotal: 1.63s\tremaining: 13.3s\n",
      "109:\tlearn: 1.7911889\ttotal: 1.64s\tremaining: 13.3s\n",
      "110:\tlearn: 1.7854528\ttotal: 1.65s\tremaining: 13.2s\n",
      "111:\tlearn: 1.7850924\ttotal: 1.67s\tremaining: 13.2s\n",
      "112:\tlearn: 1.7845209\ttotal: 1.68s\tremaining: 13.2s\n",
      "113:\tlearn: 1.7844059\ttotal: 1.69s\tremaining: 13.1s\n",
      "114:\tlearn: 1.7839212\ttotal: 1.7s\tremaining: 13.1s\n",
      "115:\tlearn: 1.7836821\ttotal: 1.72s\tremaining: 13.1s\n",
      "116:\tlearn: 1.7827405\ttotal: 1.73s\tremaining: 13.1s\n",
      "117:\tlearn: 1.7795088\ttotal: 1.74s\tremaining: 13s\n",
      "118:\tlearn: 1.7793252\ttotal: 1.76s\tremaining: 13s\n",
      "119:\tlearn: 1.7750614\ttotal: 1.77s\tremaining: 13s\n",
      "120:\tlearn: 1.7709862\ttotal: 1.78s\tremaining: 13s\n",
      "121:\tlearn: 1.7687356\ttotal: 1.8s\tremaining: 12.9s\n",
      "122:\tlearn: 1.7684121\ttotal: 1.81s\tremaining: 12.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123:\tlearn: 1.7675211\ttotal: 1.83s\tremaining: 12.9s\n",
      "124:\tlearn: 1.7671757\ttotal: 1.84s\tremaining: 12.9s\n",
      "125:\tlearn: 1.7670719\ttotal: 1.85s\tremaining: 12.9s\n",
      "126:\tlearn: 1.7623185\ttotal: 1.87s\tremaining: 12.8s\n",
      "127:\tlearn: 1.7605378\ttotal: 1.88s\tremaining: 12.8s\n",
      "128:\tlearn: 1.7591164\ttotal: 1.89s\tremaining: 12.8s\n",
      "129:\tlearn: 1.7528406\ttotal: 1.91s\tremaining: 12.8s\n",
      "130:\tlearn: 1.7450706\ttotal: 1.92s\tremaining: 12.8s\n",
      "131:\tlearn: 1.7385758\ttotal: 1.94s\tremaining: 12.7s\n",
      "132:\tlearn: 1.7352597\ttotal: 1.95s\tremaining: 12.7s\n",
      "133:\tlearn: 1.7308696\ttotal: 1.96s\tremaining: 12.7s\n",
      "134:\tlearn: 1.7293376\ttotal: 1.98s\tremaining: 12.7s\n",
      "135:\tlearn: 1.7250837\ttotal: 1.99s\tremaining: 12.7s\n",
      "136:\tlearn: 1.7240466\ttotal: 2s\tremaining: 12.6s\n",
      "137:\tlearn: 1.7230000\ttotal: 2.02s\tremaining: 12.6s\n",
      "138:\tlearn: 1.7211632\ttotal: 2.03s\tremaining: 12.6s\n",
      "139:\tlearn: 1.7184667\ttotal: 2.05s\tremaining: 12.6s\n",
      "140:\tlearn: 1.7178159\ttotal: 2.06s\tremaining: 12.6s\n",
      "141:\tlearn: 1.7134568\ttotal: 2.08s\tremaining: 12.5s\n",
      "142:\tlearn: 1.7126048\ttotal: 2.09s\tremaining: 12.5s\n",
      "143:\tlearn: 1.7115020\ttotal: 2.1s\tremaining: 12.5s\n",
      "144:\tlearn: 1.7079821\ttotal: 2.12s\tremaining: 12.5s\n",
      "145:\tlearn: 1.7068888\ttotal: 2.13s\tremaining: 12.5s\n",
      "146:\tlearn: 1.7034214\ttotal: 2.14s\tremaining: 12.4s\n",
      "147:\tlearn: 1.7018542\ttotal: 2.15s\tremaining: 12.4s\n",
      "148:\tlearn: 1.7007268\ttotal: 2.17s\tremaining: 12.4s\n",
      "149:\tlearn: 1.6987356\ttotal: 2.18s\tremaining: 12.4s\n",
      "150:\tlearn: 1.6974425\ttotal: 2.2s\tremaining: 12.3s\n",
      "151:\tlearn: 1.6952371\ttotal: 2.21s\tremaining: 12.3s\n",
      "152:\tlearn: 1.6938276\ttotal: 2.22s\tremaining: 12.3s\n",
      "153:\tlearn: 1.6914177\ttotal: 2.24s\tremaining: 12.3s\n",
      "154:\tlearn: 1.6892812\ttotal: 2.25s\tremaining: 12.3s\n",
      "155:\tlearn: 1.6868363\ttotal: 2.27s\tremaining: 12.3s\n",
      "156:\tlearn: 1.6853062\ttotal: 2.28s\tremaining: 12.2s\n",
      "157:\tlearn: 1.6824092\ttotal: 2.29s\tremaining: 12.2s\n",
      "158:\tlearn: 1.6809796\ttotal: 2.31s\tremaining: 12.2s\n",
      "159:\tlearn: 1.6791178\ttotal: 2.32s\tremaining: 12.2s\n",
      "160:\tlearn: 1.6760844\ttotal: 2.34s\tremaining: 12.2s\n",
      "161:\tlearn: 1.6731492\ttotal: 2.35s\tremaining: 12.2s\n",
      "162:\tlearn: 1.6711923\ttotal: 2.36s\tremaining: 12.1s\n",
      "163:\tlearn: 1.6696355\ttotal: 2.38s\tremaining: 12.1s\n",
      "164:\tlearn: 1.6688697\ttotal: 2.39s\tremaining: 12.1s\n",
      "165:\tlearn: 1.6659371\ttotal: 2.4s\tremaining: 12.1s\n",
      "166:\tlearn: 1.6637987\ttotal: 2.42s\tremaining: 12.1s\n",
      "167:\tlearn: 1.6625144\ttotal: 2.43s\tremaining: 12s\n",
      "168:\tlearn: 1.6603173\ttotal: 2.44s\tremaining: 12s\n",
      "169:\tlearn: 1.6584921\ttotal: 2.46s\tremaining: 12s\n",
      "170:\tlearn: 1.6562649\ttotal: 2.47s\tremaining: 12s\n",
      "171:\tlearn: 1.6529374\ttotal: 2.49s\tremaining: 12s\n",
      "172:\tlearn: 1.6503792\ttotal: 2.5s\tremaining: 12s\n",
      "173:\tlearn: 1.6478162\ttotal: 2.52s\tremaining: 11.9s\n",
      "174:\tlearn: 1.6449929\ttotal: 2.53s\tremaining: 11.9s\n",
      "175:\tlearn: 1.6443501\ttotal: 2.54s\tremaining: 11.9s\n",
      "176:\tlearn: 1.6431198\ttotal: 2.56s\tremaining: 11.9s\n",
      "177:\tlearn: 1.6424072\ttotal: 2.57s\tremaining: 11.9s\n",
      "178:\tlearn: 1.6415602\ttotal: 2.58s\tremaining: 11.8s\n",
      "179:\tlearn: 1.6394865\ttotal: 2.6s\tremaining: 11.8s\n",
      "180:\tlearn: 1.6368252\ttotal: 2.61s\tremaining: 11.8s\n",
      "181:\tlearn: 1.6348797\ttotal: 2.63s\tremaining: 11.8s\n",
      "182:\tlearn: 1.6324605\ttotal: 2.64s\tremaining: 11.8s\n",
      "183:\tlearn: 1.6302138\ttotal: 2.65s\tremaining: 11.8s\n",
      "184:\tlearn: 1.6269914\ttotal: 2.67s\tremaining: 11.8s\n",
      "185:\tlearn: 1.6241723\ttotal: 2.68s\tremaining: 11.7s\n",
      "186:\tlearn: 1.6233533\ttotal: 2.7s\tremaining: 11.7s\n",
      "187:\tlearn: 1.6218388\ttotal: 2.71s\tremaining: 11.7s\n",
      "188:\tlearn: 1.6204021\ttotal: 2.73s\tremaining: 11.7s\n",
      "189:\tlearn: 1.6191340\ttotal: 2.74s\tremaining: 11.7s\n",
      "190:\tlearn: 1.6179553\ttotal: 2.75s\tremaining: 11.7s\n",
      "191:\tlearn: 1.6172073\ttotal: 2.77s\tremaining: 11.6s\n",
      "192:\tlearn: 1.6158925\ttotal: 2.78s\tremaining: 11.6s\n",
      "193:\tlearn: 1.6149754\ttotal: 2.79s\tremaining: 11.6s\n",
      "194:\tlearn: 1.6140257\ttotal: 2.81s\tremaining: 11.6s\n",
      "195:\tlearn: 1.6124861\ttotal: 2.82s\tremaining: 11.6s\n",
      "196:\tlearn: 1.6109190\ttotal: 2.83s\tremaining: 11.6s\n",
      "197:\tlearn: 1.6070461\ttotal: 2.85s\tremaining: 11.5s\n",
      "198:\tlearn: 1.6038052\ttotal: 2.86s\tremaining: 11.5s\n",
      "199:\tlearn: 1.6018530\ttotal: 2.88s\tremaining: 11.5s\n",
      "200:\tlearn: 1.6004375\ttotal: 2.89s\tremaining: 11.5s\n",
      "201:\tlearn: 1.5999729\ttotal: 2.91s\tremaining: 11.5s\n",
      "202:\tlearn: 1.5997432\ttotal: 2.92s\tremaining: 11.5s\n",
      "203:\tlearn: 1.5996256\ttotal: 2.93s\tremaining: 11.5s\n",
      "204:\tlearn: 1.5989147\ttotal: 2.95s\tremaining: 11.4s\n",
      "205:\tlearn: 1.5976191\ttotal: 2.96s\tremaining: 11.4s\n",
      "206:\tlearn: 1.5972481\ttotal: 2.98s\tremaining: 11.4s\n",
      "207:\tlearn: 1.5964177\ttotal: 2.99s\tremaining: 11.4s\n",
      "208:\tlearn: 1.5961189\ttotal: 3s\tremaining: 11.4s\n",
      "209:\tlearn: 1.5959369\ttotal: 3.02s\tremaining: 11.4s\n",
      "210:\tlearn: 1.5956003\ttotal: 3.03s\tremaining: 11.3s\n",
      "211:\tlearn: 1.5951996\ttotal: 3.04s\tremaining: 11.3s\n",
      "212:\tlearn: 1.5945183\ttotal: 3.06s\tremaining: 11.3s\n",
      "213:\tlearn: 1.5938457\ttotal: 3.07s\tremaining: 11.3s\n",
      "214:\tlearn: 1.5933852\ttotal: 3.09s\tremaining: 11.3s\n",
      "215:\tlearn: 1.5929999\ttotal: 3.1s\tremaining: 11.3s\n",
      "216:\tlearn: 1.5918201\ttotal: 3.12s\tremaining: 11.2s\n",
      "217:\tlearn: 1.5914721\ttotal: 3.13s\tremaining: 11.2s\n",
      "218:\tlearn: 1.5908009\ttotal: 3.14s\tremaining: 11.2s\n",
      "219:\tlearn: 1.5891050\ttotal: 3.16s\tremaining: 11.2s\n",
      "220:\tlearn: 1.5885104\ttotal: 3.17s\tremaining: 11.2s\n",
      "221:\tlearn: 1.5876437\ttotal: 3.19s\tremaining: 11.2s\n",
      "222:\tlearn: 1.5870378\ttotal: 3.2s\tremaining: 11.1s\n",
      "223:\tlearn: 1.5864685\ttotal: 3.21s\tremaining: 11.1s\n",
      "224:\tlearn: 1.5857589\ttotal: 3.22s\tremaining: 11.1s\n",
      "225:\tlearn: 1.5856873\ttotal: 3.24s\tremaining: 11.1s\n",
      "226:\tlearn: 1.5851825\ttotal: 3.25s\tremaining: 11.1s\n",
      "227:\tlearn: 1.5843215\ttotal: 3.26s\tremaining: 11.1s\n",
      "228:\tlearn: 1.5839228\ttotal: 3.28s\tremaining: 11s\n",
      "229:\tlearn: 1.5833166\ttotal: 3.29s\tremaining: 11s\n",
      "230:\tlearn: 1.5818010\ttotal: 3.31s\tremaining: 11s\n",
      "231:\tlearn: 1.5815155\ttotal: 3.32s\tremaining: 11s\n",
      "232:\tlearn: 1.5796869\ttotal: 3.34s\tremaining: 11s\n",
      "233:\tlearn: 1.5783846\ttotal: 3.35s\tremaining: 11s\n",
      "234:\tlearn: 1.5779102\ttotal: 3.36s\tremaining: 10.9s\n",
      "235:\tlearn: 1.5776733\ttotal: 3.38s\tremaining: 10.9s\n",
      "236:\tlearn: 1.5762271\ttotal: 3.39s\tremaining: 10.9s\n",
      "237:\tlearn: 1.5749107\ttotal: 3.4s\tremaining: 10.9s\n",
      "238:\tlearn: 1.5737889\ttotal: 3.42s\tremaining: 10.9s\n",
      "239:\tlearn: 1.5728778\ttotal: 3.43s\tremaining: 10.9s\n",
      "240:\tlearn: 1.5719234\ttotal: 3.45s\tremaining: 10.9s\n",
      "241:\tlearn: 1.5703926\ttotal: 3.46s\tremaining: 10.8s\n",
      "242:\tlearn: 1.5701946\ttotal: 3.47s\tremaining: 10.8s\n",
      "243:\tlearn: 1.5698532\ttotal: 3.49s\tremaining: 10.8s\n",
      "244:\tlearn: 1.5685232\ttotal: 3.5s\tremaining: 10.8s\n",
      "245:\tlearn: 1.5677963\ttotal: 3.52s\tremaining: 10.8s\n",
      "246:\tlearn: 1.5672988\ttotal: 3.53s\tremaining: 10.8s\n",
      "247:\tlearn: 1.5668694\ttotal: 3.55s\tremaining: 10.8s\n",
      "248:\tlearn: 1.5662055\ttotal: 3.56s\tremaining: 10.7s\n",
      "249:\tlearn: 1.5656877\ttotal: 3.57s\tremaining: 10.7s\n",
      "250:\tlearn: 1.5649897\ttotal: 3.59s\tremaining: 10.7s\n",
      "251:\tlearn: 1.5643692\ttotal: 3.6s\tremaining: 10.7s\n",
      "252:\tlearn: 1.5635783\ttotal: 3.62s\tremaining: 10.7s\n",
      "253:\tlearn: 1.5627030\ttotal: 3.63s\tremaining: 10.7s\n",
      "254:\tlearn: 1.5617559\ttotal: 3.64s\tremaining: 10.6s\n",
      "255:\tlearn: 1.5608268\ttotal: 3.66s\tremaining: 10.6s\n",
      "256:\tlearn: 1.5598695\ttotal: 3.67s\tremaining: 10.6s\n",
      "257:\tlearn: 1.5590959\ttotal: 3.69s\tremaining: 10.6s\n",
      "258:\tlearn: 1.5583781\ttotal: 3.7s\tremaining: 10.6s\n",
      "259:\tlearn: 1.5572363\ttotal: 3.71s\tremaining: 10.6s\n",
      "260:\tlearn: 1.5567106\ttotal: 3.73s\tremaining: 10.6s\n",
      "261:\tlearn: 1.5559436\ttotal: 3.74s\tremaining: 10.5s\n",
      "262:\tlearn: 1.5541705\ttotal: 3.76s\tremaining: 10.5s\n",
      "263:\tlearn: 1.5537578\ttotal: 3.77s\tremaining: 10.5s\n",
      "264:\tlearn: 1.5527337\ttotal: 3.79s\tremaining: 10.5s\n",
      "265:\tlearn: 1.5520995\ttotal: 3.8s\tremaining: 10.5s\n",
      "266:\tlearn: 1.5512756\ttotal: 3.81s\tremaining: 10.5s\n",
      "267:\tlearn: 1.5509337\ttotal: 3.83s\tremaining: 10.4s\n",
      "268:\tlearn: 1.5501138\ttotal: 3.84s\tremaining: 10.4s\n",
      "269:\tlearn: 1.5492543\ttotal: 3.85s\tremaining: 10.4s\n",
      "270:\tlearn: 1.5487994\ttotal: 3.87s\tremaining: 10.4s\n",
      "271:\tlearn: 1.5482421\ttotal: 3.88s\tremaining: 10.4s\n",
      "272:\tlearn: 1.5475466\ttotal: 3.9s\tremaining: 10.4s\n",
      "273:\tlearn: 1.5470727\ttotal: 3.91s\tremaining: 10.4s\n",
      "274:\tlearn: 1.5465523\ttotal: 3.93s\tremaining: 10.4s\n",
      "275:\tlearn: 1.5463340\ttotal: 3.95s\tremaining: 10.4s\n",
      "276:\tlearn: 1.5457169\ttotal: 3.96s\tremaining: 10.3s\n",
      "277:\tlearn: 1.5449559\ttotal: 3.98s\tremaining: 10.3s\n",
      "278:\tlearn: 1.5433079\ttotal: 3.99s\tremaining: 10.3s\n",
      "279:\tlearn: 1.5430110\ttotal: 4s\tremaining: 10.3s\n",
      "280:\tlearn: 1.5424301\ttotal: 4.02s\tremaining: 10.3s\n",
      "281:\tlearn: 1.5419417\ttotal: 4.03s\tremaining: 10.3s\n",
      "282:\tlearn: 1.5416862\ttotal: 4.04s\tremaining: 10.2s\n",
      "283:\tlearn: 1.5416064\ttotal: 4.06s\tremaining: 10.2s\n",
      "284:\tlearn: 1.5415430\ttotal: 4.07s\tremaining: 10.2s\n",
      "285:\tlearn: 1.5414203\ttotal: 4.08s\tremaining: 10.2s\n",
      "286:\tlearn: 1.5413171\ttotal: 4.1s\tremaining: 10.2s\n",
      "287:\tlearn: 1.5412187\ttotal: 4.11s\tremaining: 10.2s\n",
      "288:\tlearn: 1.5411693\ttotal: 4.12s\tremaining: 10.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289:\tlearn: 1.5411387\ttotal: 4.14s\tremaining: 10.1s\n",
      "290:\tlearn: 1.5407092\ttotal: 4.15s\tremaining: 10.1s\n",
      "291:\tlearn: 1.5399421\ttotal: 4.17s\tremaining: 10.1s\n",
      "292:\tlearn: 1.5381884\ttotal: 4.18s\tremaining: 10.1s\n",
      "293:\tlearn: 1.5381146\ttotal: 4.19s\tremaining: 10.1s\n",
      "294:\tlearn: 1.5380438\ttotal: 4.21s\tremaining: 10.1s\n",
      "295:\tlearn: 1.5379483\ttotal: 4.22s\tremaining: 10s\n",
      "296:\tlearn: 1.5376386\ttotal: 4.24s\tremaining: 10s\n",
      "297:\tlearn: 1.5375852\ttotal: 4.25s\tremaining: 10s\n",
      "298:\tlearn: 1.5374718\ttotal: 4.26s\tremaining: 9.99s\n",
      "299:\tlearn: 1.5373476\ttotal: 4.28s\tremaining: 9.98s\n",
      "300:\tlearn: 1.5371831\ttotal: 4.29s\tremaining: 9.96s\n",
      "301:\tlearn: 1.5371338\ttotal: 4.3s\tremaining: 9.94s\n",
      "302:\tlearn: 1.5369618\ttotal: 4.31s\tremaining: 9.93s\n",
      "303:\tlearn: 1.5368951\ttotal: 4.33s\tremaining: 9.91s\n",
      "304:\tlearn: 1.5364842\ttotal: 4.34s\tremaining: 9.89s\n",
      "305:\tlearn: 1.5362516\ttotal: 4.36s\tremaining: 9.88s\n",
      "306:\tlearn: 1.5355378\ttotal: 4.37s\tremaining: 9.87s\n",
      "307:\tlearn: 1.5354317\ttotal: 4.38s\tremaining: 9.85s\n",
      "308:\tlearn: 1.5352278\ttotal: 4.4s\tremaining: 9.83s\n",
      "309:\tlearn: 1.5345836\ttotal: 4.41s\tremaining: 9.82s\n",
      "310:\tlearn: 1.5341874\ttotal: 4.42s\tremaining: 9.8s\n",
      "311:\tlearn: 1.5334098\ttotal: 4.44s\tremaining: 9.79s\n",
      "312:\tlearn: 1.5329232\ttotal: 4.45s\tremaining: 9.77s\n",
      "313:\tlearn: 1.5323769\ttotal: 4.47s\tremaining: 9.76s\n",
      "314:\tlearn: 1.5315849\ttotal: 4.48s\tremaining: 9.74s\n",
      "315:\tlearn: 1.5313965\ttotal: 4.49s\tremaining: 9.73s\n",
      "316:\tlearn: 1.5305884\ttotal: 4.51s\tremaining: 9.71s\n",
      "317:\tlearn: 1.5303916\ttotal: 4.52s\tremaining: 9.69s\n",
      "318:\tlearn: 1.5298247\ttotal: 4.53s\tremaining: 9.68s\n",
      "319:\tlearn: 1.5289499\ttotal: 4.55s\tremaining: 9.66s\n",
      "320:\tlearn: 1.5282328\ttotal: 4.56s\tremaining: 9.65s\n",
      "321:\tlearn: 1.5275583\ttotal: 4.58s\tremaining: 9.64s\n",
      "322:\tlearn: 1.5274035\ttotal: 4.59s\tremaining: 9.62s\n",
      "323:\tlearn: 1.5260096\ttotal: 4.6s\tremaining: 9.61s\n",
      "324:\tlearn: 1.5258131\ttotal: 4.62s\tremaining: 9.59s\n",
      "325:\tlearn: 1.5243445\ttotal: 4.63s\tremaining: 9.58s\n",
      "326:\tlearn: 1.5238732\ttotal: 4.65s\tremaining: 9.56s\n",
      "327:\tlearn: 1.5236722\ttotal: 4.66s\tremaining: 9.55s\n",
      "328:\tlearn: 1.5231755\ttotal: 4.67s\tremaining: 9.53s\n",
      "329:\tlearn: 1.5220118\ttotal: 4.69s\tremaining: 9.52s\n",
      "330:\tlearn: 1.5216382\ttotal: 4.7s\tremaining: 9.5s\n",
      "331:\tlearn: 1.5209461\ttotal: 4.72s\tremaining: 9.49s\n",
      "332:\tlearn: 1.5203683\ttotal: 4.73s\tremaining: 9.47s\n",
      "333:\tlearn: 1.5195060\ttotal: 4.75s\tremaining: 9.46s\n",
      "334:\tlearn: 1.5190031\ttotal: 4.76s\tremaining: 9.45s\n",
      "335:\tlearn: 1.5189880\ttotal: 4.77s\tremaining: 9.44s\n",
      "336:\tlearn: 1.5183818\ttotal: 4.79s\tremaining: 9.42s\n",
      "337:\tlearn: 1.5179702\ttotal: 4.8s\tremaining: 9.4s\n",
      "338:\tlearn: 1.5170726\ttotal: 4.82s\tremaining: 9.39s\n",
      "339:\tlearn: 1.5160070\ttotal: 4.83s\tremaining: 9.38s\n",
      "340:\tlearn: 1.5157808\ttotal: 4.84s\tremaining: 9.36s\n",
      "341:\tlearn: 1.5149018\ttotal: 4.86s\tremaining: 9.35s\n",
      "342:\tlearn: 1.5137647\ttotal: 4.87s\tremaining: 9.33s\n",
      "343:\tlearn: 1.5124624\ttotal: 4.88s\tremaining: 9.32s\n",
      "344:\tlearn: 1.5118194\ttotal: 4.9s\tremaining: 9.3s\n",
      "345:\tlearn: 1.5112158\ttotal: 4.91s\tremaining: 9.29s\n",
      "346:\tlearn: 1.5108921\ttotal: 4.93s\tremaining: 9.27s\n",
      "347:\tlearn: 1.5108311\ttotal: 4.94s\tremaining: 9.26s\n",
      "348:\tlearn: 1.5108018\ttotal: 4.95s\tremaining: 9.24s\n",
      "349:\tlearn: 1.5107021\ttotal: 4.97s\tremaining: 9.23s\n",
      "350:\tlearn: 1.5098887\ttotal: 4.98s\tremaining: 9.21s\n",
      "351:\tlearn: 1.5098822\ttotal: 5s\tremaining: 9.2s\n",
      "352:\tlearn: 1.5088624\ttotal: 5.01s\tremaining: 9.19s\n",
      "353:\tlearn: 1.5086970\ttotal: 5.03s\tremaining: 9.17s\n",
      "354:\tlearn: 1.5086760\ttotal: 5.04s\tremaining: 9.15s\n",
      "355:\tlearn: 1.5077326\ttotal: 5.05s\tremaining: 9.14s\n",
      "356:\tlearn: 1.5071664\ttotal: 5.07s\tremaining: 9.13s\n",
      "357:\tlearn: 1.5070086\ttotal: 5.08s\tremaining: 9.11s\n",
      "358:\tlearn: 1.5069406\ttotal: 5.1s\tremaining: 9.1s\n",
      "359:\tlearn: 1.5066379\ttotal: 5.11s\tremaining: 9.08s\n",
      "360:\tlearn: 1.5065757\ttotal: 5.12s\tremaining: 9.07s\n",
      "361:\tlearn: 1.5058066\ttotal: 5.14s\tremaining: 9.06s\n",
      "362:\tlearn: 1.5055984\ttotal: 5.15s\tremaining: 9.04s\n",
      "363:\tlearn: 1.5053852\ttotal: 5.17s\tremaining: 9.03s\n",
      "364:\tlearn: 1.5050624\ttotal: 5.18s\tremaining: 9.02s\n",
      "365:\tlearn: 1.5050262\ttotal: 5.2s\tremaining: 9s\n",
      "366:\tlearn: 1.5049984\ttotal: 5.21s\tremaining: 8.99s\n",
      "367:\tlearn: 1.5045369\ttotal: 5.23s\tremaining: 8.97s\n",
      "368:\tlearn: 1.5040369\ttotal: 5.24s\tremaining: 8.96s\n",
      "369:\tlearn: 1.5035792\ttotal: 5.25s\tremaining: 8.95s\n",
      "370:\tlearn: 1.5032889\ttotal: 5.27s\tremaining: 8.93s\n",
      "371:\tlearn: 1.5027985\ttotal: 5.28s\tremaining: 8.92s\n",
      "372:\tlearn: 1.5026781\ttotal: 5.3s\tremaining: 8.9s\n",
      "373:\tlearn: 1.5022860\ttotal: 5.31s\tremaining: 8.89s\n",
      "374:\tlearn: 1.5020118\ttotal: 5.33s\tremaining: 8.88s\n",
      "375:\tlearn: 1.5017083\ttotal: 5.34s\tremaining: 8.86s\n",
      "376:\tlearn: 1.5013169\ttotal: 5.36s\tremaining: 8.85s\n",
      "377:\tlearn: 1.5012476\ttotal: 5.37s\tremaining: 8.83s\n",
      "378:\tlearn: 1.5012217\ttotal: 5.38s\tremaining: 8.82s\n",
      "379:\tlearn: 1.5011776\ttotal: 5.4s\tremaining: 8.8s\n",
      "380:\tlearn: 1.5011266\ttotal: 5.41s\tremaining: 8.79s\n",
      "381:\tlearn: 1.5011070\ttotal: 5.43s\tremaining: 8.78s\n",
      "382:\tlearn: 1.5004861\ttotal: 5.44s\tremaining: 8.76s\n",
      "383:\tlearn: 1.5004709\ttotal: 5.46s\tremaining: 8.75s\n",
      "384:\tlearn: 1.5004187\ttotal: 5.47s\tremaining: 8.74s\n",
      "385:\tlearn: 1.5002249\ttotal: 5.48s\tremaining: 8.72s\n",
      "386:\tlearn: 1.5001056\ttotal: 5.5s\tremaining: 8.71s\n",
      "387:\tlearn: 1.4996947\ttotal: 5.51s\tremaining: 8.69s\n",
      "388:\tlearn: 1.4990839\ttotal: 5.53s\tremaining: 8.68s\n",
      "389:\tlearn: 1.4981609\ttotal: 5.54s\tremaining: 8.67s\n",
      "390:\tlearn: 1.4981260\ttotal: 5.56s\tremaining: 8.65s\n",
      "391:\tlearn: 1.4976501\ttotal: 5.57s\tremaining: 8.64s\n",
      "392:\tlearn: 1.4975115\ttotal: 5.58s\tremaining: 8.62s\n",
      "393:\tlearn: 1.4967254\ttotal: 5.6s\tremaining: 8.61s\n",
      "394:\tlearn: 1.4966392\ttotal: 5.61s\tremaining: 8.6s\n",
      "395:\tlearn: 1.4963277\ttotal: 5.63s\tremaining: 8.59s\n",
      "396:\tlearn: 1.4960352\ttotal: 5.64s\tremaining: 8.57s\n",
      "397:\tlearn: 1.4957988\ttotal: 5.66s\tremaining: 8.56s\n",
      "398:\tlearn: 1.4955784\ttotal: 5.67s\tremaining: 8.54s\n",
      "399:\tlearn: 1.4954688\ttotal: 5.68s\tremaining: 8.53s\n",
      "400:\tlearn: 1.4952996\ttotal: 5.7s\tremaining: 8.51s\n",
      "401:\tlearn: 1.4952976\ttotal: 5.71s\tremaining: 8.5s\n",
      "402:\tlearn: 1.4952737\ttotal: 5.73s\tremaining: 8.48s\n",
      "403:\tlearn: 1.4952736\ttotal: 5.74s\tremaining: 8.47s\n",
      "404:\tlearn: 1.4952585\ttotal: 5.76s\tremaining: 8.46s\n",
      "405:\tlearn: 1.4951405\ttotal: 5.77s\tremaining: 8.44s\n",
      "406:\tlearn: 1.4949773\ttotal: 5.79s\tremaining: 8.43s\n",
      "407:\tlearn: 1.4949176\ttotal: 5.8s\tremaining: 8.41s\n",
      "408:\tlearn: 1.4948551\ttotal: 5.81s\tremaining: 8.4s\n",
      "409:\tlearn: 1.4938350\ttotal: 5.83s\tremaining: 8.39s\n",
      "410:\tlearn: 1.4938245\ttotal: 5.85s\tremaining: 8.38s\n",
      "411:\tlearn: 1.4938091\ttotal: 5.86s\tremaining: 8.37s\n",
      "412:\tlearn: 1.4937174\ttotal: 5.88s\tremaining: 8.36s\n",
      "413:\tlearn: 1.4935556\ttotal: 5.9s\tremaining: 8.35s\n",
      "414:\tlearn: 1.4935536\ttotal: 5.91s\tremaining: 8.34s\n",
      "415:\tlearn: 1.4935239\ttotal: 5.93s\tremaining: 8.32s\n",
      "416:\tlearn: 1.4934881\ttotal: 5.95s\tremaining: 8.31s\n",
      "417:\tlearn: 1.4933175\ttotal: 5.96s\tremaining: 8.3s\n",
      "418:\tlearn: 1.4924547\ttotal: 5.98s\tremaining: 8.29s\n",
      "419:\tlearn: 1.4922634\ttotal: 5.99s\tremaining: 8.28s\n",
      "420:\tlearn: 1.4921891\ttotal: 6.01s\tremaining: 8.26s\n",
      "421:\tlearn: 1.4919197\ttotal: 6.03s\tremaining: 8.25s\n",
      "422:\tlearn: 1.4917750\ttotal: 6.04s\tremaining: 8.24s\n",
      "423:\tlearn: 1.4915383\ttotal: 6.06s\tremaining: 8.23s\n",
      "424:\tlearn: 1.4909495\ttotal: 6.07s\tremaining: 8.21s\n",
      "425:\tlearn: 1.4899926\ttotal: 6.08s\tremaining: 8.2s\n",
      "426:\tlearn: 1.4889454\ttotal: 6.1s\tremaining: 8.19s\n",
      "427:\tlearn: 1.4889433\ttotal: 6.11s\tremaining: 8.17s\n",
      "428:\tlearn: 1.4889431\ttotal: 6.13s\tremaining: 8.16s\n",
      "429:\tlearn: 1.4889392\ttotal: 6.14s\tremaining: 8.14s\n",
      "430:\tlearn: 1.4889331\ttotal: 6.16s\tremaining: 8.13s\n",
      "431:\tlearn: 1.4889165\ttotal: 6.17s\tremaining: 8.11s\n",
      "432:\tlearn: 1.4888885\ttotal: 6.18s\tremaining: 8.1s\n",
      "433:\tlearn: 1.4888885\ttotal: 6.2s\tremaining: 8.08s\n",
      "434:\tlearn: 1.4888854\ttotal: 6.21s\tremaining: 8.07s\n",
      "435:\tlearn: 1.4887555\ttotal: 6.23s\tremaining: 8.05s\n",
      "436:\tlearn: 1.4886218\ttotal: 6.24s\tremaining: 8.04s\n",
      "437:\tlearn: 1.4886173\ttotal: 6.25s\tremaining: 8.03s\n",
      "438:\tlearn: 1.4884410\ttotal: 6.27s\tremaining: 8.01s\n",
      "439:\tlearn: 1.4884403\ttotal: 6.28s\tremaining: 8s\n",
      "440:\tlearn: 1.4884392\ttotal: 6.3s\tremaining: 7.98s\n",
      "441:\tlearn: 1.4884385\ttotal: 6.31s\tremaining: 7.97s\n",
      "442:\tlearn: 1.4884385\ttotal: 6.32s\tremaining: 7.95s\n",
      "443:\tlearn: 1.4884383\ttotal: 6.34s\tremaining: 7.93s\n",
      "444:\tlearn: 1.4884383\ttotal: 6.35s\tremaining: 7.92s\n",
      "445:\tlearn: 1.4880122\ttotal: 6.36s\tremaining: 7.91s\n",
      "446:\tlearn: 1.4877770\ttotal: 6.38s\tremaining: 7.89s\n",
      "447:\tlearn: 1.4877767\ttotal: 6.39s\tremaining: 7.88s\n",
      "448:\tlearn: 1.4877759\ttotal: 6.4s\tremaining: 7.86s\n",
      "449:\tlearn: 1.4877759\ttotal: 6.42s\tremaining: 7.84s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450:\tlearn: 1.4877759\ttotal: 6.43s\tremaining: 7.83s\n",
      "451:\tlearn: 1.4873725\ttotal: 6.45s\tremaining: 7.82s\n",
      "452:\tlearn: 1.4873502\ttotal: 6.46s\tremaining: 7.8s\n",
      "453:\tlearn: 1.4872974\ttotal: 6.47s\tremaining: 7.79s\n",
      "454:\tlearn: 1.4869525\ttotal: 6.49s\tremaining: 7.77s\n",
      "455:\tlearn: 1.4869388\ttotal: 6.5s\tremaining: 7.76s\n",
      "456:\tlearn: 1.4869369\ttotal: 6.51s\tremaining: 7.74s\n",
      "457:\tlearn: 1.4869361\ttotal: 6.53s\tremaining: 7.73s\n",
      "458:\tlearn: 1.4868832\ttotal: 6.54s\tremaining: 7.71s\n",
      "459:\tlearn: 1.4866894\ttotal: 6.56s\tremaining: 7.7s\n",
      "460:\tlearn: 1.4863588\ttotal: 6.57s\tremaining: 7.68s\n",
      "461:\tlearn: 1.4863577\ttotal: 6.58s\tremaining: 7.67s\n",
      "462:\tlearn: 1.4863442\ttotal: 6.6s\tremaining: 7.65s\n",
      "463:\tlearn: 1.4855112\ttotal: 6.61s\tremaining: 7.64s\n",
      "464:\tlearn: 1.4854143\ttotal: 6.63s\tremaining: 7.63s\n",
      "465:\tlearn: 1.4848842\ttotal: 6.64s\tremaining: 7.61s\n",
      "466:\tlearn: 1.4843068\ttotal: 6.66s\tremaining: 7.6s\n",
      "467:\tlearn: 1.4842841\ttotal: 6.67s\tremaining: 7.58s\n",
      "468:\tlearn: 1.4842623\ttotal: 6.68s\tremaining: 7.57s\n",
      "469:\tlearn: 1.4841399\ttotal: 6.7s\tremaining: 7.55s\n",
      "470:\tlearn: 1.4841269\ttotal: 6.71s\tremaining: 7.54s\n",
      "471:\tlearn: 1.4841198\ttotal: 6.73s\tremaining: 7.53s\n",
      "472:\tlearn: 1.4841198\ttotal: 6.74s\tremaining: 7.51s\n",
      "473:\tlearn: 1.4841168\ttotal: 6.75s\tremaining: 7.5s\n",
      "474:\tlearn: 1.4835782\ttotal: 6.77s\tremaining: 7.48s\n",
      "475:\tlearn: 1.4835453\ttotal: 6.78s\tremaining: 7.47s\n",
      "476:\tlearn: 1.4835452\ttotal: 6.8s\tremaining: 7.45s\n",
      "477:\tlearn: 1.4835449\ttotal: 6.81s\tremaining: 7.44s\n",
      "478:\tlearn: 1.4835438\ttotal: 6.82s\tremaining: 7.42s\n",
      "479:\tlearn: 1.4834110\ttotal: 6.84s\tremaining: 7.41s\n",
      "480:\tlearn: 1.4833984\ttotal: 6.85s\tremaining: 7.39s\n",
      "481:\tlearn: 1.4829857\ttotal: 6.87s\tremaining: 7.38s\n",
      "482:\tlearn: 1.4828977\ttotal: 6.88s\tremaining: 7.37s\n",
      "483:\tlearn: 1.4828660\ttotal: 6.9s\tremaining: 7.35s\n",
      "484:\tlearn: 1.4825660\ttotal: 6.91s\tremaining: 7.34s\n",
      "485:\tlearn: 1.4825660\ttotal: 6.92s\tremaining: 7.32s\n",
      "486:\tlearn: 1.4824019\ttotal: 6.94s\tremaining: 7.31s\n",
      "487:\tlearn: 1.4823738\ttotal: 6.95s\tremaining: 7.29s\n",
      "488:\tlearn: 1.4817460\ttotal: 6.97s\tremaining: 7.28s\n",
      "489:\tlearn: 1.4815538\ttotal: 6.98s\tremaining: 7.26s\n",
      "490:\tlearn: 1.4814506\ttotal: 6.99s\tremaining: 7.25s\n",
      "491:\tlearn: 1.4807131\ttotal: 7.01s\tremaining: 7.24s\n",
      "492:\tlearn: 1.4804409\ttotal: 7.02s\tremaining: 7.22s\n",
      "493:\tlearn: 1.4803697\ttotal: 7.04s\tremaining: 7.21s\n",
      "494:\tlearn: 1.4796862\ttotal: 7.05s\tremaining: 7.19s\n",
      "495:\tlearn: 1.4796408\ttotal: 7.07s\tremaining: 7.18s\n",
      "496:\tlearn: 1.4796311\ttotal: 7.08s\tremaining: 7.17s\n",
      "497:\tlearn: 1.4796280\ttotal: 7.09s\tremaining: 7.15s\n",
      "498:\tlearn: 1.4796274\ttotal: 7.11s\tremaining: 7.13s\n",
      "499:\tlearn: 1.4795605\ttotal: 7.12s\tremaining: 7.12s\n",
      "500:\tlearn: 1.4795009\ttotal: 7.13s\tremaining: 7.11s\n",
      "501:\tlearn: 1.4790174\ttotal: 7.15s\tremaining: 7.09s\n",
      "502:\tlearn: 1.4790139\ttotal: 7.16s\tremaining: 7.08s\n",
      "503:\tlearn: 1.4790056\ttotal: 7.18s\tremaining: 7.06s\n",
      "504:\tlearn: 1.4790034\ttotal: 7.19s\tremaining: 7.05s\n",
      "505:\tlearn: 1.4789552\ttotal: 7.21s\tremaining: 7.03s\n",
      "506:\tlearn: 1.4786028\ttotal: 7.22s\tremaining: 7.02s\n",
      "507:\tlearn: 1.4782537\ttotal: 7.23s\tremaining: 7.01s\n",
      "508:\tlearn: 1.4781899\ttotal: 7.25s\tremaining: 6.99s\n",
      "509:\tlearn: 1.4780595\ttotal: 7.26s\tremaining: 6.98s\n",
      "510:\tlearn: 1.4773102\ttotal: 7.28s\tremaining: 6.96s\n",
      "511:\tlearn: 1.4772248\ttotal: 7.29s\tremaining: 6.95s\n",
      "512:\tlearn: 1.4771460\ttotal: 7.31s\tremaining: 6.94s\n",
      "513:\tlearn: 1.4771460\ttotal: 7.32s\tremaining: 6.92s\n",
      "514:\tlearn: 1.4771178\ttotal: 7.34s\tremaining: 6.91s\n",
      "515:\tlearn: 1.4770515\ttotal: 7.35s\tremaining: 6.89s\n",
      "516:\tlearn: 1.4766385\ttotal: 7.36s\tremaining: 6.88s\n",
      "517:\tlearn: 1.4766337\ttotal: 7.38s\tremaining: 6.86s\n",
      "518:\tlearn: 1.4766315\ttotal: 7.39s\tremaining: 6.85s\n",
      "519:\tlearn: 1.4766303\ttotal: 7.41s\tremaining: 6.83s\n",
      "520:\tlearn: 1.4765580\ttotal: 7.42s\tremaining: 6.82s\n",
      "521:\tlearn: 1.4759996\ttotal: 7.43s\tremaining: 6.81s\n",
      "522:\tlearn: 1.4759976\ttotal: 7.45s\tremaining: 6.79s\n",
      "523:\tlearn: 1.4759959\ttotal: 7.46s\tremaining: 6.78s\n",
      "524:\tlearn: 1.4759914\ttotal: 7.47s\tremaining: 6.76s\n",
      "525:\tlearn: 1.4759748\ttotal: 7.49s\tremaining: 6.75s\n",
      "526:\tlearn: 1.4759156\ttotal: 7.5s\tremaining: 6.74s\n",
      "527:\tlearn: 1.4758809\ttotal: 7.52s\tremaining: 6.72s\n",
      "528:\tlearn: 1.4758152\ttotal: 7.53s\tremaining: 6.71s\n",
      "529:\tlearn: 1.4757748\ttotal: 7.55s\tremaining: 6.69s\n",
      "530:\tlearn: 1.4756576\ttotal: 7.56s\tremaining: 6.68s\n",
      "531:\tlearn: 1.4756002\ttotal: 7.58s\tremaining: 6.66s\n",
      "532:\tlearn: 1.4752511\ttotal: 7.59s\tremaining: 6.65s\n",
      "533:\tlearn: 1.4748930\ttotal: 7.6s\tremaining: 6.64s\n",
      "534:\tlearn: 1.4741704\ttotal: 7.62s\tremaining: 6.62s\n",
      "535:\tlearn: 1.4741704\ttotal: 7.63s\tremaining: 6.61s\n",
      "536:\tlearn: 1.4739407\ttotal: 7.65s\tremaining: 6.59s\n",
      "537:\tlearn: 1.4737176\ttotal: 7.66s\tremaining: 6.58s\n",
      "538:\tlearn: 1.4733190\ttotal: 7.67s\tremaining: 6.56s\n",
      "539:\tlearn: 1.4728761\ttotal: 7.69s\tremaining: 6.55s\n",
      "540:\tlearn: 1.4725020\ttotal: 7.71s\tremaining: 6.54s\n",
      "541:\tlearn: 1.4724098\ttotal: 7.72s\tremaining: 6.52s\n",
      "542:\tlearn: 1.4720202\ttotal: 7.74s\tremaining: 6.51s\n",
      "543:\tlearn: 1.4709819\ttotal: 7.75s\tremaining: 6.5s\n",
      "544:\tlearn: 1.4709785\ttotal: 7.76s\tremaining: 6.48s\n",
      "545:\tlearn: 1.4709729\ttotal: 7.78s\tremaining: 6.47s\n",
      "546:\tlearn: 1.4709717\ttotal: 7.79s\tremaining: 6.45s\n",
      "547:\tlearn: 1.4709715\ttotal: 7.8s\tremaining: 6.44s\n",
      "548:\tlearn: 1.4708996\ttotal: 7.82s\tremaining: 6.42s\n",
      "549:\tlearn: 1.4708959\ttotal: 7.83s\tremaining: 6.41s\n",
      "550:\tlearn: 1.4708482\ttotal: 7.85s\tremaining: 6.39s\n",
      "551:\tlearn: 1.4708357\ttotal: 7.86s\tremaining: 6.38s\n",
      "552:\tlearn: 1.4708252\ttotal: 7.88s\tremaining: 6.37s\n",
      "553:\tlearn: 1.4708252\ttotal: 7.89s\tremaining: 6.35s\n",
      "554:\tlearn: 1.4708228\ttotal: 7.9s\tremaining: 6.33s\n",
      "555:\tlearn: 1.4708227\ttotal: 7.92s\tremaining: 6.32s\n",
      "556:\tlearn: 1.4708227\ttotal: 7.93s\tremaining: 6.31s\n",
      "557:\tlearn: 1.4708227\ttotal: 7.95s\tremaining: 6.29s\n",
      "558:\tlearn: 1.4708113\ttotal: 7.96s\tremaining: 6.28s\n",
      "559:\tlearn: 1.4701607\ttotal: 7.97s\tremaining: 6.26s\n",
      "560:\tlearn: 1.4700397\ttotal: 7.99s\tremaining: 6.25s\n",
      "561:\tlearn: 1.4697762\ttotal: 8s\tremaining: 6.24s\n",
      "562:\tlearn: 1.4697520\ttotal: 8.02s\tremaining: 6.22s\n",
      "563:\tlearn: 1.4691684\ttotal: 8.03s\tremaining: 6.21s\n",
      "564:\tlearn: 1.4691278\ttotal: 8.04s\tremaining: 6.19s\n",
      "565:\tlearn: 1.4691277\ttotal: 8.06s\tremaining: 6.18s\n",
      "566:\tlearn: 1.4691277\ttotal: 8.07s\tremaining: 6.17s\n",
      "567:\tlearn: 1.4691277\ttotal: 8.09s\tremaining: 6.15s\n",
      "568:\tlearn: 1.4691272\ttotal: 8.1s\tremaining: 6.14s\n",
      "569:\tlearn: 1.4691213\ttotal: 8.12s\tremaining: 6.12s\n",
      "570:\tlearn: 1.4688062\ttotal: 8.13s\tremaining: 6.11s\n",
      "571:\tlearn: 1.4688062\ttotal: 8.15s\tremaining: 6.1s\n",
      "572:\tlearn: 1.4688062\ttotal: 8.16s\tremaining: 6.08s\n",
      "573:\tlearn: 1.4688056\ttotal: 8.18s\tremaining: 6.07s\n",
      "574:\tlearn: 1.4688023\ttotal: 8.19s\tremaining: 6.05s\n",
      "575:\tlearn: 1.4688009\ttotal: 8.2s\tremaining: 6.04s\n",
      "576:\tlearn: 1.4687997\ttotal: 8.22s\tremaining: 6.03s\n",
      "577:\tlearn: 1.4687995\ttotal: 8.23s\tremaining: 6.01s\n",
      "578:\tlearn: 1.4687981\ttotal: 8.25s\tremaining: 6s\n",
      "579:\tlearn: 1.4687959\ttotal: 8.26s\tremaining: 5.98s\n",
      "580:\tlearn: 1.4687959\ttotal: 8.28s\tremaining: 5.97s\n",
      "581:\tlearn: 1.4687959\ttotal: 8.29s\tremaining: 5.95s\n",
      "582:\tlearn: 1.4687958\ttotal: 8.3s\tremaining: 5.94s\n",
      "583:\tlearn: 1.4687956\ttotal: 8.32s\tremaining: 5.93s\n",
      "584:\tlearn: 1.4687866\ttotal: 8.33s\tremaining: 5.91s\n",
      "585:\tlearn: 1.4687665\ttotal: 8.35s\tremaining: 5.9s\n",
      "586:\tlearn: 1.4680634\ttotal: 8.36s\tremaining: 5.88s\n",
      "587:\tlearn: 1.4680293\ttotal: 8.38s\tremaining: 5.87s\n",
      "588:\tlearn: 1.4668948\ttotal: 8.39s\tremaining: 5.86s\n",
      "589:\tlearn: 1.4668635\ttotal: 8.41s\tremaining: 5.84s\n",
      "590:\tlearn: 1.4668451\ttotal: 8.42s\tremaining: 5.83s\n",
      "591:\tlearn: 1.4664821\ttotal: 8.44s\tremaining: 5.81s\n",
      "592:\tlearn: 1.4652572\ttotal: 8.45s\tremaining: 5.8s\n",
      "593:\tlearn: 1.4645411\ttotal: 8.46s\tremaining: 5.79s\n",
      "594:\tlearn: 1.4645410\ttotal: 8.48s\tremaining: 5.77s\n",
      "595:\tlearn: 1.4645410\ttotal: 8.49s\tremaining: 5.76s\n",
      "596:\tlearn: 1.4645339\ttotal: 8.51s\tremaining: 5.74s\n",
      "597:\tlearn: 1.4645338\ttotal: 8.52s\tremaining: 5.73s\n",
      "598:\tlearn: 1.4645070\ttotal: 8.53s\tremaining: 5.71s\n",
      "599:\tlearn: 1.4645070\ttotal: 8.55s\tremaining: 5.7s\n",
      "600:\tlearn: 1.4645068\ttotal: 8.56s\tremaining: 5.68s\n",
      "601:\tlearn: 1.4645062\ttotal: 8.58s\tremaining: 5.67s\n",
      "602:\tlearn: 1.4645015\ttotal: 8.59s\tremaining: 5.66s\n",
      "603:\tlearn: 1.4645005\ttotal: 8.6s\tremaining: 5.64s\n",
      "604:\tlearn: 1.4638636\ttotal: 8.62s\tremaining: 5.63s\n",
      "605:\tlearn: 1.4634216\ttotal: 8.63s\tremaining: 5.61s\n",
      "606:\tlearn: 1.4634206\ttotal: 8.65s\tremaining: 5.6s\n",
      "607:\tlearn: 1.4634194\ttotal: 8.66s\tremaining: 5.58s\n",
      "608:\tlearn: 1.4634120\ttotal: 8.67s\tremaining: 5.57s\n",
      "609:\tlearn: 1.4634120\ttotal: 8.69s\tremaining: 5.55s\n",
      "610:\tlearn: 1.4634116\ttotal: 8.7s\tremaining: 5.54s\n",
      "611:\tlearn: 1.4634116\ttotal: 8.72s\tremaining: 5.53s\n",
      "612:\tlearn: 1.4634068\ttotal: 8.73s\tremaining: 5.51s\n",
      "613:\tlearn: 1.4634066\ttotal: 8.74s\tremaining: 5.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614:\tlearn: 1.4634065\ttotal: 8.76s\tremaining: 5.48s\n",
      "615:\tlearn: 1.4633822\ttotal: 8.78s\tremaining: 5.47s\n",
      "616:\tlearn: 1.4625633\ttotal: 8.79s\tremaining: 5.46s\n",
      "617:\tlearn: 1.4624329\ttotal: 8.8s\tremaining: 5.44s\n",
      "618:\tlearn: 1.4619026\ttotal: 8.82s\tremaining: 5.43s\n",
      "619:\tlearn: 1.4618168\ttotal: 8.83s\tremaining: 5.41s\n",
      "620:\tlearn: 1.4613791\ttotal: 8.85s\tremaining: 5.4s\n",
      "621:\tlearn: 1.4613334\ttotal: 8.86s\tremaining: 5.38s\n",
      "622:\tlearn: 1.4611900\ttotal: 8.88s\tremaining: 5.37s\n",
      "623:\tlearn: 1.4611899\ttotal: 8.89s\tremaining: 5.36s\n",
      "624:\tlearn: 1.4611899\ttotal: 8.9s\tremaining: 5.34s\n",
      "625:\tlearn: 1.4611899\ttotal: 8.92s\tremaining: 5.33s\n",
      "626:\tlearn: 1.4611899\ttotal: 8.93s\tremaining: 5.31s\n",
      "627:\tlearn: 1.4611848\ttotal: 8.95s\tremaining: 5.3s\n",
      "628:\tlearn: 1.4611832\ttotal: 8.96s\tremaining: 5.29s\n",
      "629:\tlearn: 1.4611832\ttotal: 8.98s\tremaining: 5.27s\n",
      "630:\tlearn: 1.4611794\ttotal: 8.99s\tremaining: 5.26s\n",
      "631:\tlearn: 1.4610298\ttotal: 9s\tremaining: 5.24s\n",
      "632:\tlearn: 1.4610294\ttotal: 9.02s\tremaining: 5.23s\n",
      "633:\tlearn: 1.4610294\ttotal: 9.03s\tremaining: 5.21s\n",
      "634:\tlearn: 1.4610291\ttotal: 9.05s\tremaining: 5.2s\n",
      "635:\tlearn: 1.4610291\ttotal: 9.06s\tremaining: 5.18s\n",
      "636:\tlearn: 1.4610291\ttotal: 9.07s\tremaining: 5.17s\n",
      "637:\tlearn: 1.4610291\ttotal: 9.09s\tremaining: 5.16s\n",
      "638:\tlearn: 1.4609602\ttotal: 9.1s\tremaining: 5.14s\n",
      "639:\tlearn: 1.4609150\ttotal: 9.11s\tremaining: 5.13s\n",
      "640:\tlearn: 1.4609043\ttotal: 9.13s\tremaining: 5.11s\n",
      "641:\tlearn: 1.4609042\ttotal: 9.14s\tremaining: 5.1s\n",
      "642:\tlearn: 1.4609042\ttotal: 9.15s\tremaining: 5.08s\n",
      "643:\tlearn: 1.4609042\ttotal: 9.17s\tremaining: 5.07s\n",
      "644:\tlearn: 1.4609037\ttotal: 9.18s\tremaining: 5.05s\n",
      "645:\tlearn: 1.4609037\ttotal: 9.2s\tremaining: 5.04s\n",
      "646:\tlearn: 1.4609036\ttotal: 9.21s\tremaining: 5.03s\n",
      "647:\tlearn: 1.4609025\ttotal: 9.22s\tremaining: 5.01s\n",
      "648:\tlearn: 1.4609016\ttotal: 9.24s\tremaining: 5s\n",
      "649:\tlearn: 1.4609016\ttotal: 9.25s\tremaining: 4.98s\n",
      "650:\tlearn: 1.4609016\ttotal: 9.27s\tremaining: 4.97s\n",
      "651:\tlearn: 1.4609016\ttotal: 9.28s\tremaining: 4.95s\n",
      "652:\tlearn: 1.4608972\ttotal: 9.29s\tremaining: 4.94s\n",
      "653:\tlearn: 1.4608959\ttotal: 9.31s\tremaining: 4.92s\n",
      "654:\tlearn: 1.4608782\ttotal: 9.32s\tremaining: 4.91s\n",
      "655:\tlearn: 1.4603318\ttotal: 9.34s\tremaining: 4.9s\n",
      "656:\tlearn: 1.4601447\ttotal: 9.35s\tremaining: 4.88s\n",
      "657:\tlearn: 1.4595365\ttotal: 9.37s\tremaining: 4.87s\n",
      "658:\tlearn: 1.4594656\ttotal: 9.38s\tremaining: 4.85s\n",
      "659:\tlearn: 1.4594371\ttotal: 9.39s\tremaining: 4.84s\n",
      "660:\tlearn: 1.4594326\ttotal: 9.41s\tremaining: 4.83s\n",
      "661:\tlearn: 1.4594326\ttotal: 9.43s\tremaining: 4.81s\n",
      "662:\tlearn: 1.4594324\ttotal: 9.44s\tremaining: 4.8s\n",
      "663:\tlearn: 1.4594236\ttotal: 9.45s\tremaining: 4.78s\n",
      "664:\tlearn: 1.4594236\ttotal: 9.47s\tremaining: 4.77s\n",
      "665:\tlearn: 1.4594214\ttotal: 9.48s\tremaining: 4.75s\n",
      "666:\tlearn: 1.4593516\ttotal: 9.49s\tremaining: 4.74s\n",
      "667:\tlearn: 1.4593485\ttotal: 9.51s\tremaining: 4.73s\n",
      "668:\tlearn: 1.4593475\ttotal: 9.52s\tremaining: 4.71s\n",
      "669:\tlearn: 1.4593472\ttotal: 9.54s\tremaining: 4.7s\n",
      "670:\tlearn: 1.4593371\ttotal: 9.55s\tremaining: 4.68s\n",
      "671:\tlearn: 1.4593370\ttotal: 9.56s\tremaining: 4.67s\n",
      "672:\tlearn: 1.4593370\ttotal: 9.58s\tremaining: 4.65s\n",
      "673:\tlearn: 1.4593369\ttotal: 9.59s\tremaining: 4.64s\n",
      "674:\tlearn: 1.4593368\ttotal: 9.61s\tremaining: 4.63s\n",
      "675:\tlearn: 1.4593368\ttotal: 9.62s\tremaining: 4.61s\n",
      "676:\tlearn: 1.4593368\ttotal: 9.64s\tremaining: 4.6s\n",
      "677:\tlearn: 1.4593179\ttotal: 9.65s\tremaining: 4.58s\n",
      "678:\tlearn: 1.4593155\ttotal: 9.66s\tremaining: 4.57s\n",
      "679:\tlearn: 1.4593155\ttotal: 9.68s\tremaining: 4.55s\n",
      "680:\tlearn: 1.4593155\ttotal: 9.69s\tremaining: 4.54s\n",
      "681:\tlearn: 1.4593045\ttotal: 9.71s\tremaining: 4.53s\n",
      "682:\tlearn: 1.4585345\ttotal: 9.72s\tremaining: 4.51s\n",
      "683:\tlearn: 1.4583442\ttotal: 9.74s\tremaining: 4.5s\n",
      "684:\tlearn: 1.4578776\ttotal: 9.75s\tremaining: 4.48s\n",
      "685:\tlearn: 1.4574901\ttotal: 9.77s\tremaining: 4.47s\n",
      "686:\tlearn: 1.4566765\ttotal: 9.78s\tremaining: 4.46s\n",
      "687:\tlearn: 1.4566260\ttotal: 9.79s\tremaining: 4.44s\n",
      "688:\tlearn: 1.4566065\ttotal: 9.81s\tremaining: 4.43s\n",
      "689:\tlearn: 1.4565567\ttotal: 9.82s\tremaining: 4.41s\n",
      "690:\tlearn: 1.4564414\ttotal: 9.84s\tremaining: 4.4s\n",
      "691:\tlearn: 1.4558637\ttotal: 9.85s\tremaining: 4.38s\n",
      "692:\tlearn: 1.4555156\ttotal: 9.87s\tremaining: 4.37s\n",
      "693:\tlearn: 1.4554740\ttotal: 9.88s\tremaining: 4.36s\n",
      "694:\tlearn: 1.4550351\ttotal: 9.9s\tremaining: 4.34s\n",
      "695:\tlearn: 1.4549769\ttotal: 9.91s\tremaining: 4.33s\n",
      "696:\tlearn: 1.4548294\ttotal: 9.92s\tremaining: 4.31s\n",
      "697:\tlearn: 1.4547859\ttotal: 9.94s\tremaining: 4.3s\n",
      "698:\tlearn: 1.4547859\ttotal: 9.95s\tremaining: 4.29s\n",
      "699:\tlearn: 1.4547603\ttotal: 9.97s\tremaining: 4.27s\n",
      "700:\tlearn: 1.4545174\ttotal: 9.98s\tremaining: 4.26s\n",
      "701:\tlearn: 1.4540000\ttotal: 10s\tremaining: 4.24s\n",
      "702:\tlearn: 1.4539205\ttotal: 10s\tremaining: 4.23s\n",
      "703:\tlearn: 1.4536718\ttotal: 10s\tremaining: 4.21s\n",
      "704:\tlearn: 1.4536435\ttotal: 10s\tremaining: 4.2s\n",
      "705:\tlearn: 1.4536422\ttotal: 10.1s\tremaining: 4.19s\n",
      "706:\tlearn: 1.4536418\ttotal: 10.1s\tremaining: 4.17s\n",
      "707:\tlearn: 1.4536342\ttotal: 10.1s\tremaining: 4.16s\n",
      "708:\tlearn: 1.4534393\ttotal: 10.1s\tremaining: 4.14s\n",
      "709:\tlearn: 1.4531478\ttotal: 10.1s\tremaining: 4.13s\n",
      "710:\tlearn: 1.4531478\ttotal: 10.1s\tremaining: 4.12s\n",
      "711:\tlearn: 1.4531251\ttotal: 10.1s\tremaining: 4.1s\n",
      "712:\tlearn: 1.4531251\ttotal: 10.2s\tremaining: 4.09s\n",
      "713:\tlearn: 1.4531251\ttotal: 10.2s\tremaining: 4.07s\n",
      "714:\tlearn: 1.4531052\ttotal: 10.2s\tremaining: 4.06s\n",
      "715:\tlearn: 1.4531052\ttotal: 10.2s\tremaining: 4.04s\n",
      "716:\tlearn: 1.4531052\ttotal: 10.2s\tremaining: 4.03s\n",
      "717:\tlearn: 1.4531052\ttotal: 10.2s\tremaining: 4.01s\n",
      "718:\tlearn: 1.4530617\ttotal: 10.2s\tremaining: 4s\n",
      "719:\tlearn: 1.4530519\ttotal: 10.3s\tremaining: 3.99s\n",
      "720:\tlearn: 1.4530257\ttotal: 10.3s\tremaining: 3.97s\n",
      "721:\tlearn: 1.4529893\ttotal: 10.3s\tremaining: 3.96s\n",
      "722:\tlearn: 1.4529876\ttotal: 10.3s\tremaining: 3.94s\n",
      "723:\tlearn: 1.4529874\ttotal: 10.3s\tremaining: 3.93s\n",
      "724:\tlearn: 1.4529874\ttotal: 10.3s\tremaining: 3.92s\n",
      "725:\tlearn: 1.4529749\ttotal: 10.3s\tremaining: 3.9s\n",
      "726:\tlearn: 1.4529110\ttotal: 10.4s\tremaining: 3.89s\n",
      "727:\tlearn: 1.4528942\ttotal: 10.4s\tremaining: 3.87s\n",
      "728:\tlearn: 1.4525220\ttotal: 10.4s\tremaining: 3.86s\n",
      "729:\tlearn: 1.4524240\ttotal: 10.4s\tremaining: 3.84s\n",
      "730:\tlearn: 1.4516351\ttotal: 10.4s\tremaining: 3.83s\n",
      "731:\tlearn: 1.4508472\ttotal: 10.4s\tremaining: 3.82s\n",
      "732:\tlearn: 1.4506879\ttotal: 10.4s\tremaining: 3.8s\n",
      "733:\tlearn: 1.4502022\ttotal: 10.5s\tremaining: 3.79s\n",
      "734:\tlearn: 1.4501881\ttotal: 10.5s\tremaining: 3.77s\n",
      "735:\tlearn: 1.4499951\ttotal: 10.5s\tremaining: 3.76s\n",
      "736:\tlearn: 1.4499895\ttotal: 10.5s\tremaining: 3.75s\n",
      "737:\tlearn: 1.4499702\ttotal: 10.5s\tremaining: 3.73s\n",
      "738:\tlearn: 1.4497924\ttotal: 10.5s\tremaining: 3.72s\n",
      "739:\tlearn: 1.4497916\ttotal: 10.6s\tremaining: 3.71s\n",
      "740:\tlearn: 1.4497908\ttotal: 10.6s\tremaining: 3.69s\n",
      "741:\tlearn: 1.4497908\ttotal: 10.6s\tremaining: 3.68s\n",
      "742:\tlearn: 1.4497778\ttotal: 10.6s\tremaining: 3.67s\n",
      "743:\tlearn: 1.4497774\ttotal: 10.6s\tremaining: 3.65s\n",
      "744:\tlearn: 1.4497771\ttotal: 10.6s\tremaining: 3.64s\n",
      "745:\tlearn: 1.4497770\ttotal: 10.6s\tremaining: 3.62s\n",
      "746:\tlearn: 1.4497759\ttotal: 10.7s\tremaining: 3.61s\n",
      "747:\tlearn: 1.4497759\ttotal: 10.7s\tremaining: 3.59s\n",
      "748:\tlearn: 1.4497758\ttotal: 10.7s\tremaining: 3.58s\n",
      "749:\tlearn: 1.4493852\ttotal: 10.7s\tremaining: 3.57s\n",
      "750:\tlearn: 1.4491248\ttotal: 10.7s\tremaining: 3.55s\n",
      "751:\tlearn: 1.4490754\ttotal: 10.7s\tremaining: 3.54s\n",
      "752:\tlearn: 1.4490678\ttotal: 10.7s\tremaining: 3.52s\n",
      "753:\tlearn: 1.4486374\ttotal: 10.8s\tremaining: 3.51s\n",
      "754:\tlearn: 1.4483058\ttotal: 10.8s\tremaining: 3.5s\n",
      "755:\tlearn: 1.4480609\ttotal: 10.8s\tremaining: 3.48s\n",
      "756:\tlearn: 1.4480414\ttotal: 10.8s\tremaining: 3.47s\n",
      "757:\tlearn: 1.4480414\ttotal: 10.8s\tremaining: 3.45s\n",
      "758:\tlearn: 1.4480413\ttotal: 10.8s\tremaining: 3.44s\n",
      "759:\tlearn: 1.4480413\ttotal: 10.8s\tremaining: 3.42s\n",
      "760:\tlearn: 1.4480413\ttotal: 10.9s\tremaining: 3.41s\n",
      "761:\tlearn: 1.4474131\ttotal: 10.9s\tremaining: 3.4s\n",
      "762:\tlearn: 1.4473831\ttotal: 10.9s\tremaining: 3.38s\n",
      "763:\tlearn: 1.4473064\ttotal: 10.9s\tremaining: 3.37s\n",
      "764:\tlearn: 1.4471731\ttotal: 10.9s\tremaining: 3.35s\n",
      "765:\tlearn: 1.4469585\ttotal: 10.9s\tremaining: 3.34s\n",
      "766:\tlearn: 1.4469564\ttotal: 10.9s\tremaining: 3.33s\n",
      "767:\tlearn: 1.4468896\ttotal: 11s\tremaining: 3.31s\n",
      "768:\tlearn: 1.4468716\ttotal: 11s\tremaining: 3.3s\n",
      "769:\tlearn: 1.4468714\ttotal: 11s\tremaining: 3.28s\n",
      "770:\tlearn: 1.4468453\ttotal: 11s\tremaining: 3.27s\n",
      "771:\tlearn: 1.4468147\ttotal: 11s\tremaining: 3.25s\n",
      "772:\tlearn: 1.4468127\ttotal: 11s\tremaining: 3.24s\n",
      "773:\tlearn: 1.4468110\ttotal: 11s\tremaining: 3.23s\n",
      "774:\tlearn: 1.4468110\ttotal: 11.1s\tremaining: 3.21s\n",
      "775:\tlearn: 1.4468109\ttotal: 11.1s\tremaining: 3.2s\n",
      "776:\tlearn: 1.4468106\ttotal: 11.1s\tremaining: 3.18s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777:\tlearn: 1.4468084\ttotal: 11.1s\tremaining: 3.17s\n",
      "778:\tlearn: 1.4468080\ttotal: 11.1s\tremaining: 3.15s\n",
      "779:\tlearn: 1.4468077\ttotal: 11.1s\tremaining: 3.14s\n",
      "780:\tlearn: 1.4463569\ttotal: 11.2s\tremaining: 3.13s\n",
      "781:\tlearn: 1.4463466\ttotal: 11.2s\tremaining: 3.11s\n",
      "782:\tlearn: 1.4463466\ttotal: 11.2s\tremaining: 3.1s\n",
      "783:\tlearn: 1.4463466\ttotal: 11.2s\tremaining: 3.08s\n",
      "784:\tlearn: 1.4463381\ttotal: 11.2s\tremaining: 3.07s\n",
      "785:\tlearn: 1.4463381\ttotal: 11.2s\tremaining: 3.05s\n",
      "786:\tlearn: 1.4463381\ttotal: 11.2s\tremaining: 3.04s\n",
      "787:\tlearn: 1.4461222\ttotal: 11.2s\tremaining: 3.03s\n",
      "788:\tlearn: 1.4458278\ttotal: 11.3s\tremaining: 3.01s\n",
      "789:\tlearn: 1.4457122\ttotal: 11.3s\tremaining: 3s\n",
      "790:\tlearn: 1.4456809\ttotal: 11.3s\tremaining: 2.98s\n",
      "791:\tlearn: 1.4456129\ttotal: 11.3s\tremaining: 2.97s\n",
      "792:\tlearn: 1.4456129\ttotal: 11.3s\tremaining: 2.95s\n",
      "793:\tlearn: 1.4456083\ttotal: 11.3s\tremaining: 2.94s\n",
      "794:\tlearn: 1.4455503\ttotal: 11.3s\tremaining: 2.93s\n",
      "795:\tlearn: 1.4449112\ttotal: 11.4s\tremaining: 2.91s\n",
      "796:\tlearn: 1.4447315\ttotal: 11.4s\tremaining: 2.9s\n",
      "797:\tlearn: 1.4436842\ttotal: 11.4s\tremaining: 2.88s\n",
      "798:\tlearn: 1.4433208\ttotal: 11.4s\tremaining: 2.87s\n",
      "799:\tlearn: 1.4428558\ttotal: 11.4s\tremaining: 2.85s\n",
      "800:\tlearn: 1.4428558\ttotal: 11.4s\tremaining: 2.84s\n",
      "801:\tlearn: 1.4428558\ttotal: 11.5s\tremaining: 2.83s\n",
      "802:\tlearn: 1.4427753\ttotal: 11.5s\tremaining: 2.81s\n",
      "803:\tlearn: 1.4427370\ttotal: 11.5s\tremaining: 2.8s\n",
      "804:\tlearn: 1.4427243\ttotal: 11.5s\tremaining: 2.78s\n",
      "805:\tlearn: 1.4421201\ttotal: 11.5s\tremaining: 2.77s\n",
      "806:\tlearn: 1.4419534\ttotal: 11.5s\tremaining: 2.75s\n",
      "807:\tlearn: 1.4418546\ttotal: 11.5s\tremaining: 2.74s\n",
      "808:\tlearn: 1.4412153\ttotal: 11.6s\tremaining: 2.73s\n",
      "809:\tlearn: 1.4412057\ttotal: 11.6s\tremaining: 2.71s\n",
      "810:\tlearn: 1.4412054\ttotal: 11.6s\tremaining: 2.7s\n",
      "811:\tlearn: 1.4411570\ttotal: 11.6s\tremaining: 2.68s\n",
      "812:\tlearn: 1.4411528\ttotal: 11.6s\tremaining: 2.67s\n",
      "813:\tlearn: 1.4411340\ttotal: 11.6s\tremaining: 2.65s\n",
      "814:\tlearn: 1.4409021\ttotal: 11.6s\tremaining: 2.64s\n",
      "815:\tlearn: 1.4407006\ttotal: 11.7s\tremaining: 2.63s\n",
      "816:\tlearn: 1.4406937\ttotal: 11.7s\tremaining: 2.61s\n",
      "817:\tlearn: 1.4406888\ttotal: 11.7s\tremaining: 2.6s\n",
      "818:\tlearn: 1.4406614\ttotal: 11.7s\tremaining: 2.58s\n",
      "819:\tlearn: 1.4406416\ttotal: 11.7s\tremaining: 2.57s\n",
      "820:\tlearn: 1.4406180\ttotal: 11.7s\tremaining: 2.56s\n",
      "821:\tlearn: 1.4403724\ttotal: 11.7s\tremaining: 2.54s\n",
      "822:\tlearn: 1.4403718\ttotal: 11.8s\tremaining: 2.53s\n",
      "823:\tlearn: 1.4403718\ttotal: 11.8s\tremaining: 2.51s\n",
      "824:\tlearn: 1.4403716\ttotal: 11.8s\tremaining: 2.5s\n",
      "825:\tlearn: 1.4402761\ttotal: 11.8s\tremaining: 2.48s\n",
      "826:\tlearn: 1.4400590\ttotal: 11.8s\tremaining: 2.47s\n",
      "827:\tlearn: 1.4400133\ttotal: 11.8s\tremaining: 2.46s\n",
      "828:\tlearn: 1.4399948\ttotal: 11.8s\tremaining: 2.44s\n",
      "829:\tlearn: 1.4399195\ttotal: 11.8s\tremaining: 2.43s\n",
      "830:\tlearn: 1.4399121\ttotal: 11.9s\tremaining: 2.41s\n",
      "831:\tlearn: 1.4399115\ttotal: 11.9s\tremaining: 2.4s\n",
      "832:\tlearn: 1.4399114\ttotal: 11.9s\tremaining: 2.38s\n",
      "833:\tlearn: 1.4398950\ttotal: 11.9s\tremaining: 2.37s\n",
      "834:\tlearn: 1.4398805\ttotal: 11.9s\tremaining: 2.35s\n",
      "835:\tlearn: 1.4397176\ttotal: 11.9s\tremaining: 2.34s\n",
      "836:\tlearn: 1.4394311\ttotal: 11.9s\tremaining: 2.33s\n",
      "837:\tlearn: 1.4391105\ttotal: 12s\tremaining: 2.31s\n",
      "838:\tlearn: 1.4386626\ttotal: 12s\tremaining: 2.3s\n",
      "839:\tlearn: 1.4385998\ttotal: 12s\tremaining: 2.28s\n",
      "840:\tlearn: 1.4384960\ttotal: 12s\tremaining: 2.27s\n",
      "841:\tlearn: 1.4384930\ttotal: 12s\tremaining: 2.25s\n",
      "842:\tlearn: 1.4384429\ttotal: 12s\tremaining: 2.24s\n",
      "843:\tlearn: 1.4383800\ttotal: 12s\tremaining: 2.23s\n",
      "844:\tlearn: 1.4383373\ttotal: 12.1s\tremaining: 2.21s\n",
      "845:\tlearn: 1.4380541\ttotal: 12.1s\tremaining: 2.2s\n",
      "846:\tlearn: 1.4379657\ttotal: 12.1s\tremaining: 2.18s\n",
      "847:\tlearn: 1.4372534\ttotal: 12.1s\tremaining: 2.17s\n",
      "848:\tlearn: 1.4372156\ttotal: 12.1s\tremaining: 2.15s\n",
      "849:\tlearn: 1.4370824\ttotal: 12.1s\tremaining: 2.14s\n",
      "850:\tlearn: 1.4370760\ttotal: 12.1s\tremaining: 2.13s\n",
      "851:\tlearn: 1.4370711\ttotal: 12.2s\tremaining: 2.11s\n",
      "852:\tlearn: 1.4370708\ttotal: 12.2s\tremaining: 2.1s\n",
      "853:\tlearn: 1.4370704\ttotal: 12.2s\tremaining: 2.08s\n",
      "854:\tlearn: 1.4369730\ttotal: 12.2s\tremaining: 2.07s\n",
      "855:\tlearn: 1.4369163\ttotal: 12.2s\tremaining: 2.06s\n",
      "856:\tlearn: 1.4369135\ttotal: 12.2s\tremaining: 2.04s\n",
      "857:\tlearn: 1.4368519\ttotal: 12.3s\tremaining: 2.03s\n",
      "858:\tlearn: 1.4368490\ttotal: 12.3s\tremaining: 2.01s\n",
      "859:\tlearn: 1.4368485\ttotal: 12.3s\tremaining: 2s\n",
      "860:\tlearn: 1.4364874\ttotal: 12.3s\tremaining: 1.98s\n",
      "861:\tlearn: 1.4364868\ttotal: 12.3s\tremaining: 1.97s\n",
      "862:\tlearn: 1.4364712\ttotal: 12.3s\tremaining: 1.96s\n",
      "863:\tlearn: 1.4362021\ttotal: 12.3s\tremaining: 1.94s\n",
      "864:\tlearn: 1.4360409\ttotal: 12.4s\tremaining: 1.93s\n",
      "865:\tlearn: 1.4359395\ttotal: 12.4s\tremaining: 1.91s\n",
      "866:\tlearn: 1.4358441\ttotal: 12.4s\tremaining: 1.9s\n",
      "867:\tlearn: 1.4358245\ttotal: 12.4s\tremaining: 1.89s\n",
      "868:\tlearn: 1.4358245\ttotal: 12.4s\tremaining: 1.87s\n",
      "869:\tlearn: 1.4357902\ttotal: 12.4s\tremaining: 1.86s\n",
      "870:\tlearn: 1.4357464\ttotal: 12.4s\tremaining: 1.84s\n",
      "871:\tlearn: 1.4357464\ttotal: 12.5s\tremaining: 1.83s\n",
      "872:\tlearn: 1.4357429\ttotal: 12.5s\tremaining: 1.81s\n",
      "873:\tlearn: 1.4356273\ttotal: 12.5s\tremaining: 1.8s\n",
      "874:\tlearn: 1.4356246\ttotal: 12.5s\tremaining: 1.78s\n",
      "875:\tlearn: 1.4354741\ttotal: 12.5s\tremaining: 1.77s\n",
      "876:\tlearn: 1.4352950\ttotal: 12.5s\tremaining: 1.76s\n",
      "877:\tlearn: 1.4349662\ttotal: 12.5s\tremaining: 1.74s\n",
      "878:\tlearn: 1.4346433\ttotal: 12.5s\tremaining: 1.73s\n",
      "879:\tlearn: 1.4342259\ttotal: 12.6s\tremaining: 1.71s\n",
      "880:\tlearn: 1.4342218\ttotal: 12.6s\tremaining: 1.7s\n",
      "881:\tlearn: 1.4342218\ttotal: 12.6s\tremaining: 1.68s\n",
      "882:\tlearn: 1.4341899\ttotal: 12.6s\tremaining: 1.67s\n",
      "883:\tlearn: 1.4341689\ttotal: 12.6s\tremaining: 1.66s\n",
      "884:\tlearn: 1.4340885\ttotal: 12.6s\tremaining: 1.64s\n",
      "885:\tlearn: 1.4340387\ttotal: 12.7s\tremaining: 1.63s\n",
      "886:\tlearn: 1.4340370\ttotal: 12.7s\tremaining: 1.61s\n",
      "887:\tlearn: 1.4339503\ttotal: 12.7s\tremaining: 1.6s\n",
      "888:\tlearn: 1.4338503\ttotal: 12.7s\tremaining: 1.58s\n",
      "889:\tlearn: 1.4337319\ttotal: 12.7s\tremaining: 1.57s\n",
      "890:\tlearn: 1.4332970\ttotal: 12.7s\tremaining: 1.56s\n",
      "891:\tlearn: 1.4332932\ttotal: 12.7s\tremaining: 1.54s\n",
      "892:\tlearn: 1.4332777\ttotal: 12.8s\tremaining: 1.53s\n",
      "893:\tlearn: 1.4332496\ttotal: 12.8s\tremaining: 1.51s\n",
      "894:\tlearn: 1.4332344\ttotal: 12.8s\tremaining: 1.5s\n",
      "895:\tlearn: 1.4331687\ttotal: 12.8s\tremaining: 1.48s\n",
      "896:\tlearn: 1.4331644\ttotal: 12.8s\tremaining: 1.47s\n",
      "897:\tlearn: 1.4330821\ttotal: 12.8s\tremaining: 1.46s\n",
      "898:\tlearn: 1.4330177\ttotal: 12.8s\tremaining: 1.44s\n",
      "899:\tlearn: 1.4328060\ttotal: 12.9s\tremaining: 1.43s\n",
      "900:\tlearn: 1.4328055\ttotal: 12.9s\tremaining: 1.41s\n",
      "901:\tlearn: 1.4321329\ttotal: 12.9s\tremaining: 1.4s\n",
      "902:\tlearn: 1.4321302\ttotal: 12.9s\tremaining: 1.39s\n",
      "903:\tlearn: 1.4320916\ttotal: 12.9s\tremaining: 1.37s\n",
      "904:\tlearn: 1.4320673\ttotal: 12.9s\tremaining: 1.36s\n",
      "905:\tlearn: 1.4315894\ttotal: 12.9s\tremaining: 1.34s\n",
      "906:\tlearn: 1.4311671\ttotal: 12.9s\tremaining: 1.33s\n",
      "907:\tlearn: 1.4308636\ttotal: 13s\tremaining: 1.31s\n",
      "908:\tlearn: 1.4304676\ttotal: 13s\tremaining: 1.3s\n",
      "909:\tlearn: 1.4304268\ttotal: 13s\tremaining: 1.28s\n",
      "910:\tlearn: 1.4301427\ttotal: 13s\tremaining: 1.27s\n",
      "911:\tlearn: 1.4301183\ttotal: 13s\tremaining: 1.26s\n",
      "912:\tlearn: 1.4301181\ttotal: 13s\tremaining: 1.24s\n",
      "913:\tlearn: 1.4301181\ttotal: 13.1s\tremaining: 1.23s\n",
      "914:\tlearn: 1.4301160\ttotal: 13.1s\tremaining: 1.21s\n",
      "915:\tlearn: 1.4295567\ttotal: 13.1s\tremaining: 1.2s\n",
      "916:\tlearn: 1.4295511\ttotal: 13.1s\tremaining: 1.19s\n",
      "917:\tlearn: 1.4289237\ttotal: 13.1s\tremaining: 1.17s\n",
      "918:\tlearn: 1.4289119\ttotal: 13.1s\tremaining: 1.16s\n",
      "919:\tlearn: 1.4288900\ttotal: 13.1s\tremaining: 1.14s\n",
      "920:\tlearn: 1.4286618\ttotal: 13.1s\tremaining: 1.13s\n",
      "921:\tlearn: 1.4286458\ttotal: 13.2s\tremaining: 1.11s\n",
      "922:\tlearn: 1.4286386\ttotal: 13.2s\tremaining: 1.1s\n",
      "923:\tlearn: 1.4286345\ttotal: 13.2s\tremaining: 1.08s\n",
      "924:\tlearn: 1.4283614\ttotal: 13.2s\tremaining: 1.07s\n",
      "925:\tlearn: 1.4283431\ttotal: 13.2s\tremaining: 1.06s\n",
      "926:\tlearn: 1.4278354\ttotal: 13.2s\tremaining: 1.04s\n",
      "927:\tlearn: 1.4275659\ttotal: 13.2s\tremaining: 1.03s\n",
      "928:\tlearn: 1.4275379\ttotal: 13.3s\tremaining: 1.01s\n",
      "929:\tlearn: 1.4274746\ttotal: 13.3s\tremaining: 999ms\n",
      "930:\tlearn: 1.4269330\ttotal: 13.3s\tremaining: 985ms\n",
      "931:\tlearn: 1.4265290\ttotal: 13.3s\tremaining: 971ms\n",
      "932:\tlearn: 1.4263380\ttotal: 13.3s\tremaining: 956ms\n",
      "933:\tlearn: 1.4260744\ttotal: 13.3s\tremaining: 942ms\n",
      "934:\tlearn: 1.4260638\ttotal: 13.3s\tremaining: 928ms\n",
      "935:\tlearn: 1.4260469\ttotal: 13.4s\tremaining: 913ms\n",
      "936:\tlearn: 1.4258804\ttotal: 13.4s\tremaining: 899ms\n",
      "937:\tlearn: 1.4258753\ttotal: 13.4s\tremaining: 885ms\n",
      "938:\tlearn: 1.4249645\ttotal: 13.4s\tremaining: 871ms\n",
      "939:\tlearn: 1.4249553\ttotal: 13.4s\tremaining: 856ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "940:\tlearn: 1.4249433\ttotal: 13.4s\tremaining: 842ms\n",
      "941:\tlearn: 1.4249431\ttotal: 13.4s\tremaining: 828ms\n",
      "942:\tlearn: 1.4249333\ttotal: 13.5s\tremaining: 814ms\n",
      "943:\tlearn: 1.4249077\ttotal: 13.5s\tremaining: 799ms\n",
      "944:\tlearn: 1.4249009\ttotal: 13.5s\tremaining: 785ms\n",
      "945:\tlearn: 1.4249009\ttotal: 13.5s\tremaining: 771ms\n",
      "946:\tlearn: 1.4246198\ttotal: 13.5s\tremaining: 757ms\n",
      "947:\tlearn: 1.4245548\ttotal: 13.5s\tremaining: 742ms\n",
      "948:\tlearn: 1.4245509\ttotal: 13.5s\tremaining: 728ms\n",
      "949:\tlearn: 1.4245502\ttotal: 13.6s\tremaining: 714ms\n",
      "950:\tlearn: 1.4245500\ttotal: 13.6s\tremaining: 699ms\n",
      "951:\tlearn: 1.4245333\ttotal: 13.6s\tremaining: 685ms\n",
      "952:\tlearn: 1.4245219\ttotal: 13.6s\tremaining: 671ms\n",
      "953:\tlearn: 1.4245217\ttotal: 13.6s\tremaining: 656ms\n",
      "954:\tlearn: 1.4243353\ttotal: 13.6s\tremaining: 642ms\n",
      "955:\tlearn: 1.4243314\ttotal: 13.6s\tremaining: 628ms\n",
      "956:\tlearn: 1.4243314\ttotal: 13.7s\tremaining: 614ms\n",
      "957:\tlearn: 1.4243272\ttotal: 13.7s\tremaining: 599ms\n",
      "958:\tlearn: 1.4243270\ttotal: 13.7s\tremaining: 585ms\n",
      "959:\tlearn: 1.4243149\ttotal: 13.7s\tremaining: 571ms\n",
      "960:\tlearn: 1.4242213\ttotal: 13.7s\tremaining: 557ms\n",
      "961:\tlearn: 1.4242078\ttotal: 13.7s\tremaining: 542ms\n",
      "962:\tlearn: 1.4239123\ttotal: 13.7s\tremaining: 528ms\n",
      "963:\tlearn: 1.4238812\ttotal: 13.8s\tremaining: 514ms\n",
      "964:\tlearn: 1.4238800\ttotal: 13.8s\tremaining: 500ms\n",
      "965:\tlearn: 1.4235928\ttotal: 13.8s\tremaining: 485ms\n",
      "966:\tlearn: 1.4235034\ttotal: 13.8s\tremaining: 471ms\n",
      "967:\tlearn: 1.4234932\ttotal: 13.8s\tremaining: 457ms\n",
      "968:\tlearn: 1.4234903\ttotal: 13.8s\tremaining: 442ms\n",
      "969:\tlearn: 1.4233046\ttotal: 13.8s\tremaining: 428ms\n",
      "970:\tlearn: 1.4232976\ttotal: 13.9s\tremaining: 414ms\n",
      "971:\tlearn: 1.4231757\ttotal: 13.9s\tremaining: 400ms\n",
      "972:\tlearn: 1.4231693\ttotal: 13.9s\tremaining: 385ms\n",
      "973:\tlearn: 1.4229106\ttotal: 13.9s\tremaining: 371ms\n",
      "974:\tlearn: 1.4227480\ttotal: 13.9s\tremaining: 357ms\n",
      "975:\tlearn: 1.4227449\ttotal: 13.9s\tremaining: 343ms\n",
      "976:\tlearn: 1.4224691\ttotal: 13.9s\tremaining: 328ms\n",
      "977:\tlearn: 1.4224454\ttotal: 14s\tremaining: 314ms\n",
      "978:\tlearn: 1.4221296\ttotal: 14s\tremaining: 300ms\n",
      "979:\tlearn: 1.4218117\ttotal: 14s\tremaining: 285ms\n",
      "980:\tlearn: 1.4217741\ttotal: 14s\tremaining: 271ms\n",
      "981:\tlearn: 1.4217529\ttotal: 14s\tremaining: 257ms\n",
      "982:\tlearn: 1.4217301\ttotal: 14s\tremaining: 243ms\n",
      "983:\tlearn: 1.4215865\ttotal: 14s\tremaining: 228ms\n",
      "984:\tlearn: 1.4215490\ttotal: 14.1s\tremaining: 214ms\n",
      "985:\tlearn: 1.4213931\ttotal: 14.1s\tremaining: 200ms\n",
      "986:\tlearn: 1.4213665\ttotal: 14.1s\tremaining: 186ms\n",
      "987:\tlearn: 1.4209686\ttotal: 14.1s\tremaining: 171ms\n",
      "988:\tlearn: 1.4208440\ttotal: 14.1s\tremaining: 157ms\n",
      "989:\tlearn: 1.4208390\ttotal: 14.1s\tremaining: 143ms\n",
      "990:\tlearn: 1.4208389\ttotal: 14.2s\tremaining: 129ms\n",
      "991:\tlearn: 1.4203988\ttotal: 14.2s\tremaining: 114ms\n",
      "992:\tlearn: 1.4203920\ttotal: 14.2s\tremaining: 100ms\n",
      "993:\tlearn: 1.4203802\ttotal: 14.2s\tremaining: 85.7ms\n",
      "994:\tlearn: 1.4200669\ttotal: 14.2s\tremaining: 71.4ms\n",
      "995:\tlearn: 1.4200557\ttotal: 14.2s\tremaining: 57.1ms\n",
      "996:\tlearn: 1.4196327\ttotal: 14.2s\tremaining: 42.8ms\n",
      "997:\tlearn: 1.4196324\ttotal: 14.3s\tremaining: 28.6ms\n",
      "998:\tlearn: 1.4196311\ttotal: 14.3s\tremaining: 14.3ms\n",
      "999:\tlearn: 1.4195533\ttotal: 14.3s\tremaining: 0us\n",
      "0:\tlearn: 7.7363396\ttotal: 18ms\tremaining: 18s\n",
      "1:\tlearn: 7.1942445\ttotal: 36.1ms\tremaining: 18s\n",
      "2:\tlearn: 6.6802956\ttotal: 54.2ms\tremaining: 18s\n",
      "3:\tlearn: 6.2028020\ttotal: 72.4ms\tremaining: 18s\n",
      "4:\tlearn: 5.7018303\ttotal: 90.7ms\tremaining: 18.1s\n",
      "5:\tlearn: 5.3417593\ttotal: 109ms\tremaining: 18s\n",
      "6:\tlearn: 4.9361376\ttotal: 126ms\tremaining: 17.9s\n",
      "7:\tlearn: 4.5860986\ttotal: 144ms\tremaining: 17.8s\n",
      "8:\tlearn: 4.2543175\ttotal: 161ms\tremaining: 17.7s\n",
      "9:\tlearn: 3.9421313\ttotal: 179ms\tremaining: 17.7s\n",
      "10:\tlearn: 3.6916733\ttotal: 197ms\tremaining: 17.7s\n",
      "11:\tlearn: 3.5131462\ttotal: 214ms\tremaining: 17.6s\n",
      "12:\tlearn: 3.3557144\ttotal: 232ms\tremaining: 17.6s\n",
      "13:\tlearn: 3.1571921\ttotal: 250ms\tremaining: 17.6s\n",
      "14:\tlearn: 3.0417049\ttotal: 266ms\tremaining: 17.5s\n",
      "15:\tlearn: 2.9387032\ttotal: 283ms\tremaining: 17.4s\n",
      "16:\tlearn: 2.8037035\ttotal: 302ms\tremaining: 17.4s\n",
      "17:\tlearn: 2.6825430\ttotal: 319ms\tremaining: 17.4s\n",
      "18:\tlearn: 2.6131815\ttotal: 335ms\tremaining: 17.3s\n",
      "19:\tlearn: 2.5164971\ttotal: 352ms\tremaining: 17.3s\n",
      "20:\tlearn: 2.4673435\ttotal: 369ms\tremaining: 17.2s\n",
      "21:\tlearn: 2.4188497\ttotal: 386ms\tremaining: 17.2s\n",
      "22:\tlearn: 2.3798825\ttotal: 404ms\tremaining: 17.1s\n",
      "23:\tlearn: 2.3121073\ttotal: 421ms\tremaining: 17.1s\n",
      "24:\tlearn: 2.2592076\ttotal: 439ms\tremaining: 17.1s\n",
      "25:\tlearn: 2.2327586\ttotal: 458ms\tremaining: 17.1s\n",
      "26:\tlearn: 2.2094816\ttotal: 474ms\tremaining: 17.1s\n",
      "27:\tlearn: 2.1692380\ttotal: 495ms\tremaining: 17.2s\n",
      "28:\tlearn: 2.1513174\ttotal: 514ms\tremaining: 17.2s\n",
      "29:\tlearn: 2.1126676\ttotal: 534ms\tremaining: 17.3s\n",
      "30:\tlearn: 2.0980670\ttotal: 552ms\tremaining: 17.3s\n",
      "31:\tlearn: 2.0844858\ttotal: 570ms\tremaining: 17.3s\n",
      "32:\tlearn: 2.0575448\ttotal: 589ms\tremaining: 17.3s\n",
      "33:\tlearn: 2.0332401\ttotal: 607ms\tremaining: 17.2s\n",
      "34:\tlearn: 2.0251430\ttotal: 625ms\tremaining: 17.2s\n",
      "35:\tlearn: 2.0158696\ttotal: 644ms\tremaining: 17.3s\n",
      "36:\tlearn: 1.9997434\ttotal: 664ms\tremaining: 17.3s\n",
      "37:\tlearn: 1.9798144\ttotal: 681ms\tremaining: 17.2s\n",
      "38:\tlearn: 1.9750801\ttotal: 699ms\tremaining: 17.2s\n",
      "39:\tlearn: 1.9709956\ttotal: 714ms\tremaining: 17.1s\n",
      "40:\tlearn: 1.9643633\ttotal: 731ms\tremaining: 17.1s\n",
      "41:\tlearn: 1.9594847\ttotal: 747ms\tremaining: 17s\n",
      "42:\tlearn: 1.9559500\ttotal: 764ms\tremaining: 17s\n",
      "43:\tlearn: 1.9546472\ttotal: 781ms\tremaining: 17s\n",
      "44:\tlearn: 1.9527022\ttotal: 797ms\tremaining: 16.9s\n",
      "45:\tlearn: 1.9503985\ttotal: 813ms\tremaining: 16.9s\n",
      "46:\tlearn: 1.9437658\ttotal: 830ms\tremaining: 16.8s\n",
      "47:\tlearn: 1.9408190\ttotal: 848ms\tremaining: 16.8s\n",
      "48:\tlearn: 1.9370822\ttotal: 864ms\tremaining: 16.8s\n",
      "49:\tlearn: 1.9350379\ttotal: 883ms\tremaining: 16.8s\n",
      "50:\tlearn: 1.9344470\ttotal: 901ms\tremaining: 16.8s\n",
      "51:\tlearn: 1.9320180\ttotal: 916ms\tremaining: 16.7s\n",
      "52:\tlearn: 1.9318358\ttotal: 932ms\tremaining: 16.6s\n",
      "53:\tlearn: 1.9308543\ttotal: 947ms\tremaining: 16.6s\n",
      "54:\tlearn: 1.9237713\ttotal: 964ms\tremaining: 16.6s\n",
      "55:\tlearn: 1.9085301\ttotal: 981ms\tremaining: 16.5s\n",
      "56:\tlearn: 1.9055188\ttotal: 997ms\tremaining: 16.5s\n",
      "57:\tlearn: 1.9044848\ttotal: 1.01s\tremaining: 16.5s\n",
      "58:\tlearn: 1.9043663\ttotal: 1.03s\tremaining: 16.4s\n",
      "59:\tlearn: 1.9035879\ttotal: 1.04s\tremaining: 16.4s\n",
      "60:\tlearn: 1.9032118\ttotal: 1.06s\tremaining: 16.4s\n",
      "61:\tlearn: 1.9026836\ttotal: 1.08s\tremaining: 16.3s\n",
      "62:\tlearn: 1.9015586\ttotal: 1.1s\tremaining: 16.3s\n",
      "63:\tlearn: 1.8999190\ttotal: 1.11s\tremaining: 16.3s\n",
      "64:\tlearn: 1.8995865\ttotal: 1.13s\tremaining: 16.2s\n",
      "65:\tlearn: 1.8993495\ttotal: 1.14s\tremaining: 16.2s\n",
      "66:\tlearn: 1.8985254\ttotal: 1.16s\tremaining: 16.1s\n",
      "67:\tlearn: 1.8952995\ttotal: 1.18s\tremaining: 16.1s\n",
      "68:\tlearn: 1.8908065\ttotal: 1.19s\tremaining: 16.1s\n",
      "69:\tlearn: 1.8893996\ttotal: 1.21s\tremaining: 16s\n",
      "70:\tlearn: 1.8892314\ttotal: 1.22s\tremaining: 16s\n",
      "71:\tlearn: 1.8890631\ttotal: 1.24s\tremaining: 16s\n",
      "72:\tlearn: 1.8887791\ttotal: 1.25s\tremaining: 15.9s\n",
      "73:\tlearn: 1.8885602\ttotal: 1.27s\tremaining: 15.9s\n",
      "74:\tlearn: 1.8881951\ttotal: 1.29s\tremaining: 15.9s\n",
      "75:\tlearn: 1.8873591\ttotal: 1.3s\tremaining: 15.9s\n",
      "76:\tlearn: 1.8859059\ttotal: 1.32s\tremaining: 15.8s\n",
      "77:\tlearn: 1.8858177\ttotal: 1.34s\tremaining: 15.8s\n",
      "78:\tlearn: 1.8850594\ttotal: 1.35s\tremaining: 15.8s\n",
      "79:\tlearn: 1.8747827\ttotal: 1.37s\tremaining: 15.8s\n",
      "80:\tlearn: 1.8729075\ttotal: 1.39s\tremaining: 15.7s\n",
      "81:\tlearn: 1.8640891\ttotal: 1.4s\tremaining: 15.7s\n",
      "82:\tlearn: 1.8637815\ttotal: 1.42s\tremaining: 15.7s\n",
      "83:\tlearn: 1.8634911\ttotal: 1.43s\tremaining: 15.6s\n",
      "84:\tlearn: 1.8599992\ttotal: 1.45s\tremaining: 15.6s\n",
      "85:\tlearn: 1.8597412\ttotal: 1.47s\tremaining: 15.6s\n",
      "86:\tlearn: 1.8595355\ttotal: 1.48s\tremaining: 15.6s\n",
      "87:\tlearn: 1.8587448\ttotal: 1.5s\tremaining: 15.5s\n",
      "88:\tlearn: 1.8575030\ttotal: 1.51s\tremaining: 15.5s\n",
      "89:\tlearn: 1.8562056\ttotal: 1.53s\tremaining: 15.5s\n",
      "90:\tlearn: 1.8559219\ttotal: 1.55s\tremaining: 15.5s\n",
      "91:\tlearn: 1.8545473\ttotal: 1.56s\tremaining: 15.4s\n",
      "92:\tlearn: 1.8545450\ttotal: 1.58s\tremaining: 15.4s\n",
      "93:\tlearn: 1.8538355\ttotal: 1.59s\tremaining: 15.3s\n",
      "94:\tlearn: 1.8534858\ttotal: 1.61s\tremaining: 15.3s\n",
      "95:\tlearn: 1.8533704\ttotal: 1.62s\tremaining: 15.3s\n",
      "96:\tlearn: 1.8533137\ttotal: 1.64s\tremaining: 15.2s\n",
      "97:\tlearn: 1.8524898\ttotal: 1.65s\tremaining: 15.2s\n",
      "98:\tlearn: 1.8432344\ttotal: 1.67s\tremaining: 15.2s\n",
      "99:\tlearn: 1.8429704\ttotal: 1.68s\tremaining: 15.2s\n",
      "100:\tlearn: 1.8427771\ttotal: 1.7s\tremaining: 15.1s\n",
      "101:\tlearn: 1.8405458\ttotal: 1.72s\tremaining: 15.1s\n",
      "102:\tlearn: 1.8404499\ttotal: 1.74s\tremaining: 15.1s\n",
      "103:\tlearn: 1.8312030\ttotal: 1.76s\tremaining: 15.1s\n",
      "104:\tlearn: 1.8303361\ttotal: 1.78s\tremaining: 15.1s\n",
      "105:\tlearn: 1.8299903\ttotal: 1.79s\tremaining: 15.1s\n",
      "106:\tlearn: 1.8298594\ttotal: 1.81s\tremaining: 15.1s\n",
      "107:\tlearn: 1.8275312\ttotal: 1.83s\tremaining: 15.1s\n",
      "108:\tlearn: 1.8269531\ttotal: 1.85s\tremaining: 15.1s\n",
      "109:\tlearn: 1.8268448\ttotal: 1.87s\tremaining: 15.1s\n",
      "110:\tlearn: 1.8264581\ttotal: 1.88s\tremaining: 15.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111:\tlearn: 1.8259661\ttotal: 1.9s\tremaining: 15.1s\n",
      "112:\tlearn: 1.8251750\ttotal: 1.92s\tremaining: 15.1s\n",
      "113:\tlearn: 1.8250206\ttotal: 1.94s\tremaining: 15s\n",
      "114:\tlearn: 1.8249795\ttotal: 1.95s\tremaining: 15s\n",
      "115:\tlearn: 1.8234450\ttotal: 1.97s\tremaining: 15s\n",
      "116:\tlearn: 1.8205446\ttotal: 1.98s\tremaining: 15s\n",
      "117:\tlearn: 1.8201721\ttotal: 2s\tremaining: 14.9s\n",
      "118:\tlearn: 1.8198680\ttotal: 2.01s\tremaining: 14.9s\n",
      "119:\tlearn: 1.8099870\ttotal: 2.03s\tremaining: 14.9s\n",
      "120:\tlearn: 1.8066177\ttotal: 2.05s\tremaining: 14.9s\n",
      "121:\tlearn: 1.8005126\ttotal: 2.06s\tremaining: 14.8s\n",
      "122:\tlearn: 1.7961012\ttotal: 2.08s\tremaining: 14.8s\n",
      "123:\tlearn: 1.7956833\ttotal: 2.09s\tremaining: 14.8s\n",
      "124:\tlearn: 1.7905448\ttotal: 2.11s\tremaining: 14.8s\n",
      "125:\tlearn: 1.7891939\ttotal: 2.13s\tremaining: 14.7s\n",
      "126:\tlearn: 1.7886773\ttotal: 2.14s\tremaining: 14.7s\n",
      "127:\tlearn: 1.7873164\ttotal: 2.15s\tremaining: 14.7s\n",
      "128:\tlearn: 1.7848580\ttotal: 2.17s\tremaining: 14.7s\n",
      "129:\tlearn: 1.7763639\ttotal: 2.19s\tremaining: 14.6s\n",
      "130:\tlearn: 1.7757335\ttotal: 2.2s\tremaining: 14.6s\n",
      "131:\tlearn: 1.7756962\ttotal: 2.22s\tremaining: 14.6s\n",
      "132:\tlearn: 1.7753400\ttotal: 2.23s\tremaining: 14.5s\n",
      "133:\tlearn: 1.7751805\ttotal: 2.25s\tremaining: 14.5s\n",
      "134:\tlearn: 1.7751060\ttotal: 2.26s\tremaining: 14.5s\n",
      "135:\tlearn: 1.7747315\ttotal: 2.28s\tremaining: 14.5s\n",
      "136:\tlearn: 1.7746075\ttotal: 2.29s\tremaining: 14.4s\n",
      "137:\tlearn: 1.7745441\ttotal: 2.31s\tremaining: 14.4s\n",
      "138:\tlearn: 1.7744534\ttotal: 2.32s\tremaining: 14.4s\n",
      "139:\tlearn: 1.7742810\ttotal: 2.34s\tremaining: 14.4s\n",
      "140:\tlearn: 1.7741720\ttotal: 2.35s\tremaining: 14.3s\n",
      "141:\tlearn: 1.7706893\ttotal: 2.37s\tremaining: 14.3s\n",
      "142:\tlearn: 1.7704892\ttotal: 2.38s\tremaining: 14.3s\n",
      "143:\tlearn: 1.7692384\ttotal: 2.4s\tremaining: 14.2s\n",
      "144:\tlearn: 1.7691759\ttotal: 2.41s\tremaining: 14.2s\n",
      "145:\tlearn: 1.7691084\ttotal: 2.43s\tremaining: 14.2s\n",
      "146:\tlearn: 1.7689502\ttotal: 2.44s\tremaining: 14.2s\n",
      "147:\tlearn: 1.7687881\ttotal: 2.46s\tremaining: 14.1s\n",
      "148:\tlearn: 1.7686982\ttotal: 2.47s\tremaining: 14.1s\n",
      "149:\tlearn: 1.7686444\ttotal: 2.48s\tremaining: 14.1s\n",
      "150:\tlearn: 1.7684003\ttotal: 2.5s\tremaining: 14.1s\n",
      "151:\tlearn: 1.7683098\ttotal: 2.52s\tremaining: 14s\n",
      "152:\tlearn: 1.7682178\ttotal: 2.53s\tremaining: 14s\n",
      "153:\tlearn: 1.7680332\ttotal: 2.54s\tremaining: 14s\n",
      "154:\tlearn: 1.7665096\ttotal: 2.56s\tremaining: 14s\n",
      "155:\tlearn: 1.7626502\ttotal: 2.58s\tremaining: 13.9s\n",
      "156:\tlearn: 1.7621092\ttotal: 2.59s\tremaining: 13.9s\n",
      "157:\tlearn: 1.7562211\ttotal: 2.61s\tremaining: 13.9s\n",
      "158:\tlearn: 1.7494947\ttotal: 2.62s\tremaining: 13.9s\n",
      "159:\tlearn: 1.7464626\ttotal: 2.64s\tremaining: 13.8s\n",
      "160:\tlearn: 1.7431066\ttotal: 2.65s\tremaining: 13.8s\n",
      "161:\tlearn: 1.7403949\ttotal: 2.67s\tremaining: 13.8s\n",
      "162:\tlearn: 1.7402739\ttotal: 2.68s\tremaining: 13.8s\n",
      "163:\tlearn: 1.7401199\ttotal: 2.7s\tremaining: 13.8s\n",
      "164:\tlearn: 1.7398089\ttotal: 2.71s\tremaining: 13.7s\n",
      "165:\tlearn: 1.7397384\ttotal: 2.73s\tremaining: 13.7s\n",
      "166:\tlearn: 1.7395108\ttotal: 2.74s\tremaining: 13.7s\n",
      "167:\tlearn: 1.7392830\ttotal: 2.76s\tremaining: 13.7s\n",
      "168:\tlearn: 1.7389589\ttotal: 2.78s\tremaining: 13.7s\n",
      "169:\tlearn: 1.7387353\ttotal: 2.79s\tremaining: 13.6s\n",
      "170:\tlearn: 1.7362343\ttotal: 2.81s\tremaining: 13.6s\n",
      "171:\tlearn: 1.7354000\ttotal: 2.82s\tremaining: 13.6s\n",
      "172:\tlearn: 1.7351245\ttotal: 2.84s\tremaining: 13.6s\n",
      "173:\tlearn: 1.7349294\ttotal: 2.85s\tremaining: 13.5s\n",
      "174:\tlearn: 1.7347011\ttotal: 2.87s\tremaining: 13.5s\n",
      "175:\tlearn: 1.7345231\ttotal: 2.88s\tremaining: 13.5s\n",
      "176:\tlearn: 1.7333666\ttotal: 2.9s\tremaining: 13.5s\n",
      "177:\tlearn: 1.7328974\ttotal: 2.91s\tremaining: 13.5s\n",
      "178:\tlearn: 1.7327566\ttotal: 2.93s\tremaining: 13.4s\n",
      "179:\tlearn: 1.7319477\ttotal: 2.94s\tremaining: 13.4s\n",
      "180:\tlearn: 1.7317614\ttotal: 2.96s\tremaining: 13.4s\n",
      "181:\tlearn: 1.7316414\ttotal: 2.98s\tremaining: 13.4s\n",
      "182:\tlearn: 1.7300208\ttotal: 2.99s\tremaining: 13.4s\n",
      "183:\tlearn: 1.7293949\ttotal: 3.01s\tremaining: 13.3s\n",
      "184:\tlearn: 1.7289575\ttotal: 3.02s\tremaining: 13.3s\n",
      "185:\tlearn: 1.7286798\ttotal: 3.04s\tremaining: 13.3s\n",
      "186:\tlearn: 1.7285692\ttotal: 3.06s\tremaining: 13.3s\n",
      "187:\tlearn: 1.7283644\ttotal: 3.07s\tremaining: 13.3s\n",
      "188:\tlearn: 1.7282955\ttotal: 3.09s\tremaining: 13.2s\n",
      "189:\tlearn: 1.7262435\ttotal: 3.1s\tremaining: 13.2s\n",
      "190:\tlearn: 1.7257990\ttotal: 3.12s\tremaining: 13.2s\n",
      "191:\tlearn: 1.7256955\ttotal: 3.13s\tremaining: 13.2s\n",
      "192:\tlearn: 1.7256360\ttotal: 3.15s\tremaining: 13.2s\n",
      "193:\tlearn: 1.7254522\ttotal: 3.16s\tremaining: 13.1s\n",
      "194:\tlearn: 1.7252552\ttotal: 3.18s\tremaining: 13.1s\n",
      "195:\tlearn: 1.7248529\ttotal: 3.2s\tremaining: 13.1s\n",
      "196:\tlearn: 1.7246878\ttotal: 3.21s\tremaining: 13.1s\n",
      "197:\tlearn: 1.7245564\ttotal: 3.23s\tremaining: 13.1s\n",
      "198:\tlearn: 1.7225241\ttotal: 3.24s\tremaining: 13.1s\n",
      "199:\tlearn: 1.7214963\ttotal: 3.26s\tremaining: 13s\n",
      "200:\tlearn: 1.7203967\ttotal: 3.27s\tremaining: 13s\n",
      "201:\tlearn: 1.7190301\ttotal: 3.29s\tremaining: 13s\n",
      "202:\tlearn: 1.7187863\ttotal: 3.31s\tremaining: 13s\n",
      "203:\tlearn: 1.7185968\ttotal: 3.32s\tremaining: 13s\n",
      "204:\tlearn: 1.7184402\ttotal: 3.34s\tremaining: 12.9s\n",
      "205:\tlearn: 1.7183114\ttotal: 3.35s\tremaining: 12.9s\n",
      "206:\tlearn: 1.7160941\ttotal: 3.37s\tremaining: 12.9s\n",
      "207:\tlearn: 1.7150344\ttotal: 3.38s\tremaining: 12.9s\n",
      "208:\tlearn: 1.7133233\ttotal: 3.4s\tremaining: 12.9s\n",
      "209:\tlearn: 1.7121517\ttotal: 3.42s\tremaining: 12.9s\n",
      "210:\tlearn: 1.7121011\ttotal: 3.43s\tremaining: 12.8s\n",
      "211:\tlearn: 1.7112844\ttotal: 3.44s\tremaining: 12.8s\n",
      "212:\tlearn: 1.7100094\ttotal: 3.46s\tremaining: 12.8s\n",
      "213:\tlearn: 1.7086073\ttotal: 3.47s\tremaining: 12.8s\n",
      "214:\tlearn: 1.7069367\ttotal: 3.49s\tremaining: 12.7s\n",
      "215:\tlearn: 1.7055621\ttotal: 3.5s\tremaining: 12.7s\n",
      "216:\tlearn: 1.7040617\ttotal: 3.52s\tremaining: 12.7s\n",
      "217:\tlearn: 1.7039301\ttotal: 3.53s\tremaining: 12.7s\n",
      "218:\tlearn: 1.7037744\ttotal: 3.55s\tremaining: 12.6s\n",
      "219:\tlearn: 1.7036581\ttotal: 3.56s\tremaining: 12.6s\n",
      "220:\tlearn: 1.7024160\ttotal: 3.58s\tremaining: 12.6s\n",
      "221:\tlearn: 1.7008400\ttotal: 3.59s\tremaining: 12.6s\n",
      "222:\tlearn: 1.6972906\ttotal: 3.6s\tremaining: 12.6s\n",
      "223:\tlearn: 1.6962417\ttotal: 3.62s\tremaining: 12.5s\n",
      "224:\tlearn: 1.6961630\ttotal: 3.64s\tremaining: 12.5s\n",
      "225:\tlearn: 1.6956694\ttotal: 3.65s\tremaining: 12.5s\n",
      "226:\tlearn: 1.6956426\ttotal: 3.67s\tremaining: 12.5s\n",
      "227:\tlearn: 1.6939881\ttotal: 3.68s\tremaining: 12.5s\n",
      "228:\tlearn: 1.6933633\ttotal: 3.69s\tremaining: 12.4s\n",
      "229:\tlearn: 1.6920588\ttotal: 3.71s\tremaining: 12.4s\n",
      "230:\tlearn: 1.6903785\ttotal: 3.72s\tremaining: 12.4s\n",
      "231:\tlearn: 1.6892742\ttotal: 3.74s\tremaining: 12.4s\n",
      "232:\tlearn: 1.6891824\ttotal: 3.75s\tremaining: 12.3s\n",
      "233:\tlearn: 1.6887645\ttotal: 3.77s\tremaining: 12.3s\n",
      "234:\tlearn: 1.6879766\ttotal: 3.78s\tremaining: 12.3s\n",
      "235:\tlearn: 1.6872770\ttotal: 3.79s\tremaining: 12.3s\n",
      "236:\tlearn: 1.6871899\ttotal: 3.81s\tremaining: 12.3s\n",
      "237:\tlearn: 1.6866706\ttotal: 3.82s\tremaining: 12.2s\n",
      "238:\tlearn: 1.6839648\ttotal: 3.84s\tremaining: 12.2s\n",
      "239:\tlearn: 1.6829916\ttotal: 3.85s\tremaining: 12.2s\n",
      "240:\tlearn: 1.6821867\ttotal: 3.87s\tremaining: 12.2s\n",
      "241:\tlearn: 1.6812095\ttotal: 3.88s\tremaining: 12.2s\n",
      "242:\tlearn: 1.6798521\ttotal: 3.9s\tremaining: 12.1s\n",
      "243:\tlearn: 1.6782639\ttotal: 3.91s\tremaining: 12.1s\n",
      "244:\tlearn: 1.6748362\ttotal: 3.92s\tremaining: 12.1s\n",
      "245:\tlearn: 1.6738944\ttotal: 3.94s\tremaining: 12.1s\n",
      "246:\tlearn: 1.6703935\ttotal: 3.95s\tremaining: 12.1s\n",
      "247:\tlearn: 1.6692043\ttotal: 3.97s\tremaining: 12s\n",
      "248:\tlearn: 1.6683941\ttotal: 3.98s\tremaining: 12s\n",
      "249:\tlearn: 1.6660075\ttotal: 4s\tremaining: 12s\n",
      "250:\tlearn: 1.6639736\ttotal: 4.01s\tremaining: 12s\n",
      "251:\tlearn: 1.6625610\ttotal: 4.03s\tremaining: 12s\n",
      "252:\tlearn: 1.6616889\ttotal: 4.04s\tremaining: 11.9s\n",
      "253:\tlearn: 1.6609611\ttotal: 4.06s\tremaining: 11.9s\n",
      "254:\tlearn: 1.6594255\ttotal: 4.07s\tremaining: 11.9s\n",
      "255:\tlearn: 1.6583120\ttotal: 4.09s\tremaining: 11.9s\n",
      "256:\tlearn: 1.6569459\ttotal: 4.1s\tremaining: 11.9s\n",
      "257:\tlearn: 1.6566082\ttotal: 4.12s\tremaining: 11.8s\n",
      "258:\tlearn: 1.6555884\ttotal: 4.13s\tremaining: 11.8s\n",
      "259:\tlearn: 1.6548625\ttotal: 4.14s\tremaining: 11.8s\n",
      "260:\tlearn: 1.6536203\ttotal: 4.16s\tremaining: 11.8s\n",
      "261:\tlearn: 1.6514329\ttotal: 4.17s\tremaining: 11.8s\n",
      "262:\tlearn: 1.6503350\ttotal: 4.19s\tremaining: 11.7s\n",
      "263:\tlearn: 1.6483387\ttotal: 4.2s\tremaining: 11.7s\n",
      "264:\tlearn: 1.6470432\ttotal: 4.22s\tremaining: 11.7s\n",
      "265:\tlearn: 1.6452637\ttotal: 4.23s\tremaining: 11.7s\n",
      "266:\tlearn: 1.6425874\ttotal: 4.25s\tremaining: 11.7s\n",
      "267:\tlearn: 1.6397011\ttotal: 4.26s\tremaining: 11.6s\n",
      "268:\tlearn: 1.6381097\ttotal: 4.28s\tremaining: 11.6s\n",
      "269:\tlearn: 1.6367478\ttotal: 4.29s\tremaining: 11.6s\n",
      "270:\tlearn: 1.6348818\ttotal: 4.31s\tremaining: 11.6s\n",
      "271:\tlearn: 1.6324368\ttotal: 4.32s\tremaining: 11.6s\n",
      "272:\tlearn: 1.6320320\ttotal: 4.34s\tremaining: 11.6s\n",
      "273:\tlearn: 1.6309347\ttotal: 4.35s\tremaining: 11.5s\n",
      "274:\tlearn: 1.6304683\ttotal: 4.37s\tremaining: 11.5s\n",
      "275:\tlearn: 1.6298638\ttotal: 4.38s\tremaining: 11.5s\n",
      "276:\tlearn: 1.6281336\ttotal: 4.39s\tremaining: 11.5s\n",
      "277:\tlearn: 1.6277494\ttotal: 4.41s\tremaining: 11.4s\n",
      "278:\tlearn: 1.6271590\ttotal: 4.42s\tremaining: 11.4s\n",
      "279:\tlearn: 1.6267622\ttotal: 4.44s\tremaining: 11.4s\n",
      "280:\tlearn: 1.6259869\ttotal: 4.45s\tremaining: 11.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281:\tlearn: 1.6250290\ttotal: 4.47s\tremaining: 11.4s\n",
      "282:\tlearn: 1.6239931\ttotal: 4.48s\tremaining: 11.4s\n",
      "283:\tlearn: 1.6232555\ttotal: 4.5s\tremaining: 11.3s\n",
      "284:\tlearn: 1.6217816\ttotal: 4.51s\tremaining: 11.3s\n",
      "285:\tlearn: 1.6210478\ttotal: 4.53s\tremaining: 11.3s\n",
      "286:\tlearn: 1.6204529\ttotal: 4.54s\tremaining: 11.3s\n",
      "287:\tlearn: 1.6194852\ttotal: 4.55s\tremaining: 11.3s\n",
      "288:\tlearn: 1.6191593\ttotal: 4.57s\tremaining: 11.2s\n",
      "289:\tlearn: 1.6181430\ttotal: 4.58s\tremaining: 11.2s\n",
      "290:\tlearn: 1.6180592\ttotal: 4.6s\tremaining: 11.2s\n",
      "291:\tlearn: 1.6177624\ttotal: 4.61s\tremaining: 11.2s\n",
      "292:\tlearn: 1.6163465\ttotal: 4.63s\tremaining: 11.2s\n",
      "293:\tlearn: 1.6159138\ttotal: 4.64s\tremaining: 11.1s\n",
      "294:\tlearn: 1.6157192\ttotal: 4.65s\tremaining: 11.1s\n",
      "295:\tlearn: 1.6152061\ttotal: 4.67s\tremaining: 11.1s\n",
      "296:\tlearn: 1.6138052\ttotal: 4.68s\tremaining: 11.1s\n",
      "297:\tlearn: 1.6134898\ttotal: 4.7s\tremaining: 11.1s\n",
      "298:\tlearn: 1.6128712\ttotal: 4.71s\tremaining: 11s\n",
      "299:\tlearn: 1.6115185\ttotal: 4.73s\tremaining: 11s\n",
      "300:\tlearn: 1.6104840\ttotal: 4.74s\tremaining: 11s\n",
      "301:\tlearn: 1.6096169\ttotal: 4.75s\tremaining: 11s\n",
      "302:\tlearn: 1.6092525\ttotal: 4.77s\tremaining: 11s\n",
      "303:\tlearn: 1.6087087\ttotal: 4.78s\tremaining: 11s\n",
      "304:\tlearn: 1.6078291\ttotal: 4.8s\tremaining: 10.9s\n",
      "305:\tlearn: 1.6068162\ttotal: 4.81s\tremaining: 10.9s\n",
      "306:\tlearn: 1.6067851\ttotal: 4.83s\tremaining: 10.9s\n",
      "307:\tlearn: 1.6065135\ttotal: 4.84s\tremaining: 10.9s\n",
      "308:\tlearn: 1.6057928\ttotal: 4.86s\tremaining: 10.9s\n",
      "309:\tlearn: 1.6052397\ttotal: 4.87s\tremaining: 10.8s\n",
      "310:\tlearn: 1.6048470\ttotal: 4.88s\tremaining: 10.8s\n",
      "311:\tlearn: 1.6046256\ttotal: 4.9s\tremaining: 10.8s\n",
      "312:\tlearn: 1.6045139\ttotal: 4.91s\tremaining: 10.8s\n",
      "313:\tlearn: 1.6038671\ttotal: 4.93s\tremaining: 10.8s\n",
      "314:\tlearn: 1.6038102\ttotal: 4.94s\tremaining: 10.7s\n",
      "315:\tlearn: 1.6029231\ttotal: 4.96s\tremaining: 10.7s\n",
      "316:\tlearn: 1.6015926\ttotal: 4.97s\tremaining: 10.7s\n",
      "317:\tlearn: 1.6003352\ttotal: 4.99s\tremaining: 10.7s\n",
      "318:\tlearn: 1.5996876\ttotal: 5s\tremaining: 10.7s\n",
      "319:\tlearn: 1.5994645\ttotal: 5.01s\tremaining: 10.7s\n",
      "320:\tlearn: 1.5973280\ttotal: 5.03s\tremaining: 10.6s\n",
      "321:\tlearn: 1.5968049\ttotal: 5.04s\tremaining: 10.6s\n",
      "322:\tlearn: 1.5962074\ttotal: 5.06s\tremaining: 10.6s\n",
      "323:\tlearn: 1.5960068\ttotal: 5.07s\tremaining: 10.6s\n",
      "324:\tlearn: 1.5952134\ttotal: 5.09s\tremaining: 10.6s\n",
      "325:\tlearn: 1.5946446\ttotal: 5.1s\tremaining: 10.5s\n",
      "326:\tlearn: 1.5939656\ttotal: 5.12s\tremaining: 10.5s\n",
      "327:\tlearn: 1.5932261\ttotal: 5.13s\tremaining: 10.5s\n",
      "328:\tlearn: 1.5930466\ttotal: 5.15s\tremaining: 10.5s\n",
      "329:\tlearn: 1.5926600\ttotal: 5.16s\tremaining: 10.5s\n",
      "330:\tlearn: 1.5913129\ttotal: 5.17s\tremaining: 10.5s\n",
      "331:\tlearn: 1.5895883\ttotal: 5.19s\tremaining: 10.4s\n",
      "332:\tlearn: 1.5891647\ttotal: 5.21s\tremaining: 10.4s\n",
      "333:\tlearn: 1.5889231\ttotal: 5.22s\tremaining: 10.4s\n",
      "334:\tlearn: 1.5884747\ttotal: 5.23s\tremaining: 10.4s\n",
      "335:\tlearn: 1.5882528\ttotal: 5.25s\tremaining: 10.4s\n",
      "336:\tlearn: 1.5879965\ttotal: 5.26s\tremaining: 10.4s\n",
      "337:\tlearn: 1.5867352\ttotal: 5.28s\tremaining: 10.3s\n",
      "338:\tlearn: 1.5857146\ttotal: 5.29s\tremaining: 10.3s\n",
      "339:\tlearn: 1.5852800\ttotal: 5.31s\tremaining: 10.3s\n",
      "340:\tlearn: 1.5852282\ttotal: 5.32s\tremaining: 10.3s\n",
      "341:\tlearn: 1.5850328\ttotal: 5.34s\tremaining: 10.3s\n",
      "342:\tlearn: 1.5850082\ttotal: 5.35s\tremaining: 10.3s\n",
      "343:\tlearn: 1.5848312\ttotal: 5.37s\tremaining: 10.2s\n",
      "344:\tlearn: 1.5839536\ttotal: 5.38s\tremaining: 10.2s\n",
      "345:\tlearn: 1.5838518\ttotal: 5.4s\tremaining: 10.2s\n",
      "346:\tlearn: 1.5838066\ttotal: 5.41s\tremaining: 10.2s\n",
      "347:\tlearn: 1.5830093\ttotal: 5.42s\tremaining: 10.2s\n",
      "348:\tlearn: 1.5816938\ttotal: 5.44s\tremaining: 10.1s\n",
      "349:\tlearn: 1.5814388\ttotal: 5.45s\tremaining: 10.1s\n",
      "350:\tlearn: 1.5809796\ttotal: 5.47s\tremaining: 10.1s\n",
      "351:\tlearn: 1.5804125\ttotal: 5.48s\tremaining: 10.1s\n",
      "352:\tlearn: 1.5799096\ttotal: 5.5s\tremaining: 10.1s\n",
      "353:\tlearn: 1.5798133\ttotal: 5.51s\tremaining: 10.1s\n",
      "354:\tlearn: 1.5795396\ttotal: 5.53s\tremaining: 10s\n",
      "355:\tlearn: 1.5793784\ttotal: 5.54s\tremaining: 10s\n",
      "356:\tlearn: 1.5790382\ttotal: 5.55s\tremaining: 10s\n",
      "357:\tlearn: 1.5784357\ttotal: 5.57s\tremaining: 9.99s\n",
      "358:\tlearn: 1.5780293\ttotal: 5.58s\tremaining: 9.97s\n",
      "359:\tlearn: 1.5779960\ttotal: 5.6s\tremaining: 9.95s\n",
      "360:\tlearn: 1.5756293\ttotal: 5.61s\tremaining: 9.94s\n",
      "361:\tlearn: 1.5745952\ttotal: 5.63s\tremaining: 9.92s\n",
      "362:\tlearn: 1.5744652\ttotal: 5.64s\tremaining: 9.9s\n",
      "363:\tlearn: 1.5742917\ttotal: 5.66s\tremaining: 9.88s\n",
      "364:\tlearn: 1.5738079\ttotal: 5.67s\tremaining: 9.87s\n",
      "365:\tlearn: 1.5733362\ttotal: 5.69s\tremaining: 9.85s\n",
      "366:\tlearn: 1.5725957\ttotal: 5.7s\tremaining: 9.83s\n",
      "367:\tlearn: 1.5715996\ttotal: 5.71s\tremaining: 9.82s\n",
      "368:\tlearn: 1.5710672\ttotal: 5.73s\tremaining: 9.8s\n",
      "369:\tlearn: 1.5706153\ttotal: 5.74s\tremaining: 9.78s\n",
      "370:\tlearn: 1.5704758\ttotal: 5.76s\tremaining: 9.77s\n",
      "371:\tlearn: 1.5701093\ttotal: 5.78s\tremaining: 9.75s\n",
      "372:\tlearn: 1.5694900\ttotal: 5.79s\tremaining: 9.73s\n",
      "373:\tlearn: 1.5693359\ttotal: 5.8s\tremaining: 9.71s\n",
      "374:\tlearn: 1.5687365\ttotal: 5.82s\tremaining: 9.7s\n",
      "375:\tlearn: 1.5683198\ttotal: 5.83s\tremaining: 9.68s\n",
      "376:\tlearn: 1.5682739\ttotal: 5.84s\tremaining: 9.66s\n",
      "377:\tlearn: 1.5678739\ttotal: 5.86s\tremaining: 9.64s\n",
      "378:\tlearn: 1.5664779\ttotal: 5.87s\tremaining: 9.63s\n",
      "379:\tlearn: 1.5654513\ttotal: 5.89s\tremaining: 9.61s\n",
      "380:\tlearn: 1.5652513\ttotal: 5.9s\tremaining: 9.59s\n",
      "381:\tlearn: 1.5643083\ttotal: 5.92s\tremaining: 9.57s\n",
      "382:\tlearn: 1.5638145\ttotal: 5.93s\tremaining: 9.56s\n",
      "383:\tlearn: 1.5634543\ttotal: 5.95s\tremaining: 9.54s\n",
      "384:\tlearn: 1.5631703\ttotal: 5.96s\tremaining: 9.52s\n",
      "385:\tlearn: 1.5629326\ttotal: 5.98s\tremaining: 9.51s\n",
      "386:\tlearn: 1.5624193\ttotal: 5.99s\tremaining: 9.49s\n",
      "387:\tlearn: 1.5623219\ttotal: 6.01s\tremaining: 9.48s\n",
      "388:\tlearn: 1.5622943\ttotal: 6.02s\tremaining: 9.46s\n",
      "389:\tlearn: 1.5619354\ttotal: 6.04s\tremaining: 9.44s\n",
      "390:\tlearn: 1.5611340\ttotal: 6.05s\tremaining: 9.43s\n",
      "391:\tlearn: 1.5610204\ttotal: 6.07s\tremaining: 9.41s\n",
      "392:\tlearn: 1.5602416\ttotal: 6.08s\tremaining: 9.39s\n",
      "393:\tlearn: 1.5582628\ttotal: 6.1s\tremaining: 9.38s\n",
      "394:\tlearn: 1.5565356\ttotal: 6.11s\tremaining: 9.36s\n",
      "395:\tlearn: 1.5563947\ttotal: 6.13s\tremaining: 9.35s\n",
      "396:\tlearn: 1.5556704\ttotal: 6.14s\tremaining: 9.33s\n",
      "397:\tlearn: 1.5551905\ttotal: 6.16s\tremaining: 9.31s\n",
      "398:\tlearn: 1.5538841\ttotal: 6.17s\tremaining: 9.3s\n",
      "399:\tlearn: 1.5537898\ttotal: 6.19s\tremaining: 9.28s\n",
      "400:\tlearn: 1.5534803\ttotal: 6.2s\tremaining: 9.26s\n",
      "401:\tlearn: 1.5531765\ttotal: 6.22s\tremaining: 9.25s\n",
      "402:\tlearn: 1.5531542\ttotal: 6.23s\tremaining: 9.23s\n",
      "403:\tlearn: 1.5530990\ttotal: 6.25s\tremaining: 9.21s\n",
      "404:\tlearn: 1.5520232\ttotal: 6.26s\tremaining: 9.2s\n",
      "405:\tlearn: 1.5518949\ttotal: 6.27s\tremaining: 9.18s\n",
      "406:\tlearn: 1.5518706\ttotal: 6.29s\tremaining: 9.16s\n",
      "407:\tlearn: 1.5518638\ttotal: 6.3s\tremaining: 9.14s\n",
      "408:\tlearn: 1.5514093\ttotal: 6.31s\tremaining: 9.13s\n",
      "409:\tlearn: 1.5512142\ttotal: 6.33s\tremaining: 9.11s\n",
      "410:\tlearn: 1.5509918\ttotal: 6.34s\tremaining: 9.09s\n",
      "411:\tlearn: 1.5509802\ttotal: 6.36s\tremaining: 9.07s\n",
      "412:\tlearn: 1.5509692\ttotal: 6.37s\tremaining: 9.05s\n",
      "413:\tlearn: 1.5508825\ttotal: 6.38s\tremaining: 9.04s\n",
      "414:\tlearn: 1.5505676\ttotal: 6.4s\tremaining: 9.02s\n",
      "415:\tlearn: 1.5501816\ttotal: 6.42s\tremaining: 9.01s\n",
      "416:\tlearn: 1.5500671\ttotal: 6.43s\tremaining: 8.99s\n",
      "417:\tlearn: 1.5500484\ttotal: 6.44s\tremaining: 8.97s\n",
      "418:\tlearn: 1.5497986\ttotal: 6.46s\tremaining: 8.95s\n",
      "419:\tlearn: 1.5493038\ttotal: 6.47s\tremaining: 8.94s\n",
      "420:\tlearn: 1.5493008\ttotal: 6.49s\tremaining: 8.92s\n",
      "421:\tlearn: 1.5492872\ttotal: 6.5s\tremaining: 8.9s\n",
      "422:\tlearn: 1.5492808\ttotal: 6.51s\tremaining: 8.89s\n",
      "423:\tlearn: 1.5481693\ttotal: 6.53s\tremaining: 8.87s\n",
      "424:\tlearn: 1.5477946\ttotal: 6.54s\tremaining: 8.85s\n",
      "425:\tlearn: 1.5477574\ttotal: 6.56s\tremaining: 8.84s\n",
      "426:\tlearn: 1.5477405\ttotal: 6.57s\tremaining: 8.82s\n",
      "427:\tlearn: 1.5475363\ttotal: 6.59s\tremaining: 8.8s\n",
      "428:\tlearn: 1.5474994\ttotal: 6.6s\tremaining: 8.79s\n",
      "429:\tlearn: 1.5474594\ttotal: 6.62s\tremaining: 8.77s\n",
      "430:\tlearn: 1.5474188\ttotal: 6.63s\tremaining: 8.76s\n",
      "431:\tlearn: 1.5465060\ttotal: 6.65s\tremaining: 8.74s\n",
      "432:\tlearn: 1.5459521\ttotal: 6.66s\tremaining: 8.72s\n",
      "433:\tlearn: 1.5459321\ttotal: 6.68s\tremaining: 8.71s\n",
      "434:\tlearn: 1.5455897\ttotal: 6.69s\tremaining: 8.69s\n",
      "435:\tlearn: 1.5455254\ttotal: 6.71s\tremaining: 8.67s\n",
      "436:\tlearn: 1.5455061\ttotal: 6.72s\tremaining: 8.66s\n",
      "437:\tlearn: 1.5453524\ttotal: 6.73s\tremaining: 8.64s\n",
      "438:\tlearn: 1.5451211\ttotal: 6.75s\tremaining: 8.62s\n",
      "439:\tlearn: 1.5449877\ttotal: 6.76s\tremaining: 8.61s\n",
      "440:\tlearn: 1.5448787\ttotal: 6.78s\tremaining: 8.59s\n",
      "441:\tlearn: 1.5448787\ttotal: 6.79s\tremaining: 8.57s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442:\tlearn: 1.5448787\ttotal: 6.81s\tremaining: 8.56s\n",
      "443:\tlearn: 1.5448787\ttotal: 6.82s\tremaining: 8.54s\n",
      "444:\tlearn: 1.5448787\ttotal: 6.84s\tremaining: 8.53s\n",
      "445:\tlearn: 1.5448713\ttotal: 6.85s\tremaining: 8.51s\n",
      "446:\tlearn: 1.5448713\ttotal: 6.87s\tremaining: 8.49s\n",
      "447:\tlearn: 1.5448713\ttotal: 6.88s\tremaining: 8.48s\n",
      "448:\tlearn: 1.5448689\ttotal: 6.89s\tremaining: 8.46s\n",
      "449:\tlearn: 1.5448632\ttotal: 6.91s\tremaining: 8.44s\n",
      "450:\tlearn: 1.5447948\ttotal: 6.92s\tremaining: 8.43s\n",
      "451:\tlearn: 1.5447073\ttotal: 6.93s\tremaining: 8.41s\n",
      "452:\tlearn: 1.5446371\ttotal: 6.95s\tremaining: 8.39s\n",
      "453:\tlearn: 1.5446322\ttotal: 6.96s\tremaining: 8.38s\n",
      "454:\tlearn: 1.5445755\ttotal: 6.98s\tremaining: 8.36s\n",
      "455:\tlearn: 1.5445711\ttotal: 6.99s\tremaining: 8.34s\n",
      "456:\tlearn: 1.5445310\ttotal: 7.01s\tremaining: 8.32s\n",
      "457:\tlearn: 1.5443607\ttotal: 7.02s\tremaining: 8.31s\n",
      "458:\tlearn: 1.5443595\ttotal: 7.04s\tremaining: 8.29s\n",
      "459:\tlearn: 1.5442546\ttotal: 7.05s\tremaining: 8.28s\n",
      "460:\tlearn: 1.5442508\ttotal: 7.07s\tremaining: 8.26s\n",
      "461:\tlearn: 1.5442499\ttotal: 7.08s\tremaining: 8.24s\n",
      "462:\tlearn: 1.5442383\ttotal: 7.09s\tremaining: 8.23s\n",
      "463:\tlearn: 1.5442382\ttotal: 7.11s\tremaining: 8.21s\n",
      "464:\tlearn: 1.5442343\ttotal: 7.12s\tremaining: 8.19s\n",
      "465:\tlearn: 1.5441843\ttotal: 7.14s\tremaining: 8.18s\n",
      "466:\tlearn: 1.5441508\ttotal: 7.15s\tremaining: 8.16s\n",
      "467:\tlearn: 1.5441220\ttotal: 7.16s\tremaining: 8.14s\n",
      "468:\tlearn: 1.5441095\ttotal: 7.18s\tremaining: 8.13s\n",
      "469:\tlearn: 1.5441085\ttotal: 7.19s\tremaining: 8.11s\n",
      "470:\tlearn: 1.5440508\ttotal: 7.21s\tremaining: 8.1s\n",
      "471:\tlearn: 1.5440469\ttotal: 7.22s\tremaining: 8.08s\n",
      "472:\tlearn: 1.5440467\ttotal: 7.24s\tremaining: 8.06s\n",
      "473:\tlearn: 1.5440155\ttotal: 7.25s\tremaining: 8.05s\n",
      "474:\tlearn: 1.5439752\ttotal: 7.27s\tremaining: 8.03s\n",
      "475:\tlearn: 1.5439416\ttotal: 7.28s\tremaining: 8.02s\n",
      "476:\tlearn: 1.5439002\ttotal: 7.3s\tremaining: 8s\n",
      "477:\tlearn: 1.5438353\ttotal: 7.31s\tremaining: 7.98s\n",
      "478:\tlearn: 1.5437107\ttotal: 7.32s\tremaining: 7.97s\n",
      "479:\tlearn: 1.5437107\ttotal: 7.34s\tremaining: 7.95s\n",
      "480:\tlearn: 1.5437097\ttotal: 7.35s\tremaining: 7.93s\n",
      "481:\tlearn: 1.5433672\ttotal: 7.37s\tremaining: 7.92s\n",
      "482:\tlearn: 1.5433569\ttotal: 7.38s\tremaining: 7.9s\n",
      "483:\tlearn: 1.5433568\ttotal: 7.4s\tremaining: 7.89s\n",
      "484:\tlearn: 1.5430096\ttotal: 7.41s\tremaining: 7.87s\n",
      "485:\tlearn: 1.5430063\ttotal: 7.43s\tremaining: 7.86s\n",
      "486:\tlearn: 1.5429992\ttotal: 7.44s\tremaining: 7.84s\n",
      "487:\tlearn: 1.5429991\ttotal: 7.46s\tremaining: 7.82s\n",
      "488:\tlearn: 1.5429991\ttotal: 7.47s\tremaining: 7.81s\n",
      "489:\tlearn: 1.5429931\ttotal: 7.49s\tremaining: 7.79s\n",
      "490:\tlearn: 1.5429930\ttotal: 7.5s\tremaining: 7.78s\n",
      "491:\tlearn: 1.5429929\ttotal: 7.52s\tremaining: 7.76s\n",
      "492:\tlearn: 1.5429929\ttotal: 7.53s\tremaining: 7.75s\n",
      "493:\tlearn: 1.5429929\ttotal: 7.55s\tremaining: 7.73s\n",
      "494:\tlearn: 1.5429929\ttotal: 7.56s\tremaining: 7.71s\n",
      "495:\tlearn: 1.5429926\ttotal: 7.58s\tremaining: 7.7s\n",
      "496:\tlearn: 1.5429912\ttotal: 7.59s\tremaining: 7.68s\n",
      "497:\tlearn: 1.5429912\ttotal: 7.61s\tremaining: 7.67s\n",
      "498:\tlearn: 1.5429912\ttotal: 7.62s\tremaining: 7.65s\n",
      "499:\tlearn: 1.5429912\ttotal: 7.63s\tremaining: 7.63s\n",
      "500:\tlearn: 1.5429911\ttotal: 7.65s\tremaining: 7.62s\n",
      "501:\tlearn: 1.5429876\ttotal: 7.66s\tremaining: 7.6s\n",
      "502:\tlearn: 1.5429808\ttotal: 7.68s\tremaining: 7.59s\n",
      "503:\tlearn: 1.5429685\ttotal: 7.69s\tremaining: 7.57s\n",
      "504:\tlearn: 1.5424994\ttotal: 7.71s\tremaining: 7.55s\n",
      "505:\tlearn: 1.5420812\ttotal: 7.72s\tremaining: 7.54s\n",
      "506:\tlearn: 1.5414663\ttotal: 7.73s\tremaining: 7.52s\n",
      "507:\tlearn: 1.5408453\ttotal: 7.75s\tremaining: 7.5s\n",
      "508:\tlearn: 1.5401167\ttotal: 7.76s\tremaining: 7.49s\n",
      "509:\tlearn: 1.5401129\ttotal: 7.78s\tremaining: 7.47s\n",
      "510:\tlearn: 1.5401110\ttotal: 7.79s\tremaining: 7.46s\n",
      "511:\tlearn: 1.5401036\ttotal: 7.8s\tremaining: 7.44s\n",
      "512:\tlearn: 1.5400730\ttotal: 7.82s\tremaining: 7.42s\n",
      "513:\tlearn: 1.5400725\ttotal: 7.83s\tremaining: 7.41s\n",
      "514:\tlearn: 1.5400723\ttotal: 7.85s\tremaining: 7.39s\n",
      "515:\tlearn: 1.5400721\ttotal: 7.86s\tremaining: 7.37s\n",
      "516:\tlearn: 1.5394398\ttotal: 7.88s\tremaining: 7.36s\n",
      "517:\tlearn: 1.5394245\ttotal: 7.89s\tremaining: 7.34s\n",
      "518:\tlearn: 1.5394212\ttotal: 7.91s\tremaining: 7.33s\n",
      "519:\tlearn: 1.5387925\ttotal: 7.92s\tremaining: 7.31s\n",
      "520:\tlearn: 1.5387584\ttotal: 7.94s\tremaining: 7.3s\n",
      "521:\tlearn: 1.5385251\ttotal: 7.95s\tremaining: 7.28s\n",
      "522:\tlearn: 1.5378081\ttotal: 7.97s\tremaining: 7.26s\n",
      "523:\tlearn: 1.5372623\ttotal: 7.98s\tremaining: 7.25s\n",
      "524:\tlearn: 1.5366433\ttotal: 7.99s\tremaining: 7.23s\n",
      "525:\tlearn: 1.5363805\ttotal: 8.01s\tremaining: 7.22s\n",
      "526:\tlearn: 1.5363792\ttotal: 8.02s\tremaining: 7.2s\n",
      "527:\tlearn: 1.5363791\ttotal: 8.04s\tremaining: 7.18s\n",
      "528:\tlearn: 1.5363791\ttotal: 8.05s\tremaining: 7.17s\n",
      "529:\tlearn: 1.5363748\ttotal: 8.07s\tremaining: 7.15s\n",
      "530:\tlearn: 1.5363747\ttotal: 8.08s\tremaining: 7.14s\n",
      "531:\tlearn: 1.5363747\ttotal: 8.1s\tremaining: 7.12s\n",
      "532:\tlearn: 1.5363744\ttotal: 8.11s\tremaining: 7.11s\n",
      "533:\tlearn: 1.5363742\ttotal: 8.13s\tremaining: 7.09s\n",
      "534:\tlearn: 1.5363647\ttotal: 8.14s\tremaining: 7.08s\n",
      "535:\tlearn: 1.5363644\ttotal: 8.15s\tremaining: 7.06s\n",
      "536:\tlearn: 1.5363643\ttotal: 8.17s\tremaining: 7.04s\n",
      "537:\tlearn: 1.5363640\ttotal: 8.18s\tremaining: 7.03s\n",
      "538:\tlearn: 1.5363640\ttotal: 8.2s\tremaining: 7.01s\n",
      "539:\tlearn: 1.5363601\ttotal: 8.21s\tremaining: 6.99s\n",
      "540:\tlearn: 1.5357572\ttotal: 8.22s\tremaining: 6.98s\n",
      "541:\tlearn: 1.5357571\ttotal: 8.24s\tremaining: 6.96s\n",
      "542:\tlearn: 1.5357571\ttotal: 8.25s\tremaining: 6.95s\n",
      "543:\tlearn: 1.5357571\ttotal: 8.27s\tremaining: 6.93s\n",
      "544:\tlearn: 1.5357570\ttotal: 8.28s\tremaining: 6.91s\n",
      "545:\tlearn: 1.5357494\ttotal: 8.3s\tremaining: 6.9s\n",
      "546:\tlearn: 1.5357493\ttotal: 8.31s\tremaining: 6.88s\n",
      "547:\tlearn: 1.5357465\ttotal: 8.33s\tremaining: 6.87s\n",
      "548:\tlearn: 1.5357442\ttotal: 8.34s\tremaining: 6.85s\n",
      "549:\tlearn: 1.5357429\ttotal: 8.36s\tremaining: 6.84s\n",
      "550:\tlearn: 1.5357388\ttotal: 8.37s\tremaining: 6.82s\n",
      "551:\tlearn: 1.5357388\ttotal: 8.38s\tremaining: 6.8s\n",
      "552:\tlearn: 1.5357386\ttotal: 8.4s\tremaining: 6.79s\n",
      "553:\tlearn: 1.5357191\ttotal: 8.41s\tremaining: 6.77s\n",
      "554:\tlearn: 1.5357162\ttotal: 8.43s\tremaining: 6.75s\n",
      "555:\tlearn: 1.5357081\ttotal: 8.44s\tremaining: 6.74s\n",
      "556:\tlearn: 1.5356971\ttotal: 8.45s\tremaining: 6.72s\n",
      "557:\tlearn: 1.5351905\ttotal: 8.46s\tremaining: 6.71s\n",
      "558:\tlearn: 1.5349994\ttotal: 8.48s\tremaining: 6.69s\n",
      "559:\tlearn: 1.5348443\ttotal: 8.49s\tremaining: 6.67s\n",
      "560:\tlearn: 1.5341384\ttotal: 8.51s\tremaining: 6.66s\n",
      "561:\tlearn: 1.5329122\ttotal: 8.53s\tremaining: 6.64s\n",
      "562:\tlearn: 1.5320938\ttotal: 8.54s\tremaining: 6.63s\n",
      "563:\tlearn: 1.5320237\ttotal: 8.55s\tremaining: 6.61s\n",
      "564:\tlearn: 1.5319948\ttotal: 8.57s\tremaining: 6.59s\n",
      "565:\tlearn: 1.5319656\ttotal: 8.58s\tremaining: 6.58s\n",
      "566:\tlearn: 1.5319636\ttotal: 8.6s\tremaining: 6.56s\n",
      "567:\tlearn: 1.5319449\ttotal: 8.61s\tremaining: 6.55s\n",
      "568:\tlearn: 1.5315814\ttotal: 8.62s\tremaining: 6.53s\n",
      "569:\tlearn: 1.5315063\ttotal: 8.64s\tremaining: 6.52s\n",
      "570:\tlearn: 1.5315062\ttotal: 8.65s\tremaining: 6.5s\n",
      "571:\tlearn: 1.5315061\ttotal: 8.67s\tremaining: 6.48s\n",
      "572:\tlearn: 1.5314830\ttotal: 8.68s\tremaining: 6.47s\n",
      "573:\tlearn: 1.5314625\ttotal: 8.7s\tremaining: 6.45s\n",
      "574:\tlearn: 1.5314350\ttotal: 8.71s\tremaining: 6.44s\n",
      "575:\tlearn: 1.5314094\ttotal: 8.73s\tremaining: 6.42s\n",
      "576:\tlearn: 1.5314092\ttotal: 8.74s\tremaining: 6.41s\n",
      "577:\tlearn: 1.5314084\ttotal: 8.76s\tremaining: 6.39s\n",
      "578:\tlearn: 1.5314039\ttotal: 8.77s\tremaining: 6.38s\n",
      "579:\tlearn: 1.5314038\ttotal: 8.79s\tremaining: 6.36s\n",
      "580:\tlearn: 1.5314035\ttotal: 8.8s\tremaining: 6.35s\n",
      "581:\tlearn: 1.5313974\ttotal: 8.81s\tremaining: 6.33s\n",
      "582:\tlearn: 1.5313947\ttotal: 8.83s\tremaining: 6.32s\n",
      "583:\tlearn: 1.5310009\ttotal: 8.84s\tremaining: 6.3s\n",
      "584:\tlearn: 1.5295867\ttotal: 8.86s\tremaining: 6.28s\n",
      "585:\tlearn: 1.5295364\ttotal: 8.87s\tremaining: 6.27s\n",
      "586:\tlearn: 1.5294870\ttotal: 8.89s\tremaining: 6.25s\n",
      "587:\tlearn: 1.5294839\ttotal: 8.9s\tremaining: 6.24s\n",
      "588:\tlearn: 1.5294833\ttotal: 8.91s\tremaining: 6.22s\n",
      "589:\tlearn: 1.5294833\ttotal: 8.93s\tremaining: 6.21s\n",
      "590:\tlearn: 1.5294830\ttotal: 8.95s\tremaining: 6.19s\n",
      "591:\tlearn: 1.5294828\ttotal: 8.98s\tremaining: 6.19s\n",
      "592:\tlearn: 1.5294827\ttotal: 8.99s\tremaining: 6.17s\n",
      "593:\tlearn: 1.5294763\ttotal: 9.01s\tremaining: 6.16s\n",
      "594:\tlearn: 1.5294763\ttotal: 9.02s\tremaining: 6.14s\n",
      "595:\tlearn: 1.5294762\ttotal: 9.04s\tremaining: 6.13s\n",
      "596:\tlearn: 1.5294760\ttotal: 9.05s\tremaining: 6.11s\n",
      "597:\tlearn: 1.5294760\ttotal: 9.07s\tremaining: 6.09s\n",
      "598:\tlearn: 1.5289923\ttotal: 9.08s\tremaining: 6.08s\n",
      "599:\tlearn: 1.5283432\ttotal: 9.1s\tremaining: 6.06s\n",
      "600:\tlearn: 1.5277612\ttotal: 9.11s\tremaining: 6.05s\n",
      "601:\tlearn: 1.5274303\ttotal: 9.13s\tremaining: 6.03s\n",
      "602:\tlearn: 1.5274134\ttotal: 9.14s\tremaining: 6.02s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603:\tlearn: 1.5274134\ttotal: 9.15s\tremaining: 6s\n",
      "604:\tlearn: 1.5273980\ttotal: 9.17s\tremaining: 5.99s\n",
      "605:\tlearn: 1.5273853\ttotal: 9.19s\tremaining: 5.97s\n",
      "606:\tlearn: 1.5273594\ttotal: 9.2s\tremaining: 5.96s\n",
      "607:\tlearn: 1.5272742\ttotal: 9.21s\tremaining: 5.94s\n",
      "608:\tlearn: 1.5259527\ttotal: 9.23s\tremaining: 5.92s\n",
      "609:\tlearn: 1.5257654\ttotal: 9.24s\tremaining: 5.91s\n",
      "610:\tlearn: 1.5251962\ttotal: 9.25s\tremaining: 5.89s\n",
      "611:\tlearn: 1.5251958\ttotal: 9.27s\tremaining: 5.88s\n",
      "612:\tlearn: 1.5251958\ttotal: 9.28s\tremaining: 5.86s\n",
      "613:\tlearn: 1.5251957\ttotal: 9.3s\tremaining: 5.85s\n",
      "614:\tlearn: 1.5251956\ttotal: 9.31s\tremaining: 5.83s\n",
      "615:\tlearn: 1.5251955\ttotal: 9.33s\tremaining: 5.82s\n",
      "616:\tlearn: 1.5251954\ttotal: 9.34s\tremaining: 5.8s\n",
      "617:\tlearn: 1.5251705\ttotal: 9.36s\tremaining: 5.78s\n",
      "618:\tlearn: 1.5251206\ttotal: 9.37s\tremaining: 5.77s\n",
      "619:\tlearn: 1.5250940\ttotal: 9.39s\tremaining: 5.75s\n",
      "620:\tlearn: 1.5241937\ttotal: 9.4s\tremaining: 5.74s\n",
      "621:\tlearn: 1.5236388\ttotal: 9.42s\tremaining: 5.72s\n",
      "622:\tlearn: 1.5234787\ttotal: 9.43s\tremaining: 5.71s\n",
      "623:\tlearn: 1.5230967\ttotal: 9.45s\tremaining: 5.69s\n",
      "624:\tlearn: 1.5228696\ttotal: 9.46s\tremaining: 5.67s\n",
      "625:\tlearn: 1.5224319\ttotal: 9.47s\tremaining: 5.66s\n",
      "626:\tlearn: 1.5223158\ttotal: 9.49s\tremaining: 5.64s\n",
      "627:\tlearn: 1.5223157\ttotal: 9.5s\tremaining: 5.63s\n",
      "628:\tlearn: 1.5223157\ttotal: 9.51s\tremaining: 5.61s\n",
      "629:\tlearn: 1.5222846\ttotal: 9.53s\tremaining: 5.59s\n",
      "630:\tlearn: 1.5213164\ttotal: 9.54s\tremaining: 5.58s\n",
      "631:\tlearn: 1.5212722\ttotal: 9.55s\tremaining: 5.56s\n",
      "632:\tlearn: 1.5205576\ttotal: 9.57s\tremaining: 5.55s\n",
      "633:\tlearn: 1.5202249\ttotal: 9.58s\tremaining: 5.53s\n",
      "634:\tlearn: 1.5202201\ttotal: 9.6s\tremaining: 5.52s\n",
      "635:\tlearn: 1.5202201\ttotal: 9.61s\tremaining: 5.5s\n",
      "636:\tlearn: 1.5202201\ttotal: 9.63s\tremaining: 5.49s\n",
      "637:\tlearn: 1.5202201\ttotal: 9.64s\tremaining: 5.47s\n",
      "638:\tlearn: 1.5202201\ttotal: 9.65s\tremaining: 5.46s\n",
      "639:\tlearn: 1.5202201\ttotal: 9.67s\tremaining: 5.44s\n",
      "640:\tlearn: 1.5202201\ttotal: 9.68s\tremaining: 5.42s\n",
      "641:\tlearn: 1.5202200\ttotal: 9.7s\tremaining: 5.41s\n",
      "642:\tlearn: 1.5202197\ttotal: 9.71s\tremaining: 5.39s\n",
      "643:\tlearn: 1.5202159\ttotal: 9.72s\tremaining: 5.38s\n",
      "644:\tlearn: 1.5202159\ttotal: 9.74s\tremaining: 5.36s\n",
      "645:\tlearn: 1.5202159\ttotal: 9.75s\tremaining: 5.34s\n",
      "646:\tlearn: 1.5201887\ttotal: 9.77s\tremaining: 5.33s\n",
      "647:\tlearn: 1.5201885\ttotal: 9.78s\tremaining: 5.31s\n",
      "648:\tlearn: 1.5201885\ttotal: 9.79s\tremaining: 5.3s\n",
      "649:\tlearn: 1.5201404\ttotal: 9.81s\tremaining: 5.28s\n",
      "650:\tlearn: 1.5191821\ttotal: 9.82s\tremaining: 5.27s\n",
      "651:\tlearn: 1.5186780\ttotal: 9.84s\tremaining: 5.25s\n",
      "652:\tlearn: 1.5185718\ttotal: 9.85s\tremaining: 5.24s\n",
      "653:\tlearn: 1.5185718\ttotal: 9.87s\tremaining: 5.22s\n",
      "654:\tlearn: 1.5185718\ttotal: 9.88s\tremaining: 5.2s\n",
      "655:\tlearn: 1.5185681\ttotal: 9.89s\tremaining: 5.19s\n",
      "656:\tlearn: 1.5185681\ttotal: 9.91s\tremaining: 5.17s\n",
      "657:\tlearn: 1.5185681\ttotal: 9.92s\tremaining: 5.16s\n",
      "658:\tlearn: 1.5185681\ttotal: 9.94s\tremaining: 5.14s\n",
      "659:\tlearn: 1.5185681\ttotal: 9.95s\tremaining: 5.13s\n",
      "660:\tlearn: 1.5185492\ttotal: 9.96s\tremaining: 5.11s\n",
      "661:\tlearn: 1.5184802\ttotal: 9.98s\tremaining: 5.09s\n",
      "662:\tlearn: 1.5166409\ttotal: 9.99s\tremaining: 5.08s\n",
      "663:\tlearn: 1.5166112\ttotal: 10s\tremaining: 5.06s\n",
      "664:\tlearn: 1.5166103\ttotal: 10s\tremaining: 5.05s\n",
      "665:\tlearn: 1.5166103\ttotal: 10s\tremaining: 5.03s\n",
      "666:\tlearn: 1.5166103\ttotal: 10.1s\tremaining: 5.02s\n",
      "667:\tlearn: 1.5166102\ttotal: 10.1s\tremaining: 5s\n",
      "668:\tlearn: 1.5166101\ttotal: 10.1s\tremaining: 4.99s\n",
      "669:\tlearn: 1.5166082\ttotal: 10.1s\tremaining: 4.97s\n",
      "670:\tlearn: 1.5166082\ttotal: 10.1s\tremaining: 4.96s\n",
      "671:\tlearn: 1.5166082\ttotal: 10.1s\tremaining: 4.94s\n",
      "672:\tlearn: 1.5161872\ttotal: 10.1s\tremaining: 4.92s\n",
      "673:\tlearn: 1.5160915\ttotal: 10.2s\tremaining: 4.91s\n",
      "674:\tlearn: 1.5157313\ttotal: 10.2s\tremaining: 4.89s\n",
      "675:\tlearn: 1.5156119\ttotal: 10.2s\tremaining: 4.88s\n",
      "676:\tlearn: 1.5155747\ttotal: 10.2s\tremaining: 4.86s\n",
      "677:\tlearn: 1.5155298\ttotal: 10.2s\tremaining: 4.85s\n",
      "678:\tlearn: 1.5155226\ttotal: 10.2s\tremaining: 4.83s\n",
      "679:\tlearn: 1.5154731\ttotal: 10.2s\tremaining: 4.82s\n",
      "680:\tlearn: 1.5150201\ttotal: 10.3s\tremaining: 4.8s\n",
      "681:\tlearn: 1.5148913\ttotal: 10.3s\tremaining: 4.79s\n",
      "682:\tlearn: 1.5148612\ttotal: 10.3s\tremaining: 4.77s\n",
      "683:\tlearn: 1.5142350\ttotal: 10.3s\tremaining: 4.76s\n",
      "684:\tlearn: 1.5142314\ttotal: 10.3s\tremaining: 4.74s\n",
      "685:\tlearn: 1.5142309\ttotal: 10.3s\tremaining: 4.72s\n",
      "686:\tlearn: 1.5140847\ttotal: 10.3s\tremaining: 4.71s\n",
      "687:\tlearn: 1.5139039\ttotal: 10.4s\tremaining: 4.69s\n",
      "688:\tlearn: 1.5136312\ttotal: 10.4s\tremaining: 4.68s\n",
      "689:\tlearn: 1.5131728\ttotal: 10.4s\tremaining: 4.66s\n",
      "690:\tlearn: 1.5131728\ttotal: 10.4s\tremaining: 4.65s\n",
      "691:\tlearn: 1.5131727\ttotal: 10.4s\tremaining: 4.63s\n",
      "692:\tlearn: 1.5131717\ttotal: 10.4s\tremaining: 4.62s\n",
      "693:\tlearn: 1.5131717\ttotal: 10.4s\tremaining: 4.6s\n",
      "694:\tlearn: 1.5130827\ttotal: 10.5s\tremaining: 4.59s\n",
      "695:\tlearn: 1.5129282\ttotal: 10.5s\tremaining: 4.57s\n",
      "696:\tlearn: 1.5129255\ttotal: 10.5s\tremaining: 4.56s\n",
      "697:\tlearn: 1.5128331\ttotal: 10.5s\tremaining: 4.54s\n",
      "698:\tlearn: 1.5125650\ttotal: 10.5s\tremaining: 4.53s\n",
      "699:\tlearn: 1.5124992\ttotal: 10.5s\tremaining: 4.51s\n",
      "700:\tlearn: 1.5124705\ttotal: 10.5s\tremaining: 4.5s\n",
      "701:\tlearn: 1.5124611\ttotal: 10.6s\tremaining: 4.48s\n",
      "702:\tlearn: 1.5124159\ttotal: 10.6s\tremaining: 4.46s\n",
      "703:\tlearn: 1.5124158\ttotal: 10.6s\tremaining: 4.45s\n",
      "704:\tlearn: 1.5124151\ttotal: 10.6s\tremaining: 4.43s\n",
      "705:\tlearn: 1.5124148\ttotal: 10.6s\tremaining: 4.42s\n",
      "706:\tlearn: 1.5124086\ttotal: 10.6s\tremaining: 4.4s\n",
      "707:\tlearn: 1.5118713\ttotal: 10.6s\tremaining: 4.39s\n",
      "708:\tlearn: 1.5117959\ttotal: 10.7s\tremaining: 4.37s\n",
      "709:\tlearn: 1.5113072\ttotal: 10.7s\tremaining: 4.36s\n",
      "710:\tlearn: 1.5111945\ttotal: 10.7s\tremaining: 4.34s\n",
      "711:\tlearn: 1.5111696\ttotal: 10.7s\tremaining: 4.33s\n",
      "712:\tlearn: 1.5111696\ttotal: 10.7s\tremaining: 4.31s\n",
      "713:\tlearn: 1.5111696\ttotal: 10.7s\tremaining: 4.3s\n",
      "714:\tlearn: 1.5111690\ttotal: 10.8s\tremaining: 4.29s\n",
      "715:\tlearn: 1.5111690\ttotal: 10.8s\tremaining: 4.27s\n",
      "716:\tlearn: 1.5111687\ttotal: 10.8s\tremaining: 4.25s\n",
      "717:\tlearn: 1.5111683\ttotal: 10.8s\tremaining: 4.24s\n",
      "718:\tlearn: 1.5111506\ttotal: 10.8s\tremaining: 4.22s\n",
      "719:\tlearn: 1.5108910\ttotal: 10.8s\tremaining: 4.21s\n",
      "720:\tlearn: 1.5108565\ttotal: 10.8s\tremaining: 4.19s\n",
      "721:\tlearn: 1.5099811\ttotal: 10.8s\tremaining: 4.18s\n",
      "722:\tlearn: 1.5099811\ttotal: 10.9s\tremaining: 4.16s\n",
      "723:\tlearn: 1.5099811\ttotal: 10.9s\tremaining: 4.15s\n",
      "724:\tlearn: 1.5099811\ttotal: 10.9s\tremaining: 4.13s\n",
      "725:\tlearn: 1.5099811\ttotal: 10.9s\tremaining: 4.12s\n",
      "726:\tlearn: 1.5099810\ttotal: 10.9s\tremaining: 4.1s\n",
      "727:\tlearn: 1.5099810\ttotal: 10.9s\tremaining: 4.08s\n",
      "728:\tlearn: 1.5099780\ttotal: 10.9s\tremaining: 4.07s\n",
      "729:\tlearn: 1.5099780\ttotal: 11s\tremaining: 4.05s\n",
      "730:\tlearn: 1.5099780\ttotal: 11s\tremaining: 4.04s\n",
      "731:\tlearn: 1.5099780\ttotal: 11s\tremaining: 4.02s\n",
      "732:\tlearn: 1.5099780\ttotal: 11s\tremaining: 4.01s\n",
      "733:\tlearn: 1.5099780\ttotal: 11s\tremaining: 3.99s\n",
      "734:\tlearn: 1.5099780\ttotal: 11s\tremaining: 3.98s\n",
      "735:\tlearn: 1.5099780\ttotal: 11s\tremaining: 3.96s\n",
      "736:\tlearn: 1.5099780\ttotal: 11.1s\tremaining: 3.94s\n",
      "737:\tlearn: 1.5099780\ttotal: 11.1s\tremaining: 3.93s\n",
      "738:\tlearn: 1.5088844\ttotal: 11.1s\tremaining: 3.91s\n",
      "739:\tlearn: 1.5083191\ttotal: 11.1s\tremaining: 3.9s\n",
      "740:\tlearn: 1.5082389\ttotal: 11.1s\tremaining: 3.88s\n",
      "741:\tlearn: 1.5071352\ttotal: 11.1s\tremaining: 3.87s\n",
      "742:\tlearn: 1.5070658\ttotal: 11.1s\tremaining: 3.85s\n",
      "743:\tlearn: 1.5069824\ttotal: 11.2s\tremaining: 3.84s\n",
      "744:\tlearn: 1.5069696\ttotal: 11.2s\tremaining: 3.82s\n",
      "745:\tlearn: 1.5069507\ttotal: 11.2s\tremaining: 3.81s\n",
      "746:\tlearn: 1.5069506\ttotal: 11.2s\tremaining: 3.79s\n",
      "747:\tlearn: 1.5069505\ttotal: 11.2s\tremaining: 3.78s\n",
      "748:\tlearn: 1.5068238\ttotal: 11.2s\tremaining: 3.76s\n",
      "749:\tlearn: 1.5068004\ttotal: 11.2s\tremaining: 3.75s\n",
      "750:\tlearn: 1.5066000\ttotal: 11.3s\tremaining: 3.73s\n",
      "751:\tlearn: 1.5063285\ttotal: 11.3s\tremaining: 3.72s\n",
      "752:\tlearn: 1.5063228\ttotal: 11.3s\tremaining: 3.7s\n",
      "753:\tlearn: 1.5063137\ttotal: 11.3s\tremaining: 3.69s\n",
      "754:\tlearn: 1.5062842\ttotal: 11.3s\tremaining: 3.67s\n",
      "755:\tlearn: 1.5062838\ttotal: 11.3s\tremaining: 3.66s\n",
      "756:\tlearn: 1.5062837\ttotal: 11.3s\tremaining: 3.64s\n",
      "757:\tlearn: 1.5062743\ttotal: 11.4s\tremaining: 3.63s\n",
      "758:\tlearn: 1.5062742\ttotal: 11.4s\tremaining: 3.61s\n",
      "759:\tlearn: 1.5062732\ttotal: 11.4s\tremaining: 3.6s\n",
      "760:\tlearn: 1.5062720\ttotal: 11.4s\tremaining: 3.58s\n",
      "761:\tlearn: 1.5062719\ttotal: 11.4s\tremaining: 3.56s\n",
      "762:\tlearn: 1.5062718\ttotal: 11.4s\tremaining: 3.55s\n",
      "763:\tlearn: 1.5062696\ttotal: 11.4s\tremaining: 3.54s\n",
      "764:\tlearn: 1.5062696\ttotal: 11.5s\tremaining: 3.52s\n",
      "765:\tlearn: 1.5062696\ttotal: 11.5s\tremaining: 3.51s\n",
      "766:\tlearn: 1.5062314\ttotal: 11.5s\tremaining: 3.49s\n",
      "767:\tlearn: 1.5055427\ttotal: 11.5s\tremaining: 3.48s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768:\tlearn: 1.5055349\ttotal: 11.5s\tremaining: 3.46s\n",
      "769:\tlearn: 1.5055349\ttotal: 11.5s\tremaining: 3.45s\n",
      "770:\tlearn: 1.5055348\ttotal: 11.6s\tremaining: 3.43s\n",
      "771:\tlearn: 1.5055322\ttotal: 11.6s\tremaining: 3.42s\n",
      "772:\tlearn: 1.5055096\ttotal: 11.6s\tremaining: 3.4s\n",
      "773:\tlearn: 1.5052162\ttotal: 11.6s\tremaining: 3.38s\n",
      "774:\tlearn: 1.5048025\ttotal: 11.6s\tremaining: 3.37s\n",
      "775:\tlearn: 1.5047980\ttotal: 11.6s\tremaining: 3.35s\n",
      "776:\tlearn: 1.5039046\ttotal: 11.6s\tremaining: 3.34s\n",
      "777:\tlearn: 1.5039023\ttotal: 11.7s\tremaining: 3.32s\n",
      "778:\tlearn: 1.5039023\ttotal: 11.7s\tremaining: 3.31s\n",
      "779:\tlearn: 1.5039022\ttotal: 11.7s\tremaining: 3.29s\n",
      "780:\tlearn: 1.5039018\ttotal: 11.7s\tremaining: 3.28s\n",
      "781:\tlearn: 1.5039016\ttotal: 11.7s\tremaining: 3.26s\n",
      "782:\tlearn: 1.5038991\ttotal: 11.7s\tremaining: 3.25s\n",
      "783:\tlearn: 1.5038866\ttotal: 11.7s\tremaining: 3.23s\n",
      "784:\tlearn: 1.5038644\ttotal: 11.8s\tremaining: 3.22s\n",
      "785:\tlearn: 1.5038643\ttotal: 11.8s\tremaining: 3.2s\n",
      "786:\tlearn: 1.5038093\ttotal: 11.8s\tremaining: 3.19s\n",
      "787:\tlearn: 1.5037999\ttotal: 11.8s\tremaining: 3.17s\n",
      "788:\tlearn: 1.5037999\ttotal: 11.8s\tremaining: 3.16s\n",
      "789:\tlearn: 1.5037999\ttotal: 11.8s\tremaining: 3.14s\n",
      "790:\tlearn: 1.5037737\ttotal: 11.8s\tremaining: 3.13s\n",
      "791:\tlearn: 1.5028499\ttotal: 11.8s\tremaining: 3.11s\n",
      "792:\tlearn: 1.5027831\ttotal: 11.9s\tremaining: 3.1s\n",
      "793:\tlearn: 1.5022912\ttotal: 11.9s\tremaining: 3.08s\n",
      "794:\tlearn: 1.5020212\ttotal: 11.9s\tremaining: 3.06s\n",
      "795:\tlearn: 1.5019888\ttotal: 11.9s\tremaining: 3.05s\n",
      "796:\tlearn: 1.5019808\ttotal: 11.9s\tremaining: 3.04s\n",
      "797:\tlearn: 1.5019782\ttotal: 11.9s\tremaining: 3.02s\n",
      "798:\tlearn: 1.5019763\ttotal: 11.9s\tremaining: 3s\n",
      "799:\tlearn: 1.5019762\ttotal: 12s\tremaining: 2.99s\n",
      "800:\tlearn: 1.5019760\ttotal: 12s\tremaining: 2.97s\n",
      "801:\tlearn: 1.5019441\ttotal: 12s\tremaining: 2.96s\n",
      "802:\tlearn: 1.5019268\ttotal: 12s\tremaining: 2.94s\n",
      "803:\tlearn: 1.5019063\ttotal: 12s\tremaining: 2.93s\n",
      "804:\tlearn: 1.5019040\ttotal: 12s\tremaining: 2.91s\n",
      "805:\tlearn: 1.5019017\ttotal: 12s\tremaining: 2.9s\n",
      "806:\tlearn: 1.5019017\ttotal: 12.1s\tremaining: 2.88s\n",
      "807:\tlearn: 1.5019017\ttotal: 12.1s\tremaining: 2.87s\n",
      "808:\tlearn: 1.5019017\ttotal: 12.1s\tremaining: 2.85s\n",
      "809:\tlearn: 1.5019017\ttotal: 12.1s\tremaining: 2.84s\n",
      "810:\tlearn: 1.5019017\ttotal: 12.1s\tremaining: 2.82s\n",
      "811:\tlearn: 1.5019016\ttotal: 12.1s\tremaining: 2.81s\n",
      "812:\tlearn: 1.5018846\ttotal: 12.1s\tremaining: 2.79s\n",
      "813:\tlearn: 1.5018759\ttotal: 12.2s\tremaining: 2.78s\n",
      "814:\tlearn: 1.5018721\ttotal: 12.2s\tremaining: 2.76s\n",
      "815:\tlearn: 1.5018581\ttotal: 12.2s\tremaining: 2.75s\n",
      "816:\tlearn: 1.5012763\ttotal: 12.2s\tremaining: 2.73s\n",
      "817:\tlearn: 1.5008195\ttotal: 12.2s\tremaining: 2.72s\n",
      "818:\tlearn: 1.5007431\ttotal: 12.2s\tremaining: 2.7s\n",
      "819:\tlearn: 1.4997973\ttotal: 12.2s\tremaining: 2.69s\n",
      "820:\tlearn: 1.4997843\ttotal: 12.3s\tremaining: 2.67s\n",
      "821:\tlearn: 1.4997838\ttotal: 12.3s\tremaining: 2.66s\n",
      "822:\tlearn: 1.4997631\ttotal: 12.3s\tremaining: 2.64s\n",
      "823:\tlearn: 1.4997520\ttotal: 12.3s\tremaining: 2.63s\n",
      "824:\tlearn: 1.4997520\ttotal: 12.3s\tremaining: 2.61s\n",
      "825:\tlearn: 1.4997519\ttotal: 12.3s\tremaining: 2.6s\n",
      "826:\tlearn: 1.4997121\ttotal: 12.3s\tremaining: 2.58s\n",
      "827:\tlearn: 1.4995328\ttotal: 12.4s\tremaining: 2.57s\n",
      "828:\tlearn: 1.4994745\ttotal: 12.4s\tremaining: 2.55s\n",
      "829:\tlearn: 1.4994304\ttotal: 12.4s\tremaining: 2.54s\n",
      "830:\tlearn: 1.4994303\ttotal: 12.4s\tremaining: 2.52s\n",
      "831:\tlearn: 1.4993903\ttotal: 12.4s\tremaining: 2.51s\n",
      "832:\tlearn: 1.4993744\ttotal: 12.4s\tremaining: 2.49s\n",
      "833:\tlearn: 1.4988933\ttotal: 12.4s\tremaining: 2.48s\n",
      "834:\tlearn: 1.4988929\ttotal: 12.5s\tremaining: 2.46s\n",
      "835:\tlearn: 1.4985129\ttotal: 12.5s\tremaining: 2.45s\n",
      "836:\tlearn: 1.4984195\ttotal: 12.5s\tremaining: 2.43s\n",
      "837:\tlearn: 1.4983495\ttotal: 12.5s\tremaining: 2.42s\n",
      "838:\tlearn: 1.4983361\ttotal: 12.5s\tremaining: 2.4s\n",
      "839:\tlearn: 1.4983342\ttotal: 12.5s\tremaining: 2.39s\n",
      "840:\tlearn: 1.4983342\ttotal: 12.5s\tremaining: 2.37s\n",
      "841:\tlearn: 1.4983342\ttotal: 12.6s\tremaining: 2.35s\n",
      "842:\tlearn: 1.4983243\ttotal: 12.6s\tremaining: 2.34s\n",
      "843:\tlearn: 1.4983242\ttotal: 12.6s\tremaining: 2.33s\n",
      "844:\tlearn: 1.4983160\ttotal: 12.6s\tremaining: 2.31s\n",
      "845:\tlearn: 1.4982885\ttotal: 12.6s\tremaining: 2.29s\n",
      "846:\tlearn: 1.4982605\ttotal: 12.6s\tremaining: 2.28s\n",
      "847:\tlearn: 1.4973609\ttotal: 12.6s\tremaining: 2.27s\n",
      "848:\tlearn: 1.4973018\ttotal: 12.7s\tremaining: 2.25s\n",
      "849:\tlearn: 1.4972935\ttotal: 12.7s\tremaining: 2.23s\n",
      "850:\tlearn: 1.4972935\ttotal: 12.7s\tremaining: 2.22s\n",
      "851:\tlearn: 1.4972929\ttotal: 12.7s\tremaining: 2.21s\n",
      "852:\tlearn: 1.4972928\ttotal: 12.7s\tremaining: 2.19s\n",
      "853:\tlearn: 1.4972909\ttotal: 12.7s\tremaining: 2.17s\n",
      "854:\tlearn: 1.4972909\ttotal: 12.7s\tremaining: 2.16s\n",
      "855:\tlearn: 1.4972908\ttotal: 12.8s\tremaining: 2.15s\n",
      "856:\tlearn: 1.4972907\ttotal: 12.8s\tremaining: 2.13s\n",
      "857:\tlearn: 1.4972906\ttotal: 12.8s\tremaining: 2.11s\n",
      "858:\tlearn: 1.4972906\ttotal: 12.8s\tremaining: 2.1s\n",
      "859:\tlearn: 1.4972906\ttotal: 12.8s\tremaining: 2.08s\n",
      "860:\tlearn: 1.4972905\ttotal: 12.8s\tremaining: 2.07s\n",
      "861:\tlearn: 1.4972905\ttotal: 12.8s\tremaining: 2.06s\n",
      "862:\tlearn: 1.4972752\ttotal: 12.9s\tremaining: 2.04s\n",
      "863:\tlearn: 1.4968775\ttotal: 12.9s\tremaining: 2.02s\n",
      "864:\tlearn: 1.4960898\ttotal: 12.9s\tremaining: 2.01s\n",
      "865:\tlearn: 1.4960347\ttotal: 12.9s\tremaining: 1.99s\n",
      "866:\tlearn: 1.4959551\ttotal: 12.9s\tremaining: 1.98s\n",
      "867:\tlearn: 1.4954676\ttotal: 12.9s\tremaining: 1.96s\n",
      "868:\tlearn: 1.4954668\ttotal: 12.9s\tremaining: 1.95s\n",
      "869:\tlearn: 1.4954664\ttotal: 12.9s\tremaining: 1.93s\n",
      "870:\tlearn: 1.4954426\ttotal: 13s\tremaining: 1.92s\n",
      "871:\tlearn: 1.4950414\ttotal: 13s\tremaining: 1.9s\n",
      "872:\tlearn: 1.4946248\ttotal: 13s\tremaining: 1.89s\n",
      "873:\tlearn: 1.4941983\ttotal: 13s\tremaining: 1.87s\n",
      "874:\tlearn: 1.4934778\ttotal: 13s\tremaining: 1.86s\n",
      "875:\tlearn: 1.4933435\ttotal: 13s\tremaining: 1.84s\n",
      "876:\tlearn: 1.4933435\ttotal: 13s\tremaining: 1.83s\n",
      "877:\tlearn: 1.4933435\ttotal: 13.1s\tremaining: 1.81s\n",
      "878:\tlearn: 1.4933434\ttotal: 13.1s\tremaining: 1.8s\n",
      "879:\tlearn: 1.4933428\ttotal: 13.1s\tremaining: 1.78s\n",
      "880:\tlearn: 1.4933428\ttotal: 13.1s\tremaining: 1.77s\n",
      "881:\tlearn: 1.4933386\ttotal: 13.1s\tremaining: 1.75s\n",
      "882:\tlearn: 1.4931682\ttotal: 13.1s\tremaining: 1.74s\n",
      "883:\tlearn: 1.4928696\ttotal: 13.1s\tremaining: 1.72s\n",
      "884:\tlearn: 1.4928496\ttotal: 13.2s\tremaining: 1.71s\n",
      "885:\tlearn: 1.4927052\ttotal: 13.2s\tremaining: 1.7s\n",
      "886:\tlearn: 1.4926600\ttotal: 13.2s\tremaining: 1.68s\n",
      "887:\tlearn: 1.4925042\ttotal: 13.2s\tremaining: 1.67s\n",
      "888:\tlearn: 1.4924890\ttotal: 13.2s\tremaining: 1.65s\n",
      "889:\tlearn: 1.4924746\ttotal: 13.2s\tremaining: 1.64s\n",
      "890:\tlearn: 1.4924627\ttotal: 13.2s\tremaining: 1.62s\n",
      "891:\tlearn: 1.4917518\ttotal: 13.3s\tremaining: 1.6s\n",
      "892:\tlearn: 1.4917272\ttotal: 13.3s\tremaining: 1.59s\n",
      "893:\tlearn: 1.4917271\ttotal: 13.3s\tremaining: 1.57s\n",
      "894:\tlearn: 1.4916967\ttotal: 13.3s\tremaining: 1.56s\n",
      "895:\tlearn: 1.4907102\ttotal: 13.3s\tremaining: 1.54s\n",
      "896:\tlearn: 1.4906270\ttotal: 13.3s\tremaining: 1.53s\n",
      "897:\tlearn: 1.4905491\ttotal: 13.3s\tremaining: 1.51s\n",
      "898:\tlearn: 1.4901771\ttotal: 13.4s\tremaining: 1.5s\n",
      "899:\tlearn: 1.4900683\ttotal: 13.4s\tremaining: 1.49s\n",
      "900:\tlearn: 1.4895031\ttotal: 13.4s\tremaining: 1.47s\n",
      "901:\tlearn: 1.4893575\ttotal: 13.4s\tremaining: 1.46s\n",
      "902:\tlearn: 1.4892816\ttotal: 13.4s\tremaining: 1.44s\n",
      "903:\tlearn: 1.4880887\ttotal: 13.4s\tremaining: 1.43s\n",
      "904:\tlearn: 1.4880878\ttotal: 13.4s\tremaining: 1.41s\n",
      "905:\tlearn: 1.4880550\ttotal: 13.5s\tremaining: 1.4s\n",
      "906:\tlearn: 1.4877048\ttotal: 13.5s\tremaining: 1.38s\n",
      "907:\tlearn: 1.4870677\ttotal: 13.5s\tremaining: 1.37s\n",
      "908:\tlearn: 1.4870573\ttotal: 13.5s\tremaining: 1.35s\n",
      "909:\tlearn: 1.4870572\ttotal: 13.5s\tremaining: 1.34s\n",
      "910:\tlearn: 1.4870186\ttotal: 13.5s\tremaining: 1.32s\n",
      "911:\tlearn: 1.4870138\ttotal: 13.5s\tremaining: 1.31s\n",
      "912:\tlearn: 1.4869704\ttotal: 13.6s\tremaining: 1.29s\n",
      "913:\tlearn: 1.4869085\ttotal: 13.6s\tremaining: 1.28s\n",
      "914:\tlearn: 1.4865395\ttotal: 13.6s\tremaining: 1.26s\n",
      "915:\tlearn: 1.4865240\ttotal: 13.6s\tremaining: 1.25s\n",
      "916:\tlearn: 1.4861200\ttotal: 13.6s\tremaining: 1.23s\n",
      "917:\tlearn: 1.4857432\ttotal: 13.6s\tremaining: 1.22s\n",
      "918:\tlearn: 1.4851467\ttotal: 13.6s\tremaining: 1.2s\n",
      "919:\tlearn: 1.4851021\ttotal: 13.7s\tremaining: 1.19s\n",
      "920:\tlearn: 1.4847504\ttotal: 13.7s\tremaining: 1.17s\n",
      "921:\tlearn: 1.4846541\ttotal: 13.7s\tremaining: 1.16s\n",
      "922:\tlearn: 1.4838874\ttotal: 13.7s\tremaining: 1.14s\n",
      "923:\tlearn: 1.4833080\ttotal: 13.7s\tremaining: 1.13s\n",
      "924:\tlearn: 1.4830148\ttotal: 13.7s\tremaining: 1.11s\n",
      "925:\tlearn: 1.4827041\ttotal: 13.7s\tremaining: 1.1s\n",
      "926:\tlearn: 1.4823896\ttotal: 13.8s\tremaining: 1.08s\n",
      "927:\tlearn: 1.4818184\ttotal: 13.8s\tremaining: 1.07s\n",
      "928:\tlearn: 1.4815443\ttotal: 13.8s\tremaining: 1.05s\n",
      "929:\tlearn: 1.4815235\ttotal: 13.8s\tremaining: 1.04s\n",
      "930:\tlearn: 1.4812847\ttotal: 13.8s\tremaining: 1.02s\n",
      "931:\tlearn: 1.4812846\ttotal: 13.8s\tremaining: 1.01s\n",
      "932:\tlearn: 1.4812846\ttotal: 13.8s\tremaining: 994ms\n",
      "933:\tlearn: 1.4812846\ttotal: 13.9s\tremaining: 979ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "934:\tlearn: 1.4812839\ttotal: 13.9s\tremaining: 964ms\n",
      "935:\tlearn: 1.4812838\ttotal: 13.9s\tremaining: 949ms\n",
      "936:\tlearn: 1.4812838\ttotal: 13.9s\tremaining: 935ms\n",
      "937:\tlearn: 1.4812838\ttotal: 13.9s\tremaining: 920ms\n",
      "938:\tlearn: 1.4812838\ttotal: 13.9s\tremaining: 905ms\n",
      "939:\tlearn: 1.4812816\ttotal: 13.9s\tremaining: 890ms\n",
      "940:\tlearn: 1.4811673\ttotal: 14s\tremaining: 875ms\n",
      "941:\tlearn: 1.4811355\ttotal: 14s\tremaining: 860ms\n",
      "942:\tlearn: 1.4811283\ttotal: 14s\tremaining: 845ms\n",
      "943:\tlearn: 1.4811246\ttotal: 14s\tremaining: 830ms\n",
      "944:\tlearn: 1.4811154\ttotal: 14s\tremaining: 816ms\n",
      "945:\tlearn: 1.4811147\ttotal: 14s\tremaining: 801ms\n",
      "946:\tlearn: 1.4810736\ttotal: 14s\tremaining: 786ms\n",
      "947:\tlearn: 1.4808076\ttotal: 14.1s\tremaining: 771ms\n",
      "948:\tlearn: 1.4807571\ttotal: 14.1s\tremaining: 756ms\n",
      "949:\tlearn: 1.4805109\ttotal: 14.1s\tremaining: 741ms\n",
      "950:\tlearn: 1.4804920\ttotal: 14.1s\tremaining: 727ms\n",
      "951:\tlearn: 1.4802712\ttotal: 14.1s\tremaining: 712ms\n",
      "952:\tlearn: 1.4802358\ttotal: 14.1s\tremaining: 697ms\n",
      "953:\tlearn: 1.4802330\ttotal: 14.1s\tremaining: 682ms\n",
      "954:\tlearn: 1.4801965\ttotal: 14.2s\tremaining: 667ms\n",
      "955:\tlearn: 1.4800870\ttotal: 14.2s\tremaining: 652ms\n",
      "956:\tlearn: 1.4800200\ttotal: 14.2s\tremaining: 637ms\n",
      "957:\tlearn: 1.4800188\ttotal: 14.2s\tremaining: 623ms\n",
      "958:\tlearn: 1.4798095\ttotal: 14.2s\tremaining: 608ms\n",
      "959:\tlearn: 1.4798095\ttotal: 14.2s\tremaining: 593ms\n",
      "960:\tlearn: 1.4798091\ttotal: 14.2s\tremaining: 578ms\n",
      "961:\tlearn: 1.4797032\ttotal: 14.3s\tremaining: 563ms\n",
      "962:\tlearn: 1.4796236\ttotal: 14.3s\tremaining: 548ms\n",
      "963:\tlearn: 1.4796061\ttotal: 14.3s\tremaining: 533ms\n",
      "964:\tlearn: 1.4796032\ttotal: 14.3s\tremaining: 519ms\n",
      "965:\tlearn: 1.4791307\ttotal: 14.3s\tremaining: 504ms\n",
      "966:\tlearn: 1.4781691\ttotal: 14.3s\tremaining: 489ms\n",
      "967:\tlearn: 1.4781448\ttotal: 14.3s\tremaining: 474ms\n",
      "968:\tlearn: 1.4780484\ttotal: 14.4s\tremaining: 459ms\n",
      "969:\tlearn: 1.4780445\ttotal: 14.4s\tremaining: 444ms\n",
      "970:\tlearn: 1.4780219\ttotal: 14.4s\tremaining: 430ms\n",
      "971:\tlearn: 1.4778873\ttotal: 14.4s\tremaining: 415ms\n",
      "972:\tlearn: 1.4778768\ttotal: 14.4s\tremaining: 400ms\n",
      "973:\tlearn: 1.4777993\ttotal: 14.4s\tremaining: 385ms\n",
      "974:\tlearn: 1.4777990\ttotal: 14.4s\tremaining: 370ms\n",
      "975:\tlearn: 1.4774150\ttotal: 14.5s\tremaining: 355ms\n",
      "976:\tlearn: 1.4774091\ttotal: 14.5s\tremaining: 341ms\n",
      "977:\tlearn: 1.4773973\ttotal: 14.5s\tremaining: 326ms\n",
      "978:\tlearn: 1.4771906\ttotal: 14.5s\tremaining: 311ms\n",
      "979:\tlearn: 1.4771872\ttotal: 14.5s\tremaining: 296ms\n",
      "980:\tlearn: 1.4770337\ttotal: 14.5s\tremaining: 281ms\n",
      "981:\tlearn: 1.4770336\ttotal: 14.5s\tremaining: 267ms\n",
      "982:\tlearn: 1.4770304\ttotal: 14.6s\tremaining: 252ms\n",
      "983:\tlearn: 1.4770302\ttotal: 14.6s\tremaining: 237ms\n",
      "984:\tlearn: 1.4770302\ttotal: 14.6s\tremaining: 222ms\n",
      "985:\tlearn: 1.4770216\ttotal: 14.6s\tremaining: 207ms\n",
      "986:\tlearn: 1.4770214\ttotal: 14.6s\tremaining: 192ms\n",
      "987:\tlearn: 1.4769946\ttotal: 14.6s\tremaining: 178ms\n",
      "988:\tlearn: 1.4769938\ttotal: 14.6s\tremaining: 163ms\n",
      "989:\tlearn: 1.4768920\ttotal: 14.7s\tremaining: 148ms\n",
      "990:\tlearn: 1.4768919\ttotal: 14.7s\tremaining: 133ms\n",
      "991:\tlearn: 1.4768907\ttotal: 14.7s\tremaining: 118ms\n",
      "992:\tlearn: 1.4768066\ttotal: 14.7s\tremaining: 104ms\n",
      "993:\tlearn: 1.4761112\ttotal: 14.7s\tremaining: 88.8ms\n",
      "994:\tlearn: 1.4754762\ttotal: 14.7s\tremaining: 74ms\n",
      "995:\tlearn: 1.4754315\ttotal: 14.7s\tremaining: 59.2ms\n",
      "996:\tlearn: 1.4750733\ttotal: 14.8s\tremaining: 44.4ms\n",
      "997:\tlearn: 1.4748903\ttotal: 14.8s\tremaining: 29.6ms\n",
      "998:\tlearn: 1.4746443\ttotal: 14.8s\tremaining: 14.8ms\n",
      "999:\tlearn: 1.4746353\ttotal: 14.8s\tremaining: 0us\n",
      "0:\tlearn: 9.6049396\ttotal: 18.1ms\tremaining: 18.1s\n",
      "1:\tlearn: 8.9116760\ttotal: 38.4ms\tremaining: 19.2s\n",
      "2:\tlearn: 8.2376176\ttotal: 56.9ms\tremaining: 18.9s\n",
      "3:\tlearn: 7.6454094\ttotal: 75.3ms\tremaining: 18.7s\n",
      "4:\tlearn: 7.0283600\ttotal: 93.2ms\tremaining: 18.5s\n",
      "5:\tlearn: 6.5677190\ttotal: 110ms\tremaining: 18.2s\n",
      "6:\tlearn: 6.0512962\ttotal: 127ms\tremaining: 18.1s\n",
      "7:\tlearn: 5.6969473\ttotal: 145ms\tremaining: 17.9s\n",
      "8:\tlearn: 5.2491109\ttotal: 162ms\tremaining: 17.8s\n",
      "9:\tlearn: 4.8620231\ttotal: 180ms\tremaining: 17.8s\n",
      "10:\tlearn: 4.5486492\ttotal: 197ms\tremaining: 17.7s\n",
      "11:\tlearn: 4.3428171\ttotal: 215ms\tremaining: 17.7s\n",
      "12:\tlearn: 4.0683896\ttotal: 233ms\tremaining: 17.7s\n",
      "13:\tlearn: 3.8349811\ttotal: 251ms\tremaining: 17.7s\n",
      "14:\tlearn: 3.6284363\ttotal: 268ms\tremaining: 17.6s\n",
      "15:\tlearn: 3.4457690\ttotal: 286ms\tremaining: 17.6s\n",
      "16:\tlearn: 3.3525010\ttotal: 303ms\tremaining: 17.5s\n",
      "17:\tlearn: 3.2136442\ttotal: 320ms\tremaining: 17.5s\n",
      "18:\tlearn: 3.0920471\ttotal: 336ms\tremaining: 17.4s\n",
      "19:\tlearn: 2.9724254\ttotal: 353ms\tremaining: 17.3s\n",
      "20:\tlearn: 2.9146224\ttotal: 368ms\tremaining: 17.1s\n",
      "21:\tlearn: 2.8642378\ttotal: 383ms\tremaining: 17s\n",
      "22:\tlearn: 2.8225494\ttotal: 397ms\tremaining: 16.9s\n",
      "23:\tlearn: 2.7663312\ttotal: 413ms\tremaining: 16.8s\n",
      "24:\tlearn: 2.7057133\ttotal: 427ms\tremaining: 16.7s\n",
      "25:\tlearn: 2.6805568\ttotal: 443ms\tremaining: 16.6s\n",
      "26:\tlearn: 2.6574582\ttotal: 460ms\tremaining: 16.6s\n",
      "27:\tlearn: 2.6124078\ttotal: 475ms\tremaining: 16.5s\n",
      "28:\tlearn: 2.5919888\ttotal: 490ms\tremaining: 16.4s\n",
      "29:\tlearn: 2.5478758\ttotal: 504ms\tremaining: 16.3s\n",
      "30:\tlearn: 2.5237616\ttotal: 518ms\tremaining: 16.2s\n",
      "31:\tlearn: 2.5088120\ttotal: 532ms\tremaining: 16.1s\n",
      "32:\tlearn: 2.4824120\ttotal: 547ms\tremaining: 16s\n",
      "33:\tlearn: 2.4487691\ttotal: 562ms\tremaining: 16s\n",
      "34:\tlearn: 2.4364287\ttotal: 577ms\tremaining: 15.9s\n",
      "35:\tlearn: 2.4268359\ttotal: 592ms\tremaining: 15.8s\n",
      "36:\tlearn: 2.4018124\ttotal: 607ms\tremaining: 15.8s\n",
      "37:\tlearn: 2.3844473\ttotal: 621ms\tremaining: 15.7s\n",
      "38:\tlearn: 2.3604134\ttotal: 636ms\tremaining: 15.7s\n",
      "39:\tlearn: 2.3554887\ttotal: 651ms\tremaining: 15.6s\n",
      "40:\tlearn: 2.3478867\ttotal: 668ms\tremaining: 15.6s\n",
      "41:\tlearn: 2.3444673\ttotal: 682ms\tremaining: 15.5s\n",
      "42:\tlearn: 2.3389402\ttotal: 696ms\tremaining: 15.5s\n",
      "43:\tlearn: 2.3371329\ttotal: 711ms\tremaining: 15.4s\n",
      "44:\tlearn: 2.3355670\ttotal: 726ms\tremaining: 15.4s\n",
      "45:\tlearn: 2.3336859\ttotal: 740ms\tremaining: 15.4s\n",
      "46:\tlearn: 2.3184872\ttotal: 756ms\tremaining: 15.3s\n",
      "47:\tlearn: 2.3139723\ttotal: 771ms\tremaining: 15.3s\n",
      "48:\tlearn: 2.3097543\ttotal: 785ms\tremaining: 15.2s\n",
      "49:\tlearn: 2.3077576\ttotal: 800ms\tremaining: 15.2s\n",
      "50:\tlearn: 2.3068511\ttotal: 814ms\tremaining: 15.2s\n",
      "51:\tlearn: 2.3038821\ttotal: 829ms\tremaining: 15.1s\n",
      "52:\tlearn: 2.3023571\ttotal: 843ms\tremaining: 15.1s\n",
      "53:\tlearn: 2.2999125\ttotal: 859ms\tremaining: 15s\n",
      "54:\tlearn: 2.2986210\ttotal: 874ms\tremaining: 15s\n",
      "55:\tlearn: 2.2864308\ttotal: 889ms\tremaining: 15s\n",
      "56:\tlearn: 2.2827103\ttotal: 904ms\tremaining: 15s\n",
      "57:\tlearn: 2.2820972\ttotal: 920ms\tremaining: 14.9s\n",
      "58:\tlearn: 2.2819695\ttotal: 935ms\tremaining: 14.9s\n",
      "59:\tlearn: 2.2813955\ttotal: 951ms\tremaining: 14.9s\n",
      "60:\tlearn: 2.2812602\ttotal: 968ms\tremaining: 14.9s\n",
      "61:\tlearn: 2.2807935\ttotal: 984ms\tremaining: 14.9s\n",
      "62:\tlearn: 2.2701476\ttotal: 999ms\tremaining: 14.9s\n",
      "63:\tlearn: 2.2679000\ttotal: 1.01s\tremaining: 14.8s\n",
      "64:\tlearn: 2.2673523\ttotal: 1.03s\tremaining: 14.8s\n",
      "65:\tlearn: 2.2654044\ttotal: 1.04s\tremaining: 14.7s\n",
      "66:\tlearn: 2.2648472\ttotal: 1.05s\tremaining: 14.7s\n",
      "67:\tlearn: 2.2593992\ttotal: 1.07s\tremaining: 14.7s\n",
      "68:\tlearn: 2.2518622\ttotal: 1.09s\tremaining: 14.7s\n",
      "69:\tlearn: 2.2506867\ttotal: 1.1s\tremaining: 14.7s\n",
      "70:\tlearn: 2.2504264\ttotal: 1.12s\tremaining: 14.6s\n",
      "71:\tlearn: 2.2502052\ttotal: 1.13s\tremaining: 14.6s\n",
      "72:\tlearn: 2.2497791\ttotal: 1.15s\tremaining: 14.5s\n",
      "73:\tlearn: 2.2495807\ttotal: 1.16s\tremaining: 14.5s\n",
      "74:\tlearn: 2.2491108\ttotal: 1.17s\tremaining: 14.5s\n",
      "75:\tlearn: 2.2476759\ttotal: 1.19s\tremaining: 14.5s\n",
      "76:\tlearn: 2.2461550\ttotal: 1.2s\tremaining: 14.4s\n",
      "77:\tlearn: 2.2459961\ttotal: 1.22s\tremaining: 14.4s\n",
      "78:\tlearn: 2.2449357\ttotal: 1.23s\tremaining: 14.4s\n",
      "79:\tlearn: 2.2448112\ttotal: 1.25s\tremaining: 14.3s\n",
      "80:\tlearn: 2.2431860\ttotal: 1.26s\tremaining: 14.3s\n",
      "81:\tlearn: 2.2348982\ttotal: 1.28s\tremaining: 14.3s\n",
      "82:\tlearn: 2.2343212\ttotal: 1.29s\tremaining: 14.3s\n",
      "83:\tlearn: 2.2340269\ttotal: 1.31s\tremaining: 14.3s\n",
      "84:\tlearn: 2.2282926\ttotal: 1.32s\tremaining: 14.2s\n",
      "85:\tlearn: 2.2280050\ttotal: 1.33s\tremaining: 14.2s\n",
      "86:\tlearn: 2.2274732\ttotal: 1.35s\tremaining: 14.2s\n",
      "87:\tlearn: 2.2263613\ttotal: 1.37s\tremaining: 14.2s\n",
      "88:\tlearn: 2.2260777\ttotal: 1.38s\tremaining: 14.1s\n",
      "89:\tlearn: 2.2244637\ttotal: 1.4s\tremaining: 14.1s\n",
      "90:\tlearn: 2.2242780\ttotal: 1.41s\tremaining: 14.1s\n",
      "91:\tlearn: 2.2235494\ttotal: 1.42s\tremaining: 14.1s\n",
      "92:\tlearn: 2.2235459\ttotal: 1.43s\tremaining: 14s\n",
      "93:\tlearn: 2.2227520\ttotal: 1.45s\tremaining: 13.9s\n",
      "94:\tlearn: 2.2217401\ttotal: 1.46s\tremaining: 13.9s\n",
      "95:\tlearn: 2.2217316\ttotal: 1.48s\tremaining: 13.9s\n",
      "96:\tlearn: 2.2210667\ttotal: 1.49s\tremaining: 13.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97:\tlearn: 2.2204366\ttotal: 1.51s\tremaining: 13.9s\n",
      "98:\tlearn: 2.2197398\ttotal: 1.52s\tremaining: 13.9s\n",
      "99:\tlearn: 2.2196209\ttotal: 1.54s\tremaining: 13.8s\n",
      "100:\tlearn: 2.2194746\ttotal: 1.55s\tremaining: 13.8s\n",
      "101:\tlearn: 2.2130109\ttotal: 1.56s\tremaining: 13.8s\n",
      "102:\tlearn: 2.2097834\ttotal: 1.58s\tremaining: 13.8s\n",
      "103:\tlearn: 2.2037826\ttotal: 1.59s\tremaining: 13.7s\n",
      "104:\tlearn: 2.2029397\ttotal: 1.61s\tremaining: 13.7s\n",
      "105:\tlearn: 2.2022152\ttotal: 1.62s\tremaining: 13.7s\n",
      "106:\tlearn: 2.2018472\ttotal: 1.64s\tremaining: 13.7s\n",
      "107:\tlearn: 2.2009874\ttotal: 1.65s\tremaining: 13.6s\n",
      "108:\tlearn: 2.2000644\ttotal: 1.67s\tremaining: 13.6s\n",
      "109:\tlearn: 2.1998986\ttotal: 1.68s\tremaining: 13.6s\n",
      "110:\tlearn: 2.1991565\ttotal: 1.7s\tremaining: 13.6s\n",
      "111:\tlearn: 2.1987893\ttotal: 1.71s\tremaining: 13.6s\n",
      "112:\tlearn: 2.1980590\ttotal: 1.73s\tremaining: 13.5s\n",
      "113:\tlearn: 2.1978090\ttotal: 1.74s\tremaining: 13.5s\n",
      "114:\tlearn: 2.1970882\ttotal: 1.75s\tremaining: 13.5s\n",
      "115:\tlearn: 2.1968980\ttotal: 1.77s\tremaining: 13.5s\n",
      "116:\tlearn: 2.1964123\ttotal: 1.78s\tremaining: 13.5s\n",
      "117:\tlearn: 2.1961334\ttotal: 1.8s\tremaining: 13.4s\n",
      "118:\tlearn: 2.1960140\ttotal: 1.81s\tremaining: 13.4s\n",
      "119:\tlearn: 2.1902546\ttotal: 1.83s\tremaining: 13.4s\n",
      "120:\tlearn: 2.1848395\ttotal: 1.84s\tremaining: 13.4s\n",
      "121:\tlearn: 2.1795578\ttotal: 1.85s\tremaining: 13.4s\n",
      "122:\tlearn: 2.1790154\ttotal: 1.87s\tremaining: 13.3s\n",
      "123:\tlearn: 2.1787580\ttotal: 1.88s\tremaining: 13.3s\n",
      "124:\tlearn: 2.1786069\ttotal: 1.9s\tremaining: 13.3s\n",
      "125:\tlearn: 2.1768968\ttotal: 1.91s\tremaining: 13.3s\n",
      "126:\tlearn: 2.1766373\ttotal: 1.93s\tremaining: 13.3s\n",
      "127:\tlearn: 2.1763821\ttotal: 1.94s\tremaining: 13.2s\n",
      "128:\tlearn: 2.1760164\ttotal: 1.96s\tremaining: 13.2s\n",
      "129:\tlearn: 2.1751134\ttotal: 1.97s\tremaining: 13.2s\n",
      "130:\tlearn: 2.1743129\ttotal: 1.99s\tremaining: 13.2s\n",
      "131:\tlearn: 2.1721180\ttotal: 2s\tremaining: 13.2s\n",
      "132:\tlearn: 2.1702613\ttotal: 2.02s\tremaining: 13.1s\n",
      "133:\tlearn: 2.1682752\ttotal: 2.03s\tremaining: 13.1s\n",
      "134:\tlearn: 2.1624280\ttotal: 2.04s\tremaining: 13.1s\n",
      "135:\tlearn: 2.1564164\ttotal: 2.06s\tremaining: 13.1s\n",
      "136:\tlearn: 2.1502690\ttotal: 2.07s\tremaining: 13.1s\n",
      "137:\tlearn: 2.1486667\ttotal: 2.09s\tremaining: 13s\n",
      "138:\tlearn: 2.1465760\ttotal: 2.1s\tremaining: 13s\n",
      "139:\tlearn: 2.1436612\ttotal: 2.12s\tremaining: 13s\n",
      "140:\tlearn: 2.1364742\ttotal: 2.13s\tremaining: 13s\n",
      "141:\tlearn: 2.1319237\ttotal: 2.15s\tremaining: 13s\n",
      "142:\tlearn: 2.1264773\ttotal: 2.16s\tremaining: 13s\n",
      "143:\tlearn: 2.1213840\ttotal: 2.18s\tremaining: 13s\n",
      "144:\tlearn: 2.1158080\ttotal: 2.19s\tremaining: 12.9s\n",
      "145:\tlearn: 2.1112029\ttotal: 2.21s\tremaining: 12.9s\n",
      "146:\tlearn: 2.1060747\ttotal: 2.22s\tremaining: 12.9s\n",
      "147:\tlearn: 2.1032107\ttotal: 2.24s\tremaining: 12.9s\n",
      "148:\tlearn: 2.1016861\ttotal: 2.25s\tremaining: 12.9s\n",
      "149:\tlearn: 2.1000204\ttotal: 2.27s\tremaining: 12.8s\n",
      "150:\tlearn: 2.0986949\ttotal: 2.28s\tremaining: 12.8s\n",
      "151:\tlearn: 2.0977709\ttotal: 2.3s\tremaining: 12.8s\n",
      "152:\tlearn: 2.0930140\ttotal: 2.31s\tremaining: 12.8s\n",
      "153:\tlearn: 2.0898845\ttotal: 2.33s\tremaining: 12.8s\n",
      "154:\tlearn: 2.0886588\ttotal: 2.34s\tremaining: 12.8s\n",
      "155:\tlearn: 2.0881616\ttotal: 2.35s\tremaining: 12.7s\n",
      "156:\tlearn: 2.0864799\ttotal: 2.37s\tremaining: 12.7s\n",
      "157:\tlearn: 2.0840874\ttotal: 2.38s\tremaining: 12.7s\n",
      "158:\tlearn: 2.0805638\ttotal: 2.4s\tremaining: 12.7s\n",
      "159:\tlearn: 2.0773430\ttotal: 2.41s\tremaining: 12.7s\n",
      "160:\tlearn: 2.0742732\ttotal: 2.43s\tremaining: 12.7s\n",
      "161:\tlearn: 2.0717802\ttotal: 2.44s\tremaining: 12.6s\n",
      "162:\tlearn: 2.0712830\ttotal: 2.46s\tremaining: 12.6s\n",
      "163:\tlearn: 2.0702127\ttotal: 2.47s\tremaining: 12.6s\n",
      "164:\tlearn: 2.0684909\ttotal: 2.49s\tremaining: 12.6s\n",
      "165:\tlearn: 2.0667112\ttotal: 2.52s\tremaining: 12.6s\n",
      "166:\tlearn: 2.0655845\ttotal: 2.53s\tremaining: 12.6s\n",
      "167:\tlearn: 2.0650625\ttotal: 2.54s\tremaining: 12.6s\n",
      "168:\tlearn: 2.0647434\ttotal: 2.56s\tremaining: 12.6s\n",
      "169:\tlearn: 2.0635666\ttotal: 2.58s\tremaining: 12.6s\n",
      "170:\tlearn: 2.0622215\ttotal: 2.59s\tremaining: 12.6s\n",
      "171:\tlearn: 2.0601583\ttotal: 2.6s\tremaining: 12.5s\n",
      "172:\tlearn: 2.0564468\ttotal: 2.62s\tremaining: 12.5s\n",
      "173:\tlearn: 2.0560797\ttotal: 2.63s\tremaining: 12.5s\n",
      "174:\tlearn: 2.0558376\ttotal: 2.65s\tremaining: 12.5s\n",
      "175:\tlearn: 2.0535703\ttotal: 2.66s\tremaining: 12.5s\n",
      "176:\tlearn: 2.0512174\ttotal: 2.68s\tremaining: 12.4s\n",
      "177:\tlearn: 2.0480872\ttotal: 2.69s\tremaining: 12.4s\n",
      "178:\tlearn: 2.0471504\ttotal: 2.71s\tremaining: 12.4s\n",
      "179:\tlearn: 2.0470166\ttotal: 2.72s\tremaining: 12.4s\n",
      "180:\tlearn: 2.0454864\ttotal: 2.73s\tremaining: 12.4s\n",
      "181:\tlearn: 2.0440369\ttotal: 2.75s\tremaining: 12.4s\n",
      "182:\tlearn: 2.0426625\ttotal: 2.76s\tremaining: 12.3s\n",
      "183:\tlearn: 2.0400811\ttotal: 2.78s\tremaining: 12.3s\n",
      "184:\tlearn: 2.0390683\ttotal: 2.8s\tremaining: 12.3s\n",
      "185:\tlearn: 2.0369104\ttotal: 2.81s\tremaining: 12.3s\n",
      "186:\tlearn: 2.0348825\ttotal: 2.83s\tremaining: 12.3s\n",
      "187:\tlearn: 2.0330133\ttotal: 2.84s\tremaining: 12.3s\n",
      "188:\tlearn: 2.0318392\ttotal: 2.86s\tremaining: 12.3s\n",
      "189:\tlearn: 2.0309067\ttotal: 2.87s\tremaining: 12.2s\n",
      "190:\tlearn: 2.0299596\ttotal: 2.88s\tremaining: 12.2s\n",
      "191:\tlearn: 2.0276006\ttotal: 2.9s\tremaining: 12.2s\n",
      "192:\tlearn: 2.0271681\ttotal: 2.91s\tremaining: 12.2s\n",
      "193:\tlearn: 2.0269239\ttotal: 2.93s\tremaining: 12.2s\n",
      "194:\tlearn: 2.0265508\ttotal: 2.94s\tremaining: 12.1s\n",
      "195:\tlearn: 2.0256552\ttotal: 2.96s\tremaining: 12.1s\n",
      "196:\tlearn: 2.0229729\ttotal: 2.97s\tremaining: 12.1s\n",
      "197:\tlearn: 2.0211700\ttotal: 2.99s\tremaining: 12.1s\n",
      "198:\tlearn: 2.0191903\ttotal: 3s\tremaining: 12.1s\n",
      "199:\tlearn: 2.0163230\ttotal: 3.02s\tremaining: 12.1s\n",
      "200:\tlearn: 2.0146641\ttotal: 3.03s\tremaining: 12.1s\n",
      "201:\tlearn: 2.0137518\ttotal: 3.04s\tremaining: 12s\n",
      "202:\tlearn: 2.0125353\ttotal: 3.06s\tremaining: 12s\n",
      "203:\tlearn: 2.0103851\ttotal: 3.08s\tremaining: 12s\n",
      "204:\tlearn: 2.0096387\ttotal: 3.09s\tremaining: 12s\n",
      "205:\tlearn: 2.0076615\ttotal: 3.1s\tremaining: 12s\n",
      "206:\tlearn: 2.0056126\ttotal: 3.12s\tremaining: 11.9s\n",
      "207:\tlearn: 2.0032602\ttotal: 3.13s\tremaining: 11.9s\n",
      "208:\tlearn: 2.0015561\ttotal: 3.15s\tremaining: 11.9s\n",
      "209:\tlearn: 2.0003324\ttotal: 3.16s\tremaining: 11.9s\n",
      "210:\tlearn: 1.9992689\ttotal: 3.18s\tremaining: 11.9s\n",
      "211:\tlearn: 1.9980273\ttotal: 3.19s\tremaining: 11.9s\n",
      "212:\tlearn: 1.9974848\ttotal: 3.21s\tremaining: 11.9s\n",
      "213:\tlearn: 1.9970303\ttotal: 3.22s\tremaining: 11.8s\n",
      "214:\tlearn: 1.9970034\ttotal: 3.24s\tremaining: 11.8s\n",
      "215:\tlearn: 1.9957171\ttotal: 3.25s\tremaining: 11.8s\n",
      "216:\tlearn: 1.9945738\ttotal: 3.27s\tremaining: 11.8s\n",
      "217:\tlearn: 1.9940814\ttotal: 3.28s\tremaining: 11.8s\n",
      "218:\tlearn: 1.9939976\ttotal: 3.29s\tremaining: 11.7s\n",
      "219:\tlearn: 1.9929841\ttotal: 3.31s\tremaining: 11.7s\n",
      "220:\tlearn: 1.9912511\ttotal: 3.32s\tremaining: 11.7s\n",
      "221:\tlearn: 1.9897066\ttotal: 3.34s\tremaining: 11.7s\n",
      "222:\tlearn: 1.9890495\ttotal: 3.35s\tremaining: 11.7s\n",
      "223:\tlearn: 1.9885374\ttotal: 3.37s\tremaining: 11.7s\n",
      "224:\tlearn: 1.9874016\ttotal: 3.38s\tremaining: 11.7s\n",
      "225:\tlearn: 1.9869895\ttotal: 3.4s\tremaining: 11.6s\n",
      "226:\tlearn: 1.9858260\ttotal: 3.41s\tremaining: 11.6s\n",
      "227:\tlearn: 1.9849210\ttotal: 3.43s\tremaining: 11.6s\n",
      "228:\tlearn: 1.9840927\ttotal: 3.44s\tremaining: 11.6s\n",
      "229:\tlearn: 1.9835932\ttotal: 3.46s\tremaining: 11.6s\n",
      "230:\tlearn: 1.9827729\ttotal: 3.48s\tremaining: 11.6s\n",
      "231:\tlearn: 1.9819852\ttotal: 3.49s\tremaining: 11.6s\n",
      "232:\tlearn: 1.9818877\ttotal: 3.5s\tremaining: 11.5s\n",
      "233:\tlearn: 1.9809038\ttotal: 3.52s\tremaining: 11.5s\n",
      "234:\tlearn: 1.9804311\ttotal: 3.53s\tremaining: 11.5s\n",
      "235:\tlearn: 1.9802249\ttotal: 3.55s\tremaining: 11.5s\n",
      "236:\tlearn: 1.9775817\ttotal: 3.56s\tremaining: 11.5s\n",
      "237:\tlearn: 1.9761737\ttotal: 3.58s\tremaining: 11.5s\n",
      "238:\tlearn: 1.9753967\ttotal: 3.59s\tremaining: 11.4s\n",
      "239:\tlearn: 1.9750175\ttotal: 3.61s\tremaining: 11.4s\n",
      "240:\tlearn: 1.9733647\ttotal: 3.62s\tremaining: 11.4s\n",
      "241:\tlearn: 1.9722355\ttotal: 3.64s\tremaining: 11.4s\n",
      "242:\tlearn: 1.9711546\ttotal: 3.65s\tremaining: 11.4s\n",
      "243:\tlearn: 1.9698251\ttotal: 3.67s\tremaining: 11.4s\n",
      "244:\tlearn: 1.9686682\ttotal: 3.68s\tremaining: 11.3s\n",
      "245:\tlearn: 1.9684641\ttotal: 3.7s\tremaining: 11.3s\n",
      "246:\tlearn: 1.9672386\ttotal: 3.71s\tremaining: 11.3s\n",
      "247:\tlearn: 1.9658963\ttotal: 3.73s\tremaining: 11.3s\n",
      "248:\tlearn: 1.9657743\ttotal: 3.74s\tremaining: 11.3s\n",
      "249:\tlearn: 1.9648214\ttotal: 3.75s\tremaining: 11.3s\n",
      "250:\tlearn: 1.9637963\ttotal: 3.77s\tremaining: 11.3s\n",
      "251:\tlearn: 1.9625454\ttotal: 3.79s\tremaining: 11.2s\n",
      "252:\tlearn: 1.9615672\ttotal: 3.8s\tremaining: 11.2s\n",
      "253:\tlearn: 1.9614789\ttotal: 3.81s\tremaining: 11.2s\n",
      "254:\tlearn: 1.9602897\ttotal: 3.83s\tremaining: 11.2s\n",
      "255:\tlearn: 1.9589398\ttotal: 3.84s\tremaining: 11.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256:\tlearn: 1.9581220\ttotal: 3.86s\tremaining: 11.2s\n",
      "257:\tlearn: 1.9564180\ttotal: 3.87s\tremaining: 11.1s\n",
      "258:\tlearn: 1.9553336\ttotal: 3.89s\tremaining: 11.1s\n",
      "259:\tlearn: 1.9553329\ttotal: 3.9s\tremaining: 11.1s\n",
      "260:\tlearn: 1.9550966\ttotal: 3.92s\tremaining: 11.1s\n",
      "261:\tlearn: 1.9547998\ttotal: 3.93s\tremaining: 11.1s\n",
      "262:\tlearn: 1.9542645\ttotal: 3.95s\tremaining: 11.1s\n",
      "263:\tlearn: 1.9539936\ttotal: 3.96s\tremaining: 11s\n",
      "264:\tlearn: 1.9531046\ttotal: 3.98s\tremaining: 11s\n",
      "265:\tlearn: 1.9529814\ttotal: 3.99s\tremaining: 11s\n",
      "266:\tlearn: 1.9528462\ttotal: 4.01s\tremaining: 11s\n",
      "267:\tlearn: 1.9527350\ttotal: 4.02s\tremaining: 11s\n",
      "268:\tlearn: 1.9522945\ttotal: 4.03s\tremaining: 11s\n",
      "269:\tlearn: 1.9519443\ttotal: 4.05s\tremaining: 10.9s\n",
      "270:\tlearn: 1.9514554\ttotal: 4.06s\tremaining: 10.9s\n",
      "271:\tlearn: 1.9508866\ttotal: 4.08s\tremaining: 10.9s\n",
      "272:\tlearn: 1.9507800\ttotal: 4.1s\tremaining: 10.9s\n",
      "273:\tlearn: 1.9506689\ttotal: 4.11s\tremaining: 10.9s\n",
      "274:\tlearn: 1.9503176\ttotal: 4.13s\tremaining: 10.9s\n",
      "275:\tlearn: 1.9497070\ttotal: 4.14s\tremaining: 10.9s\n",
      "276:\tlearn: 1.9494565\ttotal: 4.16s\tremaining: 10.8s\n",
      "277:\tlearn: 1.9490790\ttotal: 4.17s\tremaining: 10.8s\n",
      "278:\tlearn: 1.9489295\ttotal: 4.19s\tremaining: 10.8s\n",
      "279:\tlearn: 1.9486812\ttotal: 4.2s\tremaining: 10.8s\n",
      "280:\tlearn: 1.9484974\ttotal: 4.22s\tremaining: 10.8s\n",
      "281:\tlearn: 1.9481347\ttotal: 4.23s\tremaining: 10.8s\n",
      "282:\tlearn: 1.9471716\ttotal: 4.25s\tremaining: 10.8s\n",
      "283:\tlearn: 1.9469446\ttotal: 4.26s\tremaining: 10.7s\n",
      "284:\tlearn: 1.9465498\ttotal: 4.28s\tremaining: 10.7s\n",
      "285:\tlearn: 1.9458678\ttotal: 4.29s\tremaining: 10.7s\n",
      "286:\tlearn: 1.9456455\ttotal: 4.3s\tremaining: 10.7s\n",
      "287:\tlearn: 1.9454104\ttotal: 4.32s\tremaining: 10.7s\n",
      "288:\tlearn: 1.9443738\ttotal: 4.33s\tremaining: 10.7s\n",
      "289:\tlearn: 1.9442462\ttotal: 4.35s\tremaining: 10.6s\n",
      "290:\tlearn: 1.9432362\ttotal: 4.36s\tremaining: 10.6s\n",
      "291:\tlearn: 1.9423554\ttotal: 4.38s\tremaining: 10.6s\n",
      "292:\tlearn: 1.9423553\ttotal: 4.39s\tremaining: 10.6s\n",
      "293:\tlearn: 1.9411283\ttotal: 4.41s\tremaining: 10.6s\n",
      "294:\tlearn: 1.9410134\ttotal: 4.42s\tremaining: 10.6s\n",
      "295:\tlearn: 1.9397150\ttotal: 4.43s\tremaining: 10.5s\n",
      "296:\tlearn: 1.9393369\ttotal: 4.45s\tremaining: 10.5s\n",
      "297:\tlearn: 1.9387948\ttotal: 4.46s\tremaining: 10.5s\n",
      "298:\tlearn: 1.9384441\ttotal: 4.48s\tremaining: 10.5s\n",
      "299:\tlearn: 1.9375455\ttotal: 4.49s\tremaining: 10.5s\n",
      "300:\tlearn: 1.9372397\ttotal: 4.51s\tremaining: 10.5s\n",
      "301:\tlearn: 1.9369717\ttotal: 4.52s\tremaining: 10.5s\n",
      "302:\tlearn: 1.9367968\ttotal: 4.54s\tremaining: 10.4s\n",
      "303:\tlearn: 1.9366660\ttotal: 4.55s\tremaining: 10.4s\n",
      "304:\tlearn: 1.9363429\ttotal: 4.57s\tremaining: 10.4s\n",
      "305:\tlearn: 1.9354432\ttotal: 4.58s\tremaining: 10.4s\n",
      "306:\tlearn: 1.9353051\ttotal: 4.6s\tremaining: 10.4s\n",
      "307:\tlearn: 1.9351223\ttotal: 4.61s\tremaining: 10.4s\n",
      "308:\tlearn: 1.9347503\ttotal: 4.63s\tremaining: 10.3s\n",
      "309:\tlearn: 1.9347426\ttotal: 4.64s\tremaining: 10.3s\n",
      "310:\tlearn: 1.9345554\ttotal: 4.66s\tremaining: 10.3s\n",
      "311:\tlearn: 1.9340175\ttotal: 4.67s\tremaining: 10.3s\n",
      "312:\tlearn: 1.9340016\ttotal: 4.68s\tremaining: 10.3s\n",
      "313:\tlearn: 1.9338654\ttotal: 4.7s\tremaining: 10.3s\n",
      "314:\tlearn: 1.9333482\ttotal: 4.71s\tremaining: 10.3s\n",
      "315:\tlearn: 1.9329538\ttotal: 4.73s\tremaining: 10.2s\n",
      "316:\tlearn: 1.9317600\ttotal: 4.75s\tremaining: 10.2s\n",
      "317:\tlearn: 1.9309595\ttotal: 4.76s\tremaining: 10.2s\n",
      "318:\tlearn: 1.9307103\ttotal: 4.77s\tremaining: 10.2s\n",
      "319:\tlearn: 1.9302420\ttotal: 4.79s\tremaining: 10.2s\n",
      "320:\tlearn: 1.9295808\ttotal: 4.8s\tremaining: 10.2s\n",
      "321:\tlearn: 1.9294279\ttotal: 4.82s\tremaining: 10.1s\n",
      "322:\tlearn: 1.9282252\ttotal: 4.83s\tremaining: 10.1s\n",
      "323:\tlearn: 1.9277603\ttotal: 4.85s\tremaining: 10.1s\n",
      "324:\tlearn: 1.9271840\ttotal: 4.86s\tremaining: 10.1s\n",
      "325:\tlearn: 1.9265885\ttotal: 4.88s\tremaining: 10.1s\n",
      "326:\tlearn: 1.9260825\ttotal: 4.89s\tremaining: 10.1s\n",
      "327:\tlearn: 1.9257886\ttotal: 4.9s\tremaining: 10s\n",
      "328:\tlearn: 1.9251808\ttotal: 4.92s\tremaining: 10s\n",
      "329:\tlearn: 1.9250280\ttotal: 4.93s\tremaining: 10s\n",
      "330:\tlearn: 1.9240686\ttotal: 4.95s\tremaining: 10s\n",
      "331:\tlearn: 1.9235913\ttotal: 4.96s\tremaining: 9.99s\n",
      "332:\tlearn: 1.9229719\ttotal: 4.98s\tremaining: 9.97s\n",
      "333:\tlearn: 1.9224365\ttotal: 4.99s\tremaining: 9.95s\n",
      "334:\tlearn: 1.9220503\ttotal: 5s\tremaining: 9.94s\n",
      "335:\tlearn: 1.9219232\ttotal: 5.02s\tremaining: 9.92s\n",
      "336:\tlearn: 1.9217776\ttotal: 5.03s\tremaining: 9.9s\n",
      "337:\tlearn: 1.9216082\ttotal: 5.05s\tremaining: 9.89s\n",
      "338:\tlearn: 1.9201674\ttotal: 5.06s\tremaining: 9.87s\n",
      "339:\tlearn: 1.9197662\ttotal: 5.08s\tremaining: 9.86s\n",
      "340:\tlearn: 1.9185247\ttotal: 5.09s\tremaining: 9.84s\n",
      "341:\tlearn: 1.9176121\ttotal: 5.11s\tremaining: 9.83s\n",
      "342:\tlearn: 1.9167662\ttotal: 5.12s\tremaining: 9.81s\n",
      "343:\tlearn: 1.9167586\ttotal: 5.14s\tremaining: 9.79s\n",
      "344:\tlearn: 1.9167586\ttotal: 5.15s\tremaining: 9.78s\n",
      "345:\tlearn: 1.9165789\ttotal: 5.17s\tremaining: 9.76s\n",
      "346:\tlearn: 1.9163188\ttotal: 5.18s\tremaining: 9.75s\n",
      "347:\tlearn: 1.9162682\ttotal: 5.19s\tremaining: 9.73s\n",
      "348:\tlearn: 1.9162599\ttotal: 5.21s\tremaining: 9.71s\n",
      "349:\tlearn: 1.9162544\ttotal: 5.22s\tremaining: 9.7s\n",
      "350:\tlearn: 1.9162541\ttotal: 5.23s\tremaining: 9.68s\n",
      "351:\tlearn: 1.9161160\ttotal: 5.25s\tremaining: 9.66s\n",
      "352:\tlearn: 1.9161145\ttotal: 5.26s\tremaining: 9.65s\n",
      "353:\tlearn: 1.9161145\ttotal: 5.28s\tremaining: 9.63s\n",
      "354:\tlearn: 1.9157027\ttotal: 5.29s\tremaining: 9.61s\n",
      "355:\tlearn: 1.9157027\ttotal: 5.3s\tremaining: 9.6s\n",
      "356:\tlearn: 1.9156481\ttotal: 5.32s\tremaining: 9.58s\n",
      "357:\tlearn: 1.9156476\ttotal: 5.33s\tremaining: 9.56s\n",
      "358:\tlearn: 1.9156073\ttotal: 5.35s\tremaining: 9.55s\n",
      "359:\tlearn: 1.9154852\ttotal: 5.36s\tremaining: 9.54s\n",
      "360:\tlearn: 1.9154829\ttotal: 5.38s\tremaining: 9.52s\n",
      "361:\tlearn: 1.9154749\ttotal: 5.39s\tremaining: 9.5s\n",
      "362:\tlearn: 1.9152641\ttotal: 5.41s\tremaining: 9.49s\n",
      "363:\tlearn: 1.9152633\ttotal: 5.42s\tremaining: 9.47s\n",
      "364:\tlearn: 1.9151813\ttotal: 5.43s\tremaining: 9.45s\n",
      "365:\tlearn: 1.9148631\ttotal: 5.45s\tremaining: 9.44s\n",
      "366:\tlearn: 1.9145344\ttotal: 5.46s\tremaining: 9.42s\n",
      "367:\tlearn: 1.9140711\ttotal: 5.48s\tremaining: 9.41s\n",
      "368:\tlearn: 1.9140427\ttotal: 5.49s\tremaining: 9.39s\n",
      "369:\tlearn: 1.9138718\ttotal: 5.5s\tremaining: 9.37s\n",
      "370:\tlearn: 1.9137920\ttotal: 5.52s\tremaining: 9.36s\n",
      "371:\tlearn: 1.9136253\ttotal: 5.53s\tremaining: 9.34s\n",
      "372:\tlearn: 1.9129964\ttotal: 5.55s\tremaining: 9.33s\n",
      "373:\tlearn: 1.9129095\ttotal: 5.56s\tremaining: 9.31s\n",
      "374:\tlearn: 1.9128609\ttotal: 5.58s\tremaining: 9.3s\n",
      "375:\tlearn: 1.9128069\ttotal: 5.59s\tremaining: 9.28s\n",
      "376:\tlearn: 1.9126778\ttotal: 5.61s\tremaining: 9.27s\n",
      "377:\tlearn: 1.9126694\ttotal: 5.62s\tremaining: 9.25s\n",
      "378:\tlearn: 1.9117549\ttotal: 5.63s\tremaining: 9.23s\n",
      "379:\tlearn: 1.9107705\ttotal: 5.65s\tremaining: 9.22s\n",
      "380:\tlearn: 1.9099694\ttotal: 5.67s\tremaining: 9.2s\n",
      "381:\tlearn: 1.9098985\ttotal: 5.68s\tremaining: 9.19s\n",
      "382:\tlearn: 1.9093115\ttotal: 5.69s\tremaining: 9.17s\n",
      "383:\tlearn: 1.9090216\ttotal: 5.71s\tremaining: 9.16s\n",
      "384:\tlearn: 1.9088247\ttotal: 5.72s\tremaining: 9.14s\n",
      "385:\tlearn: 1.9087433\ttotal: 5.74s\tremaining: 9.13s\n",
      "386:\tlearn: 1.9081894\ttotal: 5.75s\tremaining: 9.11s\n",
      "387:\tlearn: 1.9080855\ttotal: 5.77s\tremaining: 9.1s\n",
      "388:\tlearn: 1.9080086\ttotal: 5.78s\tremaining: 9.09s\n",
      "389:\tlearn: 1.9074836\ttotal: 5.8s\tremaining: 9.07s\n",
      "390:\tlearn: 1.9074037\ttotal: 5.81s\tremaining: 9.05s\n",
      "391:\tlearn: 1.9073170\ttotal: 5.83s\tremaining: 9.04s\n",
      "392:\tlearn: 1.9070765\ttotal: 5.84s\tremaining: 9.02s\n",
      "393:\tlearn: 1.9068273\ttotal: 5.86s\tremaining: 9.01s\n",
      "394:\tlearn: 1.9067389\ttotal: 5.87s\tremaining: 8.99s\n",
      "395:\tlearn: 1.9066744\ttotal: 5.88s\tremaining: 8.97s\n",
      "396:\tlearn: 1.9066313\ttotal: 5.9s\tremaining: 8.96s\n",
      "397:\tlearn: 1.9063382\ttotal: 5.91s\tremaining: 8.95s\n",
      "398:\tlearn: 1.9063025\ttotal: 5.93s\tremaining: 8.93s\n",
      "399:\tlearn: 1.9057087\ttotal: 5.94s\tremaining: 8.92s\n",
      "400:\tlearn: 1.9057032\ttotal: 5.96s\tremaining: 8.9s\n",
      "401:\tlearn: 1.9052706\ttotal: 5.97s\tremaining: 8.89s\n",
      "402:\tlearn: 1.9047944\ttotal: 5.99s\tremaining: 8.87s\n",
      "403:\tlearn: 1.9040911\ttotal: 6s\tremaining: 8.86s\n",
      "404:\tlearn: 1.9033589\ttotal: 6.02s\tremaining: 8.84s\n",
      "405:\tlearn: 1.9028327\ttotal: 6.03s\tremaining: 8.83s\n",
      "406:\tlearn: 1.9026106\ttotal: 6.05s\tremaining: 8.81s\n",
      "407:\tlearn: 1.9024230\ttotal: 6.06s\tremaining: 8.8s\n",
      "408:\tlearn: 1.9020985\ttotal: 6.08s\tremaining: 8.78s\n",
      "409:\tlearn: 1.9020844\ttotal: 6.09s\tremaining: 8.77s\n",
      "410:\tlearn: 1.9020843\ttotal: 6.11s\tremaining: 8.75s\n",
      "411:\tlearn: 1.9015452\ttotal: 6.12s\tremaining: 8.73s\n",
      "412:\tlearn: 1.9009006\ttotal: 6.13s\tremaining: 8.72s\n",
      "413:\tlearn: 1.9008356\ttotal: 6.15s\tremaining: 8.7s\n",
      "414:\tlearn: 1.9008225\ttotal: 6.16s\tremaining: 8.69s\n",
      "415:\tlearn: 1.9007065\ttotal: 6.18s\tremaining: 8.67s\n",
      "416:\tlearn: 1.9007008\ttotal: 6.19s\tremaining: 8.66s\n",
      "417:\tlearn: 1.9006920\ttotal: 6.21s\tremaining: 8.64s\n",
      "418:\tlearn: 1.9006470\ttotal: 6.22s\tremaining: 8.63s\n",
      "419:\tlearn: 1.9000929\ttotal: 6.24s\tremaining: 8.61s\n",
      "420:\tlearn: 1.9000811\ttotal: 6.25s\tremaining: 8.6s\n",
      "421:\tlearn: 1.9000723\ttotal: 6.26s\tremaining: 8.58s\n",
      "422:\tlearn: 1.9000691\ttotal: 6.28s\tremaining: 8.57s\n",
      "423:\tlearn: 1.9000365\ttotal: 6.29s\tremaining: 8.55s\n",
      "424:\tlearn: 1.8999912\ttotal: 6.31s\tremaining: 8.54s\n",
      "425:\tlearn: 1.8996341\ttotal: 6.32s\tremaining: 8.52s\n",
      "426:\tlearn: 1.8994754\ttotal: 6.34s\tremaining: 8.5s\n",
      "427:\tlearn: 1.8992874\ttotal: 6.35s\tremaining: 8.49s\n",
      "428:\tlearn: 1.8992512\ttotal: 6.37s\tremaining: 8.47s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429:\tlearn: 1.8992502\ttotal: 6.38s\tremaining: 8.46s\n",
      "430:\tlearn: 1.8991371\ttotal: 6.4s\tremaining: 8.45s\n",
      "431:\tlearn: 1.8991266\ttotal: 6.41s\tremaining: 8.43s\n",
      "432:\tlearn: 1.8982703\ttotal: 6.43s\tremaining: 8.41s\n",
      "433:\tlearn: 1.8980751\ttotal: 6.44s\tremaining: 8.4s\n",
      "434:\tlearn: 1.8980742\ttotal: 6.46s\tremaining: 8.39s\n",
      "435:\tlearn: 1.8980742\ttotal: 6.47s\tremaining: 8.37s\n",
      "436:\tlearn: 1.8980546\ttotal: 6.49s\tremaining: 8.36s\n",
      "437:\tlearn: 1.8980400\ttotal: 6.5s\tremaining: 8.34s\n",
      "438:\tlearn: 1.8978102\ttotal: 6.51s\tremaining: 8.32s\n",
      "439:\tlearn: 1.8978008\ttotal: 6.53s\tremaining: 8.31s\n",
      "440:\tlearn: 1.8977662\ttotal: 6.54s\tremaining: 8.29s\n",
      "441:\tlearn: 1.8974479\ttotal: 6.56s\tremaining: 8.28s\n",
      "442:\tlearn: 1.8971609\ttotal: 6.57s\tremaining: 8.26s\n",
      "443:\tlearn: 1.8967988\ttotal: 6.58s\tremaining: 8.25s\n",
      "444:\tlearn: 1.8966781\ttotal: 6.6s\tremaining: 8.23s\n",
      "445:\tlearn: 1.8965240\ttotal: 6.62s\tremaining: 8.22s\n",
      "446:\tlearn: 1.8963247\ttotal: 6.63s\tremaining: 8.21s\n",
      "447:\tlearn: 1.8963247\ttotal: 6.65s\tremaining: 8.19s\n",
      "448:\tlearn: 1.8963247\ttotal: 6.66s\tremaining: 8.17s\n",
      "449:\tlearn: 1.8963176\ttotal: 6.67s\tremaining: 8.16s\n",
      "450:\tlearn: 1.8962572\ttotal: 6.69s\tremaining: 8.14s\n",
      "451:\tlearn: 1.8962560\ttotal: 6.7s\tremaining: 8.13s\n",
      "452:\tlearn: 1.8962550\ttotal: 6.71s\tremaining: 8.11s\n",
      "453:\tlearn: 1.8962485\ttotal: 6.73s\tremaining: 8.09s\n",
      "454:\tlearn: 1.8948011\ttotal: 6.74s\tremaining: 8.08s\n",
      "455:\tlearn: 1.8947359\ttotal: 6.76s\tremaining: 8.06s\n",
      "456:\tlearn: 1.8940133\ttotal: 6.77s\tremaining: 8.04s\n",
      "457:\tlearn: 1.8940006\ttotal: 6.78s\tremaining: 8.03s\n",
      "458:\tlearn: 1.8938153\ttotal: 6.8s\tremaining: 8.01s\n",
      "459:\tlearn: 1.8938057\ttotal: 6.81s\tremaining: 8s\n",
      "460:\tlearn: 1.8937293\ttotal: 6.83s\tremaining: 7.98s\n",
      "461:\tlearn: 1.8934980\ttotal: 6.84s\tremaining: 7.96s\n",
      "462:\tlearn: 1.8932476\ttotal: 6.85s\tremaining: 7.95s\n",
      "463:\tlearn: 1.8932352\ttotal: 6.87s\tremaining: 7.93s\n",
      "464:\tlearn: 1.8927360\ttotal: 6.88s\tremaining: 7.92s\n",
      "465:\tlearn: 1.8923963\ttotal: 6.9s\tremaining: 7.9s\n",
      "466:\tlearn: 1.8921766\ttotal: 6.91s\tremaining: 7.89s\n",
      "467:\tlearn: 1.8918958\ttotal: 6.92s\tremaining: 7.87s\n",
      "468:\tlearn: 1.8915571\ttotal: 6.94s\tremaining: 7.86s\n",
      "469:\tlearn: 1.8899703\ttotal: 6.95s\tremaining: 7.84s\n",
      "470:\tlearn: 1.8899532\ttotal: 6.97s\tremaining: 7.82s\n",
      "471:\tlearn: 1.8899524\ttotal: 6.98s\tremaining: 7.81s\n",
      "472:\tlearn: 1.8899258\ttotal: 6.99s\tremaining: 7.79s\n",
      "473:\tlearn: 1.8895929\ttotal: 7.01s\tremaining: 7.78s\n",
      "474:\tlearn: 1.8895817\ttotal: 7.02s\tremaining: 7.76s\n",
      "475:\tlearn: 1.8895059\ttotal: 7.04s\tremaining: 7.75s\n",
      "476:\tlearn: 1.8894949\ttotal: 7.05s\tremaining: 7.73s\n",
      "477:\tlearn: 1.8894825\ttotal: 7.07s\tremaining: 7.72s\n",
      "478:\tlearn: 1.8880903\ttotal: 7.08s\tremaining: 7.7s\n",
      "479:\tlearn: 1.8880888\ttotal: 7.09s\tremaining: 7.69s\n",
      "480:\tlearn: 1.8880884\ttotal: 7.11s\tremaining: 7.67s\n",
      "481:\tlearn: 1.8880884\ttotal: 7.12s\tremaining: 7.66s\n",
      "482:\tlearn: 1.8880539\ttotal: 7.14s\tremaining: 7.64s\n",
      "483:\tlearn: 1.8880538\ttotal: 7.15s\tremaining: 7.62s\n",
      "484:\tlearn: 1.8880533\ttotal: 7.17s\tremaining: 7.61s\n",
      "485:\tlearn: 1.8880533\ttotal: 7.18s\tremaining: 7.59s\n",
      "486:\tlearn: 1.8880533\ttotal: 7.19s\tremaining: 7.58s\n",
      "487:\tlearn: 1.8875367\ttotal: 7.21s\tremaining: 7.56s\n",
      "488:\tlearn: 1.8874995\ttotal: 7.22s\tremaining: 7.55s\n",
      "489:\tlearn: 1.8867278\ttotal: 7.24s\tremaining: 7.53s\n",
      "490:\tlearn: 1.8861812\ttotal: 7.25s\tremaining: 7.52s\n",
      "491:\tlearn: 1.8852356\ttotal: 7.27s\tremaining: 7.5s\n",
      "492:\tlearn: 1.8850084\ttotal: 7.28s\tremaining: 7.49s\n",
      "493:\tlearn: 1.8846975\ttotal: 7.29s\tremaining: 7.47s\n",
      "494:\tlearn: 1.8842947\ttotal: 7.31s\tremaining: 7.46s\n",
      "495:\tlearn: 1.8842011\ttotal: 7.33s\tremaining: 7.44s\n",
      "496:\tlearn: 1.8840452\ttotal: 7.34s\tremaining: 7.43s\n",
      "497:\tlearn: 1.8837506\ttotal: 7.35s\tremaining: 7.41s\n",
      "498:\tlearn: 1.8837506\ttotal: 7.37s\tremaining: 7.4s\n",
      "499:\tlearn: 1.8837446\ttotal: 7.38s\tremaining: 7.38s\n",
      "500:\tlearn: 1.8837406\ttotal: 7.4s\tremaining: 7.37s\n",
      "501:\tlearn: 1.8837391\ttotal: 7.41s\tremaining: 7.35s\n",
      "502:\tlearn: 1.8836668\ttotal: 7.43s\tremaining: 7.34s\n",
      "503:\tlearn: 1.8832978\ttotal: 7.45s\tremaining: 7.33s\n",
      "504:\tlearn: 1.8832971\ttotal: 7.46s\tremaining: 7.31s\n",
      "505:\tlearn: 1.8832971\ttotal: 7.47s\tremaining: 7.3s\n",
      "506:\tlearn: 1.8832970\ttotal: 7.49s\tremaining: 7.28s\n",
      "507:\tlearn: 1.8832968\ttotal: 7.5s\tremaining: 7.27s\n",
      "508:\tlearn: 1.8832968\ttotal: 7.52s\tremaining: 7.25s\n",
      "509:\tlearn: 1.8832951\ttotal: 7.53s\tremaining: 7.24s\n",
      "510:\tlearn: 1.8832950\ttotal: 7.55s\tremaining: 7.22s\n",
      "511:\tlearn: 1.8832950\ttotal: 7.56s\tremaining: 7.21s\n",
      "512:\tlearn: 1.8832946\ttotal: 7.58s\tremaining: 7.19s\n",
      "513:\tlearn: 1.8819735\ttotal: 7.59s\tremaining: 7.18s\n",
      "514:\tlearn: 1.8819732\ttotal: 7.61s\tremaining: 7.16s\n",
      "515:\tlearn: 1.8819607\ttotal: 7.62s\tremaining: 7.15s\n",
      "516:\tlearn: 1.8819578\ttotal: 7.63s\tremaining: 7.13s\n",
      "517:\tlearn: 1.8819492\ttotal: 7.65s\tremaining: 7.12s\n",
      "518:\tlearn: 1.8813581\ttotal: 7.66s\tremaining: 7.1s\n",
      "519:\tlearn: 1.8812663\ttotal: 7.68s\tremaining: 7.09s\n",
      "520:\tlearn: 1.8812662\ttotal: 7.69s\tremaining: 7.07s\n",
      "521:\tlearn: 1.8812328\ttotal: 7.71s\tremaining: 7.06s\n",
      "522:\tlearn: 1.8811524\ttotal: 7.72s\tremaining: 7.04s\n",
      "523:\tlearn: 1.8811294\ttotal: 7.73s\tremaining: 7.03s\n",
      "524:\tlearn: 1.8811234\ttotal: 7.75s\tremaining: 7.01s\n",
      "525:\tlearn: 1.8809222\ttotal: 7.76s\tremaining: 7s\n",
      "526:\tlearn: 1.8809181\ttotal: 7.78s\tremaining: 6.98s\n",
      "527:\tlearn: 1.8809149\ttotal: 7.79s\tremaining: 6.96s\n",
      "528:\tlearn: 1.8809042\ttotal: 7.8s\tremaining: 6.95s\n",
      "529:\tlearn: 1.8809012\ttotal: 7.82s\tremaining: 6.93s\n",
      "530:\tlearn: 1.8802271\ttotal: 7.83s\tremaining: 6.92s\n",
      "531:\tlearn: 1.8799640\ttotal: 7.85s\tremaining: 6.9s\n",
      "532:\tlearn: 1.8798562\ttotal: 7.86s\tremaining: 6.89s\n",
      "533:\tlearn: 1.8789972\ttotal: 7.87s\tremaining: 6.87s\n",
      "534:\tlearn: 1.8789780\ttotal: 7.89s\tremaining: 6.86s\n",
      "535:\tlearn: 1.8789732\ttotal: 7.91s\tremaining: 6.84s\n",
      "536:\tlearn: 1.8789702\ttotal: 7.92s\tremaining: 6.83s\n",
      "537:\tlearn: 1.8789275\ttotal: 7.93s\tremaining: 6.81s\n",
      "538:\tlearn: 1.8789175\ttotal: 7.95s\tremaining: 6.8s\n",
      "539:\tlearn: 1.8789112\ttotal: 7.96s\tremaining: 6.78s\n",
      "540:\tlearn: 1.8789096\ttotal: 7.98s\tremaining: 6.77s\n",
      "541:\tlearn: 1.8789093\ttotal: 7.99s\tremaining: 6.75s\n",
      "542:\tlearn: 1.8789025\ttotal: 8.01s\tremaining: 6.74s\n",
      "543:\tlearn: 1.8788688\ttotal: 8.02s\tremaining: 6.72s\n",
      "544:\tlearn: 1.8788684\ttotal: 8.03s\tremaining: 6.71s\n",
      "545:\tlearn: 1.8788682\ttotal: 8.05s\tremaining: 6.69s\n",
      "546:\tlearn: 1.8788682\ttotal: 8.06s\tremaining: 6.68s\n",
      "547:\tlearn: 1.8788674\ttotal: 8.07s\tremaining: 6.66s\n",
      "548:\tlearn: 1.8788670\ttotal: 8.09s\tremaining: 6.64s\n",
      "549:\tlearn: 1.8788668\ttotal: 8.11s\tremaining: 6.63s\n",
      "550:\tlearn: 1.8788667\ttotal: 8.12s\tremaining: 6.62s\n",
      "551:\tlearn: 1.8788654\ttotal: 8.13s\tremaining: 6.6s\n",
      "552:\tlearn: 1.8788652\ttotal: 8.15s\tremaining: 6.59s\n",
      "553:\tlearn: 1.8788646\ttotal: 8.16s\tremaining: 6.57s\n",
      "554:\tlearn: 1.8788643\ttotal: 8.18s\tremaining: 6.56s\n",
      "555:\tlearn: 1.8788643\ttotal: 8.19s\tremaining: 6.54s\n",
      "556:\tlearn: 1.8788524\ttotal: 8.21s\tremaining: 6.53s\n",
      "557:\tlearn: 1.8788289\ttotal: 8.22s\tremaining: 6.51s\n",
      "558:\tlearn: 1.8788254\ttotal: 8.23s\tremaining: 6.5s\n",
      "559:\tlearn: 1.8779120\ttotal: 8.25s\tremaining: 6.48s\n",
      "560:\tlearn: 1.8777609\ttotal: 8.26s\tremaining: 6.46s\n",
      "561:\tlearn: 1.8777540\ttotal: 8.28s\tremaining: 6.45s\n",
      "562:\tlearn: 1.8777301\ttotal: 8.29s\tremaining: 6.43s\n",
      "563:\tlearn: 1.8777285\ttotal: 8.3s\tremaining: 6.42s\n",
      "564:\tlearn: 1.8777143\ttotal: 8.32s\tremaining: 6.41s\n",
      "565:\tlearn: 1.8773861\ttotal: 8.33s\tremaining: 6.39s\n",
      "566:\tlearn: 1.8769436\ttotal: 8.35s\tremaining: 6.38s\n",
      "567:\tlearn: 1.8758169\ttotal: 8.36s\tremaining: 6.36s\n",
      "568:\tlearn: 1.8754516\ttotal: 8.38s\tremaining: 6.34s\n",
      "569:\tlearn: 1.8741639\ttotal: 8.39s\tremaining: 6.33s\n",
      "570:\tlearn: 1.8738286\ttotal: 8.4s\tremaining: 6.32s\n",
      "571:\tlearn: 1.8732457\ttotal: 8.42s\tremaining: 6.3s\n",
      "572:\tlearn: 1.8731652\ttotal: 8.43s\tremaining: 6.28s\n",
      "573:\tlearn: 1.8728711\ttotal: 8.45s\tremaining: 6.27s\n",
      "574:\tlearn: 1.8728261\ttotal: 8.46s\tremaining: 6.25s\n",
      "575:\tlearn: 1.8726782\ttotal: 8.48s\tremaining: 6.24s\n",
      "576:\tlearn: 1.8726566\ttotal: 8.49s\tremaining: 6.22s\n",
      "577:\tlearn: 1.8726461\ttotal: 8.51s\tremaining: 6.21s\n",
      "578:\tlearn: 1.8726279\ttotal: 8.52s\tremaining: 6.2s\n",
      "579:\tlearn: 1.8724835\ttotal: 8.54s\tremaining: 6.18s\n",
      "580:\tlearn: 1.8724790\ttotal: 8.55s\tremaining: 6.17s\n",
      "581:\tlearn: 1.8721857\ttotal: 8.56s\tremaining: 6.15s\n",
      "582:\tlearn: 1.8717622\ttotal: 8.58s\tremaining: 6.13s\n",
      "583:\tlearn: 1.8715119\ttotal: 8.59s\tremaining: 6.12s\n",
      "584:\tlearn: 1.8711951\ttotal: 8.61s\tremaining: 6.11s\n",
      "585:\tlearn: 1.8708007\ttotal: 8.62s\tremaining: 6.09s\n",
      "586:\tlearn: 1.8708007\ttotal: 8.64s\tremaining: 6.08s\n",
      "587:\tlearn: 1.8707782\ttotal: 8.65s\tremaining: 6.06s\n",
      "588:\tlearn: 1.8703411\ttotal: 8.66s\tremaining: 6.05s\n",
      "589:\tlearn: 1.8703116\ttotal: 8.68s\tremaining: 6.03s\n",
      "590:\tlearn: 1.8703084\ttotal: 8.69s\tremaining: 6.02s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591:\tlearn: 1.8702964\ttotal: 8.71s\tremaining: 6s\n",
      "592:\tlearn: 1.8702919\ttotal: 8.72s\tremaining: 5.99s\n",
      "593:\tlearn: 1.8701118\ttotal: 8.74s\tremaining: 5.97s\n",
      "594:\tlearn: 1.8693464\ttotal: 8.76s\tremaining: 5.96s\n",
      "595:\tlearn: 1.8686662\ttotal: 8.77s\tremaining: 5.94s\n",
      "596:\tlearn: 1.8683865\ttotal: 8.78s\tremaining: 5.93s\n",
      "597:\tlearn: 1.8683689\ttotal: 8.8s\tremaining: 5.91s\n",
      "598:\tlearn: 1.8683181\ttotal: 8.81s\tremaining: 5.9s\n",
      "599:\tlearn: 1.8683119\ttotal: 8.82s\tremaining: 5.88s\n",
      "600:\tlearn: 1.8672872\ttotal: 8.84s\tremaining: 5.87s\n",
      "601:\tlearn: 1.8670129\ttotal: 8.85s\tremaining: 5.85s\n",
      "602:\tlearn: 1.8669899\ttotal: 8.87s\tremaining: 5.84s\n",
      "603:\tlearn: 1.8669877\ttotal: 8.88s\tremaining: 5.82s\n",
      "604:\tlearn: 1.8669877\ttotal: 8.9s\tremaining: 5.81s\n",
      "605:\tlearn: 1.8669877\ttotal: 8.91s\tremaining: 5.79s\n",
      "606:\tlearn: 1.8669841\ttotal: 8.93s\tremaining: 5.78s\n",
      "607:\tlearn: 1.8669020\ttotal: 8.94s\tremaining: 5.76s\n",
      "608:\tlearn: 1.8664443\ttotal: 8.96s\tremaining: 5.75s\n",
      "609:\tlearn: 1.8659604\ttotal: 8.97s\tremaining: 5.74s\n",
      "610:\tlearn: 1.8656119\ttotal: 8.98s\tremaining: 5.72s\n",
      "611:\tlearn: 1.8648010\ttotal: 9s\tremaining: 5.71s\n",
      "612:\tlearn: 1.8646028\ttotal: 9.01s\tremaining: 5.69s\n",
      "613:\tlearn: 1.8646016\ttotal: 9.03s\tremaining: 5.67s\n",
      "614:\tlearn: 1.8641004\ttotal: 9.04s\tremaining: 5.66s\n",
      "615:\tlearn: 1.8632583\ttotal: 9.05s\tremaining: 5.64s\n",
      "616:\tlearn: 1.8631671\ttotal: 9.07s\tremaining: 5.63s\n",
      "617:\tlearn: 1.8631671\ttotal: 9.08s\tremaining: 5.61s\n",
      "618:\tlearn: 1.8631670\ttotal: 9.1s\tremaining: 5.6s\n",
      "619:\tlearn: 1.8631645\ttotal: 9.11s\tremaining: 5.58s\n",
      "620:\tlearn: 1.8631613\ttotal: 9.13s\tremaining: 5.57s\n",
      "621:\tlearn: 1.8631588\ttotal: 9.14s\tremaining: 5.56s\n",
      "622:\tlearn: 1.8631277\ttotal: 9.16s\tremaining: 5.54s\n",
      "623:\tlearn: 1.8630963\ttotal: 9.17s\tremaining: 5.53s\n",
      "624:\tlearn: 1.8630689\ttotal: 9.19s\tremaining: 5.51s\n",
      "625:\tlearn: 1.8630632\ttotal: 9.2s\tremaining: 5.5s\n",
      "626:\tlearn: 1.8630631\ttotal: 9.21s\tremaining: 5.48s\n",
      "627:\tlearn: 1.8630623\ttotal: 9.23s\tremaining: 5.47s\n",
      "628:\tlearn: 1.8630623\ttotal: 9.24s\tremaining: 5.45s\n",
      "629:\tlearn: 1.8630605\ttotal: 9.26s\tremaining: 5.43s\n",
      "630:\tlearn: 1.8630605\ttotal: 9.27s\tremaining: 5.42s\n",
      "631:\tlearn: 1.8630605\ttotal: 9.28s\tremaining: 5.41s\n",
      "632:\tlearn: 1.8630605\ttotal: 9.3s\tremaining: 5.39s\n",
      "633:\tlearn: 1.8630597\ttotal: 9.31s\tremaining: 5.37s\n",
      "634:\tlearn: 1.8630597\ttotal: 9.32s\tremaining: 5.36s\n",
      "635:\tlearn: 1.8630589\ttotal: 9.34s\tremaining: 5.34s\n",
      "636:\tlearn: 1.8630575\ttotal: 9.35s\tremaining: 5.33s\n",
      "637:\tlearn: 1.8630575\ttotal: 9.37s\tremaining: 5.32s\n",
      "638:\tlearn: 1.8630548\ttotal: 9.38s\tremaining: 5.3s\n",
      "639:\tlearn: 1.8630548\ttotal: 9.4s\tremaining: 5.29s\n",
      "640:\tlearn: 1.8627193\ttotal: 9.41s\tremaining: 5.27s\n",
      "641:\tlearn: 1.8625599\ttotal: 9.42s\tremaining: 5.25s\n",
      "642:\tlearn: 1.8622199\ttotal: 9.44s\tremaining: 5.24s\n",
      "643:\tlearn: 1.8621465\ttotal: 9.45s\tremaining: 5.22s\n",
      "644:\tlearn: 1.8621462\ttotal: 9.47s\tremaining: 5.21s\n",
      "645:\tlearn: 1.8617087\ttotal: 9.48s\tremaining: 5.2s\n",
      "646:\tlearn: 1.8610698\ttotal: 9.49s\tremaining: 5.18s\n",
      "647:\tlearn: 1.8609985\ttotal: 9.51s\tremaining: 5.17s\n",
      "648:\tlearn: 1.8609339\ttotal: 9.52s\tremaining: 5.15s\n",
      "649:\tlearn: 1.8608708\ttotal: 9.54s\tremaining: 5.14s\n",
      "650:\tlearn: 1.8606772\ttotal: 9.55s\tremaining: 5.12s\n",
      "651:\tlearn: 1.8605546\ttotal: 9.57s\tremaining: 5.11s\n",
      "652:\tlearn: 1.8605498\ttotal: 9.58s\tremaining: 5.09s\n",
      "653:\tlearn: 1.8596469\ttotal: 9.6s\tremaining: 5.08s\n",
      "654:\tlearn: 1.8591638\ttotal: 9.61s\tremaining: 5.06s\n",
      "655:\tlearn: 1.8583676\ttotal: 9.63s\tremaining: 5.05s\n",
      "656:\tlearn: 1.8579702\ttotal: 9.64s\tremaining: 5.03s\n",
      "657:\tlearn: 1.8579697\ttotal: 9.65s\tremaining: 5.02s\n",
      "658:\tlearn: 1.8579694\ttotal: 9.67s\tremaining: 5s\n",
      "659:\tlearn: 1.8578635\ttotal: 9.68s\tremaining: 4.99s\n",
      "660:\tlearn: 1.8565911\ttotal: 9.7s\tremaining: 4.97s\n",
      "661:\tlearn: 1.8560489\ttotal: 9.71s\tremaining: 4.96s\n",
      "662:\tlearn: 1.8560488\ttotal: 9.73s\tremaining: 4.94s\n",
      "663:\tlearn: 1.8560488\ttotal: 9.74s\tremaining: 4.93s\n",
      "664:\tlearn: 1.8560207\ttotal: 9.75s\tremaining: 4.91s\n",
      "665:\tlearn: 1.8560200\ttotal: 9.77s\tremaining: 4.9s\n",
      "666:\tlearn: 1.8559907\ttotal: 9.78s\tremaining: 4.88s\n",
      "667:\tlearn: 1.8557211\ttotal: 9.8s\tremaining: 4.87s\n",
      "668:\tlearn: 1.8544035\ttotal: 9.81s\tremaining: 4.86s\n",
      "669:\tlearn: 1.8543929\ttotal: 9.83s\tremaining: 4.84s\n",
      "670:\tlearn: 1.8543928\ttotal: 9.84s\tremaining: 4.83s\n",
      "671:\tlearn: 1.8543928\ttotal: 9.86s\tremaining: 4.81s\n",
      "672:\tlearn: 1.8543928\ttotal: 9.87s\tremaining: 4.8s\n",
      "673:\tlearn: 1.8543924\ttotal: 9.89s\tremaining: 4.78s\n",
      "674:\tlearn: 1.8539009\ttotal: 9.9s\tremaining: 4.77s\n",
      "675:\tlearn: 1.8527457\ttotal: 9.91s\tremaining: 4.75s\n",
      "676:\tlearn: 1.8526679\ttotal: 9.93s\tremaining: 4.74s\n",
      "677:\tlearn: 1.8526678\ttotal: 9.94s\tremaining: 4.72s\n",
      "678:\tlearn: 1.8521213\ttotal: 9.96s\tremaining: 4.71s\n",
      "679:\tlearn: 1.8518585\ttotal: 9.97s\tremaining: 4.69s\n",
      "680:\tlearn: 1.8516926\ttotal: 9.99s\tremaining: 4.68s\n",
      "681:\tlearn: 1.8516874\ttotal: 10s\tremaining: 4.66s\n",
      "682:\tlearn: 1.8516871\ttotal: 10s\tremaining: 4.65s\n",
      "683:\tlearn: 1.8516868\ttotal: 10s\tremaining: 4.63s\n",
      "684:\tlearn: 1.8516868\ttotal: 10s\tremaining: 4.62s\n",
      "685:\tlearn: 1.8516868\ttotal: 10.1s\tremaining: 4.6s\n",
      "686:\tlearn: 1.8516868\ttotal: 10.1s\tremaining: 4.59s\n",
      "687:\tlearn: 1.8516868\ttotal: 10.1s\tremaining: 4.57s\n",
      "688:\tlearn: 1.8515722\ttotal: 10.1s\tremaining: 4.56s\n",
      "689:\tlearn: 1.8509618\ttotal: 10.1s\tremaining: 4.54s\n",
      "690:\tlearn: 1.8509611\ttotal: 10.1s\tremaining: 4.53s\n",
      "691:\tlearn: 1.8509611\ttotal: 10.1s\tremaining: 4.51s\n",
      "692:\tlearn: 1.8509611\ttotal: 10.2s\tremaining: 4.5s\n",
      "693:\tlearn: 1.8508994\ttotal: 10.2s\tremaining: 4.48s\n",
      "694:\tlearn: 1.8502485\ttotal: 10.2s\tremaining: 4.47s\n",
      "695:\tlearn: 1.8502460\ttotal: 10.2s\tremaining: 4.46s\n",
      "696:\tlearn: 1.8502460\ttotal: 10.2s\tremaining: 4.44s\n",
      "697:\tlearn: 1.8502460\ttotal: 10.2s\tremaining: 4.42s\n",
      "698:\tlearn: 1.8502460\ttotal: 10.2s\tremaining: 4.41s\n",
      "699:\tlearn: 1.8502460\ttotal: 10.3s\tremaining: 4.4s\n",
      "700:\tlearn: 1.8502345\ttotal: 10.3s\tremaining: 4.38s\n",
      "701:\tlearn: 1.8493174\ttotal: 10.3s\tremaining: 4.37s\n",
      "702:\tlearn: 1.8487231\ttotal: 10.3s\tremaining: 4.35s\n",
      "703:\tlearn: 1.8484878\ttotal: 10.3s\tremaining: 4.34s\n",
      "704:\tlearn: 1.8484874\ttotal: 10.3s\tremaining: 4.32s\n",
      "705:\tlearn: 1.8481827\ttotal: 10.3s\tremaining: 4.31s\n",
      "706:\tlearn: 1.8481823\ttotal: 10.4s\tremaining: 4.29s\n",
      "707:\tlearn: 1.8481823\ttotal: 10.4s\tremaining: 4.28s\n",
      "708:\tlearn: 1.8481823\ttotal: 10.4s\tremaining: 4.26s\n",
      "709:\tlearn: 1.8481823\ttotal: 10.4s\tremaining: 4.25s\n",
      "710:\tlearn: 1.8481802\ttotal: 10.4s\tremaining: 4.23s\n",
      "711:\tlearn: 1.8481720\ttotal: 10.4s\tremaining: 4.22s\n",
      "712:\tlearn: 1.8477527\ttotal: 10.4s\tremaining: 4.2s\n",
      "713:\tlearn: 1.8476958\ttotal: 10.5s\tremaining: 4.19s\n",
      "714:\tlearn: 1.8476384\ttotal: 10.5s\tremaining: 4.17s\n",
      "715:\tlearn: 1.8473438\ttotal: 10.5s\tremaining: 4.16s\n",
      "716:\tlearn: 1.8470873\ttotal: 10.5s\tremaining: 4.14s\n",
      "717:\tlearn: 1.8463838\ttotal: 10.5s\tremaining: 4.13s\n",
      "718:\tlearn: 1.8463265\ttotal: 10.5s\tremaining: 4.12s\n",
      "719:\tlearn: 1.8461056\ttotal: 10.5s\tremaining: 4.1s\n",
      "720:\tlearn: 1.8459594\ttotal: 10.6s\tremaining: 4.08s\n",
      "721:\tlearn: 1.8456096\ttotal: 10.6s\tremaining: 4.07s\n",
      "722:\tlearn: 1.8453675\ttotal: 10.6s\tremaining: 4.06s\n",
      "723:\tlearn: 1.8451009\ttotal: 10.6s\tremaining: 4.04s\n",
      "724:\tlearn: 1.8450893\ttotal: 10.6s\tremaining: 4.03s\n",
      "725:\tlearn: 1.8442261\ttotal: 10.6s\tremaining: 4.01s\n",
      "726:\tlearn: 1.8440266\ttotal: 10.6s\tremaining: 4s\n",
      "727:\tlearn: 1.8440240\ttotal: 10.7s\tremaining: 3.98s\n",
      "728:\tlearn: 1.8440093\ttotal: 10.7s\tremaining: 3.97s\n",
      "729:\tlearn: 1.8439957\ttotal: 10.7s\tremaining: 3.95s\n",
      "730:\tlearn: 1.8437035\ttotal: 10.7s\tremaining: 3.94s\n",
      "731:\tlearn: 1.8434909\ttotal: 10.7s\tremaining: 3.92s\n",
      "732:\tlearn: 1.8433798\ttotal: 10.7s\tremaining: 3.91s\n",
      "733:\tlearn: 1.8433750\ttotal: 10.7s\tremaining: 3.89s\n",
      "734:\tlearn: 1.8433743\ttotal: 10.8s\tremaining: 3.88s\n",
      "735:\tlearn: 1.8429387\ttotal: 10.8s\tremaining: 3.87s\n",
      "736:\tlearn: 1.8429311\ttotal: 10.8s\tremaining: 3.85s\n",
      "737:\tlearn: 1.8420612\ttotal: 10.8s\tremaining: 3.84s\n",
      "738:\tlearn: 1.8420582\ttotal: 10.8s\tremaining: 3.82s\n",
      "739:\tlearn: 1.8417483\ttotal: 10.8s\tremaining: 3.81s\n",
      "740:\tlearn: 1.8417436\ttotal: 10.8s\tremaining: 3.79s\n",
      "741:\tlearn: 1.8417377\ttotal: 10.9s\tremaining: 3.78s\n",
      "742:\tlearn: 1.8417341\ttotal: 10.9s\tremaining: 3.76s\n",
      "743:\tlearn: 1.8417303\ttotal: 10.9s\tremaining: 3.75s\n",
      "744:\tlearn: 1.8417298\ttotal: 10.9s\tremaining: 3.73s\n",
      "745:\tlearn: 1.8417286\ttotal: 10.9s\tremaining: 3.72s\n",
      "746:\tlearn: 1.8417283\ttotal: 10.9s\tremaining: 3.71s\n",
      "747:\tlearn: 1.8417150\ttotal: 11s\tremaining: 3.69s\n",
      "748:\tlearn: 1.8417150\ttotal: 11s\tremaining: 3.68s\n",
      "749:\tlearn: 1.8417148\ttotal: 11s\tremaining: 3.66s\n",
      "750:\tlearn: 1.8417128\ttotal: 11s\tremaining: 3.65s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751:\tlearn: 1.8417126\ttotal: 11s\tremaining: 3.63s\n",
      "752:\tlearn: 1.8417122\ttotal: 11s\tremaining: 3.62s\n",
      "753:\tlearn: 1.8417004\ttotal: 11.1s\tremaining: 3.61s\n",
      "754:\tlearn: 1.8416990\ttotal: 11.1s\tremaining: 3.59s\n",
      "755:\tlearn: 1.8416971\ttotal: 11.1s\tremaining: 3.58s\n",
      "756:\tlearn: 1.8416968\ttotal: 11.1s\tremaining: 3.56s\n",
      "757:\tlearn: 1.8416643\ttotal: 11.1s\tremaining: 3.55s\n",
      "758:\tlearn: 1.8416479\ttotal: 11.1s\tremaining: 3.53s\n",
      "759:\tlearn: 1.8414299\ttotal: 11.1s\tremaining: 3.52s\n",
      "760:\tlearn: 1.8414292\ttotal: 11.2s\tremaining: 3.5s\n",
      "761:\tlearn: 1.8414292\ttotal: 11.2s\tremaining: 3.49s\n",
      "762:\tlearn: 1.8414264\ttotal: 11.2s\tremaining: 3.47s\n",
      "763:\tlearn: 1.8414236\ttotal: 11.2s\tremaining: 3.46s\n",
      "764:\tlearn: 1.8413767\ttotal: 11.2s\tremaining: 3.44s\n",
      "765:\tlearn: 1.8407871\ttotal: 11.2s\tremaining: 3.43s\n",
      "766:\tlearn: 1.8404982\ttotal: 11.2s\tremaining: 3.42s\n",
      "767:\tlearn: 1.8404180\ttotal: 11.3s\tremaining: 3.4s\n",
      "768:\tlearn: 1.8402645\ttotal: 11.3s\tremaining: 3.39s\n",
      "769:\tlearn: 1.8397991\ttotal: 11.3s\tremaining: 3.37s\n",
      "770:\tlearn: 1.8395091\ttotal: 11.3s\tremaining: 3.36s\n",
      "771:\tlearn: 1.8393025\ttotal: 11.3s\tremaining: 3.34s\n",
      "772:\tlearn: 1.8392950\ttotal: 11.3s\tremaining: 3.33s\n",
      "773:\tlearn: 1.8392870\ttotal: 11.3s\tremaining: 3.31s\n",
      "774:\tlearn: 1.8383878\ttotal: 11.4s\tremaining: 3.3s\n",
      "775:\tlearn: 1.8383579\ttotal: 11.4s\tremaining: 3.28s\n",
      "776:\tlearn: 1.8380700\ttotal: 11.4s\tremaining: 3.27s\n",
      "777:\tlearn: 1.8375560\ttotal: 11.4s\tremaining: 3.25s\n",
      "778:\tlearn: 1.8373476\ttotal: 11.4s\tremaining: 3.24s\n",
      "779:\tlearn: 1.8373468\ttotal: 11.4s\tremaining: 3.22s\n",
      "780:\tlearn: 1.8372318\ttotal: 11.4s\tremaining: 3.21s\n",
      "781:\tlearn: 1.8370685\ttotal: 11.5s\tremaining: 3.19s\n",
      "782:\tlearn: 1.8365654\ttotal: 11.5s\tremaining: 3.18s\n",
      "783:\tlearn: 1.8360606\ttotal: 11.5s\tremaining: 3.17s\n",
      "784:\tlearn: 1.8356195\ttotal: 11.5s\tremaining: 3.15s\n",
      "785:\tlearn: 1.8354195\ttotal: 11.5s\tremaining: 3.14s\n",
      "786:\tlearn: 1.8354163\ttotal: 11.5s\tremaining: 3.12s\n",
      "787:\tlearn: 1.8349310\ttotal: 11.5s\tremaining: 3.11s\n",
      "788:\tlearn: 1.8346821\ttotal: 11.6s\tremaining: 3.09s\n",
      "789:\tlearn: 1.8345875\ttotal: 11.6s\tremaining: 3.08s\n",
      "790:\tlearn: 1.8345379\ttotal: 11.6s\tremaining: 3.06s\n",
      "791:\tlearn: 1.8345378\ttotal: 11.6s\tremaining: 3.05s\n",
      "792:\tlearn: 1.8344010\ttotal: 11.6s\tremaining: 3.03s\n",
      "793:\tlearn: 1.8343217\ttotal: 11.6s\tremaining: 3.02s\n",
      "794:\tlearn: 1.8337258\ttotal: 11.6s\tremaining: 3s\n",
      "795:\tlearn: 1.8336526\ttotal: 11.7s\tremaining: 2.99s\n",
      "796:\tlearn: 1.8328546\ttotal: 11.7s\tremaining: 2.97s\n",
      "797:\tlearn: 1.8325521\ttotal: 11.7s\tremaining: 2.96s\n",
      "798:\tlearn: 1.8320225\ttotal: 11.7s\tremaining: 2.94s\n",
      "799:\tlearn: 1.8313607\ttotal: 11.7s\tremaining: 2.93s\n",
      "800:\tlearn: 1.8313606\ttotal: 11.7s\tremaining: 2.91s\n",
      "801:\tlearn: 1.8313537\ttotal: 11.7s\tremaining: 2.9s\n",
      "802:\tlearn: 1.8310992\ttotal: 11.8s\tremaining: 2.88s\n",
      "803:\tlearn: 1.8310981\ttotal: 11.8s\tremaining: 2.87s\n",
      "804:\tlearn: 1.8310640\ttotal: 11.8s\tremaining: 2.85s\n",
      "805:\tlearn: 1.8310201\ttotal: 11.8s\tremaining: 2.84s\n",
      "806:\tlearn: 1.8310200\ttotal: 11.8s\tremaining: 2.83s\n",
      "807:\tlearn: 1.8310200\ttotal: 11.8s\tremaining: 2.81s\n",
      "808:\tlearn: 1.8310197\ttotal: 11.8s\tremaining: 2.79s\n",
      "809:\tlearn: 1.8310175\ttotal: 11.9s\tremaining: 2.78s\n",
      "810:\tlearn: 1.8309455\ttotal: 11.9s\tremaining: 2.77s\n",
      "811:\tlearn: 1.8306037\ttotal: 11.9s\tremaining: 2.75s\n",
      "812:\tlearn: 1.8300666\ttotal: 11.9s\tremaining: 2.74s\n",
      "813:\tlearn: 1.8300532\ttotal: 11.9s\tremaining: 2.72s\n",
      "814:\tlearn: 1.8300098\ttotal: 11.9s\tremaining: 2.71s\n",
      "815:\tlearn: 1.8299462\ttotal: 11.9s\tremaining: 2.69s\n",
      "816:\tlearn: 1.8298852\ttotal: 12s\tremaining: 2.68s\n",
      "817:\tlearn: 1.8298423\ttotal: 12s\tremaining: 2.66s\n",
      "818:\tlearn: 1.8297688\ttotal: 12s\tremaining: 2.65s\n",
      "819:\tlearn: 1.8296833\ttotal: 12s\tremaining: 2.63s\n",
      "820:\tlearn: 1.8296583\ttotal: 12s\tremaining: 2.62s\n",
      "821:\tlearn: 1.8296486\ttotal: 12s\tremaining: 2.6s\n",
      "822:\tlearn: 1.8296485\ttotal: 12s\tremaining: 2.59s\n",
      "823:\tlearn: 1.8296397\ttotal: 12.1s\tremaining: 2.57s\n",
      "824:\tlearn: 1.8296397\ttotal: 12.1s\tremaining: 2.56s\n",
      "825:\tlearn: 1.8296397\ttotal: 12.1s\tremaining: 2.54s\n",
      "826:\tlearn: 1.8296397\ttotal: 12.1s\tremaining: 2.53s\n",
      "827:\tlearn: 1.8292601\ttotal: 12.1s\tremaining: 2.52s\n",
      "828:\tlearn: 1.8292480\ttotal: 12.1s\tremaining: 2.5s\n",
      "829:\tlearn: 1.8292476\ttotal: 12.1s\tremaining: 2.49s\n",
      "830:\tlearn: 1.8290406\ttotal: 12.2s\tremaining: 2.47s\n",
      "831:\tlearn: 1.8289947\ttotal: 12.2s\tremaining: 2.46s\n",
      "832:\tlearn: 1.8288540\ttotal: 12.2s\tremaining: 2.44s\n",
      "833:\tlearn: 1.8287775\ttotal: 12.2s\tremaining: 2.43s\n",
      "834:\tlearn: 1.8287729\ttotal: 12.2s\tremaining: 2.41s\n",
      "835:\tlearn: 1.8287726\ttotal: 12.2s\tremaining: 2.4s\n",
      "836:\tlearn: 1.8287722\ttotal: 12.2s\tremaining: 2.38s\n",
      "837:\tlearn: 1.8287722\ttotal: 12.3s\tremaining: 2.37s\n",
      "838:\tlearn: 1.8287722\ttotal: 12.3s\tremaining: 2.35s\n",
      "839:\tlearn: 1.8287721\ttotal: 12.3s\tremaining: 2.34s\n",
      "840:\tlearn: 1.8287721\ttotal: 12.3s\tremaining: 2.32s\n",
      "841:\tlearn: 1.8287720\ttotal: 12.3s\tremaining: 2.31s\n",
      "842:\tlearn: 1.8287544\ttotal: 12.3s\tremaining: 2.29s\n",
      "843:\tlearn: 1.8287519\ttotal: 12.3s\tremaining: 2.28s\n",
      "844:\tlearn: 1.8287516\ttotal: 12.3s\tremaining: 2.27s\n",
      "845:\tlearn: 1.8287453\ttotal: 12.4s\tremaining: 2.25s\n",
      "846:\tlearn: 1.8287452\ttotal: 12.4s\tremaining: 2.24s\n",
      "847:\tlearn: 1.8287262\ttotal: 12.4s\tremaining: 2.22s\n",
      "848:\tlearn: 1.8283315\ttotal: 12.4s\tremaining: 2.21s\n",
      "849:\tlearn: 1.8282715\ttotal: 12.4s\tremaining: 2.19s\n",
      "850:\tlearn: 1.8282700\ttotal: 12.4s\tremaining: 2.18s\n",
      "851:\tlearn: 1.8282545\ttotal: 12.4s\tremaining: 2.16s\n",
      "852:\tlearn: 1.8281549\ttotal: 12.5s\tremaining: 2.15s\n",
      "853:\tlearn: 1.8274822\ttotal: 12.5s\tremaining: 2.13s\n",
      "854:\tlearn: 1.8274107\ttotal: 12.5s\tremaining: 2.12s\n",
      "855:\tlearn: 1.8271072\ttotal: 12.5s\tremaining: 2.1s\n",
      "856:\tlearn: 1.8270843\ttotal: 12.5s\tremaining: 2.09s\n",
      "857:\tlearn: 1.8270784\ttotal: 12.5s\tremaining: 2.08s\n",
      "858:\tlearn: 1.8270563\ttotal: 12.6s\tremaining: 2.06s\n",
      "859:\tlearn: 1.8270526\ttotal: 12.6s\tremaining: 2.04s\n",
      "860:\tlearn: 1.8270526\ttotal: 12.6s\tremaining: 2.03s\n",
      "861:\tlearn: 1.8270526\ttotal: 12.6s\tremaining: 2.02s\n",
      "862:\tlearn: 1.8270420\ttotal: 12.6s\tremaining: 2s\n",
      "863:\tlearn: 1.8265905\ttotal: 12.6s\tremaining: 1.99s\n",
      "864:\tlearn: 1.8251921\ttotal: 12.6s\tremaining: 1.97s\n",
      "865:\tlearn: 1.8246052\ttotal: 12.7s\tremaining: 1.96s\n",
      "866:\tlearn: 1.8245022\ttotal: 12.7s\tremaining: 1.94s\n",
      "867:\tlearn: 1.8244579\ttotal: 12.7s\tremaining: 1.93s\n",
      "868:\tlearn: 1.8243656\ttotal: 12.7s\tremaining: 1.91s\n",
      "869:\tlearn: 1.8240823\ttotal: 12.7s\tremaining: 1.9s\n",
      "870:\tlearn: 1.8240783\ttotal: 12.7s\tremaining: 1.88s\n",
      "871:\tlearn: 1.8240563\ttotal: 12.7s\tremaining: 1.87s\n",
      "872:\tlearn: 1.8234171\ttotal: 12.8s\tremaining: 1.85s\n",
      "873:\tlearn: 1.8233897\ttotal: 12.8s\tremaining: 1.84s\n",
      "874:\tlearn: 1.8233897\ttotal: 12.8s\tremaining: 1.83s\n",
      "875:\tlearn: 1.8233896\ttotal: 12.8s\tremaining: 1.81s\n",
      "876:\tlearn: 1.8233893\ttotal: 12.8s\tremaining: 1.8s\n",
      "877:\tlearn: 1.8233893\ttotal: 12.8s\tremaining: 1.78s\n",
      "878:\tlearn: 1.8233615\ttotal: 12.8s\tremaining: 1.77s\n",
      "879:\tlearn: 1.8233615\ttotal: 12.9s\tremaining: 1.75s\n",
      "880:\tlearn: 1.8233614\ttotal: 12.9s\tremaining: 1.74s\n",
      "881:\tlearn: 1.8230306\ttotal: 12.9s\tremaining: 1.72s\n",
      "882:\tlearn: 1.8230297\ttotal: 12.9s\tremaining: 1.71s\n",
      "883:\tlearn: 1.8230296\ttotal: 12.9s\tremaining: 1.69s\n",
      "884:\tlearn: 1.8230285\ttotal: 12.9s\tremaining: 1.68s\n",
      "885:\tlearn: 1.8230167\ttotal: 12.9s\tremaining: 1.66s\n",
      "886:\tlearn: 1.8230128\ttotal: 12.9s\tremaining: 1.65s\n",
      "887:\tlearn: 1.8230126\ttotal: 13s\tremaining: 1.64s\n",
      "888:\tlearn: 1.8224882\ttotal: 13s\tremaining: 1.62s\n",
      "889:\tlearn: 1.8224711\ttotal: 13s\tremaining: 1.6s\n",
      "890:\tlearn: 1.8219128\ttotal: 13s\tremaining: 1.59s\n",
      "891:\tlearn: 1.8211014\ttotal: 13s\tremaining: 1.58s\n",
      "892:\tlearn: 1.8209656\ttotal: 13s\tremaining: 1.56s\n",
      "893:\tlearn: 1.8209618\ttotal: 13.1s\tremaining: 1.55s\n",
      "894:\tlearn: 1.8209616\ttotal: 13.1s\tremaining: 1.53s\n",
      "895:\tlearn: 1.8209374\ttotal: 13.1s\tremaining: 1.52s\n",
      "896:\tlearn: 1.8200515\ttotal: 13.1s\tremaining: 1.5s\n",
      "897:\tlearn: 1.8200122\ttotal: 13.1s\tremaining: 1.49s\n",
      "898:\tlearn: 1.8196193\ttotal: 13.1s\tremaining: 1.47s\n",
      "899:\tlearn: 1.8191309\ttotal: 13.1s\tremaining: 1.46s\n",
      "900:\tlearn: 1.8190990\ttotal: 13.1s\tremaining: 1.44s\n",
      "901:\tlearn: 1.8190871\ttotal: 13.2s\tremaining: 1.43s\n",
      "902:\tlearn: 1.8189510\ttotal: 13.2s\tremaining: 1.42s\n",
      "903:\tlearn: 1.8189295\ttotal: 13.2s\tremaining: 1.4s\n",
      "904:\tlearn: 1.8188693\ttotal: 13.2s\tremaining: 1.39s\n",
      "905:\tlearn: 1.8177426\ttotal: 13.2s\tremaining: 1.37s\n",
      "906:\tlearn: 1.8168981\ttotal: 13.2s\tremaining: 1.36s\n",
      "907:\tlearn: 1.8164470\ttotal: 13.2s\tremaining: 1.34s\n",
      "908:\tlearn: 1.8156587\ttotal: 13.3s\tremaining: 1.33s\n",
      "909:\tlearn: 1.8156523\ttotal: 13.3s\tremaining: 1.31s\n",
      "910:\tlearn: 1.8154275\ttotal: 13.3s\tremaining: 1.3s\n",
      "911:\tlearn: 1.8152148\ttotal: 13.3s\tremaining: 1.28s\n",
      "912:\tlearn: 1.8146928\ttotal: 13.3s\tremaining: 1.27s\n",
      "913:\tlearn: 1.8146920\ttotal: 13.3s\tremaining: 1.25s\n",
      "914:\tlearn: 1.8146167\ttotal: 13.3s\tremaining: 1.24s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915:\tlearn: 1.8138917\ttotal: 13.4s\tremaining: 1.23s\n",
      "916:\tlearn: 1.8138354\ttotal: 13.4s\tremaining: 1.21s\n",
      "917:\tlearn: 1.8138119\ttotal: 13.4s\tremaining: 1.2s\n",
      "918:\tlearn: 1.8133213\ttotal: 13.4s\tremaining: 1.18s\n",
      "919:\tlearn: 1.8130985\ttotal: 13.4s\tremaining: 1.17s\n",
      "920:\tlearn: 1.8130965\ttotal: 13.4s\tremaining: 1.15s\n",
      "921:\tlearn: 1.8130929\ttotal: 13.4s\tremaining: 1.14s\n",
      "922:\tlearn: 1.8130185\ttotal: 13.5s\tremaining: 1.12s\n",
      "923:\tlearn: 1.8130080\ttotal: 13.5s\tremaining: 1.11s\n",
      "924:\tlearn: 1.8128869\ttotal: 13.5s\tremaining: 1.09s\n",
      "925:\tlearn: 1.8128220\ttotal: 13.5s\tremaining: 1.08s\n",
      "926:\tlearn: 1.8126470\ttotal: 13.5s\tremaining: 1.06s\n",
      "927:\tlearn: 1.8126169\ttotal: 13.5s\tremaining: 1.05s\n",
      "928:\tlearn: 1.8125362\ttotal: 13.5s\tremaining: 1.03s\n",
      "929:\tlearn: 1.8123833\ttotal: 13.6s\tremaining: 1.02s\n",
      "930:\tlearn: 1.8123822\ttotal: 13.6s\tremaining: 1.01s\n",
      "931:\tlearn: 1.8123820\ttotal: 13.6s\tremaining: 992ms\n",
      "932:\tlearn: 1.8122768\ttotal: 13.6s\tremaining: 977ms\n",
      "933:\tlearn: 1.8122668\ttotal: 13.6s\tremaining: 962ms\n",
      "934:\tlearn: 1.8121951\ttotal: 13.6s\tremaining: 948ms\n",
      "935:\tlearn: 1.8121944\ttotal: 13.6s\tremaining: 933ms\n",
      "936:\tlearn: 1.8121381\ttotal: 13.7s\tremaining: 918ms\n",
      "937:\tlearn: 1.8120496\ttotal: 13.7s\tremaining: 904ms\n",
      "938:\tlearn: 1.8118470\ttotal: 13.7s\tremaining: 889ms\n",
      "939:\tlearn: 1.8113695\ttotal: 13.7s\tremaining: 875ms\n",
      "940:\tlearn: 1.8112479\ttotal: 13.7s\tremaining: 860ms\n",
      "941:\tlearn: 1.8112430\ttotal: 13.7s\tremaining: 845ms\n",
      "942:\tlearn: 1.8112256\ttotal: 13.7s\tremaining: 831ms\n",
      "943:\tlearn: 1.8112091\ttotal: 13.8s\tremaining: 816ms\n",
      "944:\tlearn: 1.8111972\ttotal: 13.8s\tremaining: 801ms\n",
      "945:\tlearn: 1.8102817\ttotal: 13.8s\tremaining: 787ms\n",
      "946:\tlearn: 1.8100811\ttotal: 13.8s\tremaining: 772ms\n",
      "947:\tlearn: 1.8095434\ttotal: 13.8s\tremaining: 758ms\n",
      "948:\tlearn: 1.8094669\ttotal: 13.8s\tremaining: 743ms\n",
      "949:\tlearn: 1.8087611\ttotal: 13.8s\tremaining: 729ms\n",
      "950:\tlearn: 1.8083185\ttotal: 13.9s\tremaining: 714ms\n",
      "951:\tlearn: 1.8083180\ttotal: 13.9s\tremaining: 699ms\n",
      "952:\tlearn: 1.8083080\ttotal: 13.9s\tremaining: 685ms\n",
      "953:\tlearn: 1.8083079\ttotal: 13.9s\tremaining: 670ms\n",
      "954:\tlearn: 1.8083023\ttotal: 13.9s\tremaining: 656ms\n",
      "955:\tlearn: 1.8082965\ttotal: 13.9s\tremaining: 641ms\n",
      "956:\tlearn: 1.8082720\ttotal: 13.9s\tremaining: 626ms\n",
      "957:\tlearn: 1.8082197\ttotal: 14s\tremaining: 612ms\n",
      "958:\tlearn: 1.8081342\ttotal: 14s\tremaining: 597ms\n",
      "959:\tlearn: 1.8081332\ttotal: 14s\tremaining: 582ms\n",
      "960:\tlearn: 1.8080333\ttotal: 14s\tremaining: 568ms\n",
      "961:\tlearn: 1.8080219\ttotal: 14s\tremaining: 553ms\n",
      "962:\tlearn: 1.8080213\ttotal: 14s\tremaining: 539ms\n",
      "963:\tlearn: 1.8080074\ttotal: 14s\tremaining: 524ms\n",
      "964:\tlearn: 1.8080059\ttotal: 14.1s\tremaining: 510ms\n",
      "965:\tlearn: 1.8079920\ttotal: 14.1s\tremaining: 495ms\n",
      "966:\tlearn: 1.8074702\ttotal: 14.1s\tremaining: 481ms\n",
      "967:\tlearn: 1.8067497\ttotal: 14.1s\tremaining: 466ms\n",
      "968:\tlearn: 1.8067468\ttotal: 14.1s\tremaining: 451ms\n",
      "969:\tlearn: 1.8067449\ttotal: 14.1s\tremaining: 437ms\n",
      "970:\tlearn: 1.8067411\ttotal: 14.1s\tremaining: 422ms\n",
      "971:\tlearn: 1.8067402\ttotal: 14.2s\tremaining: 408ms\n",
      "972:\tlearn: 1.8066277\ttotal: 14.2s\tremaining: 393ms\n",
      "973:\tlearn: 1.8064740\ttotal: 14.2s\tremaining: 379ms\n",
      "974:\tlearn: 1.8064686\ttotal: 14.2s\tremaining: 364ms\n",
      "975:\tlearn: 1.8064682\ttotal: 14.2s\tremaining: 349ms\n",
      "976:\tlearn: 1.8064383\ttotal: 14.2s\tremaining: 335ms\n",
      "977:\tlearn: 1.8064383\ttotal: 14.2s\tremaining: 320ms\n",
      "978:\tlearn: 1.8064171\ttotal: 14.3s\tremaining: 306ms\n",
      "979:\tlearn: 1.8064170\ttotal: 14.3s\tremaining: 291ms\n",
      "980:\tlearn: 1.8064139\ttotal: 14.3s\tremaining: 277ms\n",
      "981:\tlearn: 1.8063991\ttotal: 14.3s\tremaining: 262ms\n",
      "982:\tlearn: 1.8055813\ttotal: 14.3s\tremaining: 247ms\n",
      "983:\tlearn: 1.8048597\ttotal: 14.3s\tremaining: 233ms\n",
      "984:\tlearn: 1.8047513\ttotal: 14.3s\tremaining: 218ms\n",
      "985:\tlearn: 1.8045777\ttotal: 14.4s\tremaining: 204ms\n",
      "986:\tlearn: 1.8038675\ttotal: 14.4s\tremaining: 189ms\n",
      "987:\tlearn: 1.8035382\ttotal: 14.4s\tremaining: 175ms\n",
      "988:\tlearn: 1.8028694\ttotal: 14.4s\tremaining: 160ms\n",
      "989:\tlearn: 1.8026760\ttotal: 14.4s\tremaining: 146ms\n",
      "990:\tlearn: 1.8023660\ttotal: 14.4s\tremaining: 131ms\n",
      "991:\tlearn: 1.8022051\ttotal: 14.4s\tremaining: 117ms\n",
      "992:\tlearn: 1.8014745\ttotal: 14.5s\tremaining: 102ms\n",
      "993:\tlearn: 1.8012603\ttotal: 14.5s\tremaining: 87.4ms\n",
      "994:\tlearn: 1.8012601\ttotal: 14.5s\tremaining: 72.8ms\n",
      "995:\tlearn: 1.8012580\ttotal: 14.5s\tremaining: 58.3ms\n",
      "996:\tlearn: 1.8012347\ttotal: 14.5s\tremaining: 43.7ms\n",
      "997:\tlearn: 1.8012102\ttotal: 14.5s\tremaining: 29.1ms\n",
      "998:\tlearn: 1.8009059\ttotal: 14.5s\tremaining: 14.6ms\n",
      "999:\tlearn: 1.8008232\ttotal: 14.6s\tremaining: 0us\n",
      "0:\tlearn: 10.0031048\ttotal: 17.5ms\tremaining: 17.5s\n",
      "1:\tlearn: 9.2579120\ttotal: 34.9ms\tremaining: 17.4s\n",
      "2:\tlearn: 8.5579824\ttotal: 53.4ms\tremaining: 17.8s\n",
      "3:\tlearn: 7.7973883\ttotal: 71.1ms\tremaining: 17.7s\n",
      "4:\tlearn: 7.1465675\ttotal: 88.9ms\tremaining: 17.7s\n",
      "5:\tlearn: 6.6822942\ttotal: 106ms\tremaining: 17.5s\n",
      "6:\tlearn: 6.1654339\ttotal: 123ms\tremaining: 17.4s\n",
      "7:\tlearn: 5.7092116\ttotal: 140ms\tremaining: 17.4s\n",
      "8:\tlearn: 5.2695716\ttotal: 158ms\tremaining: 17.4s\n",
      "9:\tlearn: 4.8902153\ttotal: 174ms\tremaining: 17.3s\n",
      "10:\tlearn: 4.5998959\ttotal: 193ms\tremaining: 17.3s\n",
      "11:\tlearn: 4.3767025\ttotal: 210ms\tremaining: 17.3s\n",
      "12:\tlearn: 4.1100601\ttotal: 226ms\tremaining: 17.2s\n",
      "13:\tlearn: 3.8974456\ttotal: 244ms\tremaining: 17.2s\n",
      "14:\tlearn: 3.6927632\ttotal: 261ms\tremaining: 17.2s\n",
      "15:\tlearn: 3.5671854\ttotal: 279ms\tremaining: 17.2s\n",
      "16:\tlearn: 3.4608092\ttotal: 297ms\tremaining: 17.2s\n",
      "17:\tlearn: 3.3115412\ttotal: 313ms\tremaining: 17.1s\n",
      "18:\tlearn: 3.2276489\ttotal: 330ms\tremaining: 17s\n",
      "19:\tlearn: 3.1025997\ttotal: 347ms\tremaining: 17s\n",
      "20:\tlearn: 3.0455977\ttotal: 364ms\tremaining: 16.9s\n",
      "21:\tlearn: 2.9910043\ttotal: 380ms\tremaining: 16.9s\n",
      "22:\tlearn: 2.9325953\ttotal: 398ms\tremaining: 16.9s\n",
      "23:\tlearn: 2.8847060\ttotal: 414ms\tremaining: 16.8s\n",
      "24:\tlearn: 2.8135043\ttotal: 431ms\tremaining: 16.8s\n",
      "25:\tlearn: 2.7529540\ttotal: 448ms\tremaining: 16.8s\n",
      "26:\tlearn: 2.7265103\ttotal: 466ms\tremaining: 16.8s\n",
      "27:\tlearn: 2.6974741\ttotal: 484ms\tremaining: 16.8s\n",
      "28:\tlearn: 2.6517812\ttotal: 500ms\tremaining: 16.7s\n",
      "29:\tlearn: 2.6038499\ttotal: 517ms\tremaining: 16.7s\n",
      "30:\tlearn: 2.5652697\ttotal: 534ms\tremaining: 16.7s\n",
      "31:\tlearn: 2.5509696\ttotal: 551ms\tremaining: 16.7s\n",
      "32:\tlearn: 2.5251295\ttotal: 567ms\tremaining: 16.6s\n",
      "33:\tlearn: 2.4939697\ttotal: 584ms\tremaining: 16.6s\n",
      "34:\tlearn: 2.4826367\ttotal: 601ms\tremaining: 16.6s\n",
      "35:\tlearn: 2.4663961\ttotal: 618ms\tremaining: 16.5s\n",
      "36:\tlearn: 2.4460968\ttotal: 634ms\tremaining: 16.5s\n",
      "37:\tlearn: 2.4342356\ttotal: 650ms\tremaining: 16.5s\n",
      "38:\tlearn: 2.4123594\ttotal: 669ms\tremaining: 16.5s\n",
      "39:\tlearn: 2.4059848\ttotal: 685ms\tremaining: 16.4s\n",
      "40:\tlearn: 2.3853628\ttotal: 703ms\tremaining: 16.4s\n",
      "41:\tlearn: 2.3786275\ttotal: 719ms\tremaining: 16.4s\n",
      "42:\tlearn: 2.3742441\ttotal: 735ms\tremaining: 16.4s\n",
      "43:\tlearn: 2.3706696\ttotal: 751ms\tremaining: 16.3s\n",
      "44:\tlearn: 2.3681586\ttotal: 767ms\tremaining: 16.3s\n",
      "45:\tlearn: 2.3653708\ttotal: 784ms\tremaining: 16.3s\n",
      "46:\tlearn: 2.3510739\ttotal: 801ms\tremaining: 16.2s\n",
      "47:\tlearn: 2.3490245\ttotal: 817ms\tremaining: 16.2s\n",
      "48:\tlearn: 2.3443773\ttotal: 833ms\tremaining: 16.2s\n",
      "49:\tlearn: 2.3416225\ttotal: 849ms\tremaining: 16.1s\n",
      "50:\tlearn: 2.3402084\ttotal: 866ms\tremaining: 16.1s\n",
      "51:\tlearn: 2.3367238\ttotal: 884ms\tremaining: 16.1s\n",
      "52:\tlearn: 2.3362767\ttotal: 899ms\tremaining: 16.1s\n",
      "53:\tlearn: 2.3347297\ttotal: 915ms\tremaining: 16s\n",
      "54:\tlearn: 2.3293298\ttotal: 931ms\tremaining: 16s\n",
      "55:\tlearn: 2.3125877\ttotal: 948ms\tremaining: 16s\n",
      "56:\tlearn: 2.3092081\ttotal: 964ms\tremaining: 16s\n",
      "57:\tlearn: 2.3079260\ttotal: 981ms\tremaining: 15.9s\n",
      "58:\tlearn: 2.3070280\ttotal: 995ms\tremaining: 15.9s\n",
      "59:\tlearn: 2.3055902\ttotal: 1.01s\tremaining: 15.9s\n",
      "60:\tlearn: 2.3053519\ttotal: 1.03s\tremaining: 15.8s\n",
      "61:\tlearn: 2.3045030\ttotal: 1.04s\tremaining: 15.8s\n",
      "62:\tlearn: 2.2994339\ttotal: 1.06s\tremaining: 15.8s\n",
      "63:\tlearn: 2.2976378\ttotal: 1.08s\tremaining: 15.8s\n",
      "64:\tlearn: 2.2973013\ttotal: 1.09s\tremaining: 15.7s\n",
      "65:\tlearn: 2.2960546\ttotal: 1.11s\tremaining: 15.7s\n",
      "66:\tlearn: 2.2952996\ttotal: 1.13s\tremaining: 15.7s\n",
      "67:\tlearn: 2.2899753\ttotal: 1.14s\tremaining: 15.6s\n",
      "68:\tlearn: 2.2891351\ttotal: 1.16s\tremaining: 15.6s\n",
      "69:\tlearn: 2.2878145\ttotal: 1.17s\tremaining: 15.6s\n",
      "70:\tlearn: 2.2874240\ttotal: 1.19s\tremaining: 15.6s\n",
      "71:\tlearn: 2.2873157\ttotal: 1.2s\tremaining: 15.5s\n",
      "72:\tlearn: 2.2866132\ttotal: 1.22s\tremaining: 15.5s\n",
      "73:\tlearn: 2.2839591\ttotal: 1.24s\tremaining: 15.5s\n",
      "74:\tlearn: 2.2834071\ttotal: 1.25s\tremaining: 15.4s\n",
      "75:\tlearn: 2.2824198\ttotal: 1.27s\tremaining: 15.4s\n",
      "76:\tlearn: 2.2807992\ttotal: 1.28s\tremaining: 15.4s\n",
      "77:\tlearn: 2.2802602\ttotal: 1.3s\tremaining: 15.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78:\tlearn: 2.2796089\ttotal: 1.32s\tremaining: 15.4s\n",
      "79:\tlearn: 2.2794207\ttotal: 1.33s\tremaining: 15.3s\n",
      "80:\tlearn: 2.2709881\ttotal: 1.35s\tremaining: 15.3s\n",
      "81:\tlearn: 2.2700574\ttotal: 1.36s\tremaining: 15.3s\n",
      "82:\tlearn: 2.2695059\ttotal: 1.38s\tremaining: 15.3s\n",
      "83:\tlearn: 2.2691392\ttotal: 1.4s\tremaining: 15.2s\n",
      "84:\tlearn: 2.2655326\ttotal: 1.41s\tremaining: 15.2s\n",
      "85:\tlearn: 2.2651670\ttotal: 1.43s\tremaining: 15.2s\n",
      "86:\tlearn: 2.2648784\ttotal: 1.44s\tremaining: 15.1s\n",
      "87:\tlearn: 2.2637748\ttotal: 1.46s\tremaining: 15.1s\n",
      "88:\tlearn: 2.2627500\ttotal: 1.47s\tremaining: 15.1s\n",
      "89:\tlearn: 2.2611788\ttotal: 1.49s\tremaining: 15.1s\n",
      "90:\tlearn: 2.2610666\ttotal: 1.5s\tremaining: 15s\n",
      "91:\tlearn: 2.2551351\ttotal: 1.52s\tremaining: 15s\n",
      "92:\tlearn: 2.2548086\ttotal: 1.54s\tremaining: 15s\n",
      "93:\tlearn: 2.2547611\ttotal: 1.55s\tremaining: 15s\n",
      "94:\tlearn: 2.2529804\ttotal: 1.57s\tremaining: 14.9s\n",
      "95:\tlearn: 2.2519643\ttotal: 1.58s\tremaining: 14.9s\n",
      "96:\tlearn: 2.2517909\ttotal: 1.6s\tremaining: 14.9s\n",
      "97:\tlearn: 2.2499806\ttotal: 1.61s\tremaining: 14.8s\n",
      "98:\tlearn: 2.2497949\ttotal: 1.63s\tremaining: 14.8s\n",
      "99:\tlearn: 2.2492172\ttotal: 1.64s\tremaining: 14.8s\n",
      "100:\tlearn: 2.2491359\ttotal: 1.65s\tremaining: 14.7s\n",
      "101:\tlearn: 2.2490506\ttotal: 1.67s\tremaining: 14.7s\n",
      "102:\tlearn: 2.2478261\ttotal: 1.68s\tremaining: 14.6s\n",
      "103:\tlearn: 2.2467951\ttotal: 1.7s\tremaining: 14.6s\n",
      "104:\tlearn: 2.2463983\ttotal: 1.71s\tremaining: 14.6s\n",
      "105:\tlearn: 2.2454108\ttotal: 1.73s\tremaining: 14.6s\n",
      "106:\tlearn: 2.2436141\ttotal: 1.74s\tremaining: 14.5s\n",
      "107:\tlearn: 2.2427107\ttotal: 1.76s\tremaining: 14.5s\n",
      "108:\tlearn: 2.2424464\ttotal: 1.77s\tremaining: 14.5s\n",
      "109:\tlearn: 2.2413955\ttotal: 1.79s\tremaining: 14.5s\n",
      "110:\tlearn: 2.2407716\ttotal: 1.8s\tremaining: 14.4s\n",
      "111:\tlearn: 2.2406448\ttotal: 1.82s\tremaining: 14.4s\n",
      "112:\tlearn: 2.2386700\ttotal: 1.83s\tremaining: 14.4s\n",
      "113:\tlearn: 2.2334367\ttotal: 1.84s\tremaining: 14.3s\n",
      "114:\tlearn: 2.2295623\ttotal: 1.86s\tremaining: 14.3s\n",
      "115:\tlearn: 2.2294650\ttotal: 1.88s\tremaining: 14.3s\n",
      "116:\tlearn: 2.2287042\ttotal: 1.89s\tremaining: 14.3s\n",
      "117:\tlearn: 2.2252738\ttotal: 1.9s\tremaining: 14.2s\n",
      "118:\tlearn: 2.2212250\ttotal: 1.92s\tremaining: 14.2s\n",
      "119:\tlearn: 2.2185070\ttotal: 1.93s\tremaining: 14.2s\n",
      "120:\tlearn: 2.2179863\ttotal: 1.95s\tremaining: 14.1s\n",
      "121:\tlearn: 2.2152700\ttotal: 1.96s\tremaining: 14.1s\n",
      "122:\tlearn: 2.2146909\ttotal: 1.98s\tremaining: 14.1s\n",
      "123:\tlearn: 2.2138721\ttotal: 1.99s\tremaining: 14.1s\n",
      "124:\tlearn: 2.2133639\ttotal: 2.01s\tremaining: 14s\n",
      "125:\tlearn: 2.2132498\ttotal: 2.02s\tremaining: 14s\n",
      "126:\tlearn: 2.2106645\ttotal: 2.04s\tremaining: 14s\n",
      "127:\tlearn: 2.2100561\ttotal: 2.05s\tremaining: 14s\n",
      "128:\tlearn: 2.2096831\ttotal: 2.06s\tremaining: 13.9s\n",
      "129:\tlearn: 2.2082605\ttotal: 2.08s\tremaining: 13.9s\n",
      "130:\tlearn: 2.2073188\ttotal: 2.09s\tremaining: 13.9s\n",
      "131:\tlearn: 2.2031188\ttotal: 2.11s\tremaining: 13.9s\n",
      "132:\tlearn: 2.1984407\ttotal: 2.12s\tremaining: 13.8s\n",
      "133:\tlearn: 2.1929272\ttotal: 2.14s\tremaining: 13.8s\n",
      "134:\tlearn: 2.1894852\ttotal: 2.15s\tremaining: 13.8s\n",
      "135:\tlearn: 2.1871495\ttotal: 2.17s\tremaining: 13.8s\n",
      "136:\tlearn: 2.1866185\ttotal: 2.18s\tremaining: 13.8s\n",
      "137:\tlearn: 2.1861257\ttotal: 2.2s\tremaining: 13.7s\n",
      "138:\tlearn: 2.1832371\ttotal: 2.21s\tremaining: 13.7s\n",
      "139:\tlearn: 2.1827582\ttotal: 2.23s\tremaining: 13.7s\n",
      "140:\tlearn: 2.1804017\ttotal: 2.24s\tremaining: 13.7s\n",
      "141:\tlearn: 2.1798179\ttotal: 2.25s\tremaining: 13.6s\n",
      "142:\tlearn: 2.1791606\ttotal: 2.27s\tremaining: 13.6s\n",
      "143:\tlearn: 2.1786897\ttotal: 2.28s\tremaining: 13.6s\n",
      "144:\tlearn: 2.1771216\ttotal: 2.3s\tremaining: 13.6s\n",
      "145:\tlearn: 2.1766458\ttotal: 2.31s\tremaining: 13.5s\n",
      "146:\tlearn: 2.1730486\ttotal: 2.33s\tremaining: 13.5s\n",
      "147:\tlearn: 2.1720036\ttotal: 2.34s\tremaining: 13.5s\n",
      "148:\tlearn: 2.1706125\ttotal: 2.35s\tremaining: 13.5s\n",
      "149:\tlearn: 2.1665456\ttotal: 2.37s\tremaining: 13.4s\n",
      "150:\tlearn: 2.1640280\ttotal: 2.39s\tremaining: 13.4s\n",
      "151:\tlearn: 2.1614209\ttotal: 2.4s\tremaining: 13.4s\n",
      "152:\tlearn: 2.1588057\ttotal: 2.42s\tremaining: 13.4s\n",
      "153:\tlearn: 2.1543540\ttotal: 2.43s\tremaining: 13.4s\n",
      "154:\tlearn: 2.1519770\ttotal: 2.44s\tremaining: 13.3s\n",
      "155:\tlearn: 2.1499534\ttotal: 2.46s\tremaining: 13.3s\n",
      "156:\tlearn: 2.1466910\ttotal: 2.47s\tremaining: 13.3s\n",
      "157:\tlearn: 2.1429309\ttotal: 2.49s\tremaining: 13.3s\n",
      "158:\tlearn: 2.1411978\ttotal: 2.5s\tremaining: 13.2s\n",
      "159:\tlearn: 2.1403012\ttotal: 2.52s\tremaining: 13.2s\n",
      "160:\tlearn: 2.1383890\ttotal: 2.53s\tremaining: 13.2s\n",
      "161:\tlearn: 2.1371412\ttotal: 2.55s\tremaining: 13.2s\n",
      "162:\tlearn: 2.1349387\ttotal: 2.56s\tremaining: 13.2s\n",
      "163:\tlearn: 2.1315089\ttotal: 2.58s\tremaining: 13.1s\n",
      "164:\tlearn: 2.1281642\ttotal: 2.59s\tremaining: 13.1s\n",
      "165:\tlearn: 2.1239776\ttotal: 2.61s\tremaining: 13.1s\n",
      "166:\tlearn: 2.1204323\ttotal: 2.62s\tremaining: 13.1s\n",
      "167:\tlearn: 2.1170089\ttotal: 2.64s\tremaining: 13.1s\n",
      "168:\tlearn: 2.1122890\ttotal: 2.65s\tremaining: 13s\n",
      "169:\tlearn: 2.1104240\ttotal: 2.67s\tremaining: 13s\n",
      "170:\tlearn: 2.1082935\ttotal: 2.68s\tremaining: 13s\n",
      "171:\tlearn: 2.1062743\ttotal: 2.7s\tremaining: 13s\n",
      "172:\tlearn: 2.1044071\ttotal: 2.71s\tremaining: 13s\n",
      "173:\tlearn: 2.1022314\ttotal: 2.73s\tremaining: 13s\n",
      "174:\tlearn: 2.0979042\ttotal: 2.74s\tremaining: 12.9s\n",
      "175:\tlearn: 2.0968087\ttotal: 2.76s\tremaining: 12.9s\n",
      "176:\tlearn: 2.0957238\ttotal: 2.77s\tremaining: 12.9s\n",
      "177:\tlearn: 2.0952297\ttotal: 2.79s\tremaining: 12.9s\n",
      "178:\tlearn: 2.0945908\ttotal: 2.8s\tremaining: 12.9s\n",
      "179:\tlearn: 2.0935040\ttotal: 2.82s\tremaining: 12.9s\n",
      "180:\tlearn: 2.0913661\ttotal: 2.84s\tremaining: 12.8s\n",
      "181:\tlearn: 2.0900289\ttotal: 2.85s\tremaining: 12.8s\n",
      "182:\tlearn: 2.0888955\ttotal: 2.87s\tremaining: 12.8s\n",
      "183:\tlearn: 2.0881790\ttotal: 2.88s\tremaining: 12.8s\n",
      "184:\tlearn: 2.0862909\ttotal: 2.89s\tremaining: 12.7s\n",
      "185:\tlearn: 2.0837377\ttotal: 2.91s\tremaining: 12.7s\n",
      "186:\tlearn: 2.0815106\ttotal: 2.92s\tremaining: 12.7s\n",
      "187:\tlearn: 2.0797962\ttotal: 2.94s\tremaining: 12.7s\n",
      "188:\tlearn: 2.0782097\ttotal: 2.95s\tremaining: 12.7s\n",
      "189:\tlearn: 2.0770009\ttotal: 2.97s\tremaining: 12.6s\n",
      "190:\tlearn: 2.0754481\ttotal: 2.98s\tremaining: 12.6s\n",
      "191:\tlearn: 2.0748472\ttotal: 3s\tremaining: 12.6s\n",
      "192:\tlearn: 2.0727394\ttotal: 3.01s\tremaining: 12.6s\n",
      "193:\tlearn: 2.0718567\ttotal: 3.03s\tremaining: 12.6s\n",
      "194:\tlearn: 2.0705184\ttotal: 3.04s\tremaining: 12.6s\n",
      "195:\tlearn: 2.0703062\ttotal: 3.06s\tremaining: 12.5s\n",
      "196:\tlearn: 2.0690025\ttotal: 3.07s\tremaining: 12.5s\n",
      "197:\tlearn: 2.0687180\ttotal: 3.08s\tremaining: 12.5s\n",
      "198:\tlearn: 2.0676511\ttotal: 3.1s\tremaining: 12.5s\n",
      "199:\tlearn: 2.0655948\ttotal: 3.11s\tremaining: 12.5s\n",
      "200:\tlearn: 2.0629082\ttotal: 3.13s\tremaining: 12.4s\n",
      "201:\tlearn: 2.0604110\ttotal: 3.14s\tremaining: 12.4s\n",
      "202:\tlearn: 2.0578015\ttotal: 3.16s\tremaining: 12.4s\n",
      "203:\tlearn: 2.0549372\ttotal: 3.17s\tremaining: 12.4s\n",
      "204:\tlearn: 2.0531809\ttotal: 3.19s\tremaining: 12.4s\n",
      "205:\tlearn: 2.0513905\ttotal: 3.2s\tremaining: 12.3s\n",
      "206:\tlearn: 2.0505609\ttotal: 3.21s\tremaining: 12.3s\n",
      "207:\tlearn: 2.0497593\ttotal: 3.23s\tremaining: 12.3s\n",
      "208:\tlearn: 2.0486367\ttotal: 3.25s\tremaining: 12.3s\n",
      "209:\tlearn: 2.0470014\ttotal: 3.26s\tremaining: 12.3s\n",
      "210:\tlearn: 2.0452643\ttotal: 3.28s\tremaining: 12.3s\n",
      "211:\tlearn: 2.0436783\ttotal: 3.29s\tremaining: 12.2s\n",
      "212:\tlearn: 2.0425269\ttotal: 3.31s\tremaining: 12.2s\n",
      "213:\tlearn: 2.0419615\ttotal: 3.32s\tremaining: 12.2s\n",
      "214:\tlearn: 2.0415392\ttotal: 3.33s\tremaining: 12.2s\n",
      "215:\tlearn: 2.0412156\ttotal: 3.35s\tremaining: 12.2s\n",
      "216:\tlearn: 2.0398884\ttotal: 3.36s\tremaining: 12.1s\n",
      "217:\tlearn: 2.0390148\ttotal: 3.38s\tremaining: 12.1s\n",
      "218:\tlearn: 2.0385559\ttotal: 3.39s\tremaining: 12.1s\n",
      "219:\tlearn: 2.0375774\ttotal: 3.41s\tremaining: 12.1s\n",
      "220:\tlearn: 2.0364218\ttotal: 3.42s\tremaining: 12.1s\n",
      "221:\tlearn: 2.0351347\ttotal: 3.44s\tremaining: 12s\n",
      "222:\tlearn: 2.0349622\ttotal: 3.45s\tremaining: 12s\n",
      "223:\tlearn: 2.0341101\ttotal: 3.47s\tremaining: 12s\n",
      "224:\tlearn: 2.0334369\ttotal: 3.48s\tremaining: 12s\n",
      "225:\tlearn: 2.0330842\ttotal: 3.5s\tremaining: 12s\n",
      "226:\tlearn: 2.0326596\ttotal: 3.51s\tremaining: 12s\n",
      "227:\tlearn: 2.0319656\ttotal: 3.53s\tremaining: 11.9s\n",
      "228:\tlearn: 2.0314821\ttotal: 3.54s\tremaining: 11.9s\n",
      "229:\tlearn: 2.0306395\ttotal: 3.56s\tremaining: 11.9s\n",
      "230:\tlearn: 2.0298926\ttotal: 3.57s\tremaining: 11.9s\n",
      "231:\tlearn: 2.0278186\ttotal: 3.59s\tremaining: 11.9s\n",
      "232:\tlearn: 2.0259225\ttotal: 3.6s\tremaining: 11.9s\n",
      "233:\tlearn: 2.0248487\ttotal: 3.62s\tremaining: 11.8s\n",
      "234:\tlearn: 2.0240073\ttotal: 3.63s\tremaining: 11.8s\n",
      "235:\tlearn: 2.0214269\ttotal: 3.65s\tremaining: 11.8s\n",
      "236:\tlearn: 2.0191038\ttotal: 3.66s\tremaining: 11.8s\n",
      "237:\tlearn: 2.0171745\ttotal: 3.68s\tremaining: 11.8s\n",
      "238:\tlearn: 2.0149268\ttotal: 3.69s\tremaining: 11.8s\n",
      "239:\tlearn: 2.0139310\ttotal: 3.71s\tremaining: 11.7s\n",
      "240:\tlearn: 2.0127110\ttotal: 3.72s\tremaining: 11.7s\n",
      "241:\tlearn: 2.0114389\ttotal: 3.74s\tremaining: 11.7s\n",
      "242:\tlearn: 2.0110192\ttotal: 3.75s\tremaining: 11.7s\n",
      "243:\tlearn: 2.0104708\ttotal: 3.77s\tremaining: 11.7s\n",
      "244:\tlearn: 2.0100075\ttotal: 3.78s\tremaining: 11.7s\n",
      "245:\tlearn: 2.0094155\ttotal: 3.79s\tremaining: 11.6s\n",
      "246:\tlearn: 2.0092348\ttotal: 3.81s\tremaining: 11.6s\n",
      "247:\tlearn: 2.0090892\ttotal: 3.82s\tremaining: 11.6s\n",
      "248:\tlearn: 2.0088939\ttotal: 3.84s\tremaining: 11.6s\n",
      "249:\tlearn: 2.0084144\ttotal: 3.85s\tremaining: 11.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250:\tlearn: 2.0081099\ttotal: 3.87s\tremaining: 11.5s\n",
      "251:\tlearn: 2.0067067\ttotal: 3.88s\tremaining: 11.5s\n",
      "252:\tlearn: 2.0059706\ttotal: 3.9s\tremaining: 11.5s\n",
      "253:\tlearn: 2.0049933\ttotal: 3.91s\tremaining: 11.5s\n",
      "254:\tlearn: 2.0041927\ttotal: 3.93s\tremaining: 11.5s\n",
      "255:\tlearn: 2.0036071\ttotal: 3.94s\tremaining: 11.5s\n",
      "256:\tlearn: 2.0033045\ttotal: 3.96s\tremaining: 11.4s\n",
      "257:\tlearn: 2.0030127\ttotal: 3.97s\tremaining: 11.4s\n",
      "258:\tlearn: 2.0023393\ttotal: 3.98s\tremaining: 11.4s\n",
      "259:\tlearn: 2.0017260\ttotal: 4s\tremaining: 11.4s\n",
      "260:\tlearn: 2.0014946\ttotal: 4.01s\tremaining: 11.4s\n",
      "261:\tlearn: 2.0012260\ttotal: 4.03s\tremaining: 11.3s\n",
      "262:\tlearn: 1.9996862\ttotal: 4.04s\tremaining: 11.3s\n",
      "263:\tlearn: 1.9996074\ttotal: 4.06s\tremaining: 11.3s\n",
      "264:\tlearn: 1.9990841\ttotal: 4.07s\tremaining: 11.3s\n",
      "265:\tlearn: 1.9980825\ttotal: 4.09s\tremaining: 11.3s\n",
      "266:\tlearn: 1.9976241\ttotal: 4.1s\tremaining: 11.3s\n",
      "267:\tlearn: 1.9973521\ttotal: 4.12s\tremaining: 11.2s\n",
      "268:\tlearn: 1.9971134\ttotal: 4.13s\tremaining: 11.2s\n",
      "269:\tlearn: 1.9966480\ttotal: 4.14s\tremaining: 11.2s\n",
      "270:\tlearn: 1.9963880\ttotal: 4.16s\tremaining: 11.2s\n",
      "271:\tlearn: 1.9960225\ttotal: 4.17s\tremaining: 11.2s\n",
      "272:\tlearn: 1.9960179\ttotal: 4.19s\tremaining: 11.2s\n",
      "273:\tlearn: 1.9959575\ttotal: 4.2s\tremaining: 11.1s\n",
      "274:\tlearn: 1.9959010\ttotal: 4.22s\tremaining: 11.1s\n",
      "275:\tlearn: 1.9958508\ttotal: 4.23s\tremaining: 11.1s\n",
      "276:\tlearn: 1.9956780\ttotal: 4.24s\tremaining: 11.1s\n",
      "277:\tlearn: 1.9954662\ttotal: 4.26s\tremaining: 11.1s\n",
      "278:\tlearn: 1.9951334\ttotal: 4.27s\tremaining: 11s\n",
      "279:\tlearn: 1.9950337\ttotal: 4.29s\tremaining: 11s\n",
      "280:\tlearn: 1.9949466\ttotal: 4.3s\tremaining: 11s\n",
      "281:\tlearn: 1.9944749\ttotal: 4.32s\tremaining: 11s\n",
      "282:\tlearn: 1.9943120\ttotal: 4.33s\tremaining: 11s\n",
      "283:\tlearn: 1.9942869\ttotal: 4.34s\tremaining: 11s\n",
      "284:\tlearn: 1.9942312\ttotal: 4.36s\tremaining: 10.9s\n",
      "285:\tlearn: 1.9942005\ttotal: 4.37s\tremaining: 10.9s\n",
      "286:\tlearn: 1.9941182\ttotal: 4.39s\tremaining: 10.9s\n",
      "287:\tlearn: 1.9940599\ttotal: 4.4s\tremaining: 10.9s\n",
      "288:\tlearn: 1.9940205\ttotal: 4.42s\tremaining: 10.9s\n",
      "289:\tlearn: 1.9938073\ttotal: 4.43s\tremaining: 10.9s\n",
      "290:\tlearn: 1.9937161\ttotal: 4.45s\tremaining: 10.8s\n",
      "291:\tlearn: 1.9935541\ttotal: 4.46s\tremaining: 10.8s\n",
      "292:\tlearn: 1.9934987\ttotal: 4.47s\tremaining: 10.8s\n",
      "293:\tlearn: 1.9923725\ttotal: 4.49s\tremaining: 10.8s\n",
      "294:\tlearn: 1.9922155\ttotal: 4.5s\tremaining: 10.8s\n",
      "295:\tlearn: 1.9914884\ttotal: 4.52s\tremaining: 10.8s\n",
      "296:\tlearn: 1.9912536\ttotal: 4.54s\tremaining: 10.7s\n",
      "297:\tlearn: 1.9887652\ttotal: 4.55s\tremaining: 10.7s\n",
      "298:\tlearn: 1.9878122\ttotal: 4.57s\tremaining: 10.7s\n",
      "299:\tlearn: 1.9876883\ttotal: 4.58s\tremaining: 10.7s\n",
      "300:\tlearn: 1.9874751\ttotal: 4.59s\tremaining: 10.7s\n",
      "301:\tlearn: 1.9863446\ttotal: 4.61s\tremaining: 10.7s\n",
      "302:\tlearn: 1.9848154\ttotal: 4.62s\tremaining: 10.6s\n",
      "303:\tlearn: 1.9841600\ttotal: 4.64s\tremaining: 10.6s\n",
      "304:\tlearn: 1.9830413\ttotal: 4.65s\tremaining: 10.6s\n",
      "305:\tlearn: 1.9828839\ttotal: 4.67s\tremaining: 10.6s\n",
      "306:\tlearn: 1.9821305\ttotal: 4.68s\tremaining: 10.6s\n",
      "307:\tlearn: 1.9821305\ttotal: 4.7s\tremaining: 10.6s\n",
      "308:\tlearn: 1.9821157\ttotal: 4.71s\tremaining: 10.5s\n",
      "309:\tlearn: 1.9811686\ttotal: 4.73s\tremaining: 10.5s\n",
      "310:\tlearn: 1.9803885\ttotal: 4.74s\tremaining: 10.5s\n",
      "311:\tlearn: 1.9800488\ttotal: 4.76s\tremaining: 10.5s\n",
      "312:\tlearn: 1.9787334\ttotal: 4.77s\tremaining: 10.5s\n",
      "313:\tlearn: 1.9774994\ttotal: 4.79s\tremaining: 10.5s\n",
      "314:\tlearn: 1.9770739\ttotal: 4.8s\tremaining: 10.4s\n",
      "315:\tlearn: 1.9770419\ttotal: 4.82s\tremaining: 10.4s\n",
      "316:\tlearn: 1.9761067\ttotal: 4.83s\tremaining: 10.4s\n",
      "317:\tlearn: 1.9759958\ttotal: 4.85s\tremaining: 10.4s\n",
      "318:\tlearn: 1.9755496\ttotal: 4.86s\tremaining: 10.4s\n",
      "319:\tlearn: 1.9752008\ttotal: 4.87s\tremaining: 10.4s\n",
      "320:\tlearn: 1.9737748\ttotal: 4.89s\tremaining: 10.3s\n",
      "321:\tlearn: 1.9711813\ttotal: 4.9s\tremaining: 10.3s\n",
      "322:\tlearn: 1.9706481\ttotal: 4.92s\tremaining: 10.3s\n",
      "323:\tlearn: 1.9706448\ttotal: 4.93s\tremaining: 10.3s\n",
      "324:\tlearn: 1.9706424\ttotal: 4.95s\tremaining: 10.3s\n",
      "325:\tlearn: 1.9706404\ttotal: 4.96s\tremaining: 10.3s\n",
      "326:\tlearn: 1.9704994\ttotal: 4.98s\tremaining: 10.2s\n",
      "327:\tlearn: 1.9704896\ttotal: 4.99s\tremaining: 10.2s\n",
      "328:\tlearn: 1.9703655\ttotal: 5.01s\tremaining: 10.2s\n",
      "329:\tlearn: 1.9682389\ttotal: 5.02s\tremaining: 10.2s\n",
      "330:\tlearn: 1.9682349\ttotal: 5.04s\tremaining: 10.2s\n",
      "331:\tlearn: 1.9682095\ttotal: 5.05s\tremaining: 10.2s\n",
      "332:\tlearn: 1.9681169\ttotal: 5.07s\tremaining: 10.1s\n",
      "333:\tlearn: 1.9681089\ttotal: 5.08s\tremaining: 10.1s\n",
      "334:\tlearn: 1.9671917\ttotal: 5.09s\tremaining: 10.1s\n",
      "335:\tlearn: 1.9671432\ttotal: 5.11s\tremaining: 10.1s\n",
      "336:\tlearn: 1.9659360\ttotal: 5.12s\tremaining: 10.1s\n",
      "337:\tlearn: 1.9658878\ttotal: 5.14s\tremaining: 10.1s\n",
      "338:\tlearn: 1.9655605\ttotal: 5.15s\tremaining: 10s\n",
      "339:\tlearn: 1.9650493\ttotal: 5.17s\tremaining: 10s\n",
      "340:\tlearn: 1.9649398\ttotal: 5.18s\tremaining: 10s\n",
      "341:\tlearn: 1.9649221\ttotal: 5.19s\tremaining: 9.99s\n",
      "342:\tlearn: 1.9648740\ttotal: 5.21s\tremaining: 9.97s\n",
      "343:\tlearn: 1.9643429\ttotal: 5.22s\tremaining: 9.96s\n",
      "344:\tlearn: 1.9641934\ttotal: 5.24s\tremaining: 9.94s\n",
      "345:\tlearn: 1.9639176\ttotal: 5.25s\tremaining: 9.92s\n",
      "346:\tlearn: 1.9638158\ttotal: 5.26s\tremaining: 9.91s\n",
      "347:\tlearn: 1.9636613\ttotal: 5.28s\tremaining: 9.89s\n",
      "348:\tlearn: 1.9635104\ttotal: 5.29s\tremaining: 9.87s\n",
      "349:\tlearn: 1.9634292\ttotal: 5.31s\tremaining: 9.86s\n",
      "350:\tlearn: 1.9634220\ttotal: 5.32s\tremaining: 9.84s\n",
      "351:\tlearn: 1.9633508\ttotal: 5.34s\tremaining: 9.82s\n",
      "352:\tlearn: 1.9631598\ttotal: 5.35s\tremaining: 9.81s\n",
      "353:\tlearn: 1.9629245\ttotal: 5.37s\tremaining: 9.79s\n",
      "354:\tlearn: 1.9628695\ttotal: 5.38s\tremaining: 9.78s\n",
      "355:\tlearn: 1.9628361\ttotal: 5.39s\tremaining: 9.76s\n",
      "356:\tlearn: 1.9626932\ttotal: 5.41s\tremaining: 9.74s\n",
      "357:\tlearn: 1.9626537\ttotal: 5.42s\tremaining: 9.73s\n",
      "358:\tlearn: 1.9625369\ttotal: 5.44s\tremaining: 9.71s\n",
      "359:\tlearn: 1.9625024\ttotal: 5.45s\tremaining: 9.7s\n",
      "360:\tlearn: 1.9624750\ttotal: 5.47s\tremaining: 9.68s\n",
      "361:\tlearn: 1.9618190\ttotal: 5.48s\tremaining: 9.66s\n",
      "362:\tlearn: 1.9615015\ttotal: 5.5s\tremaining: 9.65s\n",
      "363:\tlearn: 1.9614432\ttotal: 5.51s\tremaining: 9.63s\n",
      "364:\tlearn: 1.9613641\ttotal: 5.53s\tremaining: 9.62s\n",
      "365:\tlearn: 1.9612697\ttotal: 5.54s\tremaining: 9.6s\n",
      "366:\tlearn: 1.9610069\ttotal: 5.56s\tremaining: 9.58s\n",
      "367:\tlearn: 1.9610040\ttotal: 5.57s\tremaining: 9.57s\n",
      "368:\tlearn: 1.9609822\ttotal: 5.59s\tremaining: 9.55s\n",
      "369:\tlearn: 1.9608549\ttotal: 5.6s\tremaining: 9.54s\n",
      "370:\tlearn: 1.9608452\ttotal: 5.61s\tremaining: 9.52s\n",
      "371:\tlearn: 1.9606477\ttotal: 5.63s\tremaining: 9.5s\n",
      "372:\tlearn: 1.9606388\ttotal: 5.64s\tremaining: 9.48s\n",
      "373:\tlearn: 1.9606246\ttotal: 5.66s\tremaining: 9.47s\n",
      "374:\tlearn: 1.9604559\ttotal: 5.67s\tremaining: 9.45s\n",
      "375:\tlearn: 1.9604548\ttotal: 5.68s\tremaining: 9.43s\n",
      "376:\tlearn: 1.9604295\ttotal: 5.7s\tremaining: 9.42s\n",
      "377:\tlearn: 1.9602071\ttotal: 5.71s\tremaining: 9.4s\n",
      "378:\tlearn: 1.9598609\ttotal: 5.73s\tremaining: 9.38s\n",
      "379:\tlearn: 1.9595224\ttotal: 5.74s\tremaining: 9.37s\n",
      "380:\tlearn: 1.9594521\ttotal: 5.75s\tremaining: 9.35s\n",
      "381:\tlearn: 1.9594459\ttotal: 5.77s\tremaining: 9.33s\n",
      "382:\tlearn: 1.9593734\ttotal: 5.79s\tremaining: 9.32s\n",
      "383:\tlearn: 1.9587036\ttotal: 5.8s\tremaining: 9.3s\n",
      "384:\tlearn: 1.9581371\ttotal: 5.81s\tremaining: 9.29s\n",
      "385:\tlearn: 1.9573841\ttotal: 5.83s\tremaining: 9.27s\n",
      "386:\tlearn: 1.9573793\ttotal: 5.84s\tremaining: 9.26s\n",
      "387:\tlearn: 1.9573782\ttotal: 5.86s\tremaining: 9.24s\n",
      "388:\tlearn: 1.9573592\ttotal: 5.87s\tremaining: 9.22s\n",
      "389:\tlearn: 1.9572232\ttotal: 5.89s\tremaining: 9.21s\n",
      "390:\tlearn: 1.9572048\ttotal: 5.9s\tremaining: 9.19s\n",
      "391:\tlearn: 1.9570465\ttotal: 5.92s\tremaining: 9.18s\n",
      "392:\tlearn: 1.9557910\ttotal: 5.93s\tremaining: 9.16s\n",
      "393:\tlearn: 1.9544236\ttotal: 5.94s\tremaining: 9.14s\n",
      "394:\tlearn: 1.9531159\ttotal: 5.96s\tremaining: 9.13s\n",
      "395:\tlearn: 1.9530402\ttotal: 5.97s\tremaining: 9.11s\n",
      "396:\tlearn: 1.9527545\ttotal: 5.99s\tremaining: 9.1s\n",
      "397:\tlearn: 1.9524924\ttotal: 6s\tremaining: 9.08s\n",
      "398:\tlearn: 1.9523530\ttotal: 6.02s\tremaining: 9.07s\n",
      "399:\tlearn: 1.9523351\ttotal: 6.03s\tremaining: 9.05s\n",
      "400:\tlearn: 1.9521186\ttotal: 6.05s\tremaining: 9.04s\n",
      "401:\tlearn: 1.9521073\ttotal: 6.06s\tremaining: 9.02s\n",
      "402:\tlearn: 1.9521032\ttotal: 6.08s\tremaining: 9s\n",
      "403:\tlearn: 1.9513733\ttotal: 6.09s\tremaining: 8.99s\n",
      "404:\tlearn: 1.9511739\ttotal: 6.11s\tremaining: 8.97s\n",
      "405:\tlearn: 1.9511739\ttotal: 6.12s\tremaining: 8.95s\n",
      "406:\tlearn: 1.9509908\ttotal: 6.13s\tremaining: 8.94s\n",
      "407:\tlearn: 1.9501718\ttotal: 6.15s\tremaining: 8.92s\n",
      "408:\tlearn: 1.9496270\ttotal: 6.16s\tremaining: 8.91s\n",
      "409:\tlearn: 1.9495355\ttotal: 6.18s\tremaining: 8.89s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410:\tlearn: 1.9493529\ttotal: 6.2s\tremaining: 8.88s\n",
      "411:\tlearn: 1.9492652\ttotal: 6.21s\tremaining: 8.86s\n",
      "412:\tlearn: 1.9489619\ttotal: 6.23s\tremaining: 8.85s\n",
      "413:\tlearn: 1.9486969\ttotal: 6.24s\tremaining: 8.83s\n",
      "414:\tlearn: 1.9483041\ttotal: 6.25s\tremaining: 8.82s\n",
      "415:\tlearn: 1.9482567\ttotal: 6.27s\tremaining: 8.8s\n",
      "416:\tlearn: 1.9482171\ttotal: 6.28s\tremaining: 8.78s\n",
      "417:\tlearn: 1.9479196\ttotal: 6.3s\tremaining: 8.77s\n",
      "418:\tlearn: 1.9467878\ttotal: 6.31s\tremaining: 8.75s\n",
      "419:\tlearn: 1.9458068\ttotal: 6.33s\tremaining: 8.73s\n",
      "420:\tlearn: 1.9447856\ttotal: 6.34s\tremaining: 8.72s\n",
      "421:\tlearn: 1.9447797\ttotal: 6.35s\tremaining: 8.7s\n",
      "422:\tlearn: 1.9445520\ttotal: 6.37s\tremaining: 8.69s\n",
      "423:\tlearn: 1.9438945\ttotal: 6.38s\tremaining: 8.67s\n",
      "424:\tlearn: 1.9435956\ttotal: 6.4s\tremaining: 8.66s\n",
      "425:\tlearn: 1.9421264\ttotal: 6.42s\tremaining: 8.64s\n",
      "426:\tlearn: 1.9419220\ttotal: 6.43s\tremaining: 8.63s\n",
      "427:\tlearn: 1.9406926\ttotal: 6.45s\tremaining: 8.62s\n",
      "428:\tlearn: 1.9406615\ttotal: 6.46s\tremaining: 8.6s\n",
      "429:\tlearn: 1.9398441\ttotal: 6.47s\tremaining: 8.58s\n",
      "430:\tlearn: 1.9398228\ttotal: 6.49s\tremaining: 8.57s\n",
      "431:\tlearn: 1.9398228\ttotal: 6.5s\tremaining: 8.55s\n",
      "432:\tlearn: 1.9398226\ttotal: 6.52s\tremaining: 8.53s\n",
      "433:\tlearn: 1.9397670\ttotal: 6.53s\tremaining: 8.52s\n",
      "434:\tlearn: 1.9392192\ttotal: 6.54s\tremaining: 8.5s\n",
      "435:\tlearn: 1.9384905\ttotal: 6.56s\tremaining: 8.48s\n",
      "436:\tlearn: 1.9384884\ttotal: 6.57s\tremaining: 8.47s\n",
      "437:\tlearn: 1.9383991\ttotal: 6.59s\tremaining: 8.45s\n",
      "438:\tlearn: 1.9381790\ttotal: 6.6s\tremaining: 8.44s\n",
      "439:\tlearn: 1.9370367\ttotal: 6.62s\tremaining: 8.42s\n",
      "440:\tlearn: 1.9368629\ttotal: 6.63s\tremaining: 8.41s\n",
      "441:\tlearn: 1.9362413\ttotal: 6.65s\tremaining: 8.39s\n",
      "442:\tlearn: 1.9358123\ttotal: 6.66s\tremaining: 8.38s\n",
      "443:\tlearn: 1.9354810\ttotal: 6.68s\tremaining: 8.36s\n",
      "444:\tlearn: 1.9354120\ttotal: 6.69s\tremaining: 8.35s\n",
      "445:\tlearn: 1.9352595\ttotal: 6.71s\tremaining: 8.33s\n",
      "446:\tlearn: 1.9352450\ttotal: 6.72s\tremaining: 8.31s\n",
      "447:\tlearn: 1.9352179\ttotal: 6.74s\tremaining: 8.3s\n",
      "448:\tlearn: 1.9347397\ttotal: 6.75s\tremaining: 8.28s\n",
      "449:\tlearn: 1.9347264\ttotal: 6.76s\tremaining: 8.27s\n",
      "450:\tlearn: 1.9344903\ttotal: 6.78s\tremaining: 8.25s\n",
      "451:\tlearn: 1.9344415\ttotal: 6.79s\tremaining: 8.24s\n",
      "452:\tlearn: 1.9343979\ttotal: 6.81s\tremaining: 8.22s\n",
      "453:\tlearn: 1.9338109\ttotal: 6.82s\tremaining: 8.21s\n",
      "454:\tlearn: 1.9337341\ttotal: 6.84s\tremaining: 8.19s\n",
      "455:\tlearn: 1.9337199\ttotal: 6.85s\tremaining: 8.17s\n",
      "456:\tlearn: 1.9336854\ttotal: 6.87s\tremaining: 8.16s\n",
      "457:\tlearn: 1.9335780\ttotal: 6.88s\tremaining: 8.14s\n",
      "458:\tlearn: 1.9335680\ttotal: 6.89s\tremaining: 8.13s\n",
      "459:\tlearn: 1.9334480\ttotal: 6.91s\tremaining: 8.11s\n",
      "460:\tlearn: 1.9334154\ttotal: 6.92s\tremaining: 8.09s\n",
      "461:\tlearn: 1.9333851\ttotal: 6.94s\tremaining: 8.08s\n",
      "462:\tlearn: 1.9322455\ttotal: 6.95s\tremaining: 8.06s\n",
      "463:\tlearn: 1.9322179\ttotal: 6.96s\tremaining: 8.05s\n",
      "464:\tlearn: 1.9321854\ttotal: 6.98s\tremaining: 8.03s\n",
      "465:\tlearn: 1.9317638\ttotal: 6.99s\tremaining: 8.02s\n",
      "466:\tlearn: 1.9301921\ttotal: 7.01s\tremaining: 8s\n",
      "467:\tlearn: 1.9297033\ttotal: 7.02s\tremaining: 7.98s\n",
      "468:\tlearn: 1.9284294\ttotal: 7.04s\tremaining: 7.97s\n",
      "469:\tlearn: 1.9280251\ttotal: 7.05s\tremaining: 7.95s\n",
      "470:\tlearn: 1.9279206\ttotal: 7.07s\tremaining: 7.94s\n",
      "471:\tlearn: 1.9278767\ttotal: 7.08s\tremaining: 7.92s\n",
      "472:\tlearn: 1.9278456\ttotal: 7.1s\tremaining: 7.91s\n",
      "473:\tlearn: 1.9276473\ttotal: 7.11s\tremaining: 7.89s\n",
      "474:\tlearn: 1.9273727\ttotal: 7.12s\tremaining: 7.87s\n",
      "475:\tlearn: 1.9272140\ttotal: 7.14s\tremaining: 7.86s\n",
      "476:\tlearn: 1.9271212\ttotal: 7.15s\tremaining: 7.84s\n",
      "477:\tlearn: 1.9270947\ttotal: 7.17s\tremaining: 7.83s\n",
      "478:\tlearn: 1.9267089\ttotal: 7.18s\tremaining: 7.81s\n",
      "479:\tlearn: 1.9265311\ttotal: 7.19s\tremaining: 7.79s\n",
      "480:\tlearn: 1.9265218\ttotal: 7.21s\tremaining: 7.78s\n",
      "481:\tlearn: 1.9265217\ttotal: 7.22s\tremaining: 7.76s\n",
      "482:\tlearn: 1.9259937\ttotal: 7.24s\tremaining: 7.75s\n",
      "483:\tlearn: 1.9253510\ttotal: 7.25s\tremaining: 7.73s\n",
      "484:\tlearn: 1.9248148\ttotal: 7.27s\tremaining: 7.72s\n",
      "485:\tlearn: 1.9246010\ttotal: 7.29s\tremaining: 7.71s\n",
      "486:\tlearn: 1.9246005\ttotal: 7.31s\tremaining: 7.7s\n",
      "487:\tlearn: 1.9244803\ttotal: 7.32s\tremaining: 7.68s\n",
      "488:\tlearn: 1.9242492\ttotal: 7.34s\tremaining: 7.67s\n",
      "489:\tlearn: 1.9239975\ttotal: 7.35s\tremaining: 7.65s\n",
      "490:\tlearn: 1.9233824\ttotal: 7.37s\tremaining: 7.64s\n",
      "491:\tlearn: 1.9229514\ttotal: 7.38s\tremaining: 7.62s\n",
      "492:\tlearn: 1.9217283\ttotal: 7.4s\tremaining: 7.61s\n",
      "493:\tlearn: 1.9214319\ttotal: 7.41s\tremaining: 7.59s\n",
      "494:\tlearn: 1.9210963\ttotal: 7.43s\tremaining: 7.58s\n",
      "495:\tlearn: 1.9205960\ttotal: 7.44s\tremaining: 7.56s\n",
      "496:\tlearn: 1.9201069\ttotal: 7.46s\tremaining: 7.55s\n",
      "497:\tlearn: 1.9200709\ttotal: 7.47s\tremaining: 7.53s\n",
      "498:\tlearn: 1.9195449\ttotal: 7.49s\tremaining: 7.52s\n",
      "499:\tlearn: 1.9195037\ttotal: 7.5s\tremaining: 7.5s\n",
      "500:\tlearn: 1.9191850\ttotal: 7.52s\tremaining: 7.49s\n",
      "501:\tlearn: 1.9189959\ttotal: 7.53s\tremaining: 7.47s\n",
      "502:\tlearn: 1.9189855\ttotal: 7.54s\tremaining: 7.46s\n",
      "503:\tlearn: 1.9187205\ttotal: 7.56s\tremaining: 7.44s\n",
      "504:\tlearn: 1.9186302\ttotal: 7.57s\tremaining: 7.42s\n",
      "505:\tlearn: 1.9184002\ttotal: 7.59s\tremaining: 7.41s\n",
      "506:\tlearn: 1.9181398\ttotal: 7.6s\tremaining: 7.39s\n",
      "507:\tlearn: 1.9180663\ttotal: 7.62s\tremaining: 7.38s\n",
      "508:\tlearn: 1.9180352\ttotal: 7.63s\tremaining: 7.36s\n",
      "509:\tlearn: 1.9178977\ttotal: 7.64s\tremaining: 7.34s\n",
      "510:\tlearn: 1.9178018\ttotal: 7.66s\tremaining: 7.33s\n",
      "511:\tlearn: 1.9177975\ttotal: 7.67s\tremaining: 7.31s\n",
      "512:\tlearn: 1.9177925\ttotal: 7.69s\tremaining: 7.3s\n",
      "513:\tlearn: 1.9177713\ttotal: 7.7s\tremaining: 7.28s\n",
      "514:\tlearn: 1.9177400\ttotal: 7.72s\tremaining: 7.27s\n",
      "515:\tlearn: 1.9177374\ttotal: 7.73s\tremaining: 7.25s\n",
      "516:\tlearn: 1.9177160\ttotal: 7.75s\tremaining: 7.24s\n",
      "517:\tlearn: 1.9177073\ttotal: 7.76s\tremaining: 7.22s\n",
      "518:\tlearn: 1.9176416\ttotal: 7.78s\tremaining: 7.21s\n",
      "519:\tlearn: 1.9174625\ttotal: 7.79s\tremaining: 7.19s\n",
      "520:\tlearn: 1.9174195\ttotal: 7.81s\tremaining: 7.18s\n",
      "521:\tlearn: 1.9170965\ttotal: 7.82s\tremaining: 7.16s\n",
      "522:\tlearn: 1.9170962\ttotal: 7.83s\tremaining: 7.15s\n",
      "523:\tlearn: 1.9170441\ttotal: 7.85s\tremaining: 7.13s\n",
      "524:\tlearn: 1.9170433\ttotal: 7.86s\tremaining: 7.12s\n",
      "525:\tlearn: 1.9170298\ttotal: 7.88s\tremaining: 7.1s\n",
      "526:\tlearn: 1.9170259\ttotal: 7.89s\tremaining: 7.08s\n",
      "527:\tlearn: 1.9170130\ttotal: 7.91s\tremaining: 7.07s\n",
      "528:\tlearn: 1.9170120\ttotal: 7.92s\tremaining: 7.05s\n",
      "529:\tlearn: 1.9170109\ttotal: 7.94s\tremaining: 7.04s\n",
      "530:\tlearn: 1.9170109\ttotal: 7.95s\tremaining: 7.02s\n",
      "531:\tlearn: 1.9170102\ttotal: 7.97s\tremaining: 7.01s\n",
      "532:\tlearn: 1.9170032\ttotal: 7.98s\tremaining: 6.99s\n",
      "533:\tlearn: 1.9170028\ttotal: 7.99s\tremaining: 6.98s\n",
      "534:\tlearn: 1.9170025\ttotal: 8.01s\tremaining: 6.96s\n",
      "535:\tlearn: 1.9169982\ttotal: 8.02s\tremaining: 6.94s\n",
      "536:\tlearn: 1.9169939\ttotal: 8.04s\tremaining: 6.93s\n",
      "537:\tlearn: 1.9169123\ttotal: 8.05s\tremaining: 6.91s\n",
      "538:\tlearn: 1.9168738\ttotal: 8.06s\tremaining: 6.9s\n",
      "539:\tlearn: 1.9168579\ttotal: 8.08s\tremaining: 6.88s\n",
      "540:\tlearn: 1.9168559\ttotal: 8.09s\tremaining: 6.86s\n",
      "541:\tlearn: 1.9168559\ttotal: 8.11s\tremaining: 6.85s\n",
      "542:\tlearn: 1.9168529\ttotal: 8.12s\tremaining: 6.83s\n",
      "543:\tlearn: 1.9168529\ttotal: 8.13s\tremaining: 6.82s\n",
      "544:\tlearn: 1.9168529\ttotal: 8.15s\tremaining: 6.8s\n",
      "545:\tlearn: 1.9168529\ttotal: 8.16s\tremaining: 6.79s\n",
      "546:\tlearn: 1.9168529\ttotal: 8.18s\tremaining: 6.77s\n",
      "547:\tlearn: 1.9168529\ttotal: 8.19s\tremaining: 6.75s\n",
      "548:\tlearn: 1.9168503\ttotal: 8.2s\tremaining: 6.74s\n",
      "549:\tlearn: 1.9168503\ttotal: 8.22s\tremaining: 6.72s\n",
      "550:\tlearn: 1.9168503\ttotal: 8.23s\tremaining: 6.71s\n",
      "551:\tlearn: 1.9168503\ttotal: 8.24s\tremaining: 6.69s\n",
      "552:\tlearn: 1.9168503\ttotal: 8.26s\tremaining: 6.68s\n",
      "553:\tlearn: 1.9168481\ttotal: 8.27s\tremaining: 6.66s\n",
      "554:\tlearn: 1.9160582\ttotal: 8.29s\tremaining: 6.64s\n",
      "555:\tlearn: 1.9160509\ttotal: 8.3s\tremaining: 6.63s\n",
      "556:\tlearn: 1.9160442\ttotal: 8.31s\tremaining: 6.61s\n",
      "557:\tlearn: 1.9159845\ttotal: 8.33s\tremaining: 6.6s\n",
      "558:\tlearn: 1.9159835\ttotal: 8.34s\tremaining: 6.58s\n",
      "559:\tlearn: 1.9159802\ttotal: 8.36s\tremaining: 6.57s\n",
      "560:\tlearn: 1.9159789\ttotal: 8.37s\tremaining: 6.55s\n",
      "561:\tlearn: 1.9157418\ttotal: 8.38s\tremaining: 6.53s\n",
      "562:\tlearn: 1.9153896\ttotal: 8.4s\tremaining: 6.52s\n",
      "563:\tlearn: 1.9153665\ttotal: 8.41s\tremaining: 6.5s\n",
      "564:\tlearn: 1.9151775\ttotal: 8.43s\tremaining: 6.49s\n",
      "565:\tlearn: 1.9147579\ttotal: 8.44s\tremaining: 6.47s\n",
      "566:\tlearn: 1.9146924\ttotal: 8.45s\tremaining: 6.46s\n",
      "567:\tlearn: 1.9146557\ttotal: 8.47s\tremaining: 6.44s\n",
      "568:\tlearn: 1.9146543\ttotal: 8.48s\tremaining: 6.42s\n",
      "569:\tlearn: 1.9146407\ttotal: 8.5s\tremaining: 6.41s\n",
      "570:\tlearn: 1.9146407\ttotal: 8.51s\tremaining: 6.39s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571:\tlearn: 1.9146194\ttotal: 8.53s\tremaining: 6.38s\n",
      "572:\tlearn: 1.9145901\ttotal: 8.54s\tremaining: 6.36s\n",
      "573:\tlearn: 1.9138274\ttotal: 8.55s\tremaining: 6.35s\n",
      "574:\tlearn: 1.9136699\ttotal: 8.57s\tremaining: 6.33s\n",
      "575:\tlearn: 1.9136374\ttotal: 8.58s\tremaining: 6.32s\n",
      "576:\tlearn: 1.9136135\ttotal: 8.6s\tremaining: 6.3s\n",
      "577:\tlearn: 1.9136032\ttotal: 8.61s\tremaining: 6.29s\n",
      "578:\tlearn: 1.9135948\ttotal: 8.63s\tremaining: 6.27s\n",
      "579:\tlearn: 1.9135500\ttotal: 8.64s\tremaining: 6.26s\n",
      "580:\tlearn: 1.9135385\ttotal: 8.65s\tremaining: 6.24s\n",
      "581:\tlearn: 1.9134274\ttotal: 8.67s\tremaining: 6.22s\n",
      "582:\tlearn: 1.9133233\ttotal: 8.68s\tremaining: 6.21s\n",
      "583:\tlearn: 1.9131443\ttotal: 8.7s\tremaining: 6.2s\n",
      "584:\tlearn: 1.9131392\ttotal: 8.71s\tremaining: 6.18s\n",
      "585:\tlearn: 1.9128507\ttotal: 8.72s\tremaining: 6.16s\n",
      "586:\tlearn: 1.9123483\ttotal: 8.74s\tremaining: 6.15s\n",
      "587:\tlearn: 1.9118336\ttotal: 8.76s\tremaining: 6.13s\n",
      "588:\tlearn: 1.9112312\ttotal: 8.77s\tremaining: 6.12s\n",
      "589:\tlearn: 1.9110256\ttotal: 8.78s\tremaining: 6.1s\n",
      "590:\tlearn: 1.9103866\ttotal: 8.8s\tremaining: 6.09s\n",
      "591:\tlearn: 1.9103422\ttotal: 8.81s\tremaining: 6.07s\n",
      "592:\tlearn: 1.9103238\ttotal: 8.83s\tremaining: 6.06s\n",
      "593:\tlearn: 1.9103238\ttotal: 8.84s\tremaining: 6.04s\n",
      "594:\tlearn: 1.9101527\ttotal: 8.86s\tremaining: 6.03s\n",
      "595:\tlearn: 1.9097637\ttotal: 8.87s\tremaining: 6.01s\n",
      "596:\tlearn: 1.9093095\ttotal: 8.88s\tremaining: 6s\n",
      "597:\tlearn: 1.9090233\ttotal: 8.9s\tremaining: 5.98s\n",
      "598:\tlearn: 1.9089907\ttotal: 8.91s\tremaining: 5.97s\n",
      "599:\tlearn: 1.9089393\ttotal: 8.93s\tremaining: 5.95s\n",
      "600:\tlearn: 1.9089179\ttotal: 8.94s\tremaining: 5.94s\n",
      "601:\tlearn: 1.9089118\ttotal: 8.96s\tremaining: 5.92s\n",
      "602:\tlearn: 1.9089084\ttotal: 8.97s\tremaining: 5.91s\n",
      "603:\tlearn: 1.9089019\ttotal: 8.99s\tremaining: 5.89s\n",
      "604:\tlearn: 1.9088712\ttotal: 9s\tremaining: 5.88s\n",
      "605:\tlearn: 1.9088501\ttotal: 9.02s\tremaining: 5.86s\n",
      "606:\tlearn: 1.9088208\ttotal: 9.03s\tremaining: 5.85s\n",
      "607:\tlearn: 1.9087424\ttotal: 9.04s\tremaining: 5.83s\n",
      "608:\tlearn: 1.9087368\ttotal: 9.06s\tremaining: 5.82s\n",
      "609:\tlearn: 1.9087364\ttotal: 9.07s\tremaining: 5.8s\n",
      "610:\tlearn: 1.9087332\ttotal: 9.09s\tremaining: 5.79s\n",
      "611:\tlearn: 1.9087332\ttotal: 9.1s\tremaining: 5.77s\n",
      "612:\tlearn: 1.9087331\ttotal: 9.11s\tremaining: 5.75s\n",
      "613:\tlearn: 1.9087330\ttotal: 9.13s\tremaining: 5.74s\n",
      "614:\tlearn: 1.9087330\ttotal: 9.14s\tremaining: 5.72s\n",
      "615:\tlearn: 1.9087330\ttotal: 9.16s\tremaining: 5.71s\n",
      "616:\tlearn: 1.9087330\ttotal: 9.17s\tremaining: 5.69s\n",
      "617:\tlearn: 1.9087330\ttotal: 9.19s\tremaining: 5.68s\n",
      "618:\tlearn: 1.9087320\ttotal: 9.2s\tremaining: 5.66s\n",
      "619:\tlearn: 1.9087315\ttotal: 9.21s\tremaining: 5.65s\n",
      "620:\tlearn: 1.9087315\ttotal: 9.23s\tremaining: 5.63s\n",
      "621:\tlearn: 1.9087294\ttotal: 9.24s\tremaining: 5.62s\n",
      "622:\tlearn: 1.9083482\ttotal: 9.26s\tremaining: 5.6s\n",
      "623:\tlearn: 1.9078049\ttotal: 9.27s\tremaining: 5.59s\n",
      "624:\tlearn: 1.9075050\ttotal: 9.29s\tremaining: 5.57s\n",
      "625:\tlearn: 1.9074567\ttotal: 9.3s\tremaining: 5.55s\n",
      "626:\tlearn: 1.9073261\ttotal: 9.31s\tremaining: 5.54s\n",
      "627:\tlearn: 1.9070726\ttotal: 9.33s\tremaining: 5.53s\n",
      "628:\tlearn: 1.9070304\ttotal: 9.34s\tremaining: 5.51s\n",
      "629:\tlearn: 1.9070288\ttotal: 9.36s\tremaining: 5.5s\n",
      "630:\tlearn: 1.9068286\ttotal: 9.37s\tremaining: 5.48s\n",
      "631:\tlearn: 1.9062809\ttotal: 9.39s\tremaining: 5.47s\n",
      "632:\tlearn: 1.9062006\ttotal: 9.4s\tremaining: 5.45s\n",
      "633:\tlearn: 1.9061975\ttotal: 9.42s\tremaining: 5.44s\n",
      "634:\tlearn: 1.9060879\ttotal: 9.43s\tremaining: 5.42s\n",
      "635:\tlearn: 1.9059691\ttotal: 9.45s\tremaining: 5.41s\n",
      "636:\tlearn: 1.9059691\ttotal: 9.46s\tremaining: 5.39s\n",
      "637:\tlearn: 1.9059691\ttotal: 9.47s\tremaining: 5.38s\n",
      "638:\tlearn: 1.9059688\ttotal: 9.49s\tremaining: 5.36s\n",
      "639:\tlearn: 1.9059684\ttotal: 9.5s\tremaining: 5.34s\n",
      "640:\tlearn: 1.9059458\ttotal: 9.52s\tremaining: 5.33s\n",
      "641:\tlearn: 1.9059458\ttotal: 9.53s\tremaining: 5.31s\n",
      "642:\tlearn: 1.9059456\ttotal: 9.54s\tremaining: 5.3s\n",
      "643:\tlearn: 1.9059140\ttotal: 9.56s\tremaining: 5.28s\n",
      "644:\tlearn: 1.9058767\ttotal: 9.57s\tremaining: 5.27s\n",
      "645:\tlearn: 1.9058766\ttotal: 9.59s\tremaining: 5.25s\n",
      "646:\tlearn: 1.9058273\ttotal: 9.6s\tremaining: 5.24s\n",
      "647:\tlearn: 1.9058252\ttotal: 9.62s\tremaining: 5.22s\n",
      "648:\tlearn: 1.9058252\ttotal: 9.63s\tremaining: 5.21s\n",
      "649:\tlearn: 1.9058174\ttotal: 9.64s\tremaining: 5.19s\n",
      "650:\tlearn: 1.9057869\ttotal: 9.66s\tremaining: 5.18s\n",
      "651:\tlearn: 1.9057821\ttotal: 9.67s\tremaining: 5.16s\n",
      "652:\tlearn: 1.9057681\ttotal: 9.69s\tremaining: 5.15s\n",
      "653:\tlearn: 1.9057063\ttotal: 9.7s\tremaining: 5.13s\n",
      "654:\tlearn: 1.9051373\ttotal: 9.71s\tremaining: 5.12s\n",
      "655:\tlearn: 1.9051217\ttotal: 9.73s\tremaining: 5.1s\n",
      "656:\tlearn: 1.9049460\ttotal: 9.74s\tremaining: 5.08s\n",
      "657:\tlearn: 1.9048926\ttotal: 9.76s\tremaining: 5.07s\n",
      "658:\tlearn: 1.9045378\ttotal: 9.77s\tremaining: 5.05s\n",
      "659:\tlearn: 1.9038912\ttotal: 9.79s\tremaining: 5.04s\n",
      "660:\tlearn: 1.9038421\ttotal: 9.8s\tremaining: 5.03s\n",
      "661:\tlearn: 1.9033908\ttotal: 9.81s\tremaining: 5.01s\n",
      "662:\tlearn: 1.9033189\ttotal: 9.83s\tremaining: 5s\n",
      "663:\tlearn: 1.9027343\ttotal: 9.84s\tremaining: 4.98s\n",
      "664:\tlearn: 1.9022044\ttotal: 9.86s\tremaining: 4.96s\n",
      "665:\tlearn: 1.9020411\ttotal: 9.87s\tremaining: 4.95s\n",
      "666:\tlearn: 1.9020406\ttotal: 9.88s\tremaining: 4.93s\n",
      "667:\tlearn: 1.9020208\ttotal: 9.9s\tremaining: 4.92s\n",
      "668:\tlearn: 1.9019996\ttotal: 9.91s\tremaining: 4.9s\n",
      "669:\tlearn: 1.9018000\ttotal: 9.93s\tremaining: 4.89s\n",
      "670:\tlearn: 1.9017486\ttotal: 9.94s\tremaining: 4.87s\n",
      "671:\tlearn: 1.9016861\ttotal: 9.95s\tremaining: 4.86s\n",
      "672:\tlearn: 1.9016818\ttotal: 9.97s\tremaining: 4.84s\n",
      "673:\tlearn: 1.9016816\ttotal: 9.98s\tremaining: 4.83s\n",
      "674:\tlearn: 1.9016816\ttotal: 10s\tremaining: 4.81s\n",
      "675:\tlearn: 1.9016816\ttotal: 10s\tremaining: 4.8s\n",
      "676:\tlearn: 1.9016816\ttotal: 10s\tremaining: 4.78s\n",
      "677:\tlearn: 1.9016813\ttotal: 10s\tremaining: 4.77s\n",
      "678:\tlearn: 1.9016813\ttotal: 10.1s\tremaining: 4.75s\n",
      "679:\tlearn: 1.9016808\ttotal: 10.1s\tremaining: 4.74s\n",
      "680:\tlearn: 1.9016532\ttotal: 10.1s\tremaining: 4.72s\n",
      "681:\tlearn: 1.9010086\ttotal: 10.1s\tremaining: 4.71s\n",
      "682:\tlearn: 1.9009176\ttotal: 10.1s\tremaining: 4.69s\n",
      "683:\tlearn: 1.9006726\ttotal: 10.1s\tremaining: 4.68s\n",
      "684:\tlearn: 1.9006274\ttotal: 10.1s\tremaining: 4.66s\n",
      "685:\tlearn: 1.8996254\ttotal: 10.2s\tremaining: 4.65s\n",
      "686:\tlearn: 1.8995527\ttotal: 10.2s\tremaining: 4.63s\n",
      "687:\tlearn: 1.8995520\ttotal: 10.2s\tremaining: 4.62s\n",
      "688:\tlearn: 1.8995490\ttotal: 10.2s\tremaining: 4.6s\n",
      "689:\tlearn: 1.8995487\ttotal: 10.2s\tremaining: 4.59s\n",
      "690:\tlearn: 1.8994626\ttotal: 10.2s\tremaining: 4.57s\n",
      "691:\tlearn: 1.8993114\ttotal: 10.2s\tremaining: 4.56s\n",
      "692:\tlearn: 1.8993083\ttotal: 10.3s\tremaining: 4.54s\n",
      "693:\tlearn: 1.8993069\ttotal: 10.3s\tremaining: 4.53s\n",
      "694:\tlearn: 1.8993027\ttotal: 10.3s\tremaining: 4.51s\n",
      "695:\tlearn: 1.8993024\ttotal: 10.3s\tremaining: 4.5s\n",
      "696:\tlearn: 1.8993023\ttotal: 10.3s\tremaining: 4.48s\n",
      "697:\tlearn: 1.8992966\ttotal: 10.3s\tremaining: 4.47s\n",
      "698:\tlearn: 1.8992955\ttotal: 10.3s\tremaining: 4.45s\n",
      "699:\tlearn: 1.8992390\ttotal: 10.4s\tremaining: 4.44s\n",
      "700:\tlearn: 1.8991508\ttotal: 10.4s\tremaining: 4.42s\n",
      "701:\tlearn: 1.8991461\ttotal: 10.4s\tremaining: 4.41s\n",
      "702:\tlearn: 1.8977043\ttotal: 10.4s\tremaining: 4.39s\n",
      "703:\tlearn: 1.8976581\ttotal: 10.4s\tremaining: 4.38s\n",
      "704:\tlearn: 1.8976158\ttotal: 10.4s\tremaining: 4.36s\n",
      "705:\tlearn: 1.8969096\ttotal: 10.4s\tremaining: 4.35s\n",
      "706:\tlearn: 1.8969096\ttotal: 10.5s\tremaining: 4.33s\n",
      "707:\tlearn: 1.8969010\ttotal: 10.5s\tremaining: 4.32s\n",
      "708:\tlearn: 1.8967732\ttotal: 10.5s\tremaining: 4.3s\n",
      "709:\tlearn: 1.8963005\ttotal: 10.5s\tremaining: 4.29s\n",
      "710:\tlearn: 1.8962756\ttotal: 10.5s\tremaining: 4.27s\n",
      "711:\tlearn: 1.8962755\ttotal: 10.5s\tremaining: 4.26s\n",
      "712:\tlearn: 1.8962285\ttotal: 10.5s\tremaining: 4.24s\n",
      "713:\tlearn: 1.8962044\ttotal: 10.6s\tremaining: 4.23s\n",
      "714:\tlearn: 1.8962042\ttotal: 10.6s\tremaining: 4.21s\n",
      "715:\tlearn: 1.8957607\ttotal: 10.6s\tremaining: 4.2s\n",
      "716:\tlearn: 1.8957607\ttotal: 10.6s\tremaining: 4.18s\n",
      "717:\tlearn: 1.8957607\ttotal: 10.6s\tremaining: 4.16s\n",
      "718:\tlearn: 1.8953817\ttotal: 10.6s\tremaining: 4.15s\n",
      "719:\tlearn: 1.8948188\ttotal: 10.6s\tremaining: 4.13s\n",
      "720:\tlearn: 1.8938850\ttotal: 10.6s\tremaining: 4.12s\n",
      "721:\tlearn: 1.8934554\ttotal: 10.7s\tremaining: 4.11s\n",
      "722:\tlearn: 1.8934553\ttotal: 10.7s\tremaining: 4.09s\n",
      "723:\tlearn: 1.8934553\ttotal: 10.7s\tremaining: 4.08s\n",
      "724:\tlearn: 1.8934552\ttotal: 10.7s\tremaining: 4.06s\n",
      "725:\tlearn: 1.8934515\ttotal: 10.7s\tremaining: 4.05s\n",
      "726:\tlearn: 1.8934515\ttotal: 10.7s\tremaining: 4.03s\n",
      "727:\tlearn: 1.8934281\ttotal: 10.8s\tremaining: 4.02s\n",
      "728:\tlearn: 1.8934029\ttotal: 10.8s\tremaining: 4s\n",
      "729:\tlearn: 1.8934027\ttotal: 10.8s\tremaining: 3.99s\n",
      "730:\tlearn: 1.8933954\ttotal: 10.8s\tremaining: 3.97s\n",
      "731:\tlearn: 1.8933945\ttotal: 10.8s\tremaining: 3.96s\n",
      "732:\tlearn: 1.8933903\ttotal: 10.8s\tremaining: 3.94s\n",
      "733:\tlearn: 1.8933903\ttotal: 10.8s\tremaining: 3.93s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734:\tlearn: 1.8933903\ttotal: 10.9s\tremaining: 3.92s\n",
      "735:\tlearn: 1.8933357\ttotal: 10.9s\tremaining: 3.9s\n",
      "736:\tlearn: 1.8931330\ttotal: 10.9s\tremaining: 3.89s\n",
      "737:\tlearn: 1.8930943\ttotal: 10.9s\tremaining: 3.87s\n",
      "738:\tlearn: 1.8930508\ttotal: 10.9s\tremaining: 3.86s\n",
      "739:\tlearn: 1.8929482\ttotal: 10.9s\tremaining: 3.84s\n",
      "740:\tlearn: 1.8929053\ttotal: 10.9s\tremaining: 3.83s\n",
      "741:\tlearn: 1.8921241\ttotal: 11s\tremaining: 3.81s\n",
      "742:\tlearn: 1.8920927\ttotal: 11s\tremaining: 3.8s\n",
      "743:\tlearn: 1.8915280\ttotal: 11s\tremaining: 3.78s\n",
      "744:\tlearn: 1.8915178\ttotal: 11s\tremaining: 3.77s\n",
      "745:\tlearn: 1.8912320\ttotal: 11s\tremaining: 3.75s\n",
      "746:\tlearn: 1.8903774\ttotal: 11s\tremaining: 3.74s\n",
      "747:\tlearn: 1.8903650\ttotal: 11s\tremaining: 3.72s\n",
      "748:\tlearn: 1.8896170\ttotal: 11.1s\tremaining: 3.71s\n",
      "749:\tlearn: 1.8886624\ttotal: 11.1s\tremaining: 3.69s\n",
      "750:\tlearn: 1.8877696\ttotal: 11.1s\tremaining: 3.68s\n",
      "751:\tlearn: 1.8874428\ttotal: 11.1s\tremaining: 3.66s\n",
      "752:\tlearn: 1.8869622\ttotal: 11.1s\tremaining: 3.65s\n",
      "753:\tlearn: 1.8869205\ttotal: 11.1s\tremaining: 3.63s\n",
      "754:\tlearn: 1.8869177\ttotal: 11.2s\tremaining: 3.62s\n",
      "755:\tlearn: 1.8864469\ttotal: 11.2s\tremaining: 3.6s\n",
      "756:\tlearn: 1.8860462\ttotal: 11.2s\tremaining: 3.59s\n",
      "757:\tlearn: 1.8860370\ttotal: 11.2s\tremaining: 3.57s\n",
      "758:\tlearn: 1.8860351\ttotal: 11.2s\tremaining: 3.56s\n",
      "759:\tlearn: 1.8860343\ttotal: 11.2s\tremaining: 3.54s\n",
      "760:\tlearn: 1.8860324\ttotal: 11.2s\tremaining: 3.53s\n",
      "761:\tlearn: 1.8855008\ttotal: 11.3s\tremaining: 3.51s\n",
      "762:\tlearn: 1.8854952\ttotal: 11.3s\tremaining: 3.5s\n",
      "763:\tlearn: 1.8854897\ttotal: 11.3s\tremaining: 3.48s\n",
      "764:\tlearn: 1.8854897\ttotal: 11.3s\tremaining: 3.47s\n",
      "765:\tlearn: 1.8854301\ttotal: 11.3s\tremaining: 3.46s\n",
      "766:\tlearn: 1.8854268\ttotal: 11.3s\tremaining: 3.44s\n",
      "767:\tlearn: 1.8854167\ttotal: 11.3s\tremaining: 3.42s\n",
      "768:\tlearn: 1.8854123\ttotal: 11.4s\tremaining: 3.41s\n",
      "769:\tlearn: 1.8854028\ttotal: 11.4s\tremaining: 3.4s\n",
      "770:\tlearn: 1.8852698\ttotal: 11.4s\tremaining: 3.38s\n",
      "771:\tlearn: 1.8852304\ttotal: 11.4s\tremaining: 3.37s\n",
      "772:\tlearn: 1.8852282\ttotal: 11.4s\tremaining: 3.35s\n",
      "773:\tlearn: 1.8852271\ttotal: 11.4s\tremaining: 3.33s\n",
      "774:\tlearn: 1.8850229\ttotal: 11.4s\tremaining: 3.32s\n",
      "775:\tlearn: 1.8846822\ttotal: 11.5s\tremaining: 3.31s\n",
      "776:\tlearn: 1.8846819\ttotal: 11.5s\tremaining: 3.29s\n",
      "777:\tlearn: 1.8846818\ttotal: 11.5s\tremaining: 3.27s\n",
      "778:\tlearn: 1.8846818\ttotal: 11.5s\tremaining: 3.26s\n",
      "779:\tlearn: 1.8846817\ttotal: 11.5s\tremaining: 3.25s\n",
      "780:\tlearn: 1.8846817\ttotal: 11.5s\tremaining: 3.23s\n",
      "781:\tlearn: 1.8846816\ttotal: 11.5s\tremaining: 3.22s\n",
      "782:\tlearn: 1.8846369\ttotal: 11.6s\tremaining: 3.2s\n",
      "783:\tlearn: 1.8846312\ttotal: 11.6s\tremaining: 3.19s\n",
      "784:\tlearn: 1.8846312\ttotal: 11.6s\tremaining: 3.17s\n",
      "785:\tlearn: 1.8846310\ttotal: 11.6s\tremaining: 3.16s\n",
      "786:\tlearn: 1.8846305\ttotal: 11.6s\tremaining: 3.14s\n",
      "787:\tlearn: 1.8845644\ttotal: 11.6s\tremaining: 3.13s\n",
      "788:\tlearn: 1.8845478\ttotal: 11.6s\tremaining: 3.11s\n",
      "789:\tlearn: 1.8844754\ttotal: 11.6s\tremaining: 3.1s\n",
      "790:\tlearn: 1.8843757\ttotal: 11.7s\tremaining: 3.08s\n",
      "791:\tlearn: 1.8843735\ttotal: 11.7s\tremaining: 3.07s\n",
      "792:\tlearn: 1.8841907\ttotal: 11.7s\tremaining: 3.05s\n",
      "793:\tlearn: 1.8840547\ttotal: 11.7s\tremaining: 3.04s\n",
      "794:\tlearn: 1.8839708\ttotal: 11.7s\tremaining: 3.02s\n",
      "795:\tlearn: 1.8839540\ttotal: 11.7s\tremaining: 3.01s\n",
      "796:\tlearn: 1.8837057\ttotal: 11.8s\tremaining: 2.99s\n",
      "797:\tlearn: 1.8835141\ttotal: 11.8s\tremaining: 2.98s\n",
      "798:\tlearn: 1.8835016\ttotal: 11.8s\tremaining: 2.96s\n",
      "799:\tlearn: 1.8834843\ttotal: 11.8s\tremaining: 2.95s\n",
      "800:\tlearn: 1.8834176\ttotal: 11.8s\tremaining: 2.93s\n",
      "801:\tlearn: 1.8834176\ttotal: 11.8s\tremaining: 2.92s\n",
      "802:\tlearn: 1.8834175\ttotal: 11.8s\tremaining: 2.9s\n",
      "803:\tlearn: 1.8834169\ttotal: 11.8s\tremaining: 2.89s\n",
      "804:\tlearn: 1.8827212\ttotal: 11.9s\tremaining: 2.87s\n",
      "805:\tlearn: 1.8819911\ttotal: 11.9s\tremaining: 2.86s\n",
      "806:\tlearn: 1.8819895\ttotal: 11.9s\tremaining: 2.84s\n",
      "807:\tlearn: 1.8819861\ttotal: 11.9s\tremaining: 2.83s\n",
      "808:\tlearn: 1.8817751\ttotal: 11.9s\tremaining: 2.81s\n",
      "809:\tlearn: 1.8817630\ttotal: 11.9s\tremaining: 2.8s\n",
      "810:\tlearn: 1.8815591\ttotal: 12s\tremaining: 2.79s\n",
      "811:\tlearn: 1.8811345\ttotal: 12s\tremaining: 2.77s\n",
      "812:\tlearn: 1.8808013\ttotal: 12s\tremaining: 2.75s\n",
      "813:\tlearn: 1.8807308\ttotal: 12s\tremaining: 2.74s\n",
      "814:\tlearn: 1.8807295\ttotal: 12s\tremaining: 2.73s\n",
      "815:\tlearn: 1.8806883\ttotal: 12s\tremaining: 2.71s\n",
      "816:\tlearn: 1.8806269\ttotal: 12s\tremaining: 2.7s\n",
      "817:\tlearn: 1.8789344\ttotal: 12.1s\tremaining: 2.68s\n",
      "818:\tlearn: 1.8785105\ttotal: 12.1s\tremaining: 2.67s\n",
      "819:\tlearn: 1.8785086\ttotal: 12.1s\tremaining: 2.65s\n",
      "820:\tlearn: 1.8784563\ttotal: 12.1s\tremaining: 2.64s\n",
      "821:\tlearn: 1.8784457\ttotal: 12.1s\tremaining: 2.62s\n",
      "822:\tlearn: 1.8784448\ttotal: 12.1s\tremaining: 2.61s\n",
      "823:\tlearn: 1.8784395\ttotal: 12.1s\tremaining: 2.59s\n",
      "824:\tlearn: 1.8784369\ttotal: 12.1s\tremaining: 2.58s\n",
      "825:\tlearn: 1.8783913\ttotal: 12.2s\tremaining: 2.56s\n",
      "826:\tlearn: 1.8774781\ttotal: 12.2s\tremaining: 2.55s\n",
      "827:\tlearn: 1.8774153\ttotal: 12.2s\tremaining: 2.53s\n",
      "828:\tlearn: 1.8774014\ttotal: 12.2s\tremaining: 2.52s\n",
      "829:\tlearn: 1.8773685\ttotal: 12.2s\tremaining: 2.5s\n",
      "830:\tlearn: 1.8773629\ttotal: 12.2s\tremaining: 2.49s\n",
      "831:\tlearn: 1.8767375\ttotal: 12.2s\tremaining: 2.47s\n",
      "832:\tlearn: 1.8767024\ttotal: 12.3s\tremaining: 2.46s\n",
      "833:\tlearn: 1.8765791\ttotal: 12.3s\tremaining: 2.44s\n",
      "834:\tlearn: 1.8762683\ttotal: 12.3s\tremaining: 2.43s\n",
      "835:\tlearn: 1.8761942\ttotal: 12.3s\tremaining: 2.41s\n",
      "836:\tlearn: 1.8761849\ttotal: 12.3s\tremaining: 2.4s\n",
      "837:\tlearn: 1.8761797\ttotal: 12.3s\tremaining: 2.38s\n",
      "838:\tlearn: 1.8761330\ttotal: 12.3s\tremaining: 2.37s\n",
      "839:\tlearn: 1.8760916\ttotal: 12.4s\tremaining: 2.35s\n",
      "840:\tlearn: 1.8760735\ttotal: 12.4s\tremaining: 2.34s\n",
      "841:\tlearn: 1.8757093\ttotal: 12.4s\tremaining: 2.33s\n",
      "842:\tlearn: 1.8756927\ttotal: 12.4s\tremaining: 2.31s\n",
      "843:\tlearn: 1.8753171\ttotal: 12.4s\tremaining: 2.29s\n",
      "844:\tlearn: 1.8752572\ttotal: 12.4s\tremaining: 2.28s\n",
      "845:\tlearn: 1.8744615\ttotal: 12.4s\tremaining: 2.27s\n",
      "846:\tlearn: 1.8740483\ttotal: 12.5s\tremaining: 2.25s\n",
      "847:\tlearn: 1.8738398\ttotal: 12.5s\tremaining: 2.24s\n",
      "848:\tlearn: 1.8738397\ttotal: 12.5s\tremaining: 2.22s\n",
      "849:\tlearn: 1.8738396\ttotal: 12.5s\tremaining: 2.21s\n",
      "850:\tlearn: 1.8738395\ttotal: 12.5s\tremaining: 2.19s\n",
      "851:\tlearn: 1.8738394\ttotal: 12.5s\tremaining: 2.18s\n",
      "852:\tlearn: 1.8738283\ttotal: 12.5s\tremaining: 2.16s\n",
      "853:\tlearn: 1.8738275\ttotal: 12.6s\tremaining: 2.15s\n",
      "854:\tlearn: 1.8738275\ttotal: 12.6s\tremaining: 2.13s\n",
      "855:\tlearn: 1.8738275\ttotal: 12.6s\tremaining: 2.12s\n",
      "856:\tlearn: 1.8738161\ttotal: 12.6s\tremaining: 2.1s\n",
      "857:\tlearn: 1.8738054\ttotal: 12.6s\tremaining: 2.09s\n",
      "858:\tlearn: 1.8738051\ttotal: 12.6s\tremaining: 2.07s\n",
      "859:\tlearn: 1.8738050\ttotal: 12.6s\tremaining: 2.06s\n",
      "860:\tlearn: 1.8738047\ttotal: 12.7s\tremaining: 2.04s\n",
      "861:\tlearn: 1.8738006\ttotal: 12.7s\tremaining: 2.03s\n",
      "862:\tlearn: 1.8735519\ttotal: 12.7s\tremaining: 2.01s\n",
      "863:\tlearn: 1.8735127\ttotal: 12.7s\tremaining: 2s\n",
      "864:\tlearn: 1.8734863\ttotal: 12.7s\tremaining: 1.98s\n",
      "865:\tlearn: 1.8734641\ttotal: 12.7s\tremaining: 1.97s\n",
      "866:\tlearn: 1.8733628\ttotal: 12.7s\tremaining: 1.95s\n",
      "867:\tlearn: 1.8733163\ttotal: 12.8s\tremaining: 1.94s\n",
      "868:\tlearn: 1.8732879\ttotal: 12.8s\tremaining: 1.92s\n",
      "869:\tlearn: 1.8732611\ttotal: 12.8s\tremaining: 1.91s\n",
      "870:\tlearn: 1.8732534\ttotal: 12.8s\tremaining: 1.9s\n",
      "871:\tlearn: 1.8731841\ttotal: 12.8s\tremaining: 1.88s\n",
      "872:\tlearn: 1.8731523\ttotal: 12.8s\tremaining: 1.87s\n",
      "873:\tlearn: 1.8731407\ttotal: 12.8s\tremaining: 1.85s\n",
      "874:\tlearn: 1.8731379\ttotal: 12.9s\tremaining: 1.84s\n",
      "875:\tlearn: 1.8731357\ttotal: 12.9s\tremaining: 1.82s\n",
      "876:\tlearn: 1.8730954\ttotal: 12.9s\tremaining: 1.81s\n",
      "877:\tlearn: 1.8730919\ttotal: 12.9s\tremaining: 1.79s\n",
      "878:\tlearn: 1.8730909\ttotal: 12.9s\tremaining: 1.78s\n",
      "879:\tlearn: 1.8730909\ttotal: 12.9s\tremaining: 1.76s\n",
      "880:\tlearn: 1.8730744\ttotal: 12.9s\tremaining: 1.75s\n",
      "881:\tlearn: 1.8730744\ttotal: 13s\tremaining: 1.73s\n",
      "882:\tlearn: 1.8730743\ttotal: 13s\tremaining: 1.72s\n",
      "883:\tlearn: 1.8730712\ttotal: 13s\tremaining: 1.7s\n",
      "884:\tlearn: 1.8730712\ttotal: 13s\tremaining: 1.69s\n",
      "885:\tlearn: 1.8730702\ttotal: 13s\tremaining: 1.67s\n",
      "886:\tlearn: 1.8730692\ttotal: 13s\tremaining: 1.66s\n",
      "887:\tlearn: 1.8730692\ttotal: 13s\tremaining: 1.64s\n",
      "888:\tlearn: 1.8730473\ttotal: 13.1s\tremaining: 1.63s\n",
      "889:\tlearn: 1.8730442\ttotal: 13.1s\tremaining: 1.61s\n",
      "890:\tlearn: 1.8730435\ttotal: 13.1s\tremaining: 1.6s\n",
      "891:\tlearn: 1.8730434\ttotal: 13.1s\tremaining: 1.58s\n",
      "892:\tlearn: 1.8730434\ttotal: 13.1s\tremaining: 1.57s\n",
      "893:\tlearn: 1.8729931\ttotal: 13.1s\tremaining: 1.55s\n",
      "894:\tlearn: 1.8729297\ttotal: 13.1s\tremaining: 1.54s\n",
      "895:\tlearn: 1.8729176\ttotal: 13.1s\tremaining: 1.53s\n",
      "896:\tlearn: 1.8719418\ttotal: 13.2s\tremaining: 1.51s\n",
      "897:\tlearn: 1.8717096\ttotal: 13.2s\tremaining: 1.5s\n",
      "898:\tlearn: 1.8707970\ttotal: 13.2s\tremaining: 1.48s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899:\tlearn: 1.8707927\ttotal: 13.2s\tremaining: 1.47s\n",
      "900:\tlearn: 1.8707915\ttotal: 13.2s\tremaining: 1.45s\n",
      "901:\tlearn: 1.8707914\ttotal: 13.2s\tremaining: 1.44s\n",
      "902:\tlearn: 1.8707146\ttotal: 13.3s\tremaining: 1.42s\n",
      "903:\tlearn: 1.8703433\ttotal: 13.3s\tremaining: 1.41s\n",
      "904:\tlearn: 1.8692230\ttotal: 13.3s\tremaining: 1.39s\n",
      "905:\tlearn: 1.8692141\ttotal: 13.3s\tremaining: 1.38s\n",
      "906:\tlearn: 1.8689767\ttotal: 13.3s\tremaining: 1.36s\n",
      "907:\tlearn: 1.8689577\ttotal: 13.3s\tremaining: 1.35s\n",
      "908:\tlearn: 1.8689563\ttotal: 13.3s\tremaining: 1.33s\n",
      "909:\tlearn: 1.8681733\ttotal: 13.4s\tremaining: 1.32s\n",
      "910:\tlearn: 1.8681721\ttotal: 13.4s\tremaining: 1.3s\n",
      "911:\tlearn: 1.8681719\ttotal: 13.4s\tremaining: 1.29s\n",
      "912:\tlearn: 1.8681718\ttotal: 13.4s\tremaining: 1.28s\n",
      "913:\tlearn: 1.8681623\ttotal: 13.4s\tremaining: 1.26s\n",
      "914:\tlearn: 1.8681623\ttotal: 13.4s\tremaining: 1.25s\n",
      "915:\tlearn: 1.8681612\ttotal: 13.4s\tremaining: 1.23s\n",
      "916:\tlearn: 1.8681610\ttotal: 13.5s\tremaining: 1.22s\n",
      "917:\tlearn: 1.8681608\ttotal: 13.5s\tremaining: 1.2s\n",
      "918:\tlearn: 1.8681603\ttotal: 13.5s\tremaining: 1.19s\n",
      "919:\tlearn: 1.8681592\ttotal: 13.5s\tremaining: 1.17s\n",
      "920:\tlearn: 1.8680451\ttotal: 13.5s\tremaining: 1.16s\n",
      "921:\tlearn: 1.8677307\ttotal: 13.5s\tremaining: 1.14s\n",
      "922:\tlearn: 1.8677211\ttotal: 13.5s\tremaining: 1.13s\n",
      "923:\tlearn: 1.8677109\ttotal: 13.6s\tremaining: 1.11s\n",
      "924:\tlearn: 1.8676900\ttotal: 13.6s\tremaining: 1.1s\n",
      "925:\tlearn: 1.8675320\ttotal: 13.6s\tremaining: 1.08s\n",
      "926:\tlearn: 1.8668477\ttotal: 13.6s\tremaining: 1.07s\n",
      "927:\tlearn: 1.8666185\ttotal: 13.6s\tremaining: 1.05s\n",
      "928:\tlearn: 1.8666114\ttotal: 13.6s\tremaining: 1.04s\n",
      "929:\tlearn: 1.8664356\ttotal: 13.6s\tremaining: 1.03s\n",
      "930:\tlearn: 1.8664347\ttotal: 13.7s\tremaining: 1.01s\n",
      "931:\tlearn: 1.8664327\ttotal: 13.7s\tremaining: 997ms\n",
      "932:\tlearn: 1.8663880\ttotal: 13.7s\tremaining: 982ms\n",
      "933:\tlearn: 1.8663832\ttotal: 13.7s\tremaining: 968ms\n",
      "934:\tlearn: 1.8663750\ttotal: 13.7s\tremaining: 953ms\n",
      "935:\tlearn: 1.8663646\ttotal: 13.7s\tremaining: 938ms\n",
      "936:\tlearn: 1.8663525\ttotal: 13.7s\tremaining: 924ms\n",
      "937:\tlearn: 1.8658604\ttotal: 13.8s\tremaining: 909ms\n",
      "938:\tlearn: 1.8648721\ttotal: 13.8s\tremaining: 894ms\n",
      "939:\tlearn: 1.8648719\ttotal: 13.8s\tremaining: 880ms\n",
      "940:\tlearn: 1.8648218\ttotal: 13.8s\tremaining: 865ms\n",
      "941:\tlearn: 1.8647500\ttotal: 13.8s\tremaining: 850ms\n",
      "942:\tlearn: 1.8647309\ttotal: 13.8s\tremaining: 836ms\n",
      "943:\tlearn: 1.8640914\ttotal: 13.8s\tremaining: 821ms\n",
      "944:\tlearn: 1.8640873\ttotal: 13.9s\tremaining: 806ms\n",
      "945:\tlearn: 1.8638255\ttotal: 13.9s\tremaining: 792ms\n",
      "946:\tlearn: 1.8636525\ttotal: 13.9s\tremaining: 777ms\n",
      "947:\tlearn: 1.8633845\ttotal: 13.9s\tremaining: 762ms\n",
      "948:\tlearn: 1.8629846\ttotal: 13.9s\tremaining: 748ms\n",
      "949:\tlearn: 1.8625363\ttotal: 13.9s\tremaining: 733ms\n",
      "950:\tlearn: 1.8616865\ttotal: 13.9s\tremaining: 718ms\n",
      "951:\tlearn: 1.8612540\ttotal: 14s\tremaining: 703ms\n",
      "952:\tlearn: 1.8605289\ttotal: 14s\tremaining: 689ms\n",
      "953:\tlearn: 1.8605281\ttotal: 14s\tremaining: 674ms\n",
      "954:\tlearn: 1.8605184\ttotal: 14s\tremaining: 659ms\n",
      "955:\tlearn: 1.8604793\ttotal: 14s\tremaining: 645ms\n",
      "956:\tlearn: 1.8602602\ttotal: 14s\tremaining: 630ms\n",
      "957:\tlearn: 1.8598645\ttotal: 14s\tremaining: 615ms\n",
      "958:\tlearn: 1.8596595\ttotal: 14.1s\tremaining: 601ms\n",
      "959:\tlearn: 1.8595855\ttotal: 14.1s\tremaining: 586ms\n",
      "960:\tlearn: 1.8595453\ttotal: 14.1s\tremaining: 571ms\n",
      "961:\tlearn: 1.8594948\ttotal: 14.1s\tremaining: 557ms\n",
      "962:\tlearn: 1.8590421\ttotal: 14.1s\tremaining: 542ms\n",
      "963:\tlearn: 1.8588653\ttotal: 14.1s\tremaining: 527ms\n",
      "964:\tlearn: 1.8588529\ttotal: 14.1s\tremaining: 513ms\n",
      "965:\tlearn: 1.8584025\ttotal: 14.2s\tremaining: 498ms\n",
      "966:\tlearn: 1.8583491\ttotal: 14.2s\tremaining: 483ms\n",
      "967:\tlearn: 1.8576168\ttotal: 14.2s\tremaining: 469ms\n",
      "968:\tlearn: 1.8571341\ttotal: 14.2s\tremaining: 454ms\n",
      "969:\tlearn: 1.8571318\ttotal: 14.2s\tremaining: 439ms\n",
      "970:\tlearn: 1.8571245\ttotal: 14.2s\tremaining: 425ms\n",
      "971:\tlearn: 1.8571245\ttotal: 14.2s\tremaining: 410ms\n",
      "972:\tlearn: 1.8570315\ttotal: 14.2s\tremaining: 395ms\n",
      "973:\tlearn: 1.8568794\ttotal: 14.3s\tremaining: 381ms\n",
      "974:\tlearn: 1.8568671\ttotal: 14.3s\tremaining: 366ms\n",
      "975:\tlearn: 1.8564506\ttotal: 14.3s\tremaining: 351ms\n",
      "976:\tlearn: 1.8561293\ttotal: 14.3s\tremaining: 337ms\n",
      "977:\tlearn: 1.8559376\ttotal: 14.3s\tremaining: 322ms\n",
      "978:\tlearn: 1.8557933\ttotal: 14.3s\tremaining: 308ms\n",
      "979:\tlearn: 1.8557928\ttotal: 14.3s\tremaining: 293ms\n",
      "980:\tlearn: 1.8557455\ttotal: 14.4s\tremaining: 278ms\n",
      "981:\tlearn: 1.8548422\ttotal: 14.4s\tremaining: 264ms\n",
      "982:\tlearn: 1.8547953\ttotal: 14.4s\tremaining: 249ms\n",
      "983:\tlearn: 1.8547950\ttotal: 14.4s\tremaining: 234ms\n",
      "984:\tlearn: 1.8547941\ttotal: 14.4s\tremaining: 220ms\n",
      "985:\tlearn: 1.8543491\ttotal: 14.4s\tremaining: 205ms\n",
      "986:\tlearn: 1.8543491\ttotal: 14.4s\tremaining: 190ms\n",
      "987:\tlearn: 1.8543204\ttotal: 14.5s\tremaining: 176ms\n",
      "988:\tlearn: 1.8543200\ttotal: 14.5s\tremaining: 161ms\n",
      "989:\tlearn: 1.8542414\ttotal: 14.5s\tremaining: 146ms\n",
      "990:\tlearn: 1.8542204\ttotal: 14.5s\tremaining: 132ms\n",
      "991:\tlearn: 1.8541740\ttotal: 14.5s\tremaining: 117ms\n",
      "992:\tlearn: 1.8539764\ttotal: 14.5s\tremaining: 102ms\n",
      "993:\tlearn: 1.8539587\ttotal: 14.5s\tremaining: 87.8ms\n",
      "994:\tlearn: 1.8538541\ttotal: 14.6s\tremaining: 73.2ms\n",
      "995:\tlearn: 1.8538086\ttotal: 14.6s\tremaining: 58.5ms\n",
      "996:\tlearn: 1.8538065\ttotal: 14.6s\tremaining: 43.9ms\n",
      "997:\tlearn: 1.8537588\ttotal: 14.6s\tremaining: 29.3ms\n",
      "998:\tlearn: 1.8531897\ttotal: 14.6s\tremaining: 14.6ms\n",
      "999:\tlearn: 1.8516498\ttotal: 14.6s\tremaining: 0us\n",
      "0:\tlearn: 9.9489420\ttotal: 17.7ms\tremaining: 17.6s\n",
      "1:\tlearn: 9.0684927\ttotal: 35.2ms\tremaining: 17.5s\n",
      "2:\tlearn: 8.4538210\ttotal: 49.5ms\tremaining: 16.4s\n",
      "3:\tlearn: 7.7298420\ttotal: 65.7ms\tremaining: 16.4s\n",
      "4:\tlearn: 7.0895111\ttotal: 81.6ms\tremaining: 16.2s\n",
      "5:\tlearn: 6.6595027\ttotal: 97.1ms\tremaining: 16.1s\n",
      "6:\tlearn: 6.1174334\ttotal: 112ms\tremaining: 15.9s\n",
      "7:\tlearn: 5.7238521\ttotal: 127ms\tremaining: 15.7s\n",
      "8:\tlearn: 5.2933390\ttotal: 141ms\tremaining: 15.5s\n",
      "9:\tlearn: 4.9035462\ttotal: 155ms\tremaining: 15.4s\n",
      "10:\tlearn: 4.5628077\ttotal: 170ms\tremaining: 15.2s\n",
      "11:\tlearn: 4.2520875\ttotal: 183ms\tremaining: 15.1s\n",
      "12:\tlearn: 3.9881473\ttotal: 197ms\tremaining: 15s\n",
      "13:\tlearn: 3.7826559\ttotal: 211ms\tremaining: 14.9s\n",
      "14:\tlearn: 3.6349228\ttotal: 224ms\tremaining: 14.7s\n",
      "15:\tlearn: 3.4491583\ttotal: 239ms\tremaining: 14.7s\n",
      "16:\tlearn: 3.3037024\ttotal: 252ms\tremaining: 14.6s\n",
      "17:\tlearn: 3.1729983\ttotal: 266ms\tremaining: 14.5s\n",
      "18:\tlearn: 3.0885419\ttotal: 280ms\tremaining: 14.4s\n",
      "19:\tlearn: 2.9864971\ttotal: 293ms\tremaining: 14.4s\n",
      "20:\tlearn: 2.9121070\ttotal: 307ms\tremaining: 14.3s\n",
      "21:\tlearn: 2.8526739\ttotal: 321ms\tremaining: 14.3s\n",
      "22:\tlearn: 2.8007504\ttotal: 334ms\tremaining: 14.2s\n",
      "23:\tlearn: 2.7330946\ttotal: 347ms\tremaining: 14.1s\n",
      "24:\tlearn: 2.6747480\ttotal: 361ms\tremaining: 14.1s\n",
      "25:\tlearn: 2.6443929\ttotal: 374ms\tremaining: 14s\n",
      "26:\tlearn: 2.6121574\ttotal: 387ms\tremaining: 13.9s\n",
      "27:\tlearn: 2.5860594\ttotal: 400ms\tremaining: 13.9s\n",
      "28:\tlearn: 2.5445919\ttotal: 412ms\tremaining: 13.8s\n",
      "29:\tlearn: 2.5159992\ttotal: 426ms\tremaining: 13.8s\n",
      "30:\tlearn: 2.4925562\ttotal: 439ms\tremaining: 13.7s\n",
      "31:\tlearn: 2.4633116\ttotal: 454ms\tremaining: 13.7s\n",
      "32:\tlearn: 2.4499699\ttotal: 467ms\tremaining: 13.7s\n",
      "33:\tlearn: 2.4250337\ttotal: 481ms\tremaining: 13.7s\n",
      "34:\tlearn: 2.4144455\ttotal: 494ms\tremaining: 13.6s\n",
      "35:\tlearn: 2.3851942\ttotal: 507ms\tremaining: 13.6s\n",
      "36:\tlearn: 2.3753973\ttotal: 521ms\tremaining: 13.6s\n",
      "37:\tlearn: 2.3616695\ttotal: 534ms\tremaining: 13.5s\n",
      "38:\tlearn: 2.3544580\ttotal: 547ms\tremaining: 13.5s\n",
      "39:\tlearn: 2.3450926\ttotal: 560ms\tremaining: 13.4s\n",
      "40:\tlearn: 2.3391744\ttotal: 574ms\tremaining: 13.4s\n",
      "41:\tlearn: 2.3360188\ttotal: 587ms\tremaining: 13.4s\n",
      "42:\tlearn: 2.3160274\ttotal: 601ms\tremaining: 13.4s\n",
      "43:\tlearn: 2.3126130\ttotal: 614ms\tremaining: 13.3s\n",
      "44:\tlearn: 2.3098847\ttotal: 626ms\tremaining: 13.3s\n",
      "45:\tlearn: 2.2951448\ttotal: 640ms\tremaining: 13.3s\n",
      "46:\tlearn: 2.2925367\ttotal: 655ms\tremaining: 13.3s\n",
      "47:\tlearn: 2.2897962\ttotal: 669ms\tremaining: 13.3s\n",
      "48:\tlearn: 2.2877997\ttotal: 682ms\tremaining: 13.2s\n",
      "49:\tlearn: 2.2829495\ttotal: 695ms\tremaining: 13.2s\n",
      "50:\tlearn: 2.2817160\ttotal: 709ms\tremaining: 13.2s\n",
      "51:\tlearn: 2.2742446\ttotal: 722ms\tremaining: 13.2s\n",
      "52:\tlearn: 2.2726287\ttotal: 734ms\tremaining: 13.1s\n",
      "53:\tlearn: 2.2706099\ttotal: 747ms\tremaining: 13.1s\n",
      "54:\tlearn: 2.2695289\ttotal: 761ms\tremaining: 13.1s\n",
      "55:\tlearn: 2.2646228\ttotal: 774ms\tremaining: 13s\n",
      "56:\tlearn: 2.2636979\ttotal: 786ms\tremaining: 13s\n",
      "57:\tlearn: 2.2586956\ttotal: 799ms\tremaining: 13s\n",
      "58:\tlearn: 2.2579083\ttotal: 811ms\tremaining: 12.9s\n",
      "59:\tlearn: 2.2573681\ttotal: 824ms\tremaining: 12.9s\n",
      "60:\tlearn: 2.2569212\ttotal: 837ms\tremaining: 12.9s\n",
      "61:\tlearn: 2.2557164\ttotal: 850ms\tremaining: 12.9s\n",
      "62:\tlearn: 2.2551887\ttotal: 863ms\tremaining: 12.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63:\tlearn: 2.2546493\ttotal: 878ms\tremaining: 12.8s\n",
      "64:\tlearn: 2.2537964\ttotal: 892ms\tremaining: 12.8s\n",
      "65:\tlearn: 2.2520912\ttotal: 905ms\tremaining: 12.8s\n",
      "66:\tlearn: 2.2517816\ttotal: 918ms\tremaining: 12.8s\n",
      "67:\tlearn: 2.2505599\ttotal: 931ms\tremaining: 12.8s\n",
      "68:\tlearn: 2.2493545\ttotal: 944ms\tremaining: 12.7s\n",
      "69:\tlearn: 2.2431102\ttotal: 957ms\tremaining: 12.7s\n",
      "70:\tlearn: 2.2423481\ttotal: 971ms\tremaining: 12.7s\n",
      "71:\tlearn: 2.2417701\ttotal: 983ms\tremaining: 12.7s\n",
      "72:\tlearn: 2.2404211\ttotal: 997ms\tremaining: 12.7s\n",
      "73:\tlearn: 2.2394677\ttotal: 1.01s\tremaining: 12.6s\n",
      "74:\tlearn: 2.2356088\ttotal: 1.02s\tremaining: 12.6s\n",
      "75:\tlearn: 2.2274752\ttotal: 1.04s\tremaining: 12.6s\n",
      "76:\tlearn: 2.2262584\ttotal: 1.05s\tremaining: 12.6s\n",
      "77:\tlearn: 2.2256307\ttotal: 1.06s\tremaining: 12.6s\n",
      "78:\tlearn: 2.2244745\ttotal: 1.08s\tremaining: 12.6s\n",
      "79:\tlearn: 2.2179540\ttotal: 1.09s\tremaining: 12.6s\n",
      "80:\tlearn: 2.2168237\ttotal: 1.1s\tremaining: 12.5s\n",
      "81:\tlearn: 2.2164597\ttotal: 1.12s\tremaining: 12.5s\n",
      "82:\tlearn: 2.2164160\ttotal: 1.13s\tremaining: 12.5s\n",
      "83:\tlearn: 2.2153599\ttotal: 1.14s\tremaining: 12.5s\n",
      "84:\tlearn: 2.2145063\ttotal: 1.16s\tremaining: 12.4s\n",
      "85:\tlearn: 2.2120130\ttotal: 1.17s\tremaining: 12.4s\n",
      "86:\tlearn: 2.2100084\ttotal: 1.18s\tremaining: 12.4s\n",
      "87:\tlearn: 2.2098672\ttotal: 1.2s\tremaining: 12.4s\n",
      "88:\tlearn: 2.2094062\ttotal: 1.21s\tremaining: 12.4s\n",
      "89:\tlearn: 2.2092143\ttotal: 1.22s\tremaining: 12.4s\n",
      "90:\tlearn: 2.2078157\ttotal: 1.24s\tremaining: 12.4s\n",
      "91:\tlearn: 2.2075374\ttotal: 1.25s\tremaining: 12.3s\n",
      "92:\tlearn: 2.2036895\ttotal: 1.26s\tremaining: 12.3s\n",
      "93:\tlearn: 2.2033529\ttotal: 1.27s\tremaining: 12.3s\n",
      "94:\tlearn: 2.2025153\ttotal: 1.29s\tremaining: 12.3s\n",
      "95:\tlearn: 2.2020064\ttotal: 1.3s\tremaining: 12.3s\n",
      "96:\tlearn: 2.2018231\ttotal: 1.32s\tremaining: 12.3s\n",
      "97:\tlearn: 2.2013540\ttotal: 1.33s\tremaining: 12.2s\n",
      "98:\tlearn: 2.2007341\ttotal: 1.34s\tremaining: 12.2s\n",
      "99:\tlearn: 2.2005548\ttotal: 1.36s\tremaining: 12.2s\n",
      "100:\tlearn: 2.1998081\ttotal: 1.37s\tremaining: 12.2s\n",
      "101:\tlearn: 2.1987063\ttotal: 1.38s\tremaining: 12.2s\n",
      "102:\tlearn: 2.1978357\ttotal: 1.39s\tremaining: 12.1s\n",
      "103:\tlearn: 2.1968051\ttotal: 1.41s\tremaining: 12.1s\n",
      "104:\tlearn: 2.1965387\ttotal: 1.42s\tremaining: 12.1s\n",
      "105:\tlearn: 2.1961991\ttotal: 1.43s\tremaining: 12.1s\n",
      "106:\tlearn: 2.1943158\ttotal: 1.45s\tremaining: 12.1s\n",
      "107:\tlearn: 2.1913405\ttotal: 1.46s\tremaining: 12.1s\n",
      "108:\tlearn: 2.1910104\ttotal: 1.47s\tremaining: 12s\n",
      "109:\tlearn: 2.1860230\ttotal: 1.49s\tremaining: 12s\n",
      "110:\tlearn: 2.1857919\ttotal: 1.5s\tremaining: 12s\n",
      "111:\tlearn: 2.1853734\ttotal: 1.51s\tremaining: 12s\n",
      "112:\tlearn: 2.1851944\ttotal: 1.52s\tremaining: 12s\n",
      "113:\tlearn: 2.1850655\ttotal: 1.54s\tremaining: 12s\n",
      "114:\tlearn: 2.1843197\ttotal: 1.55s\tremaining: 11.9s\n",
      "115:\tlearn: 2.1824809\ttotal: 1.56s\tremaining: 11.9s\n",
      "116:\tlearn: 2.1819529\ttotal: 1.58s\tremaining: 11.9s\n",
      "117:\tlearn: 2.1783790\ttotal: 1.59s\tremaining: 11.9s\n",
      "118:\tlearn: 2.1780321\ttotal: 1.6s\tremaining: 11.9s\n",
      "119:\tlearn: 2.1776712\ttotal: 1.62s\tremaining: 11.9s\n",
      "120:\tlearn: 2.1772480\ttotal: 1.63s\tremaining: 11.8s\n",
      "121:\tlearn: 2.1763268\ttotal: 1.64s\tremaining: 11.8s\n",
      "122:\tlearn: 2.1762790\ttotal: 1.66s\tremaining: 11.8s\n",
      "123:\tlearn: 2.1758880\ttotal: 1.67s\tremaining: 11.8s\n",
      "124:\tlearn: 2.1752959\ttotal: 1.68s\tremaining: 11.8s\n",
      "125:\tlearn: 2.1748227\ttotal: 1.7s\tremaining: 11.8s\n",
      "126:\tlearn: 2.1671480\ttotal: 1.71s\tremaining: 11.7s\n",
      "127:\tlearn: 2.1654029\ttotal: 1.72s\tremaining: 11.7s\n",
      "128:\tlearn: 2.1615356\ttotal: 1.74s\tremaining: 11.7s\n",
      "129:\tlearn: 2.1555891\ttotal: 1.75s\tremaining: 11.7s\n",
      "130:\tlearn: 2.1541481\ttotal: 1.76s\tremaining: 11.7s\n",
      "131:\tlearn: 2.1524332\ttotal: 1.78s\tremaining: 11.7s\n",
      "132:\tlearn: 2.1486197\ttotal: 1.79s\tremaining: 11.7s\n",
      "133:\tlearn: 2.1474773\ttotal: 1.8s\tremaining: 11.7s\n",
      "134:\tlearn: 2.1466256\ttotal: 1.82s\tremaining: 11.6s\n",
      "135:\tlearn: 2.1396066\ttotal: 1.83s\tremaining: 11.6s\n",
      "136:\tlearn: 2.1392323\ttotal: 1.84s\tremaining: 11.6s\n",
      "137:\tlearn: 2.1366423\ttotal: 1.85s\tremaining: 11.6s\n",
      "138:\tlearn: 2.1351954\ttotal: 1.87s\tremaining: 11.6s\n",
      "139:\tlearn: 2.1344097\ttotal: 1.88s\tremaining: 11.6s\n",
      "140:\tlearn: 2.1337646\ttotal: 1.9s\tremaining: 11.5s\n",
      "141:\tlearn: 2.1311008\ttotal: 1.91s\tremaining: 11.5s\n",
      "142:\tlearn: 2.1304175\ttotal: 1.92s\tremaining: 11.5s\n",
      "143:\tlearn: 2.1293129\ttotal: 1.93s\tremaining: 11.5s\n",
      "144:\tlearn: 2.1258478\ttotal: 1.95s\tremaining: 11.5s\n",
      "145:\tlearn: 2.1215646\ttotal: 1.96s\tremaining: 11.5s\n",
      "146:\tlearn: 2.1204691\ttotal: 1.98s\tremaining: 11.5s\n",
      "147:\tlearn: 2.1187660\ttotal: 1.99s\tremaining: 11.4s\n",
      "148:\tlearn: 2.1145984\ttotal: 2s\tremaining: 11.4s\n",
      "149:\tlearn: 2.1129493\ttotal: 2.02s\tremaining: 11.4s\n",
      "150:\tlearn: 2.1112084\ttotal: 2.03s\tremaining: 11.4s\n",
      "151:\tlearn: 2.1094279\ttotal: 2.04s\tremaining: 11.4s\n",
      "152:\tlearn: 2.1025698\ttotal: 2.05s\tremaining: 11.4s\n",
      "153:\tlearn: 2.0995698\ttotal: 2.07s\tremaining: 11.4s\n",
      "154:\tlearn: 2.0977850\ttotal: 2.08s\tremaining: 11.3s\n",
      "155:\tlearn: 2.0928826\ttotal: 2.09s\tremaining: 11.3s\n",
      "156:\tlearn: 2.0900366\ttotal: 2.1s\tremaining: 11.3s\n",
      "157:\tlearn: 2.0883629\ttotal: 2.12s\tremaining: 11.3s\n",
      "158:\tlearn: 2.0833555\ttotal: 2.13s\tremaining: 11.3s\n",
      "159:\tlearn: 2.0802134\ttotal: 2.15s\tremaining: 11.3s\n",
      "160:\tlearn: 2.0769116\ttotal: 2.16s\tremaining: 11.3s\n",
      "161:\tlearn: 2.0753476\ttotal: 2.17s\tremaining: 11.2s\n",
      "162:\tlearn: 2.0734989\ttotal: 2.19s\tremaining: 11.2s\n",
      "163:\tlearn: 2.0710493\ttotal: 2.2s\tremaining: 11.2s\n",
      "164:\tlearn: 2.0688431\ttotal: 2.21s\tremaining: 11.2s\n",
      "165:\tlearn: 2.0647663\ttotal: 2.23s\tremaining: 11.2s\n",
      "166:\tlearn: 2.0641377\ttotal: 2.24s\tremaining: 11.2s\n",
      "167:\tlearn: 2.0629509\ttotal: 2.25s\tremaining: 11.2s\n",
      "168:\tlearn: 2.0600935\ttotal: 2.27s\tremaining: 11.1s\n",
      "169:\tlearn: 2.0571909\ttotal: 2.28s\tremaining: 11.1s\n",
      "170:\tlearn: 2.0559116\ttotal: 2.29s\tremaining: 11.1s\n",
      "171:\tlearn: 2.0532117\ttotal: 2.31s\tremaining: 11.1s\n",
      "172:\tlearn: 2.0503505\ttotal: 2.32s\tremaining: 11.1s\n",
      "173:\tlearn: 2.0495864\ttotal: 2.33s\tremaining: 11.1s\n",
      "174:\tlearn: 2.0472109\ttotal: 2.34s\tremaining: 11.1s\n",
      "175:\tlearn: 2.0452108\ttotal: 2.36s\tremaining: 11s\n",
      "176:\tlearn: 2.0435819\ttotal: 2.37s\tremaining: 11s\n",
      "177:\tlearn: 2.0424246\ttotal: 2.38s\tremaining: 11s\n",
      "178:\tlearn: 2.0416596\ttotal: 2.4s\tremaining: 11s\n",
      "179:\tlearn: 2.0402792\ttotal: 2.41s\tremaining: 11s\n",
      "180:\tlearn: 2.0394453\ttotal: 2.42s\tremaining: 11s\n",
      "181:\tlearn: 2.0387053\ttotal: 2.44s\tremaining: 11s\n",
      "182:\tlearn: 2.0379647\ttotal: 2.45s\tremaining: 10.9s\n",
      "183:\tlearn: 2.0363919\ttotal: 2.46s\tremaining: 10.9s\n",
      "184:\tlearn: 2.0361922\ttotal: 2.48s\tremaining: 10.9s\n",
      "185:\tlearn: 2.0355055\ttotal: 2.49s\tremaining: 10.9s\n",
      "186:\tlearn: 2.0324068\ttotal: 2.5s\tremaining: 10.9s\n",
      "187:\tlearn: 2.0316721\ttotal: 2.52s\tremaining: 10.9s\n",
      "188:\tlearn: 2.0296420\ttotal: 2.53s\tremaining: 10.9s\n",
      "189:\tlearn: 2.0279105\ttotal: 2.54s\tremaining: 10.8s\n",
      "190:\tlearn: 2.0274978\ttotal: 2.56s\tremaining: 10.8s\n",
      "191:\tlearn: 2.0253354\ttotal: 2.57s\tremaining: 10.8s\n",
      "192:\tlearn: 2.0246406\ttotal: 2.58s\tremaining: 10.8s\n",
      "193:\tlearn: 2.0238478\ttotal: 2.6s\tremaining: 10.8s\n",
      "194:\tlearn: 2.0220239\ttotal: 2.61s\tremaining: 10.8s\n",
      "195:\tlearn: 2.0216887\ttotal: 2.62s\tremaining: 10.8s\n",
      "196:\tlearn: 2.0196953\ttotal: 2.64s\tremaining: 10.7s\n",
      "197:\tlearn: 2.0192223\ttotal: 2.65s\tremaining: 10.7s\n",
      "198:\tlearn: 2.0184822\ttotal: 2.66s\tremaining: 10.7s\n",
      "199:\tlearn: 2.0180001\ttotal: 2.67s\tremaining: 10.7s\n",
      "200:\tlearn: 2.0166391\ttotal: 2.69s\tremaining: 10.7s\n",
      "201:\tlearn: 2.0150757\ttotal: 2.7s\tremaining: 10.7s\n",
      "202:\tlearn: 2.0142112\ttotal: 2.71s\tremaining: 10.7s\n",
      "203:\tlearn: 2.0131769\ttotal: 2.73s\tremaining: 10.6s\n",
      "204:\tlearn: 2.0120863\ttotal: 2.74s\tremaining: 10.6s\n",
      "205:\tlearn: 2.0116554\ttotal: 2.75s\tremaining: 10.6s\n",
      "206:\tlearn: 2.0101821\ttotal: 2.77s\tremaining: 10.6s\n",
      "207:\tlearn: 2.0101617\ttotal: 2.78s\tremaining: 10.6s\n",
      "208:\tlearn: 2.0097744\ttotal: 2.79s\tremaining: 10.6s\n",
      "209:\tlearn: 2.0096951\ttotal: 2.8s\tremaining: 10.5s\n",
      "210:\tlearn: 2.0096595\ttotal: 2.82s\tremaining: 10.5s\n",
      "211:\tlearn: 2.0084010\ttotal: 2.83s\tremaining: 10.5s\n",
      "212:\tlearn: 2.0059713\ttotal: 2.84s\tremaining: 10.5s\n",
      "213:\tlearn: 2.0056016\ttotal: 2.85s\tremaining: 10.5s\n",
      "214:\tlearn: 2.0044115\ttotal: 2.87s\tremaining: 10.5s\n",
      "215:\tlearn: 2.0044109\ttotal: 2.88s\tremaining: 10.5s\n",
      "216:\tlearn: 2.0037241\ttotal: 2.89s\tremaining: 10.4s\n",
      "217:\tlearn: 2.0032575\ttotal: 2.91s\tremaining: 10.4s\n",
      "218:\tlearn: 2.0030333\ttotal: 2.92s\tremaining: 10.4s\n",
      "219:\tlearn: 2.0029642\ttotal: 2.93s\tremaining: 10.4s\n",
      "220:\tlearn: 2.0007694\ttotal: 2.95s\tremaining: 10.4s\n",
      "221:\tlearn: 1.9982693\ttotal: 2.96s\tremaining: 10.4s\n",
      "222:\tlearn: 1.9982466\ttotal: 2.97s\tremaining: 10.4s\n",
      "223:\tlearn: 1.9980699\ttotal: 2.98s\tremaining: 10.3s\n",
      "224:\tlearn: 1.9979367\ttotal: 3s\tremaining: 10.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225:\tlearn: 1.9978438\ttotal: 3.01s\tremaining: 10.3s\n",
      "226:\tlearn: 1.9978288\ttotal: 3.03s\tremaining: 10.3s\n",
      "227:\tlearn: 1.9977816\ttotal: 3.04s\tremaining: 10.3s\n",
      "228:\tlearn: 1.9968901\ttotal: 3.05s\tremaining: 10.3s\n",
      "229:\tlearn: 1.9962291\ttotal: 3.06s\tremaining: 10.3s\n",
      "230:\tlearn: 1.9957304\ttotal: 3.08s\tremaining: 10.2s\n",
      "231:\tlearn: 1.9954468\ttotal: 3.09s\tremaining: 10.2s\n",
      "232:\tlearn: 1.9937131\ttotal: 3.1s\tremaining: 10.2s\n",
      "233:\tlearn: 1.9936259\ttotal: 3.12s\tremaining: 10.2s\n",
      "234:\tlearn: 1.9930193\ttotal: 3.13s\tremaining: 10.2s\n",
      "235:\tlearn: 1.9929044\ttotal: 3.14s\tremaining: 10.2s\n",
      "236:\tlearn: 1.9928214\ttotal: 3.15s\tremaining: 10.2s\n",
      "237:\tlearn: 1.9924702\ttotal: 3.17s\tremaining: 10.1s\n",
      "238:\tlearn: 1.9921302\ttotal: 3.18s\tremaining: 10.1s\n",
      "239:\tlearn: 1.9921267\ttotal: 3.19s\tremaining: 10.1s\n",
      "240:\tlearn: 1.9920671\ttotal: 3.21s\tremaining: 10.1s\n",
      "241:\tlearn: 1.9920542\ttotal: 3.22s\tremaining: 10.1s\n",
      "242:\tlearn: 1.9912266\ttotal: 3.23s\tremaining: 10.1s\n",
      "243:\tlearn: 1.9903399\ttotal: 3.25s\tremaining: 10.1s\n",
      "244:\tlearn: 1.9896574\ttotal: 3.26s\tremaining: 10s\n",
      "245:\tlearn: 1.9895733\ttotal: 3.27s\tremaining: 10s\n",
      "246:\tlearn: 1.9895507\ttotal: 3.29s\tremaining: 10s\n",
      "247:\tlearn: 1.9885027\ttotal: 3.3s\tremaining: 10s\n",
      "248:\tlearn: 1.9881980\ttotal: 3.31s\tremaining: 9.99s\n",
      "249:\tlearn: 1.9881625\ttotal: 3.33s\tremaining: 9.97s\n",
      "250:\tlearn: 1.9879030\ttotal: 3.34s\tremaining: 9.96s\n",
      "251:\tlearn: 1.9862204\ttotal: 3.35s\tremaining: 9.95s\n",
      "252:\tlearn: 1.9844665\ttotal: 3.36s\tremaining: 9.93s\n",
      "253:\tlearn: 1.9827259\ttotal: 3.38s\tremaining: 9.92s\n",
      "254:\tlearn: 1.9816571\ttotal: 3.39s\tremaining: 9.91s\n",
      "255:\tlearn: 1.9790650\ttotal: 3.4s\tremaining: 9.89s\n",
      "256:\tlearn: 1.9787501\ttotal: 3.42s\tremaining: 9.88s\n",
      "257:\tlearn: 1.9770646\ttotal: 3.43s\tremaining: 9.87s\n",
      "258:\tlearn: 1.9770235\ttotal: 3.45s\tremaining: 9.86s\n",
      "259:\tlearn: 1.9769197\ttotal: 3.46s\tremaining: 9.85s\n",
      "260:\tlearn: 1.9757585\ttotal: 3.47s\tremaining: 9.83s\n",
      "261:\tlearn: 1.9748840\ttotal: 3.48s\tremaining: 9.82s\n",
      "262:\tlearn: 1.9719470\ttotal: 3.5s\tremaining: 9.8s\n",
      "263:\tlearn: 1.9713191\ttotal: 3.51s\tremaining: 9.79s\n",
      "264:\tlearn: 1.9706195\ttotal: 3.52s\tremaining: 9.78s\n",
      "265:\tlearn: 1.9690910\ttotal: 3.54s\tremaining: 9.76s\n",
      "266:\tlearn: 1.9682384\ttotal: 3.55s\tremaining: 9.75s\n",
      "267:\tlearn: 1.9675204\ttotal: 3.56s\tremaining: 9.74s\n",
      "268:\tlearn: 1.9643540\ttotal: 3.58s\tremaining: 9.72s\n",
      "269:\tlearn: 1.9635624\ttotal: 3.59s\tremaining: 9.71s\n",
      "270:\tlearn: 1.9622888\ttotal: 3.6s\tremaining: 9.69s\n",
      "271:\tlearn: 1.9617288\ttotal: 3.62s\tremaining: 9.68s\n",
      "272:\tlearn: 1.9611001\ttotal: 3.63s\tremaining: 9.66s\n",
      "273:\tlearn: 1.9603078\ttotal: 3.64s\tremaining: 9.65s\n",
      "274:\tlearn: 1.9602878\ttotal: 3.66s\tremaining: 9.64s\n",
      "275:\tlearn: 1.9599354\ttotal: 3.67s\tremaining: 9.63s\n",
      "276:\tlearn: 1.9589888\ttotal: 3.68s\tremaining: 9.62s\n",
      "277:\tlearn: 1.9589629\ttotal: 3.7s\tremaining: 9.6s\n",
      "278:\tlearn: 1.9580985\ttotal: 3.71s\tremaining: 9.59s\n",
      "279:\tlearn: 1.9569077\ttotal: 3.72s\tremaining: 9.57s\n",
      "280:\tlearn: 1.9551143\ttotal: 3.74s\tremaining: 9.56s\n",
      "281:\tlearn: 1.9535945\ttotal: 3.75s\tremaining: 9.55s\n",
      "282:\tlearn: 1.9524685\ttotal: 3.76s\tremaining: 9.54s\n",
      "283:\tlearn: 1.9524673\ttotal: 3.78s\tremaining: 9.52s\n",
      "284:\tlearn: 1.9512799\ttotal: 3.79s\tremaining: 9.51s\n",
      "285:\tlearn: 1.9507086\ttotal: 3.8s\tremaining: 9.49s\n",
      "286:\tlearn: 1.9499504\ttotal: 3.81s\tremaining: 9.48s\n",
      "287:\tlearn: 1.9494783\ttotal: 3.83s\tremaining: 9.46s\n",
      "288:\tlearn: 1.9486336\ttotal: 3.84s\tremaining: 9.45s\n",
      "289:\tlearn: 1.9482280\ttotal: 3.85s\tremaining: 9.43s\n",
      "290:\tlearn: 1.9481587\ttotal: 3.87s\tremaining: 9.42s\n",
      "291:\tlearn: 1.9481414\ttotal: 3.88s\tremaining: 9.41s\n",
      "292:\tlearn: 1.9480544\ttotal: 3.89s\tremaining: 9.39s\n",
      "293:\tlearn: 1.9476624\ttotal: 3.91s\tremaining: 9.38s\n",
      "294:\tlearn: 1.9475833\ttotal: 3.92s\tremaining: 9.37s\n",
      "295:\tlearn: 1.9475757\ttotal: 3.93s\tremaining: 9.35s\n",
      "296:\tlearn: 1.9473430\ttotal: 3.94s\tremaining: 9.34s\n",
      "297:\tlearn: 1.9465989\ttotal: 3.96s\tremaining: 9.32s\n",
      "298:\tlearn: 1.9465693\ttotal: 3.97s\tremaining: 9.31s\n",
      "299:\tlearn: 1.9465626\ttotal: 3.98s\tremaining: 9.29s\n",
      "300:\tlearn: 1.9461329\ttotal: 4s\tremaining: 9.28s\n",
      "301:\tlearn: 1.9460058\ttotal: 4.01s\tremaining: 9.26s\n",
      "302:\tlearn: 1.9455290\ttotal: 4.02s\tremaining: 9.25s\n",
      "303:\tlearn: 1.9454718\ttotal: 4.04s\tremaining: 9.24s\n",
      "304:\tlearn: 1.9453515\ttotal: 4.05s\tremaining: 9.22s\n",
      "305:\tlearn: 1.9449793\ttotal: 4.06s\tremaining: 9.21s\n",
      "306:\tlearn: 1.9445849\ttotal: 4.07s\tremaining: 9.2s\n",
      "307:\tlearn: 1.9437942\ttotal: 4.09s\tremaining: 9.19s\n",
      "308:\tlearn: 1.9436138\ttotal: 4.1s\tremaining: 9.17s\n",
      "309:\tlearn: 1.9425504\ttotal: 4.12s\tremaining: 9.16s\n",
      "310:\tlearn: 1.9419266\ttotal: 4.13s\tremaining: 9.15s\n",
      "311:\tlearn: 1.9413009\ttotal: 4.14s\tremaining: 9.13s\n",
      "312:\tlearn: 1.9409381\ttotal: 4.15s\tremaining: 9.12s\n",
      "313:\tlearn: 1.9399873\ttotal: 4.17s\tremaining: 9.1s\n",
      "314:\tlearn: 1.9389907\ttotal: 4.18s\tremaining: 9.09s\n",
      "315:\tlearn: 1.9379265\ttotal: 4.19s\tremaining: 9.08s\n",
      "316:\tlearn: 1.9365412\ttotal: 4.21s\tremaining: 9.06s\n",
      "317:\tlearn: 1.9359723\ttotal: 4.22s\tremaining: 9.05s\n",
      "318:\tlearn: 1.9358662\ttotal: 4.23s\tremaining: 9.04s\n",
      "319:\tlearn: 1.9348630\ttotal: 4.25s\tremaining: 9.02s\n",
      "320:\tlearn: 1.9348557\ttotal: 4.26s\tremaining: 9.01s\n",
      "321:\tlearn: 1.9348499\ttotal: 4.27s\tremaining: 8.99s\n",
      "322:\tlearn: 1.9345633\ttotal: 4.29s\tremaining: 8.98s\n",
      "323:\tlearn: 1.9345590\ttotal: 4.3s\tremaining: 8.97s\n",
      "324:\tlearn: 1.9343291\ttotal: 4.31s\tremaining: 8.96s\n",
      "325:\tlearn: 1.9339065\ttotal: 4.32s\tremaining: 8.94s\n",
      "326:\tlearn: 1.9334655\ttotal: 4.34s\tremaining: 8.93s\n",
      "327:\tlearn: 1.9334497\ttotal: 4.35s\tremaining: 8.91s\n",
      "328:\tlearn: 1.9333381\ttotal: 4.36s\tremaining: 8.9s\n",
      "329:\tlearn: 1.9327135\ttotal: 4.38s\tremaining: 8.88s\n",
      "330:\tlearn: 1.9314710\ttotal: 4.39s\tremaining: 8.87s\n",
      "331:\tlearn: 1.9305047\ttotal: 4.4s\tremaining: 8.86s\n",
      "332:\tlearn: 1.9297615\ttotal: 4.41s\tremaining: 8.84s\n",
      "333:\tlearn: 1.9296108\ttotal: 4.43s\tremaining: 8.83s\n",
      "334:\tlearn: 1.9290765\ttotal: 4.44s\tremaining: 8.81s\n",
      "335:\tlearn: 1.9289950\ttotal: 4.45s\tremaining: 8.8s\n",
      "336:\tlearn: 1.9286992\ttotal: 4.46s\tremaining: 8.78s\n",
      "337:\tlearn: 1.9284608\ttotal: 4.48s\tremaining: 8.77s\n",
      "338:\tlearn: 1.9283519\ttotal: 4.49s\tremaining: 8.75s\n",
      "339:\tlearn: 1.9282685\ttotal: 4.5s\tremaining: 8.74s\n",
      "340:\tlearn: 1.9281974\ttotal: 4.52s\tremaining: 8.73s\n",
      "341:\tlearn: 1.9280436\ttotal: 4.53s\tremaining: 8.72s\n",
      "342:\tlearn: 1.9279074\ttotal: 4.54s\tremaining: 8.7s\n",
      "343:\tlearn: 1.9271156\ttotal: 4.56s\tremaining: 8.69s\n",
      "344:\tlearn: 1.9270157\ttotal: 4.57s\tremaining: 8.67s\n",
      "345:\tlearn: 1.9269853\ttotal: 4.59s\tremaining: 8.67s\n",
      "346:\tlearn: 1.9269096\ttotal: 4.6s\tremaining: 8.65s\n",
      "347:\tlearn: 1.9269012\ttotal: 4.61s\tremaining: 8.64s\n",
      "348:\tlearn: 1.9264273\ttotal: 4.62s\tremaining: 8.62s\n",
      "349:\tlearn: 1.9263909\ttotal: 4.64s\tremaining: 8.61s\n",
      "350:\tlearn: 1.9263902\ttotal: 4.65s\tremaining: 8.59s\n",
      "351:\tlearn: 1.9263672\ttotal: 4.66s\tremaining: 8.58s\n",
      "352:\tlearn: 1.9257650\ttotal: 4.67s\tremaining: 8.56s\n",
      "353:\tlearn: 1.9256409\ttotal: 4.69s\tremaining: 8.55s\n",
      "354:\tlearn: 1.9255944\ttotal: 4.7s\tremaining: 8.54s\n",
      "355:\tlearn: 1.9255893\ttotal: 4.71s\tremaining: 8.52s\n",
      "356:\tlearn: 1.9252906\ttotal: 4.72s\tremaining: 8.51s\n",
      "357:\tlearn: 1.9250355\ttotal: 4.74s\tremaining: 8.5s\n",
      "358:\tlearn: 1.9245987\ttotal: 4.75s\tremaining: 8.48s\n",
      "359:\tlearn: 1.9245820\ttotal: 4.76s\tremaining: 8.47s\n",
      "360:\tlearn: 1.9245423\ttotal: 4.78s\tremaining: 8.45s\n",
      "361:\tlearn: 1.9245409\ttotal: 4.79s\tremaining: 8.44s\n",
      "362:\tlearn: 1.9243020\ttotal: 4.8s\tremaining: 8.42s\n",
      "363:\tlearn: 1.9238176\ttotal: 4.81s\tremaining: 8.41s\n",
      "364:\tlearn: 1.9231258\ttotal: 4.83s\tremaining: 8.4s\n",
      "365:\tlearn: 1.9230876\ttotal: 4.84s\tremaining: 8.38s\n",
      "366:\tlearn: 1.9215725\ttotal: 4.85s\tremaining: 8.37s\n",
      "367:\tlearn: 1.9205994\ttotal: 4.86s\tremaining: 8.35s\n",
      "368:\tlearn: 1.9205050\ttotal: 4.88s\tremaining: 8.34s\n",
      "369:\tlearn: 1.9205037\ttotal: 4.89s\tremaining: 8.33s\n",
      "370:\tlearn: 1.9201627\ttotal: 4.9s\tremaining: 8.31s\n",
      "371:\tlearn: 1.9199434\ttotal: 4.92s\tremaining: 8.3s\n",
      "372:\tlearn: 1.9199327\ttotal: 4.93s\tremaining: 8.28s\n",
      "373:\tlearn: 1.9198446\ttotal: 4.94s\tremaining: 8.27s\n",
      "374:\tlearn: 1.9190354\ttotal: 4.96s\tremaining: 8.26s\n",
      "375:\tlearn: 1.9189006\ttotal: 4.97s\tremaining: 8.25s\n",
      "376:\tlearn: 1.9184121\ttotal: 4.98s\tremaining: 8.23s\n",
      "377:\tlearn: 1.9176016\ttotal: 4.99s\tremaining: 8.22s\n",
      "378:\tlearn: 1.9173995\ttotal: 5.01s\tremaining: 8.21s\n",
      "379:\tlearn: 1.9171961\ttotal: 5.02s\tremaining: 8.19s\n",
      "380:\tlearn: 1.9171050\ttotal: 5.03s\tremaining: 8.18s\n",
      "381:\tlearn: 1.9168728\ttotal: 5.05s\tremaining: 8.16s\n",
      "382:\tlearn: 1.9168609\ttotal: 5.06s\tremaining: 8.16s\n",
      "383:\tlearn: 1.9167140\ttotal: 5.08s\tremaining: 8.14s\n",
      "384:\tlearn: 1.9162290\ttotal: 5.09s\tremaining: 8.13s\n",
      "385:\tlearn: 1.9161948\ttotal: 5.11s\tremaining: 8.12s\n",
      "386:\tlearn: 1.9161859\ttotal: 5.12s\tremaining: 8.11s\n",
      "387:\tlearn: 1.9161846\ttotal: 5.14s\tremaining: 8.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388:\tlearn: 1.9161773\ttotal: 5.15s\tremaining: 8.09s\n",
      "389:\tlearn: 1.9161773\ttotal: 5.17s\tremaining: 8.08s\n",
      "390:\tlearn: 1.9161670\ttotal: 5.18s\tremaining: 8.07s\n",
      "391:\tlearn: 1.9157132\ttotal: 5.2s\tremaining: 8.06s\n",
      "392:\tlearn: 1.9156970\ttotal: 5.21s\tremaining: 8.04s\n",
      "393:\tlearn: 1.9156795\ttotal: 5.22s\tremaining: 8.03s\n",
      "394:\tlearn: 1.9156647\ttotal: 5.24s\tremaining: 8.02s\n",
      "395:\tlearn: 1.9156592\ttotal: 5.25s\tremaining: 8.01s\n",
      "396:\tlearn: 1.9155832\ttotal: 5.26s\tremaining: 7.99s\n",
      "397:\tlearn: 1.9154718\ttotal: 5.27s\tremaining: 7.98s\n",
      "398:\tlearn: 1.9150673\ttotal: 5.29s\tremaining: 7.96s\n",
      "399:\tlearn: 1.9149770\ttotal: 5.3s\tremaining: 7.95s\n",
      "400:\tlearn: 1.9149125\ttotal: 5.31s\tremaining: 7.94s\n",
      "401:\tlearn: 1.9146224\ttotal: 5.33s\tremaining: 7.92s\n",
      "402:\tlearn: 1.9133524\ttotal: 5.34s\tremaining: 7.91s\n",
      "403:\tlearn: 1.9129819\ttotal: 5.35s\tremaining: 7.9s\n",
      "404:\tlearn: 1.9129659\ttotal: 5.37s\tremaining: 7.88s\n",
      "405:\tlearn: 1.9129659\ttotal: 5.38s\tremaining: 7.87s\n",
      "406:\tlearn: 1.9129135\ttotal: 5.4s\tremaining: 7.86s\n",
      "407:\tlearn: 1.9129132\ttotal: 5.41s\tremaining: 7.85s\n",
      "408:\tlearn: 1.9128990\ttotal: 5.42s\tremaining: 7.84s\n",
      "409:\tlearn: 1.9128710\ttotal: 5.44s\tremaining: 7.83s\n",
      "410:\tlearn: 1.9121354\ttotal: 5.45s\tremaining: 7.82s\n",
      "411:\tlearn: 1.9119883\ttotal: 5.47s\tremaining: 7.8s\n",
      "412:\tlearn: 1.9118372\ttotal: 5.49s\tremaining: 7.8s\n",
      "413:\tlearn: 1.9118186\ttotal: 5.51s\tremaining: 7.79s\n",
      "414:\tlearn: 1.9115793\ttotal: 5.52s\tremaining: 7.79s\n",
      "415:\tlearn: 1.9114700\ttotal: 5.54s\tremaining: 7.78s\n",
      "416:\tlearn: 1.9113746\ttotal: 5.56s\tremaining: 7.77s\n",
      "417:\tlearn: 1.9113721\ttotal: 5.58s\tremaining: 7.76s\n",
      "418:\tlearn: 1.9113432\ttotal: 5.59s\tremaining: 7.75s\n",
      "419:\tlearn: 1.9111563\ttotal: 5.6s\tremaining: 7.74s\n",
      "420:\tlearn: 1.9110514\ttotal: 5.62s\tremaining: 7.72s\n",
      "421:\tlearn: 1.9109932\ttotal: 5.63s\tremaining: 7.71s\n",
      "422:\tlearn: 1.9106969\ttotal: 5.64s\tremaining: 7.7s\n",
      "423:\tlearn: 1.9106814\ttotal: 5.66s\tremaining: 7.69s\n",
      "424:\tlearn: 1.9106759\ttotal: 5.67s\tremaining: 7.67s\n",
      "425:\tlearn: 1.9101903\ttotal: 5.68s\tremaining: 7.66s\n",
      "426:\tlearn: 1.9101740\ttotal: 5.7s\tremaining: 7.65s\n",
      "427:\tlearn: 1.9101282\ttotal: 5.71s\tremaining: 7.63s\n",
      "428:\tlearn: 1.9100712\ttotal: 5.72s\tremaining: 7.62s\n",
      "429:\tlearn: 1.9099115\ttotal: 5.74s\tremaining: 7.6s\n",
      "430:\tlearn: 1.9098080\ttotal: 5.75s\tremaining: 7.59s\n",
      "431:\tlearn: 1.9094325\ttotal: 5.76s\tremaining: 7.58s\n",
      "432:\tlearn: 1.9091301\ttotal: 5.78s\tremaining: 7.56s\n",
      "433:\tlearn: 1.9090612\ttotal: 5.79s\tremaining: 7.55s\n",
      "434:\tlearn: 1.9089773\ttotal: 5.8s\tremaining: 7.54s\n",
      "435:\tlearn: 1.9089767\ttotal: 5.81s\tremaining: 7.52s\n",
      "436:\tlearn: 1.9089761\ttotal: 5.83s\tremaining: 7.51s\n",
      "437:\tlearn: 1.9089760\ttotal: 5.84s\tremaining: 7.49s\n",
      "438:\tlearn: 1.9089750\ttotal: 5.85s\tremaining: 7.48s\n",
      "439:\tlearn: 1.9089723\ttotal: 5.87s\tremaining: 7.46s\n",
      "440:\tlearn: 1.9089723\ttotal: 5.88s\tremaining: 7.45s\n",
      "441:\tlearn: 1.9089709\ttotal: 5.89s\tremaining: 7.44s\n",
      "442:\tlearn: 1.9085769\ttotal: 5.9s\tremaining: 7.42s\n",
      "443:\tlearn: 1.9085544\ttotal: 5.92s\tremaining: 7.41s\n",
      "444:\tlearn: 1.9079911\ttotal: 5.93s\tremaining: 7.39s\n",
      "445:\tlearn: 1.9077557\ttotal: 5.94s\tremaining: 7.38s\n",
      "446:\tlearn: 1.9068124\ttotal: 5.95s\tremaining: 7.37s\n",
      "447:\tlearn: 1.9066852\ttotal: 5.97s\tremaining: 7.35s\n",
      "448:\tlearn: 1.9066834\ttotal: 5.98s\tremaining: 7.34s\n",
      "449:\tlearn: 1.9066786\ttotal: 5.99s\tremaining: 7.32s\n",
      "450:\tlearn: 1.9066774\ttotal: 6s\tremaining: 7.31s\n",
      "451:\tlearn: 1.9066772\ttotal: 6.02s\tremaining: 7.3s\n",
      "452:\tlearn: 1.9065988\ttotal: 6.03s\tremaining: 7.28s\n",
      "453:\tlearn: 1.9063475\ttotal: 6.04s\tremaining: 7.27s\n",
      "454:\tlearn: 1.9063003\ttotal: 6.05s\tremaining: 7.25s\n",
      "455:\tlearn: 1.9062581\ttotal: 6.07s\tremaining: 7.24s\n",
      "456:\tlearn: 1.9062581\ttotal: 6.08s\tremaining: 7.22s\n",
      "457:\tlearn: 1.9062576\ttotal: 6.09s\tremaining: 7.21s\n",
      "458:\tlearn: 1.9062576\ttotal: 6.11s\tremaining: 7.2s\n",
      "459:\tlearn: 1.9062510\ttotal: 6.12s\tremaining: 7.18s\n",
      "460:\tlearn: 1.9062328\ttotal: 6.13s\tremaining: 7.17s\n",
      "461:\tlearn: 1.9062095\ttotal: 6.14s\tremaining: 7.15s\n",
      "462:\tlearn: 1.9061865\ttotal: 6.16s\tremaining: 7.14s\n",
      "463:\tlearn: 1.9060861\ttotal: 6.17s\tremaining: 7.13s\n",
      "464:\tlearn: 1.9051283\ttotal: 6.18s\tremaining: 7.11s\n",
      "465:\tlearn: 1.9051102\ttotal: 6.19s\tremaining: 7.1s\n",
      "466:\tlearn: 1.9050893\ttotal: 6.21s\tremaining: 7.08s\n",
      "467:\tlearn: 1.9038972\ttotal: 6.22s\tremaining: 7.07s\n",
      "468:\tlearn: 1.9032286\ttotal: 6.24s\tremaining: 7.06s\n",
      "469:\tlearn: 1.9030867\ttotal: 6.25s\tremaining: 7.05s\n",
      "470:\tlearn: 1.9019736\ttotal: 6.27s\tremaining: 7.04s\n",
      "471:\tlearn: 1.8999793\ttotal: 6.29s\tremaining: 7.03s\n",
      "472:\tlearn: 1.8999765\ttotal: 6.3s\tremaining: 7.02s\n",
      "473:\tlearn: 1.8999228\ttotal: 6.32s\tremaining: 7.01s\n",
      "474:\tlearn: 1.8998732\ttotal: 6.33s\tremaining: 7s\n",
      "475:\tlearn: 1.8998582\ttotal: 6.34s\tremaining: 6.98s\n",
      "476:\tlearn: 1.8998482\ttotal: 6.36s\tremaining: 6.97s\n",
      "477:\tlearn: 1.8998290\ttotal: 6.37s\tremaining: 6.96s\n",
      "478:\tlearn: 1.8998257\ttotal: 6.38s\tremaining: 6.94s\n",
      "479:\tlearn: 1.8997800\ttotal: 6.4s\tremaining: 6.93s\n",
      "480:\tlearn: 1.8991513\ttotal: 6.41s\tremaining: 6.92s\n",
      "481:\tlearn: 1.8991512\ttotal: 6.43s\tremaining: 6.91s\n",
      "482:\tlearn: 1.8991511\ttotal: 6.44s\tremaining: 6.89s\n",
      "483:\tlearn: 1.8988516\ttotal: 6.45s\tremaining: 6.88s\n",
      "484:\tlearn: 1.8988391\ttotal: 6.47s\tremaining: 6.87s\n",
      "485:\tlearn: 1.8978462\ttotal: 6.48s\tremaining: 6.85s\n",
      "486:\tlearn: 1.8978389\ttotal: 6.49s\tremaining: 6.84s\n",
      "487:\tlearn: 1.8978389\ttotal: 6.5s\tremaining: 6.82s\n",
      "488:\tlearn: 1.8978375\ttotal: 6.52s\tremaining: 6.81s\n",
      "489:\tlearn: 1.8973389\ttotal: 6.53s\tremaining: 6.79s\n",
      "490:\tlearn: 1.8970288\ttotal: 6.54s\tremaining: 6.78s\n",
      "491:\tlearn: 1.8967139\ttotal: 6.55s\tremaining: 6.77s\n",
      "492:\tlearn: 1.8962071\ttotal: 6.57s\tremaining: 6.75s\n",
      "493:\tlearn: 1.8953804\ttotal: 6.58s\tremaining: 6.74s\n",
      "494:\tlearn: 1.8925487\ttotal: 6.59s\tremaining: 6.73s\n",
      "495:\tlearn: 1.8925481\ttotal: 6.61s\tremaining: 6.71s\n",
      "496:\tlearn: 1.8925372\ttotal: 6.62s\tremaining: 6.7s\n",
      "497:\tlearn: 1.8925371\ttotal: 6.63s\tremaining: 6.68s\n",
      "498:\tlearn: 1.8925357\ttotal: 6.65s\tremaining: 6.67s\n",
      "499:\tlearn: 1.8924659\ttotal: 6.66s\tremaining: 6.66s\n",
      "500:\tlearn: 1.8923346\ttotal: 6.67s\tremaining: 6.64s\n",
      "501:\tlearn: 1.8923068\ttotal: 6.68s\tremaining: 6.63s\n",
      "502:\tlearn: 1.8922894\ttotal: 6.69s\tremaining: 6.61s\n",
      "503:\tlearn: 1.8918241\ttotal: 6.71s\tremaining: 6.6s\n",
      "504:\tlearn: 1.8916228\ttotal: 6.72s\tremaining: 6.58s\n",
      "505:\tlearn: 1.8914981\ttotal: 6.73s\tremaining: 6.57s\n",
      "506:\tlearn: 1.8914475\ttotal: 6.74s\tremaining: 6.55s\n",
      "507:\tlearn: 1.8913199\ttotal: 6.75s\tremaining: 6.54s\n",
      "508:\tlearn: 1.8912470\ttotal: 6.77s\tremaining: 6.53s\n",
      "509:\tlearn: 1.8911950\ttotal: 6.78s\tremaining: 6.51s\n",
      "510:\tlearn: 1.8911929\ttotal: 6.79s\tremaining: 6.5s\n",
      "511:\tlearn: 1.8910067\ttotal: 6.8s\tremaining: 6.48s\n",
      "512:\tlearn: 1.8899011\ttotal: 6.82s\tremaining: 6.47s\n",
      "513:\tlearn: 1.8870016\ttotal: 6.83s\tremaining: 6.46s\n",
      "514:\tlearn: 1.8869918\ttotal: 6.84s\tremaining: 6.44s\n",
      "515:\tlearn: 1.8869760\ttotal: 6.86s\tremaining: 6.43s\n",
      "516:\tlearn: 1.8869659\ttotal: 6.87s\tremaining: 6.42s\n",
      "517:\tlearn: 1.8869659\ttotal: 6.88s\tremaining: 6.4s\n",
      "518:\tlearn: 1.8869655\ttotal: 6.89s\tremaining: 6.39s\n",
      "519:\tlearn: 1.8869655\ttotal: 6.9s\tremaining: 6.37s\n",
      "520:\tlearn: 1.8868593\ttotal: 6.92s\tremaining: 6.36s\n",
      "521:\tlearn: 1.8863958\ttotal: 6.93s\tremaining: 6.34s\n",
      "522:\tlearn: 1.8863953\ttotal: 6.94s\tremaining: 6.33s\n",
      "523:\tlearn: 1.8863952\ttotal: 6.95s\tremaining: 6.32s\n",
      "524:\tlearn: 1.8863952\ttotal: 6.97s\tremaining: 6.3s\n",
      "525:\tlearn: 1.8862172\ttotal: 6.98s\tremaining: 6.29s\n",
      "526:\tlearn: 1.8856415\ttotal: 6.99s\tremaining: 6.28s\n",
      "527:\tlearn: 1.8854974\ttotal: 7s\tremaining: 6.26s\n",
      "528:\tlearn: 1.8846074\ttotal: 7.02s\tremaining: 6.25s\n",
      "529:\tlearn: 1.8840503\ttotal: 7.03s\tremaining: 6.23s\n",
      "530:\tlearn: 1.8837416\ttotal: 7.04s\tremaining: 6.22s\n",
      "531:\tlearn: 1.8836963\ttotal: 7.05s\tremaining: 6.21s\n",
      "532:\tlearn: 1.8836595\ttotal: 7.07s\tremaining: 6.19s\n",
      "533:\tlearn: 1.8836590\ttotal: 7.08s\tremaining: 6.18s\n",
      "534:\tlearn: 1.8836590\ttotal: 7.09s\tremaining: 6.17s\n",
      "535:\tlearn: 1.8836582\ttotal: 7.11s\tremaining: 6.15s\n",
      "536:\tlearn: 1.8836256\ttotal: 7.12s\tremaining: 6.14s\n",
      "537:\tlearn: 1.8826043\ttotal: 7.13s\tremaining: 6.13s\n",
      "538:\tlearn: 1.8820296\ttotal: 7.14s\tremaining: 6.11s\n",
      "539:\tlearn: 1.8819848\ttotal: 7.16s\tremaining: 6.1s\n",
      "540:\tlearn: 1.8818976\ttotal: 7.17s\tremaining: 6.08s\n",
      "541:\tlearn: 1.8818828\ttotal: 7.18s\tremaining: 6.07s\n",
      "542:\tlearn: 1.8817114\ttotal: 7.19s\tremaining: 6.05s\n",
      "543:\tlearn: 1.8803305\ttotal: 7.21s\tremaining: 6.04s\n",
      "544:\tlearn: 1.8799327\ttotal: 7.22s\tremaining: 6.03s\n",
      "545:\tlearn: 1.8798991\ttotal: 7.23s\tremaining: 6.01s\n",
      "546:\tlearn: 1.8798779\ttotal: 7.24s\tremaining: 6s\n",
      "547:\tlearn: 1.8798764\ttotal: 7.26s\tremaining: 5.99s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548:\tlearn: 1.8795428\ttotal: 7.27s\tremaining: 5.97s\n",
      "549:\tlearn: 1.8788951\ttotal: 7.28s\tremaining: 5.96s\n",
      "550:\tlearn: 1.8785303\ttotal: 7.3s\tremaining: 5.95s\n",
      "551:\tlearn: 1.8784674\ttotal: 7.31s\tremaining: 5.93s\n",
      "552:\tlearn: 1.8782086\ttotal: 7.32s\tremaining: 5.92s\n",
      "553:\tlearn: 1.8781871\ttotal: 7.33s\tremaining: 5.9s\n",
      "554:\tlearn: 1.8780964\ttotal: 7.34s\tremaining: 5.89s\n",
      "555:\tlearn: 1.8780339\ttotal: 7.36s\tremaining: 5.88s\n",
      "556:\tlearn: 1.8776233\ttotal: 7.37s\tremaining: 5.86s\n",
      "557:\tlearn: 1.8772683\ttotal: 7.38s\tremaining: 5.85s\n",
      "558:\tlearn: 1.8766927\ttotal: 7.4s\tremaining: 5.83s\n",
      "559:\tlearn: 1.8766697\ttotal: 7.41s\tremaining: 5.82s\n",
      "560:\tlearn: 1.8766696\ttotal: 7.42s\tremaining: 5.81s\n",
      "561:\tlearn: 1.8766674\ttotal: 7.43s\tremaining: 5.79s\n",
      "562:\tlearn: 1.8766653\ttotal: 7.45s\tremaining: 5.78s\n",
      "563:\tlearn: 1.8766653\ttotal: 7.46s\tremaining: 5.77s\n",
      "564:\tlearn: 1.8766652\ttotal: 7.47s\tremaining: 5.75s\n",
      "565:\tlearn: 1.8766648\ttotal: 7.49s\tremaining: 5.74s\n",
      "566:\tlearn: 1.8765331\ttotal: 7.5s\tremaining: 5.73s\n",
      "567:\tlearn: 1.8765330\ttotal: 7.51s\tremaining: 5.71s\n",
      "568:\tlearn: 1.8765329\ttotal: 7.52s\tremaining: 5.7s\n",
      "569:\tlearn: 1.8765327\ttotal: 7.54s\tremaining: 5.68s\n",
      "570:\tlearn: 1.8765317\ttotal: 7.55s\tremaining: 5.67s\n",
      "571:\tlearn: 1.8765311\ttotal: 7.56s\tremaining: 5.66s\n",
      "572:\tlearn: 1.8765026\ttotal: 7.57s\tremaining: 5.64s\n",
      "573:\tlearn: 1.8751719\ttotal: 7.58s\tremaining: 5.63s\n",
      "574:\tlearn: 1.8744366\ttotal: 7.6s\tremaining: 5.62s\n",
      "575:\tlearn: 1.8742047\ttotal: 7.61s\tremaining: 5.6s\n",
      "576:\tlearn: 1.8742003\ttotal: 7.62s\tremaining: 5.59s\n",
      "577:\tlearn: 1.8741800\ttotal: 7.63s\tremaining: 5.57s\n",
      "578:\tlearn: 1.8741793\ttotal: 7.65s\tremaining: 5.56s\n",
      "579:\tlearn: 1.8741792\ttotal: 7.66s\tremaining: 5.55s\n",
      "580:\tlearn: 1.8741710\ttotal: 7.67s\tremaining: 5.53s\n",
      "581:\tlearn: 1.8741707\ttotal: 7.69s\tremaining: 5.52s\n",
      "582:\tlearn: 1.8741706\ttotal: 7.7s\tremaining: 5.51s\n",
      "583:\tlearn: 1.8741706\ttotal: 7.71s\tremaining: 5.49s\n",
      "584:\tlearn: 1.8741208\ttotal: 7.72s\tremaining: 5.48s\n",
      "585:\tlearn: 1.8741203\ttotal: 7.74s\tremaining: 5.47s\n",
      "586:\tlearn: 1.8741203\ttotal: 7.75s\tremaining: 5.45s\n",
      "587:\tlearn: 1.8741200\ttotal: 7.76s\tremaining: 5.44s\n",
      "588:\tlearn: 1.8741199\ttotal: 7.78s\tremaining: 5.43s\n",
      "589:\tlearn: 1.8741193\ttotal: 7.79s\tremaining: 5.41s\n",
      "590:\tlearn: 1.8741035\ttotal: 7.8s\tremaining: 5.4s\n",
      "591:\tlearn: 1.8741031\ttotal: 7.81s\tremaining: 5.38s\n",
      "592:\tlearn: 1.8741030\ttotal: 7.83s\tremaining: 5.37s\n",
      "593:\tlearn: 1.8741026\ttotal: 7.84s\tremaining: 5.36s\n",
      "594:\tlearn: 1.8741026\ttotal: 7.85s\tremaining: 5.34s\n",
      "595:\tlearn: 1.8741026\ttotal: 7.86s\tremaining: 5.33s\n",
      "596:\tlearn: 1.8741026\ttotal: 7.88s\tremaining: 5.32s\n",
      "597:\tlearn: 1.8741026\ttotal: 7.89s\tremaining: 5.3s\n",
      "598:\tlearn: 1.8740862\ttotal: 7.9s\tremaining: 5.29s\n",
      "599:\tlearn: 1.8740842\ttotal: 7.92s\tremaining: 5.28s\n",
      "600:\tlearn: 1.8740841\ttotal: 7.93s\tremaining: 5.26s\n",
      "601:\tlearn: 1.8740841\ttotal: 7.94s\tremaining: 5.25s\n",
      "602:\tlearn: 1.8740839\ttotal: 7.96s\tremaining: 5.24s\n",
      "603:\tlearn: 1.8740839\ttotal: 7.97s\tremaining: 5.22s\n",
      "604:\tlearn: 1.8740801\ttotal: 7.98s\tremaining: 5.21s\n",
      "605:\tlearn: 1.8740779\ttotal: 7.99s\tremaining: 5.2s\n",
      "606:\tlearn: 1.8738345\ttotal: 8.01s\tremaining: 5.18s\n",
      "607:\tlearn: 1.8735478\ttotal: 8.02s\tremaining: 5.17s\n",
      "608:\tlearn: 1.8727283\ttotal: 8.03s\tremaining: 5.16s\n",
      "609:\tlearn: 1.8714412\ttotal: 8.04s\tremaining: 5.14s\n",
      "610:\tlearn: 1.8712268\ttotal: 8.06s\tremaining: 5.13s\n",
      "611:\tlearn: 1.8712153\ttotal: 8.07s\tremaining: 5.12s\n",
      "612:\tlearn: 1.8711810\ttotal: 8.08s\tremaining: 5.1s\n",
      "613:\tlearn: 1.8709585\ttotal: 8.09s\tremaining: 5.09s\n",
      "614:\tlearn: 1.8709562\ttotal: 8.11s\tremaining: 5.07s\n",
      "615:\tlearn: 1.8706911\ttotal: 8.12s\tremaining: 5.06s\n",
      "616:\tlearn: 1.8706814\ttotal: 8.13s\tremaining: 5.05s\n",
      "617:\tlearn: 1.8706802\ttotal: 8.14s\tremaining: 5.04s\n",
      "618:\tlearn: 1.8706801\ttotal: 8.16s\tremaining: 5.02s\n",
      "619:\tlearn: 1.8706799\ttotal: 8.17s\tremaining: 5.01s\n",
      "620:\tlearn: 1.8704262\ttotal: 8.18s\tremaining: 4.99s\n",
      "621:\tlearn: 1.8698088\ttotal: 8.19s\tremaining: 4.98s\n",
      "622:\tlearn: 1.8693715\ttotal: 8.21s\tremaining: 4.97s\n",
      "623:\tlearn: 1.8692006\ttotal: 8.22s\tremaining: 4.95s\n",
      "624:\tlearn: 1.8691893\ttotal: 8.23s\tremaining: 4.94s\n",
      "625:\tlearn: 1.8691890\ttotal: 8.24s\tremaining: 4.92s\n",
      "626:\tlearn: 1.8691887\ttotal: 8.26s\tremaining: 4.91s\n",
      "627:\tlearn: 1.8691750\ttotal: 8.27s\tremaining: 4.9s\n",
      "628:\tlearn: 1.8690699\ttotal: 8.28s\tremaining: 4.88s\n",
      "629:\tlearn: 1.8690399\ttotal: 8.29s\tremaining: 4.87s\n",
      "630:\tlearn: 1.8682649\ttotal: 8.31s\tremaining: 4.86s\n",
      "631:\tlearn: 1.8673170\ttotal: 8.32s\tremaining: 4.84s\n",
      "632:\tlearn: 1.8664143\ttotal: 8.33s\tremaining: 4.83s\n",
      "633:\tlearn: 1.8663964\ttotal: 8.35s\tremaining: 4.82s\n",
      "634:\tlearn: 1.8662998\ttotal: 8.36s\tremaining: 4.8s\n",
      "635:\tlearn: 1.8659769\ttotal: 8.37s\tremaining: 4.79s\n",
      "636:\tlearn: 1.8655067\ttotal: 8.38s\tremaining: 4.78s\n",
      "637:\tlearn: 1.8654249\ttotal: 8.4s\tremaining: 4.76s\n",
      "638:\tlearn: 1.8641644\ttotal: 8.41s\tremaining: 4.75s\n",
      "639:\tlearn: 1.8638726\ttotal: 8.42s\tremaining: 4.74s\n",
      "640:\tlearn: 1.8634715\ttotal: 8.44s\tremaining: 4.72s\n",
      "641:\tlearn: 1.8634380\ttotal: 8.45s\tremaining: 4.71s\n",
      "642:\tlearn: 1.8632406\ttotal: 8.46s\tremaining: 4.7s\n",
      "643:\tlearn: 1.8629372\ttotal: 8.47s\tremaining: 4.68s\n",
      "644:\tlearn: 1.8627999\ttotal: 8.48s\tremaining: 4.67s\n",
      "645:\tlearn: 1.8627666\ttotal: 8.5s\tremaining: 4.66s\n",
      "646:\tlearn: 1.8624653\ttotal: 8.51s\tremaining: 4.64s\n",
      "647:\tlearn: 1.8622668\ttotal: 8.52s\tremaining: 4.63s\n",
      "648:\tlearn: 1.8622238\ttotal: 8.54s\tremaining: 4.62s\n",
      "649:\tlearn: 1.8622237\ttotal: 8.55s\tremaining: 4.61s\n",
      "650:\tlearn: 1.8621834\ttotal: 8.57s\tremaining: 4.59s\n",
      "651:\tlearn: 1.8620997\ttotal: 8.58s\tremaining: 4.58s\n",
      "652:\tlearn: 1.8620988\ttotal: 8.59s\tremaining: 4.57s\n",
      "653:\tlearn: 1.8620982\ttotal: 8.61s\tremaining: 4.55s\n",
      "654:\tlearn: 1.8620968\ttotal: 8.62s\tremaining: 4.54s\n",
      "655:\tlearn: 1.8620953\ttotal: 8.63s\tremaining: 4.53s\n",
      "656:\tlearn: 1.8618931\ttotal: 8.64s\tremaining: 4.51s\n",
      "657:\tlearn: 1.8616732\ttotal: 8.65s\tremaining: 4.5s\n",
      "658:\tlearn: 1.8607386\ttotal: 8.67s\tremaining: 4.49s\n",
      "659:\tlearn: 1.8607236\ttotal: 8.68s\tremaining: 4.47s\n",
      "660:\tlearn: 1.8597917\ttotal: 8.69s\tremaining: 4.46s\n",
      "661:\tlearn: 1.8597665\ttotal: 8.71s\tremaining: 4.45s\n",
      "662:\tlearn: 1.8592674\ttotal: 8.72s\tremaining: 4.43s\n",
      "663:\tlearn: 1.8584243\ttotal: 8.74s\tremaining: 4.42s\n",
      "664:\tlearn: 1.8580960\ttotal: 8.75s\tremaining: 4.41s\n",
      "665:\tlearn: 1.8574525\ttotal: 8.77s\tremaining: 4.4s\n",
      "666:\tlearn: 1.8574448\ttotal: 8.78s\tremaining: 4.38s\n",
      "667:\tlearn: 1.8574376\ttotal: 8.79s\tremaining: 4.37s\n",
      "668:\tlearn: 1.8571044\ttotal: 8.81s\tremaining: 4.36s\n",
      "669:\tlearn: 1.8569902\ttotal: 8.82s\tremaining: 4.34s\n",
      "670:\tlearn: 1.8565816\ttotal: 8.83s\tremaining: 4.33s\n",
      "671:\tlearn: 1.8565403\ttotal: 8.84s\tremaining: 4.32s\n",
      "672:\tlearn: 1.8560413\ttotal: 8.86s\tremaining: 4.3s\n",
      "673:\tlearn: 1.8556478\ttotal: 8.87s\tremaining: 4.29s\n",
      "674:\tlearn: 1.8555047\ttotal: 8.88s\tremaining: 4.28s\n",
      "675:\tlearn: 1.8553252\ttotal: 8.89s\tremaining: 4.26s\n",
      "676:\tlearn: 1.8551735\ttotal: 8.91s\tremaining: 4.25s\n",
      "677:\tlearn: 1.8550571\ttotal: 8.92s\tremaining: 4.24s\n",
      "678:\tlearn: 1.8549238\ttotal: 8.93s\tremaining: 4.22s\n",
      "679:\tlearn: 1.8546497\ttotal: 8.95s\tremaining: 4.21s\n",
      "680:\tlearn: 1.8546464\ttotal: 8.96s\tremaining: 4.2s\n",
      "681:\tlearn: 1.8544611\ttotal: 8.97s\tremaining: 4.18s\n",
      "682:\tlearn: 1.8544500\ttotal: 8.99s\tremaining: 4.17s\n",
      "683:\tlearn: 1.8544456\ttotal: 9s\tremaining: 4.16s\n",
      "684:\tlearn: 1.8542170\ttotal: 9.01s\tremaining: 4.14s\n",
      "685:\tlearn: 1.8541568\ttotal: 9.03s\tremaining: 4.13s\n",
      "686:\tlearn: 1.8538890\ttotal: 9.04s\tremaining: 4.12s\n",
      "687:\tlearn: 1.8538732\ttotal: 9.05s\tremaining: 4.1s\n",
      "688:\tlearn: 1.8534611\ttotal: 9.07s\tremaining: 4.09s\n",
      "689:\tlearn: 1.8533397\ttotal: 9.08s\tremaining: 4.08s\n",
      "690:\tlearn: 1.8531407\ttotal: 9.09s\tremaining: 4.07s\n",
      "691:\tlearn: 1.8530325\ttotal: 9.1s\tremaining: 4.05s\n",
      "692:\tlearn: 1.8530303\ttotal: 9.12s\tremaining: 4.04s\n",
      "693:\tlearn: 1.8528430\ttotal: 9.13s\tremaining: 4.02s\n",
      "694:\tlearn: 1.8521577\ttotal: 9.14s\tremaining: 4.01s\n",
      "695:\tlearn: 1.8517109\ttotal: 9.15s\tremaining: 4s\n",
      "696:\tlearn: 1.8517059\ttotal: 9.17s\tremaining: 3.98s\n",
      "697:\tlearn: 1.8516215\ttotal: 9.18s\tremaining: 3.97s\n",
      "698:\tlearn: 1.8515757\ttotal: 9.19s\tremaining: 3.96s\n",
      "699:\tlearn: 1.8514600\ttotal: 9.21s\tremaining: 3.95s\n",
      "700:\tlearn: 1.8514355\ttotal: 9.23s\tremaining: 3.94s\n",
      "701:\tlearn: 1.8512994\ttotal: 9.24s\tremaining: 3.92s\n",
      "702:\tlearn: 1.8511259\ttotal: 9.26s\tremaining: 3.91s\n",
      "703:\tlearn: 1.8510400\ttotal: 9.28s\tremaining: 3.9s\n",
      "704:\tlearn: 1.8509629\ttotal: 9.29s\tremaining: 3.89s\n",
      "705:\tlearn: 1.8509498\ttotal: 9.31s\tremaining: 3.88s\n",
      "706:\tlearn: 1.8509472\ttotal: 9.32s\tremaining: 3.86s\n",
      "707:\tlearn: 1.8509161\ttotal: 9.34s\tremaining: 3.85s\n",
      "708:\tlearn: 1.8509154\ttotal: 9.35s\tremaining: 3.84s\n",
      "709:\tlearn: 1.8506823\ttotal: 9.37s\tremaining: 3.83s\n",
      "710:\tlearn: 1.8503763\ttotal: 9.38s\tremaining: 3.81s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711:\tlearn: 1.8500323\ttotal: 9.4s\tremaining: 3.8s\n",
      "712:\tlearn: 1.8497613\ttotal: 9.42s\tremaining: 3.79s\n",
      "713:\tlearn: 1.8496568\ttotal: 9.43s\tremaining: 3.78s\n",
      "714:\tlearn: 1.8492960\ttotal: 9.45s\tremaining: 3.77s\n",
      "715:\tlearn: 1.8492279\ttotal: 9.46s\tremaining: 3.75s\n",
      "716:\tlearn: 1.8490210\ttotal: 9.48s\tremaining: 3.74s\n",
      "717:\tlearn: 1.8485916\ttotal: 9.49s\tremaining: 3.73s\n",
      "718:\tlearn: 1.8482282\ttotal: 9.51s\tremaining: 3.72s\n",
      "719:\tlearn: 1.8471356\ttotal: 9.52s\tremaining: 3.7s\n",
      "720:\tlearn: 1.8470803\ttotal: 9.54s\tremaining: 3.69s\n",
      "721:\tlearn: 1.8470340\ttotal: 9.55s\tremaining: 3.68s\n",
      "722:\tlearn: 1.8465800\ttotal: 9.57s\tremaining: 3.67s\n",
      "723:\tlearn: 1.8463787\ttotal: 9.58s\tremaining: 3.65s\n",
      "724:\tlearn: 1.8463535\ttotal: 9.6s\tremaining: 3.64s\n",
      "725:\tlearn: 1.8463534\ttotal: 9.61s\tremaining: 3.63s\n",
      "726:\tlearn: 1.8463533\ttotal: 9.63s\tremaining: 3.62s\n",
      "727:\tlearn: 1.8462767\ttotal: 9.64s\tremaining: 3.6s\n",
      "728:\tlearn: 1.8462719\ttotal: 9.66s\tremaining: 3.59s\n",
      "729:\tlearn: 1.8460561\ttotal: 9.67s\tremaining: 3.58s\n",
      "730:\tlearn: 1.8457448\ttotal: 9.69s\tremaining: 3.56s\n",
      "731:\tlearn: 1.8457447\ttotal: 9.7s\tremaining: 3.55s\n",
      "732:\tlearn: 1.8452000\ttotal: 9.71s\tremaining: 3.54s\n",
      "733:\tlearn: 1.8447442\ttotal: 9.72s\tremaining: 3.52s\n",
      "734:\tlearn: 1.8447439\ttotal: 9.74s\tremaining: 3.51s\n",
      "735:\tlearn: 1.8447211\ttotal: 9.75s\tremaining: 3.5s\n",
      "736:\tlearn: 1.8447207\ttotal: 9.76s\tremaining: 3.48s\n",
      "737:\tlearn: 1.8447002\ttotal: 9.77s\tremaining: 3.47s\n",
      "738:\tlearn: 1.8446864\ttotal: 9.79s\tremaining: 3.46s\n",
      "739:\tlearn: 1.8446708\ttotal: 9.8s\tremaining: 3.44s\n",
      "740:\tlearn: 1.8441057\ttotal: 9.81s\tremaining: 3.43s\n",
      "741:\tlearn: 1.8432268\ttotal: 9.83s\tremaining: 3.42s\n",
      "742:\tlearn: 1.8425103\ttotal: 9.84s\tremaining: 3.4s\n",
      "743:\tlearn: 1.8423845\ttotal: 9.85s\tremaining: 3.39s\n",
      "744:\tlearn: 1.8420651\ttotal: 9.87s\tremaining: 3.38s\n",
      "745:\tlearn: 1.8420611\ttotal: 9.88s\tremaining: 3.36s\n",
      "746:\tlearn: 1.8420570\ttotal: 9.89s\tremaining: 3.35s\n",
      "747:\tlearn: 1.8416826\ttotal: 9.9s\tremaining: 3.34s\n",
      "748:\tlearn: 1.8416327\ttotal: 9.92s\tremaining: 3.32s\n",
      "749:\tlearn: 1.8415658\ttotal: 9.93s\tremaining: 3.31s\n",
      "750:\tlearn: 1.8415588\ttotal: 9.94s\tremaining: 3.3s\n",
      "751:\tlearn: 1.8415528\ttotal: 9.96s\tremaining: 3.28s\n",
      "752:\tlearn: 1.8414915\ttotal: 9.97s\tremaining: 3.27s\n",
      "753:\tlearn: 1.8414676\ttotal: 9.98s\tremaining: 3.26s\n",
      "754:\tlearn: 1.8414426\ttotal: 9.99s\tremaining: 3.24s\n",
      "755:\tlearn: 1.8414389\ttotal: 10s\tremaining: 3.23s\n",
      "756:\tlearn: 1.8411258\ttotal: 10s\tremaining: 3.22s\n",
      "757:\tlearn: 1.8410471\ttotal: 10s\tremaining: 3.2s\n",
      "758:\tlearn: 1.8402402\ttotal: 10s\tremaining: 3.19s\n",
      "759:\tlearn: 1.8401459\ttotal: 10.1s\tremaining: 3.18s\n",
      "760:\tlearn: 1.8400738\ttotal: 10.1s\tremaining: 3.16s\n",
      "761:\tlearn: 1.8400735\ttotal: 10.1s\tremaining: 3.15s\n",
      "762:\tlearn: 1.8400734\ttotal: 10.1s\tremaining: 3.14s\n",
      "763:\tlearn: 1.8397075\ttotal: 10.1s\tremaining: 3.12s\n",
      "764:\tlearn: 1.8392735\ttotal: 10.1s\tremaining: 3.11s\n",
      "765:\tlearn: 1.8391304\ttotal: 10.1s\tremaining: 3.1s\n",
      "766:\tlearn: 1.8388901\ttotal: 10.2s\tremaining: 3.08s\n",
      "767:\tlearn: 1.8388408\ttotal: 10.2s\tremaining: 3.07s\n",
      "768:\tlearn: 1.8386401\ttotal: 10.2s\tremaining: 3.06s\n",
      "769:\tlearn: 1.8381536\ttotal: 10.2s\tremaining: 3.04s\n",
      "770:\tlearn: 1.8369474\ttotal: 10.2s\tremaining: 3.03s\n",
      "771:\tlearn: 1.8368967\ttotal: 10.2s\tremaining: 3.02s\n",
      "772:\tlearn: 1.8367474\ttotal: 10.2s\tremaining: 3s\n",
      "773:\tlearn: 1.8367473\ttotal: 10.2s\tremaining: 2.99s\n",
      "774:\tlearn: 1.8366974\ttotal: 10.3s\tremaining: 2.98s\n",
      "775:\tlearn: 1.8365004\ttotal: 10.3s\tremaining: 2.96s\n",
      "776:\tlearn: 1.8364328\ttotal: 10.3s\tremaining: 2.95s\n",
      "777:\tlearn: 1.8364228\ttotal: 10.3s\tremaining: 2.94s\n",
      "778:\tlearn: 1.8363456\ttotal: 10.3s\tremaining: 2.92s\n",
      "779:\tlearn: 1.8363273\ttotal: 10.3s\tremaining: 2.91s\n",
      "780:\tlearn: 1.8359578\ttotal: 10.3s\tremaining: 2.9s\n",
      "781:\tlearn: 1.8355000\ttotal: 10.3s\tremaining: 2.88s\n",
      "782:\tlearn: 1.8354955\ttotal: 10.4s\tremaining: 2.87s\n",
      "783:\tlearn: 1.8354922\ttotal: 10.4s\tremaining: 2.86s\n",
      "784:\tlearn: 1.8353442\ttotal: 10.4s\tremaining: 2.84s\n",
      "785:\tlearn: 1.8353348\ttotal: 10.4s\tremaining: 2.83s\n",
      "786:\tlearn: 1.8353288\ttotal: 10.4s\tremaining: 2.82s\n",
      "787:\tlearn: 1.8353288\ttotal: 10.4s\tremaining: 2.8s\n",
      "788:\tlearn: 1.8346925\ttotal: 10.4s\tremaining: 2.79s\n",
      "789:\tlearn: 1.8334098\ttotal: 10.5s\tremaining: 2.78s\n",
      "790:\tlearn: 1.8326951\ttotal: 10.5s\tremaining: 2.77s\n",
      "791:\tlearn: 1.8326585\ttotal: 10.5s\tremaining: 2.75s\n",
      "792:\tlearn: 1.8320795\ttotal: 10.5s\tremaining: 2.74s\n",
      "793:\tlearn: 1.8320732\ttotal: 10.5s\tremaining: 2.73s\n",
      "794:\tlearn: 1.8320358\ttotal: 10.5s\tremaining: 2.71s\n",
      "795:\tlearn: 1.8319790\ttotal: 10.5s\tremaining: 2.7s\n",
      "796:\tlearn: 1.8319640\ttotal: 10.5s\tremaining: 2.69s\n",
      "797:\tlearn: 1.8316726\ttotal: 10.6s\tremaining: 2.67s\n",
      "798:\tlearn: 1.8308014\ttotal: 10.6s\tremaining: 2.66s\n",
      "799:\tlearn: 1.8304980\ttotal: 10.6s\tremaining: 2.65s\n",
      "800:\tlearn: 1.8304251\ttotal: 10.6s\tremaining: 2.63s\n",
      "801:\tlearn: 1.8303441\ttotal: 10.6s\tremaining: 2.62s\n",
      "802:\tlearn: 1.8303362\ttotal: 10.6s\tremaining: 2.61s\n",
      "803:\tlearn: 1.8303294\ttotal: 10.6s\tremaining: 2.59s\n",
      "804:\tlearn: 1.8295800\ttotal: 10.6s\tremaining: 2.58s\n",
      "805:\tlearn: 1.8295545\ttotal: 10.7s\tremaining: 2.56s\n",
      "806:\tlearn: 1.8295541\ttotal: 10.7s\tremaining: 2.55s\n",
      "807:\tlearn: 1.8295467\ttotal: 10.7s\tremaining: 2.54s\n",
      "808:\tlearn: 1.8295358\ttotal: 10.7s\tremaining: 2.53s\n",
      "809:\tlearn: 1.8293093\ttotal: 10.7s\tremaining: 2.51s\n",
      "810:\tlearn: 1.8287489\ttotal: 10.7s\tremaining: 2.5s\n",
      "811:\tlearn: 1.8287373\ttotal: 10.7s\tremaining: 2.48s\n",
      "812:\tlearn: 1.8287371\ttotal: 10.7s\tremaining: 2.47s\n",
      "813:\tlearn: 1.8287363\ttotal: 10.8s\tremaining: 2.46s\n",
      "814:\tlearn: 1.8287346\ttotal: 10.8s\tremaining: 2.44s\n",
      "815:\tlearn: 1.8287339\ttotal: 10.8s\tremaining: 2.43s\n",
      "816:\tlearn: 1.8287339\ttotal: 10.8s\tremaining: 2.42s\n",
      "817:\tlearn: 1.8287335\ttotal: 10.8s\tremaining: 2.4s\n",
      "818:\tlearn: 1.8286987\ttotal: 10.8s\tremaining: 2.39s\n",
      "819:\tlearn: 1.8281363\ttotal: 10.8s\tremaining: 2.38s\n",
      "820:\tlearn: 1.8280479\ttotal: 10.8s\tremaining: 2.36s\n",
      "821:\tlearn: 1.8276493\ttotal: 10.9s\tremaining: 2.35s\n",
      "822:\tlearn: 1.8268274\ttotal: 10.9s\tremaining: 2.34s\n",
      "823:\tlearn: 1.8264169\ttotal: 10.9s\tremaining: 2.33s\n",
      "824:\tlearn: 1.8263886\ttotal: 10.9s\tremaining: 2.31s\n",
      "825:\tlearn: 1.8263750\ttotal: 10.9s\tremaining: 2.3s\n",
      "826:\tlearn: 1.8263749\ttotal: 10.9s\tremaining: 2.29s\n",
      "827:\tlearn: 1.8263730\ttotal: 10.9s\tremaining: 2.27s\n",
      "828:\tlearn: 1.8260267\ttotal: 11s\tremaining: 2.26s\n",
      "829:\tlearn: 1.8258656\ttotal: 11s\tremaining: 2.25s\n",
      "830:\tlearn: 1.8258629\ttotal: 11s\tremaining: 2.23s\n",
      "831:\tlearn: 1.8258373\ttotal: 11s\tremaining: 2.22s\n",
      "832:\tlearn: 1.8254103\ttotal: 11s\tremaining: 2.21s\n",
      "833:\tlearn: 1.8254049\ttotal: 11s\tremaining: 2.19s\n",
      "834:\tlearn: 1.8251628\ttotal: 11s\tremaining: 2.18s\n",
      "835:\tlearn: 1.8250594\ttotal: 11s\tremaining: 2.17s\n",
      "836:\tlearn: 1.8250525\ttotal: 11.1s\tremaining: 2.15s\n",
      "837:\tlearn: 1.8249997\ttotal: 11.1s\tremaining: 2.14s\n",
      "838:\tlearn: 1.8249952\ttotal: 11.1s\tremaining: 2.13s\n",
      "839:\tlearn: 1.8243873\ttotal: 11.1s\tremaining: 2.11s\n",
      "840:\tlearn: 1.8242864\ttotal: 11.1s\tremaining: 2.1s\n",
      "841:\tlearn: 1.8235289\ttotal: 11.1s\tremaining: 2.09s\n",
      "842:\tlearn: 1.8228979\ttotal: 11.1s\tremaining: 2.07s\n",
      "843:\tlearn: 1.8224114\ttotal: 11.2s\tremaining: 2.06s\n",
      "844:\tlearn: 1.8223955\ttotal: 11.2s\tremaining: 2.05s\n",
      "845:\tlearn: 1.8219351\ttotal: 11.2s\tremaining: 2.04s\n",
      "846:\tlearn: 1.8210646\ttotal: 11.2s\tremaining: 2.02s\n",
      "847:\tlearn: 1.8205301\ttotal: 11.2s\tremaining: 2.01s\n",
      "848:\tlearn: 1.8201789\ttotal: 11.2s\tremaining: 2s\n",
      "849:\tlearn: 1.8201455\ttotal: 11.2s\tremaining: 1.98s\n",
      "850:\tlearn: 1.8201360\ttotal: 11.3s\tremaining: 1.97s\n",
      "851:\tlearn: 1.8189997\ttotal: 11.3s\tremaining: 1.96s\n",
      "852:\tlearn: 1.8177793\ttotal: 11.3s\tremaining: 1.94s\n",
      "853:\tlearn: 1.8169578\ttotal: 11.3s\tremaining: 1.93s\n",
      "854:\tlearn: 1.8168910\ttotal: 11.3s\tremaining: 1.92s\n",
      "855:\tlearn: 1.8166394\ttotal: 11.3s\tremaining: 1.9s\n",
      "856:\tlearn: 1.8166316\ttotal: 11.3s\tremaining: 1.89s\n",
      "857:\tlearn: 1.8165926\ttotal: 11.3s\tremaining: 1.88s\n",
      "858:\tlearn: 1.8165923\ttotal: 11.4s\tremaining: 1.86s\n",
      "859:\tlearn: 1.8165877\ttotal: 11.4s\tremaining: 1.85s\n",
      "860:\tlearn: 1.8165790\ttotal: 11.4s\tremaining: 1.84s\n",
      "861:\tlearn: 1.8165775\ttotal: 11.4s\tremaining: 1.82s\n",
      "862:\tlearn: 1.8165409\ttotal: 11.4s\tremaining: 1.81s\n",
      "863:\tlearn: 1.8160103\ttotal: 11.4s\tremaining: 1.8s\n",
      "864:\tlearn: 1.8160090\ttotal: 11.4s\tremaining: 1.78s\n",
      "865:\tlearn: 1.8159908\ttotal: 11.4s\tremaining: 1.77s\n",
      "866:\tlearn: 1.8159908\ttotal: 11.5s\tremaining: 1.76s\n",
      "867:\tlearn: 1.8159876\ttotal: 11.5s\tremaining: 1.74s\n",
      "868:\tlearn: 1.8159821\ttotal: 11.5s\tremaining: 1.73s\n",
      "869:\tlearn: 1.8159760\ttotal: 11.5s\tremaining: 1.72s\n",
      "870:\tlearn: 1.8156613\ttotal: 11.5s\tremaining: 1.7s\n",
      "871:\tlearn: 1.8156592\ttotal: 11.5s\tremaining: 1.69s\n",
      "872:\tlearn: 1.8156098\ttotal: 11.5s\tremaining: 1.68s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "873:\tlearn: 1.8151547\ttotal: 11.5s\tremaining: 1.67s\n",
      "874:\tlearn: 1.8151545\ttotal: 11.6s\tremaining: 1.65s\n",
      "875:\tlearn: 1.8151339\ttotal: 11.6s\tremaining: 1.64s\n",
      "876:\tlearn: 1.8151283\ttotal: 11.6s\tremaining: 1.63s\n",
      "877:\tlearn: 1.8151266\ttotal: 11.6s\tremaining: 1.61s\n",
      "878:\tlearn: 1.8148831\ttotal: 11.6s\tremaining: 1.6s\n",
      "879:\tlearn: 1.8148519\ttotal: 11.6s\tremaining: 1.58s\n",
      "880:\tlearn: 1.8148466\ttotal: 11.6s\tremaining: 1.57s\n",
      "881:\tlearn: 1.8144122\ttotal: 11.7s\tremaining: 1.56s\n",
      "882:\tlearn: 1.8134778\ttotal: 11.7s\tremaining: 1.54s\n",
      "883:\tlearn: 1.8133705\ttotal: 11.7s\tremaining: 1.53s\n",
      "884:\tlearn: 1.8129507\ttotal: 11.7s\tremaining: 1.52s\n",
      "885:\tlearn: 1.8129502\ttotal: 11.7s\tremaining: 1.51s\n",
      "886:\tlearn: 1.8129500\ttotal: 11.7s\tremaining: 1.49s\n",
      "887:\tlearn: 1.8129004\ttotal: 11.7s\tremaining: 1.48s\n",
      "888:\tlearn: 1.8128916\ttotal: 11.7s\tremaining: 1.47s\n",
      "889:\tlearn: 1.8128893\ttotal: 11.8s\tremaining: 1.45s\n",
      "890:\tlearn: 1.8126067\ttotal: 11.8s\tremaining: 1.44s\n",
      "891:\tlearn: 1.8126002\ttotal: 11.8s\tremaining: 1.43s\n",
      "892:\tlearn: 1.8123055\ttotal: 11.8s\tremaining: 1.41s\n",
      "893:\tlearn: 1.8122961\ttotal: 11.8s\tremaining: 1.4s\n",
      "894:\tlearn: 1.8122879\ttotal: 11.8s\tremaining: 1.39s\n",
      "895:\tlearn: 1.8122483\ttotal: 11.8s\tremaining: 1.37s\n",
      "896:\tlearn: 1.8118450\ttotal: 11.8s\tremaining: 1.36s\n",
      "897:\tlearn: 1.8102263\ttotal: 11.9s\tremaining: 1.35s\n",
      "898:\tlearn: 1.8102074\ttotal: 11.9s\tremaining: 1.33s\n",
      "899:\tlearn: 1.8099767\ttotal: 11.9s\tremaining: 1.32s\n",
      "900:\tlearn: 1.8093113\ttotal: 11.9s\tremaining: 1.31s\n",
      "901:\tlearn: 1.8090741\ttotal: 11.9s\tremaining: 1.29s\n",
      "902:\tlearn: 1.8088269\ttotal: 11.9s\tremaining: 1.28s\n",
      "903:\tlearn: 1.8088265\ttotal: 11.9s\tremaining: 1.27s\n",
      "904:\tlearn: 1.8088261\ttotal: 11.9s\tremaining: 1.25s\n",
      "905:\tlearn: 1.8087018\ttotal: 12s\tremaining: 1.24s\n",
      "906:\tlearn: 1.8086457\ttotal: 12s\tremaining: 1.23s\n",
      "907:\tlearn: 1.8085866\ttotal: 12s\tremaining: 1.21s\n",
      "908:\tlearn: 1.8079731\ttotal: 12s\tremaining: 1.2s\n",
      "909:\tlearn: 1.8079565\ttotal: 12s\tremaining: 1.19s\n",
      "910:\tlearn: 1.8078179\ttotal: 12s\tremaining: 1.17s\n",
      "911:\tlearn: 1.8076980\ttotal: 12s\tremaining: 1.16s\n",
      "912:\tlearn: 1.8076941\ttotal: 12s\tremaining: 1.15s\n",
      "913:\tlearn: 1.8076780\ttotal: 12.1s\tremaining: 1.14s\n",
      "914:\tlearn: 1.8076253\ttotal: 12.1s\tremaining: 1.12s\n",
      "915:\tlearn: 1.8066530\ttotal: 12.1s\tremaining: 1.11s\n",
      "916:\tlearn: 1.8063972\ttotal: 12.1s\tremaining: 1.09s\n",
      "917:\tlearn: 1.8059128\ttotal: 12.1s\tremaining: 1.08s\n",
      "918:\tlearn: 1.8056541\ttotal: 12.1s\tremaining: 1.07s\n",
      "919:\tlearn: 1.8054477\ttotal: 12.1s\tremaining: 1.05s\n",
      "920:\tlearn: 1.8045014\ttotal: 12.1s\tremaining: 1.04s\n",
      "921:\tlearn: 1.8044929\ttotal: 12.2s\tremaining: 1.03s\n",
      "922:\tlearn: 1.8044704\ttotal: 12.2s\tremaining: 1.01s\n",
      "923:\tlearn: 1.8043779\ttotal: 12.2s\tremaining: 1s\n",
      "924:\tlearn: 1.8043273\ttotal: 12.2s\tremaining: 989ms\n",
      "925:\tlearn: 1.8043266\ttotal: 12.2s\tremaining: 976ms\n",
      "926:\tlearn: 1.8042706\ttotal: 12.2s\tremaining: 963ms\n",
      "927:\tlearn: 1.8041152\ttotal: 12.2s\tremaining: 950ms\n",
      "928:\tlearn: 1.8040961\ttotal: 12.3s\tremaining: 936ms\n",
      "929:\tlearn: 1.8040958\ttotal: 12.3s\tremaining: 923ms\n",
      "930:\tlearn: 1.8039140\ttotal: 12.3s\tremaining: 910ms\n",
      "931:\tlearn: 1.8039058\ttotal: 12.3s\tremaining: 897ms\n",
      "932:\tlearn: 1.8039024\ttotal: 12.3s\tremaining: 883ms\n",
      "933:\tlearn: 1.8039014\ttotal: 12.3s\tremaining: 870ms\n",
      "934:\tlearn: 1.8039013\ttotal: 12.3s\tremaining: 857ms\n",
      "935:\tlearn: 1.8038103\ttotal: 12.3s\tremaining: 844ms\n",
      "936:\tlearn: 1.8035783\ttotal: 12.4s\tremaining: 830ms\n",
      "937:\tlearn: 1.8034998\ttotal: 12.4s\tremaining: 817ms\n",
      "938:\tlearn: 1.8032956\ttotal: 12.4s\tremaining: 804ms\n",
      "939:\tlearn: 1.8032488\ttotal: 12.4s\tremaining: 791ms\n",
      "940:\tlearn: 1.8025157\ttotal: 12.4s\tremaining: 778ms\n",
      "941:\tlearn: 1.8025154\ttotal: 12.4s\tremaining: 764ms\n",
      "942:\tlearn: 1.8025010\ttotal: 12.4s\tremaining: 751ms\n",
      "943:\tlearn: 1.8020710\ttotal: 12.4s\tremaining: 738ms\n",
      "944:\tlearn: 1.8020176\ttotal: 12.5s\tremaining: 725ms\n",
      "945:\tlearn: 1.8020044\ttotal: 12.5s\tremaining: 712ms\n",
      "946:\tlearn: 1.8016274\ttotal: 12.5s\tremaining: 698ms\n",
      "947:\tlearn: 1.8013827\ttotal: 12.5s\tremaining: 685ms\n",
      "948:\tlearn: 1.8012600\ttotal: 12.5s\tremaining: 672ms\n",
      "949:\tlearn: 1.8012583\ttotal: 12.5s\tremaining: 659ms\n",
      "950:\tlearn: 1.8012421\ttotal: 12.5s\tremaining: 646ms\n",
      "951:\tlearn: 1.8012316\ttotal: 12.5s\tremaining: 632ms\n",
      "952:\tlearn: 1.8012255\ttotal: 12.6s\tremaining: 619ms\n",
      "953:\tlearn: 1.8012253\ttotal: 12.6s\tremaining: 606ms\n",
      "954:\tlearn: 1.8007417\ttotal: 12.6s\tremaining: 593ms\n",
      "955:\tlearn: 1.8006510\ttotal: 12.6s\tremaining: 580ms\n",
      "956:\tlearn: 1.8006281\ttotal: 12.6s\tremaining: 566ms\n",
      "957:\tlearn: 1.8002469\ttotal: 12.6s\tremaining: 553ms\n",
      "958:\tlearn: 1.8001399\ttotal: 12.6s\tremaining: 540ms\n",
      "959:\tlearn: 1.7997649\ttotal: 12.6s\tremaining: 527ms\n",
      "960:\tlearn: 1.7997454\ttotal: 12.7s\tremaining: 514ms\n",
      "961:\tlearn: 1.7997422\ttotal: 12.7s\tremaining: 500ms\n",
      "962:\tlearn: 1.7997344\ttotal: 12.7s\tremaining: 487ms\n",
      "963:\tlearn: 1.7997329\ttotal: 12.7s\tremaining: 474ms\n",
      "964:\tlearn: 1.7996121\ttotal: 12.7s\tremaining: 461ms\n",
      "965:\tlearn: 1.7992145\ttotal: 12.7s\tremaining: 448ms\n",
      "966:\tlearn: 1.7989937\ttotal: 12.7s\tremaining: 434ms\n",
      "967:\tlearn: 1.7989136\ttotal: 12.7s\tremaining: 421ms\n",
      "968:\tlearn: 1.7983981\ttotal: 12.8s\tremaining: 408ms\n",
      "969:\tlearn: 1.7983507\ttotal: 12.8s\tremaining: 395ms\n",
      "970:\tlearn: 1.7979092\ttotal: 12.8s\tremaining: 382ms\n",
      "971:\tlearn: 1.7978799\ttotal: 12.8s\tremaining: 369ms\n",
      "972:\tlearn: 1.7978459\ttotal: 12.8s\tremaining: 355ms\n",
      "973:\tlearn: 1.7978151\ttotal: 12.8s\tremaining: 342ms\n",
      "974:\tlearn: 1.7978148\ttotal: 12.8s\tremaining: 329ms\n",
      "975:\tlearn: 1.7975961\ttotal: 12.8s\tremaining: 316ms\n",
      "976:\tlearn: 1.7974092\ttotal: 12.9s\tremaining: 303ms\n",
      "977:\tlearn: 1.7972362\ttotal: 12.9s\tremaining: 289ms\n",
      "978:\tlearn: 1.7970489\ttotal: 12.9s\tremaining: 276ms\n",
      "979:\tlearn: 1.7970210\ttotal: 12.9s\tremaining: 263ms\n",
      "980:\tlearn: 1.7962745\ttotal: 12.9s\tremaining: 250ms\n",
      "981:\tlearn: 1.7962735\ttotal: 12.9s\tremaining: 237ms\n",
      "982:\tlearn: 1.7957767\ttotal: 12.9s\tremaining: 224ms\n",
      "983:\tlearn: 1.7956106\ttotal: 12.9s\tremaining: 210ms\n",
      "984:\tlearn: 1.7955305\ttotal: 13s\tremaining: 197ms\n",
      "985:\tlearn: 1.7954301\ttotal: 13s\tremaining: 184ms\n",
      "986:\tlearn: 1.7953321\ttotal: 13s\tremaining: 171ms\n",
      "987:\tlearn: 1.7952687\ttotal: 13s\tremaining: 158ms\n",
      "988:\tlearn: 1.7952119\ttotal: 13s\tremaining: 145ms\n",
      "989:\tlearn: 1.7949192\ttotal: 13s\tremaining: 132ms\n",
      "990:\tlearn: 1.7943850\ttotal: 13s\tremaining: 118ms\n",
      "991:\tlearn: 1.7937503\ttotal: 13s\tremaining: 105ms\n",
      "992:\tlearn: 1.7936679\ttotal: 13.1s\tremaining: 92ms\n",
      "993:\tlearn: 1.7936667\ttotal: 13.1s\tremaining: 78.9ms\n",
      "994:\tlearn: 1.7936611\ttotal: 13.1s\tremaining: 65.7ms\n",
      "995:\tlearn: 1.7936466\ttotal: 13.1s\tremaining: 52.6ms\n",
      "996:\tlearn: 1.7935608\ttotal: 13.1s\tremaining: 39.4ms\n",
      "997:\tlearn: 1.7935053\ttotal: 13.1s\tremaining: 26.3ms\n",
      "998:\tlearn: 1.7934986\ttotal: 13.1s\tremaining: 13.1ms\n",
      "999:\tlearn: 1.7934966\ttotal: 13.1s\tremaining: 0us\n",
      "0:\tlearn: 12.4198105\ttotal: 10.6ms\tremaining: 48.5s\n",
      "1:\tlearn: 11.2301873\ttotal: 22.2ms\tremaining: 51s\n",
      "2:\tlearn: 10.1638199\ttotal: 33.7ms\tremaining: 51.6s\n",
      "3:\tlearn: 9.2356454\ttotal: 45.3ms\tremaining: 52s\n",
      "4:\tlearn: 8.4243530\ttotal: 57.2ms\tremaining: 52.5s\n",
      "5:\tlearn: 7.7234358\ttotal: 69ms\tremaining: 52.8s\n",
      "6:\tlearn: 7.1145660\ttotal: 80.7ms\tremaining: 52.9s\n",
      "7:\tlearn: 6.5865522\ttotal: 92.3ms\tremaining: 53s\n",
      "8:\tlearn: 6.1335882\ttotal: 104ms\tremaining: 53s\n",
      "9:\tlearn: 5.7407077\ttotal: 116ms\tremaining: 53.2s\n",
      "10:\tlearn: 5.4174034\ttotal: 128ms\tremaining: 53.3s\n",
      "11:\tlearn: 5.1373729\ttotal: 140ms\tremaining: 53.3s\n",
      "12:\tlearn: 4.9077211\ttotal: 152ms\tremaining: 53.4s\n",
      "13:\tlearn: 4.6986901\ttotal: 165ms\tremaining: 53.9s\n",
      "14:\tlearn: 4.5311095\ttotal: 177ms\tremaining: 54.2s\n",
      "15:\tlearn: 4.3889646\ttotal: 189ms\tremaining: 54.2s\n",
      "16:\tlearn: 4.2705081\ttotal: 201ms\tremaining: 54.2s\n",
      "17:\tlearn: 4.1664674\ttotal: 213ms\tremaining: 54.3s\n",
      "18:\tlearn: 4.0797610\ttotal: 227ms\tremaining: 54.6s\n",
      "19:\tlearn: 4.0031417\ttotal: 240ms\tremaining: 55s\n",
      "20:\tlearn: 3.9366156\ttotal: 253ms\tremaining: 55.2s\n",
      "21:\tlearn: 3.8835950\ttotal: 265ms\tremaining: 55.2s\n",
      "22:\tlearn: 3.8337919\ttotal: 278ms\tremaining: 55.4s\n",
      "23:\tlearn: 3.7951471\ttotal: 290ms\tremaining: 55.4s\n",
      "24:\tlearn: 3.7634074\ttotal: 302ms\tremaining: 55.3s\n",
      "25:\tlearn: 3.7287467\ttotal: 315ms\tremaining: 55.4s\n",
      "26:\tlearn: 3.7028148\ttotal: 327ms\tremaining: 55.4s\n",
      "27:\tlearn: 3.6761528\ttotal: 340ms\tremaining: 55.5s\n",
      "28:\tlearn: 3.6530002\ttotal: 352ms\tremaining: 55.5s\n",
      "29:\tlearn: 3.6338786\ttotal: 365ms\tremaining: 55.5s\n",
      "30:\tlearn: 3.6199697\ttotal: 377ms\tremaining: 55.5s\n",
      "31:\tlearn: 3.6038030\ttotal: 388ms\tremaining: 55.4s\n",
      "32:\tlearn: 3.5900306\ttotal: 401ms\tremaining: 55.5s\n",
      "33:\tlearn: 3.5789816\ttotal: 413ms\tremaining: 55.4s\n",
      "34:\tlearn: 3.5656618\ttotal: 425ms\tremaining: 55.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35:\tlearn: 3.5571222\ttotal: 437ms\tremaining: 55.3s\n",
      "36:\tlearn: 3.5480371\ttotal: 450ms\tremaining: 55.4s\n",
      "37:\tlearn: 3.5399762\ttotal: 462ms\tremaining: 55.4s\n",
      "38:\tlearn: 3.5338531\ttotal: 474ms\tremaining: 55.4s\n",
      "39:\tlearn: 3.5247356\ttotal: 486ms\tremaining: 55.4s\n",
      "40:\tlearn: 3.5180903\ttotal: 499ms\tremaining: 55.5s\n",
      "41:\tlearn: 3.5110558\ttotal: 511ms\tremaining: 55.5s\n",
      "42:\tlearn: 3.5046418\ttotal: 522ms\tremaining: 55.3s\n",
      "43:\tlearn: 3.4951734\ttotal: 535ms\tremaining: 55.3s\n",
      "44:\tlearn: 3.4895933\ttotal: 546ms\tremaining: 55.3s\n",
      "45:\tlearn: 3.4829522\ttotal: 559ms\tremaining: 55.3s\n",
      "46:\tlearn: 3.4770750\ttotal: 571ms\tremaining: 55.3s\n",
      "47:\tlearn: 3.4705474\ttotal: 583ms\tremaining: 55.3s\n",
      "48:\tlearn: 3.4651990\ttotal: 595ms\tremaining: 55.3s\n",
      "49:\tlearn: 3.4595214\ttotal: 607ms\tremaining: 55.2s\n",
      "50:\tlearn: 3.4547844\ttotal: 619ms\tremaining: 55.2s\n",
      "51:\tlearn: 3.4500218\ttotal: 630ms\tremaining: 55.1s\n",
      "52:\tlearn: 3.4448369\ttotal: 642ms\tremaining: 55.1s\n",
      "53:\tlearn: 3.4384522\ttotal: 655ms\tremaining: 55.1s\n",
      "54:\tlearn: 3.4338282\ttotal: 668ms\tremaining: 55.2s\n",
      "55:\tlearn: 3.4294633\ttotal: 680ms\tremaining: 55.2s\n",
      "56:\tlearn: 3.4243435\ttotal: 692ms\tremaining: 55.2s\n",
      "57:\tlearn: 3.4189402\ttotal: 704ms\tremaining: 55.1s\n",
      "58:\tlearn: 3.4125189\ttotal: 716ms\tremaining: 55.1s\n",
      "59:\tlearn: 3.4055886\ttotal: 728ms\tremaining: 55.1s\n",
      "60:\tlearn: 3.4002471\ttotal: 739ms\tremaining: 55s\n",
      "61:\tlearn: 3.3962387\ttotal: 751ms\tremaining: 55s\n",
      "62:\tlearn: 3.3930074\ttotal: 762ms\tremaining: 54.9s\n",
      "63:\tlearn: 3.3877094\ttotal: 774ms\tremaining: 54.8s\n",
      "64:\tlearn: 3.3839294\ttotal: 787ms\tremaining: 54.9s\n",
      "65:\tlearn: 3.3800408\ttotal: 798ms\tremaining: 54.8s\n",
      "66:\tlearn: 3.3776403\ttotal: 810ms\tremaining: 54.8s\n",
      "67:\tlearn: 3.3744260\ttotal: 821ms\tremaining: 54.7s\n",
      "68:\tlearn: 3.3715778\ttotal: 833ms\tremaining: 54.7s\n",
      "69:\tlearn: 3.3674400\ttotal: 845ms\tremaining: 54.7s\n",
      "70:\tlearn: 3.3626284\ttotal: 857ms\tremaining: 54.6s\n",
      "71:\tlearn: 3.3599595\ttotal: 870ms\tremaining: 54.7s\n",
      "72:\tlearn: 3.3550960\ttotal: 885ms\tremaining: 54.8s\n",
      "73:\tlearn: 3.3514151\ttotal: 897ms\tremaining: 54.8s\n",
      "74:\tlearn: 3.3467131\ttotal: 910ms\tremaining: 54.9s\n",
      "75:\tlearn: 3.3446341\ttotal: 921ms\tremaining: 54.8s\n",
      "76:\tlearn: 3.3422952\ttotal: 933ms\tremaining: 54.8s\n",
      "77:\tlearn: 3.3387185\ttotal: 945ms\tremaining: 54.8s\n",
      "78:\tlearn: 3.3351184\ttotal: 957ms\tremaining: 54.7s\n",
      "79:\tlearn: 3.3331711\ttotal: 968ms\tremaining: 54.7s\n",
      "80:\tlearn: 3.3296341\ttotal: 980ms\tremaining: 54.7s\n",
      "81:\tlearn: 3.3272091\ttotal: 992ms\tremaining: 54.6s\n",
      "82:\tlearn: 3.3246693\ttotal: 1s\tremaining: 54.6s\n",
      "83:\tlearn: 3.3198293\ttotal: 1.01s\tremaining: 54.6s\n",
      "84:\tlearn: 3.3162209\ttotal: 1.03s\tremaining: 54.6s\n",
      "85:\tlearn: 3.3132634\ttotal: 1.04s\tremaining: 54.6s\n",
      "86:\tlearn: 3.3118150\ttotal: 1.05s\tremaining: 54.5s\n",
      "87:\tlearn: 3.3077273\ttotal: 1.06s\tremaining: 54.5s\n",
      "88:\tlearn: 3.3045296\ttotal: 1.07s\tremaining: 54.4s\n",
      "89:\tlearn: 3.3019562\ttotal: 1.09s\tremaining: 54.5s\n",
      "90:\tlearn: 3.2995822\ttotal: 1.1s\tremaining: 54.6s\n",
      "91:\tlearn: 3.2944991\ttotal: 1.11s\tremaining: 54.6s\n",
      "92:\tlearn: 3.2921507\ttotal: 1.13s\tremaining: 54.6s\n",
      "93:\tlearn: 3.2884058\ttotal: 1.14s\tremaining: 54.5s\n",
      "94:\tlearn: 3.2866248\ttotal: 1.15s\tremaining: 54.5s\n",
      "95:\tlearn: 3.2843383\ttotal: 1.16s\tremaining: 54.5s\n",
      "96:\tlearn: 3.2808492\ttotal: 1.18s\tremaining: 54.6s\n",
      "97:\tlearn: 3.2781473\ttotal: 1.19s\tremaining: 54.6s\n",
      "98:\tlearn: 3.2750371\ttotal: 1.2s\tremaining: 54.6s\n",
      "99:\tlearn: 3.2718551\ttotal: 1.21s\tremaining: 54.6s\n",
      "100:\tlearn: 3.2696429\ttotal: 1.23s\tremaining: 54.6s\n",
      "101:\tlearn: 3.2670110\ttotal: 1.24s\tremaining: 54.7s\n",
      "102:\tlearn: 3.2636485\ttotal: 1.26s\tremaining: 54.9s\n",
      "103:\tlearn: 3.2596045\ttotal: 1.27s\tremaining: 54.9s\n",
      "104:\tlearn: 3.2574819\ttotal: 1.28s\tremaining: 54.8s\n",
      "105:\tlearn: 3.2557025\ttotal: 1.29s\tremaining: 54.8s\n",
      "106:\tlearn: 3.2526439\ttotal: 1.3s\tremaining: 54.8s\n",
      "107:\tlearn: 3.2479461\ttotal: 1.32s\tremaining: 54.9s\n",
      "108:\tlearn: 3.2448252\ttotal: 1.33s\tremaining: 54.9s\n",
      "109:\tlearn: 3.2413446\ttotal: 1.34s\tremaining: 54.8s\n",
      "110:\tlearn: 3.2386462\ttotal: 1.36s\tremaining: 54.8s\n",
      "111:\tlearn: 3.2367006\ttotal: 1.37s\tremaining: 54.8s\n",
      "112:\tlearn: 3.2317601\ttotal: 1.38s\tremaining: 54.8s\n",
      "113:\tlearn: 3.2298023\ttotal: 1.39s\tremaining: 54.7s\n",
      "114:\tlearn: 3.2263915\ttotal: 1.4s\tremaining: 54.7s\n",
      "115:\tlearn: 3.2227542\ttotal: 1.41s\tremaining: 54.7s\n",
      "116:\tlearn: 3.2200405\ttotal: 1.43s\tremaining: 54.7s\n",
      "117:\tlearn: 3.2172930\ttotal: 1.44s\tremaining: 54.6s\n",
      "118:\tlearn: 3.2139310\ttotal: 1.45s\tremaining: 54.6s\n",
      "119:\tlearn: 3.2108091\ttotal: 1.46s\tremaining: 54.6s\n",
      "120:\tlearn: 3.2090132\ttotal: 1.47s\tremaining: 54.5s\n",
      "121:\tlearn: 3.2050119\ttotal: 1.48s\tremaining: 54.5s\n",
      "122:\tlearn: 3.2030187\ttotal: 1.5s\tremaining: 54.4s\n",
      "123:\tlearn: 3.1993718\ttotal: 1.51s\tremaining: 54.5s\n",
      "124:\tlearn: 3.1966029\ttotal: 1.52s\tremaining: 54.5s\n",
      "125:\tlearn: 3.1950024\ttotal: 1.53s\tremaining: 54.5s\n",
      "126:\tlearn: 3.1922611\ttotal: 1.55s\tremaining: 54.5s\n",
      "127:\tlearn: 3.1905206\ttotal: 1.56s\tremaining: 54.4s\n",
      "128:\tlearn: 3.1874358\ttotal: 1.57s\tremaining: 54.4s\n",
      "129:\tlearn: 3.1842349\ttotal: 1.58s\tremaining: 54.4s\n",
      "130:\tlearn: 3.1814932\ttotal: 1.59s\tremaining: 54.4s\n",
      "131:\tlearn: 3.1786926\ttotal: 1.61s\tremaining: 54.3s\n",
      "132:\tlearn: 3.1752881\ttotal: 1.62s\tremaining: 54.3s\n",
      "133:\tlearn: 3.1733889\ttotal: 1.63s\tremaining: 54.3s\n",
      "134:\tlearn: 3.1704799\ttotal: 1.64s\tremaining: 54.3s\n",
      "135:\tlearn: 3.1665639\ttotal: 1.65s\tremaining: 54.3s\n",
      "136:\tlearn: 3.1642296\ttotal: 1.67s\tremaining: 54.3s\n",
      "137:\tlearn: 3.1616564\ttotal: 1.68s\tremaining: 54.3s\n",
      "138:\tlearn: 3.1578794\ttotal: 1.69s\tremaining: 54.3s\n",
      "139:\tlearn: 3.1557852\ttotal: 1.7s\tremaining: 54.2s\n",
      "140:\tlearn: 3.1535947\ttotal: 1.71s\tremaining: 54.2s\n",
      "141:\tlearn: 3.1514466\ttotal: 1.73s\tremaining: 54.2s\n",
      "142:\tlearn: 3.1475090\ttotal: 1.74s\tremaining: 54.2s\n",
      "143:\tlearn: 3.1447612\ttotal: 1.75s\tremaining: 54.3s\n",
      "144:\tlearn: 3.1432568\ttotal: 1.77s\tremaining: 54.2s\n",
      "145:\tlearn: 3.1404628\ttotal: 1.78s\tremaining: 54.3s\n",
      "146:\tlearn: 3.1369470\ttotal: 1.79s\tremaining: 54.3s\n",
      "147:\tlearn: 3.1350885\ttotal: 1.8s\tremaining: 54.3s\n",
      "148:\tlearn: 3.1332240\ttotal: 1.81s\tremaining: 54.2s\n",
      "149:\tlearn: 3.1305415\ttotal: 1.83s\tremaining: 54.2s\n",
      "150:\tlearn: 3.1265272\ttotal: 1.84s\tremaining: 54.2s\n",
      "151:\tlearn: 3.1236194\ttotal: 1.85s\tremaining: 54.2s\n",
      "152:\tlearn: 3.1212439\ttotal: 1.86s\tremaining: 54.1s\n",
      "153:\tlearn: 3.1196386\ttotal: 1.87s\tremaining: 54.1s\n",
      "154:\tlearn: 3.1177159\ttotal: 1.89s\tremaining: 54.1s\n",
      "155:\tlearn: 3.1155308\ttotal: 1.9s\tremaining: 54s\n",
      "156:\tlearn: 3.1136303\ttotal: 1.91s\tremaining: 54s\n",
      "157:\tlearn: 3.1101008\ttotal: 1.92s\tremaining: 54s\n",
      "158:\tlearn: 3.1063845\ttotal: 1.94s\tremaining: 54s\n",
      "159:\tlearn: 3.1048982\ttotal: 1.95s\tremaining: 54s\n",
      "160:\tlearn: 3.1030099\ttotal: 1.96s\tremaining: 54.1s\n",
      "161:\tlearn: 3.1003577\ttotal: 1.97s\tremaining: 54.1s\n",
      "162:\tlearn: 3.0976152\ttotal: 1.99s\tremaining: 54.1s\n",
      "163:\tlearn: 3.0953064\ttotal: 2s\tremaining: 54.2s\n",
      "164:\tlearn: 3.0938751\ttotal: 2.02s\tremaining: 54.2s\n",
      "165:\tlearn: 3.0911824\ttotal: 2.03s\tremaining: 54.3s\n",
      "166:\tlearn: 3.0886584\ttotal: 2.05s\tremaining: 54.3s\n",
      "167:\tlearn: 3.0869691\ttotal: 2.06s\tremaining: 54.3s\n",
      "168:\tlearn: 3.0851009\ttotal: 2.07s\tremaining: 54.3s\n",
      "169:\tlearn: 3.0828622\ttotal: 2.09s\tremaining: 54.4s\n",
      "170:\tlearn: 3.0813467\ttotal: 2.1s\tremaining: 54.4s\n",
      "171:\tlearn: 3.0790229\ttotal: 2.11s\tremaining: 54.4s\n",
      "172:\tlearn: 3.0775886\ttotal: 2.13s\tremaining: 54.4s\n",
      "173:\tlearn: 3.0750050\ttotal: 2.14s\tremaining: 54.4s\n",
      "174:\tlearn: 3.0733393\ttotal: 2.15s\tremaining: 54.4s\n",
      "175:\tlearn: 3.0710854\ttotal: 2.17s\tremaining: 54.5s\n",
      "176:\tlearn: 3.0691301\ttotal: 2.18s\tremaining: 54.5s\n",
      "177:\tlearn: 3.0670455\ttotal: 2.19s\tremaining: 54.4s\n",
      "178:\tlearn: 3.0648250\ttotal: 2.2s\tremaining: 54.4s\n",
      "179:\tlearn: 3.0620161\ttotal: 2.22s\tremaining: 54.4s\n",
      "180:\tlearn: 3.0604911\ttotal: 2.23s\tremaining: 54.4s\n",
      "181:\tlearn: 3.0580925\ttotal: 2.24s\tremaining: 54.4s\n",
      "182:\tlearn: 3.0558319\ttotal: 2.25s\tremaining: 54.4s\n",
      "183:\tlearn: 3.0542714\ttotal: 2.27s\tremaining: 54.4s\n",
      "184:\tlearn: 3.0522180\ttotal: 2.28s\tremaining: 54.3s\n",
      "185:\tlearn: 3.0508105\ttotal: 2.29s\tremaining: 54.3s\n",
      "186:\tlearn: 3.0483023\ttotal: 2.3s\tremaining: 54.3s\n",
      "187:\tlearn: 3.0461918\ttotal: 2.31s\tremaining: 54.3s\n",
      "188:\tlearn: 3.0438777\ttotal: 2.33s\tremaining: 54.3s\n",
      "189:\tlearn: 3.0418928\ttotal: 2.34s\tremaining: 54.2s\n",
      "190:\tlearn: 3.0398302\ttotal: 2.35s\tremaining: 54.2s\n",
      "191:\tlearn: 3.0379402\ttotal: 2.36s\tremaining: 54.2s\n",
      "192:\tlearn: 3.0367582\ttotal: 2.37s\tremaining: 54.2s\n",
      "193:\tlearn: 3.0350853\ttotal: 2.39s\tremaining: 54.2s\n",
      "194:\tlearn: 3.0337027\ttotal: 2.4s\tremaining: 54.2s\n",
      "195:\tlearn: 3.0322398\ttotal: 2.41s\tremaining: 54.2s\n",
      "196:\tlearn: 3.0297885\ttotal: 2.42s\tremaining: 54.1s\n",
      "197:\tlearn: 3.0279498\ttotal: 2.44s\tremaining: 54.1s\n",
      "198:\tlearn: 3.0257003\ttotal: 2.45s\tremaining: 54.1s\n",
      "199:\tlearn: 3.0242268\ttotal: 2.46s\tremaining: 54.1s\n",
      "200:\tlearn: 3.0212706\ttotal: 2.47s\tremaining: 54s\n",
      "201:\tlearn: 3.0196201\ttotal: 2.48s\tremaining: 54s\n",
      "202:\tlearn: 3.0175662\ttotal: 2.49s\tremaining: 54s\n",
      "203:\tlearn: 3.0163673\ttotal: 2.5s\tremaining: 53.9s\n",
      "204:\tlearn: 3.0140008\ttotal: 2.52s\tremaining: 53.9s\n",
      "205:\tlearn: 3.0127784\ttotal: 2.53s\tremaining: 53.9s\n",
      "206:\tlearn: 3.0112393\ttotal: 2.54s\tremaining: 53.9s\n",
      "207:\tlearn: 3.0100708\ttotal: 2.55s\tremaining: 53.8s\n",
      "208:\tlearn: 3.0061187\ttotal: 2.56s\tremaining: 53.8s\n",
      "209:\tlearn: 3.0041811\ttotal: 2.58s\tremaining: 53.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210:\tlearn: 3.0022668\ttotal: 2.59s\tremaining: 53.8s\n",
      "211:\tlearn: 3.0010547\ttotal: 2.6s\tremaining: 53.8s\n",
      "212:\tlearn: 2.9990215\ttotal: 2.61s\tremaining: 53.8s\n",
      "213:\tlearn: 2.9972104\ttotal: 2.62s\tremaining: 53.7s\n",
      "214:\tlearn: 2.9956337\ttotal: 2.63s\tremaining: 53.7s\n",
      "215:\tlearn: 2.9931294\ttotal: 2.65s\tremaining: 53.7s\n",
      "216:\tlearn: 2.9918566\ttotal: 2.66s\tremaining: 53.7s\n",
      "217:\tlearn: 2.9897527\ttotal: 2.67s\tremaining: 53.6s\n",
      "218:\tlearn: 2.9882157\ttotal: 2.68s\tremaining: 53.6s\n",
      "219:\tlearn: 2.9867114\ttotal: 2.69s\tremaining: 53.6s\n",
      "220:\tlearn: 2.9848711\ttotal: 2.71s\tremaining: 53.6s\n",
      "221:\tlearn: 2.9838062\ttotal: 2.72s\tremaining: 53.5s\n",
      "222:\tlearn: 2.9819420\ttotal: 2.73s\tremaining: 53.5s\n",
      "223:\tlearn: 2.9784612\ttotal: 2.74s\tremaining: 53.5s\n",
      "224:\tlearn: 2.9772279\ttotal: 2.75s\tremaining: 53.5s\n",
      "225:\tlearn: 2.9756018\ttotal: 2.76s\tremaining: 53.5s\n",
      "226:\tlearn: 2.9741205\ttotal: 2.77s\tremaining: 53.4s\n",
      "227:\tlearn: 2.9717945\ttotal: 2.79s\tremaining: 53.4s\n",
      "228:\tlearn: 2.9700305\ttotal: 2.8s\tremaining: 53.4s\n",
      "229:\tlearn: 2.9688005\ttotal: 2.81s\tremaining: 53.4s\n",
      "230:\tlearn: 2.9670564\ttotal: 2.82s\tremaining: 53.4s\n",
      "231:\tlearn: 2.9650107\ttotal: 2.83s\tremaining: 53.3s\n",
      "232:\tlearn: 2.9631725\ttotal: 2.85s\tremaining: 53.3s\n",
      "233:\tlearn: 2.9619167\ttotal: 2.86s\tremaining: 53.3s\n",
      "234:\tlearn: 2.9607748\ttotal: 2.87s\tremaining: 53.3s\n",
      "235:\tlearn: 2.9589458\ttotal: 2.88s\tremaining: 53.3s\n",
      "236:\tlearn: 2.9578992\ttotal: 2.89s\tremaining: 53.2s\n",
      "237:\tlearn: 2.9565003\ttotal: 2.9s\tremaining: 53.2s\n",
      "238:\tlearn: 2.9553137\ttotal: 2.92s\tremaining: 53.2s\n",
      "239:\tlearn: 2.9535524\ttotal: 2.93s\tremaining: 53.2s\n",
      "240:\tlearn: 2.9514842\ttotal: 2.94s\tremaining: 53.2s\n",
      "241:\tlearn: 2.9491368\ttotal: 2.95s\tremaining: 53.1s\n",
      "242:\tlearn: 2.9471719\ttotal: 2.96s\tremaining: 53.1s\n",
      "243:\tlearn: 2.9441807\ttotal: 2.98s\tremaining: 53.1s\n",
      "244:\tlearn: 2.9418573\ttotal: 2.99s\tremaining: 53.1s\n",
      "245:\tlearn: 2.9396031\ttotal: 3s\tremaining: 53.1s\n",
      "246:\tlearn: 2.9389329\ttotal: 3.02s\tremaining: 53.1s\n",
      "247:\tlearn: 2.9372064\ttotal: 3.03s\tremaining: 53.1s\n",
      "248:\tlearn: 2.9363172\ttotal: 3.04s\tremaining: 53.1s\n",
      "249:\tlearn: 2.9347128\ttotal: 3.06s\tremaining: 53.2s\n",
      "250:\tlearn: 2.9327646\ttotal: 3.07s\tremaining: 53.2s\n",
      "251:\tlearn: 2.9308883\ttotal: 3.08s\tremaining: 53.2s\n",
      "252:\tlearn: 2.9282369\ttotal: 3.1s\tremaining: 53.2s\n",
      "253:\tlearn: 2.9267734\ttotal: 3.11s\tremaining: 53.2s\n",
      "254:\tlearn: 2.9252524\ttotal: 3.12s\tremaining: 53.2s\n",
      "255:\tlearn: 2.9238140\ttotal: 3.14s\tremaining: 53.2s\n",
      "256:\tlearn: 2.9225809\ttotal: 3.15s\tremaining: 53.2s\n",
      "257:\tlearn: 2.9212953\ttotal: 3.16s\tremaining: 53.2s\n",
      "258:\tlearn: 2.9198328\ttotal: 3.18s\tremaining: 53.2s\n",
      "259:\tlearn: 2.9170909\ttotal: 3.19s\tremaining: 53.2s\n",
      "260:\tlearn: 2.9154606\ttotal: 3.2s\tremaining: 53.2s\n",
      "261:\tlearn: 2.9142515\ttotal: 3.21s\tremaining: 53.2s\n",
      "262:\tlearn: 2.9133605\ttotal: 3.23s\tremaining: 53.2s\n",
      "263:\tlearn: 2.9121310\ttotal: 3.24s\tremaining: 53.2s\n",
      "264:\tlearn: 2.9102295\ttotal: 3.25s\tremaining: 53.2s\n",
      "265:\tlearn: 2.9081617\ttotal: 3.26s\tremaining: 53.1s\n",
      "266:\tlearn: 2.9066993\ttotal: 3.27s\tremaining: 53.1s\n",
      "267:\tlearn: 2.9044456\ttotal: 3.29s\tremaining: 53.1s\n",
      "268:\tlearn: 2.9022534\ttotal: 3.3s\tremaining: 53.1s\n",
      "269:\tlearn: 2.9010667\ttotal: 3.31s\tremaining: 53s\n",
      "270:\tlearn: 2.8988680\ttotal: 3.32s\tremaining: 53s\n",
      "271:\tlearn: 2.8976282\ttotal: 3.33s\tremaining: 53s\n",
      "272:\tlearn: 2.8967103\ttotal: 3.34s\tremaining: 53s\n",
      "273:\tlearn: 2.8955511\ttotal: 3.36s\tremaining: 53s\n",
      "274:\tlearn: 2.8941295\ttotal: 3.37s\tremaining: 53s\n",
      "275:\tlearn: 2.8929000\ttotal: 3.38s\tremaining: 52.9s\n",
      "276:\tlearn: 2.8911189\ttotal: 3.39s\tremaining: 52.9s\n",
      "277:\tlearn: 2.8891127\ttotal: 3.4s\tremaining: 52.9s\n",
      "278:\tlearn: 2.8882330\ttotal: 3.42s\tremaining: 52.9s\n",
      "279:\tlearn: 2.8869849\ttotal: 3.43s\tremaining: 52.9s\n",
      "280:\tlearn: 2.8856632\ttotal: 3.44s\tremaining: 52.9s\n",
      "281:\tlearn: 2.8843801\ttotal: 3.45s\tremaining: 52.8s\n",
      "282:\tlearn: 2.8824534\ttotal: 3.46s\tremaining: 52.8s\n",
      "283:\tlearn: 2.8808705\ttotal: 3.48s\tremaining: 52.8s\n",
      "284:\tlearn: 2.8790596\ttotal: 3.49s\tremaining: 52.8s\n",
      "285:\tlearn: 2.8772918\ttotal: 3.5s\tremaining: 52.7s\n",
      "286:\tlearn: 2.8749604\ttotal: 3.51s\tremaining: 52.7s\n",
      "287:\tlearn: 2.8732941\ttotal: 3.52s\tremaining: 52.7s\n",
      "288:\tlearn: 2.8722342\ttotal: 3.53s\tremaining: 52.7s\n",
      "289:\tlearn: 2.8713774\ttotal: 3.54s\tremaining: 52.6s\n",
      "290:\tlearn: 2.8699007\ttotal: 3.56s\tremaining: 52.6s\n",
      "291:\tlearn: 2.8688474\ttotal: 3.57s\tremaining: 52.6s\n",
      "292:\tlearn: 2.8677171\ttotal: 3.58s\tremaining: 52.6s\n",
      "293:\tlearn: 2.8649616\ttotal: 3.59s\tremaining: 52.6s\n",
      "294:\tlearn: 2.8630233\ttotal: 3.6s\tremaining: 52.6s\n",
      "295:\tlearn: 2.8619383\ttotal: 3.62s\tremaining: 52.5s\n",
      "296:\tlearn: 2.8605028\ttotal: 3.63s\tremaining: 52.5s\n",
      "297:\tlearn: 2.8596692\ttotal: 3.64s\tremaining: 52.5s\n",
      "298:\tlearn: 2.8583992\ttotal: 3.65s\tremaining: 52.5s\n",
      "299:\tlearn: 2.8562370\ttotal: 3.66s\tremaining: 52.5s\n",
      "300:\tlearn: 2.8551726\ttotal: 3.68s\tremaining: 52.5s\n",
      "301:\tlearn: 2.8536192\ttotal: 3.69s\tremaining: 52.5s\n",
      "302:\tlearn: 2.8518953\ttotal: 3.7s\tremaining: 52.4s\n",
      "303:\tlearn: 2.8508998\ttotal: 3.71s\tremaining: 52.4s\n",
      "304:\tlearn: 2.8489162\ttotal: 3.72s\tremaining: 52.4s\n",
      "305:\tlearn: 2.8479221\ttotal: 3.73s\tremaining: 52.4s\n",
      "306:\tlearn: 2.8457353\ttotal: 3.75s\tremaining: 52.3s\n",
      "307:\tlearn: 2.8432295\ttotal: 3.76s\tremaining: 52.3s\n",
      "308:\tlearn: 2.8411262\ttotal: 3.77s\tremaining: 52.3s\n",
      "309:\tlearn: 2.8403309\ttotal: 3.78s\tremaining: 52.3s\n",
      "310:\tlearn: 2.8394585\ttotal: 3.79s\tremaining: 52.3s\n",
      "311:\tlearn: 2.8381644\ttotal: 3.8s\tremaining: 52.3s\n",
      "312:\tlearn: 2.8362419\ttotal: 3.82s\tremaining: 52.3s\n",
      "313:\tlearn: 2.8360916\ttotal: 3.83s\tremaining: 52.2s\n",
      "314:\tlearn: 2.8348292\ttotal: 3.84s\tremaining: 52.2s\n",
      "315:\tlearn: 2.8332775\ttotal: 3.85s\tremaining: 52.2s\n",
      "316:\tlearn: 2.8323448\ttotal: 3.87s\tremaining: 52.2s\n",
      "317:\tlearn: 2.8303826\ttotal: 3.88s\tremaining: 52.2s\n",
      "318:\tlearn: 2.8293117\ttotal: 3.89s\tremaining: 52.1s\n",
      "319:\tlearn: 2.8283039\ttotal: 3.9s\tremaining: 52.1s\n",
      "320:\tlearn: 2.8268431\ttotal: 3.91s\tremaining: 52.1s\n",
      "321:\tlearn: 2.8252171\ttotal: 3.92s\tremaining: 52.1s\n",
      "322:\tlearn: 2.8228948\ttotal: 3.93s\tremaining: 52.1s\n",
      "323:\tlearn: 2.8217798\ttotal: 3.94s\tremaining: 52s\n",
      "324:\tlearn: 2.8210472\ttotal: 3.96s\tremaining: 52s\n",
      "325:\tlearn: 2.8196593\ttotal: 3.97s\tremaining: 52s\n",
      "326:\tlearn: 2.8176031\ttotal: 3.98s\tremaining: 52s\n",
      "327:\tlearn: 2.8157485\ttotal: 3.99s\tremaining: 52s\n",
      "328:\tlearn: 2.8145486\ttotal: 4s\tremaining: 52s\n",
      "329:\tlearn: 2.8130227\ttotal: 4.02s\tremaining: 51.9s\n",
      "330:\tlearn: 2.8128989\ttotal: 4.03s\tremaining: 51.9s\n",
      "331:\tlearn: 2.8114991\ttotal: 4.04s\tremaining: 51.9s\n",
      "332:\tlearn: 2.8107454\ttotal: 4.05s\tremaining: 51.9s\n",
      "333:\tlearn: 2.8088988\ttotal: 4.07s\tremaining: 51.9s\n",
      "334:\tlearn: 2.8078374\ttotal: 4.08s\tremaining: 51.9s\n",
      "335:\tlearn: 2.8064478\ttotal: 4.09s\tremaining: 51.9s\n",
      "336:\tlearn: 2.8055580\ttotal: 4.1s\tremaining: 51.8s\n",
      "337:\tlearn: 2.8034993\ttotal: 4.11s\tremaining: 51.8s\n",
      "338:\tlearn: 2.8024040\ttotal: 4.12s\tremaining: 51.8s\n",
      "339:\tlearn: 2.8008817\ttotal: 4.13s\tremaining: 51.8s\n",
      "340:\tlearn: 2.8000775\ttotal: 4.15s\tremaining: 51.8s\n",
      "341:\tlearn: 2.7979456\ttotal: 4.16s\tremaining: 51.8s\n",
      "342:\tlearn: 2.7964688\ttotal: 4.17s\tremaining: 51.8s\n",
      "343:\tlearn: 2.7946774\ttotal: 4.18s\tremaining: 51.7s\n",
      "344:\tlearn: 2.7930786\ttotal: 4.2s\tremaining: 51.7s\n",
      "345:\tlearn: 2.7921326\ttotal: 4.21s\tremaining: 51.7s\n",
      "346:\tlearn: 2.7910639\ttotal: 4.22s\tremaining: 51.7s\n",
      "347:\tlearn: 2.7898678\ttotal: 4.23s\tremaining: 51.7s\n",
      "348:\tlearn: 2.7892079\ttotal: 4.24s\tremaining: 51.6s\n",
      "349:\tlearn: 2.7884784\ttotal: 4.25s\tremaining: 51.6s\n",
      "350:\tlearn: 2.7859269\ttotal: 4.26s\tremaining: 51.6s\n",
      "351:\tlearn: 2.7847940\ttotal: 4.28s\tremaining: 51.6s\n",
      "352:\tlearn: 2.7834487\ttotal: 4.29s\tremaining: 51.6s\n",
      "353:\tlearn: 2.7833634\ttotal: 4.3s\tremaining: 51.6s\n",
      "354:\tlearn: 2.7822736\ttotal: 4.31s\tremaining: 51.6s\n",
      "355:\tlearn: 2.7808249\ttotal: 4.32s\tremaining: 51.5s\n",
      "356:\tlearn: 2.7798698\ttotal: 4.33s\tremaining: 51.5s\n",
      "357:\tlearn: 2.7788292\ttotal: 4.35s\tremaining: 51.5s\n",
      "358:\tlearn: 2.7766615\ttotal: 4.36s\tremaining: 51.5s\n",
      "359:\tlearn: 2.7755391\ttotal: 4.37s\tremaining: 51.5s\n",
      "360:\tlearn: 2.7743705\ttotal: 4.38s\tremaining: 51.4s\n",
      "361:\tlearn: 2.7728432\ttotal: 4.39s\tremaining: 51.4s\n",
      "362:\tlearn: 2.7716217\ttotal: 4.41s\tremaining: 51.4s\n",
      "363:\tlearn: 2.7702538\ttotal: 4.42s\tremaining: 51.4s\n",
      "364:\tlearn: 2.7686969\ttotal: 4.43s\tremaining: 51.4s\n",
      "365:\tlearn: 2.7685875\ttotal: 4.44s\tremaining: 51.4s\n",
      "366:\tlearn: 2.7678659\ttotal: 4.45s\tremaining: 51.4s\n",
      "367:\tlearn: 2.7669791\ttotal: 4.47s\tremaining: 51.3s\n",
      "368:\tlearn: 2.7668442\ttotal: 4.48s\tremaining: 51.3s\n",
      "369:\tlearn: 2.7661169\ttotal: 4.49s\tremaining: 51.3s\n",
      "370:\tlearn: 2.7650675\ttotal: 4.5s\tremaining: 51.3s\n",
      "371:\tlearn: 2.7643043\ttotal: 4.51s\tremaining: 51.3s\n",
      "372:\tlearn: 2.7629684\ttotal: 4.53s\tremaining: 51.3s\n",
      "373:\tlearn: 2.7619071\ttotal: 4.54s\tremaining: 51.3s\n",
      "374:\tlearn: 2.7599400\ttotal: 4.55s\tremaining: 51.3s\n",
      "375:\tlearn: 2.7585561\ttotal: 4.56s\tremaining: 51.3s\n",
      "376:\tlearn: 2.7568325\ttotal: 4.58s\tremaining: 51.2s\n",
      "377:\tlearn: 2.7554491\ttotal: 4.59s\tremaining: 51.3s\n",
      "378:\tlearn: 2.7536209\ttotal: 4.61s\tremaining: 51.3s\n",
      "379:\tlearn: 2.7524400\ttotal: 4.62s\tremaining: 51.3s\n",
      "380:\tlearn: 2.7516252\ttotal: 4.63s\tremaining: 51.2s\n",
      "381:\tlearn: 2.7509696\ttotal: 4.64s\tremaining: 51.2s\n",
      "382:\tlearn: 2.7498870\ttotal: 4.65s\tremaining: 51.2s\n",
      "383:\tlearn: 2.7493578\ttotal: 4.67s\tremaining: 51.2s\n",
      "384:\tlearn: 2.7481920\ttotal: 4.68s\tremaining: 51.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385:\tlearn: 2.7463204\ttotal: 4.69s\tremaining: 51.2s\n",
      "386:\tlearn: 2.7454577\ttotal: 4.71s\tremaining: 51.2s\n",
      "387:\tlearn: 2.7446337\ttotal: 4.72s\tremaining: 51.2s\n",
      "388:\tlearn: 2.7433695\ttotal: 4.73s\tremaining: 51.2s\n",
      "389:\tlearn: 2.7416402\ttotal: 4.74s\tremaining: 51.2s\n",
      "390:\tlearn: 2.7407984\ttotal: 4.75s\tremaining: 51.2s\n",
      "391:\tlearn: 2.7401158\ttotal: 4.76s\tremaining: 51.1s\n",
      "392:\tlearn: 2.7387197\ttotal: 4.78s\tremaining: 51.1s\n",
      "393:\tlearn: 2.7381331\ttotal: 4.79s\tremaining: 51.1s\n",
      "394:\tlearn: 2.7372785\ttotal: 4.8s\tremaining: 51.1s\n",
      "395:\tlearn: 2.7359600\ttotal: 4.81s\tremaining: 51.1s\n",
      "396:\tlearn: 2.7346767\ttotal: 4.82s\tremaining: 51s\n",
      "397:\tlearn: 2.7346589\ttotal: 4.83s\tremaining: 51s\n",
      "398:\tlearn: 2.7332472\ttotal: 4.84s\tremaining: 51s\n",
      "399:\tlearn: 2.7319610\ttotal: 4.86s\tremaining: 51s\n",
      "400:\tlearn: 2.7311914\ttotal: 4.87s\tremaining: 51s\n",
      "401:\tlearn: 2.7296192\ttotal: 4.88s\tremaining: 51s\n",
      "402:\tlearn: 2.7289013\ttotal: 4.89s\tremaining: 51s\n",
      "403:\tlearn: 2.7272654\ttotal: 4.91s\tremaining: 51s\n",
      "404:\tlearn: 2.7260732\ttotal: 4.92s\tremaining: 50.9s\n",
      "405:\tlearn: 2.7250585\ttotal: 4.93s\tremaining: 50.9s\n",
      "406:\tlearn: 2.7237464\ttotal: 4.94s\tremaining: 50.9s\n",
      "407:\tlearn: 2.7229088\ttotal: 4.96s\tremaining: 50.9s\n",
      "408:\tlearn: 2.7221667\ttotal: 4.97s\tremaining: 50.9s\n",
      "409:\tlearn: 2.7214106\ttotal: 4.98s\tremaining: 50.9s\n",
      "410:\tlearn: 2.7200177\ttotal: 4.99s\tremaining: 50.8s\n",
      "411:\tlearn: 2.7185230\ttotal: 5s\tremaining: 50.8s\n",
      "412:\tlearn: 2.7175043\ttotal: 5.01s\tremaining: 50.8s\n",
      "413:\tlearn: 2.7164418\ttotal: 5.03s\tremaining: 50.8s\n",
      "414:\tlearn: 2.7149757\ttotal: 5.04s\tremaining: 50.8s\n",
      "415:\tlearn: 2.7138977\ttotal: 5.05s\tremaining: 50.8s\n",
      "416:\tlearn: 2.7130858\ttotal: 5.06s\tremaining: 50.8s\n",
      "417:\tlearn: 2.7117156\ttotal: 5.08s\tremaining: 50.8s\n",
      "418:\tlearn: 2.7109330\ttotal: 5.09s\tremaining: 50.8s\n",
      "419:\tlearn: 2.7095910\ttotal: 5.1s\tremaining: 50.7s\n",
      "420:\tlearn: 2.7083750\ttotal: 5.12s\tremaining: 50.8s\n",
      "421:\tlearn: 2.7075017\ttotal: 5.13s\tremaining: 50.7s\n",
      "422:\tlearn: 2.7074863\ttotal: 5.14s\tremaining: 50.7s\n",
      "423:\tlearn: 2.7062818\ttotal: 5.15s\tremaining: 50.7s\n",
      "424:\tlearn: 2.7048744\ttotal: 5.16s\tremaining: 50.7s\n",
      "425:\tlearn: 2.7037099\ttotal: 5.17s\tremaining: 50.7s\n",
      "426:\tlearn: 2.7019837\ttotal: 5.18s\tremaining: 50.7s\n",
      "427:\tlearn: 2.7015865\ttotal: 5.2s\tremaining: 50.6s\n",
      "428:\tlearn: 2.6997991\ttotal: 5.21s\tremaining: 50.6s\n",
      "429:\tlearn: 2.6982366\ttotal: 5.22s\tremaining: 50.6s\n",
      "430:\tlearn: 2.6976240\ttotal: 5.23s\tremaining: 50.6s\n",
      "431:\tlearn: 2.6955648\ttotal: 5.24s\tremaining: 50.6s\n",
      "432:\tlearn: 2.6947885\ttotal: 5.26s\tremaining: 50.6s\n",
      "433:\tlearn: 2.6936993\ttotal: 5.27s\tremaining: 50.5s\n",
      "434:\tlearn: 2.6926191\ttotal: 5.28s\tremaining: 50.5s\n",
      "435:\tlearn: 2.6913231\ttotal: 5.29s\tremaining: 50.5s\n",
      "436:\tlearn: 2.6901238\ttotal: 5.3s\tremaining: 50.5s\n",
      "437:\tlearn: 2.6890301\ttotal: 5.32s\tremaining: 50.5s\n",
      "438:\tlearn: 2.6881951\ttotal: 5.33s\tremaining: 50.5s\n",
      "439:\tlearn: 2.6881812\ttotal: 5.34s\tremaining: 50.5s\n",
      "440:\tlearn: 2.6874980\ttotal: 5.35s\tremaining: 50.4s\n",
      "441:\tlearn: 2.6861385\ttotal: 5.36s\tremaining: 50.4s\n",
      "442:\tlearn: 2.6853528\ttotal: 5.38s\tremaining: 50.4s\n",
      "443:\tlearn: 2.6841275\ttotal: 5.39s\tremaining: 50.4s\n",
      "444:\tlearn: 2.6839079\ttotal: 5.4s\tremaining: 50.4s\n",
      "445:\tlearn: 2.6827933\ttotal: 5.41s\tremaining: 50.4s\n",
      "446:\tlearn: 2.6814762\ttotal: 5.42s\tremaining: 50.3s\n",
      "447:\tlearn: 2.6801186\ttotal: 5.43s\tremaining: 50.3s\n",
      "448:\tlearn: 2.6776722\ttotal: 5.44s\tremaining: 50.3s\n",
      "449:\tlearn: 2.6765860\ttotal: 5.46s\tremaining: 50.3s\n",
      "450:\tlearn: 2.6753803\ttotal: 5.47s\tremaining: 50.3s\n",
      "451:\tlearn: 2.6749586\ttotal: 5.48s\tremaining: 50.3s\n",
      "452:\tlearn: 2.6739989\ttotal: 5.49s\tremaining: 50.3s\n",
      "453:\tlearn: 2.6729443\ttotal: 5.5s\tremaining: 50.2s\n",
      "454:\tlearn: 2.6723048\ttotal: 5.51s\tremaining: 50.2s\n",
      "455:\tlearn: 2.6714612\ttotal: 5.53s\tremaining: 50.2s\n",
      "456:\tlearn: 2.6714506\ttotal: 5.54s\tremaining: 50.2s\n",
      "457:\tlearn: 2.6703867\ttotal: 5.55s\tremaining: 50.2s\n",
      "458:\tlearn: 2.6693711\ttotal: 5.56s\tremaining: 50.2s\n",
      "459:\tlearn: 2.6676830\ttotal: 5.58s\tremaining: 50.2s\n",
      "460:\tlearn: 2.6665227\ttotal: 5.59s\tremaining: 50.2s\n",
      "461:\tlearn: 2.6657512\ttotal: 5.6s\tremaining: 50.1s\n",
      "462:\tlearn: 2.6657351\ttotal: 5.61s\tremaining: 50.1s\n",
      "463:\tlearn: 2.6649131\ttotal: 5.62s\tremaining: 50.1s\n",
      "464:\tlearn: 2.6640808\ttotal: 5.63s\tremaining: 50.1s\n",
      "465:\tlearn: 2.6629400\ttotal: 5.64s\tremaining: 50.1s\n",
      "466:\tlearn: 2.6613914\ttotal: 5.66s\tremaining: 50s\n",
      "467:\tlearn: 2.6606127\ttotal: 5.67s\tremaining: 50s\n",
      "468:\tlearn: 2.6599092\ttotal: 5.68s\tremaining: 50s\n",
      "469:\tlearn: 2.6598996\ttotal: 5.69s\tremaining: 50s\n",
      "470:\tlearn: 2.6593847\ttotal: 5.7s\tremaining: 50s\n",
      "471:\tlearn: 2.6583219\ttotal: 5.71s\tremaining: 50s\n",
      "472:\tlearn: 2.6573658\ttotal: 5.72s\tremaining: 49.9s\n",
      "473:\tlearn: 2.6560218\ttotal: 5.74s\tremaining: 49.9s\n",
      "474:\tlearn: 2.6546807\ttotal: 5.75s\tremaining: 49.9s\n",
      "475:\tlearn: 2.6539252\ttotal: 5.76s\tremaining: 49.9s\n",
      "476:\tlearn: 2.6533186\ttotal: 5.78s\tremaining: 49.9s\n",
      "477:\tlearn: 2.6525039\ttotal: 5.79s\tremaining: 49.9s\n",
      "478:\tlearn: 2.6509191\ttotal: 5.8s\tremaining: 49.9s\n",
      "479:\tlearn: 2.6502415\ttotal: 5.81s\tremaining: 49.9s\n",
      "480:\tlearn: 2.6489216\ttotal: 5.82s\tremaining: 49.9s\n",
      "481:\tlearn: 2.6477528\ttotal: 5.83s\tremaining: 49.8s\n",
      "482:\tlearn: 2.6476775\ttotal: 5.85s\tremaining: 49.8s\n",
      "483:\tlearn: 2.6460877\ttotal: 5.86s\tremaining: 49.8s\n",
      "484:\tlearn: 2.6451383\ttotal: 5.87s\tremaining: 49.8s\n",
      "485:\tlearn: 2.6444647\ttotal: 5.88s\tremaining: 49.8s\n",
      "486:\tlearn: 2.6431315\ttotal: 5.89s\tremaining: 49.7s\n",
      "487:\tlearn: 2.6421230\ttotal: 5.9s\tremaining: 49.7s\n",
      "488:\tlearn: 2.6408457\ttotal: 5.92s\tremaining: 49.7s\n",
      "489:\tlearn: 2.6401564\ttotal: 5.93s\tremaining: 49.7s\n",
      "490:\tlearn: 2.6386469\ttotal: 5.94s\tremaining: 49.7s\n",
      "491:\tlearn: 2.6376520\ttotal: 5.95s\tremaining: 49.7s\n",
      "492:\tlearn: 2.6360569\ttotal: 5.97s\tremaining: 49.7s\n",
      "493:\tlearn: 2.6353199\ttotal: 5.98s\tremaining: 49.7s\n",
      "494:\tlearn: 2.6343805\ttotal: 5.99s\tremaining: 49.7s\n",
      "495:\tlearn: 2.6331240\ttotal: 6s\tremaining: 49.6s\n",
      "496:\tlearn: 2.6319706\ttotal: 6.01s\tremaining: 49.6s\n",
      "497:\tlearn: 2.6310351\ttotal: 6.03s\tremaining: 49.6s\n",
      "498:\tlearn: 2.6299296\ttotal: 6.04s\tremaining: 49.6s\n",
      "499:\tlearn: 2.6286446\ttotal: 6.05s\tremaining: 49.6s\n",
      "500:\tlearn: 2.6277492\ttotal: 6.06s\tremaining: 49.6s\n",
      "501:\tlearn: 2.6268137\ttotal: 6.07s\tremaining: 49.6s\n",
      "502:\tlearn: 2.6257040\ttotal: 6.09s\tremaining: 49.6s\n",
      "503:\tlearn: 2.6249708\ttotal: 6.1s\tremaining: 49.5s\n",
      "504:\tlearn: 2.6240823\ttotal: 6.11s\tremaining: 49.5s\n",
      "505:\tlearn: 2.6231227\ttotal: 6.12s\tremaining: 49.5s\n",
      "506:\tlearn: 2.6223606\ttotal: 6.13s\tremaining: 49.5s\n",
      "507:\tlearn: 2.6215872\ttotal: 6.15s\tremaining: 49.5s\n",
      "508:\tlearn: 2.6205833\ttotal: 6.16s\tremaining: 49.5s\n",
      "509:\tlearn: 2.6190481\ttotal: 6.17s\tremaining: 49.5s\n",
      "510:\tlearn: 2.6176539\ttotal: 6.19s\tremaining: 49.5s\n",
      "511:\tlearn: 2.6155050\ttotal: 6.2s\tremaining: 49.5s\n",
      "512:\tlearn: 2.6154956\ttotal: 6.21s\tremaining: 49.4s\n",
      "513:\tlearn: 2.6140524\ttotal: 6.22s\tremaining: 49.4s\n",
      "514:\tlearn: 2.6132299\ttotal: 6.23s\tremaining: 49.4s\n",
      "515:\tlearn: 2.6125747\ttotal: 6.24s\tremaining: 49.4s\n",
      "516:\tlearn: 2.6119482\ttotal: 6.26s\tremaining: 49.4s\n",
      "517:\tlearn: 2.6112557\ttotal: 6.27s\tremaining: 49.4s\n",
      "518:\tlearn: 2.6102730\ttotal: 6.28s\tremaining: 49.4s\n",
      "519:\tlearn: 2.6097281\ttotal: 6.29s\tremaining: 49.3s\n",
      "520:\tlearn: 2.6084615\ttotal: 6.3s\tremaining: 49.3s\n",
      "521:\tlearn: 2.6078447\ttotal: 6.31s\tremaining: 49.3s\n",
      "522:\tlearn: 2.6066719\ttotal: 6.33s\tremaining: 49.3s\n",
      "523:\tlearn: 2.6053050\ttotal: 6.34s\tremaining: 49.3s\n",
      "524:\tlearn: 2.6044224\ttotal: 6.35s\tremaining: 49.3s\n",
      "525:\tlearn: 2.6030475\ttotal: 6.36s\tremaining: 49.3s\n",
      "526:\tlearn: 2.6020007\ttotal: 6.38s\tremaining: 49.3s\n",
      "527:\tlearn: 2.6007105\ttotal: 6.39s\tremaining: 49.2s\n",
      "528:\tlearn: 2.5998890\ttotal: 6.4s\tremaining: 49.2s\n",
      "529:\tlearn: 2.5988744\ttotal: 6.41s\tremaining: 49.2s\n",
      "530:\tlearn: 2.5983411\ttotal: 6.42s\tremaining: 49.2s\n",
      "531:\tlearn: 2.5968249\ttotal: 6.43s\tremaining: 49.2s\n",
      "532:\tlearn: 2.5956677\ttotal: 6.45s\tremaining: 49.2s\n",
      "533:\tlearn: 2.5945527\ttotal: 6.46s\tremaining: 49.2s\n",
      "534:\tlearn: 2.5937560\ttotal: 6.47s\tremaining: 49.2s\n",
      "535:\tlearn: 2.5925910\ttotal: 6.48s\tremaining: 49.1s\n",
      "536:\tlearn: 2.5917616\ttotal: 6.5s\tremaining: 49.1s\n",
      "537:\tlearn: 2.5908136\ttotal: 6.51s\tremaining: 49.1s\n",
      "538:\tlearn: 2.5893472\ttotal: 6.52s\tremaining: 49.1s\n",
      "539:\tlearn: 2.5882432\ttotal: 6.53s\tremaining: 49.1s\n",
      "540:\tlearn: 2.5876093\ttotal: 6.55s\tremaining: 49.1s\n",
      "541:\tlearn: 2.5863738\ttotal: 6.56s\tremaining: 49.1s\n",
      "542:\tlearn: 2.5852520\ttotal: 6.57s\tremaining: 49.1s\n",
      "543:\tlearn: 2.5842771\ttotal: 6.59s\tremaining: 49.1s\n",
      "544:\tlearn: 2.5833171\ttotal: 6.6s\tremaining: 49.1s\n",
      "545:\tlearn: 2.5824345\ttotal: 6.61s\tremaining: 49.1s\n",
      "546:\tlearn: 2.5813991\ttotal: 6.62s\tremaining: 49.1s\n",
      "547:\tlearn: 2.5808503\ttotal: 6.64s\tremaining: 49s\n",
      "548:\tlearn: 2.5799101\ttotal: 6.65s\tremaining: 49s\n",
      "549:\tlearn: 2.5790505\ttotal: 6.66s\tremaining: 49s\n",
      "550:\tlearn: 2.5784077\ttotal: 6.67s\tremaining: 49s\n",
      "551:\tlearn: 2.5773548\ttotal: 6.68s\tremaining: 49s\n",
      "552:\tlearn: 2.5768950\ttotal: 6.69s\tremaining: 49s\n",
      "553:\tlearn: 2.5767607\ttotal: 6.7s\tremaining: 48.9s\n",
      "554:\tlearn: 2.5752495\ttotal: 6.72s\tremaining: 48.9s\n",
      "555:\tlearn: 2.5741225\ttotal: 6.73s\tremaining: 48.9s\n",
      "556:\tlearn: 2.5731565\ttotal: 6.74s\tremaining: 48.9s\n",
      "557:\tlearn: 2.5731478\ttotal: 6.75s\tremaining: 48.9s\n",
      "558:\tlearn: 2.5722859\ttotal: 6.76s\tremaining: 48.9s\n",
      "559:\tlearn: 2.5716603\ttotal: 6.78s\tremaining: 48.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560:\tlearn: 2.5704831\ttotal: 6.79s\tremaining: 48.9s\n",
      "561:\tlearn: 2.5693686\ttotal: 6.8s\tremaining: 48.9s\n",
      "562:\tlearn: 2.5681291\ttotal: 6.83s\tremaining: 48.9s\n",
      "563:\tlearn: 2.5672163\ttotal: 6.84s\tremaining: 48.9s\n",
      "564:\tlearn: 2.5660635\ttotal: 6.86s\tremaining: 48.9s\n",
      "565:\tlearn: 2.5654630\ttotal: 6.87s\tremaining: 48.9s\n",
      "566:\tlearn: 2.5645000\ttotal: 6.88s\tremaining: 48.9s\n",
      "567:\tlearn: 2.5636030\ttotal: 6.89s\tremaining: 48.9s\n",
      "568:\tlearn: 2.5630859\ttotal: 6.9s\tremaining: 48.9s\n",
      "569:\tlearn: 2.5620889\ttotal: 6.92s\tremaining: 48.9s\n",
      "570:\tlearn: 2.5611145\ttotal: 6.93s\tremaining: 48.9s\n",
      "571:\tlearn: 2.5599603\ttotal: 6.94s\tremaining: 48.9s\n",
      "572:\tlearn: 2.5589541\ttotal: 6.95s\tremaining: 48.8s\n",
      "573:\tlearn: 2.5578497\ttotal: 6.97s\tremaining: 48.8s\n",
      "574:\tlearn: 2.5566891\ttotal: 6.98s\tremaining: 48.8s\n",
      "575:\tlearn: 2.5557973\ttotal: 6.99s\tremaining: 48.8s\n",
      "576:\tlearn: 2.5549934\ttotal: 7s\tremaining: 48.8s\n",
      "577:\tlearn: 2.5541979\ttotal: 7.02s\tremaining: 48.8s\n",
      "578:\tlearn: 2.5530070\ttotal: 7.03s\tremaining: 48.8s\n",
      "579:\tlearn: 2.5523298\ttotal: 7.04s\tremaining: 48.8s\n",
      "580:\tlearn: 2.5510333\ttotal: 7.05s\tremaining: 48.8s\n",
      "581:\tlearn: 2.5505819\ttotal: 7.07s\tremaining: 48.8s\n",
      "582:\tlearn: 2.5500631\ttotal: 7.08s\tremaining: 48.7s\n",
      "583:\tlearn: 2.5490893\ttotal: 7.09s\tremaining: 48.7s\n",
      "584:\tlearn: 2.5484858\ttotal: 7.1s\tremaining: 48.7s\n",
      "585:\tlearn: 2.5473153\ttotal: 7.11s\tremaining: 48.7s\n",
      "586:\tlearn: 2.5465170\ttotal: 7.13s\tremaining: 48.7s\n",
      "587:\tlearn: 2.5465093\ttotal: 7.13s\tremaining: 48.7s\n",
      "588:\tlearn: 2.5458704\ttotal: 7.15s\tremaining: 48.6s\n",
      "589:\tlearn: 2.5458633\ttotal: 7.16s\tremaining: 48.6s\n",
      "590:\tlearn: 2.5447679\ttotal: 7.17s\tremaining: 48.6s\n",
      "591:\tlearn: 2.5438998\ttotal: 7.18s\tremaining: 48.6s\n",
      "592:\tlearn: 2.5431871\ttotal: 7.19s\tremaining: 48.6s\n",
      "593:\tlearn: 2.5422805\ttotal: 7.21s\tremaining: 48.6s\n",
      "594:\tlearn: 2.5408788\ttotal: 7.22s\tremaining: 48.6s\n",
      "595:\tlearn: 2.5399358\ttotal: 7.23s\tremaining: 48.6s\n",
      "596:\tlearn: 2.5388420\ttotal: 7.25s\tremaining: 48.6s\n",
      "597:\tlearn: 2.5378529\ttotal: 7.26s\tremaining: 48.6s\n",
      "598:\tlearn: 2.5368419\ttotal: 7.27s\tremaining: 48.5s\n",
      "599:\tlearn: 2.5360598\ttotal: 7.28s\tremaining: 48.5s\n",
      "600:\tlearn: 2.5346891\ttotal: 7.3s\tremaining: 48.5s\n",
      "601:\tlearn: 2.5339397\ttotal: 7.31s\tremaining: 48.5s\n",
      "602:\tlearn: 2.5327760\ttotal: 7.32s\tremaining: 48.5s\n",
      "603:\tlearn: 2.5315143\ttotal: 7.33s\tremaining: 48.5s\n",
      "604:\tlearn: 2.5308299\ttotal: 7.34s\tremaining: 48.5s\n",
      "605:\tlearn: 2.5297290\ttotal: 7.36s\tremaining: 48.5s\n",
      "606:\tlearn: 2.5286219\ttotal: 7.37s\tremaining: 48.4s\n",
      "607:\tlearn: 2.5280014\ttotal: 7.38s\tremaining: 48.4s\n",
      "608:\tlearn: 2.5271424\ttotal: 7.39s\tremaining: 48.4s\n",
      "609:\tlearn: 2.5265439\ttotal: 7.4s\tremaining: 48.4s\n",
      "610:\tlearn: 2.5255308\ttotal: 7.42s\tremaining: 48.4s\n",
      "611:\tlearn: 2.5245728\ttotal: 7.43s\tremaining: 48.4s\n",
      "612:\tlearn: 2.5245660\ttotal: 7.44s\tremaining: 48.4s\n",
      "613:\tlearn: 2.5241774\ttotal: 7.45s\tremaining: 48.3s\n",
      "614:\tlearn: 2.5234046\ttotal: 7.46s\tremaining: 48.3s\n",
      "615:\tlearn: 2.5229066\ttotal: 7.47s\tremaining: 48.3s\n",
      "616:\tlearn: 2.5214202\ttotal: 7.48s\tremaining: 48.3s\n",
      "617:\tlearn: 2.5208843\ttotal: 7.5s\tremaining: 48.3s\n",
      "618:\tlearn: 2.5204524\ttotal: 7.51s\tremaining: 48.3s\n",
      "619:\tlearn: 2.5194776\ttotal: 7.52s\tremaining: 48.2s\n",
      "620:\tlearn: 2.5187414\ttotal: 7.53s\tremaining: 48.2s\n",
      "621:\tlearn: 2.5178911\ttotal: 7.54s\tremaining: 48.2s\n",
      "622:\tlearn: 2.5170737\ttotal: 7.55s\tremaining: 48.2s\n",
      "623:\tlearn: 2.5162928\ttotal: 7.57s\tremaining: 48.2s\n",
      "624:\tlearn: 2.5154930\ttotal: 7.58s\tremaining: 48.2s\n",
      "625:\tlearn: 2.5148303\ttotal: 7.59s\tremaining: 48.2s\n",
      "626:\tlearn: 2.5141275\ttotal: 7.6s\tremaining: 48.1s\n",
      "627:\tlearn: 2.5130561\ttotal: 7.61s\tremaining: 48.1s\n",
      "628:\tlearn: 2.5118639\ttotal: 7.63s\tremaining: 48.1s\n",
      "629:\tlearn: 2.5118585\ttotal: 7.64s\tremaining: 48.1s\n",
      "630:\tlearn: 2.5112901\ttotal: 7.65s\tremaining: 48.1s\n",
      "631:\tlearn: 2.5107059\ttotal: 7.66s\tremaining: 48.1s\n",
      "632:\tlearn: 2.5098802\ttotal: 7.67s\tremaining: 48.1s\n",
      "633:\tlearn: 2.5094209\ttotal: 7.68s\tremaining: 48s\n",
      "634:\tlearn: 2.5088814\ttotal: 7.7s\tremaining: 48s\n",
      "635:\tlearn: 2.5079991\ttotal: 7.71s\tremaining: 48s\n",
      "636:\tlearn: 2.5076185\ttotal: 7.72s\tremaining: 48s\n",
      "637:\tlearn: 2.5060099\ttotal: 7.73s\tremaining: 48s\n",
      "638:\tlearn: 2.5050627\ttotal: 7.75s\tremaining: 48s\n",
      "639:\tlearn: 2.5045190\ttotal: 7.76s\tremaining: 48s\n",
      "640:\tlearn: 2.5033003\ttotal: 7.77s\tremaining: 48s\n",
      "641:\tlearn: 2.5020787\ttotal: 7.78s\tremaining: 47.9s\n",
      "642:\tlearn: 2.5011152\ttotal: 7.79s\tremaining: 47.9s\n",
      "643:\tlearn: 2.5005315\ttotal: 7.8s\tremaining: 47.9s\n",
      "644:\tlearn: 2.4995501\ttotal: 7.82s\tremaining: 47.9s\n",
      "645:\tlearn: 2.4984321\ttotal: 7.83s\tremaining: 47.9s\n",
      "646:\tlearn: 2.4976660\ttotal: 7.84s\tremaining: 47.9s\n",
      "647:\tlearn: 2.4966380\ttotal: 7.86s\tremaining: 47.9s\n",
      "648:\tlearn: 2.4958813\ttotal: 7.87s\tremaining: 47.9s\n",
      "649:\tlearn: 2.4958743\ttotal: 7.88s\tremaining: 47.9s\n",
      "650:\tlearn: 2.4946824\ttotal: 7.89s\tremaining: 47.8s\n",
      "651:\tlearn: 2.4938493\ttotal: 7.9s\tremaining: 47.8s\n",
      "652:\tlearn: 2.4928859\ttotal: 7.92s\tremaining: 47.8s\n",
      "653:\tlearn: 2.4928232\ttotal: 7.93s\tremaining: 47.8s\n",
      "654:\tlearn: 2.4921759\ttotal: 7.94s\tremaining: 47.8s\n",
      "655:\tlearn: 2.4909189\ttotal: 7.95s\tremaining: 47.8s\n",
      "656:\tlearn: 2.4909132\ttotal: 7.96s\tremaining: 47.7s\n",
      "657:\tlearn: 2.4902408\ttotal: 7.97s\tremaining: 47.7s\n",
      "658:\tlearn: 2.4893549\ttotal: 7.98s\tremaining: 47.7s\n",
      "659:\tlearn: 2.4885850\ttotal: 8s\tremaining: 47.7s\n",
      "660:\tlearn: 2.4875506\ttotal: 8.01s\tremaining: 47.7s\n",
      "661:\tlearn: 2.4875446\ttotal: 8.02s\tremaining: 47.7s\n",
      "662:\tlearn: 2.4867585\ttotal: 8.03s\tremaining: 47.7s\n",
      "663:\tlearn: 2.4858454\ttotal: 8.04s\tremaining: 47.7s\n",
      "664:\tlearn: 2.4853449\ttotal: 8.06s\tremaining: 47.6s\n",
      "665:\tlearn: 2.4843641\ttotal: 8.07s\tremaining: 47.6s\n",
      "666:\tlearn: 2.4834114\ttotal: 8.08s\tremaining: 47.6s\n",
      "667:\tlearn: 2.4828740\ttotal: 8.09s\tremaining: 47.6s\n",
      "668:\tlearn: 2.4818292\ttotal: 8.11s\tremaining: 47.6s\n",
      "669:\tlearn: 2.4810064\ttotal: 8.12s\tremaining: 47.6s\n",
      "670:\tlearn: 2.4794270\ttotal: 8.13s\tremaining: 47.6s\n",
      "671:\tlearn: 2.4781012\ttotal: 8.14s\tremaining: 47.6s\n",
      "672:\tlearn: 2.4772177\ttotal: 8.16s\tremaining: 47.6s\n",
      "673:\tlearn: 2.4765882\ttotal: 8.17s\tremaining: 47.6s\n",
      "674:\tlearn: 2.4760384\ttotal: 8.18s\tremaining: 47.5s\n",
      "675:\tlearn: 2.4750374\ttotal: 8.19s\tremaining: 47.5s\n",
      "676:\tlearn: 2.4743281\ttotal: 8.2s\tremaining: 47.5s\n",
      "677:\tlearn: 2.4734306\ttotal: 8.22s\tremaining: 47.5s\n",
      "678:\tlearn: 2.4721696\ttotal: 8.23s\tremaining: 47.5s\n",
      "679:\tlearn: 2.4709918\ttotal: 8.24s\tremaining: 47.5s\n",
      "680:\tlearn: 2.4700617\ttotal: 8.25s\tremaining: 47.5s\n",
      "681:\tlearn: 2.4694233\ttotal: 8.26s\tremaining: 47.4s\n",
      "682:\tlearn: 2.4683669\ttotal: 8.28s\tremaining: 47.4s\n",
      "683:\tlearn: 2.4679287\ttotal: 8.29s\tremaining: 47.4s\n",
      "684:\tlearn: 2.4673713\ttotal: 8.3s\tremaining: 47.4s\n",
      "685:\tlearn: 2.4673040\ttotal: 8.31s\tremaining: 47.4s\n",
      "686:\tlearn: 2.4654795\ttotal: 8.32s\tremaining: 47.4s\n",
      "687:\tlearn: 2.4640362\ttotal: 8.34s\tremaining: 47.4s\n",
      "688:\tlearn: 2.4631866\ttotal: 8.35s\tremaining: 47.4s\n",
      "689:\tlearn: 2.4628312\ttotal: 8.36s\tremaining: 47.4s\n",
      "690:\tlearn: 2.4617381\ttotal: 8.37s\tremaining: 47.3s\n",
      "691:\tlearn: 2.4610016\ttotal: 8.38s\tremaining: 47.3s\n",
      "692:\tlearn: 2.4600187\ttotal: 8.4s\tremaining: 47.3s\n",
      "693:\tlearn: 2.4593505\ttotal: 8.41s\tremaining: 47.3s\n",
      "694:\tlearn: 2.4585482\ttotal: 8.42s\tremaining: 47.3s\n",
      "695:\tlearn: 2.4579701\ttotal: 8.43s\tremaining: 47.3s\n",
      "696:\tlearn: 2.4574056\ttotal: 8.44s\tremaining: 47.3s\n",
      "697:\tlearn: 2.4568762\ttotal: 8.46s\tremaining: 47.2s\n",
      "698:\tlearn: 2.4557048\ttotal: 8.47s\tremaining: 47.2s\n",
      "699:\tlearn: 2.4549708\ttotal: 8.48s\tremaining: 47.2s\n",
      "700:\tlearn: 2.4546303\ttotal: 8.49s\tremaining: 47.2s\n",
      "701:\tlearn: 2.4538095\ttotal: 8.51s\tremaining: 47.2s\n",
      "702:\tlearn: 2.4526454\ttotal: 8.52s\tremaining: 47.2s\n",
      "703:\tlearn: 2.4521701\ttotal: 8.53s\tremaining: 47.2s\n",
      "704:\tlearn: 2.4514082\ttotal: 8.54s\tremaining: 47.2s\n",
      "705:\tlearn: 2.4505399\ttotal: 8.55s\tremaining: 47.2s\n",
      "706:\tlearn: 2.4496330\ttotal: 8.57s\tremaining: 47.1s\n",
      "707:\tlearn: 2.4492238\ttotal: 8.58s\tremaining: 47.1s\n",
      "708:\tlearn: 2.4485888\ttotal: 8.59s\tremaining: 47.1s\n",
      "709:\tlearn: 2.4482594\ttotal: 8.6s\tremaining: 47.1s\n",
      "710:\tlearn: 2.4475285\ttotal: 8.61s\tremaining: 47.1s\n",
      "711:\tlearn: 2.4469468\ttotal: 8.62s\tremaining: 47.1s\n",
      "712:\tlearn: 2.4458602\ttotal: 8.64s\tremaining: 47.1s\n",
      "713:\tlearn: 2.4450476\ttotal: 8.65s\tremaining: 47s\n",
      "714:\tlearn: 2.4442852\ttotal: 8.66s\tremaining: 47s\n",
      "715:\tlearn: 2.4436983\ttotal: 8.67s\tremaining: 47s\n",
      "716:\tlearn: 2.4430161\ttotal: 8.68s\tremaining: 47s\n",
      "717:\tlearn: 2.4421211\ttotal: 8.69s\tremaining: 47s\n",
      "718:\tlearn: 2.4414934\ttotal: 8.71s\tremaining: 47s\n",
      "719:\tlearn: 2.4406752\ttotal: 8.72s\tremaining: 47s\n",
      "720:\tlearn: 2.4400569\ttotal: 8.73s\tremaining: 46.9s\n",
      "721:\tlearn: 2.4388183\ttotal: 8.74s\tremaining: 46.9s\n",
      "722:\tlearn: 2.4382947\ttotal: 8.76s\tremaining: 46.9s\n",
      "723:\tlearn: 2.4378695\ttotal: 8.77s\tremaining: 46.9s\n",
      "724:\tlearn: 2.4373630\ttotal: 8.78s\tremaining: 46.9s\n",
      "725:\tlearn: 2.4370464\ttotal: 8.79s\tremaining: 46.9s\n",
      "726:\tlearn: 2.4361063\ttotal: 8.8s\tremaining: 46.9s\n",
      "727:\tlearn: 2.4353556\ttotal: 8.81s\tremaining: 46.9s\n",
      "728:\tlearn: 2.4345909\ttotal: 8.83s\tremaining: 46.9s\n",
      "729:\tlearn: 2.4340766\ttotal: 8.84s\tremaining: 46.8s\n",
      "730:\tlearn: 2.4334302\ttotal: 8.85s\tremaining: 46.8s\n",
      "731:\tlearn: 2.4325081\ttotal: 8.86s\tremaining: 46.8s\n",
      "732:\tlearn: 2.4318630\ttotal: 8.88s\tremaining: 46.8s\n",
      "733:\tlearn: 2.4304552\ttotal: 8.89s\tremaining: 46.8s\n",
      "734:\tlearn: 2.4296514\ttotal: 8.9s\tremaining: 46.8s\n",
      "735:\tlearn: 2.4291812\ttotal: 8.91s\tremaining: 46.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736:\tlearn: 2.4281037\ttotal: 8.93s\tremaining: 46.8s\n",
      "737:\tlearn: 2.4275802\ttotal: 8.94s\tremaining: 46.8s\n",
      "738:\tlearn: 2.4273068\ttotal: 8.95s\tremaining: 46.8s\n",
      "739:\tlearn: 2.4267319\ttotal: 8.96s\tremaining: 46.7s\n",
      "740:\tlearn: 2.4260180\ttotal: 8.98s\tremaining: 46.7s\n",
      "741:\tlearn: 2.4252591\ttotal: 8.99s\tremaining: 46.7s\n",
      "742:\tlearn: 2.4248405\ttotal: 9s\tremaining: 46.7s\n",
      "743:\tlearn: 2.4239244\ttotal: 9.01s\tremaining: 46.7s\n",
      "744:\tlearn: 2.4234448\ttotal: 9.02s\tremaining: 46.7s\n",
      "745:\tlearn: 2.4225906\ttotal: 9.04s\tremaining: 46.7s\n",
      "746:\tlearn: 2.4220503\ttotal: 9.05s\tremaining: 46.6s\n",
      "747:\tlearn: 2.4216275\ttotal: 9.06s\tremaining: 46.6s\n",
      "748:\tlearn: 2.4209351\ttotal: 9.07s\tremaining: 46.6s\n",
      "749:\tlearn: 2.4196987\ttotal: 9.08s\tremaining: 46.6s\n",
      "750:\tlearn: 2.4190359\ttotal: 9.1s\tremaining: 46.6s\n",
      "751:\tlearn: 2.4185531\ttotal: 9.11s\tremaining: 46.6s\n",
      "752:\tlearn: 2.4178508\ttotal: 9.12s\tremaining: 46.6s\n",
      "753:\tlearn: 2.4178471\ttotal: 9.13s\tremaining: 46.5s\n",
      "754:\tlearn: 2.4170320\ttotal: 9.14s\tremaining: 46.5s\n",
      "755:\tlearn: 2.4164837\ttotal: 9.16s\tremaining: 46.5s\n",
      "756:\tlearn: 2.4152895\ttotal: 9.17s\tremaining: 46.5s\n",
      "757:\tlearn: 2.4141886\ttotal: 9.18s\tremaining: 46.5s\n",
      "758:\tlearn: 2.4137686\ttotal: 9.19s\tremaining: 46.5s\n",
      "759:\tlearn: 2.4122784\ttotal: 9.2s\tremaining: 46.5s\n",
      "760:\tlearn: 2.4109391\ttotal: 9.22s\tremaining: 46.5s\n",
      "761:\tlearn: 2.4098914\ttotal: 9.23s\tremaining: 46.5s\n",
      "762:\tlearn: 2.4091856\ttotal: 9.24s\tremaining: 46.5s\n",
      "763:\tlearn: 2.4084414\ttotal: 9.25s\tremaining: 46.4s\n",
      "764:\tlearn: 2.4078351\ttotal: 9.27s\tremaining: 46.4s\n",
      "765:\tlearn: 2.4069032\ttotal: 9.28s\tremaining: 46.4s\n",
      "766:\tlearn: 2.4058744\ttotal: 9.29s\tremaining: 46.4s\n",
      "767:\tlearn: 2.4050994\ttotal: 9.3s\tremaining: 46.4s\n",
      "768:\tlearn: 2.4044047\ttotal: 9.31s\tremaining: 46.4s\n",
      "769:\tlearn: 2.4040569\ttotal: 9.32s\tremaining: 46.4s\n",
      "770:\tlearn: 2.4035554\ttotal: 9.34s\tremaining: 46.3s\n",
      "771:\tlearn: 2.4028999\ttotal: 9.35s\tremaining: 46.3s\n",
      "772:\tlearn: 2.4019899\ttotal: 9.37s\tremaining: 46.3s\n",
      "773:\tlearn: 2.4012572\ttotal: 9.38s\tremaining: 46.3s\n",
      "774:\tlearn: 2.4005661\ttotal: 9.39s\tremaining: 46.3s\n",
      "775:\tlearn: 2.3998200\ttotal: 9.4s\tremaining: 46.3s\n",
      "776:\tlearn: 2.3986479\ttotal: 9.41s\tremaining: 46.3s\n",
      "777:\tlearn: 2.3980165\ttotal: 9.43s\tremaining: 46.3s\n",
      "778:\tlearn: 2.3975223\ttotal: 9.44s\tremaining: 46.3s\n",
      "779:\tlearn: 2.3965790\ttotal: 9.45s\tremaining: 46.3s\n",
      "780:\tlearn: 2.3950351\ttotal: 9.46s\tremaining: 46.2s\n",
      "781:\tlearn: 2.3937624\ttotal: 9.47s\tremaining: 46.2s\n",
      "782:\tlearn: 2.3932192\ttotal: 9.48s\tremaining: 46.2s\n",
      "783:\tlearn: 2.3928499\ttotal: 9.5s\tremaining: 46.2s\n",
      "784:\tlearn: 2.3919589\ttotal: 9.51s\tremaining: 46.2s\n",
      "785:\tlearn: 2.3913235\ttotal: 9.52s\tremaining: 46.2s\n",
      "786:\tlearn: 2.3903708\ttotal: 9.53s\tremaining: 46.2s\n",
      "787:\tlearn: 2.3895270\ttotal: 9.54s\tremaining: 46.1s\n",
      "788:\tlearn: 2.3885025\ttotal: 9.56s\tremaining: 46.1s\n",
      "789:\tlearn: 2.3880014\ttotal: 9.57s\tremaining: 46.1s\n",
      "790:\tlearn: 2.3873095\ttotal: 9.58s\tremaining: 46.1s\n",
      "791:\tlearn: 2.3869413\ttotal: 9.6s\tremaining: 46.1s\n",
      "792:\tlearn: 2.3862829\ttotal: 9.61s\tremaining: 46.1s\n",
      "793:\tlearn: 2.3862349\ttotal: 9.62s\tremaining: 46.1s\n",
      "794:\tlearn: 2.3855555\ttotal: 9.63s\tremaining: 46.1s\n",
      "795:\tlearn: 2.3846763\ttotal: 9.64s\tremaining: 46s\n",
      "796:\tlearn: 2.3841247\ttotal: 9.65s\tremaining: 46s\n",
      "797:\tlearn: 2.3837497\ttotal: 9.67s\tremaining: 46s\n",
      "798:\tlearn: 2.3827322\ttotal: 9.68s\tremaining: 46s\n",
      "799:\tlearn: 2.3815239\ttotal: 9.69s\tremaining: 46s\n",
      "800:\tlearn: 2.3806241\ttotal: 9.7s\tremaining: 46s\n",
      "801:\tlearn: 2.3802103\ttotal: 9.71s\tremaining: 46s\n",
      "802:\tlearn: 2.3794730\ttotal: 9.72s\tremaining: 46s\n",
      "803:\tlearn: 2.3780644\ttotal: 9.74s\tremaining: 46s\n",
      "804:\tlearn: 2.3769663\ttotal: 9.75s\tremaining: 45.9s\n",
      "805:\tlearn: 2.3763271\ttotal: 9.76s\tremaining: 45.9s\n",
      "806:\tlearn: 2.3758236\ttotal: 9.78s\tremaining: 45.9s\n",
      "807:\tlearn: 2.3748322\ttotal: 9.79s\tremaining: 45.9s\n",
      "808:\tlearn: 2.3745579\ttotal: 9.8s\tremaining: 45.9s\n",
      "809:\tlearn: 2.3739699\ttotal: 9.81s\tremaining: 45.9s\n",
      "810:\tlearn: 2.3726881\ttotal: 9.82s\tremaining: 45.9s\n",
      "811:\tlearn: 2.3723004\ttotal: 9.84s\tremaining: 45.9s\n",
      "812:\tlearn: 2.3715485\ttotal: 9.85s\tremaining: 45.8s\n",
      "813:\tlearn: 2.3709110\ttotal: 9.86s\tremaining: 45.8s\n",
      "814:\tlearn: 2.3700340\ttotal: 9.87s\tremaining: 45.8s\n",
      "815:\tlearn: 2.3694987\ttotal: 9.88s\tremaining: 45.8s\n",
      "816:\tlearn: 2.3687344\ttotal: 9.89s\tremaining: 45.8s\n",
      "817:\tlearn: 2.3679916\ttotal: 9.91s\tremaining: 45.8s\n",
      "818:\tlearn: 2.3669768\ttotal: 9.92s\tremaining: 45.8s\n",
      "819:\tlearn: 2.3660826\ttotal: 9.93s\tremaining: 45.8s\n",
      "820:\tlearn: 2.3652459\ttotal: 9.94s\tremaining: 45.7s\n",
      "821:\tlearn: 2.3643420\ttotal: 9.95s\tremaining: 45.7s\n",
      "822:\tlearn: 2.3639585\ttotal: 9.97s\tremaining: 45.7s\n",
      "823:\tlearn: 2.3631857\ttotal: 9.98s\tremaining: 45.7s\n",
      "824:\tlearn: 2.3616986\ttotal: 10s\tremaining: 45.7s\n",
      "825:\tlearn: 2.3607702\ttotal: 10s\tremaining: 45.7s\n",
      "826:\tlearn: 2.3599535\ttotal: 10s\tremaining: 45.7s\n",
      "827:\tlearn: 2.3592667\ttotal: 10s\tremaining: 45.7s\n",
      "828:\tlearn: 2.3579494\ttotal: 10s\tremaining: 45.7s\n",
      "829:\tlearn: 2.3572737\ttotal: 10.1s\tremaining: 45.6s\n",
      "830:\tlearn: 2.3562379\ttotal: 10.1s\tremaining: 45.6s\n",
      "831:\tlearn: 2.3557404\ttotal: 10.1s\tremaining: 45.6s\n",
      "832:\tlearn: 2.3546424\ttotal: 10.1s\tremaining: 45.6s\n",
      "833:\tlearn: 2.3533923\ttotal: 10.1s\tremaining: 45.6s\n",
      "834:\tlearn: 2.3526515\ttotal: 10.1s\tremaining: 45.6s\n",
      "835:\tlearn: 2.3522400\ttotal: 10.1s\tremaining: 45.6s\n",
      "836:\tlearn: 2.3520092\ttotal: 10.1s\tremaining: 45.6s\n",
      "837:\tlearn: 2.3511786\ttotal: 10.1s\tremaining: 45.5s\n",
      "838:\tlearn: 2.3508102\ttotal: 10.2s\tremaining: 45.5s\n",
      "839:\tlearn: 2.3505209\ttotal: 10.2s\tremaining: 45.5s\n",
      "840:\tlearn: 2.3504568\ttotal: 10.2s\tremaining: 45.5s\n",
      "841:\tlearn: 2.3496557\ttotal: 10.2s\tremaining: 45.5s\n",
      "842:\tlearn: 2.3491230\ttotal: 10.2s\tremaining: 45.5s\n",
      "843:\tlearn: 2.3485005\ttotal: 10.2s\tremaining: 45.5s\n",
      "844:\tlearn: 2.3480255\ttotal: 10.2s\tremaining: 45.5s\n",
      "845:\tlearn: 2.3477231\ttotal: 10.2s\tremaining: 45.4s\n",
      "846:\tlearn: 2.3472399\ttotal: 10.3s\tremaining: 45.4s\n",
      "847:\tlearn: 2.3465224\ttotal: 10.3s\tremaining: 45.4s\n",
      "848:\tlearn: 2.3460142\ttotal: 10.3s\tremaining: 45.4s\n",
      "849:\tlearn: 2.3451784\ttotal: 10.3s\tremaining: 45.4s\n",
      "850:\tlearn: 2.3444617\ttotal: 10.3s\tremaining: 45.4s\n",
      "851:\tlearn: 2.3432522\ttotal: 10.3s\tremaining: 45.4s\n",
      "852:\tlearn: 2.3427201\ttotal: 10.3s\tremaining: 45.3s\n",
      "853:\tlearn: 2.3419551\ttotal: 10.3s\tremaining: 45.3s\n",
      "854:\tlearn: 2.3410731\ttotal: 10.4s\tremaining: 45.3s\n",
      "855:\tlearn: 2.3405538\ttotal: 10.4s\tremaining: 45.3s\n",
      "856:\tlearn: 2.3399142\ttotal: 10.4s\tremaining: 45.3s\n",
      "857:\tlearn: 2.3389286\ttotal: 10.4s\tremaining: 45.3s\n",
      "858:\tlearn: 2.3379739\ttotal: 10.4s\tremaining: 45.3s\n",
      "859:\tlearn: 2.3375456\ttotal: 10.4s\tremaining: 45.3s\n",
      "860:\tlearn: 2.3365990\ttotal: 10.4s\tremaining: 45.3s\n",
      "861:\tlearn: 2.3359575\ttotal: 10.4s\tremaining: 45.3s\n",
      "862:\tlearn: 2.3350603\ttotal: 10.5s\tremaining: 45.2s\n",
      "863:\tlearn: 2.3340571\ttotal: 10.5s\tremaining: 45.2s\n",
      "864:\tlearn: 2.3335287\ttotal: 10.5s\tremaining: 45.2s\n",
      "865:\tlearn: 2.3332372\ttotal: 10.5s\tremaining: 45.2s\n",
      "866:\tlearn: 2.3328594\ttotal: 10.5s\tremaining: 45.2s\n",
      "867:\tlearn: 2.3318550\ttotal: 10.5s\tremaining: 45.2s\n",
      "868:\tlearn: 2.3314996\ttotal: 10.5s\tremaining: 45.2s\n",
      "869:\tlearn: 2.3310187\ttotal: 10.5s\tremaining: 45.2s\n",
      "870:\tlearn: 2.3301322\ttotal: 10.6s\tremaining: 45.1s\n",
      "871:\tlearn: 2.3293547\ttotal: 10.6s\tremaining: 45.1s\n",
      "872:\tlearn: 2.3290809\ttotal: 10.6s\tremaining: 45.1s\n",
      "873:\tlearn: 2.3286964\ttotal: 10.6s\tremaining: 45.1s\n",
      "874:\tlearn: 2.3280951\ttotal: 10.6s\tremaining: 45.1s\n",
      "875:\tlearn: 2.3272719\ttotal: 10.6s\tremaining: 45.1s\n",
      "876:\tlearn: 2.3265646\ttotal: 10.6s\tremaining: 45.1s\n",
      "877:\tlearn: 2.3259120\ttotal: 10.6s\tremaining: 45.1s\n",
      "878:\tlearn: 2.3252468\ttotal: 10.6s\tremaining: 45.1s\n",
      "879:\tlearn: 2.3248212\ttotal: 10.7s\tremaining: 45s\n",
      "880:\tlearn: 2.3239337\ttotal: 10.7s\tremaining: 45s\n",
      "881:\tlearn: 2.3229743\ttotal: 10.7s\tremaining: 45s\n",
      "882:\tlearn: 2.3220452\ttotal: 10.7s\tremaining: 45s\n",
      "883:\tlearn: 2.3210313\ttotal: 10.7s\tremaining: 45s\n",
      "884:\tlearn: 2.3198266\ttotal: 10.7s\tremaining: 45s\n",
      "885:\tlearn: 2.3187236\ttotal: 10.7s\tremaining: 45s\n",
      "886:\tlearn: 2.3179007\ttotal: 10.7s\tremaining: 45s\n",
      "887:\tlearn: 2.3173276\ttotal: 10.8s\tremaining: 45s\n",
      "888:\tlearn: 2.3167116\ttotal: 10.8s\tremaining: 44.9s\n",
      "889:\tlearn: 2.3154477\ttotal: 10.8s\tremaining: 44.9s\n",
      "890:\tlearn: 2.3151015\ttotal: 10.8s\tremaining: 44.9s\n",
      "891:\tlearn: 2.3142572\ttotal: 10.8s\tremaining: 44.9s\n",
      "892:\tlearn: 2.3133461\ttotal: 10.8s\tremaining: 44.9s\n",
      "893:\tlearn: 2.3124971\ttotal: 10.8s\tremaining: 44.9s\n",
      "894:\tlearn: 2.3116093\ttotal: 10.8s\tremaining: 44.9s\n",
      "895:\tlearn: 2.3116067\ttotal: 10.9s\tremaining: 44.9s\n",
      "896:\tlearn: 2.3109971\ttotal: 10.9s\tremaining: 44.9s\n",
      "897:\tlearn: 2.3105825\ttotal: 10.9s\tremaining: 44.8s\n",
      "898:\tlearn: 2.3098618\ttotal: 10.9s\tremaining: 44.8s\n",
      "899:\tlearn: 2.3088331\ttotal: 10.9s\tremaining: 44.8s\n",
      "900:\tlearn: 2.3082667\ttotal: 10.9s\tremaining: 44.8s\n",
      "901:\tlearn: 2.3075252\ttotal: 10.9s\tremaining: 44.8s\n",
      "902:\tlearn: 2.3069934\ttotal: 10.9s\tremaining: 44.8s\n",
      "903:\tlearn: 2.3063684\ttotal: 11s\tremaining: 44.8s\n",
      "904:\tlearn: 2.3057122\ttotal: 11s\tremaining: 44.8s\n",
      "905:\tlearn: 2.3047211\ttotal: 11s\tremaining: 44.7s\n",
      "906:\tlearn: 2.3037482\ttotal: 11s\tremaining: 44.7s\n",
      "907:\tlearn: 2.3022918\ttotal: 11s\tremaining: 44.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "908:\tlearn: 2.3014817\ttotal: 11s\tremaining: 44.7s\n",
      "909:\tlearn: 2.3010441\ttotal: 11s\tremaining: 44.7s\n",
      "910:\tlearn: 2.3002113\ttotal: 11s\tremaining: 44.7s\n",
      "911:\tlearn: 2.2994245\ttotal: 11.1s\tremaining: 44.7s\n",
      "912:\tlearn: 2.2993578\ttotal: 11.1s\tremaining: 44.7s\n",
      "913:\tlearn: 2.2986355\ttotal: 11.1s\tremaining: 44.7s\n",
      "914:\tlearn: 2.2982991\ttotal: 11.1s\tremaining: 44.6s\n",
      "915:\tlearn: 2.2978100\ttotal: 11.1s\tremaining: 44.6s\n",
      "916:\tlearn: 2.2977763\ttotal: 11.1s\tremaining: 44.6s\n",
      "917:\tlearn: 2.2972364\ttotal: 11.1s\tremaining: 44.6s\n",
      "918:\tlearn: 2.2967069\ttotal: 11.1s\tremaining: 44.6s\n",
      "919:\tlearn: 2.2965531\ttotal: 11.1s\tremaining: 44.6s\n",
      "920:\tlearn: 2.2955908\ttotal: 11.2s\tremaining: 44.5s\n",
      "921:\tlearn: 2.2952322\ttotal: 11.2s\tremaining: 44.5s\n",
      "922:\tlearn: 2.2946866\ttotal: 11.2s\tremaining: 44.5s\n",
      "923:\tlearn: 2.2940130\ttotal: 11.2s\tremaining: 44.5s\n",
      "924:\tlearn: 2.2937785\ttotal: 11.2s\tremaining: 44.5s\n",
      "925:\tlearn: 2.2935601\ttotal: 11.2s\tremaining: 44.5s\n",
      "926:\tlearn: 2.2929135\ttotal: 11.2s\tremaining: 44.5s\n",
      "927:\tlearn: 2.2920809\ttotal: 11.2s\tremaining: 44.5s\n",
      "928:\tlearn: 2.2911402\ttotal: 11.3s\tremaining: 44.5s\n",
      "929:\tlearn: 2.2901319\ttotal: 11.3s\tremaining: 44.4s\n",
      "930:\tlearn: 2.2894210\ttotal: 11.3s\tremaining: 44.4s\n",
      "931:\tlearn: 2.2886234\ttotal: 11.3s\tremaining: 44.4s\n",
      "932:\tlearn: 2.2881473\ttotal: 11.3s\tremaining: 44.4s\n",
      "933:\tlearn: 2.2877281\ttotal: 11.3s\tremaining: 44.4s\n",
      "934:\tlearn: 2.2872248\ttotal: 11.3s\tremaining: 44.4s\n",
      "935:\tlearn: 2.2866506\ttotal: 11.3s\tremaining: 44.4s\n",
      "936:\tlearn: 2.2862317\ttotal: 11.4s\tremaining: 44.4s\n",
      "937:\tlearn: 2.2852201\ttotal: 11.4s\tremaining: 44.3s\n",
      "938:\tlearn: 2.2840200\ttotal: 11.4s\tremaining: 44.3s\n",
      "939:\tlearn: 2.2835151\ttotal: 11.4s\tremaining: 44.3s\n",
      "940:\tlearn: 2.2830416\ttotal: 11.4s\tremaining: 44.3s\n",
      "941:\tlearn: 2.2824394\ttotal: 11.4s\tremaining: 44.3s\n",
      "942:\tlearn: 2.2815486\ttotal: 11.4s\tremaining: 44.3s\n",
      "943:\tlearn: 2.2805421\ttotal: 11.4s\tremaining: 44.3s\n",
      "944:\tlearn: 2.2799813\ttotal: 11.4s\tremaining: 44.3s\n",
      "945:\tlearn: 2.2794509\ttotal: 11.5s\tremaining: 44.3s\n",
      "946:\tlearn: 2.2786183\ttotal: 11.5s\tremaining: 44.2s\n",
      "947:\tlearn: 2.2782114\ttotal: 11.5s\tremaining: 44.2s\n",
      "948:\tlearn: 2.2775631\ttotal: 11.5s\tremaining: 44.2s\n",
      "949:\tlearn: 2.2769863\ttotal: 11.5s\tremaining: 44.2s\n",
      "950:\tlearn: 2.2764328\ttotal: 11.5s\tremaining: 44.2s\n",
      "951:\tlearn: 2.2761441\ttotal: 11.5s\tremaining: 44.2s\n",
      "952:\tlearn: 2.2754889\ttotal: 11.5s\tremaining: 44.2s\n",
      "953:\tlearn: 2.2746320\ttotal: 11.6s\tremaining: 44.1s\n",
      "954:\tlearn: 2.2740131\ttotal: 11.6s\tremaining: 44.1s\n",
      "955:\tlearn: 2.2733249\ttotal: 11.6s\tremaining: 44.1s\n",
      "956:\tlearn: 2.2725550\ttotal: 11.6s\tremaining: 44.1s\n",
      "957:\tlearn: 2.2719309\ttotal: 11.6s\tremaining: 44.1s\n",
      "958:\tlearn: 2.2712057\ttotal: 11.6s\tremaining: 44.1s\n",
      "959:\tlearn: 2.2703097\ttotal: 11.6s\tremaining: 44.1s\n",
      "960:\tlearn: 2.2699084\ttotal: 11.6s\tremaining: 44s\n",
      "961:\tlearn: 2.2692353\ttotal: 11.7s\tremaining: 44s\n",
      "962:\tlearn: 2.2685753\ttotal: 11.7s\tremaining: 44s\n",
      "963:\tlearn: 2.2680833\ttotal: 11.7s\tremaining: 44s\n",
      "964:\tlearn: 2.2676661\ttotal: 11.7s\tremaining: 44s\n",
      "965:\tlearn: 2.2673998\ttotal: 11.7s\tremaining: 44s\n",
      "966:\tlearn: 2.2663894\ttotal: 11.7s\tremaining: 44s\n",
      "967:\tlearn: 2.2657342\ttotal: 11.7s\tremaining: 44s\n",
      "968:\tlearn: 2.2648000\ttotal: 11.7s\tremaining: 44s\n",
      "969:\tlearn: 2.2641882\ttotal: 11.8s\tremaining: 43.9s\n",
      "970:\tlearn: 2.2635466\ttotal: 11.8s\tremaining: 43.9s\n",
      "971:\tlearn: 2.2628208\ttotal: 11.8s\tremaining: 43.9s\n",
      "972:\tlearn: 2.2617052\ttotal: 11.8s\tremaining: 43.9s\n",
      "973:\tlearn: 2.2606719\ttotal: 11.8s\tremaining: 43.9s\n",
      "974:\tlearn: 2.2603539\ttotal: 11.8s\tremaining: 43.9s\n",
      "975:\tlearn: 2.2599407\ttotal: 11.8s\tremaining: 43.9s\n",
      "976:\tlearn: 2.2595993\ttotal: 11.8s\tremaining: 43.9s\n",
      "977:\tlearn: 2.2588310\ttotal: 11.8s\tremaining: 43.8s\n",
      "978:\tlearn: 2.2579876\ttotal: 11.9s\tremaining: 43.8s\n",
      "979:\tlearn: 2.2572204\ttotal: 11.9s\tremaining: 43.8s\n",
      "980:\tlearn: 2.2562428\ttotal: 11.9s\tremaining: 43.8s\n",
      "981:\tlearn: 2.2551353\ttotal: 11.9s\tremaining: 43.8s\n",
      "982:\tlearn: 2.2543787\ttotal: 11.9s\tremaining: 43.8s\n",
      "983:\tlearn: 2.2536134\ttotal: 11.9s\tremaining: 43.8s\n",
      "984:\tlearn: 2.2536109\ttotal: 11.9s\tremaining: 43.8s\n",
      "985:\tlearn: 2.2532172\ttotal: 11.9s\tremaining: 43.8s\n",
      "986:\tlearn: 2.2527365\ttotal: 12s\tremaining: 43.7s\n",
      "987:\tlearn: 2.2522608\ttotal: 12s\tremaining: 43.7s\n",
      "988:\tlearn: 2.2516110\ttotal: 12s\tremaining: 43.7s\n",
      "989:\tlearn: 2.2505567\ttotal: 12s\tremaining: 43.7s\n",
      "990:\tlearn: 2.2501575\ttotal: 12s\tremaining: 43.7s\n",
      "991:\tlearn: 2.2492978\ttotal: 12s\tremaining: 43.7s\n",
      "992:\tlearn: 2.2487308\ttotal: 12s\tremaining: 43.7s\n",
      "993:\tlearn: 2.2479767\ttotal: 12s\tremaining: 43.6s\n",
      "994:\tlearn: 2.2476223\ttotal: 12.1s\tremaining: 43.6s\n",
      "995:\tlearn: 2.2464275\ttotal: 12.1s\tremaining: 43.6s\n",
      "996:\tlearn: 2.2454630\ttotal: 12.1s\tremaining: 43.6s\n",
      "997:\tlearn: 2.2451726\ttotal: 12.1s\tremaining: 43.6s\n",
      "998:\tlearn: 2.2446493\ttotal: 12.1s\tremaining: 43.6s\n",
      "999:\tlearn: 2.2441196\ttotal: 12.1s\tremaining: 43.6s\n",
      "1000:\tlearn: 2.2441170\ttotal: 12.1s\tremaining: 43.6s\n",
      "1001:\tlearn: 2.2434303\ttotal: 12.1s\tremaining: 43.6s\n",
      "1002:\tlearn: 2.2427090\ttotal: 12.1s\tremaining: 43.5s\n",
      "1003:\tlearn: 2.2418220\ttotal: 12.2s\tremaining: 43.5s\n",
      "1004:\tlearn: 2.2412311\ttotal: 12.2s\tremaining: 43.5s\n",
      "1005:\tlearn: 2.2406450\ttotal: 12.2s\tremaining: 43.5s\n",
      "1006:\tlearn: 2.2403452\ttotal: 12.2s\tremaining: 43.5s\n",
      "1007:\tlearn: 2.2396110\ttotal: 12.2s\tremaining: 43.5s\n",
      "1008:\tlearn: 2.2388837\ttotal: 12.2s\tremaining: 43.5s\n",
      "1009:\tlearn: 2.2378523\ttotal: 12.2s\tremaining: 43.5s\n",
      "1010:\tlearn: 2.2370532\ttotal: 12.3s\tremaining: 43.5s\n",
      "1011:\tlearn: 2.2365728\ttotal: 12.3s\tremaining: 43.5s\n",
      "1012:\tlearn: 2.2356595\ttotal: 12.3s\tremaining: 43.5s\n",
      "1013:\tlearn: 2.2350695\ttotal: 12.3s\tremaining: 43.4s\n",
      "1014:\tlearn: 2.2348140\ttotal: 12.3s\tremaining: 43.4s\n",
      "1015:\tlearn: 2.2343628\ttotal: 12.3s\tremaining: 43.4s\n",
      "1016:\tlearn: 2.2339277\ttotal: 12.3s\tremaining: 43.4s\n",
      "1017:\tlearn: 2.2333773\ttotal: 12.3s\tremaining: 43.4s\n",
      "1018:\tlearn: 2.2327435\ttotal: 12.4s\tremaining: 43.4s\n",
      "1019:\tlearn: 2.2322138\ttotal: 12.4s\tremaining: 43.4s\n",
      "1020:\tlearn: 2.2312165\ttotal: 12.4s\tremaining: 43.4s\n",
      "1021:\tlearn: 2.2309674\ttotal: 12.4s\tremaining: 43.4s\n",
      "1022:\tlearn: 2.2300465\ttotal: 12.4s\tremaining: 43.3s\n",
      "1023:\tlearn: 2.2296822\ttotal: 12.4s\tremaining: 43.3s\n",
      "1024:\tlearn: 2.2289698\ttotal: 12.4s\tremaining: 43.3s\n",
      "1025:\tlearn: 2.2282463\ttotal: 12.4s\tremaining: 43.3s\n",
      "1026:\tlearn: 2.2277373\ttotal: 12.5s\tremaining: 43.3s\n",
      "1027:\tlearn: 2.2274510\ttotal: 12.5s\tremaining: 43.3s\n",
      "1028:\tlearn: 2.2268113\ttotal: 12.5s\tremaining: 43.3s\n",
      "1029:\tlearn: 2.2261334\ttotal: 12.5s\tremaining: 43.3s\n",
      "1030:\tlearn: 2.2258551\ttotal: 12.5s\tremaining: 43.3s\n",
      "1031:\tlearn: 2.2251507\ttotal: 12.5s\tremaining: 43.2s\n",
      "1032:\tlearn: 2.2246430\ttotal: 12.5s\tremaining: 43.2s\n",
      "1033:\tlearn: 2.2240990\ttotal: 12.5s\tremaining: 43.2s\n",
      "1034:\tlearn: 2.2238065\ttotal: 12.6s\tremaining: 43.2s\n",
      "1035:\tlearn: 2.2231683\ttotal: 12.6s\tremaining: 43.2s\n",
      "1036:\tlearn: 2.2223727\ttotal: 12.6s\tremaining: 43.2s\n",
      "1037:\tlearn: 2.2218137\ttotal: 12.6s\tremaining: 43.2s\n",
      "1038:\tlearn: 2.2213048\ttotal: 12.6s\tremaining: 43.2s\n",
      "1039:\tlearn: 2.2205308\ttotal: 12.6s\tremaining: 43.1s\n",
      "1040:\tlearn: 2.2197650\ttotal: 12.6s\tremaining: 43.1s\n",
      "1041:\tlearn: 2.2194084\ttotal: 12.6s\tremaining: 43.1s\n",
      "1042:\tlearn: 2.2190209\ttotal: 12.6s\tremaining: 43.1s\n",
      "1043:\tlearn: 2.2182698\ttotal: 12.7s\tremaining: 43.1s\n",
      "1044:\tlearn: 2.2178850\ttotal: 12.7s\tremaining: 43.1s\n",
      "1045:\tlearn: 2.2174191\ttotal: 12.7s\tremaining: 43.1s\n",
      "1046:\tlearn: 2.2166351\ttotal: 12.7s\tremaining: 43.1s\n",
      "1047:\tlearn: 2.2156893\ttotal: 12.7s\tremaining: 43s\n",
      "1048:\tlearn: 2.2152169\ttotal: 12.7s\tremaining: 43s\n",
      "1049:\tlearn: 2.2144520\ttotal: 12.7s\tremaining: 43s\n",
      "1050:\tlearn: 2.2141695\ttotal: 12.7s\tremaining: 43s\n",
      "1051:\tlearn: 2.2129616\ttotal: 12.8s\tremaining: 43s\n",
      "1052:\tlearn: 2.2126061\ttotal: 12.8s\tremaining: 43s\n",
      "1053:\tlearn: 2.2120442\ttotal: 12.8s\tremaining: 43s\n",
      "1054:\tlearn: 2.2111663\ttotal: 12.8s\tremaining: 43s\n",
      "1055:\tlearn: 2.2107800\ttotal: 12.8s\tremaining: 42.9s\n",
      "1056:\tlearn: 2.2101231\ttotal: 12.8s\tremaining: 42.9s\n",
      "1057:\tlearn: 2.2094321\ttotal: 12.8s\tremaining: 42.9s\n",
      "1058:\tlearn: 2.2090527\ttotal: 12.8s\tremaining: 42.9s\n",
      "1059:\tlearn: 2.2084403\ttotal: 12.8s\tremaining: 42.9s\n",
      "1060:\tlearn: 2.2079439\ttotal: 12.9s\tremaining: 42.9s\n",
      "1061:\tlearn: 2.2079411\ttotal: 12.9s\tremaining: 42.9s\n",
      "1062:\tlearn: 2.2075719\ttotal: 12.9s\tremaining: 42.8s\n",
      "1063:\tlearn: 2.2071417\ttotal: 12.9s\tremaining: 42.8s\n",
      "1064:\tlearn: 2.2068868\ttotal: 12.9s\tremaining: 42.8s\n",
      "1065:\tlearn: 2.2068838\ttotal: 12.9s\tremaining: 42.8s\n",
      "1066:\tlearn: 2.2059747\ttotal: 12.9s\tremaining: 42.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1067:\tlearn: 2.2059719\ttotal: 12.9s\tremaining: 42.8s\n",
      "1068:\tlearn: 2.2054412\ttotal: 12.9s\tremaining: 42.8s\n",
      "1069:\tlearn: 2.2050187\ttotal: 13s\tremaining: 42.7s\n",
      "1070:\tlearn: 2.2042981\ttotal: 13s\tremaining: 42.7s\n",
      "1071:\tlearn: 2.2034956\ttotal: 13s\tremaining: 42.7s\n",
      "1072:\tlearn: 2.2028927\ttotal: 13s\tremaining: 42.7s\n",
      "1073:\tlearn: 2.2022392\ttotal: 13s\tremaining: 42.7s\n",
      "1074:\tlearn: 2.2013984\ttotal: 13s\tremaining: 42.7s\n",
      "1075:\tlearn: 2.2008119\ttotal: 13s\tremaining: 42.7s\n",
      "1076:\tlearn: 2.2003976\ttotal: 13s\tremaining: 42.7s\n",
      "1077:\tlearn: 2.1997051\ttotal: 13.1s\tremaining: 42.6s\n",
      "1078:\tlearn: 2.1991700\ttotal: 13.1s\tremaining: 42.6s\n",
      "1079:\tlearn: 2.1989103\ttotal: 13.1s\tremaining: 42.6s\n",
      "1080:\tlearn: 2.1983333\ttotal: 13.1s\tremaining: 42.6s\n",
      "1081:\tlearn: 2.1977314\ttotal: 13.1s\tremaining: 42.6s\n",
      "1082:\tlearn: 2.1972212\ttotal: 13.1s\tremaining: 42.6s\n",
      "1083:\tlearn: 2.1967322\ttotal: 13.1s\tremaining: 42.6s\n",
      "1084:\tlearn: 2.1955455\ttotal: 13.1s\tremaining: 42.6s\n",
      "1085:\tlearn: 2.1947779\ttotal: 13.2s\tremaining: 42.6s\n",
      "1086:\tlearn: 2.1940287\ttotal: 13.2s\tremaining: 42.5s\n",
      "1087:\tlearn: 2.1933882\ttotal: 13.2s\tremaining: 42.5s\n",
      "1088:\tlearn: 2.1930645\ttotal: 13.2s\tremaining: 42.5s\n",
      "1089:\tlearn: 2.1917338\ttotal: 13.2s\tremaining: 42.5s\n",
      "1090:\tlearn: 2.1913846\ttotal: 13.2s\tremaining: 42.5s\n",
      "1091:\tlearn: 2.1909975\ttotal: 13.2s\tremaining: 42.5s\n",
      "1092:\tlearn: 2.1909943\ttotal: 13.2s\tremaining: 42.5s\n",
      "1093:\tlearn: 2.1901749\ttotal: 13.3s\tremaining: 42.5s\n",
      "1094:\tlearn: 2.1897202\ttotal: 13.3s\tremaining: 42.4s\n",
      "1095:\tlearn: 2.1890982\ttotal: 13.3s\tremaining: 42.4s\n",
      "1096:\tlearn: 2.1888273\ttotal: 13.3s\tremaining: 42.4s\n",
      "1097:\tlearn: 2.1883955\ttotal: 13.3s\tremaining: 42.4s\n",
      "1098:\tlearn: 2.1878176\ttotal: 13.3s\tremaining: 42.4s\n",
      "1099:\tlearn: 2.1876163\ttotal: 13.3s\tremaining: 42.4s\n",
      "1100:\tlearn: 2.1871288\ttotal: 13.3s\tremaining: 42.4s\n",
      "1101:\tlearn: 2.1863575\ttotal: 13.4s\tremaining: 42.4s\n",
      "1102:\tlearn: 2.1859834\ttotal: 13.4s\tremaining: 42.3s\n",
      "1103:\tlearn: 2.1857925\ttotal: 13.4s\tremaining: 42.3s\n",
      "1104:\tlearn: 2.1855062\ttotal: 13.4s\tremaining: 42.3s\n",
      "1105:\tlearn: 2.1848723\ttotal: 13.4s\tremaining: 42.3s\n",
      "1106:\tlearn: 2.1847465\ttotal: 13.4s\tremaining: 42.3s\n",
      "1107:\tlearn: 2.1843127\ttotal: 13.4s\tremaining: 42.3s\n",
      "1108:\tlearn: 2.1836804\ttotal: 13.4s\tremaining: 42.3s\n",
      "1109:\tlearn: 2.1831543\ttotal: 13.4s\tremaining: 42.2s\n",
      "1110:\tlearn: 2.1825417\ttotal: 13.5s\tremaining: 42.2s\n",
      "1111:\tlearn: 2.1811537\ttotal: 13.5s\tremaining: 42.2s\n",
      "1112:\tlearn: 2.1810102\ttotal: 13.5s\tremaining: 42.2s\n",
      "1113:\tlearn: 2.1805349\ttotal: 13.5s\tremaining: 42.2s\n",
      "1114:\tlearn: 2.1799412\ttotal: 13.5s\tremaining: 42.2s\n",
      "1115:\tlearn: 2.1797228\ttotal: 13.5s\tremaining: 42.2s\n",
      "1116:\tlearn: 2.1789863\ttotal: 13.5s\tremaining: 42.2s\n",
      "1117:\tlearn: 2.1787355\ttotal: 13.5s\tremaining: 42.1s\n",
      "1118:\tlearn: 2.1781698\ttotal: 13.6s\tremaining: 42.1s\n",
      "1119:\tlearn: 2.1775103\ttotal: 13.6s\tremaining: 42.1s\n",
      "1120:\tlearn: 2.1772459\ttotal: 13.6s\tremaining: 42.1s\n",
      "1121:\tlearn: 2.1766254\ttotal: 13.6s\tremaining: 42.1s\n",
      "1122:\tlearn: 2.1757379\ttotal: 13.6s\tremaining: 42.1s\n",
      "1123:\tlearn: 2.1754246\ttotal: 13.6s\tremaining: 42.1s\n",
      "1124:\tlearn: 2.1751628\ttotal: 13.6s\tremaining: 42.1s\n",
      "1125:\tlearn: 2.1746086\ttotal: 13.6s\tremaining: 42s\n",
      "1126:\tlearn: 2.1743184\ttotal: 13.6s\tremaining: 42s\n",
      "1127:\tlearn: 2.1737680\ttotal: 13.7s\tremaining: 42s\n",
      "1128:\tlearn: 2.1730881\ttotal: 13.7s\tremaining: 42s\n",
      "1129:\tlearn: 2.1723641\ttotal: 13.7s\tremaining: 42s\n",
      "1130:\tlearn: 2.1715662\ttotal: 13.7s\tremaining: 42s\n",
      "1131:\tlearn: 2.1711171\ttotal: 13.7s\tremaining: 42s\n",
      "1132:\tlearn: 2.1705529\ttotal: 13.7s\tremaining: 42s\n",
      "1133:\tlearn: 2.1696475\ttotal: 13.7s\tremaining: 41.9s\n",
      "1134:\tlearn: 2.1691975\ttotal: 13.7s\tremaining: 41.9s\n",
      "1135:\tlearn: 2.1687978\ttotal: 13.8s\tremaining: 41.9s\n",
      "1136:\tlearn: 2.1675475\ttotal: 13.8s\tremaining: 41.9s\n",
      "1137:\tlearn: 2.1670045\ttotal: 13.8s\tremaining: 41.9s\n",
      "1138:\tlearn: 2.1662743\ttotal: 13.8s\tremaining: 41.9s\n",
      "1139:\tlearn: 2.1658810\ttotal: 13.8s\tremaining: 41.9s\n",
      "1140:\tlearn: 2.1652594\ttotal: 13.8s\tremaining: 41.9s\n",
      "1141:\tlearn: 2.1645025\ttotal: 13.8s\tremaining: 41.9s\n",
      "1142:\tlearn: 2.1634977\ttotal: 13.8s\tremaining: 41.8s\n",
      "1143:\tlearn: 2.1630504\ttotal: 13.9s\tremaining: 41.8s\n",
      "1144:\tlearn: 2.1625287\ttotal: 13.9s\tremaining: 41.8s\n",
      "1145:\tlearn: 2.1617476\ttotal: 13.9s\tremaining: 41.8s\n",
      "1146:\tlearn: 2.1613627\ttotal: 13.9s\tremaining: 41.8s\n",
      "1147:\tlearn: 2.1607214\ttotal: 13.9s\tremaining: 41.8s\n",
      "1148:\tlearn: 2.1600260\ttotal: 13.9s\tremaining: 41.8s\n",
      "1149:\tlearn: 2.1593588\ttotal: 13.9s\tremaining: 41.8s\n",
      "1150:\tlearn: 2.1588391\ttotal: 13.9s\tremaining: 41.7s\n",
      "1151:\tlearn: 2.1585449\ttotal: 14s\tremaining: 41.7s\n",
      "1152:\tlearn: 2.1579242\ttotal: 14s\tremaining: 41.7s\n",
      "1153:\tlearn: 2.1574651\ttotal: 14s\tremaining: 41.7s\n",
      "1154:\tlearn: 2.1569733\ttotal: 14s\tremaining: 41.7s\n",
      "1155:\tlearn: 2.1566039\ttotal: 14s\tremaining: 41.7s\n",
      "1156:\tlearn: 2.1560974\ttotal: 14s\tremaining: 41.7s\n",
      "1157:\tlearn: 2.1556404\ttotal: 14s\tremaining: 41.7s\n",
      "1158:\tlearn: 2.1551183\ttotal: 14s\tremaining: 41.7s\n",
      "1159:\tlearn: 2.1547509\ttotal: 14.1s\tremaining: 41.6s\n",
      "1160:\tlearn: 2.1542796\ttotal: 14.1s\tremaining: 41.6s\n",
      "1161:\tlearn: 2.1536499\ttotal: 14.1s\tremaining: 41.6s\n",
      "1162:\tlearn: 2.1533319\ttotal: 14.1s\tremaining: 41.6s\n",
      "1163:\tlearn: 2.1530238\ttotal: 14.1s\tremaining: 41.6s\n",
      "1164:\tlearn: 2.1527358\ttotal: 14.1s\tremaining: 41.6s\n",
      "1165:\tlearn: 2.1523115\ttotal: 14.1s\tremaining: 41.6s\n",
      "1166:\tlearn: 2.1516337\ttotal: 14.1s\tremaining: 41.5s\n",
      "1167:\tlearn: 2.1512397\ttotal: 14.1s\tremaining: 41.5s\n",
      "1168:\tlearn: 2.1510309\ttotal: 14.2s\tremaining: 41.5s\n",
      "1169:\tlearn: 2.1504229\ttotal: 14.2s\tremaining: 41.5s\n",
      "1170:\tlearn: 2.1498957\ttotal: 14.2s\tremaining: 41.5s\n",
      "1171:\tlearn: 2.1494586\ttotal: 14.2s\tremaining: 41.5s\n",
      "1172:\tlearn: 2.1491696\ttotal: 14.2s\tremaining: 41.5s\n",
      "1173:\tlearn: 2.1487706\ttotal: 14.2s\tremaining: 41.5s\n",
      "1174:\tlearn: 2.1481625\ttotal: 14.2s\tremaining: 41.5s\n",
      "1175:\tlearn: 2.1475236\ttotal: 14.2s\tremaining: 41.4s\n",
      "1176:\tlearn: 2.1466626\ttotal: 14.3s\tremaining: 41.4s\n",
      "1177:\tlearn: 2.1463382\ttotal: 14.3s\tremaining: 41.4s\n",
      "1178:\tlearn: 2.1455453\ttotal: 14.3s\tremaining: 41.4s\n",
      "1179:\tlearn: 2.1451258\ttotal: 14.3s\tremaining: 41.4s\n",
      "1180:\tlearn: 2.1447779\ttotal: 14.3s\tremaining: 41.4s\n",
      "1181:\tlearn: 2.1444376\ttotal: 14.3s\tremaining: 41.4s\n",
      "1182:\tlearn: 2.1440674\ttotal: 14.3s\tremaining: 41.4s\n",
      "1183:\tlearn: 2.1435856\ttotal: 14.3s\tremaining: 41.3s\n",
      "1184:\tlearn: 2.1430414\ttotal: 14.3s\tremaining: 41.3s\n",
      "1185:\tlearn: 2.1424629\ttotal: 14.4s\tremaining: 41.3s\n",
      "1186:\tlearn: 2.1420434\ttotal: 14.4s\tremaining: 41.3s\n",
      "1187:\tlearn: 2.1411853\ttotal: 14.4s\tremaining: 41.3s\n",
      "1188:\tlearn: 2.1406756\ttotal: 14.4s\tremaining: 41.3s\n",
      "1189:\tlearn: 2.1401256\ttotal: 14.4s\tremaining: 41.3s\n",
      "1190:\tlearn: 2.1392753\ttotal: 14.4s\tremaining: 41.3s\n",
      "1191:\tlearn: 2.1389082\ttotal: 14.4s\tremaining: 41.2s\n",
      "1192:\tlearn: 2.1381525\ttotal: 14.4s\tremaining: 41.2s\n",
      "1193:\tlearn: 2.1373526\ttotal: 14.5s\tremaining: 41.2s\n",
      "1194:\tlearn: 2.1367717\ttotal: 14.5s\tremaining: 41.2s\n",
      "1195:\tlearn: 2.1365431\ttotal: 14.5s\tremaining: 41.2s\n",
      "1196:\tlearn: 2.1360885\ttotal: 14.5s\tremaining: 41.2s\n",
      "1197:\tlearn: 2.1357464\ttotal: 14.5s\tremaining: 41.2s\n",
      "1198:\tlearn: 2.1348858\ttotal: 14.5s\tremaining: 41.2s\n",
      "1199:\tlearn: 2.1341612\ttotal: 14.5s\tremaining: 41.1s\n",
      "1200:\tlearn: 2.1338901\ttotal: 14.5s\tremaining: 41.1s\n",
      "1201:\tlearn: 2.1331734\ttotal: 14.6s\tremaining: 41.1s\n",
      "1202:\tlearn: 2.1327734\ttotal: 14.6s\tremaining: 41.1s\n",
      "1203:\tlearn: 2.1320713\ttotal: 14.6s\tremaining: 41.1s\n",
      "1204:\tlearn: 2.1314090\ttotal: 14.6s\tremaining: 41.1s\n",
      "1205:\tlearn: 2.1309337\ttotal: 14.6s\tremaining: 41.1s\n",
      "1206:\tlearn: 2.1305464\ttotal: 14.6s\tremaining: 41.1s\n",
      "1207:\tlearn: 2.1299765\ttotal: 14.6s\tremaining: 41s\n",
      "1208:\tlearn: 2.1294321\ttotal: 14.6s\tremaining: 41s\n",
      "1209:\tlearn: 2.1290131\ttotal: 14.6s\tremaining: 41s\n",
      "1210:\tlearn: 2.1287573\ttotal: 14.7s\tremaining: 41s\n",
      "1211:\tlearn: 2.1283524\ttotal: 14.7s\tremaining: 41s\n",
      "1212:\tlearn: 2.1277437\ttotal: 14.7s\tremaining: 41s\n",
      "1213:\tlearn: 2.1270556\ttotal: 14.7s\tremaining: 41s\n",
      "1214:\tlearn: 2.1264815\ttotal: 14.7s\tremaining: 41s\n",
      "1215:\tlearn: 2.1259935\ttotal: 14.7s\tremaining: 41s\n",
      "1216:\tlearn: 2.1256257\ttotal: 14.7s\tremaining: 40.9s\n",
      "1217:\tlearn: 2.1252426\ttotal: 14.7s\tremaining: 40.9s\n",
      "1218:\tlearn: 2.1247394\ttotal: 14.8s\tremaining: 40.9s\n",
      "1219:\tlearn: 2.1238992\ttotal: 14.8s\tremaining: 40.9s\n",
      "1220:\tlearn: 2.1232895\ttotal: 14.8s\tremaining: 40.9s\n",
      "1221:\tlearn: 2.1227000\ttotal: 14.8s\tremaining: 40.9s\n",
      "1222:\tlearn: 2.1221295\ttotal: 14.8s\tremaining: 40.9s\n",
      "1223:\tlearn: 2.1214258\ttotal: 14.8s\tremaining: 40.8s\n",
      "1224:\tlearn: 2.1206284\ttotal: 14.8s\tremaining: 40.8s\n",
      "1225:\tlearn: 2.1203150\ttotal: 14.8s\tremaining: 40.8s\n",
      "1226:\tlearn: 2.1198191\ttotal: 14.9s\tremaining: 40.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1227:\tlearn: 2.1194712\ttotal: 14.9s\tremaining: 40.8s\n",
      "1228:\tlearn: 2.1188317\ttotal: 14.9s\tremaining: 40.8s\n",
      "1229:\tlearn: 2.1181072\ttotal: 14.9s\tremaining: 40.8s\n",
      "1230:\tlearn: 2.1175117\ttotal: 14.9s\tremaining: 40.8s\n",
      "1231:\tlearn: 2.1171411\ttotal: 14.9s\tremaining: 40.8s\n",
      "1232:\tlearn: 2.1168535\ttotal: 14.9s\tremaining: 40.7s\n",
      "1233:\tlearn: 2.1163874\ttotal: 14.9s\tremaining: 40.7s\n",
      "1234:\tlearn: 2.1158499\ttotal: 15s\tremaining: 40.7s\n",
      "1235:\tlearn: 2.1150890\ttotal: 15s\tremaining: 40.7s\n",
      "1236:\tlearn: 2.1147204\ttotal: 15s\tremaining: 40.7s\n",
      "1237:\tlearn: 2.1141554\ttotal: 15s\tremaining: 40.7s\n",
      "1238:\tlearn: 2.1134142\ttotal: 15s\tremaining: 40.7s\n",
      "1239:\tlearn: 2.1130841\ttotal: 15s\tremaining: 40.7s\n",
      "1240:\tlearn: 2.1121017\ttotal: 15s\tremaining: 40.6s\n",
      "1241:\tlearn: 2.1114345\ttotal: 15s\tremaining: 40.6s\n",
      "1242:\tlearn: 2.1110373\ttotal: 15.1s\tremaining: 40.6s\n",
      "1243:\tlearn: 2.1101546\ttotal: 15.1s\tremaining: 40.6s\n",
      "1244:\tlearn: 2.1096171\ttotal: 15.1s\tremaining: 40.6s\n",
      "1245:\tlearn: 2.1088720\ttotal: 15.1s\tremaining: 40.6s\n",
      "1246:\tlearn: 2.1083860\ttotal: 15.1s\tremaining: 40.6s\n",
      "1247:\tlearn: 2.1078075\ttotal: 15.1s\tremaining: 40.6s\n",
      "1248:\tlearn: 2.1074936\ttotal: 15.1s\tremaining: 40.6s\n",
      "1249:\tlearn: 2.1070843\ttotal: 15.1s\tremaining: 40.5s\n",
      "1250:\tlearn: 2.1063312\ttotal: 15.1s\tremaining: 40.5s\n",
      "1251:\tlearn: 2.1060721\ttotal: 15.2s\tremaining: 40.5s\n",
      "1252:\tlearn: 2.1053079\ttotal: 15.2s\tremaining: 40.5s\n",
      "1253:\tlearn: 2.1048007\ttotal: 15.2s\tremaining: 40.5s\n",
      "1254:\tlearn: 2.1043796\ttotal: 15.2s\tremaining: 40.5s\n",
      "1255:\tlearn: 2.1038080\ttotal: 15.2s\tremaining: 40.5s\n",
      "1256:\tlearn: 2.1034625\ttotal: 15.2s\tremaining: 40.4s\n",
      "1257:\tlearn: 2.1030046\ttotal: 15.2s\tremaining: 40.4s\n",
      "1258:\tlearn: 2.1026784\ttotal: 15.2s\tremaining: 40.4s\n",
      "1259:\tlearn: 2.1020827\ttotal: 15.3s\tremaining: 40.4s\n",
      "1260:\tlearn: 2.1018942\ttotal: 15.3s\tremaining: 40.4s\n",
      "1261:\tlearn: 2.1013638\ttotal: 15.3s\tremaining: 40.4s\n",
      "1262:\tlearn: 2.1007963\ttotal: 15.3s\tremaining: 40.4s\n",
      "1263:\tlearn: 2.1003942\ttotal: 15.3s\tremaining: 40.4s\n",
      "1264:\tlearn: 2.0998942\ttotal: 15.3s\tremaining: 40.4s\n",
      "1265:\tlearn: 2.0995990\ttotal: 15.3s\tremaining: 40.3s\n",
      "1266:\tlearn: 2.0990977\ttotal: 15.3s\tremaining: 40.3s\n",
      "1267:\tlearn: 2.0984506\ttotal: 15.3s\tremaining: 40.3s\n",
      "1268:\tlearn: 2.0976778\ttotal: 15.4s\tremaining: 40.3s\n",
      "1269:\tlearn: 2.0970205\ttotal: 15.4s\tremaining: 40.3s\n",
      "1270:\tlearn: 2.0966596\ttotal: 15.4s\tremaining: 40.3s\n",
      "1271:\tlearn: 2.0959310\ttotal: 15.4s\tremaining: 40.3s\n",
      "1272:\tlearn: 2.0953184\ttotal: 15.4s\tremaining: 40.3s\n",
      "1273:\tlearn: 2.0950819\ttotal: 15.4s\tremaining: 40.2s\n",
      "1274:\tlearn: 2.0946010\ttotal: 15.4s\tremaining: 40.2s\n",
      "1275:\tlearn: 2.0940696\ttotal: 15.4s\tremaining: 40.2s\n",
      "1276:\tlearn: 2.0933017\ttotal: 15.5s\tremaining: 40.2s\n",
      "1277:\tlearn: 2.0930243\ttotal: 15.5s\tremaining: 40.2s\n",
      "1278:\tlearn: 2.0920755\ttotal: 15.5s\tremaining: 40.2s\n",
      "1279:\tlearn: 2.0917860\ttotal: 15.5s\tremaining: 40.2s\n",
      "1280:\tlearn: 2.0913115\ttotal: 15.5s\tremaining: 40.2s\n",
      "1281:\tlearn: 2.0909210\ttotal: 15.5s\tremaining: 40.2s\n",
      "1282:\tlearn: 2.0902449\ttotal: 15.5s\tremaining: 40.1s\n",
      "1283:\tlearn: 2.0897787\ttotal: 15.5s\tremaining: 40.1s\n",
      "1284:\tlearn: 2.0893677\ttotal: 15.6s\tremaining: 40.1s\n",
      "1285:\tlearn: 2.0883618\ttotal: 15.6s\tremaining: 40.1s\n",
      "1286:\tlearn: 2.0880582\ttotal: 15.6s\tremaining: 40.1s\n",
      "1287:\tlearn: 2.0871383\ttotal: 15.6s\tremaining: 40.1s\n",
      "1288:\tlearn: 2.0865728\ttotal: 15.6s\tremaining: 40.1s\n",
      "1289:\tlearn: 2.0863157\ttotal: 15.6s\tremaining: 40.1s\n",
      "1290:\tlearn: 2.0859345\ttotal: 15.6s\tremaining: 40s\n",
      "1291:\tlearn: 2.0855553\ttotal: 15.6s\tremaining: 40s\n",
      "1292:\tlearn: 2.0848401\ttotal: 15.7s\tremaining: 40s\n",
      "1293:\tlearn: 2.0845428\ttotal: 15.7s\tremaining: 40s\n",
      "1294:\tlearn: 2.0834882\ttotal: 15.7s\tremaining: 40s\n",
      "1295:\tlearn: 2.0829713\ttotal: 15.7s\tremaining: 40s\n",
      "1296:\tlearn: 2.0822892\ttotal: 15.7s\tremaining: 40s\n",
      "1297:\tlearn: 2.0816076\ttotal: 15.7s\tremaining: 40s\n",
      "1298:\tlearn: 2.0812681\ttotal: 15.7s\tremaining: 40s\n",
      "1299:\tlearn: 2.0810930\ttotal: 15.7s\tremaining: 39.9s\n",
      "1300:\tlearn: 2.0807643\ttotal: 15.8s\tremaining: 39.9s\n",
      "1301:\tlearn: 2.0804340\ttotal: 15.8s\tremaining: 39.9s\n",
      "1302:\tlearn: 2.0800672\ttotal: 15.8s\tremaining: 39.9s\n",
      "1303:\tlearn: 2.0797830\ttotal: 15.8s\tremaining: 39.9s\n",
      "1304:\tlearn: 2.0794368\ttotal: 15.8s\tremaining: 39.9s\n",
      "1305:\tlearn: 2.0789022\ttotal: 15.8s\tremaining: 39.9s\n",
      "1306:\tlearn: 2.0786374\ttotal: 15.8s\tremaining: 39.9s\n",
      "1307:\tlearn: 2.0782355\ttotal: 15.8s\tremaining: 39.8s\n",
      "1308:\tlearn: 2.0777396\ttotal: 15.9s\tremaining: 39.8s\n",
      "1309:\tlearn: 2.0775876\ttotal: 15.9s\tremaining: 39.8s\n",
      "1310:\tlearn: 2.0770792\ttotal: 15.9s\tremaining: 39.8s\n",
      "1311:\tlearn: 2.0765396\ttotal: 15.9s\tremaining: 39.8s\n",
      "1312:\tlearn: 2.0760888\ttotal: 15.9s\tremaining: 39.8s\n",
      "1313:\tlearn: 2.0754270\ttotal: 15.9s\tremaining: 39.8s\n",
      "1314:\tlearn: 2.0751285\ttotal: 15.9s\tremaining: 39.8s\n",
      "1315:\tlearn: 2.0747776\ttotal: 15.9s\tremaining: 39.7s\n",
      "1316:\tlearn: 2.0741282\ttotal: 15.9s\tremaining: 39.7s\n",
      "1317:\tlearn: 2.0734203\ttotal: 16s\tremaining: 39.7s\n",
      "1318:\tlearn: 2.0725389\ttotal: 16s\tremaining: 39.7s\n",
      "1319:\tlearn: 2.0721385\ttotal: 16s\tremaining: 39.7s\n",
      "1320:\tlearn: 2.0716689\ttotal: 16s\tremaining: 39.7s\n",
      "1321:\tlearn: 2.0710229\ttotal: 16s\tremaining: 39.7s\n",
      "1322:\tlearn: 2.0705463\ttotal: 16s\tremaining: 39.7s\n",
      "1323:\tlearn: 2.0699233\ttotal: 16s\tremaining: 39.6s\n",
      "1324:\tlearn: 2.0695136\ttotal: 16s\tremaining: 39.6s\n",
      "1325:\tlearn: 2.0687150\ttotal: 16.1s\tremaining: 39.6s\n",
      "1326:\tlearn: 2.0681371\ttotal: 16.1s\tremaining: 39.6s\n",
      "1327:\tlearn: 2.0676587\ttotal: 16.1s\tremaining: 39.6s\n",
      "1328:\tlearn: 2.0673646\ttotal: 16.1s\tremaining: 39.6s\n",
      "1329:\tlearn: 2.0666179\ttotal: 16.1s\tremaining: 39.6s\n",
      "1330:\tlearn: 2.0662804\ttotal: 16.1s\tremaining: 39.6s\n",
      "1331:\tlearn: 2.0662773\ttotal: 16.1s\tremaining: 39.5s\n",
      "1332:\tlearn: 2.0659141\ttotal: 16.1s\tremaining: 39.5s\n",
      "1333:\tlearn: 2.0649727\ttotal: 16.2s\tremaining: 39.5s\n",
      "1334:\tlearn: 2.0648113\ttotal: 16.2s\tremaining: 39.5s\n",
      "1335:\tlearn: 2.0641682\ttotal: 16.2s\tremaining: 39.5s\n",
      "1336:\tlearn: 2.0631025\ttotal: 16.2s\tremaining: 39.5s\n",
      "1337:\tlearn: 2.0624838\ttotal: 16.2s\tremaining: 39.5s\n",
      "1338:\tlearn: 2.0613532\ttotal: 16.2s\tremaining: 39.5s\n",
      "1339:\tlearn: 2.0608488\ttotal: 16.2s\tremaining: 39.5s\n",
      "1340:\tlearn: 2.0604112\ttotal: 16.2s\tremaining: 39.4s\n",
      "1341:\tlearn: 2.0598980\ttotal: 16.3s\tremaining: 39.4s\n",
      "1342:\tlearn: 2.0592160\ttotal: 16.3s\tremaining: 39.4s\n",
      "1343:\tlearn: 2.0587034\ttotal: 16.3s\tremaining: 39.4s\n",
      "1344:\tlearn: 2.0581429\ttotal: 16.3s\tremaining: 39.4s\n",
      "1345:\tlearn: 2.0578197\ttotal: 16.3s\tremaining: 39.4s\n",
      "1346:\tlearn: 2.0577439\ttotal: 16.3s\tremaining: 39.4s\n",
      "1347:\tlearn: 2.0575507\ttotal: 16.3s\tremaining: 39.3s\n",
      "1348:\tlearn: 2.0569191\ttotal: 16.3s\tremaining: 39.3s\n",
      "1349:\tlearn: 2.0560968\ttotal: 16.3s\tremaining: 39.3s\n",
      "1350:\tlearn: 2.0553558\ttotal: 16.4s\tremaining: 39.3s\n",
      "1351:\tlearn: 2.0548984\ttotal: 16.4s\tremaining: 39.3s\n",
      "1352:\tlearn: 2.0543399\ttotal: 16.4s\tremaining: 39.3s\n",
      "1353:\tlearn: 2.0537639\ttotal: 16.4s\tremaining: 39.3s\n",
      "1354:\tlearn: 2.0533266\ttotal: 16.4s\tremaining: 39.3s\n",
      "1355:\tlearn: 2.0525603\ttotal: 16.4s\tremaining: 39.3s\n",
      "1356:\tlearn: 2.0520604\ttotal: 16.4s\tremaining: 39.2s\n",
      "1357:\tlearn: 2.0516486\ttotal: 16.4s\tremaining: 39.2s\n",
      "1358:\tlearn: 2.0516439\ttotal: 16.5s\tremaining: 39.2s\n",
      "1359:\tlearn: 2.0509353\ttotal: 16.5s\tremaining: 39.2s\n",
      "1360:\tlearn: 2.0506305\ttotal: 16.5s\tremaining: 39.2s\n",
      "1361:\tlearn: 2.0498587\ttotal: 16.5s\tremaining: 39.2s\n",
      "1362:\tlearn: 2.0494794\ttotal: 16.5s\tremaining: 39.2s\n",
      "1363:\tlearn: 2.0491381\ttotal: 16.5s\tremaining: 39.1s\n",
      "1364:\tlearn: 2.0485777\ttotal: 16.5s\tremaining: 39.1s\n",
      "1365:\tlearn: 2.0483065\ttotal: 16.5s\tremaining: 39.1s\n",
      "1366:\tlearn: 2.0477333\ttotal: 16.5s\tremaining: 39.1s\n",
      "1367:\tlearn: 2.0470704\ttotal: 16.6s\tremaining: 39.1s\n",
      "1368:\tlearn: 2.0468364\ttotal: 16.6s\tremaining: 39.1s\n",
      "1369:\tlearn: 2.0462183\ttotal: 16.6s\tremaining: 39.1s\n",
      "1370:\tlearn: 2.0456314\ttotal: 16.6s\tremaining: 39.1s\n",
      "1371:\tlearn: 2.0452296\ttotal: 16.6s\tremaining: 39.1s\n",
      "1372:\tlearn: 2.0444677\ttotal: 16.6s\tremaining: 39s\n",
      "1373:\tlearn: 2.0443586\ttotal: 16.6s\tremaining: 39s\n",
      "1374:\tlearn: 2.0442214\ttotal: 16.6s\tremaining: 39s\n",
      "1375:\tlearn: 2.0438378\ttotal: 16.7s\tremaining: 39s\n",
      "1376:\tlearn: 2.0434153\ttotal: 16.7s\tremaining: 39s\n",
      "1377:\tlearn: 2.0431683\ttotal: 16.7s\tremaining: 39s\n",
      "1378:\tlearn: 2.0429349\ttotal: 16.7s\tremaining: 39s\n",
      "1379:\tlearn: 2.0424963\ttotal: 16.7s\tremaining: 38.9s\n",
      "1380:\tlearn: 2.0423050\ttotal: 16.7s\tremaining: 38.9s\n",
      "1381:\tlearn: 2.0417403\ttotal: 16.7s\tremaining: 38.9s\n",
      "1382:\tlearn: 2.0412931\ttotal: 16.7s\tremaining: 38.9s\n",
      "1383:\tlearn: 2.0404101\ttotal: 16.7s\tremaining: 38.9s\n",
      "1384:\tlearn: 2.0397300\ttotal: 16.8s\tremaining: 38.9s\n",
      "1385:\tlearn: 2.0392123\ttotal: 16.8s\tremaining: 38.9s\n",
      "1386:\tlearn: 2.0387840\ttotal: 16.8s\tremaining: 38.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1387:\tlearn: 2.0384361\ttotal: 16.8s\tremaining: 38.8s\n",
      "1388:\tlearn: 2.0380313\ttotal: 16.8s\tremaining: 38.8s\n",
      "1389:\tlearn: 2.0375892\ttotal: 16.8s\tremaining: 38.8s\n",
      "1390:\tlearn: 2.0373340\ttotal: 16.8s\tremaining: 38.8s\n",
      "1391:\tlearn: 2.0368516\ttotal: 16.8s\tremaining: 38.8s\n",
      "1392:\tlearn: 2.0364253\ttotal: 16.9s\tremaining: 38.8s\n",
      "1393:\tlearn: 2.0357228\ttotal: 16.9s\tremaining: 38.8s\n",
      "1394:\tlearn: 2.0352815\ttotal: 16.9s\tremaining: 38.8s\n",
      "1395:\tlearn: 2.0348803\ttotal: 16.9s\tremaining: 38.8s\n",
      "1396:\tlearn: 2.0345769\ttotal: 16.9s\tremaining: 38.7s\n",
      "1397:\tlearn: 2.0345753\ttotal: 16.9s\tremaining: 38.7s\n",
      "1398:\tlearn: 2.0339623\ttotal: 16.9s\tremaining: 38.7s\n",
      "1399:\tlearn: 2.0330863\ttotal: 16.9s\tremaining: 38.7s\n",
      "1400:\tlearn: 2.0322745\ttotal: 16.9s\tremaining: 38.7s\n",
      "1401:\tlearn: 2.0317754\ttotal: 17s\tremaining: 38.7s\n",
      "1402:\tlearn: 2.0313130\ttotal: 17s\tremaining: 38.7s\n",
      "1403:\tlearn: 2.0306695\ttotal: 17s\tremaining: 38.6s\n",
      "1404:\tlearn: 2.0298493\ttotal: 17s\tremaining: 38.6s\n",
      "1405:\tlearn: 2.0292051\ttotal: 17s\tremaining: 38.6s\n",
      "1406:\tlearn: 2.0286716\ttotal: 17s\tremaining: 38.6s\n",
      "1407:\tlearn: 2.0281749\ttotal: 17s\tremaining: 38.6s\n",
      "1408:\tlearn: 2.0276475\ttotal: 17.1s\tremaining: 38.6s\n",
      "1409:\tlearn: 2.0271240\ttotal: 17.1s\tremaining: 38.6s\n",
      "1410:\tlearn: 2.0266316\ttotal: 17.1s\tremaining: 38.6s\n",
      "1411:\tlearn: 2.0262995\ttotal: 17.1s\tremaining: 38.6s\n",
      "1412:\tlearn: 2.0258598\ttotal: 17.1s\tremaining: 38.5s\n",
      "1413:\tlearn: 2.0252835\ttotal: 17.1s\tremaining: 38.5s\n",
      "1414:\tlearn: 2.0248898\ttotal: 17.1s\tremaining: 38.5s\n",
      "1415:\tlearn: 2.0242036\ttotal: 17.1s\tremaining: 38.5s\n",
      "1416:\tlearn: 2.0238559\ttotal: 17.1s\tremaining: 38.5s\n",
      "1417:\tlearn: 2.0233674\ttotal: 17.2s\tremaining: 38.5s\n",
      "1418:\tlearn: 2.0233256\ttotal: 17.2s\tremaining: 38.5s\n",
      "1419:\tlearn: 2.0230197\ttotal: 17.2s\tremaining: 38.5s\n",
      "1420:\tlearn: 2.0225235\ttotal: 17.2s\tremaining: 38.4s\n",
      "1421:\tlearn: 2.0222715\ttotal: 17.2s\tremaining: 38.4s\n",
      "1422:\tlearn: 2.0215997\ttotal: 17.2s\tremaining: 38.4s\n",
      "1423:\tlearn: 2.0211828\ttotal: 17.2s\tremaining: 38.4s\n",
      "1424:\tlearn: 2.0209540\ttotal: 17.2s\tremaining: 38.4s\n",
      "1425:\tlearn: 2.0203628\ttotal: 17.3s\tremaining: 38.4s\n",
      "1426:\tlearn: 2.0198962\ttotal: 17.3s\tremaining: 38.4s\n",
      "1427:\tlearn: 2.0192084\ttotal: 17.3s\tremaining: 38.4s\n",
      "1428:\tlearn: 2.0186081\ttotal: 17.3s\tremaining: 38.3s\n",
      "1429:\tlearn: 2.0181028\ttotal: 17.3s\tremaining: 38.3s\n",
      "1430:\tlearn: 2.0179981\ttotal: 17.3s\tremaining: 38.3s\n",
      "1431:\tlearn: 2.0173875\ttotal: 17.3s\tremaining: 38.3s\n",
      "1432:\tlearn: 2.0167473\ttotal: 17.3s\tremaining: 38.3s\n",
      "1433:\tlearn: 2.0167446\ttotal: 17.4s\tremaining: 38.3s\n",
      "1434:\tlearn: 2.0160189\ttotal: 17.4s\tremaining: 38.3s\n",
      "1435:\tlearn: 2.0156494\ttotal: 17.4s\tremaining: 38.3s\n",
      "1436:\tlearn: 2.0148534\ttotal: 17.4s\tremaining: 38.3s\n",
      "1437:\tlearn: 2.0148503\ttotal: 17.4s\tremaining: 38.2s\n",
      "1438:\tlearn: 2.0147242\ttotal: 17.4s\tremaining: 38.2s\n",
      "1439:\tlearn: 2.0145645\ttotal: 17.4s\tremaining: 38.2s\n",
      "1440:\tlearn: 2.0137946\ttotal: 17.4s\tremaining: 38.2s\n",
      "1441:\tlearn: 2.0134895\ttotal: 17.4s\tremaining: 38.2s\n",
      "1442:\tlearn: 2.0127391\ttotal: 17.5s\tremaining: 38.2s\n",
      "1443:\tlearn: 2.0119410\ttotal: 17.5s\tremaining: 38.2s\n",
      "1444:\tlearn: 2.0114334\ttotal: 17.5s\tremaining: 38.1s\n",
      "1445:\tlearn: 2.0111647\ttotal: 17.5s\tremaining: 38.1s\n",
      "1446:\tlearn: 2.0107411\ttotal: 17.5s\tremaining: 38.1s\n",
      "1447:\tlearn: 2.0102604\ttotal: 17.5s\tremaining: 38.1s\n",
      "1448:\tlearn: 2.0100097\ttotal: 17.5s\tremaining: 38.1s\n",
      "1449:\tlearn: 2.0096833\ttotal: 17.5s\tremaining: 38.1s\n",
      "1450:\tlearn: 2.0093214\ttotal: 17.6s\tremaining: 38.1s\n",
      "1451:\tlearn: 2.0085893\ttotal: 17.6s\tremaining: 38.1s\n",
      "1452:\tlearn: 2.0082027\ttotal: 17.6s\tremaining: 38s\n",
      "1453:\tlearn: 2.0080971\ttotal: 17.6s\tremaining: 38s\n",
      "1454:\tlearn: 2.0076397\ttotal: 17.6s\tremaining: 38s\n",
      "1455:\tlearn: 2.0072757\ttotal: 17.6s\tremaining: 38s\n",
      "1456:\tlearn: 2.0067714\ttotal: 17.6s\tremaining: 38s\n",
      "1457:\tlearn: 2.0063531\ttotal: 17.6s\tremaining: 38s\n",
      "1458:\tlearn: 2.0057035\ttotal: 17.6s\tremaining: 38s\n",
      "1459:\tlearn: 2.0050518\ttotal: 17.7s\tremaining: 38s\n",
      "1460:\tlearn: 2.0044510\ttotal: 17.7s\tremaining: 37.9s\n",
      "1461:\tlearn: 2.0039216\ttotal: 17.7s\tremaining: 37.9s\n",
      "1462:\tlearn: 2.0032725\ttotal: 17.7s\tremaining: 37.9s\n",
      "1463:\tlearn: 2.0027570\ttotal: 17.7s\tremaining: 37.9s\n",
      "1464:\tlearn: 2.0023304\ttotal: 17.7s\tremaining: 37.9s\n",
      "1465:\tlearn: 2.0018966\ttotal: 17.7s\tremaining: 37.9s\n",
      "1466:\tlearn: 2.0018952\ttotal: 17.7s\tremaining: 37.9s\n",
      "1467:\tlearn: 2.0011304\ttotal: 17.8s\tremaining: 37.9s\n",
      "1468:\tlearn: 2.0009256\ttotal: 17.8s\tremaining: 37.8s\n",
      "1469:\tlearn: 2.0005406\ttotal: 17.8s\tremaining: 37.8s\n",
      "1470:\tlearn: 2.0002803\ttotal: 17.8s\tremaining: 37.8s\n",
      "1471:\tlearn: 2.0001573\ttotal: 17.8s\tremaining: 37.8s\n",
      "1472:\tlearn: 1.9998469\ttotal: 17.8s\tremaining: 37.8s\n",
      "1473:\tlearn: 1.9994856\ttotal: 17.8s\tremaining: 37.8s\n",
      "1474:\tlearn: 1.9988295\ttotal: 17.8s\tremaining: 37.8s\n",
      "1475:\tlearn: 1.9984680\ttotal: 17.8s\tremaining: 37.8s\n",
      "1476:\tlearn: 1.9978918\ttotal: 17.9s\tremaining: 37.7s\n",
      "1477:\tlearn: 1.9973865\ttotal: 17.9s\tremaining: 37.7s\n",
      "1478:\tlearn: 1.9971555\ttotal: 17.9s\tremaining: 37.7s\n",
      "1479:\tlearn: 1.9967804\ttotal: 17.9s\tremaining: 37.7s\n",
      "1480:\tlearn: 1.9965136\ttotal: 17.9s\tremaining: 37.7s\n",
      "1481:\tlearn: 1.9960306\ttotal: 17.9s\tremaining: 37.7s\n",
      "1482:\tlearn: 1.9957151\ttotal: 17.9s\tremaining: 37.7s\n",
      "1483:\tlearn: 1.9954812\ttotal: 17.9s\tremaining: 37.7s\n",
      "1484:\tlearn: 1.9948454\ttotal: 18s\tremaining: 37.6s\n",
      "1485:\tlearn: 1.9947237\ttotal: 18s\tremaining: 37.6s\n",
      "1486:\tlearn: 1.9944642\ttotal: 18s\tremaining: 37.6s\n",
      "1487:\tlearn: 1.9942820\ttotal: 18s\tremaining: 37.6s\n",
      "1488:\tlearn: 1.9940112\ttotal: 18s\tremaining: 37.6s\n",
      "1489:\tlearn: 1.9937000\ttotal: 18s\tremaining: 37.6s\n",
      "1490:\tlearn: 1.9933026\ttotal: 18s\tremaining: 37.6s\n",
      "1491:\tlearn: 1.9930188\ttotal: 18s\tremaining: 37.6s\n",
      "1492:\tlearn: 1.9930111\ttotal: 18.1s\tremaining: 37.5s\n",
      "1493:\tlearn: 1.9924679\ttotal: 18.1s\tremaining: 37.5s\n",
      "1494:\tlearn: 1.9920212\ttotal: 18.1s\tremaining: 37.5s\n",
      "1495:\tlearn: 1.9913261\ttotal: 18.1s\tremaining: 37.5s\n",
      "1496:\tlearn: 1.9908344\ttotal: 18.1s\tremaining: 37.5s\n",
      "1497:\tlearn: 1.9903321\ttotal: 18.1s\tremaining: 37.5s\n",
      "1498:\tlearn: 1.9897728\ttotal: 18.1s\tremaining: 37.5s\n",
      "1499:\tlearn: 1.9894308\ttotal: 18.1s\tremaining: 37.5s\n",
      "1500:\tlearn: 1.9891907\ttotal: 18.2s\tremaining: 37.5s\n",
      "1501:\tlearn: 1.9891879\ttotal: 18.2s\tremaining: 37.4s\n",
      "1502:\tlearn: 1.9890231\ttotal: 18.2s\tremaining: 37.4s\n",
      "1503:\tlearn: 1.9887812\ttotal: 18.2s\tremaining: 37.4s\n",
      "1504:\tlearn: 1.9882282\ttotal: 18.2s\tremaining: 37.4s\n",
      "1505:\tlearn: 1.9878832\ttotal: 18.2s\tremaining: 37.4s\n",
      "1506:\tlearn: 1.9874511\ttotal: 18.2s\tremaining: 37.4s\n",
      "1507:\tlearn: 1.9866100\ttotal: 18.2s\tremaining: 37.4s\n",
      "1508:\tlearn: 1.9859259\ttotal: 18.2s\tremaining: 37.4s\n",
      "1509:\tlearn: 1.9856122\ttotal: 18.3s\tremaining: 37.3s\n",
      "1510:\tlearn: 1.9851965\ttotal: 18.3s\tremaining: 37.3s\n",
      "1511:\tlearn: 1.9848655\ttotal: 18.3s\tremaining: 37.3s\n",
      "1512:\tlearn: 1.9841374\ttotal: 18.3s\tremaining: 37.3s\n",
      "1513:\tlearn: 1.9836004\ttotal: 18.3s\tremaining: 37.3s\n",
      "1514:\tlearn: 1.9834753\ttotal: 18.3s\tremaining: 37.3s\n",
      "1515:\tlearn: 1.9831164\ttotal: 18.3s\tremaining: 37.3s\n",
      "1516:\tlearn: 1.9828275\ttotal: 18.3s\tremaining: 37.3s\n",
      "1517:\tlearn: 1.9823061\ttotal: 18.4s\tremaining: 37.2s\n",
      "1518:\tlearn: 1.9820533\ttotal: 18.4s\tremaining: 37.2s\n",
      "1519:\tlearn: 1.9818126\ttotal: 18.4s\tremaining: 37.2s\n",
      "1520:\tlearn: 1.9814473\ttotal: 18.4s\tremaining: 37.2s\n",
      "1521:\tlearn: 1.9810942\ttotal: 18.4s\tremaining: 37.2s\n",
      "1522:\tlearn: 1.9804658\ttotal: 18.4s\tremaining: 37.2s\n",
      "1523:\tlearn: 1.9801445\ttotal: 18.4s\tremaining: 37.2s\n",
      "1524:\tlearn: 1.9796265\ttotal: 18.4s\tremaining: 37.2s\n",
      "1525:\tlearn: 1.9789805\ttotal: 18.5s\tremaining: 37.1s\n",
      "1526:\tlearn: 1.9787250\ttotal: 18.5s\tremaining: 37.1s\n",
      "1527:\tlearn: 1.9781781\ttotal: 18.5s\tremaining: 37.1s\n",
      "1528:\tlearn: 1.9777386\ttotal: 18.5s\tremaining: 37.1s\n",
      "1529:\tlearn: 1.9772944\ttotal: 18.5s\tremaining: 37.1s\n",
      "1530:\tlearn: 1.9771092\ttotal: 18.5s\tremaining: 37.1s\n",
      "1531:\tlearn: 1.9766016\ttotal: 18.5s\tremaining: 37.1s\n",
      "1532:\tlearn: 1.9762945\ttotal: 18.5s\tremaining: 37.1s\n",
      "1533:\tlearn: 1.9757968\ttotal: 18.6s\tremaining: 37.1s\n",
      "1534:\tlearn: 1.9755085\ttotal: 18.6s\tremaining: 37s\n",
      "1535:\tlearn: 1.9749512\ttotal: 18.6s\tremaining: 37s\n",
      "1536:\tlearn: 1.9747096\ttotal: 18.6s\tremaining: 37s\n",
      "1537:\tlearn: 1.9744152\ttotal: 18.6s\tremaining: 37s\n",
      "1538:\tlearn: 1.9739265\ttotal: 18.6s\tremaining: 37s\n",
      "1539:\tlearn: 1.9736385\ttotal: 18.6s\tremaining: 37s\n",
      "1540:\tlearn: 1.9733439\ttotal: 18.6s\tremaining: 37s\n",
      "1541:\tlearn: 1.9726793\ttotal: 18.6s\tremaining: 37s\n",
      "1542:\tlearn: 1.9724517\ttotal: 18.7s\tremaining: 36.9s\n",
      "1543:\tlearn: 1.9719908\ttotal: 18.7s\tremaining: 36.9s\n",
      "1544:\tlearn: 1.9715912\ttotal: 18.7s\tremaining: 36.9s\n",
      "1545:\tlearn: 1.9710667\ttotal: 18.7s\tremaining: 36.9s\n",
      "1546:\tlearn: 1.9705979\ttotal: 18.7s\tremaining: 36.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1547:\tlearn: 1.9701059\ttotal: 18.7s\tremaining: 36.9s\n",
      "1548:\tlearn: 1.9699519\ttotal: 18.7s\tremaining: 36.9s\n",
      "1549:\tlearn: 1.9694251\ttotal: 18.7s\tremaining: 36.9s\n",
      "1550:\tlearn: 1.9689605\ttotal: 18.8s\tremaining: 36.9s\n",
      "1551:\tlearn: 1.9686200\ttotal: 18.8s\tremaining: 36.8s\n",
      "1552:\tlearn: 1.9682774\ttotal: 18.8s\tremaining: 36.8s\n",
      "1553:\tlearn: 1.9678428\ttotal: 18.8s\tremaining: 36.8s\n",
      "1554:\tlearn: 1.9669427\ttotal: 18.8s\tremaining: 36.8s\n",
      "1555:\tlearn: 1.9667935\ttotal: 18.8s\tremaining: 36.8s\n",
      "1556:\tlearn: 1.9662830\ttotal: 18.8s\tremaining: 36.8s\n",
      "1557:\tlearn: 1.9662809\ttotal: 18.8s\tremaining: 36.8s\n",
      "1558:\tlearn: 1.9655987\ttotal: 18.9s\tremaining: 36.8s\n",
      "1559:\tlearn: 1.9653305\ttotal: 18.9s\tremaining: 36.7s\n",
      "1560:\tlearn: 1.9649328\ttotal: 18.9s\tremaining: 36.7s\n",
      "1561:\tlearn: 1.9644108\ttotal: 18.9s\tremaining: 36.7s\n",
      "1562:\tlearn: 1.9639360\ttotal: 18.9s\tremaining: 36.7s\n",
      "1563:\tlearn: 1.9635648\ttotal: 18.9s\tremaining: 36.7s\n",
      "1564:\tlearn: 1.9631249\ttotal: 18.9s\tremaining: 36.7s\n",
      "1565:\tlearn: 1.9626615\ttotal: 18.9s\tremaining: 36.7s\n",
      "1566:\tlearn: 1.9624348\ttotal: 18.9s\tremaining: 36.7s\n",
      "1567:\tlearn: 1.9620650\ttotal: 19s\tremaining: 36.6s\n",
      "1568:\tlearn: 1.9617931\ttotal: 19s\tremaining: 36.6s\n",
      "1569:\tlearn: 1.9615781\ttotal: 19s\tremaining: 36.6s\n",
      "1570:\tlearn: 1.9611969\ttotal: 19s\tremaining: 36.6s\n",
      "1571:\tlearn: 1.9607620\ttotal: 19s\tremaining: 36.6s\n",
      "1572:\tlearn: 1.9603241\ttotal: 19s\tremaining: 36.6s\n",
      "1573:\tlearn: 1.9598335\ttotal: 19s\tremaining: 36.6s\n",
      "1574:\tlearn: 1.9595704\ttotal: 19s\tremaining: 36.6s\n",
      "1575:\tlearn: 1.9591438\ttotal: 19.1s\tremaining: 36.5s\n",
      "1576:\tlearn: 1.9589924\ttotal: 19.1s\tremaining: 36.5s\n",
      "1577:\tlearn: 1.9588060\ttotal: 19.1s\tremaining: 36.5s\n",
      "1578:\tlearn: 1.9587046\ttotal: 19.1s\tremaining: 36.5s\n",
      "1579:\tlearn: 1.9581893\ttotal: 19.1s\tremaining: 36.5s\n",
      "1580:\tlearn: 1.9577206\ttotal: 19.1s\tremaining: 36.5s\n",
      "1581:\tlearn: 1.9571308\ttotal: 19.1s\tremaining: 36.5s\n",
      "1582:\tlearn: 1.9568823\ttotal: 19.1s\tremaining: 36.5s\n",
      "1583:\tlearn: 1.9565462\ttotal: 19.2s\tremaining: 36.4s\n",
      "1584:\tlearn: 1.9563146\ttotal: 19.2s\tremaining: 36.4s\n",
      "1585:\tlearn: 1.9560349\ttotal: 19.2s\tremaining: 36.4s\n",
      "1586:\tlearn: 1.9554017\ttotal: 19.2s\tremaining: 36.4s\n",
      "1587:\tlearn: 1.9549125\ttotal: 19.2s\tremaining: 36.4s\n",
      "1588:\tlearn: 1.9546427\ttotal: 19.2s\tremaining: 36.4s\n",
      "1589:\tlearn: 1.9545564\ttotal: 19.2s\tremaining: 36.4s\n",
      "1590:\tlearn: 1.9543408\ttotal: 19.2s\tremaining: 36.4s\n",
      "1591:\tlearn: 1.9540494\ttotal: 19.2s\tremaining: 36.3s\n",
      "1592:\tlearn: 1.9537691\ttotal: 19.3s\tremaining: 36.3s\n",
      "1593:\tlearn: 1.9532677\ttotal: 19.3s\tremaining: 36.3s\n",
      "1594:\tlearn: 1.9524705\ttotal: 19.3s\tremaining: 36.3s\n",
      "1595:\tlearn: 1.9519196\ttotal: 19.3s\tremaining: 36.3s\n",
      "1596:\tlearn: 1.9515117\ttotal: 19.3s\tremaining: 36.3s\n",
      "1597:\tlearn: 1.9510830\ttotal: 19.3s\tremaining: 36.3s\n",
      "1598:\tlearn: 1.9506375\ttotal: 19.3s\tremaining: 36.3s\n",
      "1599:\tlearn: 1.9502022\ttotal: 19.3s\tremaining: 36.2s\n",
      "1600:\tlearn: 1.9498762\ttotal: 19.4s\tremaining: 36.2s\n",
      "1601:\tlearn: 1.9498730\ttotal: 19.4s\tremaining: 36.2s\n",
      "1602:\tlearn: 1.9494183\ttotal: 19.4s\tremaining: 36.2s\n",
      "1603:\tlearn: 1.9493282\ttotal: 19.4s\tremaining: 36.2s\n",
      "1604:\tlearn: 1.9491837\ttotal: 19.4s\tremaining: 36.2s\n",
      "1605:\tlearn: 1.9488867\ttotal: 19.4s\tremaining: 36.2s\n",
      "1606:\tlearn: 1.9483242\ttotal: 19.4s\tremaining: 36.2s\n",
      "1607:\tlearn: 1.9478536\ttotal: 19.4s\tremaining: 36.1s\n",
      "1608:\tlearn: 1.9478523\ttotal: 19.4s\tremaining: 36.1s\n",
      "1609:\tlearn: 1.9475572\ttotal: 19.5s\tremaining: 36.1s\n",
      "1610:\tlearn: 1.9474036\ttotal: 19.5s\tremaining: 36.1s\n",
      "1611:\tlearn: 1.9471291\ttotal: 19.5s\tremaining: 36.1s\n",
      "1612:\tlearn: 1.9468112\ttotal: 19.5s\tremaining: 36.1s\n",
      "1613:\tlearn: 1.9468082\ttotal: 19.5s\tremaining: 36.1s\n",
      "1614:\tlearn: 1.9466569\ttotal: 19.5s\tremaining: 36s\n",
      "1615:\tlearn: 1.9461394\ttotal: 19.5s\tremaining: 36s\n",
      "1616:\tlearn: 1.9458441\ttotal: 19.5s\tremaining: 36s\n",
      "1617:\tlearn: 1.9455403\ttotal: 19.6s\tremaining: 36s\n",
      "1618:\tlearn: 1.9452937\ttotal: 19.6s\tremaining: 36s\n",
      "1619:\tlearn: 1.9451521\ttotal: 19.6s\tremaining: 36s\n",
      "1620:\tlearn: 1.9447284\ttotal: 19.6s\tremaining: 36s\n",
      "1621:\tlearn: 1.9442891\ttotal: 19.6s\tremaining: 36s\n",
      "1622:\tlearn: 1.9438192\ttotal: 19.6s\tremaining: 36s\n",
      "1623:\tlearn: 1.9434333\ttotal: 19.6s\tremaining: 35.9s\n",
      "1624:\tlearn: 1.9427118\ttotal: 19.6s\tremaining: 35.9s\n",
      "1625:\tlearn: 1.9424334\ttotal: 19.6s\tremaining: 35.9s\n",
      "1626:\tlearn: 1.9420862\ttotal: 19.7s\tremaining: 35.9s\n",
      "1627:\tlearn: 1.9414705\ttotal: 19.7s\tremaining: 35.9s\n",
      "1628:\tlearn: 1.9412772\ttotal: 19.7s\tremaining: 35.9s\n",
      "1629:\tlearn: 1.9410956\ttotal: 19.7s\tremaining: 35.9s\n",
      "1630:\tlearn: 1.9407981\ttotal: 19.7s\tremaining: 35.8s\n",
      "1631:\tlearn: 1.9401387\ttotal: 19.7s\tremaining: 35.8s\n",
      "1632:\tlearn: 1.9398710\ttotal: 19.7s\tremaining: 35.8s\n",
      "1633:\tlearn: 1.9394953\ttotal: 19.7s\tremaining: 35.8s\n",
      "1634:\tlearn: 1.9391250\ttotal: 19.8s\tremaining: 35.8s\n",
      "1635:\tlearn: 1.9385465\ttotal: 19.8s\tremaining: 35.8s\n",
      "1636:\tlearn: 1.9378859\ttotal: 19.8s\tremaining: 35.8s\n",
      "1637:\tlearn: 1.9375426\ttotal: 19.8s\tremaining: 35.8s\n",
      "1638:\tlearn: 1.9370634\ttotal: 19.8s\tremaining: 35.7s\n",
      "1639:\tlearn: 1.9365503\ttotal: 19.8s\tremaining: 35.7s\n",
      "1640:\tlearn: 1.9363569\ttotal: 19.8s\tremaining: 35.7s\n",
      "1641:\tlearn: 1.9357621\ttotal: 19.8s\tremaining: 35.7s\n",
      "1642:\tlearn: 1.9353213\ttotal: 19.8s\tremaining: 35.7s\n",
      "1643:\tlearn: 1.9350545\ttotal: 19.9s\tremaining: 35.7s\n",
      "1644:\tlearn: 1.9348216\ttotal: 19.9s\tremaining: 35.7s\n",
      "1645:\tlearn: 1.9346337\ttotal: 19.9s\tremaining: 35.7s\n",
      "1646:\tlearn: 1.9343256\ttotal: 19.9s\tremaining: 35.6s\n",
      "1647:\tlearn: 1.9339464\ttotal: 19.9s\tremaining: 35.6s\n",
      "1648:\tlearn: 1.9335616\ttotal: 19.9s\tremaining: 35.6s\n",
      "1649:\tlearn: 1.9331091\ttotal: 19.9s\tremaining: 35.6s\n",
      "1650:\tlearn: 1.9325896\ttotal: 19.9s\tremaining: 35.6s\n",
      "1651:\tlearn: 1.9323804\ttotal: 19.9s\tremaining: 35.6s\n",
      "1652:\tlearn: 1.9320833\ttotal: 20s\tremaining: 35.6s\n",
      "1653:\tlearn: 1.9319597\ttotal: 20s\tremaining: 35.6s\n",
      "1654:\tlearn: 1.9317851\ttotal: 20s\tremaining: 35.5s\n",
      "1655:\tlearn: 1.9314297\ttotal: 20s\tremaining: 35.5s\n",
      "1656:\tlearn: 1.9308146\ttotal: 20s\tremaining: 35.5s\n",
      "1657:\tlearn: 1.9304831\ttotal: 20s\tremaining: 35.5s\n",
      "1658:\tlearn: 1.9304675\ttotal: 20s\tremaining: 35.5s\n",
      "1659:\tlearn: 1.9300588\ttotal: 20s\tremaining: 35.5s\n",
      "1660:\tlearn: 1.9293233\ttotal: 20.1s\tremaining: 35.5s\n",
      "1661:\tlearn: 1.9288890\ttotal: 20.1s\tremaining: 35.5s\n",
      "1662:\tlearn: 1.9285498\ttotal: 20.1s\tremaining: 35.4s\n",
      "1663:\tlearn: 1.9281732\ttotal: 20.1s\tremaining: 35.4s\n",
      "1664:\tlearn: 1.9276660\ttotal: 20.1s\tremaining: 35.4s\n",
      "1665:\tlearn: 1.9271283\ttotal: 20.1s\tremaining: 35.4s\n",
      "1666:\tlearn: 1.9267213\ttotal: 20.1s\tremaining: 35.4s\n",
      "1667:\tlearn: 1.9265254\ttotal: 20.1s\tremaining: 35.4s\n",
      "1668:\tlearn: 1.9259322\ttotal: 20.2s\tremaining: 35.4s\n",
      "1669:\tlearn: 1.9250660\ttotal: 20.2s\tremaining: 35.4s\n",
      "1670:\tlearn: 1.9245556\ttotal: 20.2s\tremaining: 35.4s\n",
      "1671:\tlearn: 1.9241230\ttotal: 20.2s\tremaining: 35.3s\n",
      "1672:\tlearn: 1.9234573\ttotal: 20.2s\tremaining: 35.3s\n",
      "1673:\tlearn: 1.9227392\ttotal: 20.2s\tremaining: 35.3s\n",
      "1674:\tlearn: 1.9223868\ttotal: 20.2s\tremaining: 35.3s\n",
      "1675:\tlearn: 1.9221068\ttotal: 20.2s\tremaining: 35.3s\n",
      "1676:\tlearn: 1.9217159\ttotal: 20.3s\tremaining: 35.3s\n",
      "1677:\tlearn: 1.9214099\ttotal: 20.3s\tremaining: 35.3s\n",
      "1678:\tlearn: 1.9208847\ttotal: 20.3s\tremaining: 35.3s\n",
      "1679:\tlearn: 1.9205537\ttotal: 20.3s\tremaining: 35.3s\n",
      "1680:\tlearn: 1.9202466\ttotal: 20.3s\tremaining: 35.2s\n",
      "1681:\tlearn: 1.9200166\ttotal: 20.3s\tremaining: 35.2s\n",
      "1682:\tlearn: 1.9195710\ttotal: 20.3s\tremaining: 35.2s\n",
      "1683:\tlearn: 1.9191773\ttotal: 20.3s\tremaining: 35.2s\n",
      "1684:\tlearn: 1.9187949\ttotal: 20.4s\tremaining: 35.2s\n",
      "1685:\tlearn: 1.9178017\ttotal: 20.4s\tremaining: 35.2s\n",
      "1686:\tlearn: 1.9174650\ttotal: 20.4s\tremaining: 35.2s\n",
      "1687:\tlearn: 1.9171325\ttotal: 20.4s\tremaining: 35.2s\n",
      "1688:\tlearn: 1.9165278\ttotal: 20.4s\tremaining: 35.1s\n",
      "1689:\tlearn: 1.9158967\ttotal: 20.4s\tremaining: 35.1s\n",
      "1690:\tlearn: 1.9153168\ttotal: 20.4s\tremaining: 35.1s\n",
      "1691:\tlearn: 1.9151149\ttotal: 20.4s\tremaining: 35.1s\n",
      "1692:\tlearn: 1.9146660\ttotal: 20.5s\tremaining: 35.1s\n",
      "1693:\tlearn: 1.9143228\ttotal: 20.5s\tremaining: 35.1s\n",
      "1694:\tlearn: 1.9135913\ttotal: 20.5s\tremaining: 35.1s\n",
      "1695:\tlearn: 1.9130924\ttotal: 20.5s\tremaining: 35.1s\n",
      "1696:\tlearn: 1.9127412\ttotal: 20.5s\tremaining: 35.1s\n",
      "1697:\tlearn: 1.9120985\ttotal: 20.5s\tremaining: 35s\n",
      "1698:\tlearn: 1.9117847\ttotal: 20.5s\tremaining: 35s\n",
      "1699:\tlearn: 1.9114654\ttotal: 20.5s\tremaining: 35s\n",
      "1700:\tlearn: 1.9111749\ttotal: 20.6s\tremaining: 35s\n",
      "1701:\tlearn: 1.9108413\ttotal: 20.6s\tremaining: 35s\n",
      "1702:\tlearn: 1.9101265\ttotal: 20.6s\tremaining: 35s\n",
      "1703:\tlearn: 1.9098627\ttotal: 20.6s\tremaining: 35s\n",
      "1704:\tlearn: 1.9094397\ttotal: 20.6s\tremaining: 35s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1705:\tlearn: 1.9089896\ttotal: 20.6s\tremaining: 34.9s\n",
      "1706:\tlearn: 1.9085829\ttotal: 20.6s\tremaining: 34.9s\n",
      "1707:\tlearn: 1.9083707\ttotal: 20.6s\tremaining: 34.9s\n",
      "1708:\tlearn: 1.9080878\ttotal: 20.6s\tremaining: 34.9s\n",
      "1709:\tlearn: 1.9077870\ttotal: 20.7s\tremaining: 34.9s\n",
      "1710:\tlearn: 1.9073937\ttotal: 20.7s\tremaining: 34.9s\n",
      "1711:\tlearn: 1.9069117\ttotal: 20.7s\tremaining: 34.9s\n",
      "1712:\tlearn: 1.9066420\ttotal: 20.7s\tremaining: 34.9s\n",
      "1713:\tlearn: 1.9061108\ttotal: 20.7s\tremaining: 34.9s\n",
      "1714:\tlearn: 1.9056628\ttotal: 20.7s\tremaining: 34.8s\n",
      "1715:\tlearn: 1.9050167\ttotal: 20.7s\tremaining: 34.8s\n",
      "1716:\tlearn: 1.9046779\ttotal: 20.7s\tremaining: 34.8s\n",
      "1717:\tlearn: 1.9042467\ttotal: 20.8s\tremaining: 34.8s\n",
      "1718:\tlearn: 1.9042441\ttotal: 20.8s\tremaining: 34.8s\n",
      "1719:\tlearn: 1.9035573\ttotal: 20.8s\tremaining: 34.8s\n",
      "1720:\tlearn: 1.9031296\ttotal: 20.8s\tremaining: 34.8s\n",
      "1721:\tlearn: 1.9025480\ttotal: 20.8s\tremaining: 34.7s\n",
      "1722:\tlearn: 1.9021178\ttotal: 20.8s\tremaining: 34.7s\n",
      "1723:\tlearn: 1.9017375\ttotal: 20.8s\tremaining: 34.7s\n",
      "1724:\tlearn: 1.9012581\ttotal: 20.8s\tremaining: 34.7s\n",
      "1725:\tlearn: 1.9008609\ttotal: 20.9s\tremaining: 34.7s\n",
      "1726:\tlearn: 1.9005322\ttotal: 20.9s\tremaining: 34.7s\n",
      "1727:\tlearn: 1.9002149\ttotal: 20.9s\tremaining: 34.7s\n",
      "1728:\tlearn: 1.8995324\ttotal: 20.9s\tremaining: 34.7s\n",
      "1729:\tlearn: 1.8991184\ttotal: 20.9s\tremaining: 34.7s\n",
      "1730:\tlearn: 1.8984169\ttotal: 20.9s\tremaining: 34.6s\n",
      "1731:\tlearn: 1.8980192\ttotal: 20.9s\tremaining: 34.6s\n",
      "1732:\tlearn: 1.8977421\ttotal: 20.9s\tremaining: 34.6s\n",
      "1733:\tlearn: 1.8972476\ttotal: 21s\tremaining: 34.6s\n",
      "1734:\tlearn: 1.8968398\ttotal: 21s\tremaining: 34.6s\n",
      "1735:\tlearn: 1.8966984\ttotal: 21s\tremaining: 34.6s\n",
      "1736:\tlearn: 1.8961966\ttotal: 21s\tremaining: 34.6s\n",
      "1737:\tlearn: 1.8959511\ttotal: 21s\tremaining: 34.6s\n",
      "1738:\tlearn: 1.8959495\ttotal: 21s\tremaining: 34.5s\n",
      "1739:\tlearn: 1.8959475\ttotal: 21s\tremaining: 34.5s\n",
      "1740:\tlearn: 1.8958472\ttotal: 21s\tremaining: 34.5s\n",
      "1741:\tlearn: 1.8951534\ttotal: 21s\tremaining: 34.5s\n",
      "1742:\tlearn: 1.8945764\ttotal: 21.1s\tremaining: 34.5s\n",
      "1743:\tlearn: 1.8940872\ttotal: 21.1s\tremaining: 34.5s\n",
      "1744:\tlearn: 1.8937697\ttotal: 21.1s\tremaining: 34.5s\n",
      "1745:\tlearn: 1.8935725\ttotal: 21.1s\tremaining: 34.5s\n",
      "1746:\tlearn: 1.8934025\ttotal: 21.1s\tremaining: 34.4s\n",
      "1747:\tlearn: 1.8930193\ttotal: 21.1s\tremaining: 34.4s\n",
      "1748:\tlearn: 1.8925814\ttotal: 21.1s\tremaining: 34.4s\n",
      "1749:\tlearn: 1.8920160\ttotal: 21.1s\tremaining: 34.4s\n",
      "1750:\tlearn: 1.8918379\ttotal: 21.1s\tremaining: 34.4s\n",
      "1751:\tlearn: 1.8915001\ttotal: 21.2s\tremaining: 34.4s\n",
      "1752:\tlearn: 1.8913799\ttotal: 21.2s\tremaining: 34.4s\n",
      "1753:\tlearn: 1.8910247\ttotal: 21.2s\tremaining: 34.3s\n",
      "1754:\tlearn: 1.8909892\ttotal: 21.2s\tremaining: 34.3s\n",
      "1755:\tlearn: 1.8906870\ttotal: 21.2s\tremaining: 34.3s\n",
      "1756:\tlearn: 1.8904467\ttotal: 21.2s\tremaining: 34.3s\n",
      "1757:\tlearn: 1.8901603\ttotal: 21.2s\tremaining: 34.3s\n",
      "1758:\tlearn: 1.8898698\ttotal: 21.2s\tremaining: 34.3s\n",
      "1759:\tlearn: 1.8893994\ttotal: 21.3s\tremaining: 34.3s\n",
      "1760:\tlearn: 1.8889770\ttotal: 21.3s\tremaining: 34.3s\n",
      "1761:\tlearn: 1.8887237\ttotal: 21.3s\tremaining: 34.2s\n",
      "1762:\tlearn: 1.8884354\ttotal: 21.3s\tremaining: 34.2s\n",
      "1763:\tlearn: 1.8879909\ttotal: 21.3s\tremaining: 34.2s\n",
      "1764:\tlearn: 1.8876872\ttotal: 21.3s\tremaining: 34.2s\n",
      "1765:\tlearn: 1.8873171\ttotal: 21.3s\tremaining: 34.2s\n",
      "1766:\tlearn: 1.8870949\ttotal: 21.3s\tremaining: 34.2s\n",
      "1767:\tlearn: 1.8866082\ttotal: 21.3s\tremaining: 34.2s\n",
      "1768:\tlearn: 1.8861531\ttotal: 21.4s\tremaining: 34.2s\n",
      "1769:\tlearn: 1.8858650\ttotal: 21.4s\tremaining: 34.1s\n",
      "1770:\tlearn: 1.8855564\ttotal: 21.4s\tremaining: 34.1s\n",
      "1771:\tlearn: 1.8851254\ttotal: 21.4s\tremaining: 34.1s\n",
      "1772:\tlearn: 1.8846950\ttotal: 21.4s\tremaining: 34.1s\n",
      "1773:\tlearn: 1.8845048\ttotal: 21.4s\tremaining: 34.1s\n",
      "1774:\tlearn: 1.8840924\ttotal: 21.4s\tremaining: 34.1s\n",
      "1775:\tlearn: 1.8837472\ttotal: 21.4s\tremaining: 34.1s\n",
      "1776:\tlearn: 1.8833525\ttotal: 21.5s\tremaining: 34.1s\n",
      "1777:\tlearn: 1.8827520\ttotal: 21.5s\tremaining: 34.1s\n",
      "1778:\tlearn: 1.8822029\ttotal: 21.5s\tremaining: 34s\n",
      "1779:\tlearn: 1.8817947\ttotal: 21.5s\tremaining: 34s\n",
      "1780:\tlearn: 1.8811675\ttotal: 21.5s\tremaining: 34s\n",
      "1781:\tlearn: 1.8807267\ttotal: 21.5s\tremaining: 34s\n",
      "1782:\tlearn: 1.8802154\ttotal: 21.5s\tremaining: 34s\n",
      "1783:\tlearn: 1.8800051\ttotal: 21.5s\tremaining: 34s\n",
      "1784:\tlearn: 1.8795289\ttotal: 21.6s\tremaining: 34s\n",
      "1785:\tlearn: 1.8790133\ttotal: 21.6s\tremaining: 34s\n",
      "1786:\tlearn: 1.8788957\ttotal: 21.6s\tremaining: 33.9s\n",
      "1787:\tlearn: 1.8784608\ttotal: 21.6s\tremaining: 33.9s\n",
      "1788:\tlearn: 1.8781678\ttotal: 21.6s\tremaining: 33.9s\n",
      "1789:\tlearn: 1.8777786\ttotal: 21.6s\tremaining: 33.9s\n",
      "1790:\tlearn: 1.8774803\ttotal: 21.6s\tremaining: 33.9s\n",
      "1791:\tlearn: 1.8772018\ttotal: 21.6s\tremaining: 33.9s\n",
      "1792:\tlearn: 1.8766862\ttotal: 21.6s\tremaining: 33.9s\n",
      "1793:\tlearn: 1.8762220\ttotal: 21.7s\tremaining: 33.9s\n",
      "1794:\tlearn: 1.8757805\ttotal: 21.7s\tremaining: 33.8s\n",
      "1795:\tlearn: 1.8753206\ttotal: 21.7s\tremaining: 33.8s\n",
      "1796:\tlearn: 1.8750014\ttotal: 21.7s\tremaining: 33.8s\n",
      "1797:\tlearn: 1.8748677\ttotal: 21.7s\tremaining: 33.8s\n",
      "1798:\tlearn: 1.8746075\ttotal: 21.7s\tremaining: 33.8s\n",
      "1799:\tlearn: 1.8741480\ttotal: 21.7s\tremaining: 33.8s\n",
      "1800:\tlearn: 1.8738276\ttotal: 21.7s\tremaining: 33.8s\n",
      "1801:\tlearn: 1.8734991\ttotal: 21.8s\tremaining: 33.8s\n",
      "1802:\tlearn: 1.8732743\ttotal: 21.8s\tremaining: 33.7s\n",
      "1803:\tlearn: 1.8730520\ttotal: 21.8s\tremaining: 33.7s\n",
      "1804:\tlearn: 1.8726659\ttotal: 21.8s\tremaining: 33.7s\n",
      "1805:\tlearn: 1.8723071\ttotal: 21.8s\tremaining: 33.7s\n",
      "1806:\tlearn: 1.8717446\ttotal: 21.8s\tremaining: 33.7s\n",
      "1807:\tlearn: 1.8714651\ttotal: 21.8s\tremaining: 33.7s\n",
      "1808:\tlearn: 1.8708381\ttotal: 21.8s\tremaining: 33.7s\n",
      "1809:\tlearn: 1.8703367\ttotal: 21.9s\tremaining: 33.7s\n",
      "1810:\tlearn: 1.8701791\ttotal: 21.9s\tremaining: 33.6s\n",
      "1811:\tlearn: 1.8699468\ttotal: 21.9s\tremaining: 33.6s\n",
      "1812:\tlearn: 1.8694378\ttotal: 21.9s\tremaining: 33.6s\n",
      "1813:\tlearn: 1.8690897\ttotal: 21.9s\tremaining: 33.6s\n",
      "1814:\tlearn: 1.8688228\ttotal: 21.9s\tremaining: 33.6s\n",
      "1815:\tlearn: 1.8681616\ttotal: 21.9s\tremaining: 33.6s\n",
      "1816:\tlearn: 1.8678221\ttotal: 21.9s\tremaining: 33.6s\n",
      "1817:\tlearn: 1.8676095\ttotal: 21.9s\tremaining: 33.6s\n",
      "1818:\tlearn: 1.8671537\ttotal: 22s\tremaining: 33.6s\n",
      "1819:\tlearn: 1.8667990\ttotal: 22s\tremaining: 33.5s\n",
      "1820:\tlearn: 1.8663406\ttotal: 22s\tremaining: 33.5s\n",
      "1821:\tlearn: 1.8658768\ttotal: 22s\tremaining: 33.5s\n",
      "1822:\tlearn: 1.8656852\ttotal: 22s\tremaining: 33.5s\n",
      "1823:\tlearn: 1.8653559\ttotal: 22s\tremaining: 33.5s\n",
      "1824:\tlearn: 1.8650270\ttotal: 22s\tremaining: 33.5s\n",
      "1825:\tlearn: 1.8644833\ttotal: 22s\tremaining: 33.5s\n",
      "1826:\tlearn: 1.8641069\ttotal: 22.1s\tremaining: 33.5s\n",
      "1827:\tlearn: 1.8638500\ttotal: 22.1s\tremaining: 33.4s\n",
      "1828:\tlearn: 1.8635940\ttotal: 22.1s\tremaining: 33.4s\n",
      "1829:\tlearn: 1.8632575\ttotal: 22.1s\tremaining: 33.4s\n",
      "1830:\tlearn: 1.8629837\ttotal: 22.1s\tremaining: 33.4s\n",
      "1831:\tlearn: 1.8627086\ttotal: 22.1s\tremaining: 33.4s\n",
      "1832:\tlearn: 1.8623381\ttotal: 22.1s\tremaining: 33.4s\n",
      "1833:\tlearn: 1.8619923\ttotal: 22.1s\tremaining: 33.4s\n",
      "1834:\tlearn: 1.8618224\ttotal: 22.2s\tremaining: 33.4s\n",
      "1835:\tlearn: 1.8613138\ttotal: 22.2s\tremaining: 33.3s\n",
      "1836:\tlearn: 1.8611292\ttotal: 22.2s\tremaining: 33.3s\n",
      "1837:\tlearn: 1.8605588\ttotal: 22.2s\tremaining: 33.3s\n",
      "1838:\tlearn: 1.8602260\ttotal: 22.2s\tremaining: 33.3s\n",
      "1839:\tlearn: 1.8598323\ttotal: 22.2s\tremaining: 33.3s\n",
      "1840:\tlearn: 1.8595969\ttotal: 22.2s\tremaining: 33.3s\n",
      "1841:\tlearn: 1.8591646\ttotal: 22.2s\tremaining: 33.3s\n",
      "1842:\tlearn: 1.8586204\ttotal: 22.3s\tremaining: 33.3s\n",
      "1843:\tlearn: 1.8583915\ttotal: 22.3s\tremaining: 33.3s\n",
      "1844:\tlearn: 1.8583091\ttotal: 22.3s\tremaining: 33.2s\n",
      "1845:\tlearn: 1.8579728\ttotal: 22.3s\tremaining: 33.2s\n",
      "1846:\tlearn: 1.8575621\ttotal: 22.3s\tremaining: 33.2s\n",
      "1847:\tlearn: 1.8571925\ttotal: 22.3s\tremaining: 33.2s\n",
      "1848:\tlearn: 1.8568027\ttotal: 22.3s\tremaining: 33.2s\n",
      "1849:\tlearn: 1.8565574\ttotal: 22.3s\tremaining: 33.2s\n",
      "1850:\tlearn: 1.8558826\ttotal: 22.4s\tremaining: 33.2s\n",
      "1851:\tlearn: 1.8552733\ttotal: 22.4s\tremaining: 33.2s\n",
      "1852:\tlearn: 1.8548949\ttotal: 22.4s\tremaining: 33.1s\n",
      "1853:\tlearn: 1.8546830\ttotal: 22.4s\tremaining: 33.1s\n",
      "1854:\tlearn: 1.8543557\ttotal: 22.4s\tremaining: 33.1s\n",
      "1855:\tlearn: 1.8539767\ttotal: 22.4s\tremaining: 33.1s\n",
      "1856:\tlearn: 1.8537082\ttotal: 22.4s\tremaining: 33.1s\n",
      "1857:\tlearn: 1.8535144\ttotal: 22.4s\tremaining: 33.1s\n",
      "1858:\tlearn: 1.8531596\ttotal: 22.4s\tremaining: 33.1s\n",
      "1859:\tlearn: 1.8527307\ttotal: 22.5s\tremaining: 33.1s\n",
      "1860:\tlearn: 1.8524515\ttotal: 22.5s\tremaining: 33s\n",
      "1861:\tlearn: 1.8521655\ttotal: 22.5s\tremaining: 33s\n",
      "1862:\tlearn: 1.8518488\ttotal: 22.5s\tremaining: 33s\n",
      "1863:\tlearn: 1.8514424\ttotal: 22.5s\tremaining: 33s\n",
      "1864:\tlearn: 1.8510294\ttotal: 22.5s\tremaining: 33s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1865:\tlearn: 1.8506912\ttotal: 22.5s\tremaining: 33s\n",
      "1866:\tlearn: 1.8501945\ttotal: 22.5s\tremaining: 33s\n",
      "1867:\tlearn: 1.8496435\ttotal: 22.6s\tremaining: 33s\n",
      "1868:\tlearn: 1.8493540\ttotal: 22.6s\tremaining: 32.9s\n",
      "1869:\tlearn: 1.8492285\ttotal: 22.6s\tremaining: 32.9s\n",
      "1870:\tlearn: 1.8485945\ttotal: 22.6s\tremaining: 32.9s\n",
      "1871:\tlearn: 1.8483016\ttotal: 22.6s\tremaining: 32.9s\n",
      "1872:\tlearn: 1.8480898\ttotal: 22.6s\tremaining: 32.9s\n",
      "1873:\tlearn: 1.8476165\ttotal: 22.6s\tremaining: 32.9s\n",
      "1874:\tlearn: 1.8470343\ttotal: 22.6s\tremaining: 32.9s\n",
      "1875:\tlearn: 1.8466539\ttotal: 22.6s\tremaining: 32.9s\n",
      "1876:\tlearn: 1.8461421\ttotal: 22.7s\tremaining: 32.9s\n",
      "1877:\tlearn: 1.8458550\ttotal: 22.7s\tremaining: 32.8s\n",
      "1878:\tlearn: 1.8455037\ttotal: 22.7s\tremaining: 32.8s\n",
      "1879:\tlearn: 1.8449557\ttotal: 22.7s\tremaining: 32.8s\n",
      "1880:\tlearn: 1.8445739\ttotal: 22.7s\tremaining: 32.8s\n",
      "1881:\tlearn: 1.8438769\ttotal: 22.7s\tremaining: 32.8s\n",
      "1882:\tlearn: 1.8435682\ttotal: 22.7s\tremaining: 32.8s\n",
      "1883:\tlearn: 1.8431318\ttotal: 22.8s\tremaining: 32.8s\n",
      "1884:\tlearn: 1.8426932\ttotal: 22.8s\tremaining: 32.8s\n",
      "1885:\tlearn: 1.8421494\ttotal: 22.8s\tremaining: 32.8s\n",
      "1886:\tlearn: 1.8419344\ttotal: 22.8s\tremaining: 32.7s\n",
      "1887:\tlearn: 1.8414920\ttotal: 22.8s\tremaining: 32.7s\n",
      "1888:\tlearn: 1.8410085\ttotal: 22.8s\tremaining: 32.7s\n",
      "1889:\tlearn: 1.8406955\ttotal: 22.8s\tremaining: 32.7s\n",
      "1890:\tlearn: 1.8403283\ttotal: 22.8s\tremaining: 32.7s\n",
      "1891:\tlearn: 1.8399407\ttotal: 22.9s\tremaining: 32.7s\n",
      "1892:\tlearn: 1.8397719\ttotal: 22.9s\tremaining: 32.7s\n",
      "1893:\tlearn: 1.8395075\ttotal: 22.9s\tremaining: 32.7s\n",
      "1894:\tlearn: 1.8388263\ttotal: 22.9s\tremaining: 32.7s\n",
      "1895:\tlearn: 1.8379990\ttotal: 22.9s\tremaining: 32.6s\n",
      "1896:\tlearn: 1.8375491\ttotal: 22.9s\tremaining: 32.6s\n",
      "1897:\tlearn: 1.8370544\ttotal: 22.9s\tremaining: 32.6s\n",
      "1898:\tlearn: 1.8365623\ttotal: 22.9s\tremaining: 32.6s\n",
      "1899:\tlearn: 1.8362471\ttotal: 23s\tremaining: 32.6s\n",
      "1900:\tlearn: 1.8359190\ttotal: 23s\tremaining: 32.6s\n",
      "1901:\tlearn: 1.8355691\ttotal: 23s\tremaining: 32.6s\n",
      "1902:\tlearn: 1.8350397\ttotal: 23s\tremaining: 32.6s\n",
      "1903:\tlearn: 1.8346393\ttotal: 23s\tremaining: 32.5s\n",
      "1904:\tlearn: 1.8342728\ttotal: 23s\tremaining: 32.5s\n",
      "1905:\tlearn: 1.8335683\ttotal: 23s\tremaining: 32.5s\n",
      "1906:\tlearn: 1.8331874\ttotal: 23s\tremaining: 32.5s\n",
      "1907:\tlearn: 1.8328569\ttotal: 23s\tremaining: 32.5s\n",
      "1908:\tlearn: 1.8323649\ttotal: 23.1s\tremaining: 32.5s\n",
      "1909:\tlearn: 1.8321472\ttotal: 23.1s\tremaining: 32.5s\n",
      "1910:\tlearn: 1.8314788\ttotal: 23.1s\tremaining: 32.5s\n",
      "1911:\tlearn: 1.8311069\ttotal: 23.1s\tremaining: 32.4s\n",
      "1912:\tlearn: 1.8308187\ttotal: 23.1s\tremaining: 32.4s\n",
      "1913:\tlearn: 1.8304757\ttotal: 23.1s\tremaining: 32.4s\n",
      "1914:\tlearn: 1.8301602\ttotal: 23.1s\tremaining: 32.4s\n",
      "1915:\tlearn: 1.8298506\ttotal: 23.1s\tremaining: 32.4s\n",
      "1916:\tlearn: 1.8296296\ttotal: 23.2s\tremaining: 32.4s\n",
      "1917:\tlearn: 1.8291964\ttotal: 23.2s\tremaining: 32.4s\n",
      "1918:\tlearn: 1.8288406\ttotal: 23.2s\tremaining: 32.4s\n",
      "1919:\tlearn: 1.8285595\ttotal: 23.2s\tremaining: 32.3s\n",
      "1920:\tlearn: 1.8283134\ttotal: 23.2s\tremaining: 32.3s\n",
      "1921:\tlearn: 1.8280629\ttotal: 23.2s\tremaining: 32.3s\n",
      "1922:\tlearn: 1.8277514\ttotal: 23.2s\tremaining: 32.3s\n",
      "1923:\tlearn: 1.8268425\ttotal: 23.2s\tremaining: 32.3s\n",
      "1924:\tlearn: 1.8260153\ttotal: 23.3s\tremaining: 32.3s\n",
      "1925:\tlearn: 1.8255102\ttotal: 23.3s\tremaining: 32.3s\n",
      "1926:\tlearn: 1.8250974\ttotal: 23.3s\tremaining: 32.3s\n",
      "1927:\tlearn: 1.8247889\ttotal: 23.3s\tremaining: 32.3s\n",
      "1928:\tlearn: 1.8243965\ttotal: 23.3s\tremaining: 32.2s\n",
      "1929:\tlearn: 1.8241574\ttotal: 23.3s\tremaining: 32.2s\n",
      "1930:\tlearn: 1.8237584\ttotal: 23.3s\tremaining: 32.2s\n",
      "1931:\tlearn: 1.8233551\ttotal: 23.3s\tremaining: 32.2s\n",
      "1932:\tlearn: 1.8228739\ttotal: 23.3s\tremaining: 32.2s\n",
      "1933:\tlearn: 1.8225607\ttotal: 23.4s\tremaining: 32.2s\n",
      "1934:\tlearn: 1.8222305\ttotal: 23.4s\tremaining: 32.2s\n",
      "1935:\tlearn: 1.8215173\ttotal: 23.4s\tremaining: 32.2s\n",
      "1936:\tlearn: 1.8209761\ttotal: 23.4s\tremaining: 32.1s\n",
      "1937:\tlearn: 1.8207137\ttotal: 23.4s\tremaining: 32.1s\n",
      "1938:\tlearn: 1.8203862\ttotal: 23.4s\tremaining: 32.1s\n",
      "1939:\tlearn: 1.8198799\ttotal: 23.4s\tremaining: 32.1s\n",
      "1940:\tlearn: 1.8195695\ttotal: 23.4s\tremaining: 32.1s\n",
      "1941:\tlearn: 1.8187926\ttotal: 23.5s\tremaining: 32.1s\n",
      "1942:\tlearn: 1.8184309\ttotal: 23.5s\tremaining: 32.1s\n",
      "1943:\tlearn: 1.8180158\ttotal: 23.5s\tremaining: 32.1s\n",
      "1944:\tlearn: 1.8176296\ttotal: 23.5s\tremaining: 32s\n",
      "1945:\tlearn: 1.8172139\ttotal: 23.5s\tremaining: 32s\n",
      "1946:\tlearn: 1.8169386\ttotal: 23.5s\tremaining: 32s\n",
      "1947:\tlearn: 1.8167387\ttotal: 23.5s\tremaining: 32s\n",
      "1948:\tlearn: 1.8160606\ttotal: 23.5s\tremaining: 32s\n",
      "1949:\tlearn: 1.8155351\ttotal: 23.6s\tremaining: 32s\n",
      "1950:\tlearn: 1.8149124\ttotal: 23.6s\tremaining: 32s\n",
      "1951:\tlearn: 1.8146141\ttotal: 23.6s\tremaining: 32s\n",
      "1952:\tlearn: 1.8143168\ttotal: 23.6s\tremaining: 31.9s\n",
      "1953:\tlearn: 1.8139665\ttotal: 23.6s\tremaining: 31.9s\n",
      "1954:\tlearn: 1.8136247\ttotal: 23.6s\tremaining: 31.9s\n",
      "1955:\tlearn: 1.8133839\ttotal: 23.6s\tremaining: 31.9s\n",
      "1956:\tlearn: 1.8130407\ttotal: 23.6s\tremaining: 31.9s\n",
      "1957:\tlearn: 1.8126867\ttotal: 23.7s\tremaining: 31.9s\n",
      "1958:\tlearn: 1.8122897\ttotal: 23.7s\tremaining: 31.9s\n",
      "1959:\tlearn: 1.8118978\ttotal: 23.7s\tremaining: 31.9s\n",
      "1960:\tlearn: 1.8113305\ttotal: 23.7s\tremaining: 31.9s\n",
      "1961:\tlearn: 1.8108599\ttotal: 23.7s\tremaining: 31.8s\n",
      "1962:\tlearn: 1.8104852\ttotal: 23.7s\tremaining: 31.8s\n",
      "1963:\tlearn: 1.8101360\ttotal: 23.7s\tremaining: 31.8s\n",
      "1964:\tlearn: 1.8097567\ttotal: 23.7s\tremaining: 31.8s\n",
      "1965:\tlearn: 1.8095493\ttotal: 23.8s\tremaining: 31.8s\n",
      "1966:\tlearn: 1.8091341\ttotal: 23.8s\tremaining: 31.8s\n",
      "1967:\tlearn: 1.8088498\ttotal: 23.8s\tremaining: 31.8s\n",
      "1968:\tlearn: 1.8084382\ttotal: 23.8s\tremaining: 31.8s\n",
      "1969:\tlearn: 1.8080494\ttotal: 23.8s\tremaining: 31.8s\n",
      "1970:\tlearn: 1.8078370\ttotal: 23.8s\tremaining: 31.7s\n",
      "1971:\tlearn: 1.8072438\ttotal: 23.8s\tremaining: 31.7s\n",
      "1972:\tlearn: 1.8068392\ttotal: 23.8s\tremaining: 31.7s\n",
      "1973:\tlearn: 1.8063559\ttotal: 23.9s\tremaining: 31.7s\n",
      "1974:\tlearn: 1.8059176\ttotal: 23.9s\tremaining: 31.7s\n",
      "1975:\tlearn: 1.8057000\ttotal: 23.9s\tremaining: 31.7s\n",
      "1976:\tlearn: 1.8054377\ttotal: 23.9s\tremaining: 31.7s\n",
      "1977:\tlearn: 1.8047610\ttotal: 23.9s\tremaining: 31.7s\n",
      "1978:\tlearn: 1.8044231\ttotal: 23.9s\tremaining: 31.6s\n",
      "1979:\tlearn: 1.8043251\ttotal: 23.9s\tremaining: 31.6s\n",
      "1980:\tlearn: 1.8041397\ttotal: 23.9s\tremaining: 31.6s\n",
      "1981:\tlearn: 1.8038309\ttotal: 23.9s\tremaining: 31.6s\n",
      "1982:\tlearn: 1.8036680\ttotal: 24s\tremaining: 31.6s\n",
      "1983:\tlearn: 1.8032401\ttotal: 24s\tremaining: 31.6s\n",
      "1984:\tlearn: 1.8029461\ttotal: 24s\tremaining: 31.6s\n",
      "1985:\tlearn: 1.8027214\ttotal: 24s\tremaining: 31.6s\n",
      "1986:\tlearn: 1.8024534\ttotal: 24s\tremaining: 31.6s\n",
      "1987:\tlearn: 1.8021948\ttotal: 24s\tremaining: 31.5s\n",
      "1988:\tlearn: 1.8021440\ttotal: 24s\tremaining: 31.5s\n",
      "1989:\tlearn: 1.8019970\ttotal: 24s\tremaining: 31.5s\n",
      "1990:\tlearn: 1.8014420\ttotal: 24.1s\tremaining: 31.5s\n",
      "1991:\tlearn: 1.8007703\ttotal: 24.1s\tremaining: 31.5s\n",
      "1992:\tlearn: 1.8002012\ttotal: 24.1s\tremaining: 31.5s\n",
      "1993:\tlearn: 1.7995932\ttotal: 24.1s\tremaining: 31.5s\n",
      "1994:\tlearn: 1.7992074\ttotal: 24.1s\tremaining: 31.5s\n",
      "1995:\tlearn: 1.7983822\ttotal: 24.1s\tremaining: 31.4s\n",
      "1996:\tlearn: 1.7978952\ttotal: 24.1s\tremaining: 31.4s\n",
      "1997:\tlearn: 1.7974966\ttotal: 24.1s\tremaining: 31.4s\n",
      "1998:\tlearn: 1.7971145\ttotal: 24.2s\tremaining: 31.4s\n",
      "1999:\tlearn: 1.7967552\ttotal: 24.2s\tremaining: 31.4s\n",
      "2000:\tlearn: 1.7963353\ttotal: 24.2s\tremaining: 31.4s\n",
      "2001:\tlearn: 1.7959817\ttotal: 24.2s\tremaining: 31.4s\n",
      "2002:\tlearn: 1.7956078\ttotal: 24.2s\tremaining: 31.4s\n",
      "2003:\tlearn: 1.7950223\ttotal: 24.2s\tremaining: 31.3s\n",
      "2004:\tlearn: 1.7945296\ttotal: 24.2s\tremaining: 31.3s\n",
      "2005:\tlearn: 1.7938873\ttotal: 24.2s\tremaining: 31.3s\n",
      "2006:\tlearn: 1.7935797\ttotal: 24.3s\tremaining: 31.3s\n",
      "2007:\tlearn: 1.7932854\ttotal: 24.3s\tremaining: 31.3s\n",
      "2008:\tlearn: 1.7927745\ttotal: 24.3s\tremaining: 31.3s\n",
      "2009:\tlearn: 1.7923162\ttotal: 24.3s\tremaining: 31.3s\n",
      "2010:\tlearn: 1.7919051\ttotal: 24.3s\tremaining: 31.3s\n",
      "2011:\tlearn: 1.7913285\ttotal: 24.3s\tremaining: 31.3s\n",
      "2012:\tlearn: 1.7911382\ttotal: 24.3s\tremaining: 31.2s\n",
      "2013:\tlearn: 1.7906836\ttotal: 24.3s\tremaining: 31.2s\n",
      "2014:\tlearn: 1.7902127\ttotal: 24.4s\tremaining: 31.2s\n",
      "2015:\tlearn: 1.7900198\ttotal: 24.4s\tremaining: 31.2s\n",
      "2016:\tlearn: 1.7897135\ttotal: 24.4s\tremaining: 31.2s\n",
      "2017:\tlearn: 1.7893139\ttotal: 24.4s\tremaining: 31.2s\n",
      "2018:\tlearn: 1.7890071\ttotal: 24.4s\tremaining: 31.2s\n",
      "2019:\tlearn: 1.7887395\ttotal: 24.4s\tremaining: 31.2s\n",
      "2020:\tlearn: 1.7880077\ttotal: 24.4s\tremaining: 31.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021:\tlearn: 1.7875401\ttotal: 24.4s\tremaining: 31.1s\n",
      "2022:\tlearn: 1.7873714\ttotal: 24.5s\tremaining: 31.1s\n",
      "2023:\tlearn: 1.7870025\ttotal: 24.5s\tremaining: 31.1s\n",
      "2024:\tlearn: 1.7865992\ttotal: 24.5s\tremaining: 31.1s\n",
      "2025:\tlearn: 1.7863279\ttotal: 24.5s\tremaining: 31.1s\n",
      "2026:\tlearn: 1.7861932\ttotal: 24.5s\tremaining: 31.1s\n",
      "2027:\tlearn: 1.7856114\ttotal: 24.5s\tremaining: 31.1s\n",
      "2028:\tlearn: 1.7852749\ttotal: 24.5s\tremaining: 31.1s\n",
      "2029:\tlearn: 1.7848520\ttotal: 24.5s\tremaining: 31s\n",
      "2030:\tlearn: 1.7847394\ttotal: 24.5s\tremaining: 31s\n",
      "2031:\tlearn: 1.7845475\ttotal: 24.6s\tremaining: 31s\n",
      "2032:\tlearn: 1.7841188\ttotal: 24.6s\tremaining: 31s\n",
      "2033:\tlearn: 1.7837761\ttotal: 24.6s\tremaining: 31s\n",
      "2034:\tlearn: 1.7835879\ttotal: 24.6s\tremaining: 31s\n",
      "2035:\tlearn: 1.7831795\ttotal: 24.6s\tremaining: 31s\n",
      "2036:\tlearn: 1.7829208\ttotal: 24.6s\tremaining: 31s\n",
      "2037:\tlearn: 1.7826982\ttotal: 24.6s\tremaining: 30.9s\n",
      "2038:\tlearn: 1.7824170\ttotal: 24.6s\tremaining: 30.9s\n",
      "2039:\tlearn: 1.7821098\ttotal: 24.7s\tremaining: 30.9s\n",
      "2040:\tlearn: 1.7817529\ttotal: 24.7s\tremaining: 30.9s\n",
      "2041:\tlearn: 1.7816993\ttotal: 24.7s\tremaining: 30.9s\n",
      "2042:\tlearn: 1.7815178\ttotal: 24.7s\tremaining: 30.9s\n",
      "2043:\tlearn: 1.7813621\ttotal: 24.7s\tremaining: 30.9s\n",
      "2044:\tlearn: 1.7809983\ttotal: 24.7s\tremaining: 30.9s\n",
      "2045:\tlearn: 1.7806967\ttotal: 24.7s\tremaining: 30.8s\n",
      "2046:\tlearn: 1.7802831\ttotal: 24.7s\tremaining: 30.8s\n",
      "2047:\tlearn: 1.7799332\ttotal: 24.8s\tremaining: 30.8s\n",
      "2048:\tlearn: 1.7797078\ttotal: 24.8s\tremaining: 30.8s\n",
      "2049:\tlearn: 1.7794848\ttotal: 24.8s\tremaining: 30.8s\n",
      "2050:\tlearn: 1.7789412\ttotal: 24.8s\tremaining: 30.8s\n",
      "2051:\tlearn: 1.7785474\ttotal: 24.8s\tremaining: 30.8s\n",
      "2052:\tlearn: 1.7782764\ttotal: 24.8s\tremaining: 30.8s\n",
      "2053:\tlearn: 1.7779827\ttotal: 24.8s\tremaining: 30.7s\n",
      "2054:\tlearn: 1.7775093\ttotal: 24.8s\tremaining: 30.7s\n",
      "2055:\tlearn: 1.7769947\ttotal: 24.9s\tremaining: 30.7s\n",
      "2056:\tlearn: 1.7767620\ttotal: 24.9s\tremaining: 30.7s\n",
      "2057:\tlearn: 1.7764882\ttotal: 24.9s\tremaining: 30.7s\n",
      "2058:\tlearn: 1.7759087\ttotal: 24.9s\tremaining: 30.7s\n",
      "2059:\tlearn: 1.7755942\ttotal: 24.9s\tremaining: 30.7s\n",
      "2060:\tlearn: 1.7754081\ttotal: 24.9s\tremaining: 30.7s\n",
      "2061:\tlearn: 1.7750673\ttotal: 24.9s\tremaining: 30.7s\n",
      "2062:\tlearn: 1.7749351\ttotal: 24.9s\tremaining: 30.6s\n",
      "2063:\tlearn: 1.7747197\ttotal: 24.9s\tremaining: 30.6s\n",
      "2064:\tlearn: 1.7744102\ttotal: 25s\tremaining: 30.6s\n",
      "2065:\tlearn: 1.7741056\ttotal: 25s\tremaining: 30.6s\n",
      "2066:\tlearn: 1.7738828\ttotal: 25s\tremaining: 30.6s\n",
      "2067:\tlearn: 1.7736251\ttotal: 25s\tremaining: 30.6s\n",
      "2068:\tlearn: 1.7733864\ttotal: 25s\tremaining: 30.6s\n",
      "2069:\tlearn: 1.7727406\ttotal: 25s\tremaining: 30.6s\n",
      "2070:\tlearn: 1.7724135\ttotal: 25s\tremaining: 30.5s\n",
      "2071:\tlearn: 1.7719588\ttotal: 25s\tremaining: 30.5s\n",
      "2072:\tlearn: 1.7716905\ttotal: 25.1s\tremaining: 30.5s\n",
      "2073:\tlearn: 1.7713793\ttotal: 25.1s\tremaining: 30.5s\n",
      "2074:\tlearn: 1.7711578\ttotal: 25.1s\tremaining: 30.5s\n",
      "2075:\tlearn: 1.7709986\ttotal: 25.1s\tremaining: 30.5s\n",
      "2076:\tlearn: 1.7706384\ttotal: 25.1s\tremaining: 30.5s\n",
      "2077:\tlearn: 1.7703888\ttotal: 25.1s\tremaining: 30.5s\n",
      "2078:\tlearn: 1.7698013\ttotal: 25.1s\tremaining: 30.5s\n",
      "2079:\tlearn: 1.7694519\ttotal: 25.2s\tremaining: 30.5s\n",
      "2080:\tlearn: 1.7691852\ttotal: 25.2s\tremaining: 30.4s\n",
      "2081:\tlearn: 1.7689350\ttotal: 25.2s\tremaining: 30.4s\n",
      "2082:\tlearn: 1.7686090\ttotal: 25.2s\tremaining: 30.4s\n",
      "2083:\tlearn: 1.7680584\ttotal: 25.2s\tremaining: 30.4s\n",
      "2084:\tlearn: 1.7677193\ttotal: 25.2s\tremaining: 30.4s\n",
      "2085:\tlearn: 1.7673791\ttotal: 25.2s\tremaining: 30.4s\n",
      "2086:\tlearn: 1.7667928\ttotal: 25.2s\tremaining: 30.4s\n",
      "2087:\tlearn: 1.7662683\ttotal: 25.3s\tremaining: 30.4s\n",
      "2088:\tlearn: 1.7661204\ttotal: 25.3s\tremaining: 30.3s\n",
      "2089:\tlearn: 1.7656645\ttotal: 25.3s\tremaining: 30.3s\n",
      "2090:\tlearn: 1.7652409\ttotal: 25.3s\tremaining: 30.3s\n",
      "2091:\tlearn: 1.7651056\ttotal: 25.3s\tremaining: 30.3s\n",
      "2092:\tlearn: 1.7649070\ttotal: 25.3s\tremaining: 30.3s\n",
      "2093:\tlearn: 1.7646478\ttotal: 25.3s\tremaining: 30.3s\n",
      "2094:\tlearn: 1.7645461\ttotal: 25.3s\tremaining: 30.3s\n",
      "2095:\tlearn: 1.7638882\ttotal: 25.3s\tremaining: 30.3s\n",
      "2096:\tlearn: 1.7635908\ttotal: 25.4s\tremaining: 30.2s\n",
      "2097:\tlearn: 1.7633162\ttotal: 25.4s\tremaining: 30.2s\n",
      "2098:\tlearn: 1.7630169\ttotal: 25.4s\tremaining: 30.2s\n",
      "2099:\tlearn: 1.7628870\ttotal: 25.4s\tremaining: 30.2s\n",
      "2100:\tlearn: 1.7624259\ttotal: 25.4s\tremaining: 30.2s\n",
      "2101:\tlearn: 1.7620859\ttotal: 25.4s\tremaining: 30.2s\n",
      "2102:\tlearn: 1.7617678\ttotal: 25.4s\tremaining: 30.2s\n",
      "2103:\tlearn: 1.7613705\ttotal: 25.4s\tremaining: 30.2s\n",
      "2104:\tlearn: 1.7610577\ttotal: 25.5s\tremaining: 30.1s\n",
      "2105:\tlearn: 1.7606228\ttotal: 25.5s\tremaining: 30.1s\n",
      "2106:\tlearn: 1.7603869\ttotal: 25.5s\tremaining: 30.1s\n",
      "2107:\tlearn: 1.7600778\ttotal: 25.5s\tremaining: 30.1s\n",
      "2108:\tlearn: 1.7596964\ttotal: 25.5s\tremaining: 30.1s\n",
      "2109:\tlearn: 1.7592794\ttotal: 25.5s\tremaining: 30.1s\n",
      "2110:\tlearn: 1.7588971\ttotal: 25.5s\tremaining: 30.1s\n",
      "2111:\tlearn: 1.7587194\ttotal: 25.5s\tremaining: 30.1s\n",
      "2112:\tlearn: 1.7584581\ttotal: 25.6s\tremaining: 30.1s\n",
      "2113:\tlearn: 1.7579581\ttotal: 25.6s\tremaining: 30s\n",
      "2114:\tlearn: 1.7573378\ttotal: 25.6s\tremaining: 30s\n",
      "2115:\tlearn: 1.7568199\ttotal: 25.6s\tremaining: 30s\n",
      "2116:\tlearn: 1.7567576\ttotal: 25.6s\tremaining: 30s\n",
      "2117:\tlearn: 1.7565627\ttotal: 25.6s\tremaining: 30s\n",
      "2118:\tlearn: 1.7562549\ttotal: 25.6s\tremaining: 30s\n",
      "2119:\tlearn: 1.7557895\ttotal: 25.6s\tremaining: 30s\n",
      "2120:\tlearn: 1.7555719\ttotal: 25.6s\tremaining: 30s\n",
      "2121:\tlearn: 1.7551946\ttotal: 25.7s\tremaining: 29.9s\n",
      "2122:\tlearn: 1.7547969\ttotal: 25.7s\tremaining: 29.9s\n",
      "2123:\tlearn: 1.7542902\ttotal: 25.7s\tremaining: 29.9s\n",
      "2124:\tlearn: 1.7540638\ttotal: 25.7s\tremaining: 29.9s\n",
      "2125:\tlearn: 1.7534779\ttotal: 25.7s\tremaining: 29.9s\n",
      "2126:\tlearn: 1.7532195\ttotal: 25.7s\tremaining: 29.9s\n",
      "2127:\tlearn: 1.7528543\ttotal: 25.7s\tremaining: 29.9s\n",
      "2128:\tlearn: 1.7526257\ttotal: 25.7s\tremaining: 29.9s\n",
      "2129:\tlearn: 1.7522365\ttotal: 25.8s\tremaining: 29.8s\n",
      "2130:\tlearn: 1.7519762\ttotal: 25.8s\tremaining: 29.8s\n",
      "2131:\tlearn: 1.7516095\ttotal: 25.8s\tremaining: 29.8s\n",
      "2132:\tlearn: 1.7512305\ttotal: 25.8s\tremaining: 29.8s\n",
      "2133:\tlearn: 1.7508358\ttotal: 25.8s\tremaining: 29.8s\n",
      "2134:\tlearn: 1.7504387\ttotal: 25.8s\tremaining: 29.8s\n",
      "2135:\tlearn: 1.7501499\ttotal: 25.8s\tremaining: 29.8s\n",
      "2136:\tlearn: 1.7498144\ttotal: 25.9s\tremaining: 29.8s\n",
      "2137:\tlearn: 1.7493752\ttotal: 25.9s\tremaining: 29.8s\n",
      "2138:\tlearn: 1.7490403\ttotal: 25.9s\tremaining: 29.7s\n",
      "2139:\tlearn: 1.7488177\ttotal: 25.9s\tremaining: 29.7s\n",
      "2140:\tlearn: 1.7486318\ttotal: 25.9s\tremaining: 29.7s\n",
      "2141:\tlearn: 1.7481927\ttotal: 25.9s\tremaining: 29.7s\n",
      "2142:\tlearn: 1.7478471\ttotal: 25.9s\tremaining: 29.7s\n",
      "2143:\tlearn: 1.7472393\ttotal: 25.9s\tremaining: 29.7s\n",
      "2144:\tlearn: 1.7469773\ttotal: 25.9s\tremaining: 29.7s\n",
      "2145:\tlearn: 1.7466999\ttotal: 26s\tremaining: 29.7s\n",
      "2146:\tlearn: 1.7462708\ttotal: 26s\tremaining: 29.7s\n",
      "2147:\tlearn: 1.7460820\ttotal: 26s\tremaining: 29.6s\n",
      "2148:\tlearn: 1.7454523\ttotal: 26s\tremaining: 29.6s\n",
      "2149:\tlearn: 1.7450480\ttotal: 26s\tremaining: 29.6s\n",
      "2150:\tlearn: 1.7445734\ttotal: 26s\tremaining: 29.6s\n",
      "2151:\tlearn: 1.7439461\ttotal: 26s\tremaining: 29.6s\n",
      "2152:\tlearn: 1.7436725\ttotal: 26s\tremaining: 29.6s\n",
      "2153:\tlearn: 1.7435378\ttotal: 26.1s\tremaining: 29.6s\n",
      "2154:\tlearn: 1.7433015\ttotal: 26.1s\tremaining: 29.6s\n",
      "2155:\tlearn: 1.7429065\ttotal: 26.1s\tremaining: 29.5s\n",
      "2156:\tlearn: 1.7426977\ttotal: 26.1s\tremaining: 29.5s\n",
      "2157:\tlearn: 1.7422045\ttotal: 26.1s\tremaining: 29.5s\n",
      "2158:\tlearn: 1.7419471\ttotal: 26.1s\tremaining: 29.5s\n",
      "2159:\tlearn: 1.7416427\ttotal: 26.1s\tremaining: 29.5s\n",
      "2160:\tlearn: 1.7413860\ttotal: 26.1s\tremaining: 29.5s\n",
      "2161:\tlearn: 1.7410305\ttotal: 26.2s\tremaining: 29.5s\n",
      "2162:\tlearn: 1.7406706\ttotal: 26.2s\tremaining: 29.5s\n",
      "2163:\tlearn: 1.7401884\ttotal: 26.2s\tremaining: 29.5s\n",
      "2164:\tlearn: 1.7397764\ttotal: 26.2s\tremaining: 29.4s\n",
      "2165:\tlearn: 1.7394694\ttotal: 26.2s\tremaining: 29.4s\n",
      "2166:\tlearn: 1.7391722\ttotal: 26.2s\tremaining: 29.4s\n",
      "2167:\tlearn: 1.7388526\ttotal: 26.2s\tremaining: 29.4s\n",
      "2168:\tlearn: 1.7382271\ttotal: 26.2s\tremaining: 29.4s\n",
      "2169:\tlearn: 1.7378131\ttotal: 26.3s\tremaining: 29.4s\n",
      "2170:\tlearn: 1.7375703\ttotal: 26.3s\tremaining: 29.4s\n",
      "2171:\tlearn: 1.7370332\ttotal: 26.3s\tremaining: 29.4s\n",
      "2172:\tlearn: 1.7368889\ttotal: 26.3s\tremaining: 29.3s\n",
      "2173:\tlearn: 1.7363942\ttotal: 26.3s\tremaining: 29.3s\n",
      "2174:\tlearn: 1.7359163\ttotal: 26.3s\tremaining: 29.3s\n",
      "2175:\tlearn: 1.7355694\ttotal: 26.3s\tremaining: 29.3s\n",
      "2176:\tlearn: 1.7353068\ttotal: 26.3s\tremaining: 29.3s\n",
      "2177:\tlearn: 1.7350652\ttotal: 26.4s\tremaining: 29.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2178:\tlearn: 1.7347643\ttotal: 26.4s\tremaining: 29.3s\n",
      "2179:\tlearn: 1.7344720\ttotal: 26.4s\tremaining: 29.3s\n",
      "2180:\tlearn: 1.7342424\ttotal: 26.4s\tremaining: 29.2s\n",
      "2181:\tlearn: 1.7339349\ttotal: 26.4s\tremaining: 29.2s\n",
      "2182:\tlearn: 1.7335874\ttotal: 26.4s\tremaining: 29.2s\n",
      "2183:\tlearn: 1.7331872\ttotal: 26.4s\tremaining: 29.2s\n",
      "2184:\tlearn: 1.7325795\ttotal: 26.4s\tremaining: 29.2s\n",
      "2185:\tlearn: 1.7323609\ttotal: 26.4s\tremaining: 29.2s\n",
      "2186:\tlearn: 1.7318522\ttotal: 26.5s\tremaining: 29.2s\n",
      "2187:\tlearn: 1.7313035\ttotal: 26.5s\tremaining: 29.2s\n",
      "2188:\tlearn: 1.7310312\ttotal: 26.5s\tremaining: 29.1s\n",
      "2189:\tlearn: 1.7306487\ttotal: 26.5s\tremaining: 29.1s\n",
      "2190:\tlearn: 1.7305209\ttotal: 26.5s\tremaining: 29.1s\n",
      "2191:\tlearn: 1.7302715\ttotal: 26.5s\tremaining: 29.1s\n",
      "2192:\tlearn: 1.7298962\ttotal: 26.5s\tremaining: 29.1s\n",
      "2193:\tlearn: 1.7296709\ttotal: 26.5s\tremaining: 29.1s\n",
      "2194:\tlearn: 1.7294467\ttotal: 26.6s\tremaining: 29.1s\n",
      "2195:\tlearn: 1.7292338\ttotal: 26.6s\tremaining: 29.1s\n",
      "2196:\tlearn: 1.7289685\ttotal: 26.6s\tremaining: 29.1s\n",
      "2197:\tlearn: 1.7287343\ttotal: 26.6s\tremaining: 29s\n",
      "2198:\tlearn: 1.7286797\ttotal: 26.6s\tremaining: 29s\n",
      "2199:\tlearn: 1.7283360\ttotal: 26.6s\tremaining: 29s\n",
      "2200:\tlearn: 1.7280415\ttotal: 26.6s\tremaining: 29s\n",
      "2201:\tlearn: 1.7278519\ttotal: 26.6s\tremaining: 29s\n",
      "2202:\tlearn: 1.7275856\ttotal: 26.7s\tremaining: 29s\n",
      "2203:\tlearn: 1.7273493\ttotal: 26.7s\tremaining: 29s\n",
      "2204:\tlearn: 1.7269851\ttotal: 26.7s\tremaining: 29s\n",
      "2205:\tlearn: 1.7267937\ttotal: 26.7s\tremaining: 28.9s\n",
      "2206:\tlearn: 1.7264090\ttotal: 26.7s\tremaining: 28.9s\n",
      "2207:\tlearn: 1.7261303\ttotal: 26.7s\tremaining: 28.9s\n",
      "2208:\tlearn: 1.7260113\ttotal: 26.7s\tremaining: 28.9s\n",
      "2209:\tlearn: 1.7257645\ttotal: 26.7s\tremaining: 28.9s\n",
      "2210:\tlearn: 1.7255208\ttotal: 26.8s\tremaining: 28.9s\n",
      "2211:\tlearn: 1.7252516\ttotal: 26.8s\tremaining: 28.9s\n",
      "2212:\tlearn: 1.7248284\ttotal: 26.8s\tremaining: 28.9s\n",
      "2213:\tlearn: 1.7246277\ttotal: 26.8s\tremaining: 28.9s\n",
      "2214:\tlearn: 1.7243013\ttotal: 26.8s\tremaining: 28.8s\n",
      "2215:\tlearn: 1.7240985\ttotal: 26.8s\tremaining: 28.8s\n",
      "2216:\tlearn: 1.7236823\ttotal: 26.8s\tremaining: 28.8s\n",
      "2217:\tlearn: 1.7234923\ttotal: 26.8s\tremaining: 28.8s\n",
      "2218:\tlearn: 1.7230686\ttotal: 26.9s\tremaining: 28.8s\n",
      "2219:\tlearn: 1.7226672\ttotal: 26.9s\tremaining: 28.8s\n",
      "2220:\tlearn: 1.7224320\ttotal: 26.9s\tremaining: 28.8s\n",
      "2221:\tlearn: 1.7221214\ttotal: 26.9s\tremaining: 28.8s\n",
      "2222:\tlearn: 1.7217201\ttotal: 26.9s\tremaining: 28.7s\n",
      "2223:\tlearn: 1.7213945\ttotal: 26.9s\tremaining: 28.7s\n",
      "2224:\tlearn: 1.7211691\ttotal: 26.9s\tremaining: 28.7s\n",
      "2225:\tlearn: 1.7210108\ttotal: 26.9s\tremaining: 28.7s\n",
      "2226:\tlearn: 1.7207446\ttotal: 26.9s\tremaining: 28.7s\n",
      "2227:\tlearn: 1.7204465\ttotal: 27s\tremaining: 28.7s\n",
      "2228:\tlearn: 1.7202133\ttotal: 27s\tremaining: 28.7s\n",
      "2229:\tlearn: 1.7197404\ttotal: 27s\tremaining: 28.7s\n",
      "2230:\tlearn: 1.7194176\ttotal: 27s\tremaining: 28.6s\n",
      "2231:\tlearn: 1.7188597\ttotal: 27s\tremaining: 28.6s\n",
      "2232:\tlearn: 1.7184485\ttotal: 27s\tremaining: 28.6s\n",
      "2233:\tlearn: 1.7180908\ttotal: 27s\tremaining: 28.6s\n",
      "2234:\tlearn: 1.7176923\ttotal: 27s\tremaining: 28.6s\n",
      "2235:\tlearn: 1.7174614\ttotal: 27.1s\tremaining: 28.6s\n",
      "2236:\tlearn: 1.7170026\ttotal: 27.1s\tremaining: 28.6s\n",
      "2237:\tlearn: 1.7169282\ttotal: 27.1s\tremaining: 28.6s\n",
      "2238:\tlearn: 1.7168408\ttotal: 27.1s\tremaining: 28.6s\n",
      "2239:\tlearn: 1.7166863\ttotal: 27.1s\tremaining: 28.5s\n",
      "2240:\tlearn: 1.7164173\ttotal: 27.1s\tremaining: 28.5s\n",
      "2241:\tlearn: 1.7161125\ttotal: 27.1s\tremaining: 28.5s\n",
      "2242:\tlearn: 1.7159432\ttotal: 27.1s\tremaining: 28.5s\n",
      "2243:\tlearn: 1.7155968\ttotal: 27.2s\tremaining: 28.5s\n",
      "2244:\tlearn: 1.7151282\ttotal: 27.2s\tremaining: 28.5s\n",
      "2245:\tlearn: 1.7148980\ttotal: 27.2s\tremaining: 28.5s\n",
      "2246:\tlearn: 1.7145940\ttotal: 27.2s\tremaining: 28.5s\n",
      "2247:\tlearn: 1.7144172\ttotal: 27.2s\tremaining: 28.4s\n",
      "2248:\tlearn: 1.7140987\ttotal: 27.2s\tremaining: 28.4s\n",
      "2249:\tlearn: 1.7138521\ttotal: 27.2s\tremaining: 28.4s\n",
      "2250:\tlearn: 1.7133748\ttotal: 27.2s\tremaining: 28.4s\n",
      "2251:\tlearn: 1.7132031\ttotal: 27.3s\tremaining: 28.4s\n",
      "2252:\tlearn: 1.7128085\ttotal: 27.3s\tremaining: 28.4s\n",
      "2253:\tlearn: 1.7125871\ttotal: 27.3s\tremaining: 28.4s\n",
      "2254:\tlearn: 1.7123617\ttotal: 27.3s\tremaining: 28.4s\n",
      "2255:\tlearn: 1.7120947\ttotal: 27.3s\tremaining: 28.3s\n",
      "2256:\tlearn: 1.7116695\ttotal: 27.3s\tremaining: 28.3s\n",
      "2257:\tlearn: 1.7111857\ttotal: 27.3s\tremaining: 28.3s\n",
      "2258:\tlearn: 1.7107442\ttotal: 27.3s\tremaining: 28.3s\n",
      "2259:\tlearn: 1.7102828\ttotal: 27.4s\tremaining: 28.3s\n",
      "2260:\tlearn: 1.7099391\ttotal: 27.4s\tremaining: 28.3s\n",
      "2261:\tlearn: 1.7095177\ttotal: 27.4s\tremaining: 28.3s\n",
      "2262:\tlearn: 1.7092225\ttotal: 27.4s\tremaining: 28.3s\n",
      "2263:\tlearn: 1.7087734\ttotal: 27.4s\tremaining: 28.3s\n",
      "2264:\tlearn: 1.7084808\ttotal: 27.4s\tremaining: 28.2s\n",
      "2265:\tlearn: 1.7082618\ttotal: 27.4s\tremaining: 28.2s\n",
      "2266:\tlearn: 1.7080646\ttotal: 27.5s\tremaining: 28.2s\n",
      "2267:\tlearn: 1.7078685\ttotal: 27.5s\tremaining: 28.2s\n",
      "2268:\tlearn: 1.7075274\ttotal: 27.5s\tremaining: 28.2s\n",
      "2269:\tlearn: 1.7072818\ttotal: 27.5s\tremaining: 28.2s\n",
      "2270:\tlearn: 1.7070100\ttotal: 27.5s\tremaining: 28.2s\n",
      "2271:\tlearn: 1.7063897\ttotal: 27.5s\tremaining: 28.2s\n",
      "2272:\tlearn: 1.7061133\ttotal: 27.5s\tremaining: 28.2s\n",
      "2273:\tlearn: 1.7059075\ttotal: 27.6s\tremaining: 28.2s\n",
      "2274:\tlearn: 1.7056880\ttotal: 27.6s\tremaining: 28.1s\n",
      "2275:\tlearn: 1.7054337\ttotal: 27.6s\tremaining: 28.1s\n",
      "2276:\tlearn: 1.7052908\ttotal: 27.6s\tremaining: 28.1s\n",
      "2277:\tlearn: 1.7051424\ttotal: 27.6s\tremaining: 28.1s\n",
      "2278:\tlearn: 1.7047151\ttotal: 27.6s\tremaining: 28.1s\n",
      "2279:\tlearn: 1.7046599\ttotal: 27.6s\tremaining: 28.1s\n",
      "2280:\tlearn: 1.7042377\ttotal: 27.6s\tremaining: 28.1s\n",
      "2281:\tlearn: 1.7038265\ttotal: 27.6s\tremaining: 28.1s\n",
      "2282:\tlearn: 1.7036322\ttotal: 27.7s\tremaining: 28.1s\n",
      "2283:\tlearn: 1.7032906\ttotal: 27.7s\tremaining: 28s\n",
      "2284:\tlearn: 1.7031419\ttotal: 27.7s\tremaining: 28s\n",
      "2285:\tlearn: 1.7027299\ttotal: 27.7s\tremaining: 28s\n",
      "2286:\tlearn: 1.7024673\ttotal: 27.7s\tremaining: 28s\n",
      "2287:\tlearn: 1.7021649\ttotal: 27.7s\tremaining: 28s\n",
      "2288:\tlearn: 1.7018773\ttotal: 27.7s\tremaining: 28s\n",
      "2289:\tlearn: 1.7015354\ttotal: 27.7s\tremaining: 28s\n",
      "2290:\tlearn: 1.7013421\ttotal: 27.8s\tremaining: 28s\n",
      "2291:\tlearn: 1.7010624\ttotal: 27.8s\tremaining: 27.9s\n",
      "2292:\tlearn: 1.7008387\ttotal: 27.8s\tremaining: 27.9s\n",
      "2293:\tlearn: 1.7007353\ttotal: 27.8s\tremaining: 27.9s\n",
      "2294:\tlearn: 1.7005353\ttotal: 27.8s\tremaining: 27.9s\n",
      "2295:\tlearn: 1.7003246\ttotal: 27.8s\tremaining: 27.9s\n",
      "2296:\tlearn: 1.7001363\ttotal: 27.8s\tremaining: 27.9s\n",
      "2297:\tlearn: 1.6997637\ttotal: 27.8s\tremaining: 27.9s\n",
      "2298:\tlearn: 1.6996386\ttotal: 27.9s\tremaining: 27.9s\n",
      "2299:\tlearn: 1.6990604\ttotal: 27.9s\tremaining: 27.8s\n",
      "2300:\tlearn: 1.6988644\ttotal: 27.9s\tremaining: 27.8s\n",
      "2301:\tlearn: 1.6985568\ttotal: 27.9s\tremaining: 27.8s\n",
      "2302:\tlearn: 1.6980230\ttotal: 27.9s\tremaining: 27.8s\n",
      "2303:\tlearn: 1.6977539\ttotal: 27.9s\tremaining: 27.8s\n",
      "2304:\tlearn: 1.6975726\ttotal: 27.9s\tremaining: 27.8s\n",
      "2305:\tlearn: 1.6973899\ttotal: 27.9s\tremaining: 27.8s\n",
      "2306:\tlearn: 1.6971526\ttotal: 27.9s\tremaining: 27.8s\n",
      "2307:\tlearn: 1.6967982\ttotal: 28s\tremaining: 27.7s\n",
      "2308:\tlearn: 1.6965751\ttotal: 28s\tremaining: 27.7s\n",
      "2309:\tlearn: 1.6961423\ttotal: 28s\tremaining: 27.7s\n",
      "2310:\tlearn: 1.6958456\ttotal: 28s\tremaining: 27.7s\n",
      "2311:\tlearn: 1.6956719\ttotal: 28s\tremaining: 27.7s\n",
      "2312:\tlearn: 1.6954742\ttotal: 28s\tremaining: 27.7s\n",
      "2313:\tlearn: 1.6949443\ttotal: 28s\tremaining: 27.7s\n",
      "2314:\tlearn: 1.6947728\ttotal: 28s\tremaining: 27.7s\n",
      "2315:\tlearn: 1.6945352\ttotal: 28.1s\tremaining: 27.6s\n",
      "2316:\tlearn: 1.6942099\ttotal: 28.1s\tremaining: 27.6s\n",
      "2317:\tlearn: 1.6937566\ttotal: 28.1s\tremaining: 27.6s\n",
      "2318:\tlearn: 1.6935382\ttotal: 28.1s\tremaining: 27.6s\n",
      "2319:\tlearn: 1.6933955\ttotal: 28.1s\tremaining: 27.6s\n",
      "2320:\tlearn: 1.6931703\ttotal: 28.1s\tremaining: 27.6s\n",
      "2321:\tlearn: 1.6928399\ttotal: 28.1s\tremaining: 27.6s\n",
      "2322:\tlearn: 1.6926728\ttotal: 28.1s\tremaining: 27.6s\n",
      "2323:\tlearn: 1.6924365\ttotal: 28.2s\tremaining: 27.5s\n",
      "2324:\tlearn: 1.6919553\ttotal: 28.2s\tremaining: 27.5s\n",
      "2325:\tlearn: 1.6915137\ttotal: 28.2s\tremaining: 27.5s\n",
      "2326:\tlearn: 1.6911978\ttotal: 28.2s\tremaining: 27.5s\n",
      "2327:\tlearn: 1.6909313\ttotal: 28.2s\tremaining: 27.5s\n",
      "2328:\tlearn: 1.6906312\ttotal: 28.2s\tremaining: 27.5s\n",
      "2329:\tlearn: 1.6903979\ttotal: 28.2s\tremaining: 27.5s\n",
      "2330:\tlearn: 1.6900038\ttotal: 28.2s\tremaining: 27.5s\n",
      "2331:\tlearn: 1.6895417\ttotal: 28.3s\tremaining: 27.5s\n",
      "2332:\tlearn: 1.6891588\ttotal: 28.3s\tremaining: 27.4s\n",
      "2333:\tlearn: 1.6888232\ttotal: 28.3s\tremaining: 27.4s\n",
      "2334:\tlearn: 1.6883700\ttotal: 28.3s\tremaining: 27.4s\n",
      "2335:\tlearn: 1.6879989\ttotal: 28.3s\tremaining: 27.4s\n",
      "2336:\tlearn: 1.6878790\ttotal: 28.3s\tremaining: 27.4s\n",
      "2337:\tlearn: 1.6874686\ttotal: 28.3s\tremaining: 27.4s\n",
      "2338:\tlearn: 1.6871368\ttotal: 28.3s\tremaining: 27.4s\n",
      "2339:\tlearn: 1.6867605\ttotal: 28.4s\tremaining: 27.4s\n",
      "2340:\tlearn: 1.6864218\ttotal: 28.4s\tremaining: 27.3s\n",
      "2341:\tlearn: 1.6863687\ttotal: 28.4s\tremaining: 27.3s\n",
      "2342:\tlearn: 1.6859565\ttotal: 28.4s\tremaining: 27.3s\n",
      "2343:\tlearn: 1.6855758\ttotal: 28.4s\tremaining: 27.3s\n",
      "2344:\tlearn: 1.6852375\ttotal: 28.4s\tremaining: 27.3s\n",
      "2345:\tlearn: 1.6848700\ttotal: 28.4s\tremaining: 27.3s\n",
      "2346:\tlearn: 1.6843860\ttotal: 28.4s\tremaining: 27.3s\n",
      "2347:\tlearn: 1.6839639\ttotal: 28.4s\tremaining: 27.3s\n",
      "2348:\tlearn: 1.6837658\ttotal: 28.5s\tremaining: 27.2s\n",
      "2349:\tlearn: 1.6835503\ttotal: 28.5s\tremaining: 27.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2350:\tlearn: 1.6833043\ttotal: 28.5s\tremaining: 27.2s\n",
      "2351:\tlearn: 1.6830943\ttotal: 28.5s\tremaining: 27.2s\n",
      "2352:\tlearn: 1.6827420\ttotal: 28.5s\tremaining: 27.2s\n",
      "2353:\tlearn: 1.6824156\ttotal: 28.5s\tremaining: 27.2s\n",
      "2354:\tlearn: 1.6820915\ttotal: 28.5s\tremaining: 27.2s\n",
      "2355:\tlearn: 1.6817820\ttotal: 28.5s\tremaining: 27.2s\n",
      "2356:\tlearn: 1.6814422\ttotal: 28.6s\tremaining: 27.2s\n",
      "2357:\tlearn: 1.6813472\ttotal: 28.6s\tremaining: 27.1s\n",
      "2358:\tlearn: 1.6805642\ttotal: 28.6s\tremaining: 27.1s\n",
      "2359:\tlearn: 1.6802957\ttotal: 28.6s\tremaining: 27.1s\n",
      "2360:\tlearn: 1.6798719\ttotal: 28.6s\tremaining: 27.1s\n",
      "2361:\tlearn: 1.6795993\ttotal: 28.6s\tremaining: 27.1s\n",
      "2362:\tlearn: 1.6792088\ttotal: 28.6s\tremaining: 27.1s\n",
      "2363:\tlearn: 1.6788262\ttotal: 28.6s\tremaining: 27.1s\n",
      "2364:\tlearn: 1.6785347\ttotal: 28.7s\tremaining: 27.1s\n",
      "2365:\tlearn: 1.6783829\ttotal: 28.7s\tremaining: 27s\n",
      "2366:\tlearn: 1.6780100\ttotal: 28.7s\tremaining: 27s\n",
      "2367:\tlearn: 1.6776772\ttotal: 28.7s\tremaining: 27s\n",
      "2368:\tlearn: 1.6773077\ttotal: 28.7s\tremaining: 27s\n",
      "2369:\tlearn: 1.6772159\ttotal: 28.7s\tremaining: 27s\n",
      "2370:\tlearn: 1.6770010\ttotal: 28.7s\tremaining: 27s\n",
      "2371:\tlearn: 1.6767534\ttotal: 28.7s\tremaining: 27s\n",
      "2372:\tlearn: 1.6765568\ttotal: 28.8s\tremaining: 27s\n",
      "2373:\tlearn: 1.6762905\ttotal: 28.8s\tremaining: 26.9s\n",
      "2374:\tlearn: 1.6759880\ttotal: 28.8s\tremaining: 26.9s\n",
      "2375:\tlearn: 1.6754793\ttotal: 28.8s\tremaining: 26.9s\n",
      "2376:\tlearn: 1.6752767\ttotal: 28.8s\tremaining: 26.9s\n",
      "2377:\tlearn: 1.6749364\ttotal: 28.8s\tremaining: 26.9s\n",
      "2378:\tlearn: 1.6745863\ttotal: 28.8s\tremaining: 26.9s\n",
      "2379:\tlearn: 1.6739244\ttotal: 28.8s\tremaining: 26.9s\n",
      "2380:\tlearn: 1.6737620\ttotal: 28.9s\tremaining: 26.9s\n",
      "2381:\tlearn: 1.6734163\ttotal: 28.9s\tremaining: 26.9s\n",
      "2382:\tlearn: 1.6730934\ttotal: 28.9s\tremaining: 26.8s\n",
      "2383:\tlearn: 1.6727818\ttotal: 28.9s\tremaining: 26.8s\n",
      "2384:\tlearn: 1.6725030\ttotal: 28.9s\tremaining: 26.8s\n",
      "2385:\tlearn: 1.6721439\ttotal: 28.9s\tremaining: 26.8s\n",
      "2386:\tlearn: 1.6719060\ttotal: 28.9s\tremaining: 26.8s\n",
      "2387:\tlearn: 1.6717209\ttotal: 28.9s\tremaining: 26.8s\n",
      "2388:\tlearn: 1.6713713\ttotal: 28.9s\tremaining: 26.8s\n",
      "2389:\tlearn: 1.6710442\ttotal: 29s\tremaining: 26.8s\n",
      "2390:\tlearn: 1.6708773\ttotal: 29s\tremaining: 26.7s\n",
      "2391:\tlearn: 1.6705372\ttotal: 29s\tremaining: 26.7s\n",
      "2392:\tlearn: 1.6704310\ttotal: 29s\tremaining: 26.7s\n",
      "2393:\tlearn: 1.6701213\ttotal: 29s\tremaining: 26.7s\n",
      "2394:\tlearn: 1.6696875\ttotal: 29s\tremaining: 26.7s\n",
      "2395:\tlearn: 1.6692014\ttotal: 29s\tremaining: 26.7s\n",
      "2396:\tlearn: 1.6687994\ttotal: 29s\tremaining: 26.7s\n",
      "2397:\tlearn: 1.6685367\ttotal: 29.1s\tremaining: 26.7s\n",
      "2398:\tlearn: 1.6684162\ttotal: 29.1s\tremaining: 26.6s\n",
      "2399:\tlearn: 1.6680795\ttotal: 29.1s\tremaining: 26.6s\n",
      "2400:\tlearn: 1.6676076\ttotal: 29.1s\tremaining: 26.6s\n",
      "2401:\tlearn: 1.6673008\ttotal: 29.1s\tremaining: 26.6s\n",
      "2402:\tlearn: 1.6670865\ttotal: 29.1s\tremaining: 26.6s\n",
      "2403:\tlearn: 1.6668893\ttotal: 29.1s\tremaining: 26.6s\n",
      "2404:\tlearn: 1.6664573\ttotal: 29.1s\tremaining: 26.6s\n",
      "2405:\tlearn: 1.6662971\ttotal: 29.1s\tremaining: 26.6s\n",
      "2406:\tlearn: 1.6660859\ttotal: 29.2s\tremaining: 26.5s\n",
      "2407:\tlearn: 1.6659393\ttotal: 29.2s\tremaining: 26.5s\n",
      "2408:\tlearn: 1.6656097\ttotal: 29.2s\tremaining: 26.5s\n",
      "2409:\tlearn: 1.6654500\ttotal: 29.2s\tremaining: 26.5s\n",
      "2410:\tlearn: 1.6651722\ttotal: 29.2s\tremaining: 26.5s\n",
      "2411:\tlearn: 1.6648319\ttotal: 29.2s\tremaining: 26.5s\n",
      "2412:\tlearn: 1.6644633\ttotal: 29.2s\tremaining: 26.5s\n",
      "2413:\tlearn: 1.6643334\ttotal: 29.2s\tremaining: 26.5s\n",
      "2414:\tlearn: 1.6641749\ttotal: 29.3s\tremaining: 26.4s\n",
      "2415:\tlearn: 1.6637843\ttotal: 29.3s\tremaining: 26.4s\n",
      "2416:\tlearn: 1.6634279\ttotal: 29.3s\tremaining: 26.4s\n",
      "2417:\tlearn: 1.6630836\ttotal: 29.3s\tremaining: 26.4s\n",
      "2418:\tlearn: 1.6626530\ttotal: 29.3s\tremaining: 26.4s\n",
      "2419:\tlearn: 1.6623239\ttotal: 29.3s\tremaining: 26.4s\n",
      "2420:\tlearn: 1.6622215\ttotal: 29.3s\tremaining: 26.4s\n",
      "2421:\tlearn: 1.6620813\ttotal: 29.3s\tremaining: 26.4s\n",
      "2422:\tlearn: 1.6616924\ttotal: 29.4s\tremaining: 26.3s\n",
      "2423:\tlearn: 1.6613803\ttotal: 29.4s\tremaining: 26.3s\n",
      "2424:\tlearn: 1.6607186\ttotal: 29.4s\tremaining: 26.3s\n",
      "2425:\tlearn: 1.6606088\ttotal: 29.4s\tremaining: 26.3s\n",
      "2426:\tlearn: 1.6602102\ttotal: 29.4s\tremaining: 26.3s\n",
      "2427:\tlearn: 1.6600186\ttotal: 29.4s\tremaining: 26.3s\n",
      "2428:\tlearn: 1.6594612\ttotal: 29.4s\tremaining: 26.3s\n",
      "2429:\tlearn: 1.6587889\ttotal: 29.5s\tremaining: 26.3s\n",
      "2430:\tlearn: 1.6584411\ttotal: 29.5s\tremaining: 26.3s\n",
      "2431:\tlearn: 1.6581943\ttotal: 29.5s\tremaining: 26.3s\n",
      "2432:\tlearn: 1.6577420\ttotal: 29.5s\tremaining: 26.2s\n",
      "2433:\tlearn: 1.6574292\ttotal: 29.5s\tremaining: 26.2s\n",
      "2434:\tlearn: 1.6571093\ttotal: 29.5s\tremaining: 26.2s\n",
      "2435:\tlearn: 1.6568794\ttotal: 29.5s\tremaining: 26.2s\n",
      "2436:\tlearn: 1.6566264\ttotal: 29.5s\tremaining: 26.2s\n",
      "2437:\tlearn: 1.6563080\ttotal: 29.5s\tremaining: 26.2s\n",
      "2438:\tlearn: 1.6560553\ttotal: 29.6s\tremaining: 26.2s\n",
      "2439:\tlearn: 1.6557776\ttotal: 29.6s\tremaining: 26.2s\n",
      "2440:\tlearn: 1.6552348\ttotal: 29.6s\tremaining: 26.1s\n",
      "2441:\tlearn: 1.6550505\ttotal: 29.6s\tremaining: 26.1s\n",
      "2442:\tlearn: 1.6547910\ttotal: 29.6s\tremaining: 26.1s\n",
      "2443:\tlearn: 1.6545833\ttotal: 29.6s\tremaining: 26.1s\n",
      "2444:\tlearn: 1.6542521\ttotal: 29.6s\tremaining: 26.1s\n",
      "2445:\tlearn: 1.6540929\ttotal: 29.6s\tremaining: 26.1s\n",
      "2446:\tlearn: 1.6537636\ttotal: 29.7s\tremaining: 26.1s\n",
      "2447:\tlearn: 1.6533068\ttotal: 29.7s\tremaining: 26.1s\n",
      "2448:\tlearn: 1.6530614\ttotal: 29.7s\tremaining: 26s\n",
      "2449:\tlearn: 1.6528338\ttotal: 29.7s\tremaining: 26s\n",
      "2450:\tlearn: 1.6526436\ttotal: 29.7s\tremaining: 26s\n",
      "2451:\tlearn: 1.6521840\ttotal: 29.7s\tremaining: 26s\n",
      "2452:\tlearn: 1.6519558\ttotal: 29.7s\tremaining: 26s\n",
      "2453:\tlearn: 1.6517670\ttotal: 29.7s\tremaining: 26s\n",
      "2454:\tlearn: 1.6513826\ttotal: 29.7s\tremaining: 26s\n",
      "2455:\tlearn: 1.6510727\ttotal: 29.8s\tremaining: 26s\n",
      "2456:\tlearn: 1.6510168\ttotal: 29.8s\tremaining: 25.9s\n",
      "2457:\tlearn: 1.6508321\ttotal: 29.8s\tremaining: 25.9s\n",
      "2458:\tlearn: 1.6505387\ttotal: 29.8s\tremaining: 25.9s\n",
      "2459:\tlearn: 1.6501474\ttotal: 29.8s\tremaining: 25.9s\n",
      "2460:\tlearn: 1.6498896\ttotal: 29.8s\tremaining: 25.9s\n",
      "2461:\tlearn: 1.6496330\ttotal: 29.8s\tremaining: 25.9s\n",
      "2462:\tlearn: 1.6494450\ttotal: 29.8s\tremaining: 25.9s\n",
      "2463:\tlearn: 1.6491129\ttotal: 29.9s\tremaining: 25.9s\n",
      "2464:\tlearn: 1.6487950\ttotal: 29.9s\tremaining: 25.8s\n",
      "2465:\tlearn: 1.6485361\ttotal: 29.9s\tremaining: 25.8s\n",
      "2466:\tlearn: 1.6483337\ttotal: 29.9s\tremaining: 25.8s\n",
      "2467:\tlearn: 1.6480931\ttotal: 29.9s\tremaining: 25.8s\n",
      "2468:\tlearn: 1.6478087\ttotal: 29.9s\tremaining: 25.8s\n",
      "2469:\tlearn: 1.6475305\ttotal: 29.9s\tremaining: 25.8s\n",
      "2470:\tlearn: 1.6470363\ttotal: 29.9s\tremaining: 25.8s\n",
      "2471:\tlearn: 1.6466439\ttotal: 29.9s\tremaining: 25.8s\n",
      "2472:\tlearn: 1.6464166\ttotal: 30s\tremaining: 25.7s\n",
      "2473:\tlearn: 1.6462805\ttotal: 30s\tremaining: 25.7s\n",
      "2474:\tlearn: 1.6459622\ttotal: 30s\tremaining: 25.7s\n",
      "2475:\tlearn: 1.6458072\ttotal: 30s\tremaining: 25.7s\n",
      "2476:\tlearn: 1.6455626\ttotal: 30s\tremaining: 25.7s\n",
      "2477:\tlearn: 1.6450261\ttotal: 30s\tremaining: 25.7s\n",
      "2478:\tlearn: 1.6447840\ttotal: 30s\tremaining: 25.7s\n",
      "2479:\tlearn: 1.6445350\ttotal: 30s\tremaining: 25.7s\n",
      "2480:\tlearn: 1.6442359\ttotal: 30.1s\tremaining: 25.6s\n",
      "2481:\tlearn: 1.6440750\ttotal: 30.1s\tremaining: 25.6s\n",
      "2482:\tlearn: 1.6436370\ttotal: 30.1s\tremaining: 25.6s\n",
      "2483:\tlearn: 1.6434033\ttotal: 30.1s\tremaining: 25.6s\n",
      "2484:\tlearn: 1.6429946\ttotal: 30.1s\tremaining: 25.6s\n",
      "2485:\tlearn: 1.6428233\ttotal: 30.1s\tremaining: 25.6s\n",
      "2486:\tlearn: 1.6425308\ttotal: 30.1s\tremaining: 25.6s\n",
      "2487:\tlearn: 1.6421279\ttotal: 30.1s\tremaining: 25.6s\n",
      "2488:\tlearn: 1.6419137\ttotal: 30.2s\tremaining: 25.5s\n",
      "2489:\tlearn: 1.6415167\ttotal: 30.2s\tremaining: 25.5s\n",
      "2490:\tlearn: 1.6413075\ttotal: 30.2s\tremaining: 25.5s\n",
      "2491:\tlearn: 1.6410800\ttotal: 30.2s\tremaining: 25.5s\n",
      "2492:\tlearn: 1.6408457\ttotal: 30.2s\tremaining: 25.5s\n",
      "2493:\tlearn: 1.6400782\ttotal: 30.2s\tremaining: 25.5s\n",
      "2494:\tlearn: 1.6397623\ttotal: 30.2s\tremaining: 25.5s\n",
      "2495:\tlearn: 1.6395067\ttotal: 30.2s\tremaining: 25.5s\n",
      "2496:\tlearn: 1.6389572\ttotal: 30.3s\tremaining: 25.5s\n",
      "2497:\tlearn: 1.6385319\ttotal: 30.3s\tremaining: 25.4s\n",
      "2498:\tlearn: 1.6384919\ttotal: 30.3s\tremaining: 25.4s\n",
      "2499:\tlearn: 1.6381557\ttotal: 30.3s\tremaining: 25.4s\n",
      "2500:\tlearn: 1.6377027\ttotal: 30.3s\tremaining: 25.4s\n",
      "2501:\tlearn: 1.6372957\ttotal: 30.3s\tremaining: 25.4s\n",
      "2502:\tlearn: 1.6369752\ttotal: 30.3s\tremaining: 25.4s\n",
      "2503:\tlearn: 1.6369324\ttotal: 30.3s\tremaining: 25.4s\n",
      "2504:\tlearn: 1.6365939\ttotal: 30.3s\tremaining: 25.4s\n",
      "2505:\tlearn: 1.6361844\ttotal: 30.4s\tremaining: 25.3s\n",
      "2506:\tlearn: 1.6358283\ttotal: 30.4s\tremaining: 25.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2507:\tlearn: 1.6355360\ttotal: 30.4s\tremaining: 25.3s\n",
      "2508:\tlearn: 1.6350152\ttotal: 30.4s\tremaining: 25.3s\n",
      "2509:\tlearn: 1.6348143\ttotal: 30.4s\tremaining: 25.3s\n",
      "2510:\tlearn: 1.6346655\ttotal: 30.4s\tremaining: 25.3s\n",
      "2511:\tlearn: 1.6343882\ttotal: 30.4s\tremaining: 25.3s\n",
      "2512:\tlearn: 1.6341003\ttotal: 30.4s\tremaining: 25.3s\n",
      "2513:\tlearn: 1.6340631\ttotal: 30.5s\tremaining: 25.2s\n",
      "2514:\tlearn: 1.6337674\ttotal: 30.5s\tremaining: 25.2s\n",
      "2515:\tlearn: 1.6333604\ttotal: 30.5s\tremaining: 25.2s\n",
      "2516:\tlearn: 1.6332017\ttotal: 30.5s\tremaining: 25.2s\n",
      "2517:\tlearn: 1.6331414\ttotal: 30.5s\tremaining: 25.2s\n",
      "2518:\tlearn: 1.6328778\ttotal: 30.5s\tremaining: 25.2s\n",
      "2519:\tlearn: 1.6326112\ttotal: 30.5s\tremaining: 25.2s\n",
      "2520:\tlearn: 1.6324229\ttotal: 30.5s\tremaining: 25.2s\n",
      "2521:\tlearn: 1.6321989\ttotal: 30.6s\tremaining: 25.1s\n",
      "2522:\tlearn: 1.6320018\ttotal: 30.6s\tremaining: 25.1s\n",
      "2523:\tlearn: 1.6318061\ttotal: 30.6s\tremaining: 25.1s\n",
      "2524:\tlearn: 1.6314494\ttotal: 30.6s\tremaining: 25.1s\n",
      "2525:\tlearn: 1.6311097\ttotal: 30.6s\tremaining: 25.1s\n",
      "2526:\tlearn: 1.6307644\ttotal: 30.6s\tremaining: 25.1s\n",
      "2527:\tlearn: 1.6304376\ttotal: 30.6s\tremaining: 25.1s\n",
      "2528:\tlearn: 1.6301335\ttotal: 30.6s\tremaining: 25.1s\n",
      "2529:\tlearn: 1.6297591\ttotal: 30.6s\tremaining: 25.1s\n",
      "2530:\tlearn: 1.6295216\ttotal: 30.7s\tremaining: 25s\n",
      "2531:\tlearn: 1.6292888\ttotal: 30.7s\tremaining: 25s\n",
      "2532:\tlearn: 1.6288639\ttotal: 30.7s\tremaining: 25s\n",
      "2533:\tlearn: 1.6286680\ttotal: 30.7s\tremaining: 25s\n",
      "2534:\tlearn: 1.6285228\ttotal: 30.7s\tremaining: 25s\n",
      "2535:\tlearn: 1.6283031\ttotal: 30.7s\tremaining: 25s\n",
      "2536:\tlearn: 1.6281385\ttotal: 30.7s\tremaining: 25s\n",
      "2537:\tlearn: 1.6278446\ttotal: 30.7s\tremaining: 25s\n",
      "2538:\tlearn: 1.6275492\ttotal: 30.8s\tremaining: 24.9s\n",
      "2539:\tlearn: 1.6271973\ttotal: 30.8s\tremaining: 24.9s\n",
      "2540:\tlearn: 1.6268803\ttotal: 30.8s\tremaining: 24.9s\n",
      "2541:\tlearn: 1.6264732\ttotal: 30.8s\tremaining: 24.9s\n",
      "2542:\tlearn: 1.6263457\ttotal: 30.8s\tremaining: 24.9s\n",
      "2543:\tlearn: 1.6259384\ttotal: 30.8s\tremaining: 24.9s\n",
      "2544:\tlearn: 1.6257900\ttotal: 30.8s\tremaining: 24.9s\n",
      "2545:\tlearn: 1.6253418\ttotal: 30.9s\tremaining: 24.9s\n",
      "2546:\tlearn: 1.6250300\ttotal: 30.9s\tremaining: 24.9s\n",
      "2547:\tlearn: 1.6247778\ttotal: 30.9s\tremaining: 24.8s\n",
      "2548:\tlearn: 1.6245653\ttotal: 30.9s\tremaining: 24.8s\n",
      "2549:\tlearn: 1.6243214\ttotal: 30.9s\tremaining: 24.8s\n",
      "2550:\tlearn: 1.6240645\ttotal: 30.9s\tremaining: 24.8s\n",
      "2551:\tlearn: 1.6237272\ttotal: 30.9s\tremaining: 24.8s\n",
      "2552:\tlearn: 1.6232789\ttotal: 30.9s\tremaining: 24.8s\n",
      "2553:\tlearn: 1.6229300\ttotal: 30.9s\tremaining: 24.8s\n",
      "2554:\tlearn: 1.6226778\ttotal: 31s\tremaining: 24.8s\n",
      "2555:\tlearn: 1.6223163\ttotal: 31s\tremaining: 24.7s\n",
      "2556:\tlearn: 1.6221749\ttotal: 31s\tremaining: 24.7s\n",
      "2557:\tlearn: 1.6219210\ttotal: 31s\tremaining: 24.7s\n",
      "2558:\tlearn: 1.6217184\ttotal: 31s\tremaining: 24.7s\n",
      "2559:\tlearn: 1.6214761\ttotal: 31s\tremaining: 24.7s\n",
      "2560:\tlearn: 1.6212249\ttotal: 31s\tremaining: 24.7s\n",
      "2561:\tlearn: 1.6210918\ttotal: 31s\tremaining: 24.7s\n",
      "2562:\tlearn: 1.6207405\ttotal: 31.1s\tremaining: 24.7s\n",
      "2563:\tlearn: 1.6204240\ttotal: 31.1s\tremaining: 24.6s\n",
      "2564:\tlearn: 1.6201374\ttotal: 31.1s\tremaining: 24.6s\n",
      "2565:\tlearn: 1.6198842\ttotal: 31.1s\tremaining: 24.6s\n",
      "2566:\tlearn: 1.6196267\ttotal: 31.1s\tremaining: 24.6s\n",
      "2567:\tlearn: 1.6193091\ttotal: 31.1s\tremaining: 24.6s\n",
      "2568:\tlearn: 1.6189556\ttotal: 31.1s\tremaining: 24.6s\n",
      "2569:\tlearn: 1.6186128\ttotal: 31.1s\tremaining: 24.6s\n",
      "2570:\tlearn: 1.6184913\ttotal: 31.2s\tremaining: 24.6s\n",
      "2571:\tlearn: 1.6184329\ttotal: 31.2s\tremaining: 24.6s\n",
      "2572:\tlearn: 1.6181332\ttotal: 31.2s\tremaining: 24.5s\n",
      "2573:\tlearn: 1.6176897\ttotal: 31.2s\tremaining: 24.5s\n",
      "2574:\tlearn: 1.6174645\ttotal: 31.2s\tremaining: 24.5s\n",
      "2575:\tlearn: 1.6173596\ttotal: 31.2s\tremaining: 24.5s\n",
      "2576:\tlearn: 1.6171709\ttotal: 31.2s\tremaining: 24.5s\n",
      "2577:\tlearn: 1.6169104\ttotal: 31.2s\tremaining: 24.5s\n",
      "2578:\tlearn: 1.6166879\ttotal: 31.3s\tremaining: 24.5s\n",
      "2579:\tlearn: 1.6163873\ttotal: 31.3s\tremaining: 24.5s\n",
      "2580:\tlearn: 1.6162483\ttotal: 31.3s\tremaining: 24.4s\n",
      "2581:\tlearn: 1.6159621\ttotal: 31.3s\tremaining: 24.4s\n",
      "2582:\tlearn: 1.6156894\ttotal: 31.3s\tremaining: 24.4s\n",
      "2583:\tlearn: 1.6156045\ttotal: 31.3s\tremaining: 24.4s\n",
      "2584:\tlearn: 1.6153729\ttotal: 31.3s\tremaining: 24.4s\n",
      "2585:\tlearn: 1.6152570\ttotal: 31.3s\tremaining: 24.4s\n",
      "2586:\tlearn: 1.6150331\ttotal: 31.4s\tremaining: 24.4s\n",
      "2587:\tlearn: 1.6146686\ttotal: 31.4s\tremaining: 24.4s\n",
      "2588:\tlearn: 1.6144812\ttotal: 31.4s\tremaining: 24.3s\n",
      "2589:\tlearn: 1.6142920\ttotal: 31.4s\tremaining: 24.3s\n",
      "2590:\tlearn: 1.6140102\ttotal: 31.4s\tremaining: 24.3s\n",
      "2591:\tlearn: 1.6136563\ttotal: 31.4s\tremaining: 24.3s\n",
      "2592:\tlearn: 1.6132776\ttotal: 31.4s\tremaining: 24.3s\n",
      "2593:\tlearn: 1.6130020\ttotal: 31.4s\tremaining: 24.3s\n",
      "2594:\tlearn: 1.6128763\ttotal: 31.4s\tremaining: 24.3s\n",
      "2595:\tlearn: 1.6125716\ttotal: 31.5s\tremaining: 24.3s\n",
      "2596:\tlearn: 1.6121628\ttotal: 31.5s\tremaining: 24.2s\n",
      "2597:\tlearn: 1.6120814\ttotal: 31.5s\tremaining: 24.2s\n",
      "2598:\tlearn: 1.6118523\ttotal: 31.5s\tremaining: 24.2s\n",
      "2599:\tlearn: 1.6116607\ttotal: 31.5s\tremaining: 24.2s\n",
      "2600:\tlearn: 1.6112345\ttotal: 31.5s\tremaining: 24.2s\n",
      "2601:\tlearn: 1.6108164\ttotal: 31.5s\tremaining: 24.2s\n",
      "2602:\tlearn: 1.6104728\ttotal: 31.5s\tremaining: 24.2s\n",
      "2603:\tlearn: 1.6102085\ttotal: 31.6s\tremaining: 24.2s\n",
      "2604:\tlearn: 1.6097857\ttotal: 31.6s\tremaining: 24.1s\n",
      "2605:\tlearn: 1.6096641\ttotal: 31.6s\tremaining: 24.1s\n",
      "2606:\tlearn: 1.6094897\ttotal: 31.6s\tremaining: 24.1s\n",
      "2607:\tlearn: 1.6091403\ttotal: 31.6s\tremaining: 24.1s\n",
      "2608:\tlearn: 1.6090669\ttotal: 31.6s\tremaining: 24.1s\n",
      "2609:\tlearn: 1.6087216\ttotal: 31.6s\tremaining: 24.1s\n",
      "2610:\tlearn: 1.6086862\ttotal: 31.6s\tremaining: 24.1s\n",
      "2611:\tlearn: 1.6081094\ttotal: 31.6s\tremaining: 24.1s\n",
      "2612:\tlearn: 1.6076582\ttotal: 31.7s\tremaining: 24.1s\n",
      "2613:\tlearn: 1.6074842\ttotal: 31.7s\tremaining: 24s\n",
      "2614:\tlearn: 1.6071905\ttotal: 31.7s\tremaining: 24s\n",
      "2615:\tlearn: 1.6067382\ttotal: 31.7s\tremaining: 24s\n",
      "2616:\tlearn: 1.6065163\ttotal: 31.7s\tremaining: 24s\n",
      "2617:\tlearn: 1.6063358\ttotal: 31.7s\tremaining: 24s\n",
      "2618:\tlearn: 1.6060611\ttotal: 31.7s\tremaining: 24s\n",
      "2619:\tlearn: 1.6055631\ttotal: 31.7s\tremaining: 24s\n",
      "2620:\tlearn: 1.6055141\ttotal: 31.8s\tremaining: 24s\n",
      "2621:\tlearn: 1.6051159\ttotal: 31.8s\tremaining: 23.9s\n",
      "2622:\tlearn: 1.6050748\ttotal: 31.8s\tremaining: 23.9s\n",
      "2623:\tlearn: 1.6045965\ttotal: 31.8s\tremaining: 23.9s\n",
      "2624:\tlearn: 1.6043819\ttotal: 31.8s\tremaining: 23.9s\n",
      "2625:\tlearn: 1.6040819\ttotal: 31.8s\tremaining: 23.9s\n",
      "2626:\tlearn: 1.6037080\ttotal: 31.8s\tremaining: 23.9s\n",
      "2627:\tlearn: 1.6034642\ttotal: 31.8s\tremaining: 23.9s\n",
      "2628:\tlearn: 1.6032248\ttotal: 31.8s\tremaining: 23.9s\n",
      "2629:\tlearn: 1.6030519\ttotal: 31.9s\tremaining: 23.8s\n",
      "2630:\tlearn: 1.6027515\ttotal: 31.9s\tremaining: 23.8s\n",
      "2631:\tlearn: 1.6026206\ttotal: 31.9s\tremaining: 23.8s\n",
      "2632:\tlearn: 1.6023467\ttotal: 31.9s\tremaining: 23.8s\n",
      "2633:\tlearn: 1.6019612\ttotal: 31.9s\tremaining: 23.8s\n",
      "2634:\tlearn: 1.6014797\ttotal: 31.9s\tremaining: 23.8s\n",
      "2635:\tlearn: 1.6010463\ttotal: 31.9s\tremaining: 23.8s\n",
      "2636:\tlearn: 1.6008254\ttotal: 31.9s\tremaining: 23.8s\n",
      "2637:\tlearn: 1.6005806\ttotal: 32s\tremaining: 23.7s\n",
      "2638:\tlearn: 1.6001533\ttotal: 32s\tremaining: 23.7s\n",
      "2639:\tlearn: 1.5998498\ttotal: 32s\tremaining: 23.7s\n",
      "2640:\tlearn: 1.5992320\ttotal: 32s\tremaining: 23.7s\n",
      "2641:\tlearn: 1.5990606\ttotal: 32s\tremaining: 23.7s\n",
      "2642:\tlearn: 1.5985768\ttotal: 32s\tremaining: 23.7s\n",
      "2643:\tlearn: 1.5983285\ttotal: 32s\tremaining: 23.7s\n",
      "2644:\tlearn: 1.5980445\ttotal: 32s\tremaining: 23.7s\n",
      "2645:\tlearn: 1.5979515\ttotal: 32.1s\tremaining: 23.6s\n",
      "2646:\tlearn: 1.5977471\ttotal: 32.1s\tremaining: 23.6s\n",
      "2647:\tlearn: 1.5976265\ttotal: 32.1s\tremaining: 23.6s\n",
      "2648:\tlearn: 1.5971965\ttotal: 32.1s\tremaining: 23.6s\n",
      "2649:\tlearn: 1.5969778\ttotal: 32.1s\tremaining: 23.6s\n",
      "2650:\tlearn: 1.5967870\ttotal: 32.1s\tremaining: 23.6s\n",
      "2651:\tlearn: 1.5965933\ttotal: 32.1s\tremaining: 23.6s\n",
      "2652:\tlearn: 1.5963819\ttotal: 32.1s\tremaining: 23.6s\n",
      "2653:\tlearn: 1.5959196\ttotal: 32.2s\tremaining: 23.6s\n",
      "2654:\tlearn: 1.5956275\ttotal: 32.2s\tremaining: 23.5s\n",
      "2655:\tlearn: 1.5955112\ttotal: 32.2s\tremaining: 23.5s\n",
      "2656:\tlearn: 1.5951389\ttotal: 32.2s\tremaining: 23.5s\n",
      "2657:\tlearn: 1.5949905\ttotal: 32.2s\tremaining: 23.5s\n",
      "2658:\tlearn: 1.5947603\ttotal: 32.2s\tremaining: 23.5s\n",
      "2659:\tlearn: 1.5943700\ttotal: 32.2s\tremaining: 23.5s\n",
      "2660:\tlearn: 1.5939403\ttotal: 32.2s\tremaining: 23.5s\n",
      "2661:\tlearn: 1.5937365\ttotal: 32.3s\tremaining: 23.5s\n",
      "2662:\tlearn: 1.5936975\ttotal: 32.3s\tremaining: 23.4s\n",
      "2663:\tlearn: 1.5932954\ttotal: 32.3s\tremaining: 23.4s\n",
      "2664:\tlearn: 1.5931103\ttotal: 32.3s\tremaining: 23.4s\n",
      "2665:\tlearn: 1.5929641\ttotal: 32.3s\tremaining: 23.4s\n",
      "2666:\tlearn: 1.5927911\ttotal: 32.3s\tremaining: 23.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2667:\tlearn: 1.5924175\ttotal: 32.3s\tremaining: 23.4s\n",
      "2668:\tlearn: 1.5921241\ttotal: 32.3s\tremaining: 23.4s\n",
      "2669:\tlearn: 1.5919434\ttotal: 32.3s\tremaining: 23.4s\n",
      "2670:\tlearn: 1.5914218\ttotal: 32.4s\tremaining: 23.3s\n",
      "2671:\tlearn: 1.5912060\ttotal: 32.4s\tremaining: 23.3s\n",
      "2672:\tlearn: 1.5909828\ttotal: 32.4s\tremaining: 23.3s\n",
      "2673:\tlearn: 1.5906413\ttotal: 32.4s\tremaining: 23.3s\n",
      "2674:\tlearn: 1.5902514\ttotal: 32.4s\tremaining: 23.3s\n",
      "2675:\tlearn: 1.5901129\ttotal: 32.4s\tremaining: 23.3s\n",
      "2676:\tlearn: 1.5899640\ttotal: 32.4s\tremaining: 23.3s\n",
      "2677:\tlearn: 1.5897268\ttotal: 32.4s\tremaining: 23.3s\n",
      "2678:\tlearn: 1.5895728\ttotal: 32.5s\tremaining: 23.2s\n",
      "2679:\tlearn: 1.5893343\ttotal: 32.5s\tremaining: 23.2s\n",
      "2680:\tlearn: 1.5890364\ttotal: 32.5s\tremaining: 23.2s\n",
      "2681:\tlearn: 1.5886950\ttotal: 32.5s\tremaining: 23.2s\n",
      "2682:\tlearn: 1.5882399\ttotal: 32.5s\tremaining: 23.2s\n",
      "2683:\tlearn: 1.5879566\ttotal: 32.5s\tremaining: 23.2s\n",
      "2684:\tlearn: 1.5876794\ttotal: 32.5s\tremaining: 23.2s\n",
      "2685:\tlearn: 1.5874794\ttotal: 32.5s\tremaining: 23.2s\n",
      "2686:\tlearn: 1.5870126\ttotal: 32.6s\tremaining: 23.2s\n",
      "2687:\tlearn: 1.5867228\ttotal: 32.6s\tremaining: 23.1s\n",
      "2688:\tlearn: 1.5864830\ttotal: 32.6s\tremaining: 23.1s\n",
      "2689:\tlearn: 1.5863459\ttotal: 32.6s\tremaining: 23.1s\n",
      "2690:\tlearn: 1.5860219\ttotal: 32.6s\tremaining: 23.1s\n",
      "2691:\tlearn: 1.5857961\ttotal: 32.6s\tremaining: 23.1s\n",
      "2692:\tlearn: 1.5857514\ttotal: 32.6s\tremaining: 23.1s\n",
      "2693:\tlearn: 1.5855346\ttotal: 32.6s\tremaining: 23.1s\n",
      "2694:\tlearn: 1.5852516\ttotal: 32.6s\tremaining: 23.1s\n",
      "2695:\tlearn: 1.5849818\ttotal: 32.7s\tremaining: 23s\n",
      "2696:\tlearn: 1.5847823\ttotal: 32.7s\tremaining: 23s\n",
      "2697:\tlearn: 1.5845002\ttotal: 32.7s\tremaining: 23s\n",
      "2698:\tlearn: 1.5840387\ttotal: 32.7s\tremaining: 23s\n",
      "2699:\tlearn: 1.5836024\ttotal: 32.7s\tremaining: 23s\n",
      "2700:\tlearn: 1.5831894\ttotal: 32.7s\tremaining: 23s\n",
      "2701:\tlearn: 1.5829321\ttotal: 32.7s\tremaining: 23s\n",
      "2702:\tlearn: 1.5824134\ttotal: 32.7s\tremaining: 23s\n",
      "2703:\tlearn: 1.5820086\ttotal: 32.8s\tremaining: 22.9s\n",
      "2704:\tlearn: 1.5817977\ttotal: 32.8s\tremaining: 22.9s\n",
      "2705:\tlearn: 1.5815460\ttotal: 32.8s\tremaining: 22.9s\n",
      "2706:\tlearn: 1.5813369\ttotal: 32.8s\tremaining: 22.9s\n",
      "2707:\tlearn: 1.5804683\ttotal: 32.8s\tremaining: 22.9s\n",
      "2708:\tlearn: 1.5803324\ttotal: 32.8s\tremaining: 22.9s\n",
      "2709:\tlearn: 1.5800286\ttotal: 32.8s\tremaining: 22.9s\n",
      "2710:\tlearn: 1.5797878\ttotal: 32.8s\tremaining: 22.9s\n",
      "2711:\tlearn: 1.5795480\ttotal: 32.9s\tremaining: 22.8s\n",
      "2712:\tlearn: 1.5791032\ttotal: 32.9s\tremaining: 22.8s\n",
      "2713:\tlearn: 1.5788006\ttotal: 32.9s\tremaining: 22.8s\n",
      "2714:\tlearn: 1.5786058\ttotal: 32.9s\tremaining: 22.8s\n",
      "2715:\tlearn: 1.5782914\ttotal: 32.9s\tremaining: 22.8s\n",
      "2716:\tlearn: 1.5780751\ttotal: 32.9s\tremaining: 22.8s\n",
      "2717:\tlearn: 1.5777998\ttotal: 32.9s\tremaining: 22.8s\n",
      "2718:\tlearn: 1.5776297\ttotal: 32.9s\tremaining: 22.8s\n",
      "2719:\tlearn: 1.5774720\ttotal: 32.9s\tremaining: 22.7s\n",
      "2720:\tlearn: 1.5772137\ttotal: 33s\tremaining: 22.7s\n",
      "2721:\tlearn: 1.5769440\ttotal: 33s\tremaining: 22.7s\n",
      "2722:\tlearn: 1.5765759\ttotal: 33s\tremaining: 22.7s\n",
      "2723:\tlearn: 1.5762595\ttotal: 33s\tremaining: 22.7s\n",
      "2724:\tlearn: 1.5760696\ttotal: 33s\tremaining: 22.7s\n",
      "2725:\tlearn: 1.5759780\ttotal: 33s\tremaining: 22.7s\n",
      "2726:\tlearn: 1.5756598\ttotal: 33s\tremaining: 22.7s\n",
      "2727:\tlearn: 1.5752909\ttotal: 33s\tremaining: 22.7s\n",
      "2728:\tlearn: 1.5749852\ttotal: 33.1s\tremaining: 22.6s\n",
      "2729:\tlearn: 1.5747360\ttotal: 33.1s\tremaining: 22.6s\n",
      "2730:\tlearn: 1.5745163\ttotal: 33.1s\tremaining: 22.6s\n",
      "2731:\tlearn: 1.5740989\ttotal: 33.1s\tremaining: 22.6s\n",
      "2732:\tlearn: 1.5739934\ttotal: 33.1s\tremaining: 22.6s\n",
      "2733:\tlearn: 1.5738097\ttotal: 33.1s\tremaining: 22.6s\n",
      "2734:\tlearn: 1.5734478\ttotal: 33.1s\tremaining: 22.6s\n",
      "2735:\tlearn: 1.5731733\ttotal: 33.1s\tremaining: 22.6s\n",
      "2736:\tlearn: 1.5727341\ttotal: 33.2s\tremaining: 22.5s\n",
      "2737:\tlearn: 1.5724474\ttotal: 33.2s\tremaining: 22.5s\n",
      "2738:\tlearn: 1.5721103\ttotal: 33.2s\tremaining: 22.5s\n",
      "2739:\tlearn: 1.5717989\ttotal: 33.2s\tremaining: 22.5s\n",
      "2740:\tlearn: 1.5713614\ttotal: 33.2s\tremaining: 22.5s\n",
      "2741:\tlearn: 1.5711045\ttotal: 33.2s\tremaining: 22.5s\n",
      "2742:\tlearn: 1.5708448\ttotal: 33.2s\tremaining: 22.5s\n",
      "2743:\tlearn: 1.5703536\ttotal: 33.2s\tremaining: 22.5s\n",
      "2744:\tlearn: 1.5700867\ttotal: 33.3s\tremaining: 22.4s\n",
      "2745:\tlearn: 1.5699198\ttotal: 33.3s\tremaining: 22.4s\n",
      "2746:\tlearn: 1.5696344\ttotal: 33.3s\tremaining: 22.4s\n",
      "2747:\tlearn: 1.5694327\ttotal: 33.3s\tremaining: 22.4s\n",
      "2748:\tlearn: 1.5693456\ttotal: 33.3s\tremaining: 22.4s\n",
      "2749:\tlearn: 1.5691849\ttotal: 33.3s\tremaining: 22.4s\n",
      "2750:\tlearn: 1.5689835\ttotal: 33.3s\tremaining: 22.4s\n",
      "2751:\tlearn: 1.5687310\ttotal: 33.3s\tremaining: 22.4s\n",
      "2752:\tlearn: 1.5685111\ttotal: 33.3s\tremaining: 22.3s\n",
      "2753:\tlearn: 1.5682164\ttotal: 33.4s\tremaining: 22.3s\n",
      "2754:\tlearn: 1.5677555\ttotal: 33.4s\tremaining: 22.3s\n",
      "2755:\tlearn: 1.5674211\ttotal: 33.4s\tremaining: 22.3s\n",
      "2756:\tlearn: 1.5672487\ttotal: 33.4s\tremaining: 22.3s\n",
      "2757:\tlearn: 1.5669801\ttotal: 33.4s\tremaining: 22.3s\n",
      "2758:\tlearn: 1.5667324\ttotal: 33.4s\tremaining: 22.3s\n",
      "2759:\tlearn: 1.5663302\ttotal: 33.5s\tremaining: 22.3s\n",
      "2760:\tlearn: 1.5659535\ttotal: 33.5s\tremaining: 22.3s\n",
      "2761:\tlearn: 1.5657537\ttotal: 33.5s\tremaining: 22.3s\n",
      "2762:\tlearn: 1.5654126\ttotal: 33.5s\tremaining: 22.2s\n",
      "2763:\tlearn: 1.5652083\ttotal: 33.5s\tremaining: 22.2s\n",
      "2764:\tlearn: 1.5648680\ttotal: 33.5s\tremaining: 22.2s\n",
      "2765:\tlearn: 1.5645914\ttotal: 33.5s\tremaining: 22.2s\n",
      "2766:\tlearn: 1.5645254\ttotal: 33.5s\tremaining: 22.2s\n",
      "2767:\tlearn: 1.5642587\ttotal: 33.6s\tremaining: 22.2s\n",
      "2768:\tlearn: 1.5641721\ttotal: 33.6s\tremaining: 22.2s\n",
      "2769:\tlearn: 1.5638786\ttotal: 33.6s\tremaining: 22.2s\n",
      "2770:\tlearn: 1.5635988\ttotal: 33.6s\tremaining: 22.1s\n",
      "2771:\tlearn: 1.5631255\ttotal: 33.6s\tremaining: 22.1s\n",
      "2772:\tlearn: 1.5627136\ttotal: 33.6s\tremaining: 22.1s\n",
      "2773:\tlearn: 1.5625405\ttotal: 33.6s\tremaining: 22.1s\n",
      "2774:\tlearn: 1.5621278\ttotal: 33.6s\tremaining: 22.1s\n",
      "2775:\tlearn: 1.5618865\ttotal: 33.7s\tremaining: 22.1s\n",
      "2776:\tlearn: 1.5617627\ttotal: 33.7s\tremaining: 22.1s\n",
      "2777:\tlearn: 1.5615270\ttotal: 33.7s\tremaining: 22.1s\n",
      "2778:\tlearn: 1.5613685\ttotal: 33.7s\tremaining: 22.1s\n",
      "2779:\tlearn: 1.5611422\ttotal: 33.7s\tremaining: 22s\n",
      "2780:\tlearn: 1.5608618\ttotal: 33.7s\tremaining: 22s\n",
      "2781:\tlearn: 1.5604485\ttotal: 33.7s\tremaining: 22s\n",
      "2782:\tlearn: 1.5601433\ttotal: 33.7s\tremaining: 22s\n",
      "2783:\tlearn: 1.5599259\ttotal: 33.7s\tremaining: 22s\n",
      "2784:\tlearn: 1.5595226\ttotal: 33.8s\tremaining: 22s\n",
      "2785:\tlearn: 1.5593504\ttotal: 33.8s\tremaining: 22s\n",
      "2786:\tlearn: 1.5590938\ttotal: 33.8s\tremaining: 22s\n",
      "2787:\tlearn: 1.5586166\ttotal: 33.8s\tremaining: 21.9s\n",
      "2788:\tlearn: 1.5582294\ttotal: 33.8s\tremaining: 21.9s\n",
      "2789:\tlearn: 1.5579863\ttotal: 33.8s\tremaining: 21.9s\n",
      "2790:\tlearn: 1.5577942\ttotal: 33.8s\tremaining: 21.9s\n",
      "2791:\tlearn: 1.5575024\ttotal: 33.8s\tremaining: 21.9s\n",
      "2792:\tlearn: 1.5572272\ttotal: 33.9s\tremaining: 21.9s\n",
      "2793:\tlearn: 1.5569623\ttotal: 33.9s\tremaining: 21.9s\n",
      "2794:\tlearn: 1.5567648\ttotal: 33.9s\tremaining: 21.9s\n",
      "2795:\tlearn: 1.5565355\ttotal: 33.9s\tremaining: 21.8s\n",
      "2796:\tlearn: 1.5562795\ttotal: 33.9s\tremaining: 21.8s\n",
      "2797:\tlearn: 1.5561386\ttotal: 33.9s\tremaining: 21.8s\n",
      "2798:\tlearn: 1.5558277\ttotal: 33.9s\tremaining: 21.8s\n",
      "2799:\tlearn: 1.5554694\ttotal: 33.9s\tremaining: 21.8s\n",
      "2800:\tlearn: 1.5551815\ttotal: 34s\tremaining: 21.8s\n",
      "2801:\tlearn: 1.5549252\ttotal: 34s\tremaining: 21.8s\n",
      "2802:\tlearn: 1.5545898\ttotal: 34s\tremaining: 21.8s\n",
      "2803:\tlearn: 1.5542622\ttotal: 34s\tremaining: 21.7s\n",
      "2804:\tlearn: 1.5540815\ttotal: 34s\tremaining: 21.7s\n",
      "2805:\tlearn: 1.5538299\ttotal: 34s\tremaining: 21.7s\n",
      "2806:\tlearn: 1.5536852\ttotal: 34s\tremaining: 21.7s\n",
      "2807:\tlearn: 1.5532053\ttotal: 34s\tremaining: 21.7s\n",
      "2808:\tlearn: 1.5530148\ttotal: 34.1s\tremaining: 21.7s\n",
      "2809:\tlearn: 1.5529302\ttotal: 34.1s\tremaining: 21.7s\n",
      "2810:\tlearn: 1.5527793\ttotal: 34.1s\tremaining: 21.7s\n",
      "2811:\tlearn: 1.5525491\ttotal: 34.1s\tremaining: 21.7s\n",
      "2812:\tlearn: 1.5519348\ttotal: 34.1s\tremaining: 21.6s\n",
      "2813:\tlearn: 1.5515978\ttotal: 34.1s\tremaining: 21.6s\n",
      "2814:\tlearn: 1.5514296\ttotal: 34.1s\tremaining: 21.6s\n",
      "2815:\tlearn: 1.5511345\ttotal: 34.1s\tremaining: 21.6s\n",
      "2816:\tlearn: 1.5507969\ttotal: 34.2s\tremaining: 21.6s\n",
      "2817:\tlearn: 1.5506498\ttotal: 34.2s\tremaining: 21.6s\n",
      "2818:\tlearn: 1.5502801\ttotal: 34.2s\tremaining: 21.6s\n",
      "2819:\tlearn: 1.5500821\ttotal: 34.2s\tremaining: 21.6s\n",
      "2820:\tlearn: 1.5497972\ttotal: 34.2s\tremaining: 21.5s\n",
      "2821:\tlearn: 1.5496830\ttotal: 34.2s\tremaining: 21.5s\n",
      "2822:\tlearn: 1.5494736\ttotal: 34.2s\tremaining: 21.5s\n",
      "2823:\tlearn: 1.5493377\ttotal: 34.2s\tremaining: 21.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2824:\tlearn: 1.5489979\ttotal: 34.3s\tremaining: 21.5s\n",
      "2825:\tlearn: 1.5488642\ttotal: 34.3s\tremaining: 21.5s\n",
      "2826:\tlearn: 1.5486465\ttotal: 34.3s\tremaining: 21.5s\n",
      "2827:\tlearn: 1.5485187\ttotal: 34.3s\tremaining: 21.5s\n",
      "2828:\tlearn: 1.5483363\ttotal: 34.3s\tremaining: 21.5s\n",
      "2829:\tlearn: 1.5479120\ttotal: 34.3s\tremaining: 21.4s\n",
      "2830:\tlearn: 1.5475954\ttotal: 34.3s\tremaining: 21.4s\n",
      "2831:\tlearn: 1.5475469\ttotal: 34.3s\tremaining: 21.4s\n",
      "2832:\tlearn: 1.5473204\ttotal: 34.4s\tremaining: 21.4s\n",
      "2833:\tlearn: 1.5470700\ttotal: 34.4s\tremaining: 21.4s\n",
      "2834:\tlearn: 1.5469340\ttotal: 34.4s\tremaining: 21.4s\n",
      "2835:\tlearn: 1.5467630\ttotal: 34.4s\tremaining: 21.4s\n",
      "2836:\tlearn: 1.5464120\ttotal: 34.4s\tremaining: 21.4s\n",
      "2837:\tlearn: 1.5461451\ttotal: 34.4s\tremaining: 21.3s\n",
      "2838:\tlearn: 1.5460343\ttotal: 34.4s\tremaining: 21.3s\n",
      "2839:\tlearn: 1.5457978\ttotal: 34.4s\tremaining: 21.3s\n",
      "2840:\tlearn: 1.5456147\ttotal: 34.5s\tremaining: 21.3s\n",
      "2841:\tlearn: 1.5453789\ttotal: 34.5s\tremaining: 21.3s\n",
      "2842:\tlearn: 1.5450980\ttotal: 34.5s\tremaining: 21.3s\n",
      "2843:\tlearn: 1.5447352\ttotal: 34.5s\tremaining: 21.3s\n",
      "2844:\tlearn: 1.5442872\ttotal: 34.5s\tremaining: 21.3s\n",
      "2845:\tlearn: 1.5441624\ttotal: 34.5s\tremaining: 21.3s\n",
      "2846:\tlearn: 1.5439825\ttotal: 34.5s\tremaining: 21.2s\n",
      "2847:\tlearn: 1.5436589\ttotal: 34.5s\tremaining: 21.2s\n",
      "2848:\tlearn: 1.5432493\ttotal: 34.6s\tremaining: 21.2s\n",
      "2849:\tlearn: 1.5430076\ttotal: 34.6s\tremaining: 21.2s\n",
      "2850:\tlearn: 1.5427409\ttotal: 34.6s\tremaining: 21.2s\n",
      "2851:\tlearn: 1.5425353\ttotal: 34.6s\tremaining: 21.2s\n",
      "2852:\tlearn: 1.5423522\ttotal: 34.6s\tremaining: 21.2s\n",
      "2853:\tlearn: 1.5419933\ttotal: 34.6s\tremaining: 21.2s\n",
      "2854:\tlearn: 1.5417901\ttotal: 34.6s\tremaining: 21.1s\n",
      "2855:\tlearn: 1.5414365\ttotal: 34.6s\tremaining: 21.1s\n",
      "2856:\tlearn: 1.5411647\ttotal: 34.7s\tremaining: 21.1s\n",
      "2857:\tlearn: 1.5408917\ttotal: 34.7s\tremaining: 21.1s\n",
      "2858:\tlearn: 1.5406096\ttotal: 34.7s\tremaining: 21.1s\n",
      "2859:\tlearn: 1.5401340\ttotal: 34.7s\tremaining: 21.1s\n",
      "2860:\tlearn: 1.5398709\ttotal: 34.7s\tremaining: 21.1s\n",
      "2861:\tlearn: 1.5395761\ttotal: 34.7s\tremaining: 21.1s\n",
      "2862:\tlearn: 1.5393196\ttotal: 34.7s\tremaining: 21s\n",
      "2863:\tlearn: 1.5389422\ttotal: 34.7s\tremaining: 21s\n",
      "2864:\tlearn: 1.5386438\ttotal: 34.8s\tremaining: 21s\n",
      "2865:\tlearn: 1.5384096\ttotal: 34.8s\tremaining: 21s\n",
      "2866:\tlearn: 1.5382297\ttotal: 34.8s\tremaining: 21s\n",
      "2867:\tlearn: 1.5377391\ttotal: 34.8s\tremaining: 21s\n",
      "2868:\tlearn: 1.5372191\ttotal: 34.8s\tremaining: 21s\n",
      "2869:\tlearn: 1.5368589\ttotal: 34.8s\tremaining: 21s\n",
      "2870:\tlearn: 1.5367122\ttotal: 34.8s\tremaining: 20.9s\n",
      "2871:\tlearn: 1.5364109\ttotal: 34.8s\tremaining: 20.9s\n",
      "2872:\tlearn: 1.5362112\ttotal: 34.9s\tremaining: 20.9s\n",
      "2873:\tlearn: 1.5360066\ttotal: 34.9s\tremaining: 20.9s\n",
      "2874:\tlearn: 1.5357260\ttotal: 34.9s\tremaining: 20.9s\n",
      "2875:\tlearn: 1.5356586\ttotal: 34.9s\tremaining: 20.9s\n",
      "2876:\tlearn: 1.5354314\ttotal: 34.9s\tremaining: 20.9s\n",
      "2877:\tlearn: 1.5352096\ttotal: 34.9s\tremaining: 20.9s\n",
      "2878:\tlearn: 1.5348685\ttotal: 34.9s\tremaining: 20.9s\n",
      "2879:\tlearn: 1.5344420\ttotal: 34.9s\tremaining: 20.8s\n",
      "2880:\tlearn: 1.5342518\ttotal: 34.9s\tremaining: 20.8s\n",
      "2881:\tlearn: 1.5340593\ttotal: 35s\tremaining: 20.8s\n",
      "2882:\tlearn: 1.5337271\ttotal: 35s\tremaining: 20.8s\n",
      "2883:\tlearn: 1.5333223\ttotal: 35s\tremaining: 20.8s\n",
      "2884:\tlearn: 1.5330545\ttotal: 35s\tremaining: 20.8s\n",
      "2885:\tlearn: 1.5326682\ttotal: 35s\tremaining: 20.8s\n",
      "2886:\tlearn: 1.5324313\ttotal: 35s\tremaining: 20.8s\n",
      "2887:\tlearn: 1.5320829\ttotal: 35s\tremaining: 20.7s\n",
      "2888:\tlearn: 1.5318883\ttotal: 35s\tremaining: 20.7s\n",
      "2889:\tlearn: 1.5317343\ttotal: 35.1s\tremaining: 20.7s\n",
      "2890:\tlearn: 1.5313649\ttotal: 35.1s\tremaining: 20.7s\n",
      "2891:\tlearn: 1.5310973\ttotal: 35.1s\tremaining: 20.7s\n",
      "2892:\tlearn: 1.5308858\ttotal: 35.1s\tremaining: 20.7s\n",
      "2893:\tlearn: 1.5305898\ttotal: 35.1s\tremaining: 20.7s\n",
      "2894:\tlearn: 1.5304367\ttotal: 35.1s\tremaining: 20.7s\n",
      "2895:\tlearn: 1.5302812\ttotal: 35.1s\tremaining: 20.6s\n",
      "2896:\tlearn: 1.5299968\ttotal: 35.1s\tremaining: 20.6s\n",
      "2897:\tlearn: 1.5297226\ttotal: 35.2s\tremaining: 20.6s\n",
      "2898:\tlearn: 1.5295206\ttotal: 35.2s\tremaining: 20.6s\n",
      "2899:\tlearn: 1.5293490\ttotal: 35.2s\tremaining: 20.6s\n",
      "2900:\tlearn: 1.5290253\ttotal: 35.2s\tremaining: 20.6s\n",
      "2901:\tlearn: 1.5287059\ttotal: 35.2s\tremaining: 20.6s\n",
      "2902:\tlearn: 1.5283349\ttotal: 35.2s\tremaining: 20.6s\n",
      "2903:\tlearn: 1.5281722\ttotal: 35.2s\tremaining: 20.5s\n",
      "2904:\tlearn: 1.5279911\ttotal: 35.2s\tremaining: 20.5s\n",
      "2905:\tlearn: 1.5275886\ttotal: 35.2s\tremaining: 20.5s\n",
      "2906:\tlearn: 1.5273258\ttotal: 35.3s\tremaining: 20.5s\n",
      "2907:\tlearn: 1.5269998\ttotal: 35.3s\tremaining: 20.5s\n",
      "2908:\tlearn: 1.5268850\ttotal: 35.3s\tremaining: 20.5s\n",
      "2909:\tlearn: 1.5266232\ttotal: 35.3s\tremaining: 20.5s\n",
      "2910:\tlearn: 1.5264205\ttotal: 35.3s\tremaining: 20.5s\n",
      "2911:\tlearn: 1.5261728\ttotal: 35.3s\tremaining: 20.4s\n",
      "2912:\tlearn: 1.5258314\ttotal: 35.3s\tremaining: 20.4s\n",
      "2913:\tlearn: 1.5255497\ttotal: 35.3s\tremaining: 20.4s\n",
      "2914:\tlearn: 1.5252319\ttotal: 35.4s\tremaining: 20.4s\n",
      "2915:\tlearn: 1.5249904\ttotal: 35.4s\tremaining: 20.4s\n",
      "2916:\tlearn: 1.5247135\ttotal: 35.4s\tremaining: 20.4s\n",
      "2917:\tlearn: 1.5242616\ttotal: 35.4s\tremaining: 20.4s\n",
      "2918:\tlearn: 1.5240544\ttotal: 35.4s\tremaining: 20.4s\n",
      "2919:\tlearn: 1.5237854\ttotal: 35.4s\tremaining: 20.4s\n",
      "2920:\tlearn: 1.5235718\ttotal: 35.4s\tremaining: 20.3s\n",
      "2921:\tlearn: 1.5232853\ttotal: 35.4s\tremaining: 20.3s\n",
      "2922:\tlearn: 1.5229355\ttotal: 35.5s\tremaining: 20.3s\n",
      "2923:\tlearn: 1.5227886\ttotal: 35.5s\tremaining: 20.3s\n",
      "2924:\tlearn: 1.5225838\ttotal: 35.5s\tremaining: 20.3s\n",
      "2925:\tlearn: 1.5222615\ttotal: 35.5s\tremaining: 20.3s\n",
      "2926:\tlearn: 1.5221074\ttotal: 35.5s\tremaining: 20.3s\n",
      "2927:\tlearn: 1.5218439\ttotal: 35.5s\tremaining: 20.3s\n",
      "2928:\tlearn: 1.5213804\ttotal: 35.5s\tremaining: 20.2s\n",
      "2929:\tlearn: 1.5211965\ttotal: 35.5s\tremaining: 20.2s\n",
      "2930:\tlearn: 1.5209804\ttotal: 35.6s\tremaining: 20.2s\n",
      "2931:\tlearn: 1.5207418\ttotal: 35.6s\tremaining: 20.2s\n",
      "2932:\tlearn: 1.5203563\ttotal: 35.6s\tremaining: 20.2s\n",
      "2933:\tlearn: 1.5200534\ttotal: 35.6s\tremaining: 20.2s\n",
      "2934:\tlearn: 1.5198566\ttotal: 35.6s\tremaining: 20.2s\n",
      "2935:\tlearn: 1.5195732\ttotal: 35.6s\tremaining: 20.2s\n",
      "2936:\tlearn: 1.5193559\ttotal: 35.6s\tremaining: 20.1s\n",
      "2937:\tlearn: 1.5190035\ttotal: 35.6s\tremaining: 20.1s\n",
      "2938:\tlearn: 1.5187078\ttotal: 35.7s\tremaining: 20.1s\n",
      "2939:\tlearn: 1.5184605\ttotal: 35.7s\tremaining: 20.1s\n",
      "2940:\tlearn: 1.5182790\ttotal: 35.7s\tremaining: 20.1s\n",
      "2941:\tlearn: 1.5178366\ttotal: 35.7s\tremaining: 20.1s\n",
      "2942:\tlearn: 1.5175313\ttotal: 35.7s\tremaining: 20.1s\n",
      "2943:\tlearn: 1.5173862\ttotal: 35.7s\tremaining: 20.1s\n",
      "2944:\tlearn: 1.5171076\ttotal: 35.7s\tremaining: 20.1s\n",
      "2945:\tlearn: 1.5168278\ttotal: 35.7s\tremaining: 20s\n",
      "2946:\tlearn: 1.5166310\ttotal: 35.8s\tremaining: 20s\n",
      "2947:\tlearn: 1.5165143\ttotal: 35.8s\tremaining: 20s\n",
      "2948:\tlearn: 1.5163396\ttotal: 35.8s\tremaining: 20s\n",
      "2949:\tlearn: 1.5161656\ttotal: 35.8s\tremaining: 20s\n",
      "2950:\tlearn: 1.5158902\ttotal: 35.8s\tremaining: 20s\n",
      "2951:\tlearn: 1.5153857\ttotal: 35.8s\tremaining: 20s\n",
      "2952:\tlearn: 1.5151562\ttotal: 35.8s\tremaining: 20s\n",
      "2953:\tlearn: 1.5149837\ttotal: 35.8s\tremaining: 19.9s\n",
      "2954:\tlearn: 1.5148055\ttotal: 35.8s\tremaining: 19.9s\n",
      "2955:\tlearn: 1.5145271\ttotal: 35.9s\tremaining: 19.9s\n",
      "2956:\tlearn: 1.5144326\ttotal: 35.9s\tremaining: 19.9s\n",
      "2957:\tlearn: 1.5143546\ttotal: 35.9s\tremaining: 19.9s\n",
      "2958:\tlearn: 1.5141999\ttotal: 35.9s\tremaining: 19.9s\n",
      "2959:\tlearn: 1.5138609\ttotal: 35.9s\tremaining: 19.9s\n",
      "2960:\tlearn: 1.5136538\ttotal: 35.9s\tremaining: 19.9s\n",
      "2961:\tlearn: 1.5134348\ttotal: 35.9s\tremaining: 19.8s\n",
      "2962:\tlearn: 1.5131122\ttotal: 35.9s\tremaining: 19.8s\n",
      "2963:\tlearn: 1.5127756\ttotal: 36s\tremaining: 19.8s\n",
      "2964:\tlearn: 1.5126470\ttotal: 36s\tremaining: 19.8s\n",
      "2965:\tlearn: 1.5123378\ttotal: 36s\tremaining: 19.8s\n",
      "2966:\tlearn: 1.5120111\ttotal: 36s\tremaining: 19.8s\n",
      "2967:\tlearn: 1.5116727\ttotal: 36s\tremaining: 19.8s\n",
      "2968:\tlearn: 1.5114812\ttotal: 36s\tremaining: 19.8s\n",
      "2969:\tlearn: 1.5113488\ttotal: 36s\tremaining: 19.8s\n",
      "2970:\tlearn: 1.5111105\ttotal: 36s\tremaining: 19.7s\n",
      "2971:\tlearn: 1.5109652\ttotal: 36.1s\tremaining: 19.7s\n",
      "2972:\tlearn: 1.5108325\ttotal: 36.1s\tremaining: 19.7s\n",
      "2973:\tlearn: 1.5104606\ttotal: 36.1s\tremaining: 19.7s\n",
      "2974:\tlearn: 1.5100960\ttotal: 36.1s\tremaining: 19.7s\n",
      "2975:\tlearn: 1.5098965\ttotal: 36.1s\tremaining: 19.7s\n",
      "2976:\tlearn: 1.5094155\ttotal: 36.1s\tremaining: 19.7s\n",
      "2977:\tlearn: 1.5090117\ttotal: 36.1s\tremaining: 19.7s\n",
      "2978:\tlearn: 1.5085815\ttotal: 36.1s\tremaining: 19.6s\n",
      "2979:\tlearn: 1.5084090\ttotal: 36.2s\tremaining: 19.6s\n",
      "2980:\tlearn: 1.5081561\ttotal: 36.2s\tremaining: 19.6s\n",
      "2981:\tlearn: 1.5080160\ttotal: 36.2s\tremaining: 19.6s\n",
      "2982:\tlearn: 1.5079166\ttotal: 36.2s\tremaining: 19.6s\n",
      "2983:\tlearn: 1.5078707\ttotal: 36.2s\tremaining: 19.6s\n",
      "2984:\tlearn: 1.5076905\ttotal: 36.2s\tremaining: 19.6s\n",
      "2985:\tlearn: 1.5074710\ttotal: 36.2s\tremaining: 19.6s\n",
      "2986:\tlearn: 1.5072187\ttotal: 36.2s\tremaining: 19.5s\n",
      "2987:\tlearn: 1.5070533\ttotal: 36.3s\tremaining: 19.5s\n",
      "2988:\tlearn: 1.5069913\ttotal: 36.3s\tremaining: 19.5s\n",
      "2989:\tlearn: 1.5067633\ttotal: 36.3s\tremaining: 19.5s\n",
      "2990:\tlearn: 1.5064331\ttotal: 36.3s\tremaining: 19.5s\n",
      "2991:\tlearn: 1.5063295\ttotal: 36.3s\tremaining: 19.5s\n",
      "2992:\tlearn: 1.5060954\ttotal: 36.3s\tremaining: 19.5s\n",
      "2993:\tlearn: 1.5059290\ttotal: 36.3s\tremaining: 19.5s\n",
      "2994:\tlearn: 1.5057636\ttotal: 36.4s\tremaining: 19.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2995:\tlearn: 1.5055693\ttotal: 36.4s\tremaining: 19.4s\n",
      "2996:\tlearn: 1.5053275\ttotal: 36.4s\tremaining: 19.4s\n",
      "2997:\tlearn: 1.5049897\ttotal: 36.4s\tremaining: 19.4s\n",
      "2998:\tlearn: 1.5047914\ttotal: 36.4s\tremaining: 19.4s\n",
      "2999:\tlearn: 1.5045408\ttotal: 36.4s\tremaining: 19.4s\n",
      "3000:\tlearn: 1.5043406\ttotal: 36.4s\tremaining: 19.4s\n",
      "3001:\tlearn: 1.5041625\ttotal: 36.5s\tremaining: 19.4s\n",
      "3002:\tlearn: 1.5040096\ttotal: 36.5s\tremaining: 19.4s\n",
      "3003:\tlearn: 1.5038512\ttotal: 36.5s\tremaining: 19.4s\n",
      "3004:\tlearn: 1.5035354\ttotal: 36.5s\tremaining: 19.4s\n",
      "3005:\tlearn: 1.5033454\ttotal: 36.5s\tremaining: 19.3s\n",
      "3006:\tlearn: 1.5030778\ttotal: 36.5s\tremaining: 19.3s\n",
      "3007:\tlearn: 1.5028178\ttotal: 36.5s\tremaining: 19.3s\n",
      "3008:\tlearn: 1.5025345\ttotal: 36.6s\tremaining: 19.3s\n",
      "3009:\tlearn: 1.5024058\ttotal: 36.6s\tremaining: 19.3s\n",
      "3010:\tlearn: 1.5021118\ttotal: 36.6s\tremaining: 19.3s\n",
      "3011:\tlearn: 1.5018104\ttotal: 36.6s\tremaining: 19.3s\n",
      "3012:\tlearn: 1.5013230\ttotal: 36.6s\tremaining: 19.3s\n",
      "3013:\tlearn: 1.5008512\ttotal: 36.6s\tremaining: 19.2s\n",
      "3014:\tlearn: 1.5003650\ttotal: 36.6s\tremaining: 19.2s\n",
      "3015:\tlearn: 1.5002431\ttotal: 36.6s\tremaining: 19.2s\n",
      "3016:\tlearn: 1.5000650\ttotal: 36.7s\tremaining: 19.2s\n",
      "3017:\tlearn: 1.4998337\ttotal: 36.7s\tremaining: 19.2s\n",
      "3018:\tlearn: 1.4996481\ttotal: 36.7s\tremaining: 19.2s\n",
      "3019:\tlearn: 1.4994169\ttotal: 36.7s\tremaining: 19.2s\n",
      "3020:\tlearn: 1.4991700\ttotal: 36.7s\tremaining: 19.2s\n",
      "3021:\tlearn: 1.4989865\ttotal: 36.7s\tremaining: 19.1s\n",
      "3022:\tlearn: 1.4988430\ttotal: 36.7s\tremaining: 19.1s\n",
      "3023:\tlearn: 1.4987587\ttotal: 36.7s\tremaining: 19.1s\n",
      "3024:\tlearn: 1.4984962\ttotal: 36.7s\tremaining: 19.1s\n",
      "3025:\tlearn: 1.4983552\ttotal: 36.8s\tremaining: 19.1s\n",
      "3026:\tlearn: 1.4982858\ttotal: 36.8s\tremaining: 19.1s\n",
      "3027:\tlearn: 1.4980414\ttotal: 36.8s\tremaining: 19.1s\n",
      "3028:\tlearn: 1.4977654\ttotal: 36.8s\tremaining: 19.1s\n",
      "3029:\tlearn: 1.4975414\ttotal: 36.8s\tremaining: 19s\n",
      "3030:\tlearn: 1.4974743\ttotal: 36.8s\tremaining: 19s\n",
      "3031:\tlearn: 1.4972440\ttotal: 36.8s\tremaining: 19s\n",
      "3032:\tlearn: 1.4968870\ttotal: 36.8s\tremaining: 19s\n",
      "3033:\tlearn: 1.4964538\ttotal: 36.9s\tremaining: 19s\n",
      "3034:\tlearn: 1.4963914\ttotal: 36.9s\tremaining: 19s\n",
      "3035:\tlearn: 1.4961533\ttotal: 36.9s\tremaining: 19s\n",
      "3036:\tlearn: 1.4959315\ttotal: 36.9s\tremaining: 19s\n",
      "3037:\tlearn: 1.4957822\ttotal: 36.9s\tremaining: 18.9s\n",
      "3038:\tlearn: 1.4956866\ttotal: 36.9s\tremaining: 18.9s\n",
      "3039:\tlearn: 1.4955517\ttotal: 36.9s\tremaining: 18.9s\n",
      "3040:\tlearn: 1.4953034\ttotal: 36.9s\tremaining: 18.9s\n",
      "3041:\tlearn: 1.4950279\ttotal: 37s\tremaining: 18.9s\n",
      "3042:\tlearn: 1.4948289\ttotal: 37s\tremaining: 18.9s\n",
      "3043:\tlearn: 1.4946739\ttotal: 37s\tremaining: 18.9s\n",
      "3044:\tlearn: 1.4944166\ttotal: 37s\tremaining: 18.9s\n",
      "3045:\tlearn: 1.4941709\ttotal: 37s\tremaining: 18.9s\n",
      "3046:\tlearn: 1.4940645\ttotal: 37s\tremaining: 18.8s\n",
      "3047:\tlearn: 1.4939077\ttotal: 37s\tremaining: 18.8s\n",
      "3048:\tlearn: 1.4937518\ttotal: 37s\tremaining: 18.8s\n",
      "3049:\tlearn: 1.4934336\ttotal: 37s\tremaining: 18.8s\n",
      "3050:\tlearn: 1.4933378\ttotal: 37.1s\tremaining: 18.8s\n",
      "3051:\tlearn: 1.4927985\ttotal: 37.1s\tremaining: 18.8s\n",
      "3052:\tlearn: 1.4924931\ttotal: 37.1s\tremaining: 18.8s\n",
      "3053:\tlearn: 1.4923666\ttotal: 37.1s\tremaining: 18.8s\n",
      "3054:\tlearn: 1.4921621\ttotal: 37.1s\tremaining: 18.7s\n",
      "3055:\tlearn: 1.4919307\ttotal: 37.1s\tremaining: 18.7s\n",
      "3056:\tlearn: 1.4917390\ttotal: 37.1s\tremaining: 18.7s\n",
      "3057:\tlearn: 1.4915124\ttotal: 37.1s\tremaining: 18.7s\n",
      "3058:\tlearn: 1.4909754\ttotal: 37.2s\tremaining: 18.7s\n",
      "3059:\tlearn: 1.4907906\ttotal: 37.2s\tremaining: 18.7s\n",
      "3060:\tlearn: 1.4905262\ttotal: 37.2s\tremaining: 18.7s\n",
      "3061:\tlearn: 1.4902291\ttotal: 37.2s\tremaining: 18.7s\n",
      "3062:\tlearn: 1.4899952\ttotal: 37.2s\tremaining: 18.6s\n",
      "3063:\tlearn: 1.4898911\ttotal: 37.2s\tremaining: 18.6s\n",
      "3064:\tlearn: 1.4897287\ttotal: 37.2s\tremaining: 18.6s\n",
      "3065:\tlearn: 1.4895958\ttotal: 37.2s\tremaining: 18.6s\n",
      "3066:\tlearn: 1.4894691\ttotal: 37.2s\tremaining: 18.6s\n",
      "3067:\tlearn: 1.4891884\ttotal: 37.3s\tremaining: 18.6s\n",
      "3068:\tlearn: 1.4890003\ttotal: 37.3s\tremaining: 18.6s\n",
      "3069:\tlearn: 1.4887806\ttotal: 37.3s\tremaining: 18.6s\n",
      "3070:\tlearn: 1.4885039\ttotal: 37.3s\tremaining: 18.5s\n",
      "3071:\tlearn: 1.4882579\ttotal: 37.3s\tremaining: 18.5s\n",
      "3072:\tlearn: 1.4880206\ttotal: 37.3s\tremaining: 18.5s\n",
      "3073:\tlearn: 1.4878953\ttotal: 37.3s\tremaining: 18.5s\n",
      "3074:\tlearn: 1.4876459\ttotal: 37.3s\tremaining: 18.5s\n",
      "3075:\tlearn: 1.4873690\ttotal: 37.4s\tremaining: 18.5s\n",
      "3076:\tlearn: 1.4872057\ttotal: 37.4s\tremaining: 18.5s\n",
      "3077:\tlearn: 1.4870853\ttotal: 37.4s\tremaining: 18.5s\n",
      "3078:\tlearn: 1.4869245\ttotal: 37.4s\tremaining: 18.4s\n",
      "3079:\tlearn: 1.4866587\ttotal: 37.4s\tremaining: 18.4s\n",
      "3080:\tlearn: 1.4864554\ttotal: 37.4s\tremaining: 18.4s\n",
      "3081:\tlearn: 1.4858889\ttotal: 37.4s\tremaining: 18.4s\n",
      "3082:\tlearn: 1.4855646\ttotal: 37.5s\tremaining: 18.4s\n",
      "3083:\tlearn: 1.4853799\ttotal: 37.5s\tremaining: 18.4s\n",
      "3084:\tlearn: 1.4851837\ttotal: 37.5s\tremaining: 18.4s\n",
      "3085:\tlearn: 1.4850692\ttotal: 37.5s\tremaining: 18.4s\n",
      "3086:\tlearn: 1.4847366\ttotal: 37.5s\tremaining: 18.4s\n",
      "3087:\tlearn: 1.4843601\ttotal: 37.5s\tremaining: 18.3s\n",
      "3088:\tlearn: 1.4840817\ttotal: 37.5s\tremaining: 18.3s\n",
      "3089:\tlearn: 1.4839958\ttotal: 37.5s\tremaining: 18.3s\n",
      "3090:\tlearn: 1.4836951\ttotal: 37.6s\tremaining: 18.3s\n",
      "3091:\tlearn: 1.4834429\ttotal: 37.6s\tremaining: 18.3s\n",
      "3092:\tlearn: 1.4832011\ttotal: 37.6s\tremaining: 18.3s\n",
      "3093:\tlearn: 1.4830015\ttotal: 37.6s\tremaining: 18.3s\n",
      "3094:\tlearn: 1.4828118\ttotal: 37.6s\tremaining: 18.3s\n",
      "3095:\tlearn: 1.4826303\ttotal: 37.6s\tremaining: 18.3s\n",
      "3096:\tlearn: 1.4821603\ttotal: 37.6s\tremaining: 18.2s\n",
      "3097:\tlearn: 1.4819797\ttotal: 37.7s\tremaining: 18.2s\n",
      "3098:\tlearn: 1.4818506\ttotal: 37.7s\tremaining: 18.2s\n",
      "3099:\tlearn: 1.4817027\ttotal: 37.7s\tremaining: 18.2s\n",
      "3100:\tlearn: 1.4815320\ttotal: 37.7s\tremaining: 18.2s\n",
      "3101:\tlearn: 1.4814007\ttotal: 37.7s\tremaining: 18.2s\n",
      "3102:\tlearn: 1.4812370\ttotal: 37.7s\tremaining: 18.2s\n",
      "3103:\tlearn: 1.4809628\ttotal: 37.7s\tremaining: 18.2s\n",
      "3104:\tlearn: 1.4806754\ttotal: 37.7s\tremaining: 18.1s\n",
      "3105:\tlearn: 1.4805768\ttotal: 37.7s\tremaining: 18.1s\n",
      "3106:\tlearn: 1.4801691\ttotal: 37.8s\tremaining: 18.1s\n",
      "3107:\tlearn: 1.4800336\ttotal: 37.8s\tremaining: 18.1s\n",
      "3108:\tlearn: 1.4797401\ttotal: 37.8s\tremaining: 18.1s\n",
      "3109:\tlearn: 1.4796008\ttotal: 37.8s\tremaining: 18.1s\n",
      "3110:\tlearn: 1.4793885\ttotal: 37.8s\tremaining: 18.1s\n",
      "3111:\tlearn: 1.4791450\ttotal: 37.8s\tremaining: 18.1s\n",
      "3112:\tlearn: 1.4790101\ttotal: 37.8s\tremaining: 18s\n",
      "3113:\tlearn: 1.4786825\ttotal: 37.8s\tremaining: 18s\n",
      "3114:\tlearn: 1.4783273\ttotal: 37.9s\tremaining: 18s\n",
      "3115:\tlearn: 1.4781777\ttotal: 37.9s\tremaining: 18s\n",
      "3116:\tlearn: 1.4779588\ttotal: 37.9s\tremaining: 18s\n",
      "3117:\tlearn: 1.4775969\ttotal: 37.9s\tremaining: 18s\n",
      "3118:\tlearn: 1.4774630\ttotal: 37.9s\tremaining: 18s\n",
      "3119:\tlearn: 1.4771924\ttotal: 37.9s\tremaining: 18s\n",
      "3120:\tlearn: 1.4770169\ttotal: 37.9s\tremaining: 17.9s\n",
      "3121:\tlearn: 1.4768402\ttotal: 37.9s\tremaining: 17.9s\n",
      "3122:\tlearn: 1.4767432\ttotal: 37.9s\tremaining: 17.9s\n",
      "3123:\tlearn: 1.4766444\ttotal: 38s\tremaining: 17.9s\n",
      "3124:\tlearn: 1.4760974\ttotal: 38s\tremaining: 17.9s\n",
      "3125:\tlearn: 1.4758725\ttotal: 38s\tremaining: 17.9s\n",
      "3126:\tlearn: 1.4756505\ttotal: 38s\tremaining: 17.9s\n",
      "3127:\tlearn: 1.4756002\ttotal: 38s\tremaining: 17.9s\n",
      "3128:\tlearn: 1.4754254\ttotal: 38s\tremaining: 17.8s\n",
      "3129:\tlearn: 1.4752375\ttotal: 38s\tremaining: 17.8s\n",
      "3130:\tlearn: 1.4748249\ttotal: 38s\tremaining: 17.8s\n",
      "3131:\tlearn: 1.4744948\ttotal: 38s\tremaining: 17.8s\n",
      "3132:\tlearn: 1.4742022\ttotal: 38.1s\tremaining: 17.8s\n",
      "3133:\tlearn: 1.4739913\ttotal: 38.1s\tremaining: 17.8s\n",
      "3134:\tlearn: 1.4738720\ttotal: 38.1s\tremaining: 17.8s\n",
      "3135:\tlearn: 1.4735983\ttotal: 38.1s\tremaining: 17.8s\n",
      "3136:\tlearn: 1.4731931\ttotal: 38.1s\tremaining: 17.7s\n",
      "3137:\tlearn: 1.4728600\ttotal: 38.1s\tremaining: 17.7s\n",
      "3138:\tlearn: 1.4726878\ttotal: 38.1s\tremaining: 17.7s\n",
      "3139:\tlearn: 1.4724867\ttotal: 38.1s\tremaining: 17.7s\n",
      "3140:\tlearn: 1.4722978\ttotal: 38.2s\tremaining: 17.7s\n",
      "3141:\tlearn: 1.4721217\ttotal: 38.2s\tremaining: 17.7s\n",
      "3142:\tlearn: 1.4719428\ttotal: 38.2s\tremaining: 17.7s\n",
      "3143:\tlearn: 1.4718354\ttotal: 38.2s\tremaining: 17.7s\n",
      "3144:\tlearn: 1.4715339\ttotal: 38.2s\tremaining: 17.6s\n",
      "3145:\tlearn: 1.4712058\ttotal: 38.2s\tremaining: 17.6s\n",
      "3146:\tlearn: 1.4708809\ttotal: 38.2s\tremaining: 17.6s\n",
      "3147:\tlearn: 1.4706277\ttotal: 38.2s\tremaining: 17.6s\n",
      "3148:\tlearn: 1.4703455\ttotal: 38.2s\tremaining: 17.6s\n",
      "3149:\tlearn: 1.4699162\ttotal: 38.3s\tremaining: 17.6s\n",
      "3150:\tlearn: 1.4696942\ttotal: 38.3s\tremaining: 17.6s\n",
      "3151:\tlearn: 1.4695582\ttotal: 38.3s\tremaining: 17.6s\n",
      "3152:\tlearn: 1.4693091\ttotal: 38.3s\tremaining: 17.6s\n",
      "3153:\tlearn: 1.4691925\ttotal: 38.3s\tremaining: 17.5s\n",
      "3154:\tlearn: 1.4687689\ttotal: 38.3s\tremaining: 17.5s\n",
      "3155:\tlearn: 1.4684508\ttotal: 38.3s\tremaining: 17.5s\n",
      "3156:\tlearn: 1.4682995\ttotal: 38.4s\tremaining: 17.5s\n",
      "3157:\tlearn: 1.4680299\ttotal: 38.4s\tremaining: 17.5s\n",
      "3158:\tlearn: 1.4678526\ttotal: 38.4s\tremaining: 17.5s\n",
      "3159:\tlearn: 1.4677075\ttotal: 38.4s\tremaining: 17.5s\n",
      "3160:\tlearn: 1.4674920\ttotal: 38.4s\tremaining: 17.5s\n",
      "3161:\tlearn: 1.4672170\ttotal: 38.4s\tremaining: 17.4s\n",
      "3162:\tlearn: 1.4669898\ttotal: 38.4s\tremaining: 17.4s\n",
      "3163:\tlearn: 1.4667668\ttotal: 38.4s\tremaining: 17.4s\n",
      "3164:\tlearn: 1.4663793\ttotal: 38.4s\tremaining: 17.4s\n",
      "3165:\tlearn: 1.4660032\ttotal: 38.5s\tremaining: 17.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3166:\tlearn: 1.4659179\ttotal: 38.5s\tremaining: 17.4s\n",
      "3167:\tlearn: 1.4657640\ttotal: 38.5s\tremaining: 17.4s\n",
      "3168:\tlearn: 1.4655002\ttotal: 38.5s\tremaining: 17.4s\n",
      "3169:\tlearn: 1.4653563\ttotal: 38.5s\tremaining: 17.3s\n",
      "3170:\tlearn: 1.4651202\ttotal: 38.5s\tremaining: 17.3s\n",
      "3171:\tlearn: 1.4648947\ttotal: 38.5s\tremaining: 17.3s\n",
      "3172:\tlearn: 1.4646813\ttotal: 38.5s\tremaining: 17.3s\n",
      "3173:\tlearn: 1.4645949\ttotal: 38.6s\tremaining: 17.3s\n",
      "3174:\tlearn: 1.4643814\ttotal: 38.6s\tremaining: 17.3s\n",
      "3175:\tlearn: 1.4643132\ttotal: 38.6s\tremaining: 17.3s\n",
      "3176:\tlearn: 1.4640512\ttotal: 38.6s\tremaining: 17.3s\n",
      "3177:\tlearn: 1.4636977\ttotal: 38.6s\tremaining: 17.3s\n",
      "3178:\tlearn: 1.4634941\ttotal: 38.6s\tremaining: 17.2s\n",
      "3179:\tlearn: 1.4632941\ttotal: 38.6s\tremaining: 17.2s\n",
      "3180:\tlearn: 1.4630926\ttotal: 38.6s\tremaining: 17.2s\n",
      "3181:\tlearn: 1.4629208\ttotal: 38.7s\tremaining: 17.2s\n",
      "3182:\tlearn: 1.4626777\ttotal: 38.7s\tremaining: 17.2s\n",
      "3183:\tlearn: 1.4625448\ttotal: 38.7s\tremaining: 17.2s\n",
      "3184:\tlearn: 1.4622564\ttotal: 38.7s\tremaining: 17.2s\n",
      "3185:\tlearn: 1.4621093\ttotal: 38.7s\tremaining: 17.2s\n",
      "3186:\tlearn: 1.4617858\ttotal: 38.7s\tremaining: 17.1s\n",
      "3187:\tlearn: 1.4614298\ttotal: 38.7s\tremaining: 17.1s\n",
      "3188:\tlearn: 1.4612158\ttotal: 38.7s\tremaining: 17.1s\n",
      "3189:\tlearn: 1.4611831\ttotal: 38.8s\tremaining: 17.1s\n",
      "3190:\tlearn: 1.4609106\ttotal: 38.8s\tremaining: 17.1s\n",
      "3191:\tlearn: 1.4603509\ttotal: 38.8s\tremaining: 17.1s\n",
      "3192:\tlearn: 1.4601535\ttotal: 38.8s\tremaining: 17.1s\n",
      "3193:\tlearn: 1.4599952\ttotal: 38.8s\tremaining: 17.1s\n",
      "3194:\tlearn: 1.4597362\ttotal: 38.8s\tremaining: 17s\n",
      "3195:\tlearn: 1.4595499\ttotal: 38.8s\tremaining: 17s\n",
      "3196:\tlearn: 1.4594418\ttotal: 38.8s\tremaining: 17s\n",
      "3197:\tlearn: 1.4592692\ttotal: 38.9s\tremaining: 17s\n",
      "3198:\tlearn: 1.4588304\ttotal: 38.9s\tremaining: 17s\n",
      "3199:\tlearn: 1.4587731\ttotal: 38.9s\tremaining: 17s\n",
      "3200:\tlearn: 1.4584757\ttotal: 38.9s\tremaining: 17s\n",
      "3201:\tlearn: 1.4582194\ttotal: 38.9s\tremaining: 17s\n",
      "3202:\tlearn: 1.4578927\ttotal: 38.9s\tremaining: 16.9s\n",
      "3203:\tlearn: 1.4577678\ttotal: 38.9s\tremaining: 16.9s\n",
      "3204:\tlearn: 1.4576427\ttotal: 38.9s\tremaining: 16.9s\n",
      "3205:\tlearn: 1.4573584\ttotal: 39s\tremaining: 16.9s\n",
      "3206:\tlearn: 1.4572140\ttotal: 39s\tremaining: 16.9s\n",
      "3207:\tlearn: 1.4569979\ttotal: 39s\tremaining: 16.9s\n",
      "3208:\tlearn: 1.4567512\ttotal: 39s\tremaining: 16.9s\n",
      "3209:\tlearn: 1.4564790\ttotal: 39s\tremaining: 16.9s\n",
      "3210:\tlearn: 1.4563803\ttotal: 39s\tremaining: 16.9s\n",
      "3211:\tlearn: 1.4561055\ttotal: 39s\tremaining: 16.8s\n",
      "3212:\tlearn: 1.4559627\ttotal: 39s\tremaining: 16.8s\n",
      "3213:\tlearn: 1.4557842\ttotal: 39s\tremaining: 16.8s\n",
      "3214:\tlearn: 1.4555194\ttotal: 39.1s\tremaining: 16.8s\n",
      "3215:\tlearn: 1.4554534\ttotal: 39.1s\tremaining: 16.8s\n",
      "3216:\tlearn: 1.4552873\ttotal: 39.1s\tremaining: 16.8s\n",
      "3217:\tlearn: 1.4551593\ttotal: 39.1s\tremaining: 16.8s\n",
      "3218:\tlearn: 1.4549502\ttotal: 39.1s\tremaining: 16.8s\n",
      "3219:\tlearn: 1.4547344\ttotal: 39.1s\tremaining: 16.7s\n",
      "3220:\tlearn: 1.4544517\ttotal: 39.1s\tremaining: 16.7s\n",
      "3221:\tlearn: 1.4541206\ttotal: 39.1s\tremaining: 16.7s\n",
      "3222:\tlearn: 1.4539251\ttotal: 39.2s\tremaining: 16.7s\n",
      "3223:\tlearn: 1.4537709\ttotal: 39.2s\tremaining: 16.7s\n",
      "3224:\tlearn: 1.4534506\ttotal: 39.2s\tremaining: 16.7s\n",
      "3225:\tlearn: 1.4531204\ttotal: 39.2s\tremaining: 16.7s\n",
      "3226:\tlearn: 1.4528783\ttotal: 39.2s\tremaining: 16.7s\n",
      "3227:\tlearn: 1.4526849\ttotal: 39.2s\tremaining: 16.6s\n",
      "3228:\tlearn: 1.4524807\ttotal: 39.2s\tremaining: 16.6s\n",
      "3229:\tlearn: 1.4522495\ttotal: 39.2s\tremaining: 16.6s\n",
      "3230:\tlearn: 1.4520768\ttotal: 39.3s\tremaining: 16.6s\n",
      "3231:\tlearn: 1.4519131\ttotal: 39.3s\tremaining: 16.6s\n",
      "3232:\tlearn: 1.4517521\ttotal: 39.3s\tremaining: 16.6s\n",
      "3233:\tlearn: 1.4515597\ttotal: 39.3s\tremaining: 16.6s\n",
      "3234:\tlearn: 1.4511425\ttotal: 39.3s\tremaining: 16.6s\n",
      "3235:\tlearn: 1.4508060\ttotal: 39.3s\tremaining: 16.5s\n",
      "3236:\tlearn: 1.4506549\ttotal: 39.3s\tremaining: 16.5s\n",
      "3237:\tlearn: 1.4505557\ttotal: 39.3s\tremaining: 16.5s\n",
      "3238:\tlearn: 1.4504512\ttotal: 39.4s\tremaining: 16.5s\n",
      "3239:\tlearn: 1.4502173\ttotal: 39.4s\tremaining: 16.5s\n",
      "3240:\tlearn: 1.4500202\ttotal: 39.4s\tremaining: 16.5s\n",
      "3241:\tlearn: 1.4498426\ttotal: 39.4s\tremaining: 16.5s\n",
      "3242:\tlearn: 1.4495883\ttotal: 39.4s\tremaining: 16.5s\n",
      "3243:\tlearn: 1.4494493\ttotal: 39.4s\tremaining: 16.5s\n",
      "3244:\tlearn: 1.4492974\ttotal: 39.4s\tremaining: 16.4s\n",
      "3245:\tlearn: 1.4490344\ttotal: 39.4s\tremaining: 16.4s\n",
      "3246:\tlearn: 1.4489449\ttotal: 39.5s\tremaining: 16.4s\n",
      "3247:\tlearn: 1.4487450\ttotal: 39.5s\tremaining: 16.4s\n",
      "3248:\tlearn: 1.4487048\ttotal: 39.5s\tremaining: 16.4s\n",
      "3249:\tlearn: 1.4486324\ttotal: 39.5s\tremaining: 16.4s\n",
      "3250:\tlearn: 1.4485195\ttotal: 39.5s\tremaining: 16.4s\n",
      "3251:\tlearn: 1.4481280\ttotal: 39.5s\tremaining: 16.4s\n",
      "3252:\tlearn: 1.4477997\ttotal: 39.5s\tremaining: 16.3s\n",
      "3253:\tlearn: 1.4476607\ttotal: 39.5s\tremaining: 16.3s\n",
      "3254:\tlearn: 1.4473582\ttotal: 39.5s\tremaining: 16.3s\n",
      "3255:\tlearn: 1.4471223\ttotal: 39.6s\tremaining: 16.3s\n",
      "3256:\tlearn: 1.4469455\ttotal: 39.6s\tremaining: 16.3s\n",
      "3257:\tlearn: 1.4467253\ttotal: 39.6s\tremaining: 16.3s\n",
      "3258:\tlearn: 1.4465796\ttotal: 39.6s\tremaining: 16.3s\n",
      "3259:\tlearn: 1.4464603\ttotal: 39.6s\tremaining: 16.3s\n",
      "3260:\tlearn: 1.4462473\ttotal: 39.6s\tremaining: 16.2s\n",
      "3261:\tlearn: 1.4460186\ttotal: 39.6s\tremaining: 16.2s\n",
      "3262:\tlearn: 1.4455387\ttotal: 39.6s\tremaining: 16.2s\n",
      "3263:\tlearn: 1.4453556\ttotal: 39.7s\tremaining: 16.2s\n",
      "3264:\tlearn: 1.4451742\ttotal: 39.7s\tremaining: 16.2s\n",
      "3265:\tlearn: 1.4450282\ttotal: 39.7s\tremaining: 16.2s\n",
      "3266:\tlearn: 1.4448162\ttotal: 39.7s\tremaining: 16.2s\n",
      "3267:\tlearn: 1.4445503\ttotal: 39.7s\tremaining: 16.2s\n",
      "3268:\tlearn: 1.4444205\ttotal: 39.7s\tremaining: 16.1s\n",
      "3269:\tlearn: 1.4442404\ttotal: 39.7s\tremaining: 16.1s\n",
      "3270:\tlearn: 1.4440630\ttotal: 39.7s\tremaining: 16.1s\n",
      "3271:\tlearn: 1.4439149\ttotal: 39.8s\tremaining: 16.1s\n",
      "3272:\tlearn: 1.4436882\ttotal: 39.8s\tremaining: 16.1s\n",
      "3273:\tlearn: 1.4434567\ttotal: 39.8s\tremaining: 16.1s\n",
      "3274:\tlearn: 1.4433811\ttotal: 39.8s\tremaining: 16.1s\n",
      "3275:\tlearn: 1.4432400\ttotal: 39.8s\tremaining: 16.1s\n",
      "3276:\tlearn: 1.4431023\ttotal: 39.8s\tremaining: 16.1s\n",
      "3277:\tlearn: 1.4429993\ttotal: 39.8s\tremaining: 16s\n",
      "3278:\tlearn: 1.4429982\ttotal: 39.8s\tremaining: 16s\n",
      "3279:\tlearn: 1.4427963\ttotal: 39.9s\tremaining: 16s\n",
      "3280:\tlearn: 1.4426325\ttotal: 39.9s\tremaining: 16s\n",
      "3281:\tlearn: 1.4425425\ttotal: 39.9s\tremaining: 16s\n",
      "3282:\tlearn: 1.4424134\ttotal: 39.9s\tremaining: 16s\n",
      "3283:\tlearn: 1.4421513\ttotal: 39.9s\tremaining: 16s\n",
      "3284:\tlearn: 1.4417826\ttotal: 39.9s\tremaining: 16s\n",
      "3285:\tlearn: 1.4416322\ttotal: 39.9s\tremaining: 15.9s\n",
      "3286:\tlearn: 1.4415130\ttotal: 39.9s\tremaining: 15.9s\n",
      "3287:\tlearn: 1.4411907\ttotal: 39.9s\tremaining: 15.9s\n",
      "3288:\tlearn: 1.4408982\ttotal: 40s\tremaining: 15.9s\n",
      "3289:\tlearn: 1.4408000\ttotal: 40s\tremaining: 15.9s\n",
      "3290:\tlearn: 1.4405384\ttotal: 40s\tremaining: 15.9s\n",
      "3291:\tlearn: 1.4402838\ttotal: 40s\tremaining: 15.9s\n",
      "3292:\tlearn: 1.4399252\ttotal: 40s\tremaining: 15.9s\n",
      "3293:\tlearn: 1.4397396\ttotal: 40s\tremaining: 15.8s\n",
      "3294:\tlearn: 1.4395421\ttotal: 40s\tremaining: 15.8s\n",
      "3295:\tlearn: 1.4393015\ttotal: 40s\tremaining: 15.8s\n",
      "3296:\tlearn: 1.4389449\ttotal: 40.1s\tremaining: 15.8s\n",
      "3297:\tlearn: 1.4386986\ttotal: 40.1s\tremaining: 15.8s\n",
      "3298:\tlearn: 1.4382082\ttotal: 40.1s\tremaining: 15.8s\n",
      "3299:\tlearn: 1.4380118\ttotal: 40.1s\tremaining: 15.8s\n",
      "3300:\tlearn: 1.4378500\ttotal: 40.1s\tremaining: 15.8s\n",
      "3301:\tlearn: 1.4376526\ttotal: 40.1s\tremaining: 15.7s\n",
      "3302:\tlearn: 1.4374091\ttotal: 40.1s\tremaining: 15.7s\n",
      "3303:\tlearn: 1.4371815\ttotal: 40.1s\tremaining: 15.7s\n",
      "3304:\tlearn: 1.4369789\ttotal: 40.2s\tremaining: 15.7s\n",
      "3305:\tlearn: 1.4366931\ttotal: 40.2s\tremaining: 15.7s\n",
      "3306:\tlearn: 1.4365574\ttotal: 40.2s\tremaining: 15.7s\n",
      "3307:\tlearn: 1.4362482\ttotal: 40.2s\tremaining: 15.7s\n",
      "3308:\tlearn: 1.4360669\ttotal: 40.2s\tremaining: 15.7s\n",
      "3309:\tlearn: 1.4358829\ttotal: 40.2s\tremaining: 15.7s\n",
      "3310:\tlearn: 1.4356295\ttotal: 40.2s\tremaining: 15.6s\n",
      "3311:\tlearn: 1.4355420\ttotal: 40.2s\tremaining: 15.6s\n",
      "3312:\tlearn: 1.4354423\ttotal: 40.3s\tremaining: 15.6s\n",
      "3313:\tlearn: 1.4353435\ttotal: 40.3s\tremaining: 15.6s\n",
      "3314:\tlearn: 1.4350740\ttotal: 40.3s\tremaining: 15.6s\n",
      "3315:\tlearn: 1.4347219\ttotal: 40.3s\tremaining: 15.6s\n",
      "3316:\tlearn: 1.4343488\ttotal: 40.3s\tremaining: 15.6s\n",
      "3317:\tlearn: 1.4340805\ttotal: 40.3s\tremaining: 15.6s\n",
      "3318:\tlearn: 1.4339432\ttotal: 40.3s\tremaining: 15.5s\n",
      "3319:\tlearn: 1.4336715\ttotal: 40.3s\tremaining: 15.5s\n",
      "3320:\tlearn: 1.4335039\ttotal: 40.4s\tremaining: 15.5s\n",
      "3321:\tlearn: 1.4334125\ttotal: 40.4s\tremaining: 15.5s\n",
      "3322:\tlearn: 1.4332336\ttotal: 40.4s\tremaining: 15.5s\n",
      "3323:\tlearn: 1.4329781\ttotal: 40.4s\tremaining: 15.5s\n",
      "3324:\tlearn: 1.4328538\ttotal: 40.4s\tremaining: 15.5s\n",
      "3325:\tlearn: 1.4327302\ttotal: 40.4s\tremaining: 15.5s\n",
      "3326:\tlearn: 1.4326691\ttotal: 40.4s\tremaining: 15.4s\n",
      "3327:\tlearn: 1.4325340\ttotal: 40.4s\tremaining: 15.4s\n",
      "3328:\tlearn: 1.4323673\ttotal: 40.5s\tremaining: 15.4s\n",
      "3329:\tlearn: 1.4320819\ttotal: 40.5s\tremaining: 15.4s\n",
      "3330:\tlearn: 1.4317985\ttotal: 40.5s\tremaining: 15.4s\n",
      "3331:\tlearn: 1.4314490\ttotal: 40.5s\tremaining: 15.4s\n",
      "3332:\tlearn: 1.4312419\ttotal: 40.5s\tremaining: 15.4s\n",
      "3333:\tlearn: 1.4311081\ttotal: 40.5s\tremaining: 15.4s\n",
      "3334:\tlearn: 1.4310224\ttotal: 40.5s\tremaining: 15.3s\n",
      "3335:\tlearn: 1.4308867\ttotal: 40.5s\tremaining: 15.3s\n",
      "3336:\tlearn: 1.4307123\ttotal: 40.6s\tremaining: 15.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3337:\tlearn: 1.4305387\ttotal: 40.6s\tremaining: 15.3s\n",
      "3338:\tlearn: 1.4303801\ttotal: 40.6s\tremaining: 15.3s\n",
      "3339:\tlearn: 1.4302687\ttotal: 40.6s\tremaining: 15.3s\n",
      "3340:\tlearn: 1.4299151\ttotal: 40.6s\tremaining: 15.3s\n",
      "3341:\tlearn: 1.4297502\ttotal: 40.6s\tremaining: 15.3s\n",
      "3342:\tlearn: 1.4295670\ttotal: 40.6s\tremaining: 15.3s\n",
      "3343:\tlearn: 1.4291304\ttotal: 40.6s\tremaining: 15.2s\n",
      "3344:\tlearn: 1.4288525\ttotal: 40.7s\tremaining: 15.2s\n",
      "3345:\tlearn: 1.4286596\ttotal: 40.7s\tremaining: 15.2s\n",
      "3346:\tlearn: 1.4283266\ttotal: 40.7s\tremaining: 15.2s\n",
      "3347:\tlearn: 1.4282330\ttotal: 40.7s\tremaining: 15.2s\n",
      "3348:\tlearn: 1.4282006\ttotal: 40.7s\tremaining: 15.2s\n",
      "3349:\tlearn: 1.4280734\ttotal: 40.7s\tremaining: 15.2s\n",
      "3350:\tlearn: 1.4278860\ttotal: 40.7s\tremaining: 15.2s\n",
      "3351:\tlearn: 1.4276060\ttotal: 40.7s\tremaining: 15.1s\n",
      "3352:\tlearn: 1.4274080\ttotal: 40.7s\tremaining: 15.1s\n",
      "3353:\tlearn: 1.4271807\ttotal: 40.8s\tremaining: 15.1s\n",
      "3354:\tlearn: 1.4269642\ttotal: 40.8s\tremaining: 15.1s\n",
      "3355:\tlearn: 1.4268933\ttotal: 40.8s\tremaining: 15.1s\n",
      "3356:\tlearn: 1.4265718\ttotal: 40.8s\tremaining: 15.1s\n",
      "3357:\tlearn: 1.4263604\ttotal: 40.8s\tremaining: 15.1s\n",
      "3358:\tlearn: 1.4259768\ttotal: 40.8s\tremaining: 15.1s\n",
      "3359:\tlearn: 1.4257638\ttotal: 40.8s\tremaining: 15s\n",
      "3360:\tlearn: 1.4256698\ttotal: 40.9s\tremaining: 15s\n",
      "3361:\tlearn: 1.4255827\ttotal: 40.9s\tremaining: 15s\n",
      "3362:\tlearn: 1.4254018\ttotal: 40.9s\tremaining: 15s\n",
      "3363:\tlearn: 1.4252119\ttotal: 40.9s\tremaining: 15s\n",
      "3364:\tlearn: 1.4249006\ttotal: 40.9s\tremaining: 15s\n",
      "3365:\tlearn: 1.4247337\ttotal: 40.9s\tremaining: 15s\n",
      "3366:\tlearn: 1.4245359\ttotal: 40.9s\tremaining: 15s\n",
      "3367:\tlearn: 1.4240897\ttotal: 40.9s\tremaining: 14.9s\n",
      "3368:\tlearn: 1.4239341\ttotal: 40.9s\tremaining: 14.9s\n",
      "3369:\tlearn: 1.4238266\ttotal: 41s\tremaining: 14.9s\n",
      "3370:\tlearn: 1.4234742\ttotal: 41s\tremaining: 14.9s\n",
      "3371:\tlearn: 1.4230959\ttotal: 41s\tremaining: 14.9s\n",
      "3372:\tlearn: 1.4228250\ttotal: 41s\tremaining: 14.9s\n",
      "3373:\tlearn: 1.4225672\ttotal: 41s\tremaining: 14.9s\n",
      "3374:\tlearn: 1.4222506\ttotal: 41s\tremaining: 14.9s\n",
      "3375:\tlearn: 1.4221180\ttotal: 41s\tremaining: 14.9s\n",
      "3376:\tlearn: 1.4219154\ttotal: 41s\tremaining: 14.8s\n",
      "3377:\tlearn: 1.4215958\ttotal: 41.1s\tremaining: 14.8s\n",
      "3378:\tlearn: 1.4215132\ttotal: 41.1s\tremaining: 14.8s\n",
      "3379:\tlearn: 1.4212647\ttotal: 41.1s\tremaining: 14.8s\n",
      "3380:\tlearn: 1.4211513\ttotal: 41.1s\tremaining: 14.8s\n",
      "3381:\tlearn: 1.4207686\ttotal: 41.1s\tremaining: 14.8s\n",
      "3382:\tlearn: 1.4205883\ttotal: 41.1s\tremaining: 14.8s\n",
      "3383:\tlearn: 1.4202618\ttotal: 41.1s\tremaining: 14.8s\n",
      "3384:\tlearn: 1.4198985\ttotal: 41.1s\tremaining: 14.7s\n",
      "3385:\tlearn: 1.4197931\ttotal: 41.2s\tremaining: 14.7s\n",
      "3386:\tlearn: 1.4197924\ttotal: 41.2s\tremaining: 14.7s\n",
      "3387:\tlearn: 1.4195673\ttotal: 41.2s\tremaining: 14.7s\n",
      "3388:\tlearn: 1.4194361\ttotal: 41.2s\tremaining: 14.7s\n",
      "3389:\tlearn: 1.4194355\ttotal: 41.2s\tremaining: 14.7s\n",
      "3390:\tlearn: 1.4193555\ttotal: 41.2s\tremaining: 14.7s\n",
      "3391:\tlearn: 1.4190859\ttotal: 41.2s\tremaining: 14.7s\n",
      "3392:\tlearn: 1.4187857\ttotal: 41.2s\tremaining: 14.6s\n",
      "3393:\tlearn: 1.4187850\ttotal: 41.2s\tremaining: 14.6s\n",
      "3394:\tlearn: 1.4187019\ttotal: 41.3s\tremaining: 14.6s\n",
      "3395:\tlearn: 1.4186078\ttotal: 41.3s\tremaining: 14.6s\n",
      "3396:\tlearn: 1.4183269\ttotal: 41.3s\tremaining: 14.6s\n",
      "3397:\tlearn: 1.4181918\ttotal: 41.3s\tremaining: 14.6s\n",
      "3398:\tlearn: 1.4176891\ttotal: 41.3s\tremaining: 14.6s\n",
      "3399:\tlearn: 1.4176121\ttotal: 41.3s\tremaining: 14.6s\n",
      "3400:\tlearn: 1.4173830\ttotal: 41.3s\tremaining: 14.5s\n",
      "3401:\tlearn: 1.4169507\ttotal: 41.3s\tremaining: 14.5s\n",
      "3402:\tlearn: 1.4165650\ttotal: 41.4s\tremaining: 14.5s\n",
      "3403:\tlearn: 1.4163782\ttotal: 41.4s\tremaining: 14.5s\n",
      "3404:\tlearn: 1.4162745\ttotal: 41.4s\tremaining: 14.5s\n",
      "3405:\tlearn: 1.4161418\ttotal: 41.4s\tremaining: 14.5s\n",
      "3406:\tlearn: 1.4159755\ttotal: 41.4s\tremaining: 14.5s\n",
      "3407:\tlearn: 1.4158618\ttotal: 41.4s\tremaining: 14.5s\n",
      "3408:\tlearn: 1.4156844\ttotal: 41.4s\tremaining: 14.4s\n",
      "3409:\tlearn: 1.4153067\ttotal: 41.4s\tremaining: 14.4s\n",
      "3410:\tlearn: 1.4151502\ttotal: 41.5s\tremaining: 14.4s\n",
      "3411:\tlearn: 1.4148123\ttotal: 41.5s\tremaining: 14.4s\n",
      "3412:\tlearn: 1.4144622\ttotal: 41.5s\tremaining: 14.4s\n",
      "3413:\tlearn: 1.4142445\ttotal: 41.5s\tremaining: 14.4s\n",
      "3414:\tlearn: 1.4140985\ttotal: 41.5s\tremaining: 14.4s\n",
      "3415:\tlearn: 1.4139659\ttotal: 41.5s\tremaining: 14.4s\n",
      "3416:\tlearn: 1.4137919\ttotal: 41.5s\tremaining: 14.4s\n",
      "3417:\tlearn: 1.4135204\ttotal: 41.5s\tremaining: 14.3s\n",
      "3418:\tlearn: 1.4134038\ttotal: 41.6s\tremaining: 14.3s\n",
      "3419:\tlearn: 1.4130670\ttotal: 41.6s\tremaining: 14.3s\n",
      "3420:\tlearn: 1.4127371\ttotal: 41.6s\tremaining: 14.3s\n",
      "3421:\tlearn: 1.4123648\ttotal: 41.6s\tremaining: 14.3s\n",
      "3422:\tlearn: 1.4122385\ttotal: 41.6s\tremaining: 14.3s\n",
      "3423:\tlearn: 1.4119965\ttotal: 41.6s\tremaining: 14.3s\n",
      "3424:\tlearn: 1.4117171\ttotal: 41.6s\tremaining: 14.3s\n",
      "3425:\tlearn: 1.4116003\ttotal: 41.6s\tremaining: 14.2s\n",
      "3426:\tlearn: 1.4113197\ttotal: 41.7s\tremaining: 14.2s\n",
      "3427:\tlearn: 1.4110905\ttotal: 41.7s\tremaining: 14.2s\n",
      "3428:\tlearn: 1.4109009\ttotal: 41.7s\tremaining: 14.2s\n",
      "3429:\tlearn: 1.4106014\ttotal: 41.7s\tremaining: 14.2s\n",
      "3430:\tlearn: 1.4104336\ttotal: 41.7s\tremaining: 14.2s\n",
      "3431:\tlearn: 1.4102750\ttotal: 41.7s\tremaining: 14.2s\n",
      "3432:\tlearn: 1.4099117\ttotal: 41.7s\tremaining: 14.2s\n",
      "3433:\tlearn: 1.4096380\ttotal: 41.8s\tremaining: 14.2s\n",
      "3434:\tlearn: 1.4093760\ttotal: 41.8s\tremaining: 14.1s\n",
      "3435:\tlearn: 1.4092098\ttotal: 41.8s\tremaining: 14.1s\n",
      "3436:\tlearn: 1.4090632\ttotal: 41.8s\tremaining: 14.1s\n",
      "3437:\tlearn: 1.4089014\ttotal: 41.8s\tremaining: 14.1s\n",
      "3438:\tlearn: 1.4086415\ttotal: 41.8s\tremaining: 14.1s\n",
      "3439:\tlearn: 1.4083279\ttotal: 41.8s\tremaining: 14.1s\n",
      "3440:\tlearn: 1.4081715\ttotal: 41.8s\tremaining: 14.1s\n",
      "3441:\tlearn: 1.4078517\ttotal: 41.8s\tremaining: 14.1s\n",
      "3442:\tlearn: 1.4074403\ttotal: 41.9s\tremaining: 14s\n",
      "3443:\tlearn: 1.4072104\ttotal: 41.9s\tremaining: 14s\n",
      "3444:\tlearn: 1.4070040\ttotal: 41.9s\tremaining: 14s\n",
      "3445:\tlearn: 1.4068159\ttotal: 41.9s\tremaining: 14s\n",
      "3446:\tlearn: 1.4064429\ttotal: 41.9s\tremaining: 14s\n",
      "3447:\tlearn: 1.4062733\ttotal: 41.9s\tremaining: 14s\n",
      "3448:\tlearn: 1.4059318\ttotal: 41.9s\tremaining: 14s\n",
      "3449:\tlearn: 1.4057905\ttotal: 42s\tremaining: 14s\n",
      "3450:\tlearn: 1.4056270\ttotal: 42s\tremaining: 13.9s\n",
      "3451:\tlearn: 1.4053515\ttotal: 42s\tremaining: 13.9s\n",
      "3452:\tlearn: 1.4052710\ttotal: 42s\tremaining: 13.9s\n",
      "3453:\tlearn: 1.4050835\ttotal: 42s\tremaining: 13.9s\n",
      "3454:\tlearn: 1.4048293\ttotal: 42s\tremaining: 13.9s\n",
      "3455:\tlearn: 1.4046854\ttotal: 42s\tremaining: 13.9s\n",
      "3456:\tlearn: 1.4044148\ttotal: 42s\tremaining: 13.9s\n",
      "3457:\tlearn: 1.4042882\ttotal: 42s\tremaining: 13.9s\n",
      "3458:\tlearn: 1.4039921\ttotal: 42.1s\tremaining: 13.9s\n",
      "3459:\tlearn: 1.4035734\ttotal: 42.1s\tremaining: 13.8s\n",
      "3460:\tlearn: 1.4034665\ttotal: 42.1s\tremaining: 13.8s\n",
      "3461:\tlearn: 1.4033091\ttotal: 42.1s\tremaining: 13.8s\n",
      "3462:\tlearn: 1.4031025\ttotal: 42.1s\tremaining: 13.8s\n",
      "3463:\tlearn: 1.4028467\ttotal: 42.1s\tremaining: 13.8s\n",
      "3464:\tlearn: 1.4027430\ttotal: 42.1s\tremaining: 13.8s\n",
      "3465:\tlearn: 1.4024141\ttotal: 42.2s\tremaining: 13.8s\n",
      "3466:\tlearn: 1.4021914\ttotal: 42.2s\tremaining: 13.8s\n",
      "3467:\tlearn: 1.4018700\ttotal: 42.2s\tremaining: 13.7s\n",
      "3468:\tlearn: 1.4016632\ttotal: 42.2s\tremaining: 13.7s\n",
      "3469:\tlearn: 1.4013942\ttotal: 42.2s\tremaining: 13.7s\n",
      "3470:\tlearn: 1.4010915\ttotal: 42.2s\tremaining: 13.7s\n",
      "3471:\tlearn: 1.4009837\ttotal: 42.2s\tremaining: 13.7s\n",
      "3472:\tlearn: 1.4006286\ttotal: 42.2s\tremaining: 13.7s\n",
      "3473:\tlearn: 1.4003870\ttotal: 42.2s\tremaining: 13.7s\n",
      "3474:\tlearn: 1.4002262\ttotal: 42.3s\tremaining: 13.7s\n",
      "3475:\tlearn: 1.4000716\ttotal: 42.3s\tremaining: 13.6s\n",
      "3476:\tlearn: 1.3998782\ttotal: 42.3s\tremaining: 13.6s\n",
      "3477:\tlearn: 1.3994969\ttotal: 42.3s\tremaining: 13.6s\n",
      "3478:\tlearn: 1.3991531\ttotal: 42.3s\tremaining: 13.6s\n",
      "3479:\tlearn: 1.3989913\ttotal: 42.3s\tremaining: 13.6s\n",
      "3480:\tlearn: 1.3986764\ttotal: 42.3s\tremaining: 13.6s\n",
      "3481:\tlearn: 1.3984457\ttotal: 42.3s\tremaining: 13.6s\n",
      "3482:\tlearn: 1.3981748\ttotal: 42.4s\tremaining: 13.6s\n",
      "3483:\tlearn: 1.3980143\ttotal: 42.4s\tremaining: 13.5s\n",
      "3484:\tlearn: 1.3976986\ttotal: 42.4s\tremaining: 13.5s\n",
      "3485:\tlearn: 1.3975359\ttotal: 42.4s\tremaining: 13.5s\n",
      "3486:\tlearn: 1.3974022\ttotal: 42.4s\tremaining: 13.5s\n",
      "3487:\tlearn: 1.3972399\ttotal: 42.4s\tremaining: 13.5s\n",
      "3488:\tlearn: 1.3969983\ttotal: 42.4s\tremaining: 13.5s\n",
      "3489:\tlearn: 1.3967428\ttotal: 42.4s\tremaining: 13.5s\n",
      "3490:\tlearn: 1.3966992\ttotal: 42.5s\tremaining: 13.5s\n",
      "3491:\tlearn: 1.3965521\ttotal: 42.5s\tremaining: 13.4s\n",
      "3492:\tlearn: 1.3961732\ttotal: 42.5s\tremaining: 13.4s\n",
      "3493:\tlearn: 1.3960048\ttotal: 42.5s\tremaining: 13.4s\n",
      "3494:\tlearn: 1.3959790\ttotal: 42.5s\tremaining: 13.4s\n",
      "3495:\tlearn: 1.3957817\ttotal: 42.5s\tremaining: 13.4s\n",
      "3496:\tlearn: 1.3955684\ttotal: 42.5s\tremaining: 13.4s\n",
      "3497:\tlearn: 1.3953214\ttotal: 42.5s\tremaining: 13.4s\n",
      "3498:\tlearn: 1.3952002\ttotal: 42.6s\tremaining: 13.4s\n",
      "3499:\tlearn: 1.3949632\ttotal: 42.6s\tremaining: 13.4s\n",
      "3500:\tlearn: 1.3947891\ttotal: 42.6s\tremaining: 13.3s\n",
      "3501:\tlearn: 1.3947178\ttotal: 42.6s\tremaining: 13.3s\n",
      "3502:\tlearn: 1.3945116\ttotal: 42.6s\tremaining: 13.3s\n",
      "3503:\tlearn: 1.3944364\ttotal: 42.6s\tremaining: 13.3s\n",
      "3504:\tlearn: 1.3942200\ttotal: 42.6s\tremaining: 13.3s\n",
      "3505:\tlearn: 1.3941137\ttotal: 42.6s\tremaining: 13.3s\n",
      "3506:\tlearn: 1.3939185\ttotal: 42.6s\tremaining: 13.3s\n",
      "3507:\tlearn: 1.3936412\ttotal: 42.7s\tremaining: 13.3s\n",
      "3508:\tlearn: 1.3935705\ttotal: 42.7s\tremaining: 13.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3509:\tlearn: 1.3932080\ttotal: 42.7s\tremaining: 13.2s\n",
      "3510:\tlearn: 1.3929413\ttotal: 42.7s\tremaining: 13.2s\n",
      "3511:\tlearn: 1.3926377\ttotal: 42.7s\tremaining: 13.2s\n",
      "3512:\tlearn: 1.3924424\ttotal: 42.7s\tremaining: 13.2s\n",
      "3513:\tlearn: 1.3921688\ttotal: 42.7s\tremaining: 13.2s\n",
      "3514:\tlearn: 1.3919331\ttotal: 42.7s\tremaining: 13.2s\n",
      "3515:\tlearn: 1.3917603\ttotal: 42.8s\tremaining: 13.2s\n",
      "3516:\tlearn: 1.3915164\ttotal: 42.8s\tremaining: 13.1s\n",
      "3517:\tlearn: 1.3911889\ttotal: 42.8s\tremaining: 13.1s\n",
      "3518:\tlearn: 1.3910427\ttotal: 42.8s\tremaining: 13.1s\n",
      "3519:\tlearn: 1.3908467\ttotal: 42.8s\tremaining: 13.1s\n",
      "3520:\tlearn: 1.3906365\ttotal: 42.8s\tremaining: 13.1s\n",
      "3521:\tlearn: 1.3904498\ttotal: 42.8s\tremaining: 13.1s\n",
      "3522:\tlearn: 1.3903284\ttotal: 42.8s\tremaining: 13.1s\n",
      "3523:\tlearn: 1.3900071\ttotal: 42.9s\tremaining: 13.1s\n",
      "3524:\tlearn: 1.3898298\ttotal: 42.9s\tremaining: 13s\n",
      "3525:\tlearn: 1.3896379\ttotal: 42.9s\tremaining: 13s\n",
      "3526:\tlearn: 1.3893279\ttotal: 42.9s\tremaining: 13s\n",
      "3527:\tlearn: 1.3891795\ttotal: 42.9s\tremaining: 13s\n",
      "3528:\tlearn: 1.3889567\ttotal: 42.9s\tremaining: 13s\n",
      "3529:\tlearn: 1.3887307\ttotal: 42.9s\tremaining: 13s\n",
      "3530:\tlearn: 1.3884939\ttotal: 42.9s\tremaining: 13s\n",
      "3531:\tlearn: 1.3881437\ttotal: 43s\tremaining: 13s\n",
      "3532:\tlearn: 1.3879071\ttotal: 43s\tremaining: 13s\n",
      "3533:\tlearn: 1.3876507\ttotal: 43s\tremaining: 12.9s\n",
      "3534:\tlearn: 1.3874483\ttotal: 43s\tremaining: 12.9s\n",
      "3535:\tlearn: 1.3871343\ttotal: 43s\tremaining: 12.9s\n",
      "3536:\tlearn: 1.3870589\ttotal: 43s\tremaining: 12.9s\n",
      "3537:\tlearn: 1.3868021\ttotal: 43s\tremaining: 12.9s\n",
      "3538:\tlearn: 1.3865975\ttotal: 43s\tremaining: 12.9s\n",
      "3539:\tlearn: 1.3863196\ttotal: 43.1s\tremaining: 12.9s\n",
      "3540:\tlearn: 1.3861335\ttotal: 43.1s\tremaining: 12.9s\n",
      "3541:\tlearn: 1.3857273\ttotal: 43.1s\tremaining: 12.8s\n",
      "3542:\tlearn: 1.3856047\ttotal: 43.1s\tremaining: 12.8s\n",
      "3543:\tlearn: 1.3853813\ttotal: 43.1s\tremaining: 12.8s\n",
      "3544:\tlearn: 1.3851668\ttotal: 43.1s\tremaining: 12.8s\n",
      "3545:\tlearn: 1.3849144\ttotal: 43.1s\tremaining: 12.8s\n",
      "3546:\tlearn: 1.3847339\ttotal: 43.1s\tremaining: 12.8s\n",
      "3547:\tlearn: 1.3846055\ttotal: 43.2s\tremaining: 12.8s\n",
      "3548:\tlearn: 1.3843110\ttotal: 43.2s\tremaining: 12.8s\n",
      "3549:\tlearn: 1.3840641\ttotal: 43.2s\tremaining: 12.7s\n",
      "3550:\tlearn: 1.3839638\ttotal: 43.2s\tremaining: 12.7s\n",
      "3551:\tlearn: 1.3838376\ttotal: 43.2s\tremaining: 12.7s\n",
      "3552:\tlearn: 1.3835711\ttotal: 43.2s\tremaining: 12.7s\n",
      "3553:\tlearn: 1.3833249\ttotal: 43.2s\tremaining: 12.7s\n",
      "3554:\tlearn: 1.3831930\ttotal: 43.2s\tremaining: 12.7s\n",
      "3555:\tlearn: 1.3829824\ttotal: 43.2s\tremaining: 12.7s\n",
      "3556:\tlearn: 1.3828825\ttotal: 43.3s\tremaining: 12.7s\n",
      "3557:\tlearn: 1.3827224\ttotal: 43.3s\tremaining: 12.6s\n",
      "3558:\tlearn: 1.3820523\ttotal: 43.3s\tremaining: 12.6s\n",
      "3559:\tlearn: 1.3817926\ttotal: 43.3s\tremaining: 12.6s\n",
      "3560:\tlearn: 1.3816884\ttotal: 43.3s\tremaining: 12.6s\n",
      "3561:\tlearn: 1.3812959\ttotal: 43.3s\tremaining: 12.6s\n",
      "3562:\tlearn: 1.3811094\ttotal: 43.3s\tremaining: 12.6s\n",
      "3563:\tlearn: 1.3809354\ttotal: 43.3s\tremaining: 12.6s\n",
      "3564:\tlearn: 1.3806461\ttotal: 43.4s\tremaining: 12.6s\n",
      "3565:\tlearn: 1.3803777\ttotal: 43.4s\tremaining: 12.6s\n",
      "3566:\tlearn: 1.3802419\ttotal: 43.4s\tremaining: 12.5s\n",
      "3567:\tlearn: 1.3800380\ttotal: 43.4s\tremaining: 12.5s\n",
      "3568:\tlearn: 1.3798507\ttotal: 43.4s\tremaining: 12.5s\n",
      "3569:\tlearn: 1.3796198\ttotal: 43.4s\tremaining: 12.5s\n",
      "3570:\tlearn: 1.3794248\ttotal: 43.4s\tremaining: 12.5s\n",
      "3571:\tlearn: 1.3792609\ttotal: 43.4s\tremaining: 12.5s\n",
      "3572:\tlearn: 1.3791093\ttotal: 43.5s\tremaining: 12.5s\n",
      "3573:\tlearn: 1.3788335\ttotal: 43.5s\tremaining: 12.5s\n",
      "3574:\tlearn: 1.3786849\ttotal: 43.5s\tremaining: 12.4s\n",
      "3575:\tlearn: 1.3784682\ttotal: 43.5s\tremaining: 12.4s\n",
      "3576:\tlearn: 1.3781185\ttotal: 43.5s\tremaining: 12.4s\n",
      "3577:\tlearn: 1.3779208\ttotal: 43.5s\tremaining: 12.4s\n",
      "3578:\tlearn: 1.3776579\ttotal: 43.5s\tremaining: 12.4s\n",
      "3579:\tlearn: 1.3773333\ttotal: 43.5s\tremaining: 12.4s\n",
      "3580:\tlearn: 1.3771854\ttotal: 43.6s\tremaining: 12.4s\n",
      "3581:\tlearn: 1.3771208\ttotal: 43.6s\tremaining: 12.4s\n",
      "3582:\tlearn: 1.3768624\ttotal: 43.6s\tremaining: 12.3s\n",
      "3583:\tlearn: 1.3767153\ttotal: 43.6s\tremaining: 12.3s\n",
      "3584:\tlearn: 1.3765110\ttotal: 43.6s\tremaining: 12.3s\n",
      "3585:\tlearn: 1.3763669\ttotal: 43.6s\tremaining: 12.3s\n",
      "3586:\tlearn: 1.3762716\ttotal: 43.6s\tremaining: 12.3s\n",
      "3587:\tlearn: 1.3759621\ttotal: 43.6s\tremaining: 12.3s\n",
      "3588:\tlearn: 1.3756139\ttotal: 43.7s\tremaining: 12.3s\n",
      "3589:\tlearn: 1.3753872\ttotal: 43.7s\tremaining: 12.3s\n",
      "3590:\tlearn: 1.3751125\ttotal: 43.7s\tremaining: 12.2s\n",
      "3591:\tlearn: 1.3749376\ttotal: 43.7s\tremaining: 12.2s\n",
      "3592:\tlearn: 1.3746957\ttotal: 43.7s\tremaining: 12.2s\n",
      "3593:\tlearn: 1.3744100\ttotal: 43.7s\tremaining: 12.2s\n",
      "3594:\tlearn: 1.3742051\ttotal: 43.7s\tremaining: 12.2s\n",
      "3595:\tlearn: 1.3739947\ttotal: 43.7s\tremaining: 12.2s\n",
      "3596:\tlearn: 1.3737109\ttotal: 43.8s\tremaining: 12.2s\n",
      "3597:\tlearn: 1.3735675\ttotal: 43.8s\tremaining: 12.2s\n",
      "3598:\tlearn: 1.3735028\ttotal: 43.8s\tremaining: 12.2s\n",
      "3599:\tlearn: 1.3733338\ttotal: 43.8s\tremaining: 12.1s\n",
      "3600:\tlearn: 1.3732367\ttotal: 43.8s\tremaining: 12.1s\n",
      "3601:\tlearn: 1.3729583\ttotal: 43.8s\tremaining: 12.1s\n",
      "3602:\tlearn: 1.3728007\ttotal: 43.8s\tremaining: 12.1s\n",
      "3603:\tlearn: 1.3725175\ttotal: 43.8s\tremaining: 12.1s\n",
      "3604:\tlearn: 1.3722372\ttotal: 43.9s\tremaining: 12.1s\n",
      "3605:\tlearn: 1.3721254\ttotal: 43.9s\tremaining: 12.1s\n",
      "3606:\tlearn: 1.3719322\ttotal: 43.9s\tremaining: 12.1s\n",
      "3607:\tlearn: 1.3717514\ttotal: 43.9s\tremaining: 12s\n",
      "3608:\tlearn: 1.3714998\ttotal: 43.9s\tremaining: 12s\n",
      "3609:\tlearn: 1.3713668\ttotal: 43.9s\tremaining: 12s\n",
      "3610:\tlearn: 1.3710538\ttotal: 43.9s\tremaining: 12s\n",
      "3611:\tlearn: 1.3708571\ttotal: 43.9s\tremaining: 12s\n",
      "3612:\tlearn: 1.3706484\ttotal: 44s\tremaining: 12s\n",
      "3613:\tlearn: 1.3705223\ttotal: 44s\tremaining: 12s\n",
      "3614:\tlearn: 1.3702514\ttotal: 44s\tremaining: 12s\n",
      "3615:\tlearn: 1.3701340\ttotal: 44s\tremaining: 11.9s\n",
      "3616:\tlearn: 1.3698759\ttotal: 44s\tremaining: 11.9s\n",
      "3617:\tlearn: 1.3697746\ttotal: 44s\tremaining: 11.9s\n",
      "3618:\tlearn: 1.3692665\ttotal: 44s\tremaining: 11.9s\n",
      "3619:\tlearn: 1.3690523\ttotal: 44s\tremaining: 11.9s\n",
      "3620:\tlearn: 1.3688533\ttotal: 44.1s\tremaining: 11.9s\n",
      "3621:\tlearn: 1.3685238\ttotal: 44.1s\tremaining: 11.9s\n",
      "3622:\tlearn: 1.3682918\ttotal: 44.1s\tremaining: 11.9s\n",
      "3623:\tlearn: 1.3680213\ttotal: 44.1s\tremaining: 11.8s\n",
      "3624:\tlearn: 1.3679185\ttotal: 44.1s\tremaining: 11.8s\n",
      "3625:\tlearn: 1.3676705\ttotal: 44.1s\tremaining: 11.8s\n",
      "3626:\tlearn: 1.3674840\ttotal: 44.1s\tremaining: 11.8s\n",
      "3627:\tlearn: 1.3671234\ttotal: 44.1s\tremaining: 11.8s\n",
      "3628:\tlearn: 1.3669373\ttotal: 44.2s\tremaining: 11.8s\n",
      "3629:\tlearn: 1.3667302\ttotal: 44.2s\tremaining: 11.8s\n",
      "3630:\tlearn: 1.3664886\ttotal: 44.2s\tremaining: 11.8s\n",
      "3631:\tlearn: 1.3663225\ttotal: 44.2s\tremaining: 11.8s\n",
      "3632:\tlearn: 1.3661060\ttotal: 44.2s\tremaining: 11.7s\n",
      "3633:\tlearn: 1.3658078\ttotal: 44.2s\tremaining: 11.7s\n",
      "3634:\tlearn: 1.3655614\ttotal: 44.2s\tremaining: 11.7s\n",
      "3635:\tlearn: 1.3654520\ttotal: 44.2s\tremaining: 11.7s\n",
      "3636:\tlearn: 1.3653397\ttotal: 44.2s\tremaining: 11.7s\n",
      "3637:\tlearn: 1.3652362\ttotal: 44.3s\tremaining: 11.7s\n",
      "3638:\tlearn: 1.3650424\ttotal: 44.3s\tremaining: 11.7s\n",
      "3639:\tlearn: 1.3649453\ttotal: 44.3s\tremaining: 11.7s\n",
      "3640:\tlearn: 1.3645592\ttotal: 44.3s\tremaining: 11.6s\n",
      "3641:\tlearn: 1.3643043\ttotal: 44.3s\tremaining: 11.6s\n",
      "3642:\tlearn: 1.3641636\ttotal: 44.3s\tremaining: 11.6s\n",
      "3643:\tlearn: 1.3639135\ttotal: 44.3s\tremaining: 11.6s\n",
      "3644:\tlearn: 1.3637315\ttotal: 44.3s\tremaining: 11.6s\n",
      "3645:\tlearn: 1.3635286\ttotal: 44.4s\tremaining: 11.6s\n",
      "3646:\tlearn: 1.3634309\ttotal: 44.4s\tremaining: 11.6s\n",
      "3647:\tlearn: 1.3632676\ttotal: 44.4s\tremaining: 11.6s\n",
      "3648:\tlearn: 1.3630059\ttotal: 44.4s\tremaining: 11.5s\n",
      "3649:\tlearn: 1.3628833\ttotal: 44.4s\tremaining: 11.5s\n",
      "3650:\tlearn: 1.3627232\ttotal: 44.4s\tremaining: 11.5s\n",
      "3651:\tlearn: 1.3626240\ttotal: 44.4s\tremaining: 11.5s\n",
      "3652:\tlearn: 1.3624968\ttotal: 44.4s\tremaining: 11.5s\n",
      "3653:\tlearn: 1.3623522\ttotal: 44.5s\tremaining: 11.5s\n",
      "3654:\tlearn: 1.3621199\ttotal: 44.5s\tremaining: 11.5s\n",
      "3655:\tlearn: 1.3618366\ttotal: 44.5s\tremaining: 11.5s\n",
      "3656:\tlearn: 1.3615197\ttotal: 44.5s\tremaining: 11.4s\n",
      "3657:\tlearn: 1.3612076\ttotal: 44.5s\tremaining: 11.4s\n",
      "3658:\tlearn: 1.3609929\ttotal: 44.5s\tremaining: 11.4s\n",
      "3659:\tlearn: 1.3606959\ttotal: 44.5s\tremaining: 11.4s\n",
      "3660:\tlearn: 1.3605116\ttotal: 44.5s\tremaining: 11.4s\n",
      "3661:\tlearn: 1.3602870\ttotal: 44.6s\tremaining: 11.4s\n",
      "3662:\tlearn: 1.3600711\ttotal: 44.6s\tremaining: 11.4s\n",
      "3663:\tlearn: 1.3599102\ttotal: 44.6s\tremaining: 11.4s\n",
      "3664:\tlearn: 1.3598098\ttotal: 44.6s\tremaining: 11.4s\n",
      "3665:\tlearn: 1.3595260\ttotal: 44.6s\tremaining: 11.3s\n",
      "3666:\tlearn: 1.3594214\ttotal: 44.6s\tremaining: 11.3s\n",
      "3667:\tlearn: 1.3592910\ttotal: 44.6s\tremaining: 11.3s\n",
      "3668:\tlearn: 1.3590777\ttotal: 44.6s\tremaining: 11.3s\n",
      "3669:\tlearn: 1.3590061\ttotal: 44.7s\tremaining: 11.3s\n",
      "3670:\tlearn: 1.3589195\ttotal: 44.7s\tremaining: 11.3s\n",
      "3671:\tlearn: 1.3588300\ttotal: 44.7s\tremaining: 11.3s\n",
      "3672:\tlearn: 1.3586781\ttotal: 44.7s\tremaining: 11.3s\n",
      "3673:\tlearn: 1.3585486\ttotal: 44.7s\tremaining: 11.2s\n",
      "3674:\tlearn: 1.3583620\ttotal: 44.7s\tremaining: 11.2s\n",
      "3675:\tlearn: 1.3581819\ttotal: 44.7s\tremaining: 11.2s\n",
      "3676:\tlearn: 1.3579702\ttotal: 44.7s\tremaining: 11.2s\n",
      "3677:\tlearn: 1.3577689\ttotal: 44.7s\tremaining: 11.2s\n",
      "3678:\tlearn: 1.3576252\ttotal: 44.8s\tremaining: 11.2s\n",
      "3679:\tlearn: 1.3575173\ttotal: 44.8s\tremaining: 11.2s\n",
      "3680:\tlearn: 1.3573200\ttotal: 44.8s\tremaining: 11.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3681:\tlearn: 1.3571198\ttotal: 44.8s\tremaining: 11.1s\n",
      "3682:\tlearn: 1.3569230\ttotal: 44.8s\tremaining: 11.1s\n",
      "3683:\tlearn: 1.3565988\ttotal: 44.8s\tremaining: 11.1s\n",
      "3684:\tlearn: 1.3565027\ttotal: 44.8s\tremaining: 11.1s\n",
      "3685:\tlearn: 1.3562563\ttotal: 44.8s\tremaining: 11.1s\n",
      "3686:\tlearn: 1.3562053\ttotal: 44.9s\tremaining: 11.1s\n",
      "3687:\tlearn: 1.3560677\ttotal: 44.9s\tremaining: 11.1s\n",
      "3688:\tlearn: 1.3560216\ttotal: 44.9s\tremaining: 11.1s\n",
      "3689:\tlearn: 1.3557555\ttotal: 44.9s\tremaining: 11s\n",
      "3690:\tlearn: 1.3556319\ttotal: 44.9s\tremaining: 11s\n",
      "3691:\tlearn: 1.3554242\ttotal: 44.9s\tremaining: 11s\n",
      "3692:\tlearn: 1.3552691\ttotal: 44.9s\tremaining: 11s\n",
      "3693:\tlearn: 1.3551221\ttotal: 44.9s\tremaining: 11s\n",
      "3694:\tlearn: 1.3549785\ttotal: 44.9s\tremaining: 11s\n",
      "3695:\tlearn: 1.3548079\ttotal: 45s\tremaining: 11s\n",
      "3696:\tlearn: 1.3545953\ttotal: 45s\tremaining: 11s\n",
      "3697:\tlearn: 1.3542903\ttotal: 45s\tremaining: 10.9s\n",
      "3698:\tlearn: 1.3541009\ttotal: 45s\tremaining: 10.9s\n",
      "3699:\tlearn: 1.3538651\ttotal: 45s\tremaining: 10.9s\n",
      "3700:\tlearn: 1.3536603\ttotal: 45s\tremaining: 10.9s\n",
      "3701:\tlearn: 1.3535232\ttotal: 45s\tremaining: 10.9s\n",
      "3702:\tlearn: 1.3530794\ttotal: 45s\tremaining: 10.9s\n",
      "3703:\tlearn: 1.3529599\ttotal: 45.1s\tremaining: 10.9s\n",
      "3704:\tlearn: 1.3527689\ttotal: 45.1s\tremaining: 10.9s\n",
      "3705:\tlearn: 1.3525429\ttotal: 45.1s\tremaining: 10.9s\n",
      "3706:\tlearn: 1.3524084\ttotal: 45.1s\tremaining: 10.8s\n",
      "3707:\tlearn: 1.3522202\ttotal: 45.1s\tremaining: 10.8s\n",
      "3708:\tlearn: 1.3519545\ttotal: 45.1s\tremaining: 10.8s\n",
      "3709:\tlearn: 1.3517352\ttotal: 45.1s\tremaining: 10.8s\n",
      "3710:\tlearn: 1.3513780\ttotal: 45.1s\tremaining: 10.8s\n",
      "3711:\tlearn: 1.3510792\ttotal: 45.2s\tremaining: 10.8s\n",
      "3712:\tlearn: 1.3509016\ttotal: 45.2s\tremaining: 10.8s\n",
      "3713:\tlearn: 1.3504787\ttotal: 45.2s\tremaining: 10.8s\n",
      "3714:\tlearn: 1.3502648\ttotal: 45.2s\tremaining: 10.7s\n",
      "3715:\tlearn: 1.3501435\ttotal: 45.2s\tremaining: 10.7s\n",
      "3716:\tlearn: 1.3499353\ttotal: 45.2s\tremaining: 10.7s\n",
      "3717:\tlearn: 1.3497458\ttotal: 45.2s\tremaining: 10.7s\n",
      "3718:\tlearn: 1.3495516\ttotal: 45.3s\tremaining: 10.7s\n",
      "3719:\tlearn: 1.3494046\ttotal: 45.3s\tremaining: 10.7s\n",
      "3720:\tlearn: 1.3492046\ttotal: 45.3s\tremaining: 10.7s\n",
      "3721:\tlearn: 1.3490689\ttotal: 45.3s\tremaining: 10.7s\n",
      "3722:\tlearn: 1.3488652\ttotal: 45.3s\tremaining: 10.6s\n",
      "3723:\tlearn: 1.3484601\ttotal: 45.3s\tremaining: 10.6s\n",
      "3724:\tlearn: 1.3481693\ttotal: 45.3s\tremaining: 10.6s\n",
      "3725:\tlearn: 1.3481239\ttotal: 45.3s\tremaining: 10.6s\n",
      "3726:\tlearn: 1.3479254\ttotal: 45.3s\tremaining: 10.6s\n",
      "3727:\tlearn: 1.3476838\ttotal: 45.4s\tremaining: 10.6s\n",
      "3728:\tlearn: 1.3475347\ttotal: 45.4s\tremaining: 10.6s\n",
      "3729:\tlearn: 1.3473304\ttotal: 45.4s\tremaining: 10.6s\n",
      "3730:\tlearn: 1.3472154\ttotal: 45.4s\tremaining: 10.5s\n",
      "3731:\tlearn: 1.3470479\ttotal: 45.4s\tremaining: 10.5s\n",
      "3732:\tlearn: 1.3468462\ttotal: 45.4s\tremaining: 10.5s\n",
      "3733:\tlearn: 1.3466124\ttotal: 45.4s\tremaining: 10.5s\n",
      "3734:\tlearn: 1.3464453\ttotal: 45.4s\tremaining: 10.5s\n",
      "3735:\tlearn: 1.3463628\ttotal: 45.5s\tremaining: 10.5s\n",
      "3736:\tlearn: 1.3461568\ttotal: 45.5s\tremaining: 10.5s\n",
      "3737:\tlearn: 1.3459171\ttotal: 45.5s\tremaining: 10.5s\n",
      "3738:\tlearn: 1.3458803\ttotal: 45.5s\tremaining: 10.5s\n",
      "3739:\tlearn: 1.3456897\ttotal: 45.5s\tremaining: 10.4s\n",
      "3740:\tlearn: 1.3454046\ttotal: 45.5s\tremaining: 10.4s\n",
      "3741:\tlearn: 1.3453610\ttotal: 45.5s\tremaining: 10.4s\n",
      "3742:\tlearn: 1.3450986\ttotal: 45.5s\tremaining: 10.4s\n",
      "3743:\tlearn: 1.3448414\ttotal: 45.6s\tremaining: 10.4s\n",
      "3744:\tlearn: 1.3446959\ttotal: 45.6s\tremaining: 10.4s\n",
      "3745:\tlearn: 1.3444780\ttotal: 45.6s\tremaining: 10.4s\n",
      "3746:\tlearn: 1.3442569\ttotal: 45.6s\tremaining: 10.4s\n",
      "3747:\tlearn: 1.3439771\ttotal: 45.6s\tremaining: 10.3s\n",
      "3748:\tlearn: 1.3438655\ttotal: 45.6s\tremaining: 10.3s\n",
      "3749:\tlearn: 1.3436606\ttotal: 45.6s\tremaining: 10.3s\n",
      "3750:\tlearn: 1.3435123\ttotal: 45.6s\tremaining: 10.3s\n",
      "3751:\tlearn: 1.3433147\ttotal: 45.7s\tremaining: 10.3s\n",
      "3752:\tlearn: 1.3429773\ttotal: 45.7s\tremaining: 10.3s\n",
      "3753:\tlearn: 1.3428924\ttotal: 45.7s\tremaining: 10.3s\n",
      "3754:\tlearn: 1.3427481\ttotal: 45.7s\tremaining: 10.3s\n",
      "3755:\tlearn: 1.3425639\ttotal: 45.7s\tremaining: 10.2s\n",
      "3756:\tlearn: 1.3424677\ttotal: 45.7s\tremaining: 10.2s\n",
      "3757:\tlearn: 1.3423397\ttotal: 45.7s\tremaining: 10.2s\n",
      "3758:\tlearn: 1.3422045\ttotal: 45.7s\tremaining: 10.2s\n",
      "3759:\tlearn: 1.3420796\ttotal: 45.8s\tremaining: 10.2s\n",
      "3760:\tlearn: 1.3419654\ttotal: 45.8s\tremaining: 10.2s\n",
      "3761:\tlearn: 1.3417675\ttotal: 45.8s\tremaining: 10.2s\n",
      "3762:\tlearn: 1.3415939\ttotal: 45.8s\tremaining: 10.2s\n",
      "3763:\tlearn: 1.3413306\ttotal: 45.8s\tremaining: 10.1s\n",
      "3764:\tlearn: 1.3412111\ttotal: 45.8s\tremaining: 10.1s\n",
      "3765:\tlearn: 1.3410588\ttotal: 45.8s\tremaining: 10.1s\n",
      "3766:\tlearn: 1.3409845\ttotal: 45.8s\tremaining: 10.1s\n",
      "3767:\tlearn: 1.3408219\ttotal: 45.8s\tremaining: 10.1s\n",
      "3768:\tlearn: 1.3406399\ttotal: 45.9s\tremaining: 10.1s\n",
      "3769:\tlearn: 1.3398295\ttotal: 45.9s\tremaining: 10.1s\n",
      "3770:\tlearn: 1.3396688\ttotal: 45.9s\tremaining: 10.1s\n",
      "3771:\tlearn: 1.3395549\ttotal: 45.9s\tremaining: 10.1s\n",
      "3772:\tlearn: 1.3392569\ttotal: 45.9s\tremaining: 10s\n",
      "3773:\tlearn: 1.3391665\ttotal: 45.9s\tremaining: 10s\n",
      "3774:\tlearn: 1.3389541\ttotal: 45.9s\tremaining: 10s\n",
      "3775:\tlearn: 1.3386213\ttotal: 45.9s\tremaining: 10s\n",
      "3776:\tlearn: 1.3384902\ttotal: 46s\tremaining: 9.99s\n",
      "3777:\tlearn: 1.3382919\ttotal: 46s\tremaining: 9.98s\n",
      "3778:\tlearn: 1.3381858\ttotal: 46s\tremaining: 9.96s\n",
      "3779:\tlearn: 1.3381722\ttotal: 46s\tremaining: 9.95s\n",
      "3780:\tlearn: 1.3380266\ttotal: 46s\tremaining: 9.94s\n",
      "3781:\tlearn: 1.3377826\ttotal: 46s\tremaining: 9.93s\n",
      "3782:\tlearn: 1.3377250\ttotal: 46s\tremaining: 9.92s\n",
      "3783:\tlearn: 1.3373847\ttotal: 46s\tremaining: 9.9s\n",
      "3784:\tlearn: 1.3372906\ttotal: 46.1s\tremaining: 9.89s\n",
      "3785:\tlearn: 1.3372631\ttotal: 46.1s\tremaining: 9.88s\n",
      "3786:\tlearn: 1.3370760\ttotal: 46.1s\tremaining: 9.87s\n",
      "3787:\tlearn: 1.3367048\ttotal: 46.1s\tremaining: 9.86s\n",
      "3788:\tlearn: 1.3366240\ttotal: 46.1s\tremaining: 9.84s\n",
      "3789:\tlearn: 1.3363810\ttotal: 46.1s\tremaining: 9.83s\n",
      "3790:\tlearn: 1.3362329\ttotal: 46.1s\tremaining: 9.82s\n",
      "3791:\tlearn: 1.3360109\ttotal: 46.1s\tremaining: 9.81s\n",
      "3792:\tlearn: 1.3358703\ttotal: 46.2s\tremaining: 9.79s\n",
      "3793:\tlearn: 1.3356366\ttotal: 46.2s\tremaining: 9.78s\n",
      "3794:\tlearn: 1.3354643\ttotal: 46.2s\tremaining: 9.77s\n",
      "3795:\tlearn: 1.3353581\ttotal: 46.2s\tremaining: 9.76s\n",
      "3796:\tlearn: 1.3351636\ttotal: 46.2s\tremaining: 9.75s\n",
      "3797:\tlearn: 1.3349478\ttotal: 46.2s\tremaining: 9.73s\n",
      "3798:\tlearn: 1.3346873\ttotal: 46.2s\tremaining: 9.72s\n",
      "3799:\tlearn: 1.3344427\ttotal: 46.2s\tremaining: 9.71s\n",
      "3800:\tlearn: 1.3341847\ttotal: 46.3s\tremaining: 9.7s\n",
      "3801:\tlearn: 1.3339722\ttotal: 46.3s\tremaining: 9.69s\n",
      "3802:\tlearn: 1.3337037\ttotal: 46.3s\tremaining: 9.67s\n",
      "3803:\tlearn: 1.3334811\ttotal: 46.3s\tremaining: 9.66s\n",
      "3804:\tlearn: 1.3333440\ttotal: 46.3s\tremaining: 9.65s\n",
      "3805:\tlearn: 1.3331363\ttotal: 46.3s\tremaining: 9.64s\n",
      "3806:\tlearn: 1.3330526\ttotal: 46.3s\tremaining: 9.63s\n",
      "3807:\tlearn: 1.3329212\ttotal: 46.3s\tremaining: 9.61s\n",
      "3808:\tlearn: 1.3327343\ttotal: 46.3s\tremaining: 9.6s\n",
      "3809:\tlearn: 1.3325583\ttotal: 46.4s\tremaining: 9.59s\n",
      "3810:\tlearn: 1.3324221\ttotal: 46.4s\tremaining: 9.58s\n",
      "3811:\tlearn: 1.3322810\ttotal: 46.4s\tremaining: 9.56s\n",
      "3812:\tlearn: 1.3322232\ttotal: 46.4s\tremaining: 9.55s\n",
      "3813:\tlearn: 1.3319167\ttotal: 46.4s\tremaining: 9.54s\n",
      "3814:\tlearn: 1.3316573\ttotal: 46.4s\tremaining: 9.53s\n",
      "3815:\tlearn: 1.3315461\ttotal: 46.4s\tremaining: 9.51s\n",
      "3816:\tlearn: 1.3314027\ttotal: 46.4s\tremaining: 9.5s\n",
      "3817:\tlearn: 1.3312452\ttotal: 46.5s\tremaining: 9.49s\n",
      "3818:\tlearn: 1.3309626\ttotal: 46.5s\tremaining: 9.48s\n",
      "3819:\tlearn: 1.3308388\ttotal: 46.5s\tremaining: 9.46s\n",
      "3820:\tlearn: 1.3306766\ttotal: 46.5s\tremaining: 9.45s\n",
      "3821:\tlearn: 1.3304561\ttotal: 46.5s\tremaining: 9.44s\n",
      "3822:\tlearn: 1.3302471\ttotal: 46.5s\tremaining: 9.43s\n",
      "3823:\tlearn: 1.3300649\ttotal: 46.5s\tremaining: 9.42s\n",
      "3824:\tlearn: 1.3299489\ttotal: 46.5s\tremaining: 9.4s\n",
      "3825:\tlearn: 1.3297034\ttotal: 46.6s\tremaining: 9.39s\n",
      "3826:\tlearn: 1.3294623\ttotal: 46.6s\tremaining: 9.38s\n",
      "3827:\tlearn: 1.3293870\ttotal: 46.6s\tremaining: 9.37s\n",
      "3828:\tlearn: 1.3293321\ttotal: 46.6s\tremaining: 9.36s\n",
      "3829:\tlearn: 1.3291266\ttotal: 46.6s\tremaining: 9.34s\n",
      "3830:\tlearn: 1.3288585\ttotal: 46.6s\tremaining: 9.33s\n",
      "3831:\tlearn: 1.3286968\ttotal: 46.6s\tremaining: 9.32s\n",
      "3832:\tlearn: 1.3284358\ttotal: 46.6s\tremaining: 9.31s\n",
      "3833:\tlearn: 1.3281005\ttotal: 46.6s\tremaining: 9.29s\n",
      "3834:\tlearn: 1.3279108\ttotal: 46.7s\tremaining: 9.28s\n",
      "3835:\tlearn: 1.3277845\ttotal: 46.7s\tremaining: 9.27s\n",
      "3836:\tlearn: 1.3275548\ttotal: 46.7s\tremaining: 9.26s\n",
      "3837:\tlearn: 1.3273352\ttotal: 46.7s\tremaining: 9.25s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3838:\tlearn: 1.3272416\ttotal: 46.7s\tremaining: 9.23s\n",
      "3839:\tlearn: 1.3272072\ttotal: 46.7s\tremaining: 9.22s\n",
      "3840:\tlearn: 1.3270713\ttotal: 46.7s\tremaining: 9.21s\n",
      "3841:\tlearn: 1.3266436\ttotal: 46.7s\tremaining: 9.2s\n",
      "3842:\tlearn: 1.3265000\ttotal: 46.8s\tremaining: 9.19s\n",
      "3843:\tlearn: 1.3263317\ttotal: 46.8s\tremaining: 9.17s\n",
      "3844:\tlearn: 1.3260804\ttotal: 46.8s\tremaining: 9.16s\n",
      "3845:\tlearn: 1.3260041\ttotal: 46.8s\tremaining: 9.15s\n",
      "3846:\tlearn: 1.3258179\ttotal: 46.8s\tremaining: 9.14s\n",
      "3847:\tlearn: 1.3256239\ttotal: 46.8s\tremaining: 9.13s\n",
      "3848:\tlearn: 1.3253571\ttotal: 46.8s\tremaining: 9.11s\n",
      "3849:\tlearn: 1.3252336\ttotal: 46.8s\tremaining: 9.1s\n",
      "3850:\tlearn: 1.3251140\ttotal: 46.9s\tremaining: 9.09s\n",
      "3851:\tlearn: 1.3248880\ttotal: 46.9s\tremaining: 9.08s\n",
      "3852:\tlearn: 1.3246747\ttotal: 46.9s\tremaining: 9.06s\n",
      "3853:\tlearn: 1.3242145\ttotal: 46.9s\tremaining: 9.05s\n",
      "3854:\tlearn: 1.3239600\ttotal: 46.9s\tremaining: 9.04s\n",
      "3855:\tlearn: 1.3237973\ttotal: 46.9s\tremaining: 9.03s\n",
      "3856:\tlearn: 1.3235892\ttotal: 46.9s\tremaining: 9.02s\n",
      "3857:\tlearn: 1.3234146\ttotal: 46.9s\tremaining: 9s\n",
      "3858:\tlearn: 1.3231820\ttotal: 47s\tremaining: 8.99s\n",
      "3859:\tlearn: 1.3229903\ttotal: 47s\tremaining: 8.98s\n",
      "3860:\tlearn: 1.3227891\ttotal: 47s\tremaining: 8.97s\n",
      "3861:\tlearn: 1.3225158\ttotal: 47s\tremaining: 8.96s\n",
      "3862:\tlearn: 1.3223061\ttotal: 47s\tremaining: 8.94s\n",
      "3863:\tlearn: 1.3219479\ttotal: 47s\tremaining: 8.93s\n",
      "3864:\tlearn: 1.3217471\ttotal: 47s\tremaining: 8.92s\n",
      "3865:\tlearn: 1.3216045\ttotal: 47s\tremaining: 8.91s\n",
      "3866:\tlearn: 1.3215177\ttotal: 47.1s\tremaining: 8.89s\n",
      "3867:\tlearn: 1.3213473\ttotal: 47.1s\tremaining: 8.88s\n",
      "3868:\tlearn: 1.3213093\ttotal: 47.1s\tremaining: 8.87s\n",
      "3869:\tlearn: 1.3210913\ttotal: 47.1s\tremaining: 8.86s\n",
      "3870:\tlearn: 1.3208180\ttotal: 47.1s\tremaining: 8.85s\n",
      "3871:\tlearn: 1.3206242\ttotal: 47.1s\tremaining: 8.83s\n",
      "3872:\tlearn: 1.3205049\ttotal: 47.1s\tremaining: 8.82s\n",
      "3873:\tlearn: 1.3202732\ttotal: 47.1s\tremaining: 8.81s\n",
      "3874:\tlearn: 1.3200577\ttotal: 47.2s\tremaining: 8.8s\n",
      "3875:\tlearn: 1.3197352\ttotal: 47.2s\tremaining: 8.79s\n",
      "3876:\tlearn: 1.3195174\ttotal: 47.2s\tremaining: 8.77s\n",
      "3877:\tlearn: 1.3193799\ttotal: 47.2s\tremaining: 8.76s\n",
      "3878:\tlearn: 1.3193037\ttotal: 47.2s\tremaining: 8.75s\n",
      "3879:\tlearn: 1.3190405\ttotal: 47.2s\tremaining: 8.74s\n",
      "3880:\tlearn: 1.3186834\ttotal: 47.2s\tremaining: 8.72s\n",
      "3881:\tlearn: 1.3185360\ttotal: 47.2s\tremaining: 8.71s\n",
      "3882:\tlearn: 1.3183061\ttotal: 47.3s\tremaining: 8.7s\n",
      "3883:\tlearn: 1.3181313\ttotal: 47.3s\tremaining: 8.69s\n",
      "3884:\tlearn: 1.3180877\ttotal: 47.3s\tremaining: 8.68s\n",
      "3885:\tlearn: 1.3178937\ttotal: 47.3s\tremaining: 8.66s\n",
      "3886:\tlearn: 1.3177642\ttotal: 47.3s\tremaining: 8.65s\n",
      "3887:\tlearn: 1.3175318\ttotal: 47.3s\tremaining: 8.64s\n",
      "3888:\tlearn: 1.3174073\ttotal: 47.3s\tremaining: 8.63s\n",
      "3889:\tlearn: 1.3172268\ttotal: 47.3s\tremaining: 8.62s\n",
      "3890:\tlearn: 1.3170147\ttotal: 47.3s\tremaining: 8.6s\n",
      "3891:\tlearn: 1.3169060\ttotal: 47.4s\tremaining: 8.59s\n",
      "3892:\tlearn: 1.3166823\ttotal: 47.4s\tremaining: 8.58s\n",
      "3893:\tlearn: 1.3165307\ttotal: 47.4s\tremaining: 8.57s\n",
      "3894:\tlearn: 1.3164168\ttotal: 47.4s\tremaining: 8.55s\n",
      "3895:\tlearn: 1.3162818\ttotal: 47.4s\tremaining: 8.54s\n",
      "3896:\tlearn: 1.3160831\ttotal: 47.4s\tremaining: 8.53s\n",
      "3897:\tlearn: 1.3159462\ttotal: 47.4s\tremaining: 8.52s\n",
      "3898:\tlearn: 1.3158345\ttotal: 47.4s\tremaining: 8.51s\n",
      "3899:\tlearn: 1.3157550\ttotal: 47.5s\tremaining: 8.49s\n",
      "3900:\tlearn: 1.3155430\ttotal: 47.5s\tremaining: 8.48s\n",
      "3901:\tlearn: 1.3153232\ttotal: 47.5s\tremaining: 8.47s\n",
      "3902:\tlearn: 1.3152773\ttotal: 47.5s\tremaining: 8.46s\n",
      "3903:\tlearn: 1.3151509\ttotal: 47.5s\tremaining: 8.44s\n",
      "3904:\tlearn: 1.3148825\ttotal: 47.5s\tremaining: 8.43s\n",
      "3905:\tlearn: 1.3147529\ttotal: 47.5s\tremaining: 8.42s\n",
      "3906:\tlearn: 1.3143948\ttotal: 47.5s\tremaining: 8.41s\n",
      "3907:\tlearn: 1.3141733\ttotal: 47.6s\tremaining: 8.4s\n",
      "3908:\tlearn: 1.3140789\ttotal: 47.6s\tremaining: 8.38s\n",
      "3909:\tlearn: 1.3139502\ttotal: 47.6s\tremaining: 8.37s\n",
      "3910:\tlearn: 1.3138506\ttotal: 47.6s\tremaining: 8.36s\n",
      "3911:\tlearn: 1.3137701\ttotal: 47.6s\tremaining: 8.35s\n",
      "3912:\tlearn: 1.3133912\ttotal: 47.6s\tremaining: 8.34s\n",
      "3913:\tlearn: 1.3132342\ttotal: 47.6s\tremaining: 8.32s\n",
      "3914:\tlearn: 1.3131158\ttotal: 47.6s\tremaining: 8.31s\n",
      "3915:\tlearn: 1.3129823\ttotal: 47.7s\tremaining: 8.3s\n",
      "3916:\tlearn: 1.3128254\ttotal: 47.7s\tremaining: 8.29s\n",
      "3917:\tlearn: 1.3126932\ttotal: 47.7s\tremaining: 8.27s\n",
      "3918:\tlearn: 1.3125279\ttotal: 47.7s\tremaining: 8.26s\n",
      "3919:\tlearn: 1.3123829\ttotal: 47.7s\tremaining: 8.25s\n",
      "3920:\tlearn: 1.3122514\ttotal: 47.7s\tremaining: 8.24s\n",
      "3921:\tlearn: 1.3120350\ttotal: 47.7s\tremaining: 8.22s\n",
      "3922:\tlearn: 1.3118987\ttotal: 47.7s\tremaining: 8.21s\n",
      "3923:\tlearn: 1.3116952\ttotal: 47.7s\tremaining: 8.2s\n",
      "3924:\tlearn: 1.3115530\ttotal: 47.8s\tremaining: 8.19s\n",
      "3925:\tlearn: 1.3114863\ttotal: 47.8s\tremaining: 8.18s\n",
      "3926:\tlearn: 1.3113167\ttotal: 47.8s\tremaining: 8.16s\n",
      "3927:\tlearn: 1.3111350\ttotal: 47.8s\tremaining: 8.15s\n",
      "3928:\tlearn: 1.3109393\ttotal: 47.8s\tremaining: 8.14s\n",
      "3929:\tlearn: 1.3107186\ttotal: 47.8s\tremaining: 8.13s\n",
      "3930:\tlearn: 1.3105367\ttotal: 47.8s\tremaining: 8.12s\n",
      "3931:\tlearn: 1.3104837\ttotal: 47.8s\tremaining: 8.1s\n",
      "3932:\tlearn: 1.3102043\ttotal: 47.9s\tremaining: 8.09s\n",
      "3933:\tlearn: 1.3100462\ttotal: 47.9s\tremaining: 8.08s\n",
      "3934:\tlearn: 1.3099128\ttotal: 47.9s\tremaining: 8.07s\n",
      "3935:\tlearn: 1.3097827\ttotal: 47.9s\tremaining: 8.05s\n",
      "3936:\tlearn: 1.3096178\ttotal: 47.9s\tremaining: 8.04s\n",
      "3937:\tlearn: 1.3093800\ttotal: 47.9s\tremaining: 8.03s\n",
      "3938:\tlearn: 1.3092195\ttotal: 47.9s\tremaining: 8.02s\n",
      "3939:\tlearn: 1.3090984\ttotal: 47.9s\tremaining: 8.01s\n",
      "3940:\tlearn: 1.3088145\ttotal: 48s\tremaining: 7.99s\n",
      "3941:\tlearn: 1.3087036\ttotal: 48s\tremaining: 7.98s\n",
      "3942:\tlearn: 1.3085505\ttotal: 48s\tremaining: 7.97s\n",
      "3943:\tlearn: 1.3084437\ttotal: 48s\tremaining: 7.96s\n",
      "3944:\tlearn: 1.3082377\ttotal: 48s\tremaining: 7.95s\n",
      "3945:\tlearn: 1.3081009\ttotal: 48s\tremaining: 7.93s\n",
      "3946:\tlearn: 1.3079065\ttotal: 48s\tremaining: 7.92s\n",
      "3947:\tlearn: 1.3076350\ttotal: 48s\tremaining: 7.91s\n",
      "3948:\tlearn: 1.3074262\ttotal: 48.1s\tremaining: 7.9s\n",
      "3949:\tlearn: 1.3073016\ttotal: 48.1s\tremaining: 7.88s\n",
      "3950:\tlearn: 1.3070677\ttotal: 48.1s\tremaining: 7.87s\n",
      "3951:\tlearn: 1.3069888\ttotal: 48.1s\tremaining: 7.86s\n",
      "3952:\tlearn: 1.3068574\ttotal: 48.1s\tremaining: 7.85s\n",
      "3953:\tlearn: 1.3067460\ttotal: 48.1s\tremaining: 7.83s\n",
      "3954:\tlearn: 1.3065780\ttotal: 48.1s\tremaining: 7.82s\n",
      "3955:\tlearn: 1.3063861\ttotal: 48.1s\tremaining: 7.81s\n",
      "3956:\tlearn: 1.3062822\ttotal: 48.1s\tremaining: 7.8s\n",
      "3957:\tlearn: 1.3058339\ttotal: 48.2s\tremaining: 7.79s\n",
      "3958:\tlearn: 1.3057355\ttotal: 48.2s\tremaining: 7.77s\n",
      "3959:\tlearn: 1.3055856\ttotal: 48.2s\tremaining: 7.76s\n",
      "3960:\tlearn: 1.3054433\ttotal: 48.2s\tremaining: 7.75s\n",
      "3961:\tlearn: 1.3052669\ttotal: 48.2s\tremaining: 7.74s\n",
      "3962:\tlearn: 1.3049810\ttotal: 48.2s\tremaining: 7.72s\n",
      "3963:\tlearn: 1.3049063\ttotal: 48.2s\tremaining: 7.71s\n",
      "3964:\tlearn: 1.3046225\ttotal: 48.2s\tremaining: 7.7s\n",
      "3965:\tlearn: 1.3045240\ttotal: 48.3s\tremaining: 7.69s\n",
      "3966:\tlearn: 1.3043543\ttotal: 48.3s\tremaining: 7.68s\n",
      "3967:\tlearn: 1.3040555\ttotal: 48.3s\tremaining: 7.67s\n",
      "3968:\tlearn: 1.3039922\ttotal: 48.3s\tremaining: 7.65s\n",
      "3969:\tlearn: 1.3038737\ttotal: 48.3s\tremaining: 7.64s\n",
      "3970:\tlearn: 1.3037422\ttotal: 48.3s\tremaining: 7.63s\n",
      "3971:\tlearn: 1.3034861\ttotal: 48.3s\tremaining: 7.62s\n",
      "3972:\tlearn: 1.3033844\ttotal: 48.3s\tremaining: 7.6s\n",
      "3973:\tlearn: 1.3032895\ttotal: 48.3s\tremaining: 7.59s\n",
      "3974:\tlearn: 1.3031520\ttotal: 48.4s\tremaining: 7.58s\n",
      "3975:\tlearn: 1.3031012\ttotal: 48.4s\tremaining: 7.57s\n",
      "3976:\tlearn: 1.3028400\ttotal: 48.4s\tremaining: 7.55s\n",
      "3977:\tlearn: 1.3027506\ttotal: 48.4s\tremaining: 7.54s\n",
      "3978:\tlearn: 1.3026555\ttotal: 48.4s\tremaining: 7.53s\n",
      "3979:\tlearn: 1.3025317\ttotal: 48.4s\tremaining: 7.52s\n",
      "3980:\tlearn: 1.3023979\ttotal: 48.4s\tremaining: 7.5s\n",
      "3981:\tlearn: 1.3023203\ttotal: 48.4s\tremaining: 7.49s\n",
      "3982:\tlearn: 1.3020901\ttotal: 48.5s\tremaining: 7.48s\n",
      "3983:\tlearn: 1.3019838\ttotal: 48.5s\tremaining: 7.47s\n",
      "3984:\tlearn: 1.3017787\ttotal: 48.5s\tremaining: 7.46s\n",
      "3985:\tlearn: 1.3016467\ttotal: 48.5s\tremaining: 7.45s\n",
      "3986:\tlearn: 1.3014179\ttotal: 48.5s\tremaining: 7.43s\n",
      "3987:\tlearn: 1.3012733\ttotal: 48.5s\tremaining: 7.42s\n",
      "3988:\tlearn: 1.3011629\ttotal: 48.5s\tremaining: 7.41s\n",
      "3989:\tlearn: 1.3010983\ttotal: 48.5s\tremaining: 7.4s\n",
      "3990:\tlearn: 1.3008991\ttotal: 48.5s\tremaining: 7.38s\n",
      "3991:\tlearn: 1.3006964\ttotal: 48.6s\tremaining: 7.37s\n",
      "3992:\tlearn: 1.3005448\ttotal: 48.6s\tremaining: 7.36s\n",
      "3993:\tlearn: 1.3003746\ttotal: 48.6s\tremaining: 7.35s\n",
      "3994:\tlearn: 1.3001273\ttotal: 48.6s\tremaining: 7.33s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3995:\tlearn: 1.2999981\ttotal: 48.6s\tremaining: 7.32s\n",
      "3996:\tlearn: 1.2998546\ttotal: 48.6s\tremaining: 7.31s\n",
      "3997:\tlearn: 1.2997015\ttotal: 48.6s\tremaining: 7.3s\n",
      "3998:\tlearn: 1.2995105\ttotal: 48.6s\tremaining: 7.29s\n",
      "3999:\tlearn: 1.2992956\ttotal: 48.7s\tremaining: 7.27s\n",
      "4000:\tlearn: 1.2991043\ttotal: 48.7s\tremaining: 7.26s\n",
      "4001:\tlearn: 1.2988874\ttotal: 48.7s\tremaining: 7.25s\n",
      "4002:\tlearn: 1.2987445\ttotal: 48.7s\tremaining: 7.24s\n",
      "4003:\tlearn: 1.2986019\ttotal: 48.7s\tremaining: 7.23s\n",
      "4004:\tlearn: 1.2985122\ttotal: 48.7s\tremaining: 7.21s\n",
      "4005:\tlearn: 1.2983307\ttotal: 48.7s\tremaining: 7.2s\n",
      "4006:\tlearn: 1.2980528\ttotal: 48.7s\tremaining: 7.19s\n",
      "4007:\tlearn: 1.2977956\ttotal: 48.8s\tremaining: 7.18s\n",
      "4008:\tlearn: 1.2976154\ttotal: 48.8s\tremaining: 7.17s\n",
      "4009:\tlearn: 1.2975097\ttotal: 48.8s\tremaining: 7.15s\n",
      "4010:\tlearn: 1.2973310\ttotal: 48.8s\tremaining: 7.14s\n",
      "4011:\tlearn: 1.2972788\ttotal: 48.8s\tremaining: 7.13s\n",
      "4012:\tlearn: 1.2970707\ttotal: 48.8s\tremaining: 7.12s\n",
      "4013:\tlearn: 1.2966826\ttotal: 48.8s\tremaining: 7.1s\n",
      "4014:\tlearn: 1.2964190\ttotal: 48.8s\tremaining: 7.09s\n",
      "4015:\tlearn: 1.2962883\ttotal: 48.9s\tremaining: 7.08s\n",
      "4016:\tlearn: 1.2961442\ttotal: 48.9s\tremaining: 7.07s\n",
      "4017:\tlearn: 1.2960649\ttotal: 48.9s\tremaining: 7.05s\n",
      "4018:\tlearn: 1.2959345\ttotal: 48.9s\tremaining: 7.04s\n",
      "4019:\tlearn: 1.2956708\ttotal: 48.9s\tremaining: 7.03s\n",
      "4020:\tlearn: 1.2954262\ttotal: 48.9s\tremaining: 7.02s\n",
      "4021:\tlearn: 1.2952761\ttotal: 48.9s\tremaining: 7.01s\n",
      "4022:\tlearn: 1.2950270\ttotal: 48.9s\tremaining: 7s\n",
      "4023:\tlearn: 1.2949831\ttotal: 49s\tremaining: 6.98s\n",
      "4024:\tlearn: 1.2948628\ttotal: 49s\tremaining: 6.97s\n",
      "4025:\tlearn: 1.2947241\ttotal: 49s\tremaining: 6.96s\n",
      "4026:\tlearn: 1.2945559\ttotal: 49s\tremaining: 6.95s\n",
      "4027:\tlearn: 1.2944410\ttotal: 49s\tremaining: 6.93s\n",
      "4028:\tlearn: 1.2943189\ttotal: 49s\tremaining: 6.92s\n",
      "4029:\tlearn: 1.2940728\ttotal: 49s\tremaining: 6.91s\n",
      "4030:\tlearn: 1.2939621\ttotal: 49s\tremaining: 6.9s\n",
      "4031:\tlearn: 1.2937378\ttotal: 49s\tremaining: 6.88s\n",
      "4032:\tlearn: 1.2934830\ttotal: 49.1s\tremaining: 6.87s\n",
      "4033:\tlearn: 1.2932329\ttotal: 49.1s\tremaining: 6.86s\n",
      "4034:\tlearn: 1.2930753\ttotal: 49.1s\tremaining: 6.85s\n",
      "4035:\tlearn: 1.2928473\ttotal: 49.1s\tremaining: 6.84s\n",
      "4036:\tlearn: 1.2926392\ttotal: 49.1s\tremaining: 6.82s\n",
      "4037:\tlearn: 1.2925284\ttotal: 49.1s\tremaining: 6.81s\n",
      "4038:\tlearn: 1.2921765\ttotal: 49.1s\tremaining: 6.8s\n",
      "4039:\tlearn: 1.2920304\ttotal: 49.1s\tremaining: 6.79s\n",
      "4040:\tlearn: 1.2916402\ttotal: 49.2s\tremaining: 6.78s\n",
      "4041:\tlearn: 1.2914813\ttotal: 49.2s\tremaining: 6.76s\n",
      "4042:\tlearn: 1.2912000\ttotal: 49.2s\tremaining: 6.75s\n",
      "4043:\tlearn: 1.2908986\ttotal: 49.2s\tremaining: 6.74s\n",
      "4044:\tlearn: 1.2906121\ttotal: 49.2s\tremaining: 6.73s\n",
      "4045:\tlearn: 1.2904843\ttotal: 49.2s\tremaining: 6.71s\n",
      "4046:\tlearn: 1.2903073\ttotal: 49.2s\tremaining: 6.7s\n",
      "4047:\tlearn: 1.2900807\ttotal: 49.2s\tremaining: 6.69s\n",
      "4048:\tlearn: 1.2899132\ttotal: 49.3s\tremaining: 6.68s\n",
      "4049:\tlearn: 1.2897169\ttotal: 49.3s\tremaining: 6.67s\n",
      "4050:\tlearn: 1.2895080\ttotal: 49.3s\tremaining: 6.65s\n",
      "4051:\tlearn: 1.2892489\ttotal: 49.3s\tremaining: 6.64s\n",
      "4052:\tlearn: 1.2890528\ttotal: 49.3s\tremaining: 6.63s\n",
      "4053:\tlearn: 1.2888911\ttotal: 49.3s\tremaining: 6.62s\n",
      "4054:\tlearn: 1.2887703\ttotal: 49.3s\tremaining: 6.61s\n",
      "4055:\tlearn: 1.2886509\ttotal: 49.3s\tremaining: 6.59s\n",
      "4056:\tlearn: 1.2882377\ttotal: 49.4s\tremaining: 6.58s\n",
      "4057:\tlearn: 1.2881740\ttotal: 49.4s\tremaining: 6.57s\n",
      "4058:\tlearn: 1.2879550\ttotal: 49.4s\tremaining: 6.56s\n",
      "4059:\tlearn: 1.2877653\ttotal: 49.4s\tremaining: 6.54s\n",
      "4060:\tlearn: 1.2875344\ttotal: 49.4s\tremaining: 6.53s\n",
      "4061:\tlearn: 1.2873247\ttotal: 49.4s\tremaining: 6.52s\n",
      "4062:\tlearn: 1.2871561\ttotal: 49.4s\tremaining: 6.51s\n",
      "4063:\tlearn: 1.2869620\ttotal: 49.4s\tremaining: 6.5s\n",
      "4064:\tlearn: 1.2866415\ttotal: 49.5s\tremaining: 6.48s\n",
      "4065:\tlearn: 1.2864004\ttotal: 49.5s\tremaining: 6.47s\n",
      "4066:\tlearn: 1.2863222\ttotal: 49.5s\tremaining: 6.46s\n",
      "4067:\tlearn: 1.2859724\ttotal: 49.5s\tremaining: 6.45s\n",
      "4068:\tlearn: 1.2858625\ttotal: 49.5s\tremaining: 6.43s\n",
      "4069:\tlearn: 1.2857184\ttotal: 49.5s\tremaining: 6.42s\n",
      "4070:\tlearn: 1.2856001\ttotal: 49.5s\tremaining: 6.41s\n",
      "4071:\tlearn: 1.2855123\ttotal: 49.5s\tremaining: 6.4s\n",
      "4072:\tlearn: 1.2854011\ttotal: 49.6s\tremaining: 6.39s\n",
      "4073:\tlearn: 1.2851808\ttotal: 49.6s\tremaining: 6.37s\n",
      "4074:\tlearn: 1.2849641\ttotal: 49.6s\tremaining: 6.36s\n",
      "4075:\tlearn: 1.2846737\ttotal: 49.6s\tremaining: 6.35s\n",
      "4076:\tlearn: 1.2843776\ttotal: 49.6s\tremaining: 6.34s\n",
      "4077:\tlearn: 1.2842518\ttotal: 49.6s\tremaining: 6.33s\n",
      "4078:\tlearn: 1.2840814\ttotal: 49.6s\tremaining: 6.31s\n",
      "4079:\tlearn: 1.2838828\ttotal: 49.6s\tremaining: 6.3s\n",
      "4080:\tlearn: 1.2837290\ttotal: 49.6s\tremaining: 6.29s\n",
      "4081:\tlearn: 1.2834901\ttotal: 49.7s\tremaining: 6.28s\n",
      "4082:\tlearn: 1.2833631\ttotal: 49.7s\tremaining: 6.26s\n",
      "4083:\tlearn: 1.2832583\ttotal: 49.7s\tremaining: 6.25s\n",
      "4084:\tlearn: 1.2829752\ttotal: 49.7s\tremaining: 6.24s\n",
      "4085:\tlearn: 1.2828726\ttotal: 49.7s\tremaining: 6.23s\n",
      "4086:\tlearn: 1.2825001\ttotal: 49.7s\tremaining: 6.22s\n",
      "4087:\tlearn: 1.2819796\ttotal: 49.7s\tremaining: 6.21s\n",
      "4088:\tlearn: 1.2818942\ttotal: 49.7s\tremaining: 6.19s\n",
      "4089:\tlearn: 1.2817284\ttotal: 49.8s\tremaining: 6.18s\n",
      "4090:\tlearn: 1.2816391\ttotal: 49.8s\tremaining: 6.17s\n",
      "4091:\tlearn: 1.2815105\ttotal: 49.8s\tremaining: 6.16s\n",
      "4092:\tlearn: 1.2812347\ttotal: 49.8s\tremaining: 6.14s\n",
      "4093:\tlearn: 1.2811096\ttotal: 49.8s\tremaining: 6.13s\n",
      "4094:\tlearn: 1.2809472\ttotal: 49.8s\tremaining: 6.12s\n",
      "4095:\tlearn: 1.2807516\ttotal: 49.8s\tremaining: 6.11s\n",
      "4096:\tlearn: 1.2804633\ttotal: 49.8s\tremaining: 6.09s\n",
      "4097:\tlearn: 1.2798603\ttotal: 49.9s\tremaining: 6.08s\n",
      "4098:\tlearn: 1.2796001\ttotal: 49.9s\tremaining: 6.07s\n",
      "4099:\tlearn: 1.2794383\ttotal: 49.9s\tremaining: 6.06s\n",
      "4100:\tlearn: 1.2793670\ttotal: 49.9s\tremaining: 6.05s\n",
      "4101:\tlearn: 1.2791295\ttotal: 49.9s\tremaining: 6.03s\n",
      "4102:\tlearn: 1.2789866\ttotal: 49.9s\tremaining: 6.02s\n",
      "4103:\tlearn: 1.2787966\ttotal: 49.9s\tremaining: 6.01s\n",
      "4104:\tlearn: 1.2786528\ttotal: 49.9s\tremaining: 6s\n",
      "4105:\tlearn: 1.2784138\ttotal: 50s\tremaining: 5.99s\n",
      "4106:\tlearn: 1.2782883\ttotal: 50s\tremaining: 5.97s\n",
      "4107:\tlearn: 1.2781618\ttotal: 50s\tremaining: 5.96s\n",
      "4108:\tlearn: 1.2780443\ttotal: 50s\tremaining: 5.95s\n",
      "4109:\tlearn: 1.2778591\ttotal: 50s\tremaining: 5.94s\n",
      "4110:\tlearn: 1.2776026\ttotal: 50s\tremaining: 5.92s\n",
      "4111:\tlearn: 1.2773413\ttotal: 50s\tremaining: 5.91s\n",
      "4112:\tlearn: 1.2772328\ttotal: 50s\tremaining: 5.9s\n",
      "4113:\tlearn: 1.2771042\ttotal: 50.1s\tremaining: 5.89s\n",
      "4114:\tlearn: 1.2768922\ttotal: 50.1s\tremaining: 5.88s\n",
      "4115:\tlearn: 1.2767169\ttotal: 50.1s\tremaining: 5.86s\n",
      "4116:\tlearn: 1.2766367\ttotal: 50.1s\tremaining: 5.85s\n",
      "4117:\tlearn: 1.2764346\ttotal: 50.1s\tremaining: 5.84s\n",
      "4118:\tlearn: 1.2763008\ttotal: 50.1s\tremaining: 5.83s\n",
      "4119:\tlearn: 1.2760814\ttotal: 50.1s\tremaining: 5.82s\n",
      "4120:\tlearn: 1.2757887\ttotal: 50.1s\tremaining: 5.8s\n",
      "4121:\tlearn: 1.2756289\ttotal: 50.2s\tremaining: 5.79s\n",
      "4122:\tlearn: 1.2755300\ttotal: 50.2s\tremaining: 5.78s\n",
      "4123:\tlearn: 1.2753480\ttotal: 50.2s\tremaining: 5.77s\n",
      "4124:\tlearn: 1.2752115\ttotal: 50.2s\tremaining: 5.75s\n",
      "4125:\tlearn: 1.2749419\ttotal: 50.2s\tremaining: 5.74s\n",
      "4126:\tlearn: 1.2747618\ttotal: 50.2s\tremaining: 5.73s\n",
      "4127:\tlearn: 1.2746699\ttotal: 50.2s\tremaining: 5.72s\n",
      "4128:\tlearn: 1.2743934\ttotal: 50.2s\tremaining: 5.71s\n",
      "4129:\tlearn: 1.2741895\ttotal: 50.3s\tremaining: 5.69s\n",
      "4130:\tlearn: 1.2739156\ttotal: 50.3s\tremaining: 5.68s\n",
      "4131:\tlearn: 1.2737429\ttotal: 50.3s\tremaining: 5.67s\n",
      "4132:\tlearn: 1.2735728\ttotal: 50.3s\tremaining: 5.66s\n",
      "4133:\tlearn: 1.2734847\ttotal: 50.3s\tremaining: 5.65s\n",
      "4134:\tlearn: 1.2733778\ttotal: 50.3s\tremaining: 5.63s\n",
      "4135:\tlearn: 1.2732552\ttotal: 50.3s\tremaining: 5.62s\n",
      "4136:\tlearn: 1.2730699\ttotal: 50.3s\tremaining: 5.61s\n",
      "4137:\tlearn: 1.2728491\ttotal: 50.4s\tremaining: 5.6s\n",
      "4138:\tlearn: 1.2726829\ttotal: 50.4s\tremaining: 5.58s\n",
      "4139:\tlearn: 1.2724903\ttotal: 50.4s\tremaining: 5.57s\n",
      "4140:\tlearn: 1.2722408\ttotal: 50.4s\tremaining: 5.56s\n",
      "4141:\tlearn: 1.2720453\ttotal: 50.4s\tremaining: 5.55s\n",
      "4142:\tlearn: 1.2718515\ttotal: 50.4s\tremaining: 5.54s\n",
      "4143:\tlearn: 1.2716829\ttotal: 50.4s\tremaining: 5.53s\n",
      "4144:\tlearn: 1.2715841\ttotal: 50.4s\tremaining: 5.51s\n",
      "4145:\tlearn: 1.2713177\ttotal: 50.5s\tremaining: 5.5s\n",
      "4146:\tlearn: 1.2712244\ttotal: 50.5s\tremaining: 5.49s\n",
      "4147:\tlearn: 1.2711117\ttotal: 50.5s\tremaining: 5.48s\n",
      "4148:\tlearn: 1.2708071\ttotal: 50.5s\tremaining: 5.46s\n",
      "4149:\tlearn: 1.2705393\ttotal: 50.5s\tremaining: 5.45s\n",
      "4150:\tlearn: 1.2701953\ttotal: 50.5s\tremaining: 5.44s\n",
      "4151:\tlearn: 1.2700275\ttotal: 50.5s\tremaining: 5.43s\n",
      "4152:\tlearn: 1.2698711\ttotal: 50.5s\tremaining: 5.42s\n",
      "4153:\tlearn: 1.2697743\ttotal: 50.6s\tremaining: 5.4s\n",
      "4154:\tlearn: 1.2695941\ttotal: 50.6s\tremaining: 5.39s\n",
      "4155:\tlearn: 1.2695216\ttotal: 50.6s\tremaining: 5.38s\n",
      "4156:\tlearn: 1.2691909\ttotal: 50.6s\tremaining: 5.37s\n",
      "4157:\tlearn: 1.2690979\ttotal: 50.6s\tremaining: 5.36s\n",
      "4158:\tlearn: 1.2688355\ttotal: 50.6s\tremaining: 5.34s\n",
      "4159:\tlearn: 1.2686393\ttotal: 50.6s\tremaining: 5.33s\n",
      "4160:\tlearn: 1.2684743\ttotal: 50.6s\tremaining: 5.32s\n",
      "4161:\tlearn: 1.2683477\ttotal: 50.7s\tremaining: 5.31s\n",
      "4162:\tlearn: 1.2681153\ttotal: 50.7s\tremaining: 5.29s\n",
      "4163:\tlearn: 1.2678595\ttotal: 50.7s\tremaining: 5.28s\n",
      "4164:\tlearn: 1.2677639\ttotal: 50.7s\tremaining: 5.27s\n",
      "4165:\tlearn: 1.2674876\ttotal: 50.7s\tremaining: 5.26s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4166:\tlearn: 1.2673704\ttotal: 50.7s\tremaining: 5.25s\n",
      "4167:\tlearn: 1.2671296\ttotal: 50.7s\tremaining: 5.23s\n",
      "4168:\tlearn: 1.2670566\ttotal: 50.7s\tremaining: 5.22s\n",
      "4169:\tlearn: 1.2668712\ttotal: 50.8s\tremaining: 5.21s\n",
      "4170:\tlearn: 1.2667625\ttotal: 50.8s\tremaining: 5.2s\n",
      "4171:\tlearn: 1.2665843\ttotal: 50.8s\tremaining: 5.18s\n",
      "4172:\tlearn: 1.2664418\ttotal: 50.8s\tremaining: 5.17s\n",
      "4173:\tlearn: 1.2662896\ttotal: 50.8s\tremaining: 5.16s\n",
      "4174:\tlearn: 1.2661020\ttotal: 50.8s\tremaining: 5.15s\n",
      "4175:\tlearn: 1.2659690\ttotal: 50.8s\tremaining: 5.14s\n",
      "4176:\tlearn: 1.2658867\ttotal: 50.8s\tremaining: 5.12s\n",
      "4177:\tlearn: 1.2658589\ttotal: 50.9s\tremaining: 5.11s\n",
      "4178:\tlearn: 1.2656856\ttotal: 50.9s\tremaining: 5.1s\n",
      "4179:\tlearn: 1.2655399\ttotal: 50.9s\tremaining: 5.09s\n",
      "4180:\tlearn: 1.2654303\ttotal: 50.9s\tremaining: 5.08s\n",
      "4181:\tlearn: 1.2650598\ttotal: 50.9s\tremaining: 5.06s\n",
      "4182:\tlearn: 1.2649733\ttotal: 50.9s\tremaining: 5.05s\n",
      "4183:\tlearn: 1.2645398\ttotal: 50.9s\tremaining: 5.04s\n",
      "4184:\tlearn: 1.2643787\ttotal: 51s\tremaining: 5.03s\n",
      "4185:\tlearn: 1.2642605\ttotal: 51s\tremaining: 5.02s\n",
      "4186:\tlearn: 1.2641227\ttotal: 51s\tremaining: 5s\n",
      "4187:\tlearn: 1.2639246\ttotal: 51s\tremaining: 4.99s\n",
      "4188:\tlearn: 1.2637514\ttotal: 51s\tremaining: 4.98s\n",
      "4189:\tlearn: 1.2634616\ttotal: 51s\tremaining: 4.97s\n",
      "4190:\tlearn: 1.2632232\ttotal: 51s\tremaining: 4.96s\n",
      "4191:\tlearn: 1.2630915\ttotal: 51s\tremaining: 4.94s\n",
      "4192:\tlearn: 1.2627911\ttotal: 51.1s\tremaining: 4.93s\n",
      "4193:\tlearn: 1.2626428\ttotal: 51.1s\tremaining: 4.92s\n",
      "4194:\tlearn: 1.2625522\ttotal: 51.1s\tremaining: 4.91s\n",
      "4195:\tlearn: 1.2623841\ttotal: 51.1s\tremaining: 4.89s\n",
      "4196:\tlearn: 1.2621664\ttotal: 51.1s\tremaining: 4.88s\n",
      "4197:\tlearn: 1.2619382\ttotal: 51.1s\tremaining: 4.87s\n",
      "4198:\tlearn: 1.2617658\ttotal: 51.1s\tremaining: 4.86s\n",
      "4199:\tlearn: 1.2616156\ttotal: 51.1s\tremaining: 4.84s\n",
      "4200:\tlearn: 1.2614764\ttotal: 51.1s\tremaining: 4.83s\n",
      "4201:\tlearn: 1.2613932\ttotal: 51.2s\tremaining: 4.82s\n",
      "4202:\tlearn: 1.2612016\ttotal: 51.2s\tremaining: 4.81s\n",
      "4203:\tlearn: 1.2611257\ttotal: 51.2s\tremaining: 4.8s\n",
      "4204:\tlearn: 1.2608155\ttotal: 51.2s\tremaining: 4.79s\n",
      "4205:\tlearn: 1.2606646\ttotal: 51.2s\tremaining: 4.77s\n",
      "4206:\tlearn: 1.2604366\ttotal: 51.2s\tremaining: 4.76s\n",
      "4207:\tlearn: 1.2601787\ttotal: 51.2s\tremaining: 4.75s\n",
      "4208:\tlearn: 1.2599802\ttotal: 51.2s\tremaining: 4.74s\n",
      "4209:\tlearn: 1.2598593\ttotal: 51.3s\tremaining: 4.72s\n",
      "4210:\tlearn: 1.2597225\ttotal: 51.3s\tremaining: 4.71s\n",
      "4211:\tlearn: 1.2596237\ttotal: 51.3s\tremaining: 4.7s\n",
      "4212:\tlearn: 1.2593804\ttotal: 51.3s\tremaining: 4.69s\n",
      "4213:\tlearn: 1.2591730\ttotal: 51.3s\tremaining: 4.67s\n",
      "4214:\tlearn: 1.2590533\ttotal: 51.3s\tremaining: 4.66s\n",
      "4215:\tlearn: 1.2589349\ttotal: 51.3s\tremaining: 4.65s\n",
      "4216:\tlearn: 1.2587141\ttotal: 51.3s\tremaining: 4.64s\n",
      "4217:\tlearn: 1.2585333\ttotal: 51.4s\tremaining: 4.63s\n",
      "4218:\tlearn: 1.2583425\ttotal: 51.4s\tremaining: 4.61s\n",
      "4219:\tlearn: 1.2582505\ttotal: 51.4s\tremaining: 4.6s\n",
      "4220:\tlearn: 1.2581357\ttotal: 51.4s\tremaining: 4.59s\n",
      "4221:\tlearn: 1.2579566\ttotal: 51.4s\tremaining: 4.58s\n",
      "4222:\tlearn: 1.2577171\ttotal: 51.4s\tremaining: 4.57s\n",
      "4223:\tlearn: 1.2576114\ttotal: 51.4s\tremaining: 4.55s\n",
      "4224:\tlearn: 1.2575339\ttotal: 51.4s\tremaining: 4.54s\n",
      "4225:\tlearn: 1.2574181\ttotal: 51.4s\tremaining: 4.53s\n",
      "4226:\tlearn: 1.2571897\ttotal: 51.5s\tremaining: 4.52s\n",
      "4227:\tlearn: 1.2570711\ttotal: 51.5s\tremaining: 4.5s\n",
      "4228:\tlearn: 1.2570093\ttotal: 51.5s\tremaining: 4.49s\n",
      "4229:\tlearn: 1.2568968\ttotal: 51.5s\tremaining: 4.48s\n",
      "4230:\tlearn: 1.2566673\ttotal: 51.5s\tremaining: 4.47s\n",
      "4231:\tlearn: 1.2564930\ttotal: 51.5s\tremaining: 4.46s\n",
      "4232:\tlearn: 1.2563514\ttotal: 51.5s\tremaining: 4.44s\n",
      "4233:\tlearn: 1.2562413\ttotal: 51.5s\tremaining: 4.43s\n",
      "4234:\tlearn: 1.2561196\ttotal: 51.6s\tremaining: 4.42s\n",
      "4235:\tlearn: 1.2560220\ttotal: 51.6s\tremaining: 4.41s\n",
      "4236:\tlearn: 1.2558442\ttotal: 51.6s\tremaining: 4.39s\n",
      "4237:\tlearn: 1.2557284\ttotal: 51.6s\tremaining: 4.38s\n",
      "4238:\tlearn: 1.2556139\ttotal: 51.6s\tremaining: 4.37s\n",
      "4239:\tlearn: 1.2554245\ttotal: 51.6s\tremaining: 4.36s\n",
      "4240:\tlearn: 1.2552199\ttotal: 51.6s\tremaining: 4.34s\n",
      "4241:\tlearn: 1.2550113\ttotal: 51.6s\tremaining: 4.33s\n",
      "4242:\tlearn: 1.2545378\ttotal: 51.6s\tremaining: 4.32s\n",
      "4243:\tlearn: 1.2544340\ttotal: 51.7s\tremaining: 4.31s\n",
      "4244:\tlearn: 1.2542949\ttotal: 51.7s\tremaining: 4.3s\n",
      "4245:\tlearn: 1.2540912\ttotal: 51.7s\tremaining: 4.28s\n",
      "4246:\tlearn: 1.2539934\ttotal: 51.7s\tremaining: 4.27s\n",
      "4247:\tlearn: 1.2539167\ttotal: 51.7s\tremaining: 4.26s\n",
      "4248:\tlearn: 1.2537223\ttotal: 51.7s\tremaining: 4.25s\n",
      "4249:\tlearn: 1.2533764\ttotal: 51.7s\tremaining: 4.24s\n",
      "4250:\tlearn: 1.2532775\ttotal: 51.7s\tremaining: 4.22s\n",
      "4251:\tlearn: 1.2530308\ttotal: 51.8s\tremaining: 4.21s\n",
      "4252:\tlearn: 1.2528197\ttotal: 51.8s\tremaining: 4.2s\n",
      "4253:\tlearn: 1.2526439\ttotal: 51.8s\tremaining: 4.19s\n",
      "4254:\tlearn: 1.2525388\ttotal: 51.8s\tremaining: 4.17s\n",
      "4255:\tlearn: 1.2523464\ttotal: 51.8s\tremaining: 4.16s\n",
      "4256:\tlearn: 1.2521986\ttotal: 51.8s\tremaining: 4.15s\n",
      "4257:\tlearn: 1.2520288\ttotal: 51.8s\tremaining: 4.14s\n",
      "4258:\tlearn: 1.2519158\ttotal: 51.8s\tremaining: 4.13s\n",
      "4259:\tlearn: 1.2517768\ttotal: 51.9s\tremaining: 4.11s\n",
      "4260:\tlearn: 1.2516146\ttotal: 51.9s\tremaining: 4.1s\n",
      "4261:\tlearn: 1.2513867\ttotal: 51.9s\tremaining: 4.09s\n",
      "4262:\tlearn: 1.2512486\ttotal: 51.9s\tremaining: 4.08s\n",
      "4263:\tlearn: 1.2510312\ttotal: 51.9s\tremaining: 4.07s\n",
      "4264:\tlearn: 1.2508549\ttotal: 51.9s\tremaining: 4.05s\n",
      "4265:\tlearn: 1.2507908\ttotal: 51.9s\tremaining: 4.04s\n",
      "4266:\tlearn: 1.2504916\ttotal: 51.9s\tremaining: 4.03s\n",
      "4267:\tlearn: 1.2503179\ttotal: 52s\tremaining: 4.02s\n",
      "4268:\tlearn: 1.2501274\ttotal: 52s\tremaining: 4s\n",
      "4269:\tlearn: 1.2499787\ttotal: 52s\tremaining: 3.99s\n",
      "4270:\tlearn: 1.2498588\ttotal: 52s\tremaining: 3.98s\n",
      "4271:\tlearn: 1.2496587\ttotal: 52s\tremaining: 3.97s\n",
      "4272:\tlearn: 1.2495447\ttotal: 52s\tremaining: 3.96s\n",
      "4273:\tlearn: 1.2492724\ttotal: 52s\tremaining: 3.94s\n",
      "4274:\tlearn: 1.2490353\ttotal: 52s\tremaining: 3.93s\n",
      "4275:\tlearn: 1.2487241\ttotal: 52.1s\tremaining: 3.92s\n",
      "4276:\tlearn: 1.2485770\ttotal: 52.1s\tremaining: 3.91s\n",
      "4277:\tlearn: 1.2484453\ttotal: 52.1s\tremaining: 3.9s\n",
      "4278:\tlearn: 1.2482379\ttotal: 52.1s\tremaining: 3.88s\n",
      "4279:\tlearn: 1.2481530\ttotal: 52.1s\tremaining: 3.87s\n",
      "4280:\tlearn: 1.2479016\ttotal: 52.1s\tremaining: 3.86s\n",
      "4281:\tlearn: 1.2478161\ttotal: 52.1s\tremaining: 3.85s\n",
      "4282:\tlearn: 1.2476518\ttotal: 52.2s\tremaining: 3.83s\n",
      "4283:\tlearn: 1.2475536\ttotal: 52.2s\tremaining: 3.82s\n",
      "4284:\tlearn: 1.2473683\ttotal: 52.2s\tremaining: 3.81s\n",
      "4285:\tlearn: 1.2472775\ttotal: 52.2s\tremaining: 3.8s\n",
      "4286:\tlearn: 1.2471761\ttotal: 52.2s\tremaining: 3.79s\n",
      "4287:\tlearn: 1.2469577\ttotal: 52.2s\tremaining: 3.77s\n",
      "4288:\tlearn: 1.2468659\ttotal: 52.2s\tremaining: 3.76s\n",
      "4289:\tlearn: 1.2466822\ttotal: 52.2s\tremaining: 3.75s\n",
      "4290:\tlearn: 1.2465229\ttotal: 52.3s\tremaining: 3.74s\n",
      "4291:\tlearn: 1.2463918\ttotal: 52.3s\tremaining: 3.73s\n",
      "4292:\tlearn: 1.2462661\ttotal: 52.3s\tremaining: 3.71s\n",
      "4293:\tlearn: 1.2460927\ttotal: 52.3s\tremaining: 3.7s\n",
      "4294:\tlearn: 1.2458803\ttotal: 52.3s\tremaining: 3.69s\n",
      "4295:\tlearn: 1.2456375\ttotal: 52.3s\tremaining: 3.68s\n",
      "4296:\tlearn: 1.2455246\ttotal: 52.3s\tremaining: 3.67s\n",
      "4297:\tlearn: 1.2453267\ttotal: 52.3s\tremaining: 3.65s\n",
      "4298:\tlearn: 1.2452086\ttotal: 52.3s\tremaining: 3.64s\n",
      "4299:\tlearn: 1.2450547\ttotal: 52.4s\tremaining: 3.63s\n",
      "4300:\tlearn: 1.2448814\ttotal: 52.4s\tremaining: 3.62s\n",
      "4301:\tlearn: 1.2448259\ttotal: 52.4s\tremaining: 3.6s\n",
      "4302:\tlearn: 1.2446987\ttotal: 52.4s\tremaining: 3.59s\n",
      "4303:\tlearn: 1.2445498\ttotal: 52.4s\tremaining: 3.58s\n",
      "4304:\tlearn: 1.2442534\ttotal: 52.4s\tremaining: 3.57s\n",
      "4305:\tlearn: 1.2441632\ttotal: 52.4s\tremaining: 3.56s\n",
      "4306:\tlearn: 1.2440764\ttotal: 52.4s\tremaining: 3.54s\n",
      "4307:\tlearn: 1.2438948\ttotal: 52.5s\tremaining: 3.53s\n",
      "4308:\tlearn: 1.2435869\ttotal: 52.5s\tremaining: 3.52s\n",
      "4309:\tlearn: 1.2435260\ttotal: 52.5s\tremaining: 3.51s\n",
      "4310:\tlearn: 1.2433929\ttotal: 52.5s\tremaining: 3.49s\n",
      "4311:\tlearn: 1.2432316\ttotal: 52.5s\tremaining: 3.48s\n",
      "4312:\tlearn: 1.2430589\ttotal: 52.5s\tremaining: 3.47s\n",
      "4313:\tlearn: 1.2429806\ttotal: 52.5s\tremaining: 3.46s\n",
      "4314:\tlearn: 1.2428546\ttotal: 52.5s\tremaining: 3.44s\n",
      "4315:\tlearn: 1.2427699\ttotal: 52.6s\tremaining: 3.43s\n",
      "4316:\tlearn: 1.2426560\ttotal: 52.6s\tremaining: 3.42s\n",
      "4317:\tlearn: 1.2424218\ttotal: 52.6s\tremaining: 3.41s\n",
      "4318:\tlearn: 1.2422560\ttotal: 52.6s\tremaining: 3.4s\n",
      "4319:\tlearn: 1.2420777\ttotal: 52.6s\tremaining: 3.38s\n",
      "4320:\tlearn: 1.2419831\ttotal: 52.6s\tremaining: 3.37s\n",
      "4321:\tlearn: 1.2418787\ttotal: 52.6s\tremaining: 3.36s\n",
      "4322:\tlearn: 1.2416577\ttotal: 52.6s\tremaining: 3.35s\n",
      "4323:\tlearn: 1.2415628\ttotal: 52.6s\tremaining: 3.34s\n",
      "4324:\tlearn: 1.2415219\ttotal: 52.7s\tremaining: 3.32s\n",
      "4325:\tlearn: 1.2413785\ttotal: 52.7s\tremaining: 3.31s\n",
      "4326:\tlearn: 1.2412528\ttotal: 52.7s\tremaining: 3.3s\n",
      "4327:\tlearn: 1.2409037\ttotal: 52.7s\tremaining: 3.29s\n",
      "4328:\tlearn: 1.2407672\ttotal: 52.7s\tremaining: 3.27s\n",
      "4329:\tlearn: 1.2405887\ttotal: 52.7s\tremaining: 3.26s\n",
      "4330:\tlearn: 1.2403997\ttotal: 52.7s\tremaining: 3.25s\n",
      "4331:\tlearn: 1.2401896\ttotal: 52.7s\tremaining: 3.24s\n",
      "4332:\tlearn: 1.2400106\ttotal: 52.7s\tremaining: 3.23s\n",
      "4333:\tlearn: 1.2399456\ttotal: 52.8s\tremaining: 3.21s\n",
      "4334:\tlearn: 1.2398581\ttotal: 52.8s\tremaining: 3.2s\n",
      "4335:\tlearn: 1.2396907\ttotal: 52.8s\tremaining: 3.19s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4336:\tlearn: 1.2395270\ttotal: 52.8s\tremaining: 3.18s\n",
      "4337:\tlearn: 1.2393787\ttotal: 52.8s\tremaining: 3.17s\n",
      "4338:\tlearn: 1.2392798\ttotal: 52.8s\tremaining: 3.15s\n",
      "4339:\tlearn: 1.2390142\ttotal: 52.8s\tremaining: 3.14s\n",
      "4340:\tlearn: 1.2389406\ttotal: 52.8s\tremaining: 3.13s\n",
      "4341:\tlearn: 1.2388298\ttotal: 52.9s\tremaining: 3.12s\n",
      "4342:\tlearn: 1.2385198\ttotal: 52.9s\tremaining: 3.1s\n",
      "4343:\tlearn: 1.2381183\ttotal: 52.9s\tremaining: 3.09s\n",
      "4344:\tlearn: 1.2379500\ttotal: 52.9s\tremaining: 3.08s\n",
      "4345:\tlearn: 1.2377483\ttotal: 52.9s\tremaining: 3.07s\n",
      "4346:\tlearn: 1.2375626\ttotal: 52.9s\tremaining: 3.06s\n",
      "4347:\tlearn: 1.2374862\ttotal: 52.9s\tremaining: 3.04s\n",
      "4348:\tlearn: 1.2371499\ttotal: 52.9s\tremaining: 3.03s\n",
      "4349:\tlearn: 1.2368203\ttotal: 53s\tremaining: 3.02s\n",
      "4350:\tlearn: 1.2366605\ttotal: 53s\tremaining: 3.01s\n",
      "4351:\tlearn: 1.2364905\ttotal: 53s\tremaining: 2.99s\n",
      "4352:\tlearn: 1.2363320\ttotal: 53s\tremaining: 2.98s\n",
      "4353:\tlearn: 1.2361782\ttotal: 53s\tremaining: 2.97s\n",
      "4354:\tlearn: 1.2360004\ttotal: 53s\tremaining: 2.96s\n",
      "4355:\tlearn: 1.2357269\ttotal: 53s\tremaining: 2.94s\n",
      "4356:\tlearn: 1.2356059\ttotal: 53s\tremaining: 2.93s\n",
      "4357:\tlearn: 1.2355302\ttotal: 53s\tremaining: 2.92s\n",
      "4358:\tlearn: 1.2353707\ttotal: 53.1s\tremaining: 2.91s\n",
      "4359:\tlearn: 1.2350552\ttotal: 53.1s\tremaining: 2.9s\n",
      "4360:\tlearn: 1.2348893\ttotal: 53.1s\tremaining: 2.88s\n",
      "4361:\tlearn: 1.2347383\ttotal: 53.1s\tremaining: 2.87s\n",
      "4362:\tlearn: 1.2345277\ttotal: 53.1s\tremaining: 2.86s\n",
      "4363:\tlearn: 1.2344289\ttotal: 53.1s\tremaining: 2.85s\n",
      "4364:\tlearn: 1.2342070\ttotal: 53.1s\tremaining: 2.84s\n",
      "4365:\tlearn: 1.2341019\ttotal: 53.1s\tremaining: 2.82s\n",
      "4366:\tlearn: 1.2340271\ttotal: 53.2s\tremaining: 2.81s\n",
      "4367:\tlearn: 1.2338155\ttotal: 53.2s\tremaining: 2.8s\n",
      "4368:\tlearn: 1.2336511\ttotal: 53.2s\tremaining: 2.79s\n",
      "4369:\tlearn: 1.2333690\ttotal: 53.2s\tremaining: 2.77s\n",
      "4370:\tlearn: 1.2331481\ttotal: 53.2s\tremaining: 2.76s\n",
      "4371:\tlearn: 1.2329867\ttotal: 53.2s\tremaining: 2.75s\n",
      "4372:\tlearn: 1.2328493\ttotal: 53.2s\tremaining: 2.74s\n",
      "4373:\tlearn: 1.2326823\ttotal: 53.3s\tremaining: 2.73s\n",
      "4374:\tlearn: 1.2324576\ttotal: 53.3s\tremaining: 2.71s\n",
      "4375:\tlearn: 1.2323917\ttotal: 53.3s\tremaining: 2.7s\n",
      "4376:\tlearn: 1.2321796\ttotal: 53.3s\tremaining: 2.69s\n",
      "4377:\tlearn: 1.2320304\ttotal: 53.3s\tremaining: 2.68s\n",
      "4378:\tlearn: 1.2318240\ttotal: 53.3s\tremaining: 2.67s\n",
      "4379:\tlearn: 1.2317137\ttotal: 53.3s\tremaining: 2.65s\n",
      "4380:\tlearn: 1.2315662\ttotal: 53.3s\tremaining: 2.64s\n",
      "4381:\tlearn: 1.2314078\ttotal: 53.4s\tremaining: 2.63s\n",
      "4382:\tlearn: 1.2313036\ttotal: 53.4s\tremaining: 2.62s\n",
      "4383:\tlearn: 1.2310516\ttotal: 53.4s\tremaining: 2.6s\n",
      "4384:\tlearn: 1.2308822\ttotal: 53.4s\tremaining: 2.59s\n",
      "4385:\tlearn: 1.2307111\ttotal: 53.4s\tremaining: 2.58s\n",
      "4386:\tlearn: 1.2304291\ttotal: 53.4s\tremaining: 2.57s\n",
      "4387:\tlearn: 1.2301600\ttotal: 53.4s\tremaining: 2.56s\n",
      "4388:\tlearn: 1.2299640\ttotal: 53.4s\tremaining: 2.54s\n",
      "4389:\tlearn: 1.2297133\ttotal: 53.5s\tremaining: 2.53s\n",
      "4390:\tlearn: 1.2296163\ttotal: 53.5s\tremaining: 2.52s\n",
      "4391:\tlearn: 1.2294384\ttotal: 53.5s\tremaining: 2.51s\n",
      "4392:\tlearn: 1.2292942\ttotal: 53.5s\tremaining: 2.5s\n",
      "4393:\tlearn: 1.2292027\ttotal: 53.5s\tremaining: 2.48s\n",
      "4394:\tlearn: 1.2289861\ttotal: 53.5s\tremaining: 2.47s\n",
      "4395:\tlearn: 1.2288460\ttotal: 53.5s\tremaining: 2.46s\n",
      "4396:\tlearn: 1.2286416\ttotal: 53.5s\tremaining: 2.45s\n",
      "4397:\tlearn: 1.2284247\ttotal: 53.5s\tremaining: 2.44s\n",
      "4398:\tlearn: 1.2282214\ttotal: 53.6s\tremaining: 2.42s\n",
      "4399:\tlearn: 1.2280350\ttotal: 53.6s\tremaining: 2.41s\n",
      "4400:\tlearn: 1.2276903\ttotal: 53.6s\tremaining: 2.4s\n",
      "4401:\tlearn: 1.2275983\ttotal: 53.6s\tremaining: 2.39s\n",
      "4402:\tlearn: 1.2274194\ttotal: 53.6s\tremaining: 2.37s\n",
      "4403:\tlearn: 1.2272214\ttotal: 53.6s\tremaining: 2.36s\n",
      "4404:\tlearn: 1.2270167\ttotal: 53.6s\tremaining: 2.35s\n",
      "4405:\tlearn: 1.2268670\ttotal: 53.6s\tremaining: 2.34s\n",
      "4406:\tlearn: 1.2267348\ttotal: 53.7s\tremaining: 2.33s\n",
      "4407:\tlearn: 1.2266712\ttotal: 53.7s\tremaining: 2.31s\n",
      "4408:\tlearn: 1.2265638\ttotal: 53.7s\tremaining: 2.3s\n",
      "4409:\tlearn: 1.2264827\ttotal: 53.7s\tremaining: 2.29s\n",
      "4410:\tlearn: 1.2259789\ttotal: 53.7s\tremaining: 2.28s\n",
      "4411:\tlearn: 1.2258644\ttotal: 53.7s\tremaining: 2.26s\n",
      "4412:\tlearn: 1.2255382\ttotal: 53.7s\tremaining: 2.25s\n",
      "4413:\tlearn: 1.2254135\ttotal: 53.7s\tremaining: 2.24s\n",
      "4414:\tlearn: 1.2253286\ttotal: 53.8s\tremaining: 2.23s\n",
      "4415:\tlearn: 1.2251071\ttotal: 53.8s\tremaining: 2.22s\n",
      "4416:\tlearn: 1.2250387\ttotal: 53.8s\tremaining: 2.2s\n",
      "4417:\tlearn: 1.2248998\ttotal: 53.8s\tremaining: 2.19s\n",
      "4418:\tlearn: 1.2248117\ttotal: 53.8s\tremaining: 2.18s\n",
      "4419:\tlearn: 1.2247245\ttotal: 53.8s\tremaining: 2.17s\n",
      "4420:\tlearn: 1.2244474\ttotal: 53.8s\tremaining: 2.15s\n",
      "4421:\tlearn: 1.2243491\ttotal: 53.8s\tremaining: 2.14s\n",
      "4422:\tlearn: 1.2242138\ttotal: 53.9s\tremaining: 2.13s\n",
      "4423:\tlearn: 1.2240145\ttotal: 53.9s\tremaining: 2.12s\n",
      "4424:\tlearn: 1.2239463\ttotal: 53.9s\tremaining: 2.11s\n",
      "4425:\tlearn: 1.2238353\ttotal: 53.9s\tremaining: 2.09s\n",
      "4426:\tlearn: 1.2236909\ttotal: 53.9s\tremaining: 2.08s\n",
      "4427:\tlearn: 1.2235624\ttotal: 53.9s\tremaining: 2.07s\n",
      "4428:\tlearn: 1.2234237\ttotal: 53.9s\tremaining: 2.06s\n",
      "4429:\tlearn: 1.2233197\ttotal: 53.9s\tremaining: 2.04s\n",
      "4430:\tlearn: 1.2231447\ttotal: 53.9s\tremaining: 2.03s\n",
      "4431:\tlearn: 1.2228048\ttotal: 54s\tremaining: 2.02s\n",
      "4432:\tlearn: 1.2227859\ttotal: 54s\tremaining: 2.01s\n",
      "4433:\tlearn: 1.2226640\ttotal: 54s\tremaining: 2s\n",
      "4434:\tlearn: 1.2225678\ttotal: 54s\tremaining: 1.98s\n",
      "4435:\tlearn: 1.2224179\ttotal: 54s\tremaining: 1.97s\n",
      "4436:\tlearn: 1.2222473\ttotal: 54s\tremaining: 1.96s\n",
      "4437:\tlearn: 1.2219833\ttotal: 54s\tremaining: 1.95s\n",
      "4438:\tlearn: 1.2217947\ttotal: 54s\tremaining: 1.94s\n",
      "4439:\tlearn: 1.2215413\ttotal: 54.1s\tremaining: 1.92s\n",
      "4440:\tlearn: 1.2214233\ttotal: 54.1s\tremaining: 1.91s\n",
      "4441:\tlearn: 1.2211695\ttotal: 54.1s\tremaining: 1.9s\n",
      "4442:\tlearn: 1.2209637\ttotal: 54.1s\tremaining: 1.89s\n",
      "4443:\tlearn: 1.2208162\ttotal: 54.1s\tremaining: 1.88s\n",
      "4444:\tlearn: 1.2206984\ttotal: 54.1s\tremaining: 1.86s\n",
      "4445:\tlearn: 1.2205534\ttotal: 54.1s\tremaining: 1.85s\n",
      "4446:\tlearn: 1.2203560\ttotal: 54.1s\tremaining: 1.84s\n",
      "4447:\tlearn: 1.2201624\ttotal: 54.2s\tremaining: 1.83s\n",
      "4448:\tlearn: 1.2199479\ttotal: 54.2s\tremaining: 1.81s\n",
      "4449:\tlearn: 1.2198347\ttotal: 54.2s\tremaining: 1.8s\n",
      "4450:\tlearn: 1.2197305\ttotal: 54.2s\tremaining: 1.79s\n",
      "4451:\tlearn: 1.2196217\ttotal: 54.2s\tremaining: 1.78s\n",
      "4452:\tlearn: 1.2195021\ttotal: 54.2s\tremaining: 1.76s\n",
      "4453:\tlearn: 1.2192182\ttotal: 54.2s\tremaining: 1.75s\n",
      "4454:\tlearn: 1.2190045\ttotal: 54.2s\tremaining: 1.74s\n",
      "4455:\tlearn: 1.2188433\ttotal: 54.3s\tremaining: 1.73s\n",
      "4456:\tlearn: 1.2187093\ttotal: 54.3s\tremaining: 1.72s\n",
      "4457:\tlearn: 1.2185412\ttotal: 54.3s\tremaining: 1.7s\n",
      "4458:\tlearn: 1.2183674\ttotal: 54.3s\tremaining: 1.69s\n",
      "4459:\tlearn: 1.2182120\ttotal: 54.3s\tremaining: 1.68s\n",
      "4460:\tlearn: 1.2180330\ttotal: 54.3s\tremaining: 1.67s\n",
      "4461:\tlearn: 1.2179754\ttotal: 54.3s\tremaining: 1.66s\n",
      "4462:\tlearn: 1.2178883\ttotal: 54.3s\tremaining: 1.64s\n",
      "4463:\tlearn: 1.2177876\ttotal: 54.4s\tremaining: 1.63s\n",
      "4464:\tlearn: 1.2177229\ttotal: 54.4s\tremaining: 1.62s\n",
      "4465:\tlearn: 1.2175065\ttotal: 54.4s\tremaining: 1.61s\n",
      "4466:\tlearn: 1.2173682\ttotal: 54.4s\tremaining: 1.59s\n",
      "4467:\tlearn: 1.2172807\ttotal: 54.4s\tremaining: 1.58s\n",
      "4468:\tlearn: 1.2171011\ttotal: 54.4s\tremaining: 1.57s\n",
      "4469:\tlearn: 1.2169827\ttotal: 54.4s\tremaining: 1.56s\n",
      "4470:\tlearn: 1.2167986\ttotal: 54.4s\tremaining: 1.55s\n",
      "4471:\tlearn: 1.2165424\ttotal: 54.4s\tremaining: 1.53s\n",
      "4472:\tlearn: 1.2163446\ttotal: 54.5s\tremaining: 1.52s\n",
      "4473:\tlearn: 1.2162347\ttotal: 54.5s\tremaining: 1.51s\n",
      "4474:\tlearn: 1.2161576\ttotal: 54.5s\tremaining: 1.5s\n",
      "4475:\tlearn: 1.2160947\ttotal: 54.5s\tremaining: 1.49s\n",
      "4476:\tlearn: 1.2159675\ttotal: 54.5s\tremaining: 1.47s\n",
      "4477:\tlearn: 1.2158555\ttotal: 54.5s\tremaining: 1.46s\n",
      "4478:\tlearn: 1.2156791\ttotal: 54.5s\tremaining: 1.45s\n",
      "4479:\tlearn: 1.2155871\ttotal: 54.5s\tremaining: 1.44s\n",
      "4480:\tlearn: 1.2154745\ttotal: 54.6s\tremaining: 1.42s\n",
      "4481:\tlearn: 1.2152658\ttotal: 54.6s\tremaining: 1.41s\n",
      "4482:\tlearn: 1.2150889\ttotal: 54.6s\tremaining: 1.4s\n",
      "4483:\tlearn: 1.2148421\ttotal: 54.6s\tremaining: 1.39s\n",
      "4484:\tlearn: 1.2147307\ttotal: 54.6s\tremaining: 1.38s\n",
      "4485:\tlearn: 1.2145148\ttotal: 54.6s\tremaining: 1.36s\n",
      "4486:\tlearn: 1.2143764\ttotal: 54.6s\tremaining: 1.35s\n",
      "4487:\tlearn: 1.2142350\ttotal: 54.6s\tremaining: 1.34s\n",
      "4488:\tlearn: 1.2140199\ttotal: 54.7s\tremaining: 1.33s\n",
      "4489:\tlearn: 1.2138313\ttotal: 54.7s\tremaining: 1.31s\n",
      "4490:\tlearn: 1.2135575\ttotal: 54.7s\tremaining: 1.3s\n",
      "4491:\tlearn: 1.2133841\ttotal: 54.7s\tremaining: 1.29s\n",
      "4492:\tlearn: 1.2131964\ttotal: 54.7s\tremaining: 1.28s\n",
      "4493:\tlearn: 1.2129469\ttotal: 54.7s\tremaining: 1.27s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4494:\tlearn: 1.2128335\ttotal: 54.7s\tremaining: 1.25s\n",
      "4495:\tlearn: 1.2126955\ttotal: 54.7s\tremaining: 1.24s\n",
      "4496:\tlearn: 1.2126562\ttotal: 54.8s\tremaining: 1.23s\n",
      "4497:\tlearn: 1.2125258\ttotal: 54.8s\tremaining: 1.22s\n",
      "4498:\tlearn: 1.2124121\ttotal: 54.8s\tremaining: 1.21s\n",
      "4499:\tlearn: 1.2122721\ttotal: 54.8s\tremaining: 1.19s\n",
      "4500:\tlearn: 1.2121086\ttotal: 54.8s\tremaining: 1.18s\n",
      "4501:\tlearn: 1.2119870\ttotal: 54.8s\tremaining: 1.17s\n",
      "4502:\tlearn: 1.2118400\ttotal: 54.8s\tremaining: 1.16s\n",
      "4503:\tlearn: 1.2117377\ttotal: 54.8s\tremaining: 1.14s\n",
      "4504:\tlearn: 1.2115803\ttotal: 54.9s\tremaining: 1.13s\n",
      "4505:\tlearn: 1.2114867\ttotal: 54.9s\tremaining: 1.12s\n",
      "4506:\tlearn: 1.2114302\ttotal: 54.9s\tremaining: 1.11s\n",
      "4507:\tlearn: 1.2111888\ttotal: 54.9s\tremaining: 1.09s\n",
      "4508:\tlearn: 1.2111282\ttotal: 54.9s\tremaining: 1.08s\n",
      "4509:\tlearn: 1.2109875\ttotal: 54.9s\tremaining: 1.07s\n",
      "4510:\tlearn: 1.2108829\ttotal: 54.9s\tremaining: 1.06s\n",
      "4511:\tlearn: 1.2108212\ttotal: 54.9s\tremaining: 1.05s\n",
      "4512:\tlearn: 1.2106758\ttotal: 54.9s\tremaining: 1.03s\n",
      "4513:\tlearn: 1.2106333\ttotal: 55s\tremaining: 1.02s\n",
      "4514:\tlearn: 1.2104933\ttotal: 55s\tremaining: 1.01s\n",
      "4515:\tlearn: 1.2103580\ttotal: 55s\tremaining: 998ms\n",
      "4516:\tlearn: 1.2101947\ttotal: 55s\tremaining: 986ms\n",
      "4517:\tlearn: 1.2100814\ttotal: 55s\tremaining: 974ms\n",
      "4518:\tlearn: 1.2099154\ttotal: 55s\tremaining: 962ms\n",
      "4519:\tlearn: 1.2097899\ttotal: 55s\tremaining: 950ms\n",
      "4520:\tlearn: 1.2096151\ttotal: 55s\tremaining: 938ms\n",
      "4521:\tlearn: 1.2093344\ttotal: 55.1s\tremaining: 925ms\n",
      "4522:\tlearn: 1.2091107\ttotal: 55.1s\tremaining: 913ms\n",
      "4523:\tlearn: 1.2089578\ttotal: 55.1s\tremaining: 901ms\n",
      "4524:\tlearn: 1.2089031\ttotal: 55.1s\tremaining: 889ms\n",
      "4525:\tlearn: 1.2087456\ttotal: 55.1s\tremaining: 877ms\n",
      "4526:\tlearn: 1.2084783\ttotal: 55.1s\tremaining: 864ms\n",
      "4527:\tlearn: 1.2083489\ttotal: 55.1s\tremaining: 852ms\n",
      "4528:\tlearn: 1.2081079\ttotal: 55.1s\tremaining: 840ms\n",
      "4529:\tlearn: 1.2079866\ttotal: 55.2s\tremaining: 828ms\n",
      "4530:\tlearn: 1.2078642\ttotal: 55.2s\tremaining: 816ms\n",
      "4531:\tlearn: 1.2077332\ttotal: 55.2s\tremaining: 804ms\n",
      "4532:\tlearn: 1.2075960\ttotal: 55.2s\tremaining: 791ms\n",
      "4533:\tlearn: 1.2072810\ttotal: 55.2s\tremaining: 779ms\n",
      "4534:\tlearn: 1.2071201\ttotal: 55.2s\tremaining: 767ms\n",
      "4535:\tlearn: 1.2068344\ttotal: 55.2s\tremaining: 755ms\n",
      "4536:\tlearn: 1.2067549\ttotal: 55.2s\tremaining: 743ms\n",
      "4537:\tlearn: 1.2066504\ttotal: 55.3s\tremaining: 731ms\n",
      "4538:\tlearn: 1.2065676\ttotal: 55.3s\tremaining: 718ms\n",
      "4539:\tlearn: 1.2064283\ttotal: 55.3s\tremaining: 706ms\n",
      "4540:\tlearn: 1.2063199\ttotal: 55.3s\tremaining: 694ms\n",
      "4541:\tlearn: 1.2062277\ttotal: 55.3s\tremaining: 682ms\n",
      "4542:\tlearn: 1.2060907\ttotal: 55.3s\tremaining: 670ms\n",
      "4543:\tlearn: 1.2060394\ttotal: 55.3s\tremaining: 657ms\n",
      "4544:\tlearn: 1.2059086\ttotal: 55.3s\tremaining: 645ms\n",
      "4545:\tlearn: 1.2058186\ttotal: 55.3s\tremaining: 633ms\n",
      "4546:\tlearn: 1.2055471\ttotal: 55.4s\tremaining: 621ms\n",
      "4547:\tlearn: 1.2054088\ttotal: 55.4s\tremaining: 609ms\n",
      "4548:\tlearn: 1.2053593\ttotal: 55.4s\tremaining: 597ms\n",
      "4549:\tlearn: 1.2051503\ttotal: 55.4s\tremaining: 584ms\n",
      "4550:\tlearn: 1.2049006\ttotal: 55.4s\tremaining: 572ms\n",
      "4551:\tlearn: 1.2047434\ttotal: 55.4s\tremaining: 560ms\n",
      "4552:\tlearn: 1.2046538\ttotal: 55.4s\tremaining: 548ms\n",
      "4553:\tlearn: 1.2043027\ttotal: 55.4s\tremaining: 536ms\n",
      "4554:\tlearn: 1.2041512\ttotal: 55.5s\tremaining: 524ms\n",
      "4555:\tlearn: 1.2039683\ttotal: 55.5s\tremaining: 511ms\n",
      "4556:\tlearn: 1.2037993\ttotal: 55.5s\tremaining: 499ms\n",
      "4557:\tlearn: 1.2036247\ttotal: 55.5s\tremaining: 487ms\n",
      "4558:\tlearn: 1.2034106\ttotal: 55.5s\tremaining: 475ms\n",
      "4559:\tlearn: 1.2033509\ttotal: 55.5s\tremaining: 463ms\n",
      "4560:\tlearn: 1.2030393\ttotal: 55.5s\tremaining: 451ms\n",
      "4561:\tlearn: 1.2028187\ttotal: 55.5s\tremaining: 438ms\n",
      "4562:\tlearn: 1.2026559\ttotal: 55.6s\tremaining: 426ms\n",
      "4563:\tlearn: 1.2024835\ttotal: 55.6s\tremaining: 414ms\n",
      "4564:\tlearn: 1.2022692\ttotal: 55.6s\tremaining: 402ms\n",
      "4565:\tlearn: 1.2020149\ttotal: 55.6s\tremaining: 390ms\n",
      "4566:\tlearn: 1.2019122\ttotal: 55.6s\tremaining: 378ms\n",
      "4567:\tlearn: 1.2017210\ttotal: 55.6s\tremaining: 365ms\n",
      "4568:\tlearn: 1.2014948\ttotal: 55.6s\tremaining: 353ms\n",
      "4569:\tlearn: 1.2012606\ttotal: 55.7s\tremaining: 341ms\n",
      "4570:\tlearn: 1.2010887\ttotal: 55.7s\tremaining: 329ms\n",
      "4571:\tlearn: 1.2009227\ttotal: 55.7s\tremaining: 317ms\n",
      "4572:\tlearn: 1.2008103\ttotal: 55.7s\tremaining: 304ms\n",
      "4573:\tlearn: 1.2007379\ttotal: 55.7s\tremaining: 292ms\n",
      "4574:\tlearn: 1.2006326\ttotal: 55.7s\tremaining: 280ms\n",
      "4575:\tlearn: 1.2005179\ttotal: 55.7s\tremaining: 268ms\n",
      "4576:\tlearn: 1.2002818\ttotal: 55.7s\tremaining: 256ms\n",
      "4577:\tlearn: 1.2001678\ttotal: 55.7s\tremaining: 244ms\n",
      "4578:\tlearn: 1.1998457\ttotal: 55.8s\tremaining: 231ms\n",
      "4579:\tlearn: 1.1996054\ttotal: 55.8s\tremaining: 219ms\n",
      "4580:\tlearn: 1.1994722\ttotal: 55.8s\tremaining: 207ms\n",
      "4581:\tlearn: 1.1993752\ttotal: 55.8s\tremaining: 195ms\n",
      "4582:\tlearn: 1.1993035\ttotal: 55.8s\tremaining: 183ms\n",
      "4583:\tlearn: 1.1991417\ttotal: 55.8s\tremaining: 170ms\n",
      "4584:\tlearn: 1.1990324\ttotal: 55.8s\tremaining: 158ms\n",
      "4585:\tlearn: 1.1989179\ttotal: 55.9s\tremaining: 146ms\n",
      "4586:\tlearn: 1.1986751\ttotal: 55.9s\tremaining: 134ms\n",
      "4587:\tlearn: 1.1985626\ttotal: 55.9s\tremaining: 122ms\n",
      "4588:\tlearn: 1.1984067\ttotal: 55.9s\tremaining: 110ms\n",
      "4589:\tlearn: 1.1982096\ttotal: 55.9s\tremaining: 97.4ms\n",
      "4590:\tlearn: 1.1980095\ttotal: 55.9s\tremaining: 85.3ms\n",
      "4591:\tlearn: 1.1978588\ttotal: 55.9s\tremaining: 73.1ms\n",
      "4592:\tlearn: 1.1975581\ttotal: 55.9s\tremaining: 60.9ms\n",
      "4593:\tlearn: 1.1973387\ttotal: 56s\tremaining: 48.7ms\n",
      "4594:\tlearn: 1.1971964\ttotal: 56s\tremaining: 36.5ms\n",
      "4595:\tlearn: 1.1969943\ttotal: 56s\tremaining: 24.4ms\n",
      "4596:\tlearn: 1.1968068\ttotal: 56s\tremaining: 12.2ms\n",
      "4597:\tlearn: 1.1966913\ttotal: 56s\tremaining: 0us\n",
      "0:\tlearn: 11.8789350\ttotal: 10.7ms\tremaining: 49.2s\n",
      "1:\tlearn: 10.7682060\ttotal: 21.9ms\tremaining: 50.4s\n",
      "2:\tlearn: 9.7880923\ttotal: 33.7ms\tremaining: 51.6s\n",
      "3:\tlearn: 8.9334716\ttotal: 45.2ms\tremaining: 51.9s\n",
      "4:\tlearn: 8.1833427\ttotal: 56.7ms\tremaining: 52s\n",
      "5:\tlearn: 7.5441596\ttotal: 68ms\tremaining: 52.1s\n",
      "6:\tlearn: 6.9790800\ttotal: 80ms\tremaining: 52.4s\n",
      "7:\tlearn: 6.4914551\ttotal: 92ms\tremaining: 52.8s\n",
      "8:\tlearn: 6.0733398\ttotal: 104ms\tremaining: 53s\n",
      "9:\tlearn: 5.7228824\ttotal: 116ms\tremaining: 53.3s\n",
      "10:\tlearn: 5.4247241\ttotal: 128ms\tremaining: 53.5s\n",
      "11:\tlearn: 5.1656484\ttotal: 141ms\tremaining: 53.7s\n",
      "12:\tlearn: 4.9538675\ttotal: 152ms\tremaining: 53.7s\n",
      "13:\tlearn: 4.7666791\ttotal: 165ms\tremaining: 54s\n",
      "14:\tlearn: 4.6135603\ttotal: 177ms\tremaining: 54.2s\n",
      "15:\tlearn: 4.4856293\ttotal: 189ms\tremaining: 54.1s\n",
      "16:\tlearn: 4.3771090\ttotal: 201ms\tremaining: 54.2s\n",
      "17:\tlearn: 4.2865492\ttotal: 213ms\tremaining: 54.2s\n",
      "18:\tlearn: 4.2127986\ttotal: 226ms\tremaining: 54.4s\n",
      "19:\tlearn: 4.1477695\ttotal: 239ms\tremaining: 54.6s\n",
      "20:\tlearn: 4.0905065\ttotal: 252ms\tremaining: 54.9s\n",
      "21:\tlearn: 4.0429983\ttotal: 264ms\tremaining: 54.9s\n",
      "22:\tlearn: 3.9991374\ttotal: 277ms\tremaining: 55.1s\n",
      "23:\tlearn: 3.9651674\ttotal: 289ms\tremaining: 55.2s\n",
      "24:\tlearn: 3.9370667\ttotal: 301ms\tremaining: 55.1s\n",
      "25:\tlearn: 3.9124370\ttotal: 313ms\tremaining: 55.1s\n",
      "26:\tlearn: 3.8886997\ttotal: 325ms\tremaining: 55s\n",
      "27:\tlearn: 3.8699541\ttotal: 336ms\tremaining: 54.9s\n",
      "28:\tlearn: 3.8479003\ttotal: 348ms\tremaining: 54.9s\n",
      "29:\tlearn: 3.8298355\ttotal: 361ms\tremaining: 54.9s\n",
      "30:\tlearn: 3.8151381\ttotal: 373ms\tremaining: 54.9s\n",
      "31:\tlearn: 3.8017444\ttotal: 384ms\tremaining: 54.8s\n",
      "32:\tlearn: 3.7887530\ttotal: 396ms\tremaining: 54.8s\n",
      "33:\tlearn: 3.7788017\ttotal: 407ms\tremaining: 54.7s\n",
      "34:\tlearn: 3.7680564\ttotal: 420ms\tremaining: 54.7s\n",
      "35:\tlearn: 3.7589997\ttotal: 433ms\tremaining: 54.9s\n",
      "36:\tlearn: 3.7521414\ttotal: 446ms\tremaining: 55s\n",
      "37:\tlearn: 3.7408536\ttotal: 459ms\tremaining: 55.1s\n",
      "38:\tlearn: 3.7303459\ttotal: 472ms\tremaining: 55.2s\n",
      "39:\tlearn: 3.7192255\ttotal: 485ms\tremaining: 55.2s\n",
      "40:\tlearn: 3.7110306\ttotal: 496ms\tremaining: 55.2s\n",
      "41:\tlearn: 3.7015324\ttotal: 508ms\tremaining: 55.2s\n",
      "42:\tlearn: 3.6956667\ttotal: 520ms\tremaining: 55.1s\n",
      "43:\tlearn: 3.6878982\ttotal: 531ms\tremaining: 54.9s\n",
      "44:\tlearn: 3.6820788\ttotal: 543ms\tremaining: 54.9s\n",
      "45:\tlearn: 3.6757816\ttotal: 555ms\tremaining: 54.9s\n",
      "46:\tlearn: 3.6696919\ttotal: 567ms\tremaining: 54.9s\n",
      "47:\tlearn: 3.6662617\ttotal: 578ms\tremaining: 54.8s\n",
      "48:\tlearn: 3.6637226\ttotal: 590ms\tremaining: 54.8s\n",
      "49:\tlearn: 3.6545970\ttotal: 603ms\tremaining: 54.9s\n",
      "50:\tlearn: 3.6486118\ttotal: 616ms\tremaining: 54.9s\n",
      "51:\tlearn: 3.6433422\ttotal: 628ms\tremaining: 54.9s\n",
      "52:\tlearn: 3.6354109\ttotal: 640ms\tremaining: 54.9s\n",
      "53:\tlearn: 3.6265945\ttotal: 655ms\tremaining: 55.1s\n",
      "54:\tlearn: 3.6210470\ttotal: 668ms\tremaining: 55.2s\n",
      "55:\tlearn: 3.6152433\ttotal: 680ms\tremaining: 55.2s\n",
      "56:\tlearn: 3.6115058\ttotal: 692ms\tremaining: 55.1s\n",
      "57:\tlearn: 3.6068606\ttotal: 703ms\tremaining: 55.1s\n",
      "58:\tlearn: 3.6032073\ttotal: 715ms\tremaining: 55s\n",
      "59:\tlearn: 3.5983689\ttotal: 727ms\tremaining: 55s\n",
      "60:\tlearn: 3.5963293\ttotal: 739ms\tremaining: 54.9s\n",
      "61:\tlearn: 3.5914056\ttotal: 750ms\tremaining: 54.9s\n",
      "62:\tlearn: 3.5874233\ttotal: 761ms\tremaining: 54.8s\n",
      "63:\tlearn: 3.5833297\ttotal: 773ms\tremaining: 54.8s\n",
      "64:\tlearn: 3.5770637\ttotal: 786ms\tremaining: 54.8s\n",
      "65:\tlearn: 3.5734869\ttotal: 798ms\tremaining: 54.8s\n",
      "66:\tlearn: 3.5705345\ttotal: 809ms\tremaining: 54.7s\n",
      "67:\tlearn: 3.5684268\ttotal: 821ms\tremaining: 54.7s\n",
      "68:\tlearn: 3.5586568\ttotal: 833ms\tremaining: 54.7s\n",
      "69:\tlearn: 3.5564962\ttotal: 845ms\tremaining: 54.6s\n",
      "70:\tlearn: 3.5542361\ttotal: 856ms\tremaining: 54.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71:\tlearn: 3.5525347\ttotal: 873ms\tremaining: 54.9s\n",
      "72:\tlearn: 3.5504553\ttotal: 906ms\tremaining: 56.2s\n",
      "73:\tlearn: 3.5470441\ttotal: 921ms\tremaining: 56.3s\n",
      "74:\tlearn: 3.5414344\ttotal: 936ms\tremaining: 56.5s\n",
      "75:\tlearn: 3.5399914\ttotal: 950ms\tremaining: 56.5s\n",
      "76:\tlearn: 3.5318999\ttotal: 965ms\tremaining: 56.7s\n",
      "77:\tlearn: 3.5239960\ttotal: 980ms\tremaining: 56.8s\n",
      "78:\tlearn: 3.5220090\ttotal: 991ms\tremaining: 56.7s\n",
      "79:\tlearn: 3.5192783\ttotal: 1s\tremaining: 56.6s\n",
      "80:\tlearn: 3.5158049\ttotal: 1.01s\tremaining: 56.6s\n",
      "81:\tlearn: 3.5120530\ttotal: 1.03s\tremaining: 56.6s\n",
      "82:\tlearn: 3.5081600\ttotal: 1.04s\tremaining: 56.5s\n",
      "83:\tlearn: 3.5025202\ttotal: 1.05s\tremaining: 56.5s\n",
      "84:\tlearn: 3.4994674\ttotal: 1.06s\tremaining: 56.5s\n",
      "85:\tlearn: 3.4969877\ttotal: 1.07s\tremaining: 56.4s\n",
      "86:\tlearn: 3.4946015\ttotal: 1.09s\tremaining: 56.5s\n",
      "87:\tlearn: 3.4887350\ttotal: 1.1s\tremaining: 56.5s\n",
      "88:\tlearn: 3.4854586\ttotal: 1.11s\tremaining: 56.5s\n",
      "89:\tlearn: 3.4826576\ttotal: 1.13s\tremaining: 56.5s\n",
      "90:\tlearn: 3.4803927\ttotal: 1.14s\tremaining: 56.4s\n",
      "91:\tlearn: 3.4771505\ttotal: 1.15s\tremaining: 56.4s\n",
      "92:\tlearn: 3.4737025\ttotal: 1.16s\tremaining: 56.4s\n",
      "93:\tlearn: 3.4700394\ttotal: 1.18s\tremaining: 56.4s\n",
      "94:\tlearn: 3.4652694\ttotal: 1.19s\tremaining: 56.3s\n",
      "95:\tlearn: 3.4622608\ttotal: 1.2s\tremaining: 56.3s\n",
      "96:\tlearn: 3.4580219\ttotal: 1.21s\tremaining: 56.3s\n",
      "97:\tlearn: 3.4529398\ttotal: 1.23s\tremaining: 56.3s\n",
      "98:\tlearn: 3.4470919\ttotal: 1.24s\tremaining: 56.3s\n",
      "99:\tlearn: 3.4433847\ttotal: 1.25s\tremaining: 56.2s\n",
      "100:\tlearn: 3.4421817\ttotal: 1.26s\tremaining: 56.2s\n",
      "101:\tlearn: 3.4381823\ttotal: 1.27s\tremaining: 56.2s\n",
      "102:\tlearn: 3.4362700\ttotal: 1.29s\tremaining: 56.2s\n",
      "103:\tlearn: 3.4324851\ttotal: 1.3s\tremaining: 56.2s\n",
      "104:\tlearn: 3.4290771\ttotal: 1.31s\tremaining: 56.2s\n",
      "105:\tlearn: 3.4261265\ttotal: 1.32s\tremaining: 56.2s\n",
      "106:\tlearn: 3.4230881\ttotal: 1.34s\tremaining: 56.2s\n",
      "107:\tlearn: 3.4172863\ttotal: 1.35s\tremaining: 56.2s\n",
      "108:\tlearn: 3.4126573\ttotal: 1.36s\tremaining: 56.1s\n",
      "109:\tlearn: 3.4070526\ttotal: 1.37s\tremaining: 56.1s\n",
      "110:\tlearn: 3.4020238\ttotal: 1.39s\tremaining: 56.1s\n",
      "111:\tlearn: 3.3972745\ttotal: 1.4s\tremaining: 56.1s\n",
      "112:\tlearn: 3.3926259\ttotal: 1.41s\tremaining: 56s\n",
      "113:\tlearn: 3.3893745\ttotal: 1.42s\tremaining: 56s\n",
      "114:\tlearn: 3.3856925\ttotal: 1.44s\tremaining: 56s\n",
      "115:\tlearn: 3.3819677\ttotal: 1.45s\tremaining: 55.9s\n",
      "116:\tlearn: 3.3789939\ttotal: 1.46s\tremaining: 55.9s\n",
      "117:\tlearn: 3.3754620\ttotal: 1.47s\tremaining: 55.9s\n",
      "118:\tlearn: 3.3733721\ttotal: 1.48s\tremaining: 55.9s\n",
      "119:\tlearn: 3.3702695\ttotal: 1.5s\tremaining: 55.9s\n",
      "120:\tlearn: 3.3670511\ttotal: 1.51s\tremaining: 55.9s\n",
      "121:\tlearn: 3.3611477\ttotal: 1.52s\tremaining: 55.9s\n",
      "122:\tlearn: 3.3587202\ttotal: 1.53s\tremaining: 55.8s\n",
      "123:\tlearn: 3.3549021\ttotal: 1.55s\tremaining: 55.8s\n",
      "124:\tlearn: 3.3516670\ttotal: 1.56s\tremaining: 55.8s\n",
      "125:\tlearn: 3.3485896\ttotal: 1.57s\tremaining: 55.7s\n",
      "126:\tlearn: 3.3452235\ttotal: 1.58s\tremaining: 55.7s\n",
      "127:\tlearn: 3.3423667\ttotal: 1.59s\tremaining: 55.7s\n",
      "128:\tlearn: 3.3394690\ttotal: 1.6s\tremaining: 55.6s\n",
      "129:\tlearn: 3.3360511\ttotal: 1.62s\tremaining: 55.6s\n",
      "130:\tlearn: 3.3329454\ttotal: 1.63s\tremaining: 55.6s\n",
      "131:\tlearn: 3.3302475\ttotal: 1.64s\tremaining: 55.5s\n",
      "132:\tlearn: 3.3267676\ttotal: 1.65s\tremaining: 55.5s\n",
      "133:\tlearn: 3.3235958\ttotal: 1.67s\tremaining: 55.5s\n",
      "134:\tlearn: 3.3211112\ttotal: 1.68s\tremaining: 55.5s\n",
      "135:\tlearn: 3.3193125\ttotal: 1.69s\tremaining: 55.5s\n",
      "136:\tlearn: 3.3163358\ttotal: 1.7s\tremaining: 55.4s\n",
      "137:\tlearn: 3.3128338\ttotal: 1.71s\tremaining: 55.4s\n",
      "138:\tlearn: 3.3101014\ttotal: 1.73s\tremaining: 55.4s\n",
      "139:\tlearn: 3.3065803\ttotal: 1.74s\tremaining: 55.4s\n",
      "140:\tlearn: 3.3040557\ttotal: 1.75s\tremaining: 55.4s\n",
      "141:\tlearn: 3.3012237\ttotal: 1.76s\tremaining: 55.3s\n",
      "142:\tlearn: 3.2991266\ttotal: 1.77s\tremaining: 55.3s\n",
      "143:\tlearn: 3.2959031\ttotal: 1.79s\tremaining: 55.3s\n",
      "144:\tlearn: 3.2920097\ttotal: 1.8s\tremaining: 55.2s\n",
      "145:\tlearn: 3.2890045\ttotal: 1.81s\tremaining: 55.2s\n",
      "146:\tlearn: 3.2857824\ttotal: 1.82s\tremaining: 55.2s\n",
      "147:\tlearn: 3.2818388\ttotal: 1.83s\tremaining: 55.2s\n",
      "148:\tlearn: 3.2790279\ttotal: 1.85s\tremaining: 55.2s\n",
      "149:\tlearn: 3.2772300\ttotal: 1.86s\tremaining: 55.1s\n",
      "150:\tlearn: 3.2752169\ttotal: 1.87s\tremaining: 55.1s\n",
      "151:\tlearn: 3.2724043\ttotal: 1.88s\tremaining: 55.1s\n",
      "152:\tlearn: 3.2706043\ttotal: 1.89s\tremaining: 55.1s\n",
      "153:\tlearn: 3.2682558\ttotal: 1.91s\tremaining: 55s\n",
      "154:\tlearn: 3.2639451\ttotal: 1.92s\tremaining: 55s\n",
      "155:\tlearn: 3.2621091\ttotal: 1.93s\tremaining: 55s\n",
      "156:\tlearn: 3.2601577\ttotal: 1.94s\tremaining: 55s\n",
      "157:\tlearn: 3.2576727\ttotal: 1.96s\tremaining: 55s\n",
      "158:\tlearn: 3.2541083\ttotal: 1.97s\tremaining: 55s\n",
      "159:\tlearn: 3.2516526\ttotal: 1.98s\tremaining: 55s\n",
      "160:\tlearn: 3.2495889\ttotal: 1.99s\tremaining: 55s\n",
      "161:\tlearn: 3.2476711\ttotal: 2s\tremaining: 54.9s\n",
      "162:\tlearn: 3.2444414\ttotal: 2.02s\tremaining: 54.9s\n",
      "163:\tlearn: 3.2412558\ttotal: 2.03s\tremaining: 54.9s\n",
      "164:\tlearn: 3.2383335\ttotal: 2.04s\tremaining: 54.8s\n",
      "165:\tlearn: 3.2355999\ttotal: 2.05s\tremaining: 54.8s\n",
      "166:\tlearn: 3.2340185\ttotal: 2.06s\tremaining: 54.8s\n",
      "167:\tlearn: 3.2315818\ttotal: 2.08s\tremaining: 54.7s\n",
      "168:\tlearn: 3.2291235\ttotal: 2.09s\tremaining: 54.7s\n",
      "169:\tlearn: 3.2251905\ttotal: 2.1s\tremaining: 54.7s\n",
      "170:\tlearn: 3.2237124\ttotal: 2.11s\tremaining: 54.6s\n",
      "171:\tlearn: 3.2216374\ttotal: 2.12s\tremaining: 54.6s\n",
      "172:\tlearn: 3.2177602\ttotal: 2.13s\tremaining: 54.6s\n",
      "173:\tlearn: 3.2163148\ttotal: 2.15s\tremaining: 54.6s\n",
      "174:\tlearn: 3.2139078\ttotal: 2.16s\tremaining: 54.6s\n",
      "175:\tlearn: 3.2119041\ttotal: 2.17s\tremaining: 54.6s\n",
      "176:\tlearn: 3.2090133\ttotal: 2.19s\tremaining: 54.6s\n",
      "177:\tlearn: 3.2071354\ttotal: 2.2s\tremaining: 54.6s\n",
      "178:\tlearn: 3.2053234\ttotal: 2.21s\tremaining: 54.6s\n",
      "179:\tlearn: 3.2033387\ttotal: 2.22s\tremaining: 54.6s\n",
      "180:\tlearn: 3.2010201\ttotal: 2.23s\tremaining: 54.5s\n",
      "181:\tlearn: 3.1984340\ttotal: 2.25s\tremaining: 54.5s\n",
      "182:\tlearn: 3.1943233\ttotal: 2.26s\tremaining: 54.5s\n",
      "183:\tlearn: 3.1923208\ttotal: 2.27s\tremaining: 54.5s\n",
      "184:\tlearn: 3.1876438\ttotal: 2.28s\tremaining: 54.5s\n",
      "185:\tlearn: 3.1854214\ttotal: 2.29s\tremaining: 54.4s\n",
      "186:\tlearn: 3.1829208\ttotal: 2.31s\tremaining: 54.4s\n",
      "187:\tlearn: 3.1800569\ttotal: 2.32s\tremaining: 54.4s\n",
      "188:\tlearn: 3.1763266\ttotal: 2.33s\tremaining: 54.4s\n",
      "189:\tlearn: 3.1727678\ttotal: 2.34s\tremaining: 54.4s\n",
      "190:\tlearn: 3.1700007\ttotal: 2.35s\tremaining: 54.3s\n",
      "191:\tlearn: 3.1665220\ttotal: 2.37s\tremaining: 54.3s\n",
      "192:\tlearn: 3.1644938\ttotal: 2.38s\tremaining: 54.4s\n",
      "193:\tlearn: 3.1623908\ttotal: 2.39s\tremaining: 54.3s\n",
      "194:\tlearn: 3.1607324\ttotal: 2.4s\tremaining: 54.3s\n",
      "195:\tlearn: 3.1577019\ttotal: 2.42s\tremaining: 54.3s\n",
      "196:\tlearn: 3.1562443\ttotal: 2.43s\tremaining: 54.3s\n",
      "197:\tlearn: 3.1532764\ttotal: 2.44s\tremaining: 54.3s\n",
      "198:\tlearn: 3.1511779\ttotal: 2.46s\tremaining: 54.3s\n",
      "199:\tlearn: 3.1497941\ttotal: 2.47s\tremaining: 54.3s\n",
      "200:\tlearn: 3.1456544\ttotal: 2.48s\tremaining: 54.3s\n",
      "201:\tlearn: 3.1434843\ttotal: 2.49s\tremaining: 54.2s\n",
      "202:\tlearn: 3.1416434\ttotal: 2.5s\tremaining: 54.2s\n",
      "203:\tlearn: 3.1391122\ttotal: 2.52s\tremaining: 54.2s\n",
      "204:\tlearn: 3.1373809\ttotal: 2.53s\tremaining: 54.2s\n",
      "205:\tlearn: 3.1346919\ttotal: 2.54s\tremaining: 54.2s\n",
      "206:\tlearn: 3.1316665\ttotal: 2.55s\tremaining: 54.2s\n",
      "207:\tlearn: 3.1298076\ttotal: 2.56s\tremaining: 54.1s\n",
      "208:\tlearn: 3.1283242\ttotal: 2.58s\tremaining: 54.1s\n",
      "209:\tlearn: 3.1268393\ttotal: 2.59s\tremaining: 54.1s\n",
      "210:\tlearn: 3.1245750\ttotal: 2.6s\tremaining: 54.2s\n",
      "211:\tlearn: 3.1226149\ttotal: 2.62s\tremaining: 54.1s\n",
      "212:\tlearn: 3.1204295\ttotal: 2.63s\tremaining: 54.1s\n",
      "213:\tlearn: 3.1193683\ttotal: 2.64s\tremaining: 54.1s\n",
      "214:\tlearn: 3.1174002\ttotal: 2.65s\tremaining: 54.1s\n",
      "215:\tlearn: 3.1152756\ttotal: 2.67s\tremaining: 54.1s\n",
      "216:\tlearn: 3.1148235\ttotal: 2.67s\tremaining: 54s\n",
      "217:\tlearn: 3.1130404\ttotal: 2.69s\tremaining: 54s\n",
      "218:\tlearn: 3.1104938\ttotal: 2.7s\tremaining: 54s\n",
      "219:\tlearn: 3.1078958\ttotal: 2.71s\tremaining: 54s\n",
      "220:\tlearn: 3.1063346\ttotal: 2.72s\tremaining: 54s\n",
      "221:\tlearn: 3.1041312\ttotal: 2.73s\tremaining: 53.9s\n",
      "222:\tlearn: 3.1013253\ttotal: 2.75s\tremaining: 53.9s\n",
      "223:\tlearn: 3.0989446\ttotal: 2.76s\tremaining: 53.9s\n",
      "224:\tlearn: 3.0969511\ttotal: 2.77s\tremaining: 53.9s\n",
      "225:\tlearn: 3.0954883\ttotal: 2.78s\tremaining: 53.9s\n",
      "226:\tlearn: 3.0938306\ttotal: 2.8s\tremaining: 53.9s\n",
      "227:\tlearn: 3.0912909\ttotal: 2.81s\tremaining: 53.9s\n",
      "228:\tlearn: 3.0889427\ttotal: 2.82s\tremaining: 53.9s\n",
      "229:\tlearn: 3.0872921\ttotal: 2.84s\tremaining: 53.9s\n",
      "230:\tlearn: 3.0854349\ttotal: 2.85s\tremaining: 53.8s\n",
      "231:\tlearn: 3.0839085\ttotal: 2.86s\tremaining: 53.8s\n",
      "232:\tlearn: 3.0822769\ttotal: 2.87s\tremaining: 53.8s\n",
      "233:\tlearn: 3.0799103\ttotal: 2.88s\tremaining: 53.8s\n",
      "234:\tlearn: 3.0787158\ttotal: 2.9s\tremaining: 53.8s\n",
      "235:\tlearn: 3.0776420\ttotal: 2.91s\tremaining: 53.7s\n",
      "236:\tlearn: 3.0762007\ttotal: 2.92s\tremaining: 53.7s\n",
      "237:\tlearn: 3.0736063\ttotal: 2.93s\tremaining: 53.7s\n",
      "238:\tlearn: 3.0714191\ttotal: 2.94s\tremaining: 53.7s\n",
      "239:\tlearn: 3.0684342\ttotal: 2.96s\tremaining: 53.7s\n",
      "240:\tlearn: 3.0666967\ttotal: 2.97s\tremaining: 53.6s\n",
      "241:\tlearn: 3.0645314\ttotal: 2.98s\tremaining: 53.6s\n",
      "242:\tlearn: 3.0628292\ttotal: 2.99s\tremaining: 53.6s\n",
      "243:\tlearn: 3.0617110\ttotal: 3s\tremaining: 53.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244:\tlearn: 3.0602379\ttotal: 3.01s\tremaining: 53.5s\n",
      "245:\tlearn: 3.0585479\ttotal: 3.03s\tremaining: 53.6s\n",
      "246:\tlearn: 3.0569031\ttotal: 3.04s\tremaining: 53.5s\n",
      "247:\tlearn: 3.0561599\ttotal: 3.05s\tremaining: 53.5s\n",
      "248:\tlearn: 3.0544670\ttotal: 3.06s\tremaining: 53.5s\n",
      "249:\tlearn: 3.0512950\ttotal: 3.08s\tremaining: 53.5s\n",
      "250:\tlearn: 3.0490324\ttotal: 3.09s\tremaining: 53.5s\n",
      "251:\tlearn: 3.0472524\ttotal: 3.1s\tremaining: 53.5s\n",
      "252:\tlearn: 3.0447879\ttotal: 3.11s\tremaining: 53.5s\n",
      "253:\tlearn: 3.0425569\ttotal: 3.12s\tremaining: 53.4s\n",
      "254:\tlearn: 3.0407197\ttotal: 3.14s\tremaining: 53.4s\n",
      "255:\tlearn: 3.0395948\ttotal: 3.15s\tremaining: 53.4s\n",
      "256:\tlearn: 3.0365926\ttotal: 3.16s\tremaining: 53.4s\n",
      "257:\tlearn: 3.0340773\ttotal: 3.17s\tremaining: 53.4s\n",
      "258:\tlearn: 3.0321783\ttotal: 3.18s\tremaining: 53.4s\n",
      "259:\tlearn: 3.0301169\ttotal: 3.19s\tremaining: 53.3s\n",
      "260:\tlearn: 3.0287829\ttotal: 3.21s\tremaining: 53.3s\n",
      "261:\tlearn: 3.0254391\ttotal: 3.22s\tremaining: 53.3s\n",
      "262:\tlearn: 3.0229259\ttotal: 3.23s\tremaining: 53.3s\n",
      "263:\tlearn: 3.0196381\ttotal: 3.25s\tremaining: 53.3s\n",
      "264:\tlearn: 3.0180895\ttotal: 3.26s\tremaining: 53.3s\n",
      "265:\tlearn: 3.0163116\ttotal: 3.27s\tremaining: 53.3s\n",
      "266:\tlearn: 3.0146344\ttotal: 3.28s\tremaining: 53.3s\n",
      "267:\tlearn: 3.0137842\ttotal: 3.29s\tremaining: 53.2s\n",
      "268:\tlearn: 3.0109865\ttotal: 3.31s\tremaining: 53.2s\n",
      "269:\tlearn: 3.0096072\ttotal: 3.32s\tremaining: 53.2s\n",
      "270:\tlearn: 3.0072290\ttotal: 3.33s\tremaining: 53.2s\n",
      "271:\tlearn: 3.0050994\ttotal: 3.34s\tremaining: 53.2s\n",
      "272:\tlearn: 3.0037526\ttotal: 3.36s\tremaining: 53.2s\n",
      "273:\tlearn: 3.0022818\ttotal: 3.37s\tremaining: 53.2s\n",
      "274:\tlearn: 3.0008174\ttotal: 3.38s\tremaining: 53.1s\n",
      "275:\tlearn: 2.9986971\ttotal: 3.39s\tremaining: 53.1s\n",
      "276:\tlearn: 2.9972289\ttotal: 3.4s\tremaining: 53.1s\n",
      "277:\tlearn: 2.9956440\ttotal: 3.41s\tremaining: 53s\n",
      "278:\tlearn: 2.9939481\ttotal: 3.42s\tremaining: 53s\n",
      "279:\tlearn: 2.9918746\ttotal: 3.44s\tremaining: 53s\n",
      "280:\tlearn: 2.9905161\ttotal: 3.45s\tremaining: 53s\n",
      "281:\tlearn: 2.9890004\ttotal: 3.46s\tremaining: 53s\n",
      "282:\tlearn: 2.9877627\ttotal: 3.47s\tremaining: 53s\n",
      "283:\tlearn: 2.9861627\ttotal: 3.49s\tremaining: 53s\n",
      "284:\tlearn: 2.9845316\ttotal: 3.5s\tremaining: 53s\n",
      "285:\tlearn: 2.9822223\ttotal: 3.51s\tremaining: 52.9s\n",
      "286:\tlearn: 2.9807622\ttotal: 3.52s\tremaining: 52.9s\n",
      "287:\tlearn: 2.9781970\ttotal: 3.53s\tremaining: 52.9s\n",
      "288:\tlearn: 2.9778472\ttotal: 3.54s\tremaining: 52.9s\n",
      "289:\tlearn: 2.9768131\ttotal: 3.56s\tremaining: 52.8s\n",
      "290:\tlearn: 2.9758641\ttotal: 3.57s\tremaining: 52.8s\n",
      "291:\tlearn: 2.9743841\ttotal: 3.58s\tremaining: 52.8s\n",
      "292:\tlearn: 2.9728045\ttotal: 3.59s\tremaining: 52.8s\n",
      "293:\tlearn: 2.9711967\ttotal: 3.6s\tremaining: 52.8s\n",
      "294:\tlearn: 2.9687678\ttotal: 3.62s\tremaining: 52.8s\n",
      "295:\tlearn: 2.9668340\ttotal: 3.63s\tremaining: 52.8s\n",
      "296:\tlearn: 2.9640636\ttotal: 3.64s\tremaining: 52.8s\n",
      "297:\tlearn: 2.9626658\ttotal: 3.65s\tremaining: 52.8s\n",
      "298:\tlearn: 2.9605204\ttotal: 3.67s\tremaining: 52.8s\n",
      "299:\tlearn: 2.9591349\ttotal: 3.68s\tremaining: 52.7s\n",
      "300:\tlearn: 2.9573127\ttotal: 3.69s\tremaining: 52.7s\n",
      "301:\tlearn: 2.9558681\ttotal: 3.71s\tremaining: 52.7s\n",
      "302:\tlearn: 2.9541400\ttotal: 3.72s\tremaining: 52.7s\n",
      "303:\tlearn: 2.9527559\ttotal: 3.73s\tremaining: 52.7s\n",
      "304:\tlearn: 2.9512447\ttotal: 3.74s\tremaining: 52.7s\n",
      "305:\tlearn: 2.9498626\ttotal: 3.75s\tremaining: 52.7s\n",
      "306:\tlearn: 2.9481363\ttotal: 3.77s\tremaining: 52.6s\n",
      "307:\tlearn: 2.9467392\ttotal: 3.78s\tremaining: 52.6s\n",
      "308:\tlearn: 2.9447134\ttotal: 3.79s\tremaining: 52.6s\n",
      "309:\tlearn: 2.9433643\ttotal: 3.8s\tremaining: 52.6s\n",
      "310:\tlearn: 2.9424847\ttotal: 3.81s\tremaining: 52.6s\n",
      "311:\tlearn: 2.9408126\ttotal: 3.83s\tremaining: 52.6s\n",
      "312:\tlearn: 2.9382146\ttotal: 3.84s\tremaining: 52.6s\n",
      "313:\tlearn: 2.9344612\ttotal: 3.85s\tremaining: 52.6s\n",
      "314:\tlearn: 2.9331621\ttotal: 3.86s\tremaining: 52.5s\n",
      "315:\tlearn: 2.9316577\ttotal: 3.88s\tremaining: 52.5s\n",
      "316:\tlearn: 2.9288372\ttotal: 3.9s\tremaining: 52.7s\n",
      "317:\tlearn: 2.9282764\ttotal: 3.92s\tremaining: 52.7s\n",
      "318:\tlearn: 2.9262808\ttotal: 3.93s\tremaining: 52.7s\n",
      "319:\tlearn: 2.9246294\ttotal: 3.94s\tremaining: 52.7s\n",
      "320:\tlearn: 2.9235629\ttotal: 3.95s\tremaining: 52.7s\n",
      "321:\tlearn: 2.9220203\ttotal: 3.96s\tremaining: 52.6s\n",
      "322:\tlearn: 2.9203248\ttotal: 3.98s\tremaining: 52.6s\n",
      "323:\tlearn: 2.9187514\ttotal: 3.99s\tremaining: 52.6s\n",
      "324:\tlearn: 2.9176876\ttotal: 4s\tremaining: 52.6s\n",
      "325:\tlearn: 2.9164131\ttotal: 4.01s\tremaining: 52.6s\n",
      "326:\tlearn: 2.9141240\ttotal: 4.02s\tremaining: 52.6s\n",
      "327:\tlearn: 2.9125605\ttotal: 4.04s\tremaining: 52.5s\n",
      "328:\tlearn: 2.9097191\ttotal: 4.05s\tremaining: 52.5s\n",
      "329:\tlearn: 2.9088833\ttotal: 4.06s\tremaining: 52.5s\n",
      "330:\tlearn: 2.9068269\ttotal: 4.08s\tremaining: 52.6s\n",
      "331:\tlearn: 2.9051132\ttotal: 4.1s\tremaining: 52.6s\n",
      "332:\tlearn: 2.9040331\ttotal: 4.11s\tremaining: 52.6s\n",
      "333:\tlearn: 2.9022722\ttotal: 4.12s\tremaining: 52.6s\n",
      "334:\tlearn: 2.9008689\ttotal: 4.13s\tremaining: 52.6s\n",
      "335:\tlearn: 2.8999393\ttotal: 4.14s\tremaining: 52.6s\n",
      "336:\tlearn: 2.8986498\ttotal: 4.16s\tremaining: 52.6s\n",
      "337:\tlearn: 2.8968136\ttotal: 4.17s\tremaining: 52.5s\n",
      "338:\tlearn: 2.8953010\ttotal: 4.18s\tremaining: 52.5s\n",
      "339:\tlearn: 2.8939750\ttotal: 4.19s\tremaining: 52.5s\n",
      "340:\tlearn: 2.8919027\ttotal: 4.21s\tremaining: 52.5s\n",
      "341:\tlearn: 2.8907802\ttotal: 4.22s\tremaining: 52.5s\n",
      "342:\tlearn: 2.8886989\ttotal: 4.23s\tremaining: 52.5s\n",
      "343:\tlearn: 2.8867724\ttotal: 4.24s\tremaining: 52.5s\n",
      "344:\tlearn: 2.8848524\ttotal: 4.25s\tremaining: 52.4s\n",
      "345:\tlearn: 2.8834545\ttotal: 4.27s\tremaining: 52.4s\n",
      "346:\tlearn: 2.8822227\ttotal: 4.28s\tremaining: 52.4s\n",
      "347:\tlearn: 2.8813112\ttotal: 4.29s\tremaining: 52.4s\n",
      "348:\tlearn: 2.8802916\ttotal: 4.3s\tremaining: 52.4s\n",
      "349:\tlearn: 2.8790343\ttotal: 4.32s\tremaining: 52.4s\n",
      "350:\tlearn: 2.8778612\ttotal: 4.33s\tremaining: 52.4s\n",
      "351:\tlearn: 2.8757291\ttotal: 4.34s\tremaining: 52.4s\n",
      "352:\tlearn: 2.8740604\ttotal: 4.35s\tremaining: 52.4s\n",
      "353:\tlearn: 2.8722832\ttotal: 4.37s\tremaining: 52.3s\n",
      "354:\tlearn: 2.8704690\ttotal: 4.38s\tremaining: 52.3s\n",
      "355:\tlearn: 2.8692870\ttotal: 4.39s\tremaining: 52.3s\n",
      "356:\tlearn: 2.8673147\ttotal: 4.4s\tremaining: 52.3s\n",
      "357:\tlearn: 2.8661820\ttotal: 4.41s\tremaining: 52.3s\n",
      "358:\tlearn: 2.8652167\ttotal: 4.42s\tremaining: 52.3s\n",
      "359:\tlearn: 2.8629883\ttotal: 4.44s\tremaining: 52.2s\n",
      "360:\tlearn: 2.8610069\ttotal: 4.45s\tremaining: 52.2s\n",
      "361:\tlearn: 2.8595164\ttotal: 4.46s\tremaining: 52.2s\n",
      "362:\tlearn: 2.8582403\ttotal: 4.47s\tremaining: 52.2s\n",
      "363:\tlearn: 2.8565653\ttotal: 4.48s\tremaining: 52.2s\n",
      "364:\tlearn: 2.8552877\ttotal: 4.5s\tremaining: 52.1s\n",
      "365:\tlearn: 2.8535964\ttotal: 4.51s\tremaining: 52.2s\n",
      "366:\tlearn: 2.8523982\ttotal: 4.52s\tremaining: 52.2s\n",
      "367:\tlearn: 2.8512266\ttotal: 4.54s\tremaining: 52.1s\n",
      "368:\tlearn: 2.8481552\ttotal: 4.55s\tremaining: 52.1s\n",
      "369:\tlearn: 2.8463562\ttotal: 4.56s\tremaining: 52.1s\n",
      "370:\tlearn: 2.8451787\ttotal: 4.57s\tremaining: 52.1s\n",
      "371:\tlearn: 2.8434162\ttotal: 4.58s\tremaining: 52.1s\n",
      "372:\tlearn: 2.8419855\ttotal: 4.6s\tremaining: 52.1s\n",
      "373:\tlearn: 2.8412746\ttotal: 4.61s\tremaining: 52s\n",
      "374:\tlearn: 2.8399328\ttotal: 4.62s\tremaining: 52s\n",
      "375:\tlearn: 2.8389237\ttotal: 4.63s\tremaining: 52s\n",
      "376:\tlearn: 2.8374535\ttotal: 4.64s\tremaining: 52s\n",
      "377:\tlearn: 2.8355887\ttotal: 4.66s\tremaining: 52s\n",
      "378:\tlearn: 2.8343655\ttotal: 4.67s\tremaining: 51.9s\n",
      "379:\tlearn: 2.8320736\ttotal: 4.68s\tremaining: 51.9s\n",
      "380:\tlearn: 2.8303355\ttotal: 4.69s\tremaining: 51.9s\n",
      "381:\tlearn: 2.8287869\ttotal: 4.7s\tremaining: 51.9s\n",
      "382:\tlearn: 2.8277542\ttotal: 4.71s\tremaining: 51.9s\n",
      "383:\tlearn: 2.8268717\ttotal: 4.73s\tremaining: 51.9s\n",
      "384:\tlearn: 2.8251946\ttotal: 4.74s\tremaining: 51.9s\n",
      "385:\tlearn: 2.8241660\ttotal: 4.75s\tremaining: 51.8s\n",
      "386:\tlearn: 2.8225386\ttotal: 4.76s\tremaining: 51.8s\n",
      "387:\tlearn: 2.8212649\ttotal: 4.78s\tremaining: 51.8s\n",
      "388:\tlearn: 2.8170954\ttotal: 4.79s\tremaining: 51.8s\n",
      "389:\tlearn: 2.8140951\ttotal: 4.8s\tremaining: 51.8s\n",
      "390:\tlearn: 2.8126959\ttotal: 4.81s\tremaining: 51.8s\n",
      "391:\tlearn: 2.8109153\ttotal: 4.83s\tremaining: 51.8s\n",
      "392:\tlearn: 2.8098236\ttotal: 4.84s\tremaining: 51.8s\n",
      "393:\tlearn: 2.8091176\ttotal: 4.86s\tremaining: 51.8s\n",
      "394:\tlearn: 2.8076470\ttotal: 4.87s\tremaining: 51.8s\n",
      "395:\tlearn: 2.8063311\ttotal: 4.88s\tremaining: 51.8s\n",
      "396:\tlearn: 2.8054298\ttotal: 4.9s\tremaining: 51.8s\n",
      "397:\tlearn: 2.8041270\ttotal: 4.91s\tremaining: 51.8s\n",
      "398:\tlearn: 2.8034733\ttotal: 4.92s\tremaining: 51.8s\n",
      "399:\tlearn: 2.8009465\ttotal: 4.94s\tremaining: 51.8s\n",
      "400:\tlearn: 2.7990894\ttotal: 4.95s\tremaining: 51.8s\n",
      "401:\tlearn: 2.7978246\ttotal: 4.97s\tremaining: 51.8s\n",
      "402:\tlearn: 2.7964285\ttotal: 4.98s\tremaining: 51.8s\n",
      "403:\tlearn: 2.7952610\ttotal: 4.99s\tremaining: 51.8s\n",
      "404:\tlearn: 2.7945226\ttotal: 5s\tremaining: 51.8s\n",
      "405:\tlearn: 2.7930189\ttotal: 5.01s\tremaining: 51.8s\n",
      "406:\tlearn: 2.7918935\ttotal: 5.03s\tremaining: 51.8s\n",
      "407:\tlearn: 2.7910699\ttotal: 5.04s\tremaining: 51.7s\n",
      "408:\tlearn: 2.7898480\ttotal: 5.05s\tremaining: 51.7s\n",
      "409:\tlearn: 2.7886428\ttotal: 5.06s\tremaining: 51.7s\n",
      "410:\tlearn: 2.7865964\ttotal: 5.07s\tremaining: 51.7s\n",
      "411:\tlearn: 2.7856235\ttotal: 5.09s\tremaining: 51.7s\n",
      "412:\tlearn: 2.7849317\ttotal: 5.1s\tremaining: 51.7s\n",
      "413:\tlearn: 2.7838585\ttotal: 5.11s\tremaining: 51.6s\n",
      "414:\tlearn: 2.7822948\ttotal: 5.12s\tremaining: 51.6s\n",
      "415:\tlearn: 2.7802320\ttotal: 5.13s\tremaining: 51.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416:\tlearn: 2.7786584\ttotal: 5.14s\tremaining: 51.6s\n",
      "417:\tlearn: 2.7774333\ttotal: 5.16s\tremaining: 51.6s\n",
      "418:\tlearn: 2.7765868\ttotal: 5.17s\tremaining: 51.6s\n",
      "419:\tlearn: 2.7749602\ttotal: 5.18s\tremaining: 51.6s\n",
      "420:\tlearn: 2.7738935\ttotal: 5.19s\tremaining: 51.5s\n",
      "421:\tlearn: 2.7722041\ttotal: 5.21s\tremaining: 51.5s\n",
      "422:\tlearn: 2.7711711\ttotal: 5.22s\tremaining: 51.5s\n",
      "423:\tlearn: 2.7689893\ttotal: 5.23s\tremaining: 51.5s\n",
      "424:\tlearn: 2.7678738\ttotal: 5.24s\tremaining: 51.5s\n",
      "425:\tlearn: 2.7667060\ttotal: 5.25s\tremaining: 51.5s\n",
      "426:\tlearn: 2.7657490\ttotal: 5.27s\tremaining: 51.5s\n",
      "427:\tlearn: 2.7637040\ttotal: 5.28s\tremaining: 51.4s\n",
      "428:\tlearn: 2.7626435\ttotal: 5.29s\tremaining: 51.4s\n",
      "429:\tlearn: 2.7617887\ttotal: 5.3s\tremaining: 51.4s\n",
      "430:\tlearn: 2.7602123\ttotal: 5.32s\tremaining: 51.4s\n",
      "431:\tlearn: 2.7593630\ttotal: 5.33s\tremaining: 51.4s\n",
      "432:\tlearn: 2.7585298\ttotal: 5.34s\tremaining: 51.4s\n",
      "433:\tlearn: 2.7575774\ttotal: 5.35s\tremaining: 51.3s\n",
      "434:\tlearn: 2.7566009\ttotal: 5.36s\tremaining: 51.3s\n",
      "435:\tlearn: 2.7560131\ttotal: 5.38s\tremaining: 51.3s\n",
      "436:\tlearn: 2.7544769\ttotal: 5.39s\tremaining: 51.3s\n",
      "437:\tlearn: 2.7537613\ttotal: 5.4s\tremaining: 51.3s\n",
      "438:\tlearn: 2.7525720\ttotal: 5.41s\tremaining: 51.3s\n",
      "439:\tlearn: 2.7512802\ttotal: 5.42s\tremaining: 51.2s\n",
      "440:\tlearn: 2.7499149\ttotal: 5.43s\tremaining: 51.2s\n",
      "441:\tlearn: 2.7489769\ttotal: 5.44s\tremaining: 51.2s\n",
      "442:\tlearn: 2.7473930\ttotal: 5.46s\tremaining: 51.2s\n",
      "443:\tlearn: 2.7459829\ttotal: 5.47s\tremaining: 51.2s\n",
      "444:\tlearn: 2.7442849\ttotal: 5.48s\tremaining: 51.1s\n",
      "445:\tlearn: 2.7432197\ttotal: 5.49s\tremaining: 51.1s\n",
      "446:\tlearn: 2.7417533\ttotal: 5.5s\tremaining: 51.1s\n",
      "447:\tlearn: 2.7408894\ttotal: 5.51s\tremaining: 51.1s\n",
      "448:\tlearn: 2.7390290\ttotal: 5.53s\tremaining: 51.1s\n",
      "449:\tlearn: 2.7373053\ttotal: 5.54s\tremaining: 51.1s\n",
      "450:\tlearn: 2.7363360\ttotal: 5.55s\tremaining: 51s\n",
      "451:\tlearn: 2.7352884\ttotal: 5.56s\tremaining: 51s\n",
      "452:\tlearn: 2.7343484\ttotal: 5.58s\tremaining: 51s\n",
      "453:\tlearn: 2.7328731\ttotal: 5.59s\tremaining: 51s\n",
      "454:\tlearn: 2.7316848\ttotal: 5.6s\tremaining: 51s\n",
      "455:\tlearn: 2.7304959\ttotal: 5.61s\tremaining: 51s\n",
      "456:\tlearn: 2.7299780\ttotal: 5.62s\tremaining: 50.9s\n",
      "457:\tlearn: 2.7290352\ttotal: 5.63s\tremaining: 50.9s\n",
      "458:\tlearn: 2.7283407\ttotal: 5.64s\tremaining: 50.9s\n",
      "459:\tlearn: 2.7256921\ttotal: 5.66s\tremaining: 50.9s\n",
      "460:\tlearn: 2.7242560\ttotal: 5.67s\tremaining: 50.9s\n",
      "461:\tlearn: 2.7224295\ttotal: 5.68s\tremaining: 50.9s\n",
      "462:\tlearn: 2.7218138\ttotal: 5.69s\tremaining: 50.8s\n",
      "463:\tlearn: 2.7207646\ttotal: 5.71s\tremaining: 50.8s\n",
      "464:\tlearn: 2.7183864\ttotal: 5.72s\tremaining: 50.8s\n",
      "465:\tlearn: 2.7174251\ttotal: 5.73s\tremaining: 50.8s\n",
      "466:\tlearn: 2.7156067\ttotal: 5.74s\tremaining: 50.8s\n",
      "467:\tlearn: 2.7150163\ttotal: 5.75s\tremaining: 50.8s\n",
      "468:\tlearn: 2.7139199\ttotal: 5.76s\tremaining: 50.7s\n",
      "469:\tlearn: 2.7130875\ttotal: 5.77s\tremaining: 50.7s\n",
      "470:\tlearn: 2.7123173\ttotal: 5.79s\tremaining: 50.7s\n",
      "471:\tlearn: 2.7116114\ttotal: 5.8s\tremaining: 50.7s\n",
      "472:\tlearn: 2.7101420\ttotal: 5.81s\tremaining: 50.7s\n",
      "473:\tlearn: 2.7079554\ttotal: 5.82s\tremaining: 50.7s\n",
      "474:\tlearn: 2.7070097\ttotal: 5.83s\tremaining: 50.7s\n",
      "475:\tlearn: 2.7057453\ttotal: 5.85s\tremaining: 50.6s\n",
      "476:\tlearn: 2.7044596\ttotal: 5.86s\tremaining: 50.6s\n",
      "477:\tlearn: 2.7030207\ttotal: 5.87s\tremaining: 50.6s\n",
      "478:\tlearn: 2.7012676\ttotal: 5.88s\tremaining: 50.6s\n",
      "479:\tlearn: 2.7002033\ttotal: 5.9s\tremaining: 50.6s\n",
      "480:\tlearn: 2.6987757\ttotal: 5.91s\tremaining: 50.6s\n",
      "481:\tlearn: 2.6973018\ttotal: 5.92s\tremaining: 50.6s\n",
      "482:\tlearn: 2.6958055\ttotal: 5.93s\tremaining: 50.6s\n",
      "483:\tlearn: 2.6947014\ttotal: 5.95s\tremaining: 50.5s\n",
      "484:\tlearn: 2.6943025\ttotal: 5.96s\tremaining: 50.5s\n",
      "485:\tlearn: 2.6928718\ttotal: 5.97s\tremaining: 50.5s\n",
      "486:\tlearn: 2.6921718\ttotal: 5.98s\tremaining: 50.5s\n",
      "487:\tlearn: 2.6912464\ttotal: 5.99s\tremaining: 50.5s\n",
      "488:\tlearn: 2.6906504\ttotal: 6s\tremaining: 50.5s\n",
      "489:\tlearn: 2.6893873\ttotal: 6.02s\tremaining: 50.5s\n",
      "490:\tlearn: 2.6883824\ttotal: 6.03s\tremaining: 50.5s\n",
      "491:\tlearn: 2.6875119\ttotal: 6.05s\tremaining: 50.5s\n",
      "492:\tlearn: 2.6868570\ttotal: 6.06s\tremaining: 50.5s\n",
      "493:\tlearn: 2.6862454\ttotal: 6.07s\tremaining: 50.5s\n",
      "494:\tlearn: 2.6843296\ttotal: 6.09s\tremaining: 50.5s\n",
      "495:\tlearn: 2.6836237\ttotal: 6.1s\tremaining: 50.5s\n",
      "496:\tlearn: 2.6827787\ttotal: 6.11s\tremaining: 50.4s\n",
      "497:\tlearn: 2.6818334\ttotal: 6.13s\tremaining: 50.4s\n",
      "498:\tlearn: 2.6794287\ttotal: 6.14s\tremaining: 50.4s\n",
      "499:\tlearn: 2.6784090\ttotal: 6.15s\tremaining: 50.4s\n",
      "500:\tlearn: 2.6778010\ttotal: 6.16s\tremaining: 50.4s\n",
      "501:\tlearn: 2.6764857\ttotal: 6.18s\tremaining: 50.4s\n",
      "502:\tlearn: 2.6756646\ttotal: 6.19s\tremaining: 50.4s\n",
      "503:\tlearn: 2.6751229\ttotal: 6.2s\tremaining: 50.4s\n",
      "504:\tlearn: 2.6742444\ttotal: 6.22s\tremaining: 50.4s\n",
      "505:\tlearn: 2.6736175\ttotal: 6.23s\tremaining: 50.4s\n",
      "506:\tlearn: 2.6726526\ttotal: 6.24s\tremaining: 50.3s\n",
      "507:\tlearn: 2.6720700\ttotal: 6.25s\tremaining: 50.3s\n",
      "508:\tlearn: 2.6712383\ttotal: 6.26s\tremaining: 50.3s\n",
      "509:\tlearn: 2.6700279\ttotal: 6.27s\tremaining: 50.3s\n",
      "510:\tlearn: 2.6685506\ttotal: 6.28s\tremaining: 50.3s\n",
      "511:\tlearn: 2.6677847\ttotal: 6.3s\tremaining: 50.3s\n",
      "512:\tlearn: 2.6669951\ttotal: 6.31s\tremaining: 50.2s\n",
      "513:\tlearn: 2.6664262\ttotal: 6.32s\tremaining: 50.2s\n",
      "514:\tlearn: 2.6650354\ttotal: 6.33s\tremaining: 50.2s\n",
      "515:\tlearn: 2.6635728\ttotal: 6.34s\tremaining: 50.2s\n",
      "516:\tlearn: 2.6613957\ttotal: 6.36s\tremaining: 50.2s\n",
      "517:\tlearn: 2.6603858\ttotal: 6.37s\tremaining: 50.1s\n",
      "518:\tlearn: 2.6590562\ttotal: 6.38s\tremaining: 50.1s\n",
      "519:\tlearn: 2.6573979\ttotal: 6.39s\tremaining: 50.1s\n",
      "520:\tlearn: 2.6563672\ttotal: 6.4s\tremaining: 50.1s\n",
      "521:\tlearn: 2.6540962\ttotal: 6.42s\tremaining: 50.1s\n",
      "522:\tlearn: 2.6532593\ttotal: 6.43s\tremaining: 50.1s\n",
      "523:\tlearn: 2.6520602\ttotal: 6.44s\tremaining: 50.1s\n",
      "524:\tlearn: 2.6520332\ttotal: 6.45s\tremaining: 50s\n",
      "525:\tlearn: 2.6509653\ttotal: 6.46s\tremaining: 50s\n",
      "526:\tlearn: 2.6492752\ttotal: 6.47s\tremaining: 50s\n",
      "527:\tlearn: 2.6477667\ttotal: 6.49s\tremaining: 50s\n",
      "528:\tlearn: 2.6467118\ttotal: 6.5s\tremaining: 50s\n",
      "529:\tlearn: 2.6455270\ttotal: 6.51s\tremaining: 50s\n",
      "530:\tlearn: 2.6446281\ttotal: 6.52s\tremaining: 49.9s\n",
      "531:\tlearn: 2.6439331\ttotal: 6.53s\tremaining: 49.9s\n",
      "532:\tlearn: 2.6427068\ttotal: 6.54s\tremaining: 49.9s\n",
      "533:\tlearn: 2.6416457\ttotal: 6.55s\tremaining: 49.9s\n",
      "534:\tlearn: 2.6408326\ttotal: 6.57s\tremaining: 49.9s\n",
      "535:\tlearn: 2.6398200\ttotal: 6.58s\tremaining: 49.9s\n",
      "536:\tlearn: 2.6377787\ttotal: 6.59s\tremaining: 49.8s\n",
      "537:\tlearn: 2.6366036\ttotal: 6.6s\tremaining: 49.8s\n",
      "538:\tlearn: 2.6360181\ttotal: 6.61s\tremaining: 49.8s\n",
      "539:\tlearn: 2.6347844\ttotal: 6.63s\tremaining: 49.8s\n",
      "540:\tlearn: 2.6340128\ttotal: 6.64s\tremaining: 49.8s\n",
      "541:\tlearn: 2.6331136\ttotal: 6.65s\tremaining: 49.8s\n",
      "542:\tlearn: 2.6323277\ttotal: 6.66s\tremaining: 49.7s\n",
      "543:\tlearn: 2.6314351\ttotal: 6.67s\tremaining: 49.7s\n",
      "544:\tlearn: 2.6308962\ttotal: 6.68s\tremaining: 49.7s\n",
      "545:\tlearn: 2.6299225\ttotal: 6.69s\tremaining: 49.7s\n",
      "546:\tlearn: 2.6292541\ttotal: 6.71s\tremaining: 49.7s\n",
      "547:\tlearn: 2.6286653\ttotal: 6.72s\tremaining: 49.6s\n",
      "548:\tlearn: 2.6272190\ttotal: 6.73s\tremaining: 49.6s\n",
      "549:\tlearn: 2.6264449\ttotal: 6.74s\tremaining: 49.6s\n",
      "550:\tlearn: 2.6256595\ttotal: 6.75s\tremaining: 49.6s\n",
      "551:\tlearn: 2.6245120\ttotal: 6.76s\tremaining: 49.6s\n",
      "552:\tlearn: 2.6240850\ttotal: 6.77s\tremaining: 49.5s\n",
      "553:\tlearn: 2.6229703\ttotal: 6.79s\tremaining: 49.5s\n",
      "554:\tlearn: 2.6225522\ttotal: 6.79s\tremaining: 49.5s\n",
      "555:\tlearn: 2.6212741\ttotal: 6.81s\tremaining: 49.5s\n",
      "556:\tlearn: 2.6201531\ttotal: 6.82s\tremaining: 49.5s\n",
      "557:\tlearn: 2.6187030\ttotal: 6.83s\tremaining: 49.5s\n",
      "558:\tlearn: 2.6176734\ttotal: 6.84s\tremaining: 49.5s\n",
      "559:\tlearn: 2.6169331\ttotal: 6.86s\tremaining: 49.5s\n",
      "560:\tlearn: 2.6154147\ttotal: 6.87s\tremaining: 49.4s\n",
      "561:\tlearn: 2.6149788\ttotal: 6.88s\tremaining: 49.4s\n",
      "562:\tlearn: 2.6142122\ttotal: 6.89s\tremaining: 49.4s\n",
      "563:\tlearn: 2.6130364\ttotal: 6.9s\tremaining: 49.4s\n",
      "564:\tlearn: 2.6116700\ttotal: 6.92s\tremaining: 49.4s\n",
      "565:\tlearn: 2.6103927\ttotal: 6.93s\tremaining: 49.3s\n",
      "566:\tlearn: 2.6093907\ttotal: 6.94s\tremaining: 49.3s\n",
      "567:\tlearn: 2.6077960\ttotal: 6.95s\tremaining: 49.3s\n",
      "568:\tlearn: 2.6063715\ttotal: 6.96s\tremaining: 49.3s\n",
      "569:\tlearn: 2.6053782\ttotal: 6.97s\tremaining: 49.3s\n",
      "570:\tlearn: 2.6043174\ttotal: 6.99s\tremaining: 49.3s\n",
      "571:\tlearn: 2.6028580\ttotal: 7s\tremaining: 49.3s\n",
      "572:\tlearn: 2.6018276\ttotal: 7.01s\tremaining: 49.2s\n",
      "573:\tlearn: 2.6009062\ttotal: 7.02s\tremaining: 49.2s\n",
      "574:\tlearn: 2.5993458\ttotal: 7.03s\tremaining: 49.2s\n",
      "575:\tlearn: 2.5987658\ttotal: 7.04s\tremaining: 49.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576:\tlearn: 2.5969343\ttotal: 7.06s\tremaining: 49.2s\n",
      "577:\tlearn: 2.5959653\ttotal: 7.07s\tremaining: 49.2s\n",
      "578:\tlearn: 2.5954158\ttotal: 7.08s\tremaining: 49.2s\n",
      "579:\tlearn: 2.5943535\ttotal: 7.09s\tremaining: 49.1s\n",
      "580:\tlearn: 2.5928115\ttotal: 7.11s\tremaining: 49.1s\n",
      "581:\tlearn: 2.5901662\ttotal: 7.12s\tremaining: 49.1s\n",
      "582:\tlearn: 2.5891084\ttotal: 7.13s\tremaining: 49.1s\n",
      "583:\tlearn: 2.5880792\ttotal: 7.14s\tremaining: 49.1s\n",
      "584:\tlearn: 2.5872869\ttotal: 7.16s\tremaining: 49.1s\n",
      "585:\tlearn: 2.5853262\ttotal: 7.17s\tremaining: 49.1s\n",
      "586:\tlearn: 2.5839557\ttotal: 7.18s\tremaining: 49.1s\n",
      "587:\tlearn: 2.5826425\ttotal: 7.19s\tremaining: 49.1s\n",
      "588:\tlearn: 2.5811820\ttotal: 7.21s\tremaining: 49s\n",
      "589:\tlearn: 2.5800266\ttotal: 7.22s\tremaining: 49s\n",
      "590:\tlearn: 2.5791541\ttotal: 7.23s\tremaining: 49s\n",
      "591:\tlearn: 2.5779604\ttotal: 7.24s\tremaining: 49s\n",
      "592:\tlearn: 2.5769940\ttotal: 7.25s\tremaining: 49s\n",
      "593:\tlearn: 2.5763930\ttotal: 7.27s\tremaining: 49s\n",
      "594:\tlearn: 2.5758181\ttotal: 7.28s\tremaining: 49s\n",
      "595:\tlearn: 2.5743557\ttotal: 7.29s\tremaining: 49s\n",
      "596:\tlearn: 2.5731703\ttotal: 7.3s\tremaining: 48.9s\n",
      "597:\tlearn: 2.5731590\ttotal: 7.31s\tremaining: 48.9s\n",
      "598:\tlearn: 2.5726220\ttotal: 7.32s\tremaining: 48.9s\n",
      "599:\tlearn: 2.5723308\ttotal: 7.34s\tremaining: 48.9s\n",
      "600:\tlearn: 2.5711483\ttotal: 7.35s\tremaining: 48.9s\n",
      "601:\tlearn: 2.5706650\ttotal: 7.36s\tremaining: 48.9s\n",
      "602:\tlearn: 2.5696824\ttotal: 7.37s\tremaining: 48.8s\n",
      "603:\tlearn: 2.5681422\ttotal: 7.38s\tremaining: 48.8s\n",
      "604:\tlearn: 2.5676328\ttotal: 7.4s\tremaining: 48.8s\n",
      "605:\tlearn: 2.5667437\ttotal: 7.41s\tremaining: 48.8s\n",
      "606:\tlearn: 2.5661077\ttotal: 7.42s\tremaining: 48.8s\n",
      "607:\tlearn: 2.5655622\ttotal: 7.43s\tremaining: 48.8s\n",
      "608:\tlearn: 2.5646223\ttotal: 7.44s\tremaining: 48.8s\n",
      "609:\tlearn: 2.5633079\ttotal: 7.46s\tremaining: 48.7s\n",
      "610:\tlearn: 2.5625637\ttotal: 7.47s\tremaining: 48.7s\n",
      "611:\tlearn: 2.5607370\ttotal: 7.48s\tremaining: 48.7s\n",
      "612:\tlearn: 2.5599595\ttotal: 7.5s\tremaining: 48.7s\n",
      "613:\tlearn: 2.5589923\ttotal: 7.51s\tremaining: 48.7s\n",
      "614:\tlearn: 2.5582999\ttotal: 7.52s\tremaining: 48.7s\n",
      "615:\tlearn: 2.5575634\ttotal: 7.53s\tremaining: 48.7s\n",
      "616:\tlearn: 2.5568022\ttotal: 7.54s\tremaining: 48.7s\n",
      "617:\tlearn: 2.5555962\ttotal: 7.56s\tremaining: 48.7s\n",
      "618:\tlearn: 2.5548937\ttotal: 7.57s\tremaining: 48.7s\n",
      "619:\tlearn: 2.5540033\ttotal: 7.58s\tremaining: 48.6s\n",
      "620:\tlearn: 2.5531119\ttotal: 7.59s\tremaining: 48.6s\n",
      "621:\tlearn: 2.5522734\ttotal: 7.61s\tremaining: 48.6s\n",
      "622:\tlearn: 2.5516307\ttotal: 7.62s\tremaining: 48.6s\n",
      "623:\tlearn: 2.5508383\ttotal: 7.63s\tremaining: 48.6s\n",
      "624:\tlearn: 2.5494105\ttotal: 7.64s\tremaining: 48.6s\n",
      "625:\tlearn: 2.5486185\ttotal: 7.65s\tremaining: 48.6s\n",
      "626:\tlearn: 2.5475841\ttotal: 7.67s\tremaining: 48.5s\n",
      "627:\tlearn: 2.5464954\ttotal: 7.68s\tremaining: 48.5s\n",
      "628:\tlearn: 2.5450820\ttotal: 7.69s\tremaining: 48.5s\n",
      "629:\tlearn: 2.5438315\ttotal: 7.7s\tremaining: 48.5s\n",
      "630:\tlearn: 2.5433187\ttotal: 7.71s\tremaining: 48.5s\n",
      "631:\tlearn: 2.5425240\ttotal: 7.73s\tremaining: 48.5s\n",
      "632:\tlearn: 2.5413427\ttotal: 7.74s\tremaining: 48.5s\n",
      "633:\tlearn: 2.5402568\ttotal: 7.75s\tremaining: 48.5s\n",
      "634:\tlearn: 2.5399244\ttotal: 7.76s\tremaining: 48.5s\n",
      "635:\tlearn: 2.5395596\ttotal: 7.78s\tremaining: 48.4s\n",
      "636:\tlearn: 2.5381392\ttotal: 7.79s\tremaining: 48.4s\n",
      "637:\tlearn: 2.5372392\ttotal: 7.8s\tremaining: 48.4s\n",
      "638:\tlearn: 2.5364215\ttotal: 7.81s\tremaining: 48.4s\n",
      "639:\tlearn: 2.5352427\ttotal: 7.82s\tremaining: 48.4s\n",
      "640:\tlearn: 2.5341913\ttotal: 7.83s\tremaining: 48.4s\n",
      "641:\tlearn: 2.5327811\ttotal: 7.85s\tremaining: 48.4s\n",
      "642:\tlearn: 2.5320101\ttotal: 7.86s\tremaining: 48.3s\n",
      "643:\tlearn: 2.5311085\ttotal: 7.87s\tremaining: 48.3s\n",
      "644:\tlearn: 2.5301029\ttotal: 7.88s\tremaining: 48.3s\n",
      "645:\tlearn: 2.5291944\ttotal: 7.89s\tremaining: 48.3s\n",
      "646:\tlearn: 2.5280133\ttotal: 7.91s\tremaining: 48.3s\n",
      "647:\tlearn: 2.5271484\ttotal: 7.92s\tremaining: 48.3s\n",
      "648:\tlearn: 2.5267445\ttotal: 7.93s\tremaining: 48.3s\n",
      "649:\tlearn: 2.5252583\ttotal: 7.95s\tremaining: 48.3s\n",
      "650:\tlearn: 2.5249507\ttotal: 7.96s\tremaining: 48.2s\n",
      "651:\tlearn: 2.5238731\ttotal: 7.97s\tremaining: 48.2s\n",
      "652:\tlearn: 2.5221958\ttotal: 7.98s\tremaining: 48.2s\n",
      "653:\tlearn: 2.5205906\ttotal: 7.99s\tremaining: 48.2s\n",
      "654:\tlearn: 2.5194918\ttotal: 8.01s\tremaining: 48.2s\n",
      "655:\tlearn: 2.5179272\ttotal: 8.02s\tremaining: 48.2s\n",
      "656:\tlearn: 2.5175062\ttotal: 8.03s\tremaining: 48.2s\n",
      "657:\tlearn: 2.5168433\ttotal: 8.04s\tremaining: 48.1s\n",
      "658:\tlearn: 2.5159912\ttotal: 8.05s\tremaining: 48.1s\n",
      "659:\tlearn: 2.5151449\ttotal: 8.06s\tremaining: 48.1s\n",
      "660:\tlearn: 2.5138935\ttotal: 8.08s\tremaining: 48.1s\n",
      "661:\tlearn: 2.5136066\ttotal: 8.09s\tremaining: 48.1s\n",
      "662:\tlearn: 2.5123741\ttotal: 8.1s\tremaining: 48.1s\n",
      "663:\tlearn: 2.5115844\ttotal: 8.11s\tremaining: 48.1s\n",
      "664:\tlearn: 2.5087524\ttotal: 8.13s\tremaining: 48.1s\n",
      "665:\tlearn: 2.5077855\ttotal: 8.14s\tremaining: 48.1s\n",
      "666:\tlearn: 2.5070078\ttotal: 8.15s\tremaining: 48.1s\n",
      "667:\tlearn: 2.5057977\ttotal: 8.17s\tremaining: 48s\n",
      "668:\tlearn: 2.5047119\ttotal: 8.18s\tremaining: 48s\n",
      "669:\tlearn: 2.5038577\ttotal: 8.19s\tremaining: 48s\n",
      "670:\tlearn: 2.5024046\ttotal: 8.2s\tremaining: 48s\n",
      "671:\tlearn: 2.5014737\ttotal: 8.21s\tremaining: 48s\n",
      "672:\tlearn: 2.5003194\ttotal: 8.22s\tremaining: 48s\n",
      "673:\tlearn: 2.4995097\ttotal: 8.24s\tremaining: 47.9s\n",
      "674:\tlearn: 2.4990648\ttotal: 8.25s\tremaining: 47.9s\n",
      "675:\tlearn: 2.4985418\ttotal: 8.26s\tremaining: 47.9s\n",
      "676:\tlearn: 2.4980060\ttotal: 8.27s\tremaining: 47.9s\n",
      "677:\tlearn: 2.4970456\ttotal: 8.28s\tremaining: 47.9s\n",
      "678:\tlearn: 2.4963347\ttotal: 8.29s\tremaining: 47.9s\n",
      "679:\tlearn: 2.4958253\ttotal: 8.3s\tremaining: 47.9s\n",
      "680:\tlearn: 2.4948633\ttotal: 8.32s\tremaining: 47.8s\n",
      "681:\tlearn: 2.4936604\ttotal: 8.33s\tremaining: 47.8s\n",
      "682:\tlearn: 2.4928510\ttotal: 8.34s\tremaining: 47.8s\n",
      "683:\tlearn: 2.4921327\ttotal: 8.36s\tremaining: 47.8s\n",
      "684:\tlearn: 2.4915266\ttotal: 8.37s\tremaining: 47.8s\n",
      "685:\tlearn: 2.4910067\ttotal: 8.38s\tremaining: 47.8s\n",
      "686:\tlearn: 2.4900283\ttotal: 8.39s\tremaining: 47.8s\n",
      "687:\tlearn: 2.4885760\ttotal: 8.4s\tremaining: 47.8s\n",
      "688:\tlearn: 2.4877438\ttotal: 8.41s\tremaining: 47.7s\n",
      "689:\tlearn: 2.4866814\ttotal: 8.43s\tremaining: 47.7s\n",
      "690:\tlearn: 2.4854781\ttotal: 8.44s\tremaining: 47.7s\n",
      "691:\tlearn: 2.4846588\ttotal: 8.45s\tremaining: 47.7s\n",
      "692:\tlearn: 2.4832877\ttotal: 8.46s\tremaining: 47.7s\n",
      "693:\tlearn: 2.4825916\ttotal: 8.47s\tremaining: 47.7s\n",
      "694:\tlearn: 2.4818072\ttotal: 8.49s\tremaining: 47.7s\n",
      "695:\tlearn: 2.4811488\ttotal: 8.5s\tremaining: 47.6s\n",
      "696:\tlearn: 2.4804060\ttotal: 8.51s\tremaining: 47.6s\n",
      "697:\tlearn: 2.4793421\ttotal: 8.52s\tremaining: 47.6s\n",
      "698:\tlearn: 2.4782250\ttotal: 8.54s\tremaining: 47.6s\n",
      "699:\tlearn: 2.4770258\ttotal: 8.55s\tremaining: 47.6s\n",
      "700:\tlearn: 2.4761743\ttotal: 8.56s\tremaining: 47.6s\n",
      "701:\tlearn: 2.4755152\ttotal: 8.57s\tremaining: 47.6s\n",
      "702:\tlearn: 2.4750581\ttotal: 8.58s\tremaining: 47.6s\n",
      "703:\tlearn: 2.4736942\ttotal: 8.6s\tremaining: 47.5s\n",
      "704:\tlearn: 2.4731699\ttotal: 8.61s\tremaining: 47.5s\n",
      "705:\tlearn: 2.4719873\ttotal: 8.62s\tremaining: 47.5s\n",
      "706:\tlearn: 2.4710689\ttotal: 8.63s\tremaining: 47.5s\n",
      "707:\tlearn: 2.4697086\ttotal: 8.64s\tremaining: 47.5s\n",
      "708:\tlearn: 2.4690640\ttotal: 8.66s\tremaining: 47.5s\n",
      "709:\tlearn: 2.4684490\ttotal: 8.67s\tremaining: 47.5s\n",
      "710:\tlearn: 2.4675399\ttotal: 8.68s\tremaining: 47.5s\n",
      "711:\tlearn: 2.4663475\ttotal: 8.69s\tremaining: 47.4s\n",
      "712:\tlearn: 2.4658518\ttotal: 8.7s\tremaining: 47.4s\n",
      "713:\tlearn: 2.4650224\ttotal: 8.72s\tremaining: 47.4s\n",
      "714:\tlearn: 2.4644906\ttotal: 8.73s\tremaining: 47.4s\n",
      "715:\tlearn: 2.4636474\ttotal: 8.74s\tremaining: 47.4s\n",
      "716:\tlearn: 2.4630142\ttotal: 8.75s\tremaining: 47.4s\n",
      "717:\tlearn: 2.4619882\ttotal: 8.77s\tremaining: 47.4s\n",
      "718:\tlearn: 2.4607428\ttotal: 8.78s\tremaining: 47.4s\n",
      "719:\tlearn: 2.4601588\ttotal: 8.79s\tremaining: 47.4s\n",
      "720:\tlearn: 2.4584998\ttotal: 8.8s\tremaining: 47.4s\n",
      "721:\tlearn: 2.4572907\ttotal: 8.82s\tremaining: 47.3s\n",
      "722:\tlearn: 2.4564248\ttotal: 8.83s\tremaining: 47.3s\n",
      "723:\tlearn: 2.4558451\ttotal: 8.84s\tremaining: 47.3s\n",
      "724:\tlearn: 2.4545681\ttotal: 8.85s\tremaining: 47.3s\n",
      "725:\tlearn: 2.4536525\ttotal: 8.87s\tremaining: 47.3s\n",
      "726:\tlearn: 2.4530614\ttotal: 8.88s\tremaining: 47.3s\n",
      "727:\tlearn: 2.4518578\ttotal: 8.89s\tremaining: 47.3s\n",
      "728:\tlearn: 2.4507896\ttotal: 8.9s\tremaining: 47.2s\n",
      "729:\tlearn: 2.4503641\ttotal: 8.91s\tremaining: 47.2s\n",
      "730:\tlearn: 2.4496759\ttotal: 8.92s\tremaining: 47.2s\n",
      "731:\tlearn: 2.4484571\ttotal: 8.94s\tremaining: 47.2s\n",
      "732:\tlearn: 2.4479597\ttotal: 8.95s\tremaining: 47.2s\n",
      "733:\tlearn: 2.4472457\ttotal: 8.96s\tremaining: 47.2s\n",
      "734:\tlearn: 2.4465656\ttotal: 8.97s\tremaining: 47.2s\n",
      "735:\tlearn: 2.4460096\ttotal: 8.99s\tremaining: 47.2s\n",
      "736:\tlearn: 2.4448363\ttotal: 9s\tremaining: 47.1s\n",
      "737:\tlearn: 2.4436660\ttotal: 9.01s\tremaining: 47.1s\n",
      "738:\tlearn: 2.4426583\ttotal: 9.02s\tremaining: 47.1s\n",
      "739:\tlearn: 2.4417742\ttotal: 9.04s\tremaining: 47.1s\n",
      "740:\tlearn: 2.4405631\ttotal: 9.05s\tremaining: 47.1s\n",
      "741:\tlearn: 2.4397481\ttotal: 9.06s\tremaining: 47.1s\n",
      "742:\tlearn: 2.4391175\ttotal: 9.07s\tremaining: 47.1s\n",
      "743:\tlearn: 2.4379803\ttotal: 9.08s\tremaining: 47.1s\n",
      "744:\tlearn: 2.4354406\ttotal: 9.1s\tremaining: 47s\n",
      "745:\tlearn: 2.4340952\ttotal: 9.11s\tremaining: 47s\n",
      "746:\tlearn: 2.4335659\ttotal: 9.12s\tremaining: 47s\n",
      "747:\tlearn: 2.4330040\ttotal: 9.13s\tremaining: 47s\n",
      "748:\tlearn: 2.4318012\ttotal: 9.14s\tremaining: 47s\n",
      "749:\tlearn: 2.4312007\ttotal: 9.16s\tremaining: 47s\n",
      "750:\tlearn: 2.4302890\ttotal: 9.17s\tremaining: 47s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751:\tlearn: 2.4297702\ttotal: 9.18s\tremaining: 47s\n",
      "752:\tlearn: 2.4289234\ttotal: 9.2s\tremaining: 47s\n",
      "753:\tlearn: 2.4279783\ttotal: 9.21s\tremaining: 46.9s\n",
      "754:\tlearn: 2.4269858\ttotal: 9.22s\tremaining: 46.9s\n",
      "755:\tlearn: 2.4263170\ttotal: 9.23s\tremaining: 46.9s\n",
      "756:\tlearn: 2.4248877\ttotal: 9.24s\tremaining: 46.9s\n",
      "757:\tlearn: 2.4244218\ttotal: 9.26s\tremaining: 46.9s\n",
      "758:\tlearn: 2.4232881\ttotal: 9.27s\tremaining: 46.9s\n",
      "759:\tlearn: 2.4224791\ttotal: 9.28s\tremaining: 46.9s\n",
      "760:\tlearn: 2.4218237\ttotal: 9.29s\tremaining: 46.8s\n",
      "761:\tlearn: 2.4210568\ttotal: 9.3s\tremaining: 46.8s\n",
      "762:\tlearn: 2.4199436\ttotal: 9.31s\tremaining: 46.8s\n",
      "763:\tlearn: 2.4194423\ttotal: 9.33s\tremaining: 46.8s\n",
      "764:\tlearn: 2.4183975\ttotal: 9.34s\tremaining: 46.8s\n",
      "765:\tlearn: 2.4179616\ttotal: 9.35s\tremaining: 46.8s\n",
      "766:\tlearn: 2.4175029\ttotal: 9.36s\tremaining: 46.8s\n",
      "767:\tlearn: 2.4158802\ttotal: 9.37s\tremaining: 46.8s\n",
      "768:\tlearn: 2.4157299\ttotal: 9.39s\tremaining: 46.7s\n",
      "769:\tlearn: 2.4144498\ttotal: 9.4s\tremaining: 46.7s\n",
      "770:\tlearn: 2.4131632\ttotal: 9.41s\tremaining: 46.7s\n",
      "771:\tlearn: 2.4121508\ttotal: 9.43s\tremaining: 46.7s\n",
      "772:\tlearn: 2.4118788\ttotal: 9.44s\tremaining: 46.7s\n",
      "773:\tlearn: 2.4111985\ttotal: 9.45s\tremaining: 46.7s\n",
      "774:\tlearn: 2.4099265\ttotal: 9.46s\tremaining: 46.7s\n",
      "775:\tlearn: 2.4095374\ttotal: 9.48s\tremaining: 46.7s\n",
      "776:\tlearn: 2.4090130\ttotal: 9.49s\tremaining: 46.7s\n",
      "777:\tlearn: 2.4082800\ttotal: 9.5s\tremaining: 46.7s\n",
      "778:\tlearn: 2.4074396\ttotal: 9.51s\tremaining: 46.6s\n",
      "779:\tlearn: 2.4067549\ttotal: 9.52s\tremaining: 46.6s\n",
      "780:\tlearn: 2.4051337\ttotal: 9.54s\tremaining: 46.6s\n",
      "781:\tlearn: 2.4045787\ttotal: 9.55s\tremaining: 46.6s\n",
      "782:\tlearn: 2.4041884\ttotal: 9.56s\tremaining: 46.6s\n",
      "783:\tlearn: 2.4037036\ttotal: 9.57s\tremaining: 46.6s\n",
      "784:\tlearn: 2.4029130\ttotal: 9.58s\tremaining: 46.5s\n",
      "785:\tlearn: 2.4023166\ttotal: 9.59s\tremaining: 46.5s\n",
      "786:\tlearn: 2.4021108\ttotal: 9.61s\tremaining: 46.5s\n",
      "787:\tlearn: 2.4009254\ttotal: 9.62s\tremaining: 46.5s\n",
      "788:\tlearn: 2.3981353\ttotal: 9.63s\tremaining: 46.5s\n",
      "789:\tlearn: 2.3977186\ttotal: 9.65s\tremaining: 46.5s\n",
      "790:\tlearn: 2.3964722\ttotal: 9.66s\tremaining: 46.5s\n",
      "791:\tlearn: 2.3956693\ttotal: 9.67s\tremaining: 46.5s\n",
      "792:\tlearn: 2.3951356\ttotal: 9.69s\tremaining: 46.5s\n",
      "793:\tlearn: 2.3944258\ttotal: 9.7s\tremaining: 46.5s\n",
      "794:\tlearn: 2.3939436\ttotal: 9.71s\tremaining: 46.4s\n",
      "795:\tlearn: 2.3932684\ttotal: 9.72s\tremaining: 46.4s\n",
      "796:\tlearn: 2.3926864\ttotal: 9.73s\tremaining: 46.4s\n",
      "797:\tlearn: 2.3921389\ttotal: 9.74s\tremaining: 46.4s\n",
      "798:\tlearn: 2.3908885\ttotal: 9.75s\tremaining: 46.4s\n",
      "799:\tlearn: 2.3903633\ttotal: 9.77s\tremaining: 46.4s\n",
      "800:\tlearn: 2.3898160\ttotal: 9.78s\tremaining: 46.3s\n",
      "801:\tlearn: 2.3887665\ttotal: 9.79s\tremaining: 46.3s\n",
      "802:\tlearn: 2.3882048\ttotal: 9.8s\tremaining: 46.3s\n",
      "803:\tlearn: 2.3876822\ttotal: 9.81s\tremaining: 46.3s\n",
      "804:\tlearn: 2.3865734\ttotal: 9.82s\tremaining: 46.3s\n",
      "805:\tlearn: 2.3859832\ttotal: 9.84s\tremaining: 46.3s\n",
      "806:\tlearn: 2.3851373\ttotal: 9.85s\tremaining: 46.3s\n",
      "807:\tlearn: 2.3844976\ttotal: 9.86s\tremaining: 46.3s\n",
      "808:\tlearn: 2.3836976\ttotal: 9.88s\tremaining: 46.3s\n",
      "809:\tlearn: 2.3829274\ttotal: 9.89s\tremaining: 46.2s\n",
      "810:\tlearn: 2.3820828\ttotal: 9.9s\tremaining: 46.2s\n",
      "811:\tlearn: 2.3814461\ttotal: 9.91s\tremaining: 46.2s\n",
      "812:\tlearn: 2.3806882\ttotal: 9.92s\tremaining: 46.2s\n",
      "813:\tlearn: 2.3796175\ttotal: 9.94s\tremaining: 46.2s\n",
      "814:\tlearn: 2.3782748\ttotal: 9.95s\tremaining: 46.2s\n",
      "815:\tlearn: 2.3777415\ttotal: 9.96s\tremaining: 46.2s\n",
      "816:\tlearn: 2.3773706\ttotal: 9.97s\tremaining: 46.1s\n",
      "817:\tlearn: 2.3763070\ttotal: 9.98s\tremaining: 46.1s\n",
      "818:\tlearn: 2.3748954\ttotal: 9.99s\tremaining: 46.1s\n",
      "819:\tlearn: 2.3738104\ttotal: 10s\tremaining: 46.1s\n",
      "820:\tlearn: 2.3736260\ttotal: 10s\tremaining: 46.1s\n",
      "821:\tlearn: 2.3729994\ttotal: 10s\tremaining: 46.1s\n",
      "822:\tlearn: 2.3720782\ttotal: 10s\tremaining: 46.1s\n",
      "823:\tlearn: 2.3708155\ttotal: 10.1s\tremaining: 46.1s\n",
      "824:\tlearn: 2.3698219\ttotal: 10.1s\tremaining: 46s\n",
      "825:\tlearn: 2.3688694\ttotal: 10.1s\tremaining: 46s\n",
      "826:\tlearn: 2.3681740\ttotal: 10.1s\tremaining: 46s\n",
      "827:\tlearn: 2.3675379\ttotal: 10.1s\tremaining: 46s\n",
      "828:\tlearn: 2.3667201\ttotal: 10.1s\tremaining: 46s\n",
      "829:\tlearn: 2.3659417\ttotal: 10.1s\tremaining: 46s\n",
      "830:\tlearn: 2.3651247\ttotal: 10.1s\tremaining: 46s\n",
      "831:\tlearn: 2.3640042\ttotal: 10.1s\tremaining: 45.9s\n",
      "832:\tlearn: 2.3638031\ttotal: 10.2s\tremaining: 45.9s\n",
      "833:\tlearn: 2.3632037\ttotal: 10.2s\tremaining: 45.9s\n",
      "834:\tlearn: 2.3624964\ttotal: 10.2s\tremaining: 45.9s\n",
      "835:\tlearn: 2.3612444\ttotal: 10.2s\tremaining: 45.9s\n",
      "836:\tlearn: 2.3605100\ttotal: 10.2s\tremaining: 45.9s\n",
      "837:\tlearn: 2.3600447\ttotal: 10.2s\tremaining: 45.9s\n",
      "838:\tlearn: 2.3591862\ttotal: 10.2s\tremaining: 45.8s\n",
      "839:\tlearn: 2.3584938\ttotal: 10.2s\tremaining: 45.8s\n",
      "840:\tlearn: 2.3573292\ttotal: 10.3s\tremaining: 45.8s\n",
      "841:\tlearn: 2.3568399\ttotal: 10.3s\tremaining: 45.8s\n",
      "842:\tlearn: 2.3559410\ttotal: 10.3s\tremaining: 45.8s\n",
      "843:\tlearn: 2.3546161\ttotal: 10.3s\tremaining: 45.8s\n",
      "844:\tlearn: 2.3541872\ttotal: 10.3s\tremaining: 45.8s\n",
      "845:\tlearn: 2.3536373\ttotal: 10.3s\tremaining: 45.8s\n",
      "846:\tlearn: 2.3525322\ttotal: 10.3s\tremaining: 45.7s\n",
      "847:\tlearn: 2.3520688\ttotal: 10.3s\tremaining: 45.7s\n",
      "848:\tlearn: 2.3513557\ttotal: 10.4s\tremaining: 45.7s\n",
      "849:\tlearn: 2.3500654\ttotal: 10.4s\tremaining: 45.7s\n",
      "850:\tlearn: 2.3490468\ttotal: 10.4s\tremaining: 45.7s\n",
      "851:\tlearn: 2.3482586\ttotal: 10.4s\tremaining: 45.7s\n",
      "852:\tlearn: 2.3468922\ttotal: 10.4s\tremaining: 45.7s\n",
      "853:\tlearn: 2.3465646\ttotal: 10.4s\tremaining: 45.7s\n",
      "854:\tlearn: 2.3458279\ttotal: 10.4s\tremaining: 45.7s\n",
      "855:\tlearn: 2.3452098\ttotal: 10.4s\tremaining: 45.6s\n",
      "856:\tlearn: 2.3446315\ttotal: 10.5s\tremaining: 45.6s\n",
      "857:\tlearn: 2.3439926\ttotal: 10.5s\tremaining: 45.6s\n",
      "858:\tlearn: 2.3430191\ttotal: 10.5s\tremaining: 45.6s\n",
      "859:\tlearn: 2.3415176\ttotal: 10.5s\tremaining: 45.6s\n",
      "860:\tlearn: 2.3408946\ttotal: 10.5s\tremaining: 45.6s\n",
      "861:\tlearn: 2.3402506\ttotal: 10.5s\tremaining: 45.6s\n",
      "862:\tlearn: 2.3392987\ttotal: 10.5s\tremaining: 45.6s\n",
      "863:\tlearn: 2.3389178\ttotal: 10.5s\tremaining: 45.6s\n",
      "864:\tlearn: 2.3379799\ttotal: 10.6s\tremaining: 45.5s\n",
      "865:\tlearn: 2.3375577\ttotal: 10.6s\tremaining: 45.5s\n",
      "866:\tlearn: 2.3370839\ttotal: 10.6s\tremaining: 45.5s\n",
      "867:\tlearn: 2.3365827\ttotal: 10.6s\tremaining: 45.5s\n",
      "868:\tlearn: 2.3360252\ttotal: 10.6s\tremaining: 45.5s\n",
      "869:\tlearn: 2.3353582\ttotal: 10.6s\tremaining: 45.5s\n",
      "870:\tlearn: 2.3349498\ttotal: 10.6s\tremaining: 45.5s\n",
      "871:\tlearn: 2.3347290\ttotal: 10.6s\tremaining: 45.4s\n",
      "872:\tlearn: 2.3341083\ttotal: 10.6s\tremaining: 45.4s\n",
      "873:\tlearn: 2.3332741\ttotal: 10.7s\tremaining: 45.4s\n",
      "874:\tlearn: 2.3329403\ttotal: 10.7s\tremaining: 45.4s\n",
      "875:\tlearn: 2.3325754\ttotal: 10.7s\tremaining: 45.4s\n",
      "876:\tlearn: 2.3320617\ttotal: 10.7s\tremaining: 45.4s\n",
      "877:\tlearn: 2.3319438\ttotal: 10.7s\tremaining: 45.4s\n",
      "878:\tlearn: 2.3312066\ttotal: 10.7s\tremaining: 45.4s\n",
      "879:\tlearn: 2.3302994\ttotal: 10.7s\tremaining: 45.3s\n",
      "880:\tlearn: 2.3293136\ttotal: 10.7s\tremaining: 45.3s\n",
      "881:\tlearn: 2.3285562\ttotal: 10.8s\tremaining: 45.3s\n",
      "882:\tlearn: 2.3281957\ttotal: 10.8s\tremaining: 45.3s\n",
      "883:\tlearn: 2.3275740\ttotal: 10.8s\tremaining: 45.3s\n",
      "884:\tlearn: 2.3273309\ttotal: 10.8s\tremaining: 45.3s\n",
      "885:\tlearn: 2.3257572\ttotal: 10.8s\tremaining: 45.3s\n",
      "886:\tlearn: 2.3249440\ttotal: 10.8s\tremaining: 45.3s\n",
      "887:\tlearn: 2.3238786\ttotal: 10.8s\tremaining: 45.3s\n",
      "888:\tlearn: 2.3227245\ttotal: 10.8s\tremaining: 45.2s\n",
      "889:\tlearn: 2.3218591\ttotal: 10.9s\tremaining: 45.2s\n",
      "890:\tlearn: 2.3216273\ttotal: 10.9s\tremaining: 45.2s\n",
      "891:\tlearn: 2.3205422\ttotal: 10.9s\tremaining: 45.2s\n",
      "892:\tlearn: 2.3199005\ttotal: 10.9s\tremaining: 45.2s\n",
      "893:\tlearn: 2.3189568\ttotal: 10.9s\tremaining: 45.2s\n",
      "894:\tlearn: 2.3178541\ttotal: 10.9s\tremaining: 45.2s\n",
      "895:\tlearn: 2.3167585\ttotal: 10.9s\tremaining: 45.2s\n",
      "896:\tlearn: 2.3154076\ttotal: 10.9s\tremaining: 45.2s\n",
      "897:\tlearn: 2.3152085\ttotal: 11s\tremaining: 45.1s\n",
      "898:\tlearn: 2.3140153\ttotal: 11s\tremaining: 45.1s\n",
      "899:\tlearn: 2.3136719\ttotal: 11s\tremaining: 45.1s\n",
      "900:\tlearn: 2.3125648\ttotal: 11s\tremaining: 45.1s\n",
      "901:\tlearn: 2.3107230\ttotal: 11s\tremaining: 45.1s\n",
      "902:\tlearn: 2.3100788\ttotal: 11s\tremaining: 45.1s\n",
      "903:\tlearn: 2.3085396\ttotal: 11s\tremaining: 45.1s\n",
      "904:\tlearn: 2.3073424\ttotal: 11s\tremaining: 45.1s\n",
      "905:\tlearn: 2.3067406\ttotal: 11.1s\tremaining: 45s\n",
      "906:\tlearn: 2.3061950\ttotal: 11.1s\tremaining: 45s\n",
      "907:\tlearn: 2.3053396\ttotal: 11.1s\tremaining: 45s\n",
      "908:\tlearn: 2.3043324\ttotal: 11.1s\tremaining: 45s\n",
      "909:\tlearn: 2.3040495\ttotal: 11.1s\tremaining: 45s\n",
      "910:\tlearn: 2.3032911\ttotal: 11.1s\tremaining: 45s\n",
      "911:\tlearn: 2.3028816\ttotal: 11.1s\tremaining: 45s\n",
      "912:\tlearn: 2.3022009\ttotal: 11.1s\tremaining: 45s\n",
      "913:\tlearn: 2.3007836\ttotal: 11.2s\tremaining: 45s\n",
      "914:\tlearn: 2.3003561\ttotal: 11.2s\tremaining: 44.9s\n",
      "915:\tlearn: 2.2999709\ttotal: 11.2s\tremaining: 44.9s\n",
      "916:\tlearn: 2.2990371\ttotal: 11.2s\tremaining: 44.9s\n",
      "917:\tlearn: 2.2981561\ttotal: 11.2s\tremaining: 44.9s\n",
      "918:\tlearn: 2.2976906\ttotal: 11.2s\tremaining: 44.9s\n",
      "919:\tlearn: 2.2970770\ttotal: 11.2s\tremaining: 44.9s\n",
      "920:\tlearn: 2.2967093\ttotal: 11.2s\tremaining: 44.9s\n",
      "921:\tlearn: 2.2959323\ttotal: 11.2s\tremaining: 44.8s\n",
      "922:\tlearn: 2.2949798\ttotal: 11.3s\tremaining: 44.8s\n",
      "923:\tlearn: 2.2943470\ttotal: 11.3s\tremaining: 44.8s\n",
      "924:\tlearn: 2.2938383\ttotal: 11.3s\tremaining: 44.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "925:\tlearn: 2.2930066\ttotal: 11.3s\tremaining: 44.8s\n",
      "926:\tlearn: 2.2921852\ttotal: 11.3s\tremaining: 44.8s\n",
      "927:\tlearn: 2.2917927\ttotal: 11.3s\tremaining: 44.8s\n",
      "928:\tlearn: 2.2909403\ttotal: 11.3s\tremaining: 44.8s\n",
      "929:\tlearn: 2.2904727\ttotal: 11.3s\tremaining: 44.7s\n",
      "930:\tlearn: 2.2895215\ttotal: 11.4s\tremaining: 44.7s\n",
      "931:\tlearn: 2.2887606\ttotal: 11.4s\tremaining: 44.7s\n",
      "932:\tlearn: 2.2882913\ttotal: 11.4s\tremaining: 44.7s\n",
      "933:\tlearn: 2.2880096\ttotal: 11.4s\tremaining: 44.7s\n",
      "934:\tlearn: 2.2872268\ttotal: 11.4s\tremaining: 44.7s\n",
      "935:\tlearn: 2.2862091\ttotal: 11.4s\tremaining: 44.7s\n",
      "936:\tlearn: 2.2855804\ttotal: 11.4s\tremaining: 44.7s\n",
      "937:\tlearn: 2.2850401\ttotal: 11.4s\tremaining: 44.6s\n",
      "938:\tlearn: 2.2839825\ttotal: 11.5s\tremaining: 44.6s\n",
      "939:\tlearn: 2.2832930\ttotal: 11.5s\tremaining: 44.6s\n",
      "940:\tlearn: 2.2824759\ttotal: 11.5s\tremaining: 44.6s\n",
      "941:\tlearn: 2.2819754\ttotal: 11.5s\tremaining: 44.6s\n",
      "942:\tlearn: 2.2813547\ttotal: 11.5s\tremaining: 44.6s\n",
      "943:\tlearn: 2.2809162\ttotal: 11.5s\tremaining: 44.6s\n",
      "944:\tlearn: 2.2795005\ttotal: 11.5s\tremaining: 44.5s\n",
      "945:\tlearn: 2.2784956\ttotal: 11.5s\tremaining: 44.5s\n",
      "946:\tlearn: 2.2773736\ttotal: 11.5s\tremaining: 44.5s\n",
      "947:\tlearn: 2.2768370\ttotal: 11.6s\tremaining: 44.5s\n",
      "948:\tlearn: 2.2764736\ttotal: 11.6s\tremaining: 44.5s\n",
      "949:\tlearn: 2.2759119\ttotal: 11.6s\tremaining: 44.5s\n",
      "950:\tlearn: 2.2754268\ttotal: 11.6s\tremaining: 44.5s\n",
      "951:\tlearn: 2.2745088\ttotal: 11.6s\tremaining: 44.5s\n",
      "952:\tlearn: 2.2735877\ttotal: 11.6s\tremaining: 44.4s\n",
      "953:\tlearn: 2.2729128\ttotal: 11.6s\tremaining: 44.4s\n",
      "954:\tlearn: 2.2722010\ttotal: 11.6s\tremaining: 44.4s\n",
      "955:\tlearn: 2.2715455\ttotal: 11.7s\tremaining: 44.4s\n",
      "956:\tlearn: 2.2706863\ttotal: 11.7s\tremaining: 44.4s\n",
      "957:\tlearn: 2.2698835\ttotal: 11.7s\tremaining: 44.4s\n",
      "958:\tlearn: 2.2693188\ttotal: 11.7s\tremaining: 44.4s\n",
      "959:\tlearn: 2.2687292\ttotal: 11.7s\tremaining: 44.3s\n",
      "960:\tlearn: 2.2675424\ttotal: 11.7s\tremaining: 44.3s\n",
      "961:\tlearn: 2.2670271\ttotal: 11.7s\tremaining: 44.3s\n",
      "962:\tlearn: 2.2665628\ttotal: 11.7s\tremaining: 44.3s\n",
      "963:\tlearn: 2.2657739\ttotal: 11.8s\tremaining: 44.3s\n",
      "964:\tlearn: 2.2648475\ttotal: 11.8s\tremaining: 44.3s\n",
      "965:\tlearn: 2.2644316\ttotal: 11.8s\tremaining: 44.3s\n",
      "966:\tlearn: 2.2634233\ttotal: 11.8s\tremaining: 44.3s\n",
      "967:\tlearn: 2.2634135\ttotal: 11.8s\tremaining: 44.2s\n",
      "968:\tlearn: 2.2630094\ttotal: 11.8s\tremaining: 44.2s\n",
      "969:\tlearn: 2.2626772\ttotal: 11.8s\tremaining: 44.2s\n",
      "970:\tlearn: 2.2622581\ttotal: 11.8s\tremaining: 44.2s\n",
      "971:\tlearn: 2.2614413\ttotal: 11.8s\tremaining: 44.2s\n",
      "972:\tlearn: 2.2606010\ttotal: 11.9s\tremaining: 44.2s\n",
      "973:\tlearn: 2.2598515\ttotal: 11.9s\tremaining: 44.2s\n",
      "974:\tlearn: 2.2586855\ttotal: 11.9s\tremaining: 44.2s\n",
      "975:\tlearn: 2.2578273\ttotal: 11.9s\tremaining: 44.2s\n",
      "976:\tlearn: 2.2572921\ttotal: 11.9s\tremaining: 44.1s\n",
      "977:\tlearn: 2.2569090\ttotal: 11.9s\tremaining: 44.1s\n",
      "978:\tlearn: 2.2563322\ttotal: 11.9s\tremaining: 44.1s\n",
      "979:\tlearn: 2.2556294\ttotal: 11.9s\tremaining: 44.1s\n",
      "980:\tlearn: 2.2548787\ttotal: 12s\tremaining: 44.1s\n",
      "981:\tlearn: 2.2544264\ttotal: 12s\tremaining: 44.1s\n",
      "982:\tlearn: 2.2537841\ttotal: 12s\tremaining: 44.1s\n",
      "983:\tlearn: 2.2535417\ttotal: 12s\tremaining: 44.1s\n",
      "984:\tlearn: 2.2533154\ttotal: 12s\tremaining: 44s\n",
      "985:\tlearn: 2.2526245\ttotal: 12s\tremaining: 44s\n",
      "986:\tlearn: 2.2520864\ttotal: 12s\tremaining: 44s\n",
      "987:\tlearn: 2.2513921\ttotal: 12s\tremaining: 44s\n",
      "988:\tlearn: 2.2504858\ttotal: 12.1s\tremaining: 44s\n",
      "989:\tlearn: 2.2500939\ttotal: 12.1s\tremaining: 44s\n",
      "990:\tlearn: 2.2494951\ttotal: 12.1s\tremaining: 44s\n",
      "991:\tlearn: 2.2490816\ttotal: 12.1s\tremaining: 43.9s\n",
      "992:\tlearn: 2.2486664\ttotal: 12.1s\tremaining: 43.9s\n",
      "993:\tlearn: 2.2480004\ttotal: 12.1s\tremaining: 43.9s\n",
      "994:\tlearn: 2.2468534\ttotal: 12.1s\tremaining: 43.9s\n",
      "995:\tlearn: 2.2466645\ttotal: 12.1s\tremaining: 43.9s\n",
      "996:\tlearn: 2.2458289\ttotal: 12.1s\tremaining: 43.9s\n",
      "997:\tlearn: 2.2453967\ttotal: 12.2s\tremaining: 43.9s\n",
      "998:\tlearn: 2.2448931\ttotal: 12.2s\tremaining: 43.9s\n",
      "999:\tlearn: 2.2441136\ttotal: 12.2s\tremaining: 43.8s\n",
      "1000:\tlearn: 2.2434457\ttotal: 12.2s\tremaining: 43.8s\n",
      "1001:\tlearn: 2.2428870\ttotal: 12.2s\tremaining: 43.8s\n",
      "1002:\tlearn: 2.2423770\ttotal: 12.2s\tremaining: 43.8s\n",
      "1003:\tlearn: 2.2411889\ttotal: 12.2s\tremaining: 43.8s\n",
      "1004:\tlearn: 2.2408314\ttotal: 12.2s\tremaining: 43.8s\n",
      "1005:\tlearn: 2.2402242\ttotal: 12.3s\tremaining: 43.8s\n",
      "1006:\tlearn: 2.2398564\ttotal: 12.3s\tremaining: 43.8s\n",
      "1007:\tlearn: 2.2393653\ttotal: 12.3s\tremaining: 43.7s\n",
      "1008:\tlearn: 2.2387997\ttotal: 12.3s\tremaining: 43.7s\n",
      "1009:\tlearn: 2.2382609\ttotal: 12.3s\tremaining: 43.7s\n",
      "1010:\tlearn: 2.2370524\ttotal: 12.3s\tremaining: 43.7s\n",
      "1011:\tlearn: 2.2362471\ttotal: 12.3s\tremaining: 43.7s\n",
      "1012:\tlearn: 2.2358619\ttotal: 12.3s\tremaining: 43.7s\n",
      "1013:\tlearn: 2.2349596\ttotal: 12.4s\tremaining: 43.7s\n",
      "1014:\tlearn: 2.2343872\ttotal: 12.4s\tremaining: 43.7s\n",
      "1015:\tlearn: 2.2338001\ttotal: 12.4s\tremaining: 43.6s\n",
      "1016:\tlearn: 2.2328642\ttotal: 12.4s\tremaining: 43.6s\n",
      "1017:\tlearn: 2.2320831\ttotal: 12.4s\tremaining: 43.6s\n",
      "1018:\tlearn: 2.2315366\ttotal: 12.4s\tremaining: 43.6s\n",
      "1019:\tlearn: 2.2303464\ttotal: 12.4s\tremaining: 43.6s\n",
      "1020:\tlearn: 2.2301953\ttotal: 12.4s\tremaining: 43.6s\n",
      "1021:\tlearn: 2.2296374\ttotal: 12.4s\tremaining: 43.6s\n",
      "1022:\tlearn: 2.2291542\ttotal: 12.5s\tremaining: 43.5s\n",
      "1023:\tlearn: 2.2286006\ttotal: 12.5s\tremaining: 43.5s\n",
      "1024:\tlearn: 2.2280474\ttotal: 12.5s\tremaining: 43.5s\n",
      "1025:\tlearn: 2.2275140\ttotal: 12.5s\tremaining: 43.5s\n",
      "1026:\tlearn: 2.2267375\ttotal: 12.5s\tremaining: 43.5s\n",
      "1027:\tlearn: 2.2263174\ttotal: 12.5s\tremaining: 43.5s\n",
      "1028:\tlearn: 2.2263136\ttotal: 12.5s\tremaining: 43.5s\n",
      "1029:\tlearn: 2.2254598\ttotal: 12.5s\tremaining: 43.5s\n",
      "1030:\tlearn: 2.2249191\ttotal: 12.6s\tremaining: 43.4s\n",
      "1031:\tlearn: 2.2242908\ttotal: 12.6s\tremaining: 43.4s\n",
      "1032:\tlearn: 2.2236765\ttotal: 12.6s\tremaining: 43.4s\n",
      "1033:\tlearn: 2.2226238\ttotal: 12.6s\tremaining: 43.4s\n",
      "1034:\tlearn: 2.2221692\ttotal: 12.6s\tremaining: 43.4s\n",
      "1035:\tlearn: 2.2215872\ttotal: 12.6s\tremaining: 43.4s\n",
      "1036:\tlearn: 2.2209823\ttotal: 12.6s\tremaining: 43.4s\n",
      "1037:\tlearn: 2.2206097\ttotal: 12.6s\tremaining: 43.4s\n",
      "1038:\tlearn: 2.2197495\ttotal: 12.7s\tremaining: 43.3s\n",
      "1039:\tlearn: 2.2192663\ttotal: 12.7s\tremaining: 43.3s\n",
      "1040:\tlearn: 2.2187479\ttotal: 12.7s\tremaining: 43.3s\n",
      "1041:\tlearn: 2.2182528\ttotal: 12.7s\tremaining: 43.3s\n",
      "1042:\tlearn: 2.2174235\ttotal: 12.7s\tremaining: 43.3s\n",
      "1043:\tlearn: 2.2167305\ttotal: 12.7s\tremaining: 43.3s\n",
      "1044:\tlearn: 2.2157192\ttotal: 12.7s\tremaining: 43.3s\n",
      "1045:\tlearn: 2.2153884\ttotal: 12.7s\tremaining: 43.3s\n",
      "1046:\tlearn: 2.2149216\ttotal: 12.8s\tremaining: 43.2s\n",
      "1047:\tlearn: 2.2144682\ttotal: 12.8s\tremaining: 43.2s\n",
      "1048:\tlearn: 2.2141671\ttotal: 12.8s\tremaining: 43.2s\n",
      "1049:\tlearn: 2.2138365\ttotal: 12.8s\tremaining: 43.2s\n",
      "1050:\tlearn: 2.2125963\ttotal: 12.8s\tremaining: 43.2s\n",
      "1051:\tlearn: 2.2121843\ttotal: 12.8s\tremaining: 43.2s\n",
      "1052:\tlearn: 2.2117113\ttotal: 12.8s\tremaining: 43.2s\n",
      "1053:\tlearn: 2.2108806\ttotal: 12.8s\tremaining: 43.2s\n",
      "1054:\tlearn: 2.2102808\ttotal: 12.8s\tremaining: 43.1s\n",
      "1055:\tlearn: 2.2098073\ttotal: 12.9s\tremaining: 43.1s\n",
      "1056:\tlearn: 2.2094066\ttotal: 12.9s\tremaining: 43.1s\n",
      "1057:\tlearn: 2.2087411\ttotal: 12.9s\tremaining: 43.1s\n",
      "1058:\tlearn: 2.2083026\ttotal: 12.9s\tremaining: 43.1s\n",
      "1059:\tlearn: 2.2079289\ttotal: 12.9s\tremaining: 43.1s\n",
      "1060:\tlearn: 2.2064338\ttotal: 12.9s\tremaining: 43.1s\n",
      "1061:\tlearn: 2.2059415\ttotal: 12.9s\tremaining: 43s\n",
      "1062:\tlearn: 2.2052857\ttotal: 12.9s\tremaining: 43s\n",
      "1063:\tlearn: 2.2052792\ttotal: 13s\tremaining: 43s\n",
      "1064:\tlearn: 2.2047875\ttotal: 13s\tremaining: 43s\n",
      "1065:\tlearn: 2.2042035\ttotal: 13s\tremaining: 43s\n",
      "1066:\tlearn: 2.2037041\ttotal: 13s\tremaining: 43s\n",
      "1067:\tlearn: 2.2036974\ttotal: 13s\tremaining: 43s\n",
      "1068:\tlearn: 2.2030766\ttotal: 13s\tremaining: 43s\n",
      "1069:\tlearn: 2.2024668\ttotal: 13s\tremaining: 42.9s\n",
      "1070:\tlearn: 2.2020486\ttotal: 13s\tremaining: 42.9s\n",
      "1071:\tlearn: 2.2018496\ttotal: 13s\tremaining: 42.9s\n",
      "1072:\tlearn: 2.2013341\ttotal: 13.1s\tremaining: 42.9s\n",
      "1073:\tlearn: 2.2004685\ttotal: 13.1s\tremaining: 42.9s\n",
      "1074:\tlearn: 2.2001614\ttotal: 13.1s\tremaining: 42.9s\n",
      "1075:\tlearn: 2.1997035\ttotal: 13.1s\tremaining: 42.8s\n",
      "1076:\tlearn: 2.1986713\ttotal: 13.1s\tremaining: 42.8s\n",
      "1077:\tlearn: 2.1978253\ttotal: 13.1s\tremaining: 42.8s\n",
      "1078:\tlearn: 2.1974908\ttotal: 13.1s\tremaining: 42.8s\n",
      "1079:\tlearn: 2.1965299\ttotal: 13.1s\tremaining: 42.8s\n",
      "1080:\tlearn: 2.1956820\ttotal: 13.2s\tremaining: 42.8s\n",
      "1081:\tlearn: 2.1946745\ttotal: 13.2s\tremaining: 42.8s\n",
      "1082:\tlearn: 2.1941764\ttotal: 13.2s\tremaining: 42.8s\n",
      "1083:\tlearn: 2.1934182\ttotal: 13.2s\tremaining: 42.7s\n",
      "1084:\tlearn: 2.1919634\ttotal: 13.2s\tremaining: 42.7s\n",
      "1085:\tlearn: 2.1914693\ttotal: 13.2s\tremaining: 42.7s\n",
      "1086:\tlearn: 2.1907291\ttotal: 13.2s\tremaining: 42.7s\n",
      "1087:\tlearn: 2.1900050\ttotal: 13.2s\tremaining: 42.7s\n",
      "1088:\tlearn: 2.1895744\ttotal: 13.2s\tremaining: 42.7s\n",
      "1089:\tlearn: 2.1893111\ttotal: 13.3s\tremaining: 42.7s\n",
      "1090:\tlearn: 2.1886890\ttotal: 13.3s\tremaining: 42.7s\n",
      "1091:\tlearn: 2.1877993\ttotal: 13.3s\tremaining: 42.6s\n",
      "1092:\tlearn: 2.1870064\ttotal: 13.3s\tremaining: 42.6s\n",
      "1093:\tlearn: 2.1866451\ttotal: 13.3s\tremaining: 42.6s\n",
      "1094:\tlearn: 2.1860389\ttotal: 13.3s\tremaining: 42.6s\n",
      "1095:\tlearn: 2.1851149\ttotal: 13.3s\tremaining: 42.6s\n",
      "1096:\tlearn: 2.1842824\ttotal: 13.3s\tremaining: 42.6s\n",
      "1097:\tlearn: 2.1834748\ttotal: 13.4s\tremaining: 42.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1098:\tlearn: 2.1828862\ttotal: 13.4s\tremaining: 42.6s\n",
      "1099:\tlearn: 2.1823290\ttotal: 13.4s\tremaining: 42.5s\n",
      "1100:\tlearn: 2.1811919\ttotal: 13.4s\tremaining: 42.5s\n",
      "1101:\tlearn: 2.1807298\ttotal: 13.4s\tremaining: 42.5s\n",
      "1102:\tlearn: 2.1802235\ttotal: 13.4s\tremaining: 42.5s\n",
      "1103:\tlearn: 2.1797710\ttotal: 13.4s\tremaining: 42.5s\n",
      "1104:\tlearn: 2.1793740\ttotal: 13.4s\tremaining: 42.5s\n",
      "1105:\tlearn: 2.1784748\ttotal: 13.4s\tremaining: 42.5s\n",
      "1106:\tlearn: 2.1772021\ttotal: 13.5s\tremaining: 42.5s\n",
      "1107:\tlearn: 2.1762666\ttotal: 13.5s\tremaining: 42.4s\n",
      "1108:\tlearn: 2.1756262\ttotal: 13.5s\tremaining: 42.4s\n",
      "1109:\tlearn: 2.1748655\ttotal: 13.5s\tremaining: 42.4s\n",
      "1110:\tlearn: 2.1746010\ttotal: 13.5s\tremaining: 42.4s\n",
      "1111:\tlearn: 2.1739401\ttotal: 13.5s\tremaining: 42.4s\n",
      "1112:\tlearn: 2.1733560\ttotal: 13.5s\tremaining: 42.4s\n",
      "1113:\tlearn: 2.1729796\ttotal: 13.5s\tremaining: 42.4s\n",
      "1114:\tlearn: 2.1723241\ttotal: 13.6s\tremaining: 42.4s\n",
      "1115:\tlearn: 2.1719018\ttotal: 13.6s\tremaining: 42.3s\n",
      "1116:\tlearn: 2.1711855\ttotal: 13.6s\tremaining: 42.3s\n",
      "1117:\tlearn: 2.1705332\ttotal: 13.6s\tremaining: 42.3s\n",
      "1118:\tlearn: 2.1700782\ttotal: 13.6s\tremaining: 42.3s\n",
      "1119:\tlearn: 2.1693099\ttotal: 13.6s\tremaining: 42.3s\n",
      "1120:\tlearn: 2.1685958\ttotal: 13.6s\tremaining: 42.3s\n",
      "1121:\tlearn: 2.1682865\ttotal: 13.6s\tremaining: 42.3s\n",
      "1122:\tlearn: 2.1674732\ttotal: 13.7s\tremaining: 42.3s\n",
      "1123:\tlearn: 2.1670670\ttotal: 13.7s\tremaining: 42.3s\n",
      "1124:\tlearn: 2.1664589\ttotal: 13.7s\tremaining: 42.2s\n",
      "1125:\tlearn: 2.1658965\ttotal: 13.7s\tremaining: 42.2s\n",
      "1126:\tlearn: 2.1653427\ttotal: 13.7s\tremaining: 42.2s\n",
      "1127:\tlearn: 2.1650055\ttotal: 13.7s\tremaining: 42.2s\n",
      "1128:\tlearn: 2.1648931\ttotal: 13.7s\tremaining: 42.2s\n",
      "1129:\tlearn: 2.1642844\ttotal: 13.7s\tremaining: 42.2s\n",
      "1130:\tlearn: 2.1634268\ttotal: 13.8s\tremaining: 42.2s\n",
      "1131:\tlearn: 2.1631459\ttotal: 13.8s\tremaining: 42.1s\n",
      "1132:\tlearn: 2.1622035\ttotal: 13.8s\tremaining: 42.1s\n",
      "1133:\tlearn: 2.1612193\ttotal: 13.8s\tremaining: 42.1s\n",
      "1134:\tlearn: 2.1607534\ttotal: 13.8s\tremaining: 42.1s\n",
      "1135:\tlearn: 2.1601312\ttotal: 13.8s\tremaining: 42.1s\n",
      "1136:\tlearn: 2.1593283\ttotal: 13.8s\tremaining: 42.1s\n",
      "1137:\tlearn: 2.1582720\ttotal: 13.8s\tremaining: 42.1s\n",
      "1138:\tlearn: 2.1574648\ttotal: 13.8s\tremaining: 42.1s\n",
      "1139:\tlearn: 2.1567614\ttotal: 13.9s\tremaining: 42.1s\n",
      "1140:\tlearn: 2.1558432\ttotal: 13.9s\tremaining: 42s\n",
      "1141:\tlearn: 2.1551404\ttotal: 13.9s\tremaining: 42s\n",
      "1142:\tlearn: 2.1545409\ttotal: 13.9s\tremaining: 42s\n",
      "1143:\tlearn: 2.1533034\ttotal: 13.9s\tremaining: 42s\n",
      "1144:\tlearn: 2.1524165\ttotal: 13.9s\tremaining: 42s\n",
      "1145:\tlearn: 2.1518881\ttotal: 13.9s\tremaining: 42s\n",
      "1146:\tlearn: 2.1514494\ttotal: 13.9s\tremaining: 42s\n",
      "1147:\tlearn: 2.1510853\ttotal: 14s\tremaining: 41.9s\n",
      "1148:\tlearn: 2.1501448\ttotal: 14s\tremaining: 41.9s\n",
      "1149:\tlearn: 2.1497515\ttotal: 14s\tremaining: 41.9s\n",
      "1150:\tlearn: 2.1490375\ttotal: 14s\tremaining: 41.9s\n",
      "1151:\tlearn: 2.1486545\ttotal: 14s\tremaining: 41.9s\n",
      "1152:\tlearn: 2.1478109\ttotal: 14s\tremaining: 41.9s\n",
      "1153:\tlearn: 2.1474048\ttotal: 14s\tremaining: 41.9s\n",
      "1154:\tlearn: 2.1467249\ttotal: 14s\tremaining: 41.9s\n",
      "1155:\tlearn: 2.1462101\ttotal: 14.1s\tremaining: 41.9s\n",
      "1156:\tlearn: 2.1452966\ttotal: 14.1s\tremaining: 41.8s\n",
      "1157:\tlearn: 2.1446773\ttotal: 14.1s\tremaining: 41.8s\n",
      "1158:\tlearn: 2.1440771\ttotal: 14.1s\tremaining: 41.8s\n",
      "1159:\tlearn: 2.1440741\ttotal: 14.1s\tremaining: 41.8s\n",
      "1160:\tlearn: 2.1436326\ttotal: 14.1s\tremaining: 41.8s\n",
      "1161:\tlearn: 2.1433104\ttotal: 14.1s\tremaining: 41.8s\n",
      "1162:\tlearn: 2.1424371\ttotal: 14.1s\tremaining: 41.8s\n",
      "1163:\tlearn: 2.1420543\ttotal: 14.1s\tremaining: 41.7s\n",
      "1164:\tlearn: 2.1413000\ttotal: 14.2s\tremaining: 41.7s\n",
      "1165:\tlearn: 2.1406767\ttotal: 14.2s\tremaining: 41.7s\n",
      "1166:\tlearn: 2.1397963\ttotal: 14.2s\tremaining: 41.7s\n",
      "1167:\tlearn: 2.1390963\ttotal: 14.2s\tremaining: 41.7s\n",
      "1168:\tlearn: 2.1387107\ttotal: 14.2s\tremaining: 41.7s\n",
      "1169:\tlearn: 2.1383140\ttotal: 14.2s\tremaining: 41.7s\n",
      "1170:\tlearn: 2.1379497\ttotal: 14.2s\tremaining: 41.7s\n",
      "1171:\tlearn: 2.1375058\ttotal: 14.3s\tremaining: 41.7s\n",
      "1172:\tlearn: 2.1371593\ttotal: 14.3s\tremaining: 41.7s\n",
      "1173:\tlearn: 2.1366059\ttotal: 14.3s\tremaining: 41.6s\n",
      "1174:\tlearn: 2.1358295\ttotal: 14.3s\tremaining: 41.6s\n",
      "1175:\tlearn: 2.1353479\ttotal: 14.3s\tremaining: 41.6s\n",
      "1176:\tlearn: 2.1349531\ttotal: 14.3s\tremaining: 41.6s\n",
      "1177:\tlearn: 2.1346060\ttotal: 14.3s\tremaining: 41.6s\n",
      "1178:\tlearn: 2.1341704\ttotal: 14.3s\tremaining: 41.6s\n",
      "1179:\tlearn: 2.1339656\ttotal: 14.4s\tremaining: 41.6s\n",
      "1180:\tlearn: 2.1333796\ttotal: 14.4s\tremaining: 41.6s\n",
      "1181:\tlearn: 2.1329960\ttotal: 14.4s\tremaining: 41.5s\n",
      "1182:\tlearn: 2.1325935\ttotal: 14.4s\tremaining: 41.5s\n",
      "1183:\tlearn: 2.1321323\ttotal: 14.4s\tremaining: 41.5s\n",
      "1184:\tlearn: 2.1319301\ttotal: 14.4s\tremaining: 41.5s\n",
      "1185:\tlearn: 2.1315616\ttotal: 14.4s\tremaining: 41.5s\n",
      "1186:\tlearn: 2.1307808\ttotal: 14.4s\tremaining: 41.5s\n",
      "1187:\tlearn: 2.1305414\ttotal: 14.4s\tremaining: 41.5s\n",
      "1188:\tlearn: 2.1300253\ttotal: 14.5s\tremaining: 41.5s\n",
      "1189:\tlearn: 2.1295747\ttotal: 14.5s\tremaining: 41.4s\n",
      "1190:\tlearn: 2.1290438\ttotal: 14.5s\tremaining: 41.4s\n",
      "1191:\tlearn: 2.1286017\ttotal: 14.5s\tremaining: 41.4s\n",
      "1192:\tlearn: 2.1282869\ttotal: 14.5s\tremaining: 41.4s\n",
      "1193:\tlearn: 2.1278689\ttotal: 14.5s\tremaining: 41.4s\n",
      "1194:\tlearn: 2.1275693\ttotal: 14.5s\tremaining: 41.4s\n",
      "1195:\tlearn: 2.1266828\ttotal: 14.5s\tremaining: 41.4s\n",
      "1196:\tlearn: 2.1250311\ttotal: 14.6s\tremaining: 41.3s\n",
      "1197:\tlearn: 2.1241715\ttotal: 14.6s\tremaining: 41.3s\n",
      "1198:\tlearn: 2.1236973\ttotal: 14.6s\tremaining: 41.3s\n",
      "1199:\tlearn: 2.1234029\ttotal: 14.6s\tremaining: 41.3s\n",
      "1200:\tlearn: 2.1230083\ttotal: 14.6s\tremaining: 41.3s\n",
      "1201:\tlearn: 2.1224964\ttotal: 14.6s\tremaining: 41.3s\n",
      "1202:\tlearn: 2.1223349\ttotal: 14.6s\tremaining: 41.3s\n",
      "1203:\tlearn: 2.1219788\ttotal: 14.6s\tremaining: 41.3s\n",
      "1204:\tlearn: 2.1211070\ttotal: 14.7s\tremaining: 41.3s\n",
      "1205:\tlearn: 2.1206398\ttotal: 14.7s\tremaining: 41.2s\n",
      "1206:\tlearn: 2.1200935\ttotal: 14.7s\tremaining: 41.2s\n",
      "1207:\tlearn: 2.1188922\ttotal: 14.7s\tremaining: 41.2s\n",
      "1208:\tlearn: 2.1180500\ttotal: 14.7s\tremaining: 41.2s\n",
      "1209:\tlearn: 2.1175396\ttotal: 14.7s\tremaining: 41.2s\n",
      "1210:\tlearn: 2.1173085\ttotal: 14.7s\tremaining: 41.2s\n",
      "1211:\tlearn: 2.1167303\ttotal: 14.7s\tremaining: 41.2s\n",
      "1212:\tlearn: 2.1161550\ttotal: 14.8s\tremaining: 41.2s\n",
      "1213:\tlearn: 2.1156215\ttotal: 14.8s\tremaining: 41.2s\n",
      "1214:\tlearn: 2.1150722\ttotal: 14.8s\tremaining: 41.2s\n",
      "1215:\tlearn: 2.1143821\ttotal: 14.8s\tremaining: 41.2s\n",
      "1216:\tlearn: 2.1139766\ttotal: 14.8s\tremaining: 41.2s\n",
      "1217:\tlearn: 2.1133275\ttotal: 14.8s\tremaining: 41.1s\n",
      "1218:\tlearn: 2.1129053\ttotal: 14.8s\tremaining: 41.1s\n",
      "1219:\tlearn: 2.1121490\ttotal: 14.9s\tremaining: 41.1s\n",
      "1220:\tlearn: 2.1116019\ttotal: 14.9s\tremaining: 41.1s\n",
      "1221:\tlearn: 2.1106658\ttotal: 14.9s\tremaining: 41.1s\n",
      "1222:\tlearn: 2.1102922\ttotal: 14.9s\tremaining: 41.1s\n",
      "1223:\tlearn: 2.1097115\ttotal: 14.9s\tremaining: 41.1s\n",
      "1224:\tlearn: 2.1091405\ttotal: 14.9s\tremaining: 41.1s\n",
      "1225:\tlearn: 2.1087114\ttotal: 14.9s\tremaining: 41.1s\n",
      "1226:\tlearn: 2.1080572\ttotal: 14.9s\tremaining: 41.1s\n",
      "1227:\tlearn: 2.1076603\ttotal: 15s\tremaining: 41s\n",
      "1228:\tlearn: 2.1067118\ttotal: 15s\tremaining: 41s\n",
      "1229:\tlearn: 2.1061365\ttotal: 15s\tremaining: 41s\n",
      "1230:\tlearn: 2.1055774\ttotal: 15s\tremaining: 41s\n",
      "1231:\tlearn: 2.1052026\ttotal: 15s\tremaining: 41s\n",
      "1232:\tlearn: 2.1048105\ttotal: 15s\tremaining: 41s\n",
      "1233:\tlearn: 2.1041407\ttotal: 15s\tremaining: 41s\n",
      "1234:\tlearn: 2.1037414\ttotal: 15.1s\tremaining: 41s\n",
      "1235:\tlearn: 2.1030061\ttotal: 15.1s\tremaining: 41s\n",
      "1236:\tlearn: 2.1025993\ttotal: 15.1s\tremaining: 41s\n",
      "1237:\tlearn: 2.1022036\ttotal: 15.1s\tremaining: 41s\n",
      "1238:\tlearn: 2.1013568\ttotal: 15.1s\tremaining: 40.9s\n",
      "1239:\tlearn: 2.1012868\ttotal: 15.1s\tremaining: 40.9s\n",
      "1240:\tlearn: 2.1007678\ttotal: 15.1s\tremaining: 40.9s\n",
      "1241:\tlearn: 2.1004234\ttotal: 15.1s\tremaining: 40.9s\n",
      "1242:\tlearn: 2.0999335\ttotal: 15.1s\tremaining: 40.9s\n",
      "1243:\tlearn: 2.0994969\ttotal: 15.2s\tremaining: 40.9s\n",
      "1244:\tlearn: 2.0989242\ttotal: 15.2s\tremaining: 40.9s\n",
      "1245:\tlearn: 2.0985760\ttotal: 15.2s\tremaining: 40.8s\n",
      "1246:\tlearn: 2.0982786\ttotal: 15.2s\tremaining: 40.8s\n",
      "1247:\tlearn: 2.0978501\ttotal: 15.2s\tremaining: 40.8s\n",
      "1248:\tlearn: 2.0976247\ttotal: 15.2s\tremaining: 40.8s\n",
      "1249:\tlearn: 2.0967732\ttotal: 15.2s\tremaining: 40.8s\n",
      "1250:\tlearn: 2.0962575\ttotal: 15.2s\tremaining: 40.8s\n",
      "1251:\tlearn: 2.0954870\ttotal: 15.3s\tremaining: 40.8s\n",
      "1252:\tlearn: 2.0950365\ttotal: 15.3s\tremaining: 40.8s\n",
      "1253:\tlearn: 2.0946685\ttotal: 15.3s\tremaining: 40.7s\n",
      "1254:\tlearn: 2.0940939\ttotal: 15.3s\tremaining: 40.7s\n",
      "1255:\tlearn: 2.0936790\ttotal: 15.3s\tremaining: 40.7s\n",
      "1256:\tlearn: 2.0929384\ttotal: 15.3s\tremaining: 40.7s\n",
      "1257:\tlearn: 2.0925001\ttotal: 15.3s\tremaining: 40.7s\n",
      "1258:\tlearn: 2.0920538\ttotal: 15.3s\tremaining: 40.7s\n",
      "1259:\tlearn: 2.0910252\ttotal: 15.3s\tremaining: 40.7s\n",
      "1260:\tlearn: 2.0907051\ttotal: 15.4s\tremaining: 40.6s\n",
      "1261:\tlearn: 2.0903755\ttotal: 15.4s\tremaining: 40.6s\n",
      "1262:\tlearn: 2.0899919\ttotal: 15.4s\tremaining: 40.6s\n",
      "1263:\tlearn: 2.0896397\ttotal: 15.4s\tremaining: 40.6s\n",
      "1264:\tlearn: 2.0892218\ttotal: 15.4s\tremaining: 40.6s\n",
      "1265:\tlearn: 2.0886557\ttotal: 15.4s\tremaining: 40.6s\n",
      "1266:\tlearn: 2.0879831\ttotal: 15.4s\tremaining: 40.6s\n",
      "1267:\tlearn: 2.0873410\ttotal: 15.4s\tremaining: 40.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1268:\tlearn: 2.0867388\ttotal: 15.5s\tremaining: 40.5s\n",
      "1269:\tlearn: 2.0860031\ttotal: 15.5s\tremaining: 40.5s\n",
      "1270:\tlearn: 2.0855931\ttotal: 15.5s\tremaining: 40.5s\n",
      "1271:\tlearn: 2.0850129\ttotal: 15.5s\tremaining: 40.5s\n",
      "1272:\tlearn: 2.0846278\ttotal: 15.5s\tremaining: 40.5s\n",
      "1273:\tlearn: 2.0840984\ttotal: 15.5s\tremaining: 40.5s\n",
      "1274:\tlearn: 2.0837403\ttotal: 15.5s\tremaining: 40.5s\n",
      "1275:\tlearn: 2.0832464\ttotal: 15.5s\tremaining: 40.5s\n",
      "1276:\tlearn: 2.0832129\ttotal: 15.5s\tremaining: 40.4s\n",
      "1277:\tlearn: 2.0827062\ttotal: 15.6s\tremaining: 40.4s\n",
      "1278:\tlearn: 2.0823851\ttotal: 15.6s\tremaining: 40.4s\n",
      "1279:\tlearn: 2.0812975\ttotal: 15.6s\tremaining: 40.4s\n",
      "1280:\tlearn: 2.0809218\ttotal: 15.6s\tremaining: 40.4s\n",
      "1281:\tlearn: 2.0803585\ttotal: 15.6s\tremaining: 40.4s\n",
      "1282:\tlearn: 2.0797161\ttotal: 15.6s\tremaining: 40.4s\n",
      "1283:\tlearn: 2.0793682\ttotal: 15.6s\tremaining: 40.4s\n",
      "1284:\tlearn: 2.0790715\ttotal: 15.6s\tremaining: 40.3s\n",
      "1285:\tlearn: 2.0787194\ttotal: 15.7s\tremaining: 40.3s\n",
      "1286:\tlearn: 2.0781355\ttotal: 15.7s\tremaining: 40.3s\n",
      "1287:\tlearn: 2.0775724\ttotal: 15.7s\tremaining: 40.3s\n",
      "1288:\tlearn: 2.0772135\ttotal: 15.7s\tremaining: 40.3s\n",
      "1289:\tlearn: 2.0766774\ttotal: 15.7s\tremaining: 40.3s\n",
      "1290:\tlearn: 2.0761051\ttotal: 15.7s\tremaining: 40.3s\n",
      "1291:\tlearn: 2.0751636\ttotal: 15.7s\tremaining: 40.3s\n",
      "1292:\tlearn: 2.0745550\ttotal: 15.7s\tremaining: 40.2s\n",
      "1293:\tlearn: 2.0739512\ttotal: 15.8s\tremaining: 40.2s\n",
      "1294:\tlearn: 2.0727859\ttotal: 15.8s\tremaining: 40.2s\n",
      "1295:\tlearn: 2.0721217\ttotal: 15.8s\tremaining: 40.2s\n",
      "1296:\tlearn: 2.0714861\ttotal: 15.8s\tremaining: 40.2s\n",
      "1297:\tlearn: 2.0710553\ttotal: 15.8s\tremaining: 40.2s\n",
      "1298:\tlearn: 2.0707358\ttotal: 15.8s\tremaining: 40.2s\n",
      "1299:\tlearn: 2.0701653\ttotal: 15.8s\tremaining: 40.2s\n",
      "1300:\tlearn: 2.0695607\ttotal: 15.8s\tremaining: 40.1s\n",
      "1301:\tlearn: 2.0687829\ttotal: 15.9s\tremaining: 40.1s\n",
      "1302:\tlearn: 2.0682238\ttotal: 15.9s\tremaining: 40.1s\n",
      "1303:\tlearn: 2.0671517\ttotal: 15.9s\tremaining: 40.1s\n",
      "1304:\tlearn: 2.0667779\ttotal: 15.9s\tremaining: 40.1s\n",
      "1305:\tlearn: 2.0664801\ttotal: 15.9s\tremaining: 40.1s\n",
      "1306:\tlearn: 2.0660565\ttotal: 15.9s\tremaining: 40.1s\n",
      "1307:\tlearn: 2.0656218\ttotal: 15.9s\tremaining: 40.1s\n",
      "1308:\tlearn: 2.0652713\ttotal: 15.9s\tremaining: 40.1s\n",
      "1309:\tlearn: 2.0648196\ttotal: 16s\tremaining: 40.1s\n",
      "1310:\tlearn: 2.0643313\ttotal: 16s\tremaining: 40s\n",
      "1311:\tlearn: 2.0641647\ttotal: 16s\tremaining: 40s\n",
      "1312:\tlearn: 2.0634375\ttotal: 16s\tremaining: 40s\n",
      "1313:\tlearn: 2.0631153\ttotal: 16s\tremaining: 40s\n",
      "1314:\tlearn: 2.0630210\ttotal: 16s\tremaining: 40s\n",
      "1315:\tlearn: 2.0625655\ttotal: 16s\tremaining: 40s\n",
      "1316:\tlearn: 2.0619200\ttotal: 16.1s\tremaining: 40s\n",
      "1317:\tlearn: 2.0617247\ttotal: 16.1s\tremaining: 40s\n",
      "1318:\tlearn: 2.0611911\ttotal: 16.1s\tremaining: 40s\n",
      "1319:\tlearn: 2.0607610\ttotal: 16.1s\tremaining: 40s\n",
      "1320:\tlearn: 2.0598025\ttotal: 16.1s\tremaining: 39.9s\n",
      "1321:\tlearn: 2.0591524\ttotal: 16.1s\tremaining: 39.9s\n",
      "1322:\tlearn: 2.0587117\ttotal: 16.1s\tremaining: 39.9s\n",
      "1323:\tlearn: 2.0582453\ttotal: 16.1s\tremaining: 39.9s\n",
      "1324:\tlearn: 2.0577428\ttotal: 16.2s\tremaining: 39.9s\n",
      "1325:\tlearn: 2.0573599\ttotal: 16.2s\tremaining: 39.9s\n",
      "1326:\tlearn: 2.0566014\ttotal: 16.2s\tremaining: 39.9s\n",
      "1327:\tlearn: 2.0562011\ttotal: 16.2s\tremaining: 39.9s\n",
      "1328:\tlearn: 2.0556439\ttotal: 16.2s\tremaining: 39.9s\n",
      "1329:\tlearn: 2.0553527\ttotal: 16.2s\tremaining: 39.9s\n",
      "1330:\tlearn: 2.0547293\ttotal: 16.2s\tremaining: 39.8s\n",
      "1331:\tlearn: 2.0540865\ttotal: 16.2s\tremaining: 39.8s\n",
      "1332:\tlearn: 2.0539923\ttotal: 16.3s\tremaining: 39.8s\n",
      "1333:\tlearn: 2.0536315\ttotal: 16.3s\tremaining: 39.8s\n",
      "1334:\tlearn: 2.0535765\ttotal: 16.3s\tremaining: 39.8s\n",
      "1335:\tlearn: 2.0531817\ttotal: 16.3s\tremaining: 39.8s\n",
      "1336:\tlearn: 2.0531766\ttotal: 16.3s\tremaining: 39.8s\n",
      "1337:\tlearn: 2.0527101\ttotal: 16.3s\tremaining: 39.7s\n",
      "1338:\tlearn: 2.0523905\ttotal: 16.3s\tremaining: 39.7s\n",
      "1339:\tlearn: 2.0520322\ttotal: 16.3s\tremaining: 39.7s\n",
      "1340:\tlearn: 2.0519489\ttotal: 16.3s\tremaining: 39.7s\n",
      "1341:\tlearn: 2.0515034\ttotal: 16.4s\tremaining: 39.7s\n",
      "1342:\tlearn: 2.0503633\ttotal: 16.4s\tremaining: 39.7s\n",
      "1343:\tlearn: 2.0500004\ttotal: 16.4s\tremaining: 39.7s\n",
      "1344:\tlearn: 2.0495400\ttotal: 16.4s\tremaining: 39.6s\n",
      "1345:\tlearn: 2.0490524\ttotal: 16.4s\tremaining: 39.6s\n",
      "1346:\tlearn: 2.0482623\ttotal: 16.4s\tremaining: 39.6s\n",
      "1347:\tlearn: 2.0479112\ttotal: 16.4s\tremaining: 39.6s\n",
      "1348:\tlearn: 2.0474040\ttotal: 16.4s\tremaining: 39.6s\n",
      "1349:\tlearn: 2.0469179\ttotal: 16.4s\tremaining: 39.6s\n",
      "1350:\tlearn: 2.0463212\ttotal: 16.5s\tremaining: 39.6s\n",
      "1351:\tlearn: 2.0459723\ttotal: 16.5s\tremaining: 39.6s\n",
      "1352:\tlearn: 2.0449230\ttotal: 16.5s\tremaining: 39.5s\n",
      "1353:\tlearn: 2.0445659\ttotal: 16.5s\tremaining: 39.5s\n",
      "1354:\tlearn: 2.0442015\ttotal: 16.5s\tremaining: 39.5s\n",
      "1355:\tlearn: 2.0435953\ttotal: 16.5s\tremaining: 39.5s\n",
      "1356:\tlearn: 2.0435198\ttotal: 16.5s\tremaining: 39.5s\n",
      "1357:\tlearn: 2.0427607\ttotal: 16.5s\tremaining: 39.5s\n",
      "1358:\tlearn: 2.0421793\ttotal: 16.6s\tremaining: 39.5s\n",
      "1359:\tlearn: 2.0413656\ttotal: 16.6s\tremaining: 39.5s\n",
      "1360:\tlearn: 2.0409533\ttotal: 16.6s\tremaining: 39.4s\n",
      "1361:\tlearn: 2.0405173\ttotal: 16.6s\tremaining: 39.4s\n",
      "1362:\tlearn: 2.0403060\ttotal: 16.6s\tremaining: 39.4s\n",
      "1363:\tlearn: 2.0399466\ttotal: 16.6s\tremaining: 39.4s\n",
      "1364:\tlearn: 2.0395896\ttotal: 16.6s\tremaining: 39.4s\n",
      "1365:\tlearn: 2.0391516\ttotal: 16.6s\tremaining: 39.4s\n",
      "1366:\tlearn: 2.0388947\ttotal: 16.6s\tremaining: 39.4s\n",
      "1367:\tlearn: 2.0385456\ttotal: 16.7s\tremaining: 39.3s\n",
      "1368:\tlearn: 2.0383514\ttotal: 16.7s\tremaining: 39.3s\n",
      "1369:\tlearn: 2.0380657\ttotal: 16.7s\tremaining: 39.3s\n",
      "1370:\tlearn: 2.0377532\ttotal: 16.7s\tremaining: 39.3s\n",
      "1371:\tlearn: 2.0370725\ttotal: 16.7s\tremaining: 39.3s\n",
      "1372:\tlearn: 2.0365906\ttotal: 16.7s\tremaining: 39.3s\n",
      "1373:\tlearn: 2.0360246\ttotal: 16.7s\tremaining: 39.3s\n",
      "1374:\tlearn: 2.0355563\ttotal: 16.7s\tremaining: 39.3s\n",
      "1375:\tlearn: 2.0353008\ttotal: 16.8s\tremaining: 39.2s\n",
      "1376:\tlearn: 2.0348279\ttotal: 16.8s\tremaining: 39.2s\n",
      "1377:\tlearn: 2.0340869\ttotal: 16.8s\tremaining: 39.2s\n",
      "1378:\tlearn: 2.0337769\ttotal: 16.8s\tremaining: 39.2s\n",
      "1379:\tlearn: 2.0331794\ttotal: 16.8s\tremaining: 39.2s\n",
      "1380:\tlearn: 2.0328749\ttotal: 16.8s\tremaining: 39.2s\n",
      "1381:\tlearn: 2.0323621\ttotal: 16.8s\tremaining: 39.2s\n",
      "1382:\tlearn: 2.0318894\ttotal: 16.8s\tremaining: 39.1s\n",
      "1383:\tlearn: 2.0313931\ttotal: 16.9s\tremaining: 39.1s\n",
      "1384:\tlearn: 2.0305876\ttotal: 16.9s\tremaining: 39.1s\n",
      "1385:\tlearn: 2.0303872\ttotal: 16.9s\tremaining: 39.1s\n",
      "1386:\tlearn: 2.0300388\ttotal: 16.9s\tremaining: 39.1s\n",
      "1387:\tlearn: 2.0297083\ttotal: 16.9s\tremaining: 39.1s\n",
      "1388:\tlearn: 2.0296007\ttotal: 16.9s\tremaining: 39.1s\n",
      "1389:\tlearn: 2.0287823\ttotal: 16.9s\tremaining: 39.1s\n",
      "1390:\tlearn: 2.0285083\ttotal: 16.9s\tremaining: 39s\n",
      "1391:\tlearn: 2.0278347\ttotal: 16.9s\tremaining: 39s\n",
      "1392:\tlearn: 2.0272303\ttotal: 17s\tremaining: 39s\n",
      "1393:\tlearn: 2.0269646\ttotal: 17s\tremaining: 39s\n",
      "1394:\tlearn: 2.0265641\ttotal: 17s\tremaining: 39s\n",
      "1395:\tlearn: 2.0260086\ttotal: 17s\tremaining: 39s\n",
      "1396:\tlearn: 2.0252918\ttotal: 17s\tremaining: 39s\n",
      "1397:\tlearn: 2.0246135\ttotal: 17s\tremaining: 39s\n",
      "1398:\tlearn: 2.0241737\ttotal: 17s\tremaining: 38.9s\n",
      "1399:\tlearn: 2.0236825\ttotal: 17s\tremaining: 38.9s\n",
      "1400:\tlearn: 2.0232899\ttotal: 17.1s\tremaining: 38.9s\n",
      "1401:\tlearn: 2.0227727\ttotal: 17.1s\tremaining: 38.9s\n",
      "1402:\tlearn: 2.0219418\ttotal: 17.1s\tremaining: 38.9s\n",
      "1403:\tlearn: 2.0215194\ttotal: 17.1s\tremaining: 38.9s\n",
      "1404:\tlearn: 2.0207252\ttotal: 17.1s\tremaining: 38.9s\n",
      "1405:\tlearn: 2.0200054\ttotal: 17.1s\tremaining: 38.9s\n",
      "1406:\tlearn: 2.0196399\ttotal: 17.1s\tremaining: 38.8s\n",
      "1407:\tlearn: 2.0189286\ttotal: 17.1s\tremaining: 38.8s\n",
      "1408:\tlearn: 2.0182565\ttotal: 17.2s\tremaining: 38.8s\n",
      "1409:\tlearn: 2.0175364\ttotal: 17.2s\tremaining: 38.8s\n",
      "1410:\tlearn: 2.0173840\ttotal: 17.2s\tremaining: 38.8s\n",
      "1411:\tlearn: 2.0170663\ttotal: 17.2s\tremaining: 38.8s\n",
      "1412:\tlearn: 2.0163637\ttotal: 17.2s\tremaining: 38.8s\n",
      "1413:\tlearn: 2.0157870\ttotal: 17.2s\tremaining: 38.8s\n",
      "1414:\tlearn: 2.0153674\ttotal: 17.2s\tremaining: 38.7s\n",
      "1415:\tlearn: 2.0143281\ttotal: 17.2s\tremaining: 38.7s\n",
      "1416:\tlearn: 2.0135512\ttotal: 17.2s\tremaining: 38.7s\n",
      "1417:\tlearn: 2.0127659\ttotal: 17.3s\tremaining: 38.7s\n",
      "1418:\tlearn: 2.0122302\ttotal: 17.3s\tremaining: 38.7s\n",
      "1419:\tlearn: 2.0118279\ttotal: 17.3s\tremaining: 38.7s\n",
      "1420:\tlearn: 2.0115164\ttotal: 17.3s\tremaining: 38.7s\n",
      "1421:\tlearn: 2.0105496\ttotal: 17.3s\tremaining: 38.7s\n",
      "1422:\tlearn: 2.0100743\ttotal: 17.3s\tremaining: 38.6s\n",
      "1423:\tlearn: 2.0096274\ttotal: 17.3s\tremaining: 38.6s\n",
      "1424:\tlearn: 2.0085047\ttotal: 17.3s\tremaining: 38.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1425:\tlearn: 2.0081621\ttotal: 17.4s\tremaining: 38.6s\n",
      "1426:\tlearn: 2.0077319\ttotal: 17.4s\tremaining: 38.6s\n",
      "1427:\tlearn: 2.0073811\ttotal: 17.4s\tremaining: 38.6s\n",
      "1428:\tlearn: 2.0070131\ttotal: 17.4s\tremaining: 38.6s\n",
      "1429:\tlearn: 2.0065226\ttotal: 17.4s\tremaining: 38.6s\n",
      "1430:\tlearn: 2.0061538\ttotal: 17.4s\tremaining: 38.6s\n",
      "1431:\tlearn: 2.0058163\ttotal: 17.4s\tremaining: 38.5s\n",
      "1432:\tlearn: 2.0056723\ttotal: 17.4s\tremaining: 38.5s\n",
      "1433:\tlearn: 2.0052128\ttotal: 17.5s\tremaining: 38.5s\n",
      "1434:\tlearn: 2.0049528\ttotal: 17.5s\tremaining: 38.5s\n",
      "1435:\tlearn: 2.0045683\ttotal: 17.5s\tremaining: 38.5s\n",
      "1436:\tlearn: 2.0041801\ttotal: 17.5s\tremaining: 38.5s\n",
      "1437:\tlearn: 2.0036365\ttotal: 17.5s\tremaining: 38.5s\n",
      "1438:\tlearn: 2.0031925\ttotal: 17.5s\tremaining: 38.5s\n",
      "1439:\tlearn: 2.0025227\ttotal: 17.5s\tremaining: 38.4s\n",
      "1440:\tlearn: 2.0023989\ttotal: 17.5s\tremaining: 38.4s\n",
      "1441:\tlearn: 2.0016251\ttotal: 17.5s\tremaining: 38.4s\n",
      "1442:\tlearn: 2.0007195\ttotal: 17.6s\tremaining: 38.4s\n",
      "1443:\tlearn: 2.0005870\ttotal: 17.6s\tremaining: 38.4s\n",
      "1444:\tlearn: 2.0002386\ttotal: 17.6s\tremaining: 38.4s\n",
      "1445:\tlearn: 1.9999350\ttotal: 17.6s\tremaining: 38.4s\n",
      "1446:\tlearn: 1.9994067\ttotal: 17.6s\tremaining: 38.3s\n",
      "1447:\tlearn: 1.9986580\ttotal: 17.6s\tremaining: 38.3s\n",
      "1448:\tlearn: 1.9982661\ttotal: 17.6s\tremaining: 38.3s\n",
      "1449:\tlearn: 1.9975729\ttotal: 17.6s\tremaining: 38.3s\n",
      "1450:\tlearn: 1.9971648\ttotal: 17.7s\tremaining: 38.3s\n",
      "1451:\tlearn: 1.9967732\ttotal: 17.7s\tremaining: 38.3s\n",
      "1452:\tlearn: 1.9962582\ttotal: 17.7s\tremaining: 38.3s\n",
      "1453:\tlearn: 1.9958679\ttotal: 17.7s\tremaining: 38.3s\n",
      "1454:\tlearn: 1.9952376\ttotal: 17.7s\tremaining: 38.2s\n",
      "1455:\tlearn: 1.9948351\ttotal: 17.7s\tremaining: 38.2s\n",
      "1456:\tlearn: 1.9944217\ttotal: 17.7s\tremaining: 38.2s\n",
      "1457:\tlearn: 1.9940013\ttotal: 17.7s\tremaining: 38.2s\n",
      "1458:\tlearn: 1.9935187\ttotal: 17.8s\tremaining: 38.2s\n",
      "1459:\tlearn: 1.9930660\ttotal: 17.8s\tremaining: 38.2s\n",
      "1460:\tlearn: 1.9922431\ttotal: 17.8s\tremaining: 38.2s\n",
      "1461:\tlearn: 1.9919130\ttotal: 17.8s\tremaining: 38.2s\n",
      "1462:\tlearn: 1.9910744\ttotal: 17.8s\tremaining: 38.1s\n",
      "1463:\tlearn: 1.9905650\ttotal: 17.8s\tremaining: 38.1s\n",
      "1464:\tlearn: 1.9899396\ttotal: 17.8s\tremaining: 38.1s\n",
      "1465:\tlearn: 1.9893307\ttotal: 17.8s\tremaining: 38.1s\n",
      "1466:\tlearn: 1.9885248\ttotal: 17.9s\tremaining: 38.1s\n",
      "1467:\tlearn: 1.9880022\ttotal: 17.9s\tremaining: 38.1s\n",
      "1468:\tlearn: 1.9874259\ttotal: 17.9s\tremaining: 38.1s\n",
      "1469:\tlearn: 1.9869616\ttotal: 17.9s\tremaining: 38.1s\n",
      "1470:\tlearn: 1.9865116\ttotal: 17.9s\tremaining: 38.1s\n",
      "1471:\tlearn: 1.9857668\ttotal: 17.9s\tremaining: 38s\n",
      "1472:\tlearn: 1.9853279\ttotal: 17.9s\tremaining: 38s\n",
      "1473:\tlearn: 1.9847956\ttotal: 17.9s\tremaining: 38s\n",
      "1474:\tlearn: 1.9845708\ttotal: 17.9s\tremaining: 38s\n",
      "1475:\tlearn: 1.9844308\ttotal: 18s\tremaining: 38s\n",
      "1476:\tlearn: 1.9840808\ttotal: 18s\tremaining: 38s\n",
      "1477:\tlearn: 1.9834019\ttotal: 18s\tremaining: 38s\n",
      "1478:\tlearn: 1.9826527\ttotal: 18s\tremaining: 38s\n",
      "1479:\tlearn: 1.9820531\ttotal: 18s\tremaining: 37.9s\n",
      "1480:\tlearn: 1.9814830\ttotal: 18s\tremaining: 37.9s\n",
      "1481:\tlearn: 1.9805027\ttotal: 18s\tremaining: 37.9s\n",
      "1482:\tlearn: 1.9799834\ttotal: 18s\tremaining: 37.9s\n",
      "1483:\tlearn: 1.9795000\ttotal: 18.1s\tremaining: 37.9s\n",
      "1484:\tlearn: 1.9787847\ttotal: 18.1s\tremaining: 37.9s\n",
      "1485:\tlearn: 1.9782715\ttotal: 18.1s\tremaining: 37.9s\n",
      "1486:\tlearn: 1.9777801\ttotal: 18.1s\tremaining: 37.9s\n",
      "1487:\tlearn: 1.9771176\ttotal: 18.1s\tremaining: 37.8s\n",
      "1488:\tlearn: 1.9768256\ttotal: 18.1s\tremaining: 37.8s\n",
      "1489:\tlearn: 1.9765305\ttotal: 18.1s\tremaining: 37.8s\n",
      "1490:\tlearn: 1.9760968\ttotal: 18.1s\tremaining: 37.8s\n",
      "1491:\tlearn: 1.9760043\ttotal: 18.1s\tremaining: 37.8s\n",
      "1492:\tlearn: 1.9753705\ttotal: 18.2s\tremaining: 37.8s\n",
      "1493:\tlearn: 1.9747622\ttotal: 18.2s\tremaining: 37.8s\n",
      "1494:\tlearn: 1.9743203\ttotal: 18.2s\tremaining: 37.7s\n",
      "1495:\tlearn: 1.9739360\ttotal: 18.2s\tremaining: 37.7s\n",
      "1496:\tlearn: 1.9736651\ttotal: 18.2s\tremaining: 37.7s\n",
      "1497:\tlearn: 1.9727121\ttotal: 18.2s\tremaining: 37.7s\n",
      "1498:\tlearn: 1.9724085\ttotal: 18.2s\tremaining: 37.7s\n",
      "1499:\tlearn: 1.9719988\ttotal: 18.2s\tremaining: 37.7s\n",
      "1500:\tlearn: 1.9715200\ttotal: 18.3s\tremaining: 37.7s\n",
      "1501:\tlearn: 1.9708174\ttotal: 18.3s\tremaining: 37.7s\n",
      "1502:\tlearn: 1.9705820\ttotal: 18.3s\tremaining: 37.6s\n",
      "1503:\tlearn: 1.9702332\ttotal: 18.3s\tremaining: 37.6s\n",
      "1504:\tlearn: 1.9698865\ttotal: 18.3s\tremaining: 37.6s\n",
      "1505:\tlearn: 1.9693912\ttotal: 18.3s\tremaining: 37.6s\n",
      "1506:\tlearn: 1.9687601\ttotal: 18.3s\tremaining: 37.6s\n",
      "1507:\tlearn: 1.9686468\ttotal: 18.3s\tremaining: 37.6s\n",
      "1508:\tlearn: 1.9683528\ttotal: 18.3s\tremaining: 37.6s\n",
      "1509:\tlearn: 1.9674752\ttotal: 18.4s\tremaining: 37.5s\n",
      "1510:\tlearn: 1.9669763\ttotal: 18.4s\tremaining: 37.5s\n",
      "1511:\tlearn: 1.9668579\ttotal: 18.4s\tremaining: 37.5s\n",
      "1512:\tlearn: 1.9664016\ttotal: 18.4s\tremaining: 37.5s\n",
      "1513:\tlearn: 1.9656027\ttotal: 18.4s\tremaining: 37.5s\n",
      "1514:\tlearn: 1.9651906\ttotal: 18.4s\tremaining: 37.5s\n",
      "1515:\tlearn: 1.9645007\ttotal: 18.4s\tremaining: 37.5s\n",
      "1516:\tlearn: 1.9638191\ttotal: 18.4s\tremaining: 37.5s\n",
      "1517:\tlearn: 1.9631592\ttotal: 18.5s\tremaining: 37.5s\n",
      "1518:\tlearn: 1.9626619\ttotal: 18.5s\tremaining: 37.4s\n",
      "1519:\tlearn: 1.9622694\ttotal: 18.5s\tremaining: 37.4s\n",
      "1520:\tlearn: 1.9618698\ttotal: 18.5s\tremaining: 37.4s\n",
      "1521:\tlearn: 1.9613352\ttotal: 18.5s\tremaining: 37.4s\n",
      "1522:\tlearn: 1.9609097\ttotal: 18.5s\tremaining: 37.4s\n",
      "1523:\tlearn: 1.9603327\ttotal: 18.5s\tremaining: 37.4s\n",
      "1524:\tlearn: 1.9600524\ttotal: 18.5s\tremaining: 37.4s\n",
      "1525:\tlearn: 1.9596148\ttotal: 18.6s\tremaining: 37.4s\n",
      "1526:\tlearn: 1.9592180\ttotal: 18.6s\tremaining: 37.3s\n",
      "1527:\tlearn: 1.9587674\ttotal: 18.6s\tremaining: 37.3s\n",
      "1528:\tlearn: 1.9585158\ttotal: 18.6s\tremaining: 37.3s\n",
      "1529:\tlearn: 1.9581276\ttotal: 18.6s\tremaining: 37.3s\n",
      "1530:\tlearn: 1.9580132\ttotal: 18.6s\tremaining: 37.3s\n",
      "1531:\tlearn: 1.9575044\ttotal: 18.6s\tremaining: 37.3s\n",
      "1532:\tlearn: 1.9567146\ttotal: 18.6s\tremaining: 37.3s\n",
      "1533:\tlearn: 1.9561808\ttotal: 18.7s\tremaining: 37.3s\n",
      "1534:\tlearn: 1.9556624\ttotal: 18.7s\tremaining: 37.2s\n",
      "1535:\tlearn: 1.9550823\ttotal: 18.7s\tremaining: 37.2s\n",
      "1536:\tlearn: 1.9544225\ttotal: 18.7s\tremaining: 37.2s\n",
      "1537:\tlearn: 1.9533451\ttotal: 18.7s\tremaining: 37.2s\n",
      "1538:\tlearn: 1.9528902\ttotal: 18.7s\tremaining: 37.2s\n",
      "1539:\tlearn: 1.9523558\ttotal: 18.7s\tremaining: 37.2s\n",
      "1540:\tlearn: 1.9519424\ttotal: 18.7s\tremaining: 37.2s\n",
      "1541:\tlearn: 1.9512578\ttotal: 18.8s\tremaining: 37.2s\n",
      "1542:\tlearn: 1.9505966\ttotal: 18.8s\tremaining: 37.2s\n",
      "1543:\tlearn: 1.9502675\ttotal: 18.8s\tremaining: 37.1s\n",
      "1544:\tlearn: 1.9498157\ttotal: 18.8s\tremaining: 37.1s\n",
      "1545:\tlearn: 1.9495055\ttotal: 18.8s\tremaining: 37.1s\n",
      "1546:\tlearn: 1.9489977\ttotal: 18.8s\tremaining: 37.1s\n",
      "1547:\tlearn: 1.9482126\ttotal: 18.8s\tremaining: 37.1s\n",
      "1548:\tlearn: 1.9477895\ttotal: 18.8s\tremaining: 37.1s\n",
      "1549:\tlearn: 1.9474814\ttotal: 18.9s\tremaining: 37.1s\n",
      "1550:\tlearn: 1.9472909\ttotal: 18.9s\tremaining: 37.1s\n",
      "1551:\tlearn: 1.9466390\ttotal: 18.9s\tremaining: 37s\n",
      "1552:\tlearn: 1.9463708\ttotal: 18.9s\tremaining: 37s\n",
      "1553:\tlearn: 1.9455990\ttotal: 18.9s\tremaining: 37s\n",
      "1554:\tlearn: 1.9454965\ttotal: 18.9s\tremaining: 37s\n",
      "1555:\tlearn: 1.9444536\ttotal: 18.9s\tremaining: 37s\n",
      "1556:\tlearn: 1.9441610\ttotal: 18.9s\tremaining: 37s\n",
      "1557:\tlearn: 1.9435582\ttotal: 18.9s\tremaining: 37s\n",
      "1558:\tlearn: 1.9430196\ttotal: 19s\tremaining: 37s\n",
      "1559:\tlearn: 1.9425809\ttotal: 19s\tremaining: 36.9s\n",
      "1560:\tlearn: 1.9418559\ttotal: 19s\tremaining: 36.9s\n",
      "1561:\tlearn: 1.9415698\ttotal: 19s\tremaining: 36.9s\n",
      "1562:\tlearn: 1.9410223\ttotal: 19s\tremaining: 36.9s\n",
      "1563:\tlearn: 1.9400741\ttotal: 19s\tremaining: 36.9s\n",
      "1564:\tlearn: 1.9397594\ttotal: 19s\tremaining: 36.9s\n",
      "1565:\tlearn: 1.9394698\ttotal: 19s\tremaining: 36.9s\n",
      "1566:\tlearn: 1.9388830\ttotal: 19.1s\tremaining: 36.9s\n",
      "1567:\tlearn: 1.9386133\ttotal: 19.1s\tremaining: 36.8s\n",
      "1568:\tlearn: 1.9382470\ttotal: 19.1s\tremaining: 36.8s\n",
      "1569:\tlearn: 1.9378497\ttotal: 19.1s\tremaining: 36.8s\n",
      "1570:\tlearn: 1.9373306\ttotal: 19.1s\tremaining: 36.8s\n",
      "1571:\tlearn: 1.9366053\ttotal: 19.1s\tremaining: 36.8s\n",
      "1572:\tlearn: 1.9361160\ttotal: 19.1s\tremaining: 36.8s\n",
      "1573:\tlearn: 1.9353886\ttotal: 19.1s\tremaining: 36.8s\n",
      "1574:\tlearn: 1.9350852\ttotal: 19.1s\tremaining: 36.8s\n",
      "1575:\tlearn: 1.9345845\ttotal: 19.2s\tremaining: 36.7s\n",
      "1576:\tlearn: 1.9339440\ttotal: 19.2s\tremaining: 36.7s\n",
      "1577:\tlearn: 1.9333352\ttotal: 19.2s\tremaining: 36.7s\n",
      "1578:\tlearn: 1.9329938\ttotal: 19.2s\tremaining: 36.7s\n",
      "1579:\tlearn: 1.9321497\ttotal: 19.2s\tremaining: 36.7s\n",
      "1580:\tlearn: 1.9318085\ttotal: 19.2s\tremaining: 36.7s\n",
      "1581:\tlearn: 1.9311442\ttotal: 19.2s\tremaining: 36.7s\n",
      "1582:\tlearn: 1.9305793\ttotal: 19.2s\tremaining: 36.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1583:\tlearn: 1.9304192\ttotal: 19.3s\tremaining: 36.6s\n",
      "1584:\tlearn: 1.9298738\ttotal: 19.3s\tremaining: 36.6s\n",
      "1585:\tlearn: 1.9293870\ttotal: 19.3s\tremaining: 36.6s\n",
      "1586:\tlearn: 1.9288219\ttotal: 19.3s\tremaining: 36.6s\n",
      "1587:\tlearn: 1.9285608\ttotal: 19.3s\tremaining: 36.6s\n",
      "1588:\tlearn: 1.9283357\ttotal: 19.3s\tremaining: 36.6s\n",
      "1589:\tlearn: 1.9278368\ttotal: 19.3s\tremaining: 36.6s\n",
      "1590:\tlearn: 1.9271582\ttotal: 19.4s\tremaining: 36.6s\n",
      "1591:\tlearn: 1.9267198\ttotal: 19.4s\tremaining: 36.6s\n",
      "1592:\tlearn: 1.9262058\ttotal: 19.4s\tremaining: 36.6s\n",
      "1593:\tlearn: 1.9255401\ttotal: 19.4s\tremaining: 36.6s\n",
      "1594:\tlearn: 1.9251884\ttotal: 19.4s\tremaining: 36.5s\n",
      "1595:\tlearn: 1.9244279\ttotal: 19.4s\tremaining: 36.5s\n",
      "1596:\tlearn: 1.9241997\ttotal: 19.4s\tremaining: 36.5s\n",
      "1597:\tlearn: 1.9236981\ttotal: 19.4s\tremaining: 36.5s\n",
      "1598:\tlearn: 1.9232163\ttotal: 19.5s\tremaining: 36.5s\n",
      "1599:\tlearn: 1.9230016\ttotal: 19.5s\tremaining: 36.5s\n",
      "1600:\tlearn: 1.9228128\ttotal: 19.5s\tremaining: 36.5s\n",
      "1601:\tlearn: 1.9220705\ttotal: 19.5s\tremaining: 36.5s\n",
      "1602:\tlearn: 1.9214790\ttotal: 19.5s\tremaining: 36.4s\n",
      "1603:\tlearn: 1.9208974\ttotal: 19.5s\tremaining: 36.4s\n",
      "1604:\tlearn: 1.9204739\ttotal: 19.5s\tremaining: 36.4s\n",
      "1605:\tlearn: 1.9198839\ttotal: 19.5s\tremaining: 36.4s\n",
      "1606:\tlearn: 1.9196613\ttotal: 19.6s\tremaining: 36.4s\n",
      "1607:\tlearn: 1.9192879\ttotal: 19.6s\tremaining: 36.4s\n",
      "1608:\tlearn: 1.9189345\ttotal: 19.6s\tremaining: 36.4s\n",
      "1609:\tlearn: 1.9183163\ttotal: 19.6s\tremaining: 36.4s\n",
      "1610:\tlearn: 1.9178757\ttotal: 19.6s\tremaining: 36.3s\n",
      "1611:\tlearn: 1.9174310\ttotal: 19.6s\tremaining: 36.3s\n",
      "1612:\tlearn: 1.9172174\ttotal: 19.6s\tremaining: 36.3s\n",
      "1613:\tlearn: 1.9165938\ttotal: 19.6s\tremaining: 36.3s\n",
      "1614:\tlearn: 1.9162637\ttotal: 19.7s\tremaining: 36.3s\n",
      "1615:\tlearn: 1.9154066\ttotal: 19.7s\tremaining: 36.3s\n",
      "1616:\tlearn: 1.9149995\ttotal: 19.7s\tremaining: 36.3s\n",
      "1617:\tlearn: 1.9142135\ttotal: 19.7s\tremaining: 36.3s\n",
      "1618:\tlearn: 1.9141074\ttotal: 19.7s\tremaining: 36.3s\n",
      "1619:\tlearn: 1.9135527\ttotal: 19.7s\tremaining: 36.2s\n",
      "1620:\tlearn: 1.9131367\ttotal: 19.7s\tremaining: 36.2s\n",
      "1621:\tlearn: 1.9128404\ttotal: 19.7s\tremaining: 36.2s\n",
      "1622:\tlearn: 1.9123857\ttotal: 19.8s\tremaining: 36.2s\n",
      "1623:\tlearn: 1.9119223\ttotal: 19.8s\tremaining: 36.2s\n",
      "1624:\tlearn: 1.9114119\ttotal: 19.8s\tremaining: 36.2s\n",
      "1625:\tlearn: 1.9112777\ttotal: 19.8s\tremaining: 36.2s\n",
      "1626:\tlearn: 1.9107275\ttotal: 19.8s\tremaining: 36.2s\n",
      "1627:\tlearn: 1.9104460\ttotal: 19.8s\tremaining: 36.1s\n",
      "1628:\tlearn: 1.9096602\ttotal: 19.8s\tremaining: 36.1s\n",
      "1629:\tlearn: 1.9095712\ttotal: 19.8s\tremaining: 36.1s\n",
      "1630:\tlearn: 1.9091952\ttotal: 19.8s\tremaining: 36.1s\n",
      "1631:\tlearn: 1.9090545\ttotal: 19.9s\tremaining: 36.1s\n",
      "1632:\tlearn: 1.9086979\ttotal: 19.9s\tremaining: 36.1s\n",
      "1633:\tlearn: 1.9081463\ttotal: 19.9s\tremaining: 36.1s\n",
      "1634:\tlearn: 1.9078244\ttotal: 19.9s\tremaining: 36.1s\n",
      "1635:\tlearn: 1.9074202\ttotal: 19.9s\tremaining: 36s\n",
      "1636:\tlearn: 1.9071274\ttotal: 19.9s\tremaining: 36s\n",
      "1637:\tlearn: 1.9065011\ttotal: 19.9s\tremaining: 36s\n",
      "1638:\tlearn: 1.9059663\ttotal: 19.9s\tremaining: 36s\n",
      "1639:\tlearn: 1.9057459\ttotal: 20s\tremaining: 36s\n",
      "1640:\tlearn: 1.9049838\ttotal: 20s\tremaining: 36s\n",
      "1641:\tlearn: 1.9045866\ttotal: 20s\tremaining: 36s\n",
      "1642:\tlearn: 1.9042155\ttotal: 20s\tremaining: 36s\n",
      "1643:\tlearn: 1.9037711\ttotal: 20s\tremaining: 35.9s\n",
      "1644:\tlearn: 1.9031317\ttotal: 20s\tremaining: 35.9s\n",
      "1645:\tlearn: 1.9027394\ttotal: 20s\tremaining: 35.9s\n",
      "1646:\tlearn: 1.9022785\ttotal: 20s\tremaining: 35.9s\n",
      "1647:\tlearn: 1.9021480\ttotal: 20.1s\tremaining: 35.9s\n",
      "1648:\tlearn: 1.9015230\ttotal: 20.1s\tremaining: 35.9s\n",
      "1649:\tlearn: 1.9011190\ttotal: 20.1s\tremaining: 35.9s\n",
      "1650:\tlearn: 1.9005563\ttotal: 20.1s\tremaining: 35.9s\n",
      "1651:\tlearn: 1.9000576\ttotal: 20.1s\tremaining: 35.9s\n",
      "1652:\tlearn: 1.8996869\ttotal: 20.1s\tremaining: 35.8s\n",
      "1653:\tlearn: 1.8991833\ttotal: 20.1s\tremaining: 35.8s\n",
      "1654:\tlearn: 1.8987351\ttotal: 20.1s\tremaining: 35.8s\n",
      "1655:\tlearn: 1.8981163\ttotal: 20.2s\tremaining: 35.8s\n",
      "1656:\tlearn: 1.8976734\ttotal: 20.2s\tremaining: 35.8s\n",
      "1657:\tlearn: 1.8972575\ttotal: 20.2s\tremaining: 35.8s\n",
      "1658:\tlearn: 1.8969102\ttotal: 20.2s\tremaining: 35.8s\n",
      "1659:\tlearn: 1.8964305\ttotal: 20.2s\tremaining: 35.8s\n",
      "1660:\tlearn: 1.8957683\ttotal: 20.2s\tremaining: 35.8s\n",
      "1661:\tlearn: 1.8950877\ttotal: 20.2s\tremaining: 35.8s\n",
      "1662:\tlearn: 1.8945020\ttotal: 20.2s\tremaining: 35.7s\n",
      "1663:\tlearn: 1.8941649\ttotal: 20.3s\tremaining: 35.7s\n",
      "1664:\tlearn: 1.8934469\ttotal: 20.3s\tremaining: 35.7s\n",
      "1665:\tlearn: 1.8931079\ttotal: 20.3s\tremaining: 35.7s\n",
      "1666:\tlearn: 1.8926970\ttotal: 20.3s\tremaining: 35.7s\n",
      "1667:\tlearn: 1.8920217\ttotal: 20.3s\tremaining: 35.7s\n",
      "1668:\tlearn: 1.8917693\ttotal: 20.3s\tremaining: 35.7s\n",
      "1669:\tlearn: 1.8909622\ttotal: 20.3s\tremaining: 35.7s\n",
      "1670:\tlearn: 1.8898178\ttotal: 20.3s\tremaining: 35.6s\n",
      "1671:\tlearn: 1.8894697\ttotal: 20.4s\tremaining: 35.6s\n",
      "1672:\tlearn: 1.8889791\ttotal: 20.4s\tremaining: 35.6s\n",
      "1673:\tlearn: 1.8881685\ttotal: 20.4s\tremaining: 35.6s\n",
      "1674:\tlearn: 1.8877167\ttotal: 20.4s\tremaining: 35.6s\n",
      "1675:\tlearn: 1.8873350\ttotal: 20.4s\tremaining: 35.6s\n",
      "1676:\tlearn: 1.8871400\ttotal: 20.4s\tremaining: 35.6s\n",
      "1677:\tlearn: 1.8866572\ttotal: 20.4s\tremaining: 35.6s\n",
      "1678:\tlearn: 1.8858704\ttotal: 20.4s\tremaining: 35.6s\n",
      "1679:\tlearn: 1.8855131\ttotal: 20.5s\tremaining: 35.5s\n",
      "1680:\tlearn: 1.8848899\ttotal: 20.5s\tremaining: 35.5s\n",
      "1681:\tlearn: 1.8842138\ttotal: 20.5s\tremaining: 35.5s\n",
      "1682:\tlearn: 1.8836786\ttotal: 20.5s\tremaining: 35.5s\n",
      "1683:\tlearn: 1.8834239\ttotal: 20.5s\tremaining: 35.5s\n",
      "1684:\tlearn: 1.8830280\ttotal: 20.5s\tremaining: 35.5s\n",
      "1685:\tlearn: 1.8822452\ttotal: 20.5s\tremaining: 35.5s\n",
      "1686:\tlearn: 1.8816869\ttotal: 20.5s\tremaining: 35.5s\n",
      "1687:\tlearn: 1.8813988\ttotal: 20.6s\tremaining: 35.4s\n",
      "1688:\tlearn: 1.8808589\ttotal: 20.6s\tremaining: 35.4s\n",
      "1689:\tlearn: 1.8805946\ttotal: 20.6s\tremaining: 35.4s\n",
      "1690:\tlearn: 1.8799807\ttotal: 20.6s\tremaining: 35.4s\n",
      "1691:\tlearn: 1.8795309\ttotal: 20.6s\tremaining: 35.4s\n",
      "1692:\tlearn: 1.8793146\ttotal: 20.6s\tremaining: 35.4s\n",
      "1693:\tlearn: 1.8788053\ttotal: 20.6s\tremaining: 35.4s\n",
      "1694:\tlearn: 1.8782430\ttotal: 20.6s\tremaining: 35.4s\n",
      "1695:\tlearn: 1.8778977\ttotal: 20.7s\tremaining: 35.3s\n",
      "1696:\tlearn: 1.8774773\ttotal: 20.7s\tremaining: 35.3s\n",
      "1697:\tlearn: 1.8771303\ttotal: 20.7s\tremaining: 35.3s\n",
      "1698:\tlearn: 1.8768269\ttotal: 20.7s\tremaining: 35.3s\n",
      "1699:\tlearn: 1.8766354\ttotal: 20.7s\tremaining: 35.3s\n",
      "1700:\tlearn: 1.8762396\ttotal: 20.7s\tremaining: 35.3s\n",
      "1701:\tlearn: 1.8758540\ttotal: 20.7s\tremaining: 35.3s\n",
      "1702:\tlearn: 1.8755000\ttotal: 20.7s\tremaining: 35.3s\n",
      "1703:\tlearn: 1.8750154\ttotal: 20.8s\tremaining: 35.2s\n",
      "1704:\tlearn: 1.8744253\ttotal: 20.8s\tremaining: 35.2s\n",
      "1705:\tlearn: 1.8740964\ttotal: 20.8s\tremaining: 35.2s\n",
      "1706:\tlearn: 1.8738922\ttotal: 20.8s\tremaining: 35.2s\n",
      "1707:\tlearn: 1.8735274\ttotal: 20.8s\tremaining: 35.2s\n",
      "1708:\tlearn: 1.8732319\ttotal: 20.8s\tremaining: 35.2s\n",
      "1709:\tlearn: 1.8727368\ttotal: 20.8s\tremaining: 35.2s\n",
      "1710:\tlearn: 1.8725425\ttotal: 20.8s\tremaining: 35.2s\n",
      "1711:\tlearn: 1.8723172\ttotal: 20.8s\tremaining: 35.1s\n",
      "1712:\tlearn: 1.8721801\ttotal: 20.9s\tremaining: 35.1s\n",
      "1713:\tlearn: 1.8718894\ttotal: 20.9s\tremaining: 35.1s\n",
      "1714:\tlearn: 1.8714847\ttotal: 20.9s\tremaining: 35.1s\n",
      "1715:\tlearn: 1.8713483\ttotal: 20.9s\tremaining: 35.1s\n",
      "1716:\tlearn: 1.8707951\ttotal: 20.9s\tremaining: 35.1s\n",
      "1717:\tlearn: 1.8704256\ttotal: 20.9s\tremaining: 35.1s\n",
      "1718:\tlearn: 1.8699511\ttotal: 20.9s\tremaining: 35.1s\n",
      "1719:\tlearn: 1.8694737\ttotal: 20.9s\tremaining: 35s\n",
      "1720:\tlearn: 1.8689172\ttotal: 21s\tremaining: 35s\n",
      "1721:\tlearn: 1.8686310\ttotal: 21s\tremaining: 35s\n",
      "1722:\tlearn: 1.8683618\ttotal: 21s\tremaining: 35s\n",
      "1723:\tlearn: 1.8681150\ttotal: 21s\tremaining: 35s\n",
      "1724:\tlearn: 1.8675765\ttotal: 21s\tremaining: 35s\n",
      "1725:\tlearn: 1.8674187\ttotal: 21s\tremaining: 35s\n",
      "1726:\tlearn: 1.8665295\ttotal: 21s\tremaining: 35s\n",
      "1727:\tlearn: 1.8662209\ttotal: 21s\tremaining: 34.9s\n",
      "1728:\tlearn: 1.8659979\ttotal: 21.1s\tremaining: 34.9s\n",
      "1729:\tlearn: 1.8656543\ttotal: 21.1s\tremaining: 34.9s\n",
      "1730:\tlearn: 1.8654160\ttotal: 21.1s\tremaining: 34.9s\n",
      "1731:\tlearn: 1.8651947\ttotal: 21.1s\tremaining: 34.9s\n",
      "1732:\tlearn: 1.8647391\ttotal: 21.1s\tremaining: 34.9s\n",
      "1733:\tlearn: 1.8643131\ttotal: 21.1s\tremaining: 34.9s\n",
      "1734:\tlearn: 1.8640622\ttotal: 21.1s\tremaining: 34.9s\n",
      "1735:\tlearn: 1.8636478\ttotal: 21.1s\tremaining: 34.8s\n",
      "1736:\tlearn: 1.8631890\ttotal: 21.1s\tremaining: 34.8s\n",
      "1737:\tlearn: 1.8626407\ttotal: 21.2s\tremaining: 34.8s\n",
      "1738:\tlearn: 1.8624876\ttotal: 21.2s\tremaining: 34.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1739:\tlearn: 1.8621952\ttotal: 21.2s\tremaining: 34.8s\n",
      "1740:\tlearn: 1.8617627\ttotal: 21.2s\tremaining: 34.8s\n",
      "1741:\tlearn: 1.8615429\ttotal: 21.2s\tremaining: 34.8s\n",
      "1742:\tlearn: 1.8610617\ttotal: 21.2s\tremaining: 34.8s\n",
      "1743:\tlearn: 1.8606743\ttotal: 21.2s\tremaining: 34.7s\n",
      "1744:\tlearn: 1.8600832\ttotal: 21.2s\tremaining: 34.7s\n",
      "1745:\tlearn: 1.8596802\ttotal: 21.3s\tremaining: 34.7s\n",
      "1746:\tlearn: 1.8594593\ttotal: 21.3s\tremaining: 34.7s\n",
      "1747:\tlearn: 1.8591187\ttotal: 21.3s\tremaining: 34.7s\n",
      "1748:\tlearn: 1.8589831\ttotal: 21.3s\tremaining: 34.7s\n",
      "1749:\tlearn: 1.8587483\ttotal: 21.3s\tremaining: 34.7s\n",
      "1750:\tlearn: 1.8582417\ttotal: 21.3s\tremaining: 34.6s\n",
      "1751:\tlearn: 1.8575839\ttotal: 21.3s\tremaining: 34.6s\n",
      "1752:\tlearn: 1.8571109\ttotal: 21.3s\tremaining: 34.6s\n",
      "1753:\tlearn: 1.8566776\ttotal: 21.3s\tremaining: 34.6s\n",
      "1754:\tlearn: 1.8564062\ttotal: 21.4s\tremaining: 34.6s\n",
      "1755:\tlearn: 1.8559457\ttotal: 21.4s\tremaining: 34.6s\n",
      "1756:\tlearn: 1.8553821\ttotal: 21.4s\tremaining: 34.6s\n",
      "1757:\tlearn: 1.8551024\ttotal: 21.4s\tremaining: 34.6s\n",
      "1758:\tlearn: 1.8547048\ttotal: 21.4s\tremaining: 34.6s\n",
      "1759:\tlearn: 1.8542761\ttotal: 21.4s\tremaining: 34.5s\n",
      "1760:\tlearn: 1.8538847\ttotal: 21.4s\tremaining: 34.5s\n",
      "1761:\tlearn: 1.8535410\ttotal: 21.4s\tremaining: 34.5s\n",
      "1762:\tlearn: 1.8530631\ttotal: 21.5s\tremaining: 34.5s\n",
      "1763:\tlearn: 1.8526694\ttotal: 21.5s\tremaining: 34.5s\n",
      "1764:\tlearn: 1.8522639\ttotal: 21.5s\tremaining: 34.5s\n",
      "1765:\tlearn: 1.8517792\ttotal: 21.5s\tremaining: 34.5s\n",
      "1766:\tlearn: 1.8513120\ttotal: 21.5s\tremaining: 34.5s\n",
      "1767:\tlearn: 1.8507093\ttotal: 21.5s\tremaining: 34.4s\n",
      "1768:\tlearn: 1.8500857\ttotal: 21.5s\tremaining: 34.4s\n",
      "1769:\tlearn: 1.8496669\ttotal: 21.5s\tremaining: 34.4s\n",
      "1770:\tlearn: 1.8491037\ttotal: 21.6s\tremaining: 34.4s\n",
      "1771:\tlearn: 1.8485760\ttotal: 21.6s\tremaining: 34.4s\n",
      "1772:\tlearn: 1.8476081\ttotal: 21.6s\tremaining: 34.4s\n",
      "1773:\tlearn: 1.8473705\ttotal: 21.6s\tremaining: 34.4s\n",
      "1774:\tlearn: 1.8470614\ttotal: 21.6s\tremaining: 34.4s\n",
      "1775:\tlearn: 1.8469208\ttotal: 21.6s\tremaining: 34.3s\n",
      "1776:\tlearn: 1.8462141\ttotal: 21.6s\tremaining: 34.3s\n",
      "1777:\tlearn: 1.8457382\ttotal: 21.6s\tremaining: 34.3s\n",
      "1778:\tlearn: 1.8456224\ttotal: 21.6s\tremaining: 34.3s\n",
      "1779:\tlearn: 1.8453502\ttotal: 21.7s\tremaining: 34.3s\n",
      "1780:\tlearn: 1.8449936\ttotal: 21.7s\tremaining: 34.3s\n",
      "1781:\tlearn: 1.8447055\ttotal: 21.7s\tremaining: 34.3s\n",
      "1782:\tlearn: 1.8444391\ttotal: 21.7s\tremaining: 34.3s\n",
      "1783:\tlearn: 1.8441643\ttotal: 21.7s\tremaining: 34.2s\n",
      "1784:\tlearn: 1.8437369\ttotal: 21.7s\tremaining: 34.2s\n",
      "1785:\tlearn: 1.8431606\ttotal: 21.7s\tremaining: 34.2s\n",
      "1786:\tlearn: 1.8428853\ttotal: 21.7s\tremaining: 34.2s\n",
      "1787:\tlearn: 1.8424433\ttotal: 21.8s\tremaining: 34.2s\n",
      "1788:\tlearn: 1.8416942\ttotal: 21.8s\tremaining: 34.2s\n",
      "1789:\tlearn: 1.8412232\ttotal: 21.8s\tremaining: 34.2s\n",
      "1790:\tlearn: 1.8409959\ttotal: 21.8s\tremaining: 34.2s\n",
      "1791:\tlearn: 1.8405112\ttotal: 21.8s\tremaining: 34.1s\n",
      "1792:\tlearn: 1.8404758\ttotal: 21.8s\tremaining: 34.1s\n",
      "1793:\tlearn: 1.8400875\ttotal: 21.8s\tremaining: 34.1s\n",
      "1794:\tlearn: 1.8398473\ttotal: 21.8s\tremaining: 34.1s\n",
      "1795:\tlearn: 1.8394664\ttotal: 21.9s\tremaining: 34.1s\n",
      "1796:\tlearn: 1.8393328\ttotal: 21.9s\tremaining: 34.1s\n",
      "1797:\tlearn: 1.8390717\ttotal: 21.9s\tremaining: 34.1s\n",
      "1798:\tlearn: 1.8385328\ttotal: 21.9s\tremaining: 34.1s\n",
      "1799:\tlearn: 1.8384099\ttotal: 21.9s\tremaining: 34s\n",
      "1800:\tlearn: 1.8379165\ttotal: 21.9s\tremaining: 34s\n",
      "1801:\tlearn: 1.8373982\ttotal: 21.9s\tremaining: 34s\n",
      "1802:\tlearn: 1.8369234\ttotal: 21.9s\tremaining: 34s\n",
      "1803:\tlearn: 1.8363898\ttotal: 22s\tremaining: 34s\n",
      "1804:\tlearn: 1.8360534\ttotal: 22s\tremaining: 34s\n",
      "1805:\tlearn: 1.8356175\ttotal: 22s\tremaining: 34s\n",
      "1806:\tlearn: 1.8353501\ttotal: 22s\tremaining: 34s\n",
      "1807:\tlearn: 1.8351805\ttotal: 22s\tremaining: 33.9s\n",
      "1808:\tlearn: 1.8347989\ttotal: 22s\tremaining: 33.9s\n",
      "1809:\tlearn: 1.8347041\ttotal: 22s\tremaining: 33.9s\n",
      "1810:\tlearn: 1.8343836\ttotal: 22s\tremaining: 33.9s\n",
      "1811:\tlearn: 1.8342205\ttotal: 22s\tremaining: 33.9s\n",
      "1812:\tlearn: 1.8341476\ttotal: 22.1s\tremaining: 33.9s\n",
      "1813:\tlearn: 1.8337852\ttotal: 22.1s\tremaining: 33.9s\n",
      "1814:\tlearn: 1.8332946\ttotal: 22.1s\tremaining: 33.9s\n",
      "1815:\tlearn: 1.8328716\ttotal: 22.1s\tremaining: 33.8s\n",
      "1816:\tlearn: 1.8324444\ttotal: 22.1s\tremaining: 33.8s\n",
      "1817:\tlearn: 1.8320438\ttotal: 22.1s\tremaining: 33.8s\n",
      "1818:\tlearn: 1.8318296\ttotal: 22.1s\tremaining: 33.8s\n",
      "1819:\tlearn: 1.8313572\ttotal: 22.1s\tremaining: 33.8s\n",
      "1820:\tlearn: 1.8311794\ttotal: 22.2s\tremaining: 33.8s\n",
      "1821:\tlearn: 1.8307674\ttotal: 22.2s\tremaining: 33.8s\n",
      "1822:\tlearn: 1.8303938\ttotal: 22.2s\tremaining: 33.8s\n",
      "1823:\tlearn: 1.8299444\ttotal: 22.2s\tremaining: 33.7s\n",
      "1824:\tlearn: 1.8291803\ttotal: 22.2s\tremaining: 33.7s\n",
      "1825:\tlearn: 1.8288442\ttotal: 22.2s\tremaining: 33.7s\n",
      "1826:\tlearn: 1.8282952\ttotal: 22.2s\tremaining: 33.7s\n",
      "1827:\tlearn: 1.8280200\ttotal: 22.2s\tremaining: 33.7s\n",
      "1828:\tlearn: 1.8278476\ttotal: 22.2s\tremaining: 33.7s\n",
      "1829:\tlearn: 1.8270884\ttotal: 22.3s\tremaining: 33.7s\n",
      "1830:\tlearn: 1.8266625\ttotal: 22.3s\tremaining: 33.7s\n",
      "1831:\tlearn: 1.8262603\ttotal: 22.3s\tremaining: 33.6s\n",
      "1832:\tlearn: 1.8259384\ttotal: 22.3s\tremaining: 33.6s\n",
      "1833:\tlearn: 1.8255979\ttotal: 22.3s\tremaining: 33.6s\n",
      "1834:\tlearn: 1.8251806\ttotal: 22.3s\tremaining: 33.6s\n",
      "1835:\tlearn: 1.8245249\ttotal: 22.3s\tremaining: 33.6s\n",
      "1836:\tlearn: 1.8244134\ttotal: 22.3s\tremaining: 33.6s\n",
      "1837:\tlearn: 1.8241534\ttotal: 22.4s\tremaining: 33.6s\n",
      "1838:\tlearn: 1.8239113\ttotal: 22.4s\tremaining: 33.6s\n",
      "1839:\tlearn: 1.8235396\ttotal: 22.4s\tremaining: 33.5s\n",
      "1840:\tlearn: 1.8229915\ttotal: 22.4s\tremaining: 33.5s\n",
      "1841:\tlearn: 1.8225530\ttotal: 22.4s\tremaining: 33.5s\n",
      "1842:\tlearn: 1.8220383\ttotal: 22.4s\tremaining: 33.5s\n",
      "1843:\tlearn: 1.8215222\ttotal: 22.4s\tremaining: 33.5s\n",
      "1844:\tlearn: 1.8212441\ttotal: 22.4s\tremaining: 33.5s\n",
      "1845:\tlearn: 1.8209089\ttotal: 22.5s\tremaining: 33.5s\n",
      "1846:\tlearn: 1.8205140\ttotal: 22.5s\tremaining: 33.5s\n",
      "1847:\tlearn: 1.8200664\ttotal: 22.5s\tremaining: 33.5s\n",
      "1848:\tlearn: 1.8196495\ttotal: 22.5s\tremaining: 33.4s\n",
      "1849:\tlearn: 1.8192935\ttotal: 22.5s\tremaining: 33.4s\n",
      "1850:\tlearn: 1.8188786\ttotal: 22.5s\tremaining: 33.4s\n",
      "1851:\tlearn: 1.8185245\ttotal: 22.5s\tremaining: 33.4s\n",
      "1852:\tlearn: 1.8181866\ttotal: 22.5s\tremaining: 33.4s\n",
      "1853:\tlearn: 1.8177912\ttotal: 22.6s\tremaining: 33.4s\n",
      "1854:\tlearn: 1.8173596\ttotal: 22.6s\tremaining: 33.4s\n",
      "1855:\tlearn: 1.8169925\ttotal: 22.6s\tremaining: 33.4s\n",
      "1856:\tlearn: 1.8163105\ttotal: 22.6s\tremaining: 33.3s\n",
      "1857:\tlearn: 1.8156162\ttotal: 22.6s\tremaining: 33.3s\n",
      "1858:\tlearn: 1.8151520\ttotal: 22.6s\tremaining: 33.3s\n",
      "1859:\tlearn: 1.8147995\ttotal: 22.6s\tremaining: 33.3s\n",
      "1860:\tlearn: 1.8144597\ttotal: 22.6s\tremaining: 33.3s\n",
      "1861:\tlearn: 1.8140672\ttotal: 22.6s\tremaining: 33.3s\n",
      "1862:\tlearn: 1.8137163\ttotal: 22.7s\tremaining: 33.3s\n",
      "1863:\tlearn: 1.8133990\ttotal: 22.7s\tremaining: 33.3s\n",
      "1864:\tlearn: 1.8129268\ttotal: 22.7s\tremaining: 33.2s\n",
      "1865:\tlearn: 1.8128119\ttotal: 22.7s\tremaining: 33.2s\n",
      "1866:\tlearn: 1.8120814\ttotal: 22.7s\tremaining: 33.2s\n",
      "1867:\tlearn: 1.8118730\ttotal: 22.7s\tremaining: 33.2s\n",
      "1868:\tlearn: 1.8113570\ttotal: 22.7s\tremaining: 33.2s\n",
      "1869:\tlearn: 1.8111840\ttotal: 22.7s\tremaining: 33.2s\n",
      "1870:\tlearn: 1.8109532\ttotal: 22.8s\tremaining: 33.2s\n",
      "1871:\tlearn: 1.8105766\ttotal: 22.8s\tremaining: 33.2s\n",
      "1872:\tlearn: 1.8101964\ttotal: 22.8s\tremaining: 33.1s\n",
      "1873:\tlearn: 1.8097668\ttotal: 22.8s\tremaining: 33.1s\n",
      "1874:\tlearn: 1.8092033\ttotal: 22.8s\tremaining: 33.1s\n",
      "1875:\tlearn: 1.8085677\ttotal: 22.8s\tremaining: 33.1s\n",
      "1876:\tlearn: 1.8083556\ttotal: 22.8s\tremaining: 33.1s\n",
      "1877:\tlearn: 1.8079857\ttotal: 22.8s\tremaining: 33.1s\n",
      "1878:\tlearn: 1.8077232\ttotal: 22.9s\tremaining: 33.1s\n",
      "1879:\tlearn: 1.8073581\ttotal: 22.9s\tremaining: 33.1s\n",
      "1880:\tlearn: 1.8069674\ttotal: 22.9s\tremaining: 33s\n",
      "1881:\tlearn: 1.8063653\ttotal: 22.9s\tremaining: 33s\n",
      "1882:\tlearn: 1.8056808\ttotal: 22.9s\tremaining: 33s\n",
      "1883:\tlearn: 1.8053873\ttotal: 22.9s\tremaining: 33s\n",
      "1884:\tlearn: 1.8050444\ttotal: 22.9s\tremaining: 33s\n",
      "1885:\tlearn: 1.8045508\ttotal: 22.9s\tremaining: 33s\n",
      "1886:\tlearn: 1.8044358\ttotal: 22.9s\tremaining: 33s\n",
      "1887:\tlearn: 1.8039723\ttotal: 23s\tremaining: 33s\n",
      "1888:\tlearn: 1.8037254\ttotal: 23s\tremaining: 32.9s\n",
      "1889:\tlearn: 1.8033039\ttotal: 23s\tremaining: 32.9s\n",
      "1890:\tlearn: 1.8031666\ttotal: 23s\tremaining: 32.9s\n",
      "1891:\tlearn: 1.8030049\ttotal: 23s\tremaining: 32.9s\n",
      "1892:\tlearn: 1.8027373\ttotal: 23s\tremaining: 32.9s\n",
      "1893:\tlearn: 1.8025178\ttotal: 23s\tremaining: 32.9s\n",
      "1894:\tlearn: 1.8020483\ttotal: 23s\tremaining: 32.9s\n",
      "1895:\tlearn: 1.8017087\ttotal: 23.1s\tremaining: 32.9s\n",
      "1896:\tlearn: 1.8012633\ttotal: 23.1s\tremaining: 32.8s\n",
      "1897:\tlearn: 1.8007044\ttotal: 23.1s\tremaining: 32.8s\n",
      "1898:\tlearn: 1.8004583\ttotal: 23.1s\tremaining: 32.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1899:\tlearn: 1.7999888\ttotal: 23.1s\tremaining: 32.8s\n",
      "1900:\tlearn: 1.7997153\ttotal: 23.1s\tremaining: 32.8s\n",
      "1901:\tlearn: 1.7995692\ttotal: 23.1s\tremaining: 32.8s\n",
      "1902:\tlearn: 1.7993911\ttotal: 23.1s\tremaining: 32.8s\n",
      "1903:\tlearn: 1.7991291\ttotal: 23.2s\tremaining: 32.8s\n",
      "1904:\tlearn: 1.7983491\ttotal: 23.2s\tremaining: 32.7s\n",
      "1905:\tlearn: 1.7979919\ttotal: 23.2s\tremaining: 32.7s\n",
      "1906:\tlearn: 1.7976367\ttotal: 23.2s\tremaining: 32.7s\n",
      "1907:\tlearn: 1.7972444\ttotal: 23.2s\tremaining: 32.7s\n",
      "1908:\tlearn: 1.7969799\ttotal: 23.2s\tremaining: 32.7s\n",
      "1909:\tlearn: 1.7966040\ttotal: 23.2s\tremaining: 32.7s\n",
      "1910:\tlearn: 1.7963610\ttotal: 23.2s\tremaining: 32.7s\n",
      "1911:\tlearn: 1.7958772\ttotal: 23.2s\tremaining: 32.7s\n",
      "1912:\tlearn: 1.7956354\ttotal: 23.3s\tremaining: 32.6s\n",
      "1913:\tlearn: 1.7952723\ttotal: 23.3s\tremaining: 32.6s\n",
      "1914:\tlearn: 1.7942710\ttotal: 23.3s\tremaining: 32.6s\n",
      "1915:\tlearn: 1.7939715\ttotal: 23.3s\tremaining: 32.6s\n",
      "1916:\tlearn: 1.7937980\ttotal: 23.3s\tremaining: 32.6s\n",
      "1917:\tlearn: 1.7935781\ttotal: 23.3s\tremaining: 32.6s\n",
      "1918:\tlearn: 1.7931644\ttotal: 23.3s\tremaining: 32.6s\n",
      "1919:\tlearn: 1.7929485\ttotal: 23.3s\tremaining: 32.6s\n",
      "1920:\tlearn: 1.7928581\ttotal: 23.4s\tremaining: 32.5s\n",
      "1921:\tlearn: 1.7924800\ttotal: 23.4s\tremaining: 32.5s\n",
      "1922:\tlearn: 1.7921384\ttotal: 23.4s\tremaining: 32.5s\n",
      "1923:\tlearn: 1.7915335\ttotal: 23.4s\tremaining: 32.5s\n",
      "1924:\tlearn: 1.7908963\ttotal: 23.4s\tremaining: 32.5s\n",
      "1925:\tlearn: 1.7907641\ttotal: 23.4s\tremaining: 32.5s\n",
      "1926:\tlearn: 1.7903546\ttotal: 23.4s\tremaining: 32.5s\n",
      "1927:\tlearn: 1.7900778\ttotal: 23.4s\tremaining: 32.5s\n",
      "1928:\tlearn: 1.7897973\ttotal: 23.4s\tremaining: 32.4s\n",
      "1929:\tlearn: 1.7897242\ttotal: 23.5s\tremaining: 32.4s\n",
      "1930:\tlearn: 1.7893482\ttotal: 23.5s\tremaining: 32.4s\n",
      "1931:\tlearn: 1.7888982\ttotal: 23.5s\tremaining: 32.4s\n",
      "1932:\tlearn: 1.7885091\ttotal: 23.5s\tremaining: 32.4s\n",
      "1933:\tlearn: 1.7876523\ttotal: 23.5s\tremaining: 32.4s\n",
      "1934:\tlearn: 1.7874003\ttotal: 23.5s\tremaining: 32.4s\n",
      "1935:\tlearn: 1.7868447\ttotal: 23.5s\tremaining: 32.4s\n",
      "1936:\tlearn: 1.7862989\ttotal: 23.5s\tremaining: 32.3s\n",
      "1937:\tlearn: 1.7858574\ttotal: 23.6s\tremaining: 32.3s\n",
      "1938:\tlearn: 1.7857737\ttotal: 23.6s\tremaining: 32.3s\n",
      "1939:\tlearn: 1.7856080\ttotal: 23.6s\tremaining: 32.3s\n",
      "1940:\tlearn: 1.7854320\ttotal: 23.6s\tremaining: 32.3s\n",
      "1941:\tlearn: 1.7850039\ttotal: 23.6s\tremaining: 32.3s\n",
      "1942:\tlearn: 1.7846501\ttotal: 23.6s\tremaining: 32.3s\n",
      "1943:\tlearn: 1.7842385\ttotal: 23.6s\tremaining: 32.3s\n",
      "1944:\tlearn: 1.7839520\ttotal: 23.6s\tremaining: 32.2s\n",
      "1945:\tlearn: 1.7835002\ttotal: 23.7s\tremaining: 32.2s\n",
      "1946:\tlearn: 1.7828403\ttotal: 23.7s\tremaining: 32.2s\n",
      "1947:\tlearn: 1.7825152\ttotal: 23.7s\tremaining: 32.2s\n",
      "1948:\tlearn: 1.7822871\ttotal: 23.7s\tremaining: 32.2s\n",
      "1949:\tlearn: 1.7816277\ttotal: 23.7s\tremaining: 32.2s\n",
      "1950:\tlearn: 1.7813088\ttotal: 23.7s\tremaining: 32.2s\n",
      "1951:\tlearn: 1.7809025\ttotal: 23.7s\tremaining: 32.2s\n",
      "1952:\tlearn: 1.7803520\ttotal: 23.7s\tremaining: 32.1s\n",
      "1953:\tlearn: 1.7799954\ttotal: 23.8s\tremaining: 32.1s\n",
      "1954:\tlearn: 1.7797536\ttotal: 23.8s\tremaining: 32.1s\n",
      "1955:\tlearn: 1.7792002\ttotal: 23.8s\tremaining: 32.1s\n",
      "1956:\tlearn: 1.7788151\ttotal: 23.8s\tremaining: 32.1s\n",
      "1957:\tlearn: 1.7784842\ttotal: 23.8s\tremaining: 32.1s\n",
      "1958:\tlearn: 1.7779812\ttotal: 23.8s\tremaining: 32.1s\n",
      "1959:\tlearn: 1.7777816\ttotal: 23.8s\tremaining: 32.1s\n",
      "1960:\tlearn: 1.7774911\ttotal: 23.8s\tremaining: 32s\n",
      "1961:\tlearn: 1.7770178\ttotal: 23.8s\tremaining: 32s\n",
      "1962:\tlearn: 1.7762546\ttotal: 23.9s\tremaining: 32s\n",
      "1963:\tlearn: 1.7759783\ttotal: 23.9s\tremaining: 32s\n",
      "1964:\tlearn: 1.7755997\ttotal: 23.9s\tremaining: 32s\n",
      "1965:\tlearn: 1.7752884\ttotal: 23.9s\tremaining: 32s\n",
      "1966:\tlearn: 1.7748844\ttotal: 23.9s\tremaining: 32s\n",
      "1967:\tlearn: 1.7741351\ttotal: 23.9s\tremaining: 32s\n",
      "1968:\tlearn: 1.7737952\ttotal: 23.9s\tremaining: 32s\n",
      "1969:\tlearn: 1.7734922\ttotal: 23.9s\tremaining: 31.9s\n",
      "1970:\tlearn: 1.7730015\ttotal: 24s\tremaining: 31.9s\n",
      "1971:\tlearn: 1.7727990\ttotal: 24s\tremaining: 31.9s\n",
      "1972:\tlearn: 1.7724423\ttotal: 24s\tremaining: 31.9s\n",
      "1973:\tlearn: 1.7723182\ttotal: 24s\tremaining: 31.9s\n",
      "1974:\tlearn: 1.7720719\ttotal: 24s\tremaining: 31.9s\n",
      "1975:\tlearn: 1.7716467\ttotal: 24s\tremaining: 31.9s\n",
      "1976:\tlearn: 1.7713585\ttotal: 24s\tremaining: 31.9s\n",
      "1977:\tlearn: 1.7710687\ttotal: 24s\tremaining: 31.8s\n",
      "1978:\tlearn: 1.7705399\ttotal: 24.1s\tremaining: 31.8s\n",
      "1979:\tlearn: 1.7703697\ttotal: 24.1s\tremaining: 31.8s\n",
      "1980:\tlearn: 1.7699503\ttotal: 24.1s\tremaining: 31.8s\n",
      "1981:\tlearn: 1.7694685\ttotal: 24.1s\tremaining: 31.8s\n",
      "1982:\tlearn: 1.7692575\ttotal: 24.1s\tremaining: 31.8s\n",
      "1983:\tlearn: 1.7688741\ttotal: 24.1s\tremaining: 31.8s\n",
      "1984:\tlearn: 1.7686870\ttotal: 24.1s\tremaining: 31.8s\n",
      "1985:\tlearn: 1.7682994\ttotal: 24.1s\tremaining: 31.7s\n",
      "1986:\tlearn: 1.7680437\ttotal: 24.1s\tremaining: 31.7s\n",
      "1987:\tlearn: 1.7677379\ttotal: 24.2s\tremaining: 31.7s\n",
      "1988:\tlearn: 1.7675022\ttotal: 24.2s\tremaining: 31.7s\n",
      "1989:\tlearn: 1.7670095\ttotal: 24.2s\tremaining: 31.7s\n",
      "1990:\tlearn: 1.7668667\ttotal: 24.2s\tremaining: 31.7s\n",
      "1991:\tlearn: 1.7665540\ttotal: 24.2s\tremaining: 31.7s\n",
      "1992:\tlearn: 1.7661882\ttotal: 24.2s\tremaining: 31.7s\n",
      "1993:\tlearn: 1.7658189\ttotal: 24.2s\tremaining: 31.6s\n",
      "1994:\tlearn: 1.7653534\ttotal: 24.2s\tremaining: 31.6s\n",
      "1995:\tlearn: 1.7648677\ttotal: 24.3s\tremaining: 31.6s\n",
      "1996:\tlearn: 1.7644018\ttotal: 24.3s\tremaining: 31.6s\n",
      "1997:\tlearn: 1.7640037\ttotal: 24.3s\tremaining: 31.6s\n",
      "1998:\tlearn: 1.7636252\ttotal: 24.3s\tremaining: 31.6s\n",
      "1999:\tlearn: 1.7630262\ttotal: 24.3s\tremaining: 31.6s\n",
      "2000:\tlearn: 1.7627108\ttotal: 24.3s\tremaining: 31.6s\n",
      "2001:\tlearn: 1.7622126\ttotal: 24.3s\tremaining: 31.5s\n",
      "2002:\tlearn: 1.7618125\ttotal: 24.3s\tremaining: 31.5s\n",
      "2003:\tlearn: 1.7611226\ttotal: 24.4s\tremaining: 31.5s\n",
      "2004:\tlearn: 1.7608455\ttotal: 24.4s\tremaining: 31.5s\n",
      "2005:\tlearn: 1.7604998\ttotal: 24.4s\tremaining: 31.5s\n",
      "2006:\tlearn: 1.7600864\ttotal: 24.4s\tremaining: 31.5s\n",
      "2007:\tlearn: 1.7597240\ttotal: 24.4s\tremaining: 31.5s\n",
      "2008:\tlearn: 1.7595473\ttotal: 24.4s\tremaining: 31.5s\n",
      "2009:\tlearn: 1.7594015\ttotal: 24.4s\tremaining: 31.4s\n",
      "2010:\tlearn: 1.7589249\ttotal: 24.4s\tremaining: 31.4s\n",
      "2011:\tlearn: 1.7586909\ttotal: 24.4s\tremaining: 31.4s\n",
      "2012:\tlearn: 1.7578368\ttotal: 24.5s\tremaining: 31.4s\n",
      "2013:\tlearn: 1.7573828\ttotal: 24.5s\tremaining: 31.4s\n",
      "2014:\tlearn: 1.7571775\ttotal: 24.5s\tremaining: 31.4s\n",
      "2015:\tlearn: 1.7568229\ttotal: 24.5s\tremaining: 31.4s\n",
      "2016:\tlearn: 1.7565193\ttotal: 24.5s\tremaining: 31.4s\n",
      "2017:\tlearn: 1.7561812\ttotal: 24.5s\tremaining: 31.3s\n",
      "2018:\tlearn: 1.7559861\ttotal: 24.5s\tremaining: 31.3s\n",
      "2019:\tlearn: 1.7555182\ttotal: 24.5s\tremaining: 31.3s\n",
      "2020:\tlearn: 1.7550779\ttotal: 24.6s\tremaining: 31.3s\n",
      "2021:\tlearn: 1.7545833\ttotal: 24.6s\tremaining: 31.3s\n",
      "2022:\tlearn: 1.7542695\ttotal: 24.6s\tremaining: 31.3s\n",
      "2023:\tlearn: 1.7537938\ttotal: 24.6s\tremaining: 31.3s\n",
      "2024:\tlearn: 1.7535340\ttotal: 24.6s\tremaining: 31.3s\n",
      "2025:\tlearn: 1.7532674\ttotal: 24.6s\tremaining: 31.3s\n",
      "2026:\tlearn: 1.7527200\ttotal: 24.6s\tremaining: 31.2s\n",
      "2027:\tlearn: 1.7522421\ttotal: 24.6s\tremaining: 31.2s\n",
      "2028:\tlearn: 1.7520133\ttotal: 24.7s\tremaining: 31.2s\n",
      "2029:\tlearn: 1.7517924\ttotal: 24.7s\tremaining: 31.2s\n",
      "2030:\tlearn: 1.7515073\ttotal: 24.7s\tremaining: 31.2s\n",
      "2031:\tlearn: 1.7512445\ttotal: 24.7s\tremaining: 31.2s\n",
      "2032:\tlearn: 1.7506355\ttotal: 24.7s\tremaining: 31.2s\n",
      "2033:\tlearn: 1.7499066\ttotal: 24.7s\tremaining: 31.2s\n",
      "2034:\tlearn: 1.7495324\ttotal: 24.7s\tremaining: 31.1s\n",
      "2035:\tlearn: 1.7494069\ttotal: 24.7s\tremaining: 31.1s\n",
      "2036:\tlearn: 1.7490640\ttotal: 24.8s\tremaining: 31.1s\n",
      "2037:\tlearn: 1.7484982\ttotal: 24.8s\tremaining: 31.1s\n",
      "2038:\tlearn: 1.7480611\ttotal: 24.8s\tremaining: 31.1s\n",
      "2039:\tlearn: 1.7478138\ttotal: 24.8s\tremaining: 31.1s\n",
      "2040:\tlearn: 1.7476585\ttotal: 24.8s\tremaining: 31.1s\n",
      "2041:\tlearn: 1.7474297\ttotal: 24.8s\tremaining: 31.1s\n",
      "2042:\tlearn: 1.7471457\ttotal: 24.8s\tremaining: 31s\n",
      "2043:\tlearn: 1.7468181\ttotal: 24.8s\tremaining: 31s\n",
      "2044:\tlearn: 1.7465577\ttotal: 24.9s\tremaining: 31s\n",
      "2045:\tlearn: 1.7462443\ttotal: 24.9s\tremaining: 31s\n",
      "2046:\tlearn: 1.7455987\ttotal: 24.9s\tremaining: 31s\n",
      "2047:\tlearn: 1.7453272\ttotal: 24.9s\tremaining: 31s\n",
      "2048:\tlearn: 1.7449700\ttotal: 24.9s\tremaining: 31s\n",
      "2049:\tlearn: 1.7444466\ttotal: 24.9s\tremaining: 31s\n",
      "2050:\tlearn: 1.7442406\ttotal: 24.9s\tremaining: 30.9s\n",
      "2051:\tlearn: 1.7436262\ttotal: 24.9s\tremaining: 30.9s\n",
      "2052:\tlearn: 1.7434105\ttotal: 24.9s\tremaining: 30.9s\n",
      "2053:\tlearn: 1.7431303\ttotal: 25s\tremaining: 30.9s\n",
      "2054:\tlearn: 1.7427496\ttotal: 25s\tremaining: 30.9s\n",
      "2055:\tlearn: 1.7423111\ttotal: 25s\tremaining: 30.9s\n",
      "2056:\tlearn: 1.7420450\ttotal: 25s\tremaining: 30.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057:\tlearn: 1.7412201\ttotal: 25s\tremaining: 30.9s\n",
      "2058:\tlearn: 1.7410548\ttotal: 25s\tremaining: 30.9s\n",
      "2059:\tlearn: 1.7406495\ttotal: 25s\tremaining: 30.8s\n",
      "2060:\tlearn: 1.7402402\ttotal: 25s\tremaining: 30.8s\n",
      "2061:\tlearn: 1.7398791\ttotal: 25.1s\tremaining: 30.8s\n",
      "2062:\tlearn: 1.7393968\ttotal: 25.1s\tremaining: 30.8s\n",
      "2063:\tlearn: 1.7389398\ttotal: 25.1s\tremaining: 30.8s\n",
      "2064:\tlearn: 1.7385120\ttotal: 25.1s\tremaining: 30.8s\n",
      "2065:\tlearn: 1.7382019\ttotal: 25.1s\tremaining: 30.8s\n",
      "2066:\tlearn: 1.7378960\ttotal: 25.1s\tremaining: 30.8s\n",
      "2067:\tlearn: 1.7376134\ttotal: 25.1s\tremaining: 30.7s\n",
      "2068:\tlearn: 1.7366744\ttotal: 25.1s\tremaining: 30.7s\n",
      "2069:\tlearn: 1.7363845\ttotal: 25.2s\tremaining: 30.7s\n",
      "2070:\tlearn: 1.7357456\ttotal: 25.2s\tremaining: 30.7s\n",
      "2071:\tlearn: 1.7352190\ttotal: 25.2s\tremaining: 30.7s\n",
      "2072:\tlearn: 1.7349976\ttotal: 25.2s\tremaining: 30.7s\n",
      "2073:\tlearn: 1.7347275\ttotal: 25.2s\tremaining: 30.7s\n",
      "2074:\tlearn: 1.7342315\ttotal: 25.2s\tremaining: 30.7s\n",
      "2075:\tlearn: 1.7339175\ttotal: 25.2s\tremaining: 30.7s\n",
      "2076:\tlearn: 1.7335826\ttotal: 25.2s\tremaining: 30.6s\n",
      "2077:\tlearn: 1.7332817\ttotal: 25.3s\tremaining: 30.6s\n",
      "2078:\tlearn: 1.7329699\ttotal: 25.3s\tremaining: 30.6s\n",
      "2079:\tlearn: 1.7321651\ttotal: 25.3s\tremaining: 30.6s\n",
      "2080:\tlearn: 1.7319314\ttotal: 25.3s\tremaining: 30.6s\n",
      "2081:\tlearn: 1.7313259\ttotal: 25.3s\tremaining: 30.6s\n",
      "2082:\tlearn: 1.7309349\ttotal: 25.3s\tremaining: 30.6s\n",
      "2083:\tlearn: 1.7306147\ttotal: 25.3s\tremaining: 30.6s\n",
      "2084:\tlearn: 1.7301280\ttotal: 25.3s\tremaining: 30.5s\n",
      "2085:\tlearn: 1.7297831\ttotal: 25.4s\tremaining: 30.5s\n",
      "2086:\tlearn: 1.7291798\ttotal: 25.4s\tremaining: 30.5s\n",
      "2087:\tlearn: 1.7285628\ttotal: 25.4s\tremaining: 30.5s\n",
      "2088:\tlearn: 1.7282028\ttotal: 25.4s\tremaining: 30.5s\n",
      "2089:\tlearn: 1.7276428\ttotal: 25.4s\tremaining: 30.5s\n",
      "2090:\tlearn: 1.7272160\ttotal: 25.4s\tremaining: 30.5s\n",
      "2091:\tlearn: 1.7268573\ttotal: 25.4s\tremaining: 30.5s\n",
      "2092:\tlearn: 1.7267216\ttotal: 25.4s\tremaining: 30.5s\n",
      "2093:\tlearn: 1.7263980\ttotal: 25.5s\tremaining: 30.4s\n",
      "2094:\tlearn: 1.7261915\ttotal: 25.5s\tremaining: 30.4s\n",
      "2095:\tlearn: 1.7259427\ttotal: 25.5s\tremaining: 30.4s\n",
      "2096:\tlearn: 1.7256408\ttotal: 25.5s\tremaining: 30.4s\n",
      "2097:\tlearn: 1.7253623\ttotal: 25.5s\tremaining: 30.4s\n",
      "2098:\tlearn: 1.7249775\ttotal: 25.5s\tremaining: 30.4s\n",
      "2099:\tlearn: 1.7244923\ttotal: 25.5s\tremaining: 30.4s\n",
      "2100:\tlearn: 1.7240712\ttotal: 25.5s\tremaining: 30.4s\n",
      "2101:\tlearn: 1.7237282\ttotal: 25.6s\tremaining: 30.3s\n",
      "2102:\tlearn: 1.7233910\ttotal: 25.6s\tremaining: 30.3s\n",
      "2103:\tlearn: 1.7230825\ttotal: 25.6s\tremaining: 30.3s\n",
      "2104:\tlearn: 1.7228079\ttotal: 25.6s\tremaining: 30.3s\n",
      "2105:\tlearn: 1.7221617\ttotal: 25.6s\tremaining: 30.3s\n",
      "2106:\tlearn: 1.7214834\ttotal: 25.6s\tremaining: 30.3s\n",
      "2107:\tlearn: 1.7208570\ttotal: 25.6s\tremaining: 30.3s\n",
      "2108:\tlearn: 1.7205702\ttotal: 25.6s\tremaining: 30.3s\n",
      "2109:\tlearn: 1.7201581\ttotal: 25.7s\tremaining: 30.2s\n",
      "2110:\tlearn: 1.7201036\ttotal: 25.7s\tremaining: 30.2s\n",
      "2111:\tlearn: 1.7199250\ttotal: 25.7s\tremaining: 30.2s\n",
      "2112:\tlearn: 1.7194309\ttotal: 25.7s\tremaining: 30.2s\n",
      "2113:\tlearn: 1.7192289\ttotal: 25.7s\tremaining: 30.2s\n",
      "2114:\tlearn: 1.7185331\ttotal: 25.7s\tremaining: 30.2s\n",
      "2115:\tlearn: 1.7182046\ttotal: 25.7s\tremaining: 30.2s\n",
      "2116:\tlearn: 1.7181504\ttotal: 25.7s\tremaining: 30.2s\n",
      "2117:\tlearn: 1.7180644\ttotal: 25.7s\tremaining: 30.1s\n",
      "2118:\tlearn: 1.7178192\ttotal: 25.8s\tremaining: 30.1s\n",
      "2119:\tlearn: 1.7175205\ttotal: 25.8s\tremaining: 30.1s\n",
      "2120:\tlearn: 1.7173703\ttotal: 25.8s\tremaining: 30.1s\n",
      "2121:\tlearn: 1.7171381\ttotal: 25.8s\tremaining: 30.1s\n",
      "2122:\tlearn: 1.7168666\ttotal: 25.8s\tremaining: 30.1s\n",
      "2123:\tlearn: 1.7165486\ttotal: 25.8s\tremaining: 30.1s\n",
      "2124:\tlearn: 1.7163397\ttotal: 25.8s\tremaining: 30.1s\n",
      "2125:\tlearn: 1.7159722\ttotal: 25.8s\tremaining: 30s\n",
      "2126:\tlearn: 1.7155994\ttotal: 25.9s\tremaining: 30s\n",
      "2127:\tlearn: 1.7153849\ttotal: 25.9s\tremaining: 30s\n",
      "2128:\tlearn: 1.7149536\ttotal: 25.9s\tremaining: 30s\n",
      "2129:\tlearn: 1.7144712\ttotal: 25.9s\tremaining: 30s\n",
      "2130:\tlearn: 1.7140358\ttotal: 25.9s\tremaining: 30s\n",
      "2131:\tlearn: 1.7137441\ttotal: 25.9s\tremaining: 30s\n",
      "2132:\tlearn: 1.7135015\ttotal: 25.9s\tremaining: 30s\n",
      "2133:\tlearn: 1.7134094\ttotal: 25.9s\tremaining: 29.9s\n",
      "2134:\tlearn: 1.7132074\ttotal: 25.9s\tremaining: 29.9s\n",
      "2135:\tlearn: 1.7130394\ttotal: 26s\tremaining: 29.9s\n",
      "2136:\tlearn: 1.7127960\ttotal: 26s\tremaining: 29.9s\n",
      "2137:\tlearn: 1.7121942\ttotal: 26s\tremaining: 29.9s\n",
      "2138:\tlearn: 1.7118556\ttotal: 26s\tremaining: 29.9s\n",
      "2139:\tlearn: 1.7114874\ttotal: 26s\tremaining: 29.9s\n",
      "2140:\tlearn: 1.7111383\ttotal: 26s\tremaining: 29.9s\n",
      "2141:\tlearn: 1.7109241\ttotal: 26s\tremaining: 29.8s\n",
      "2142:\tlearn: 1.7105354\ttotal: 26s\tremaining: 29.8s\n",
      "2143:\tlearn: 1.7104350\ttotal: 26.1s\tremaining: 29.8s\n",
      "2144:\tlearn: 1.7099493\ttotal: 26.1s\tremaining: 29.8s\n",
      "2145:\tlearn: 1.7096855\ttotal: 26.1s\tremaining: 29.8s\n",
      "2146:\tlearn: 1.7093207\ttotal: 26.1s\tremaining: 29.8s\n",
      "2147:\tlearn: 1.7088678\ttotal: 26.1s\tremaining: 29.8s\n",
      "2148:\tlearn: 1.7086213\ttotal: 26.1s\tremaining: 29.8s\n",
      "2149:\tlearn: 1.7081334\ttotal: 26.1s\tremaining: 29.8s\n",
      "2150:\tlearn: 1.7078838\ttotal: 26.1s\tremaining: 29.7s\n",
      "2151:\tlearn: 1.7075596\ttotal: 26.2s\tremaining: 29.7s\n",
      "2152:\tlearn: 1.7071483\ttotal: 26.2s\tremaining: 29.7s\n",
      "2153:\tlearn: 1.7069259\ttotal: 26.2s\tremaining: 29.7s\n",
      "2154:\tlearn: 1.7066539\ttotal: 26.2s\tremaining: 29.7s\n",
      "2155:\tlearn: 1.7061353\ttotal: 26.2s\tremaining: 29.7s\n",
      "2156:\tlearn: 1.7058327\ttotal: 26.2s\tremaining: 29.7s\n",
      "2157:\tlearn: 1.7053365\ttotal: 26.2s\tremaining: 29.6s\n",
      "2158:\tlearn: 1.7051277\ttotal: 26.2s\tremaining: 29.6s\n",
      "2159:\tlearn: 1.7047480\ttotal: 26.2s\tremaining: 29.6s\n",
      "2160:\tlearn: 1.7041990\ttotal: 26.3s\tremaining: 29.6s\n",
      "2161:\tlearn: 1.7039148\ttotal: 26.3s\tremaining: 29.6s\n",
      "2162:\tlearn: 1.7034842\ttotal: 26.3s\tremaining: 29.6s\n",
      "2163:\tlearn: 1.7032911\ttotal: 26.3s\tremaining: 29.6s\n",
      "2164:\tlearn: 1.7028071\ttotal: 26.3s\tremaining: 29.6s\n",
      "2165:\tlearn: 1.7026037\ttotal: 26.3s\tremaining: 29.6s\n",
      "2166:\tlearn: 1.7024356\ttotal: 26.3s\tremaining: 29.5s\n",
      "2167:\tlearn: 1.7023380\ttotal: 26.3s\tremaining: 29.5s\n",
      "2168:\tlearn: 1.7018408\ttotal: 26.4s\tremaining: 29.5s\n",
      "2169:\tlearn: 1.7014692\ttotal: 26.4s\tremaining: 29.5s\n",
      "2170:\tlearn: 1.7011854\ttotal: 26.4s\tremaining: 29.5s\n",
      "2171:\tlearn: 1.7007135\ttotal: 26.4s\tremaining: 29.5s\n",
      "2172:\tlearn: 1.7003932\ttotal: 26.4s\tremaining: 29.5s\n",
      "2173:\tlearn: 1.7000028\ttotal: 26.4s\tremaining: 29.5s\n",
      "2174:\tlearn: 1.6998290\ttotal: 26.4s\tremaining: 29.4s\n",
      "2175:\tlearn: 1.6995198\ttotal: 26.4s\tremaining: 29.4s\n",
      "2176:\tlearn: 1.6991297\ttotal: 26.5s\tremaining: 29.4s\n",
      "2177:\tlearn: 1.6988825\ttotal: 26.5s\tremaining: 29.4s\n",
      "2178:\tlearn: 1.6985855\ttotal: 26.5s\tremaining: 29.4s\n",
      "2179:\tlearn: 1.6980160\ttotal: 26.5s\tremaining: 29.4s\n",
      "2180:\tlearn: 1.6976292\ttotal: 26.5s\tremaining: 29.4s\n",
      "2181:\tlearn: 1.6973878\ttotal: 26.5s\tremaining: 29.4s\n",
      "2182:\tlearn: 1.6966057\ttotal: 26.5s\tremaining: 29.4s\n",
      "2183:\tlearn: 1.6964714\ttotal: 26.5s\tremaining: 29.3s\n",
      "2184:\tlearn: 1.6961995\ttotal: 26.6s\tremaining: 29.3s\n",
      "2185:\tlearn: 1.6959679\ttotal: 26.6s\tremaining: 29.3s\n",
      "2186:\tlearn: 1.6956765\ttotal: 26.6s\tremaining: 29.3s\n",
      "2187:\tlearn: 1.6953308\ttotal: 26.6s\tremaining: 29.3s\n",
      "2188:\tlearn: 1.6950256\ttotal: 26.6s\tremaining: 29.3s\n",
      "2189:\tlearn: 1.6948288\ttotal: 26.6s\tremaining: 29.3s\n",
      "2190:\tlearn: 1.6944019\ttotal: 26.6s\tremaining: 29.3s\n",
      "2191:\tlearn: 1.6936798\ttotal: 26.6s\tremaining: 29.2s\n",
      "2192:\tlearn: 1.6933986\ttotal: 26.7s\tremaining: 29.2s\n",
      "2193:\tlearn: 1.6930736\ttotal: 26.7s\tremaining: 29.2s\n",
      "2194:\tlearn: 1.6929372\ttotal: 26.7s\tremaining: 29.2s\n",
      "2195:\tlearn: 1.6925455\ttotal: 26.7s\tremaining: 29.2s\n",
      "2196:\tlearn: 1.6920834\ttotal: 26.7s\tremaining: 29.2s\n",
      "2197:\tlearn: 1.6918047\ttotal: 26.7s\tremaining: 29.2s\n",
      "2198:\tlearn: 1.6915818\ttotal: 26.7s\tremaining: 29.2s\n",
      "2199:\tlearn: 1.6913780\ttotal: 26.7s\tremaining: 29.1s\n",
      "2200:\tlearn: 1.6908065\ttotal: 26.8s\tremaining: 29.1s\n",
      "2201:\tlearn: 1.6902845\ttotal: 26.8s\tremaining: 29.1s\n",
      "2202:\tlearn: 1.6900445\ttotal: 26.8s\tremaining: 29.1s\n",
      "2203:\tlearn: 1.6897649\ttotal: 26.8s\tremaining: 29.1s\n",
      "2204:\tlearn: 1.6892368\ttotal: 26.8s\tremaining: 29.1s\n",
      "2205:\tlearn: 1.6890599\ttotal: 26.8s\tremaining: 29.1s\n",
      "2206:\tlearn: 1.6886483\ttotal: 26.8s\tremaining: 29.1s\n",
      "2207:\tlearn: 1.6885618\ttotal: 26.8s\tremaining: 29s\n",
      "2208:\tlearn: 1.6883401\ttotal: 26.8s\tremaining: 29s\n",
      "2209:\tlearn: 1.6881119\ttotal: 26.9s\tremaining: 29s\n",
      "2210:\tlearn: 1.6875276\ttotal: 26.9s\tremaining: 29s\n",
      "2211:\tlearn: 1.6871196\ttotal: 26.9s\tremaining: 29s\n",
      "2212:\tlearn: 1.6867798\ttotal: 26.9s\tremaining: 29s\n",
      "2213:\tlearn: 1.6864525\ttotal: 26.9s\tremaining: 29s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214:\tlearn: 1.6861120\ttotal: 26.9s\tremaining: 29s\n",
      "2215:\tlearn: 1.6857390\ttotal: 26.9s\tremaining: 28.9s\n",
      "2216:\tlearn: 1.6852614\ttotal: 26.9s\tremaining: 28.9s\n",
      "2217:\tlearn: 1.6850023\ttotal: 27s\tremaining: 28.9s\n",
      "2218:\tlearn: 1.6846000\ttotal: 27s\tremaining: 28.9s\n",
      "2219:\tlearn: 1.6843600\ttotal: 27s\tremaining: 28.9s\n",
      "2220:\tlearn: 1.6842005\ttotal: 27s\tremaining: 28.9s\n",
      "2221:\tlearn: 1.6838818\ttotal: 27s\tremaining: 28.9s\n",
      "2222:\tlearn: 1.6834583\ttotal: 27s\tremaining: 28.9s\n",
      "2223:\tlearn: 1.6829944\ttotal: 27s\tremaining: 28.8s\n",
      "2224:\tlearn: 1.6828731\ttotal: 27s\tremaining: 28.8s\n",
      "2225:\tlearn: 1.6827544\ttotal: 27s\tremaining: 28.8s\n",
      "2226:\tlearn: 1.6822931\ttotal: 27.1s\tremaining: 28.8s\n",
      "2227:\tlearn: 1.6819482\ttotal: 27.1s\tremaining: 28.8s\n",
      "2228:\tlearn: 1.6815597\ttotal: 27.1s\tremaining: 28.8s\n",
      "2229:\tlearn: 1.6813766\ttotal: 27.1s\tremaining: 28.8s\n",
      "2230:\tlearn: 1.6810927\ttotal: 27.1s\tremaining: 28.8s\n",
      "2231:\tlearn: 1.6808770\ttotal: 27.1s\tremaining: 28.7s\n",
      "2232:\tlearn: 1.6807907\ttotal: 27.1s\tremaining: 28.7s\n",
      "2233:\tlearn: 1.6805369\ttotal: 27.1s\tremaining: 28.7s\n",
      "2234:\tlearn: 1.6804040\ttotal: 27.2s\tremaining: 28.7s\n",
      "2235:\tlearn: 1.6801014\ttotal: 27.2s\tremaining: 28.7s\n",
      "2236:\tlearn: 1.6798586\ttotal: 27.2s\tremaining: 28.7s\n",
      "2237:\tlearn: 1.6797033\ttotal: 27.2s\tremaining: 28.7s\n",
      "2238:\tlearn: 1.6794082\ttotal: 27.2s\tremaining: 28.7s\n",
      "2239:\tlearn: 1.6790003\ttotal: 27.2s\tremaining: 28.7s\n",
      "2240:\tlearn: 1.6787016\ttotal: 27.2s\tremaining: 28.6s\n",
      "2241:\tlearn: 1.6785051\ttotal: 27.2s\tremaining: 28.6s\n",
      "2242:\tlearn: 1.6783008\ttotal: 27.3s\tremaining: 28.6s\n",
      "2243:\tlearn: 1.6776606\ttotal: 27.3s\tremaining: 28.6s\n",
      "2244:\tlearn: 1.6773470\ttotal: 27.3s\tremaining: 28.6s\n",
      "2245:\tlearn: 1.6771416\ttotal: 27.3s\tremaining: 28.6s\n",
      "2246:\tlearn: 1.6767858\ttotal: 27.3s\tremaining: 28.6s\n",
      "2247:\tlearn: 1.6765739\ttotal: 27.3s\tremaining: 28.6s\n",
      "2248:\tlearn: 1.6763429\ttotal: 27.3s\tremaining: 28.5s\n",
      "2249:\tlearn: 1.6762419\ttotal: 27.3s\tremaining: 28.5s\n",
      "2250:\tlearn: 1.6759483\ttotal: 27.3s\tremaining: 28.5s\n",
      "2251:\tlearn: 1.6754947\ttotal: 27.4s\tremaining: 28.5s\n",
      "2252:\tlearn: 1.6751478\ttotal: 27.4s\tremaining: 28.5s\n",
      "2253:\tlearn: 1.6748164\ttotal: 27.4s\tremaining: 28.5s\n",
      "2254:\tlearn: 1.6743170\ttotal: 27.4s\tremaining: 28.5s\n",
      "2255:\tlearn: 1.6742089\ttotal: 27.4s\tremaining: 28.5s\n",
      "2256:\tlearn: 1.6739544\ttotal: 27.4s\tremaining: 28.4s\n",
      "2257:\tlearn: 1.6738811\ttotal: 27.4s\tremaining: 28.4s\n",
      "2258:\tlearn: 1.6738234\ttotal: 27.4s\tremaining: 28.4s\n",
      "2259:\tlearn: 1.6736317\ttotal: 27.5s\tremaining: 28.4s\n",
      "2260:\tlearn: 1.6732784\ttotal: 27.5s\tremaining: 28.4s\n",
      "2261:\tlearn: 1.6728200\ttotal: 27.5s\tremaining: 28.4s\n",
      "2262:\tlearn: 1.6724952\ttotal: 27.5s\tremaining: 28.4s\n",
      "2263:\tlearn: 1.6722763\ttotal: 27.5s\tremaining: 28.4s\n",
      "2264:\tlearn: 1.6717168\ttotal: 27.5s\tremaining: 28.3s\n",
      "2265:\tlearn: 1.6712396\ttotal: 27.5s\tremaining: 28.3s\n",
      "2266:\tlearn: 1.6707366\ttotal: 27.5s\tremaining: 28.3s\n",
      "2267:\tlearn: 1.6705810\ttotal: 27.5s\tremaining: 28.3s\n",
      "2268:\tlearn: 1.6702535\ttotal: 27.6s\tremaining: 28.3s\n",
      "2269:\tlearn: 1.6698007\ttotal: 27.6s\tremaining: 28.3s\n",
      "2270:\tlearn: 1.6694797\ttotal: 27.6s\tremaining: 28.3s\n",
      "2271:\tlearn: 1.6689678\ttotal: 27.6s\tremaining: 28.3s\n",
      "2272:\tlearn: 1.6683710\ttotal: 27.6s\tremaining: 28.2s\n",
      "2273:\tlearn: 1.6681715\ttotal: 27.6s\tremaining: 28.2s\n",
      "2274:\tlearn: 1.6680109\ttotal: 27.6s\tremaining: 28.2s\n",
      "2275:\tlearn: 1.6677893\ttotal: 27.6s\tremaining: 28.2s\n",
      "2276:\tlearn: 1.6672173\ttotal: 27.7s\tremaining: 28.2s\n",
      "2277:\tlearn: 1.6670542\ttotal: 27.7s\tremaining: 28.2s\n",
      "2278:\tlearn: 1.6664414\ttotal: 27.7s\tremaining: 28.2s\n",
      "2279:\tlearn: 1.6659531\ttotal: 27.7s\tremaining: 28.2s\n",
      "2280:\tlearn: 1.6656991\ttotal: 27.7s\tremaining: 28.1s\n",
      "2281:\tlearn: 1.6652486\ttotal: 27.7s\tremaining: 28.1s\n",
      "2282:\tlearn: 1.6648887\ttotal: 27.7s\tremaining: 28.1s\n",
      "2283:\tlearn: 1.6647406\ttotal: 27.7s\tremaining: 28.1s\n",
      "2284:\tlearn: 1.6644525\ttotal: 27.8s\tremaining: 28.1s\n",
      "2285:\tlearn: 1.6639021\ttotal: 27.8s\tremaining: 28.1s\n",
      "2286:\tlearn: 1.6636086\ttotal: 27.8s\tremaining: 28.1s\n",
      "2287:\tlearn: 1.6635217\ttotal: 27.8s\tremaining: 28.1s\n",
      "2288:\tlearn: 1.6630158\ttotal: 27.8s\tremaining: 28s\n",
      "2289:\tlearn: 1.6625522\ttotal: 27.8s\tremaining: 28s\n",
      "2290:\tlearn: 1.6621742\ttotal: 27.8s\tremaining: 28s\n",
      "2291:\tlearn: 1.6619171\ttotal: 27.8s\tremaining: 28s\n",
      "2292:\tlearn: 1.6614777\ttotal: 27.9s\tremaining: 28s\n",
      "2293:\tlearn: 1.6612582\ttotal: 27.9s\tremaining: 28s\n",
      "2294:\tlearn: 1.6608536\ttotal: 27.9s\tremaining: 28s\n",
      "2295:\tlearn: 1.6606509\ttotal: 27.9s\tremaining: 28s\n",
      "2296:\tlearn: 1.6604817\ttotal: 27.9s\tremaining: 27.9s\n",
      "2297:\tlearn: 1.6601074\ttotal: 27.9s\tremaining: 27.9s\n",
      "2298:\tlearn: 1.6597835\ttotal: 27.9s\tremaining: 27.9s\n",
      "2299:\tlearn: 1.6595465\ttotal: 27.9s\tremaining: 27.9s\n",
      "2300:\tlearn: 1.6592551\ttotal: 27.9s\tremaining: 27.9s\n",
      "2301:\tlearn: 1.6590210\ttotal: 28s\tremaining: 27.9s\n",
      "2302:\tlearn: 1.6587133\ttotal: 28s\tremaining: 27.9s\n",
      "2303:\tlearn: 1.6584139\ttotal: 28s\tremaining: 27.9s\n",
      "2304:\tlearn: 1.6580639\ttotal: 28s\tremaining: 27.9s\n",
      "2305:\tlearn: 1.6579075\ttotal: 28s\tremaining: 27.8s\n",
      "2306:\tlearn: 1.6577937\ttotal: 28s\tremaining: 27.8s\n",
      "2307:\tlearn: 1.6573253\ttotal: 28s\tremaining: 27.8s\n",
      "2308:\tlearn: 1.6569752\ttotal: 28s\tremaining: 27.8s\n",
      "2309:\tlearn: 1.6566590\ttotal: 28.1s\tremaining: 27.8s\n",
      "2310:\tlearn: 1.6563576\ttotal: 28.1s\tremaining: 27.8s\n",
      "2311:\tlearn: 1.6559604\ttotal: 28.1s\tremaining: 27.8s\n",
      "2312:\tlearn: 1.6557271\ttotal: 28.1s\tremaining: 27.8s\n",
      "2313:\tlearn: 1.6554665\ttotal: 28.1s\tremaining: 27.7s\n",
      "2314:\tlearn: 1.6552648\ttotal: 28.1s\tremaining: 27.7s\n",
      "2315:\tlearn: 1.6549875\ttotal: 28.1s\tremaining: 27.7s\n",
      "2316:\tlearn: 1.6545650\ttotal: 28.1s\tremaining: 27.7s\n",
      "2317:\tlearn: 1.6543138\ttotal: 28.2s\tremaining: 27.7s\n",
      "2318:\tlearn: 1.6537895\ttotal: 28.2s\tremaining: 27.7s\n",
      "2319:\tlearn: 1.6536851\ttotal: 28.2s\tremaining: 27.7s\n",
      "2320:\tlearn: 1.6535822\ttotal: 28.2s\tremaining: 27.7s\n",
      "2321:\tlearn: 1.6530176\ttotal: 28.2s\tremaining: 27.6s\n",
      "2322:\tlearn: 1.6525410\ttotal: 28.2s\tremaining: 27.6s\n",
      "2323:\tlearn: 1.6523298\ttotal: 28.2s\tremaining: 27.6s\n",
      "2324:\tlearn: 1.6521436\ttotal: 28.2s\tremaining: 27.6s\n",
      "2325:\tlearn: 1.6519088\ttotal: 28.2s\tremaining: 27.6s\n",
      "2326:\tlearn: 1.6516711\ttotal: 28.3s\tremaining: 27.6s\n",
      "2327:\tlearn: 1.6513314\ttotal: 28.3s\tremaining: 27.6s\n",
      "2328:\tlearn: 1.6511926\ttotal: 28.3s\tremaining: 27.6s\n",
      "2329:\tlearn: 1.6509246\ttotal: 28.3s\tremaining: 27.5s\n",
      "2330:\tlearn: 1.6505552\ttotal: 28.3s\tremaining: 27.5s\n",
      "2331:\tlearn: 1.6504144\ttotal: 28.3s\tremaining: 27.5s\n",
      "2332:\tlearn: 1.6501851\ttotal: 28.3s\tremaining: 27.5s\n",
      "2333:\tlearn: 1.6496690\ttotal: 28.3s\tremaining: 27.5s\n",
      "2334:\tlearn: 1.6493243\ttotal: 28.4s\tremaining: 27.5s\n",
      "2335:\tlearn: 1.6491578\ttotal: 28.4s\tremaining: 27.5s\n",
      "2336:\tlearn: 1.6486285\ttotal: 28.4s\tremaining: 27.5s\n",
      "2337:\tlearn: 1.6483085\ttotal: 28.4s\tremaining: 27.4s\n",
      "2338:\tlearn: 1.6477817\ttotal: 28.4s\tremaining: 27.4s\n",
      "2339:\tlearn: 1.6472679\ttotal: 28.4s\tremaining: 27.4s\n",
      "2340:\tlearn: 1.6465756\ttotal: 28.4s\tremaining: 27.4s\n",
      "2341:\tlearn: 1.6463134\ttotal: 28.4s\tremaining: 27.4s\n",
      "2342:\tlearn: 1.6461699\ttotal: 28.5s\tremaining: 27.4s\n",
      "2343:\tlearn: 1.6458934\ttotal: 28.5s\tremaining: 27.4s\n",
      "2344:\tlearn: 1.6455137\ttotal: 28.5s\tremaining: 27.4s\n",
      "2345:\tlearn: 1.6451487\ttotal: 28.5s\tremaining: 27.3s\n",
      "2346:\tlearn: 1.6448489\ttotal: 28.5s\tremaining: 27.3s\n",
      "2347:\tlearn: 1.6443790\ttotal: 28.5s\tremaining: 27.3s\n",
      "2348:\tlearn: 1.6440523\ttotal: 28.5s\tremaining: 27.3s\n",
      "2349:\tlearn: 1.6435596\ttotal: 28.5s\tremaining: 27.3s\n",
      "2350:\tlearn: 1.6434184\ttotal: 28.5s\tremaining: 27.3s\n",
      "2351:\tlearn: 1.6431717\ttotal: 28.6s\tremaining: 27.3s\n",
      "2352:\tlearn: 1.6429147\ttotal: 28.6s\tremaining: 27.3s\n",
      "2353:\tlearn: 1.6427219\ttotal: 28.6s\tremaining: 27.2s\n",
      "2354:\tlearn: 1.6424964\ttotal: 28.6s\tremaining: 27.2s\n",
      "2355:\tlearn: 1.6421453\ttotal: 28.6s\tremaining: 27.2s\n",
      "2356:\tlearn: 1.6418934\ttotal: 28.6s\tremaining: 27.2s\n",
      "2357:\tlearn: 1.6414711\ttotal: 28.6s\tremaining: 27.2s\n",
      "2358:\tlearn: 1.6413326\ttotal: 28.6s\tremaining: 27.2s\n",
      "2359:\tlearn: 1.6410894\ttotal: 28.7s\tremaining: 27.2s\n",
      "2360:\tlearn: 1.6410174\ttotal: 28.7s\tremaining: 27.2s\n",
      "2361:\tlearn: 1.6407353\ttotal: 28.7s\tremaining: 27.2s\n",
      "2362:\tlearn: 1.6404594\ttotal: 28.7s\tremaining: 27.1s\n",
      "2363:\tlearn: 1.6400746\ttotal: 28.7s\tremaining: 27.1s\n",
      "2364:\tlearn: 1.6397264\ttotal: 28.7s\tremaining: 27.1s\n",
      "2365:\tlearn: 1.6394084\ttotal: 28.7s\tremaining: 27.1s\n",
      "2366:\tlearn: 1.6389642\ttotal: 28.7s\tremaining: 27.1s\n",
      "2367:\tlearn: 1.6384665\ttotal: 28.8s\tremaining: 27.1s\n",
      "2368:\tlearn: 1.6383309\ttotal: 28.8s\tremaining: 27.1s\n",
      "2369:\tlearn: 1.6380154\ttotal: 28.8s\tremaining: 27.1s\n",
      "2370:\tlearn: 1.6374382\ttotal: 28.8s\tremaining: 27s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2371:\tlearn: 1.6371258\ttotal: 28.8s\tremaining: 27s\n",
      "2372:\tlearn: 1.6366645\ttotal: 28.8s\tremaining: 27s\n",
      "2373:\tlearn: 1.6364847\ttotal: 28.8s\tremaining: 27s\n",
      "2374:\tlearn: 1.6361289\ttotal: 28.8s\tremaining: 27s\n",
      "2375:\tlearn: 1.6357977\ttotal: 28.9s\tremaining: 27s\n",
      "2376:\tlearn: 1.6354485\ttotal: 28.9s\tremaining: 27s\n",
      "2377:\tlearn: 1.6350936\ttotal: 28.9s\tremaining: 27s\n",
      "2378:\tlearn: 1.6348374\ttotal: 28.9s\tremaining: 26.9s\n",
      "2379:\tlearn: 1.6343143\ttotal: 28.9s\tremaining: 26.9s\n",
      "2380:\tlearn: 1.6341118\ttotal: 28.9s\tremaining: 26.9s\n",
      "2381:\tlearn: 1.6337907\ttotal: 28.9s\tremaining: 26.9s\n",
      "2382:\tlearn: 1.6334742\ttotal: 28.9s\tremaining: 26.9s\n",
      "2383:\tlearn: 1.6331697\ttotal: 29s\tremaining: 26.9s\n",
      "2384:\tlearn: 1.6328376\ttotal: 29s\tremaining: 26.9s\n",
      "2385:\tlearn: 1.6323288\ttotal: 29s\tremaining: 26.9s\n",
      "2386:\tlearn: 1.6321102\ttotal: 29s\tremaining: 26.9s\n",
      "2387:\tlearn: 1.6317764\ttotal: 29s\tremaining: 26.8s\n",
      "2388:\tlearn: 1.6312727\ttotal: 29s\tremaining: 26.8s\n",
      "2389:\tlearn: 1.6309653\ttotal: 29s\tremaining: 26.8s\n",
      "2390:\tlearn: 1.6302931\ttotal: 29s\tremaining: 26.8s\n",
      "2391:\tlearn: 1.6299653\ttotal: 29.1s\tremaining: 26.8s\n",
      "2392:\tlearn: 1.6294675\ttotal: 29.1s\tremaining: 26.8s\n",
      "2393:\tlearn: 1.6293902\ttotal: 29.1s\tremaining: 26.8s\n",
      "2394:\tlearn: 1.6290954\ttotal: 29.1s\tremaining: 26.8s\n",
      "2395:\tlearn: 1.6289051\ttotal: 29.1s\tremaining: 26.7s\n",
      "2396:\tlearn: 1.6286152\ttotal: 29.1s\tremaining: 26.7s\n",
      "2397:\tlearn: 1.6284223\ttotal: 29.1s\tremaining: 26.7s\n",
      "2398:\tlearn: 1.6283431\ttotal: 29.1s\tremaining: 26.7s\n",
      "2399:\tlearn: 1.6279938\ttotal: 29.1s\tremaining: 26.7s\n",
      "2400:\tlearn: 1.6275474\ttotal: 29.2s\tremaining: 26.7s\n",
      "2401:\tlearn: 1.6270432\ttotal: 29.2s\tremaining: 26.7s\n",
      "2402:\tlearn: 1.6265919\ttotal: 29.2s\tremaining: 26.7s\n",
      "2403:\tlearn: 1.6262631\ttotal: 29.2s\tremaining: 26.6s\n",
      "2404:\tlearn: 1.6259220\ttotal: 29.2s\tremaining: 26.6s\n",
      "2405:\tlearn: 1.6257548\ttotal: 29.2s\tremaining: 26.6s\n",
      "2406:\tlearn: 1.6255664\ttotal: 29.2s\tremaining: 26.6s\n",
      "2407:\tlearn: 1.6250485\ttotal: 29.2s\tremaining: 26.6s\n",
      "2408:\tlearn: 1.6245772\ttotal: 29.3s\tremaining: 26.6s\n",
      "2409:\tlearn: 1.6239634\ttotal: 29.3s\tremaining: 26.6s\n",
      "2410:\tlearn: 1.6236594\ttotal: 29.3s\tremaining: 26.6s\n",
      "2411:\tlearn: 1.6230887\ttotal: 29.3s\tremaining: 26.6s\n",
      "2412:\tlearn: 1.6229933\ttotal: 29.3s\tremaining: 26.5s\n",
      "2413:\tlearn: 1.6227394\ttotal: 29.3s\tremaining: 26.5s\n",
      "2414:\tlearn: 1.6223950\ttotal: 29.3s\tremaining: 26.5s\n",
      "2415:\tlearn: 1.6220501\ttotal: 29.3s\tremaining: 26.5s\n",
      "2416:\tlearn: 1.6218653\ttotal: 29.4s\tremaining: 26.5s\n",
      "2417:\tlearn: 1.6217173\ttotal: 29.4s\tremaining: 26.5s\n",
      "2418:\tlearn: 1.6214720\ttotal: 29.4s\tremaining: 26.5s\n",
      "2419:\tlearn: 1.6213126\ttotal: 29.4s\tremaining: 26.5s\n",
      "2420:\tlearn: 1.6211456\ttotal: 29.4s\tremaining: 26.4s\n",
      "2421:\tlearn: 1.6209241\ttotal: 29.4s\tremaining: 26.4s\n",
      "2422:\tlearn: 1.6205704\ttotal: 29.4s\tremaining: 26.4s\n",
      "2423:\tlearn: 1.6203838\ttotal: 29.4s\tremaining: 26.4s\n",
      "2424:\tlearn: 1.6199896\ttotal: 29.5s\tremaining: 26.4s\n",
      "2425:\tlearn: 1.6196102\ttotal: 29.5s\tremaining: 26.4s\n",
      "2426:\tlearn: 1.6191959\ttotal: 29.5s\tremaining: 26.4s\n",
      "2427:\tlearn: 1.6185033\ttotal: 29.5s\tremaining: 26.4s\n",
      "2428:\tlearn: 1.6180690\ttotal: 29.5s\tremaining: 26.3s\n",
      "2429:\tlearn: 1.6177999\ttotal: 29.5s\tremaining: 26.3s\n",
      "2430:\tlearn: 1.6173928\ttotal: 29.5s\tremaining: 26.3s\n",
      "2431:\tlearn: 1.6173524\ttotal: 29.5s\tremaining: 26.3s\n",
      "2432:\tlearn: 1.6170806\ttotal: 29.6s\tremaining: 26.3s\n",
      "2433:\tlearn: 1.6167412\ttotal: 29.6s\tremaining: 26.3s\n",
      "2434:\tlearn: 1.6166691\ttotal: 29.6s\tremaining: 26.3s\n",
      "2435:\tlearn: 1.6165393\ttotal: 29.6s\tremaining: 26.3s\n",
      "2436:\tlearn: 1.6162447\ttotal: 29.6s\tremaining: 26.2s\n",
      "2437:\tlearn: 1.6160110\ttotal: 29.6s\tremaining: 26.2s\n",
      "2438:\tlearn: 1.6157079\ttotal: 29.6s\tremaining: 26.2s\n",
      "2439:\tlearn: 1.6154256\ttotal: 29.6s\tremaining: 26.2s\n",
      "2440:\tlearn: 1.6151917\ttotal: 29.6s\tremaining: 26.2s\n",
      "2441:\tlearn: 1.6151552\ttotal: 29.7s\tremaining: 26.2s\n",
      "2442:\tlearn: 1.6150310\ttotal: 29.7s\tremaining: 26.2s\n",
      "2443:\tlearn: 1.6148000\ttotal: 29.7s\tremaining: 26.2s\n",
      "2444:\tlearn: 1.6147129\ttotal: 29.7s\tremaining: 26.1s\n",
      "2445:\tlearn: 1.6145630\ttotal: 29.7s\tremaining: 26.1s\n",
      "2446:\tlearn: 1.6141610\ttotal: 29.7s\tremaining: 26.1s\n",
      "2447:\tlearn: 1.6136757\ttotal: 29.7s\tremaining: 26.1s\n",
      "2448:\tlearn: 1.6129128\ttotal: 29.7s\tremaining: 26.1s\n",
      "2449:\tlearn: 1.6124799\ttotal: 29.8s\tremaining: 26.1s\n",
      "2450:\tlearn: 1.6119726\ttotal: 29.8s\tremaining: 26.1s\n",
      "2451:\tlearn: 1.6115965\ttotal: 29.8s\tremaining: 26.1s\n",
      "2452:\tlearn: 1.6114367\ttotal: 29.8s\tremaining: 26.1s\n",
      "2453:\tlearn: 1.6111140\ttotal: 29.8s\tremaining: 26s\n",
      "2454:\tlearn: 1.6106844\ttotal: 29.8s\tremaining: 26s\n",
      "2455:\tlearn: 1.6105420\ttotal: 29.8s\tremaining: 26s\n",
      "2456:\tlearn: 1.6103607\ttotal: 29.8s\tremaining: 26s\n",
      "2457:\tlearn: 1.6100706\ttotal: 29.9s\tremaining: 26s\n",
      "2458:\tlearn: 1.6097730\ttotal: 29.9s\tremaining: 26s\n",
      "2459:\tlearn: 1.6094959\ttotal: 29.9s\tremaining: 26s\n",
      "2460:\tlearn: 1.6091538\ttotal: 29.9s\tremaining: 26s\n",
      "2461:\tlearn: 1.6088888\ttotal: 29.9s\tremaining: 25.9s\n",
      "2462:\tlearn: 1.6082418\ttotal: 29.9s\tremaining: 25.9s\n",
      "2463:\tlearn: 1.6080342\ttotal: 29.9s\tremaining: 25.9s\n",
      "2464:\tlearn: 1.6076959\ttotal: 29.9s\tremaining: 25.9s\n",
      "2465:\tlearn: 1.6076418\ttotal: 29.9s\tremaining: 25.9s\n",
      "2466:\tlearn: 1.6074991\ttotal: 30s\tremaining: 25.9s\n",
      "2467:\tlearn: 1.6072563\ttotal: 30s\tremaining: 25.9s\n",
      "2468:\tlearn: 1.6071116\ttotal: 30s\tremaining: 25.9s\n",
      "2469:\tlearn: 1.6068148\ttotal: 30s\tremaining: 25.8s\n",
      "2470:\tlearn: 1.6066567\ttotal: 30s\tremaining: 25.8s\n",
      "2471:\tlearn: 1.6064627\ttotal: 30s\tremaining: 25.8s\n",
      "2472:\tlearn: 1.6060770\ttotal: 30s\tremaining: 25.8s\n",
      "2473:\tlearn: 1.6055009\ttotal: 30s\tremaining: 25.8s\n",
      "2474:\tlearn: 1.6050541\ttotal: 30.1s\tremaining: 25.8s\n",
      "2475:\tlearn: 1.6047118\ttotal: 30.1s\tremaining: 25.8s\n",
      "2476:\tlearn: 1.6040913\ttotal: 30.1s\tremaining: 25.8s\n",
      "2477:\tlearn: 1.6038044\ttotal: 30.1s\tremaining: 25.7s\n",
      "2478:\tlearn: 1.6037702\ttotal: 30.1s\tremaining: 25.7s\n",
      "2479:\tlearn: 1.6032799\ttotal: 30.1s\tremaining: 25.7s\n",
      "2480:\tlearn: 1.6030569\ttotal: 30.1s\tremaining: 25.7s\n",
      "2481:\tlearn: 1.6027803\ttotal: 30.1s\tremaining: 25.7s\n",
      "2482:\tlearn: 1.6026993\ttotal: 30.2s\tremaining: 25.7s\n",
      "2483:\tlearn: 1.6023828\ttotal: 30.2s\tremaining: 25.7s\n",
      "2484:\tlearn: 1.6020943\ttotal: 30.2s\tremaining: 25.7s\n",
      "2485:\tlearn: 1.6018493\ttotal: 30.2s\tremaining: 25.6s\n",
      "2486:\tlearn: 1.6016745\ttotal: 30.2s\tremaining: 25.6s\n",
      "2487:\tlearn: 1.6014618\ttotal: 30.2s\tremaining: 25.6s\n",
      "2488:\tlearn: 1.6013052\ttotal: 30.2s\tremaining: 25.6s\n",
      "2489:\tlearn: 1.6010019\ttotal: 30.2s\tremaining: 25.6s\n",
      "2490:\tlearn: 1.6006573\ttotal: 30.2s\tremaining: 25.6s\n",
      "2491:\tlearn: 1.6003668\ttotal: 30.3s\tremaining: 25.6s\n",
      "2492:\tlearn: 1.6000153\ttotal: 30.3s\tremaining: 25.6s\n",
      "2493:\tlearn: 1.5998838\ttotal: 30.3s\tremaining: 25.5s\n",
      "2494:\tlearn: 1.5998035\ttotal: 30.3s\tremaining: 25.5s\n",
      "2495:\tlearn: 1.5995721\ttotal: 30.3s\tremaining: 25.5s\n",
      "2496:\tlearn: 1.5993085\ttotal: 30.3s\tremaining: 25.5s\n",
      "2497:\tlearn: 1.5992784\ttotal: 30.3s\tremaining: 25.5s\n",
      "2498:\tlearn: 1.5991960\ttotal: 30.3s\tremaining: 25.5s\n",
      "2499:\tlearn: 1.5988530\ttotal: 30.4s\tremaining: 25.5s\n",
      "2500:\tlearn: 1.5985720\ttotal: 30.4s\tremaining: 25.5s\n",
      "2501:\tlearn: 1.5983205\ttotal: 30.4s\tremaining: 25.4s\n",
      "2502:\tlearn: 1.5979692\ttotal: 30.4s\tremaining: 25.4s\n",
      "2503:\tlearn: 1.5977351\ttotal: 30.4s\tremaining: 25.4s\n",
      "2504:\tlearn: 1.5976478\ttotal: 30.4s\tremaining: 25.4s\n",
      "2505:\tlearn: 1.5974966\ttotal: 30.4s\tremaining: 25.4s\n",
      "2506:\tlearn: 1.5971774\ttotal: 30.4s\tremaining: 25.4s\n",
      "2507:\tlearn: 1.5968580\ttotal: 30.4s\tremaining: 25.4s\n",
      "2508:\tlearn: 1.5963047\ttotal: 30.5s\tremaining: 25.4s\n",
      "2509:\tlearn: 1.5959432\ttotal: 30.5s\tremaining: 25.4s\n",
      "2510:\tlearn: 1.5955052\ttotal: 30.5s\tremaining: 25.3s\n",
      "2511:\tlearn: 1.5953251\ttotal: 30.5s\tremaining: 25.3s\n",
      "2512:\tlearn: 1.5951425\ttotal: 30.5s\tremaining: 25.3s\n",
      "2513:\tlearn: 1.5948385\ttotal: 30.5s\tremaining: 25.3s\n",
      "2514:\tlearn: 1.5946274\ttotal: 30.5s\tremaining: 25.3s\n",
      "2515:\tlearn: 1.5944028\ttotal: 30.6s\tremaining: 25.3s\n",
      "2516:\tlearn: 1.5940076\ttotal: 30.6s\tremaining: 25.3s\n",
      "2517:\tlearn: 1.5938509\ttotal: 30.6s\tremaining: 25.3s\n",
      "2518:\tlearn: 1.5935967\ttotal: 30.6s\tremaining: 25.3s\n",
      "2519:\tlearn: 1.5930345\ttotal: 30.6s\tremaining: 25.2s\n",
      "2520:\tlearn: 1.5927071\ttotal: 30.6s\tremaining: 25.2s\n",
      "2521:\tlearn: 1.5923967\ttotal: 30.6s\tremaining: 25.2s\n",
      "2522:\tlearn: 1.5919895\ttotal: 30.7s\tremaining: 25.2s\n",
      "2523:\tlearn: 1.5915924\ttotal: 30.7s\tremaining: 25.2s\n",
      "2524:\tlearn: 1.5911371\ttotal: 30.7s\tremaining: 25.2s\n",
      "2525:\tlearn: 1.5907905\ttotal: 30.7s\tremaining: 25.2s\n",
      "2526:\tlearn: 1.5905482\ttotal: 30.7s\tremaining: 25.2s\n",
      "2527:\tlearn: 1.5903242\ttotal: 30.7s\tremaining: 25.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2528:\tlearn: 1.5901619\ttotal: 30.7s\tremaining: 25.1s\n",
      "2529:\tlearn: 1.5900217\ttotal: 30.7s\tremaining: 25.1s\n",
      "2530:\tlearn: 1.5897858\ttotal: 30.8s\tremaining: 25.1s\n",
      "2531:\tlearn: 1.5895432\ttotal: 30.8s\tremaining: 25.1s\n",
      "2532:\tlearn: 1.5894284\ttotal: 30.8s\tremaining: 25.1s\n",
      "2533:\tlearn: 1.5891916\ttotal: 30.8s\tremaining: 25.1s\n",
      "2534:\tlearn: 1.5889596\ttotal: 30.8s\tremaining: 25.1s\n",
      "2535:\tlearn: 1.5886790\ttotal: 30.8s\tremaining: 25.1s\n",
      "2536:\tlearn: 1.5885216\ttotal: 30.8s\tremaining: 25s\n",
      "2537:\tlearn: 1.5884585\ttotal: 30.8s\tremaining: 25s\n",
      "2538:\tlearn: 1.5883402\ttotal: 30.8s\tremaining: 25s\n",
      "2539:\tlearn: 1.5881142\ttotal: 30.9s\tremaining: 25s\n",
      "2540:\tlearn: 1.5879413\ttotal: 30.9s\tremaining: 25s\n",
      "2541:\tlearn: 1.5874635\ttotal: 30.9s\tremaining: 25s\n",
      "2542:\tlearn: 1.5872849\ttotal: 30.9s\tremaining: 25s\n",
      "2543:\tlearn: 1.5870691\ttotal: 30.9s\tremaining: 25s\n",
      "2544:\tlearn: 1.5867202\ttotal: 30.9s\tremaining: 24.9s\n",
      "2545:\tlearn: 1.5864700\ttotal: 30.9s\tremaining: 24.9s\n",
      "2546:\tlearn: 1.5859593\ttotal: 30.9s\tremaining: 24.9s\n",
      "2547:\tlearn: 1.5859440\ttotal: 31s\tremaining: 24.9s\n",
      "2548:\tlearn: 1.5858449\ttotal: 31s\tremaining: 24.9s\n",
      "2549:\tlearn: 1.5857144\ttotal: 31s\tremaining: 24.9s\n",
      "2550:\tlearn: 1.5853817\ttotal: 31s\tremaining: 24.9s\n",
      "2551:\tlearn: 1.5849718\ttotal: 31s\tremaining: 24.9s\n",
      "2552:\tlearn: 1.5847287\ttotal: 31s\tremaining: 24.8s\n",
      "2553:\tlearn: 1.5841548\ttotal: 31s\tremaining: 24.8s\n",
      "2554:\tlearn: 1.5838832\ttotal: 31s\tremaining: 24.8s\n",
      "2555:\tlearn: 1.5834586\ttotal: 31.1s\tremaining: 24.8s\n",
      "2556:\tlearn: 1.5831046\ttotal: 31.1s\tremaining: 24.8s\n",
      "2557:\tlearn: 1.5827382\ttotal: 31.1s\tremaining: 24.8s\n",
      "2558:\tlearn: 1.5824597\ttotal: 31.1s\tremaining: 24.8s\n",
      "2559:\tlearn: 1.5822884\ttotal: 31.1s\tremaining: 24.8s\n",
      "2560:\tlearn: 1.5821347\ttotal: 31.1s\tremaining: 24.7s\n",
      "2561:\tlearn: 1.5819049\ttotal: 31.1s\tremaining: 24.7s\n",
      "2562:\tlearn: 1.5818302\ttotal: 31.1s\tremaining: 24.7s\n",
      "2563:\tlearn: 1.5813523\ttotal: 31.1s\tremaining: 24.7s\n",
      "2564:\tlearn: 1.5811067\ttotal: 31.2s\tremaining: 24.7s\n",
      "2565:\tlearn: 1.5807128\ttotal: 31.2s\tremaining: 24.7s\n",
      "2566:\tlearn: 1.5801648\ttotal: 31.2s\tremaining: 24.7s\n",
      "2567:\tlearn: 1.5798136\ttotal: 31.2s\tremaining: 24.7s\n",
      "2568:\tlearn: 1.5796068\ttotal: 31.2s\tremaining: 24.6s\n",
      "2569:\tlearn: 1.5792092\ttotal: 31.2s\tremaining: 24.6s\n",
      "2570:\tlearn: 1.5789090\ttotal: 31.2s\tremaining: 24.6s\n",
      "2571:\tlearn: 1.5786238\ttotal: 31.2s\tremaining: 24.6s\n",
      "2572:\tlearn: 1.5784552\ttotal: 31.3s\tremaining: 24.6s\n",
      "2573:\tlearn: 1.5783062\ttotal: 31.3s\tremaining: 24.6s\n",
      "2574:\tlearn: 1.5780537\ttotal: 31.3s\tremaining: 24.6s\n",
      "2575:\tlearn: 1.5775914\ttotal: 31.3s\tremaining: 24.6s\n",
      "2576:\tlearn: 1.5771718\ttotal: 31.3s\tremaining: 24.5s\n",
      "2577:\tlearn: 1.5767312\ttotal: 31.3s\tremaining: 24.5s\n",
      "2578:\tlearn: 1.5766455\ttotal: 31.3s\tremaining: 24.5s\n",
      "2579:\tlearn: 1.5763263\ttotal: 31.3s\tremaining: 24.5s\n",
      "2580:\tlearn: 1.5761333\ttotal: 31.3s\tremaining: 24.5s\n",
      "2581:\tlearn: 1.5760380\ttotal: 31.4s\tremaining: 24.5s\n",
      "2582:\tlearn: 1.5758020\ttotal: 31.4s\tremaining: 24.5s\n",
      "2583:\tlearn: 1.5756798\ttotal: 31.4s\tremaining: 24.5s\n",
      "2584:\tlearn: 1.5754278\ttotal: 31.4s\tremaining: 24.4s\n",
      "2585:\tlearn: 1.5751477\ttotal: 31.4s\tremaining: 24.4s\n",
      "2586:\tlearn: 1.5746399\ttotal: 31.4s\tremaining: 24.4s\n",
      "2587:\tlearn: 1.5745698\ttotal: 31.4s\tremaining: 24.4s\n",
      "2588:\tlearn: 1.5742203\ttotal: 31.4s\tremaining: 24.4s\n",
      "2589:\tlearn: 1.5739979\ttotal: 31.5s\tremaining: 24.4s\n",
      "2590:\tlearn: 1.5734390\ttotal: 31.5s\tremaining: 24.4s\n",
      "2591:\tlearn: 1.5732030\ttotal: 31.5s\tremaining: 24.4s\n",
      "2592:\tlearn: 1.5728855\ttotal: 31.5s\tremaining: 24.4s\n",
      "2593:\tlearn: 1.5725165\ttotal: 31.5s\tremaining: 24.3s\n",
      "2594:\tlearn: 1.5722930\ttotal: 31.5s\tremaining: 24.3s\n",
      "2595:\tlearn: 1.5719361\ttotal: 31.5s\tremaining: 24.3s\n",
      "2596:\tlearn: 1.5717093\ttotal: 31.5s\tremaining: 24.3s\n",
      "2597:\tlearn: 1.5713645\ttotal: 31.6s\tremaining: 24.3s\n",
      "2598:\tlearn: 1.5711658\ttotal: 31.6s\tremaining: 24.3s\n",
      "2599:\tlearn: 1.5708623\ttotal: 31.6s\tremaining: 24.3s\n",
      "2600:\tlearn: 1.5706015\ttotal: 31.6s\tremaining: 24.3s\n",
      "2601:\tlearn: 1.5701102\ttotal: 31.6s\tremaining: 24.2s\n",
      "2602:\tlearn: 1.5698554\ttotal: 31.6s\tremaining: 24.2s\n",
      "2603:\tlearn: 1.5696085\ttotal: 31.6s\tremaining: 24.2s\n",
      "2604:\tlearn: 1.5691343\ttotal: 31.6s\tremaining: 24.2s\n",
      "2605:\tlearn: 1.5686467\ttotal: 31.7s\tremaining: 24.2s\n",
      "2606:\tlearn: 1.5681070\ttotal: 31.7s\tremaining: 24.2s\n",
      "2607:\tlearn: 1.5680160\ttotal: 31.7s\tremaining: 24.2s\n",
      "2608:\tlearn: 1.5676762\ttotal: 31.7s\tremaining: 24.2s\n",
      "2609:\tlearn: 1.5675257\ttotal: 31.7s\tremaining: 24.1s\n",
      "2610:\tlearn: 1.5673070\ttotal: 31.7s\tremaining: 24.1s\n",
      "2611:\tlearn: 1.5671462\ttotal: 31.7s\tremaining: 24.1s\n",
      "2612:\tlearn: 1.5668941\ttotal: 31.7s\tremaining: 24.1s\n",
      "2613:\tlearn: 1.5668372\ttotal: 31.7s\tremaining: 24.1s\n",
      "2614:\tlearn: 1.5666730\ttotal: 31.8s\tremaining: 24.1s\n",
      "2615:\tlearn: 1.5664833\ttotal: 31.8s\tremaining: 24.1s\n",
      "2616:\tlearn: 1.5660424\ttotal: 31.8s\tremaining: 24.1s\n",
      "2617:\tlearn: 1.5658257\ttotal: 31.8s\tremaining: 24s\n",
      "2618:\tlearn: 1.5657346\ttotal: 31.8s\tremaining: 24s\n",
      "2619:\tlearn: 1.5651167\ttotal: 31.8s\tremaining: 24s\n",
      "2620:\tlearn: 1.5647298\ttotal: 31.8s\tremaining: 24s\n",
      "2621:\tlearn: 1.5644383\ttotal: 31.8s\tremaining: 24s\n",
      "2622:\tlearn: 1.5641784\ttotal: 31.9s\tremaining: 24s\n",
      "2623:\tlearn: 1.5637597\ttotal: 31.9s\tremaining: 24s\n",
      "2624:\tlearn: 1.5630526\ttotal: 31.9s\tremaining: 24s\n",
      "2625:\tlearn: 1.5624072\ttotal: 31.9s\tremaining: 24s\n",
      "2626:\tlearn: 1.5621129\ttotal: 31.9s\tremaining: 23.9s\n",
      "2627:\tlearn: 1.5618531\ttotal: 31.9s\tremaining: 23.9s\n",
      "2628:\tlearn: 1.5618375\ttotal: 31.9s\tremaining: 23.9s\n",
      "2629:\tlearn: 1.5617750\ttotal: 31.9s\tremaining: 23.9s\n",
      "2630:\tlearn: 1.5615577\ttotal: 32s\tremaining: 23.9s\n",
      "2631:\tlearn: 1.5611501\ttotal: 32s\tremaining: 23.9s\n",
      "2632:\tlearn: 1.5610080\ttotal: 32s\tremaining: 23.9s\n",
      "2633:\tlearn: 1.5607209\ttotal: 32s\tremaining: 23.9s\n",
      "2634:\tlearn: 1.5601618\ttotal: 32s\tremaining: 23.8s\n",
      "2635:\tlearn: 1.5598759\ttotal: 32s\tremaining: 23.8s\n",
      "2636:\tlearn: 1.5594314\ttotal: 32s\tremaining: 23.8s\n",
      "2637:\tlearn: 1.5593572\ttotal: 32s\tremaining: 23.8s\n",
      "2638:\tlearn: 1.5591058\ttotal: 32.1s\tremaining: 23.8s\n",
      "2639:\tlearn: 1.5589334\ttotal: 32.1s\tremaining: 23.8s\n",
      "2640:\tlearn: 1.5585846\ttotal: 32.1s\tremaining: 23.8s\n",
      "2641:\tlearn: 1.5583186\ttotal: 32.1s\tremaining: 23.8s\n",
      "2642:\tlearn: 1.5579989\ttotal: 32.1s\tremaining: 23.7s\n",
      "2643:\tlearn: 1.5577440\ttotal: 32.1s\tremaining: 23.7s\n",
      "2644:\tlearn: 1.5573848\ttotal: 32.1s\tremaining: 23.7s\n",
      "2645:\tlearn: 1.5571539\ttotal: 32.1s\tremaining: 23.7s\n",
      "2646:\tlearn: 1.5570060\ttotal: 32.1s\tremaining: 23.7s\n",
      "2647:\tlearn: 1.5566838\ttotal: 32.2s\tremaining: 23.7s\n",
      "2648:\tlearn: 1.5563562\ttotal: 32.2s\tremaining: 23.7s\n",
      "2649:\tlearn: 1.5561017\ttotal: 32.2s\tremaining: 23.7s\n",
      "2650:\tlearn: 1.5559408\ttotal: 32.2s\tremaining: 23.6s\n",
      "2651:\tlearn: 1.5557091\ttotal: 32.2s\tremaining: 23.6s\n",
      "2652:\tlearn: 1.5554433\ttotal: 32.2s\tremaining: 23.6s\n",
      "2653:\tlearn: 1.5550655\ttotal: 32.2s\tremaining: 23.6s\n",
      "2654:\tlearn: 1.5547741\ttotal: 32.3s\tremaining: 23.6s\n",
      "2655:\tlearn: 1.5544007\ttotal: 32.3s\tremaining: 23.6s\n",
      "2656:\tlearn: 1.5543250\ttotal: 32.3s\tremaining: 23.6s\n",
      "2657:\tlearn: 1.5540224\ttotal: 32.3s\tremaining: 23.6s\n",
      "2658:\tlearn: 1.5535873\ttotal: 32.3s\tremaining: 23.6s\n",
      "2659:\tlearn: 1.5533986\ttotal: 32.3s\tremaining: 23.5s\n",
      "2660:\tlearn: 1.5530559\ttotal: 32.3s\tremaining: 23.5s\n",
      "2661:\tlearn: 1.5527458\ttotal: 32.3s\tremaining: 23.5s\n",
      "2662:\tlearn: 1.5523741\ttotal: 32.3s\tremaining: 23.5s\n",
      "2663:\tlearn: 1.5522405\ttotal: 32.4s\tremaining: 23.5s\n",
      "2664:\tlearn: 1.5520527\ttotal: 32.4s\tremaining: 23.5s\n",
      "2665:\tlearn: 1.5518792\ttotal: 32.4s\tremaining: 23.5s\n",
      "2666:\tlearn: 1.5516107\ttotal: 32.4s\tremaining: 23.5s\n",
      "2667:\tlearn: 1.5514207\ttotal: 32.4s\tremaining: 23.4s\n",
      "2668:\tlearn: 1.5510520\ttotal: 32.4s\tremaining: 23.4s\n",
      "2669:\tlearn: 1.5507662\ttotal: 32.4s\tremaining: 23.4s\n",
      "2670:\tlearn: 1.5505158\ttotal: 32.4s\tremaining: 23.4s\n",
      "2671:\tlearn: 1.5503639\ttotal: 32.5s\tremaining: 23.4s\n",
      "2672:\tlearn: 1.5500905\ttotal: 32.5s\tremaining: 23.4s\n",
      "2673:\tlearn: 1.5497639\ttotal: 32.5s\tremaining: 23.4s\n",
      "2674:\tlearn: 1.5494929\ttotal: 32.5s\tremaining: 23.4s\n",
      "2675:\tlearn: 1.5492739\ttotal: 32.5s\tremaining: 23.3s\n",
      "2676:\tlearn: 1.5491433\ttotal: 32.5s\tremaining: 23.3s\n",
      "2677:\tlearn: 1.5488104\ttotal: 32.5s\tremaining: 23.3s\n",
      "2678:\tlearn: 1.5485431\ttotal: 32.5s\tremaining: 23.3s\n",
      "2679:\tlearn: 1.5482536\ttotal: 32.5s\tremaining: 23.3s\n",
      "2680:\tlearn: 1.5479532\ttotal: 32.6s\tremaining: 23.3s\n",
      "2681:\tlearn: 1.5476838\ttotal: 32.6s\tremaining: 23.3s\n",
      "2682:\tlearn: 1.5473452\ttotal: 32.6s\tremaining: 23.3s\n",
      "2683:\tlearn: 1.5470024\ttotal: 32.6s\tremaining: 23.2s\n",
      "2684:\tlearn: 1.5467656\ttotal: 32.6s\tremaining: 23.2s\n",
      "2685:\tlearn: 1.5464430\ttotal: 32.6s\tremaining: 23.2s\n",
      "2686:\tlearn: 1.5460993\ttotal: 32.6s\tremaining: 23.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2687:\tlearn: 1.5458871\ttotal: 32.6s\tremaining: 23.2s\n",
      "2688:\tlearn: 1.5457845\ttotal: 32.7s\tremaining: 23.2s\n",
      "2689:\tlearn: 1.5455608\ttotal: 32.7s\tremaining: 23.2s\n",
      "2690:\tlearn: 1.5449892\ttotal: 32.7s\tremaining: 23.2s\n",
      "2691:\tlearn: 1.5446726\ttotal: 32.7s\tremaining: 23.1s\n",
      "2692:\tlearn: 1.5445937\ttotal: 32.7s\tremaining: 23.1s\n",
      "2693:\tlearn: 1.5443577\ttotal: 32.7s\tremaining: 23.1s\n",
      "2694:\tlearn: 1.5441969\ttotal: 32.7s\tremaining: 23.1s\n",
      "2695:\tlearn: 1.5436761\ttotal: 32.7s\tremaining: 23.1s\n",
      "2696:\tlearn: 1.5434397\ttotal: 32.8s\tremaining: 23.1s\n",
      "2697:\tlearn: 1.5431188\ttotal: 32.8s\tremaining: 23.1s\n",
      "2698:\tlearn: 1.5427094\ttotal: 32.8s\tremaining: 23.1s\n",
      "2699:\tlearn: 1.5424944\ttotal: 32.8s\tremaining: 23.1s\n",
      "2700:\tlearn: 1.5419380\ttotal: 32.8s\tremaining: 23s\n",
      "2701:\tlearn: 1.5417170\ttotal: 32.8s\tremaining: 23s\n",
      "2702:\tlearn: 1.5413518\ttotal: 32.8s\tremaining: 23s\n",
      "2703:\tlearn: 1.5410283\ttotal: 32.8s\tremaining: 23s\n",
      "2704:\tlearn: 1.5407148\ttotal: 32.9s\tremaining: 23s\n",
      "2705:\tlearn: 1.5404939\ttotal: 32.9s\tremaining: 23s\n",
      "2706:\tlearn: 1.5401438\ttotal: 32.9s\tremaining: 23s\n",
      "2707:\tlearn: 1.5397587\ttotal: 32.9s\tremaining: 23s\n",
      "2708:\tlearn: 1.5395825\ttotal: 32.9s\tremaining: 22.9s\n",
      "2709:\tlearn: 1.5394720\ttotal: 32.9s\tremaining: 22.9s\n",
      "2710:\tlearn: 1.5392929\ttotal: 32.9s\tremaining: 22.9s\n",
      "2711:\tlearn: 1.5389221\ttotal: 32.9s\tremaining: 22.9s\n",
      "2712:\tlearn: 1.5384940\ttotal: 32.9s\tremaining: 22.9s\n",
      "2713:\tlearn: 1.5381007\ttotal: 33s\tremaining: 22.9s\n",
      "2714:\tlearn: 1.5378620\ttotal: 33s\tremaining: 22.9s\n",
      "2715:\tlearn: 1.5377188\ttotal: 33s\tremaining: 22.9s\n",
      "2716:\tlearn: 1.5371608\ttotal: 33s\tremaining: 22.8s\n",
      "2717:\tlearn: 1.5369069\ttotal: 33s\tremaining: 22.8s\n",
      "2718:\tlearn: 1.5366323\ttotal: 33s\tremaining: 22.8s\n",
      "2719:\tlearn: 1.5365635\ttotal: 33s\tremaining: 22.8s\n",
      "2720:\tlearn: 1.5362063\ttotal: 33s\tremaining: 22.8s\n",
      "2721:\tlearn: 1.5360754\ttotal: 33.1s\tremaining: 22.8s\n",
      "2722:\tlearn: 1.5358631\ttotal: 33.1s\tremaining: 22.8s\n",
      "2723:\tlearn: 1.5355929\ttotal: 33.1s\tremaining: 22.8s\n",
      "2724:\tlearn: 1.5352852\ttotal: 33.1s\tremaining: 22.7s\n",
      "2725:\tlearn: 1.5350858\ttotal: 33.1s\tremaining: 22.7s\n",
      "2726:\tlearn: 1.5345687\ttotal: 33.1s\tremaining: 22.7s\n",
      "2727:\tlearn: 1.5343862\ttotal: 33.1s\tremaining: 22.7s\n",
      "2728:\tlearn: 1.5339884\ttotal: 33.1s\tremaining: 22.7s\n",
      "2729:\tlearn: 1.5336585\ttotal: 33.2s\tremaining: 22.7s\n",
      "2730:\tlearn: 1.5334010\ttotal: 33.2s\tremaining: 22.7s\n",
      "2731:\tlearn: 1.5331418\ttotal: 33.2s\tremaining: 22.7s\n",
      "2732:\tlearn: 1.5327530\ttotal: 33.2s\tremaining: 22.7s\n",
      "2733:\tlearn: 1.5325456\ttotal: 33.2s\tremaining: 22.6s\n",
      "2734:\tlearn: 1.5323831\ttotal: 33.2s\tremaining: 22.6s\n",
      "2735:\tlearn: 1.5322917\ttotal: 33.2s\tremaining: 22.6s\n",
      "2736:\tlearn: 1.5320233\ttotal: 33.2s\tremaining: 22.6s\n",
      "2737:\tlearn: 1.5315469\ttotal: 33.3s\tremaining: 22.6s\n",
      "2738:\tlearn: 1.5311794\ttotal: 33.3s\tremaining: 22.6s\n",
      "2739:\tlearn: 1.5310173\ttotal: 33.3s\tremaining: 22.6s\n",
      "2740:\tlearn: 1.5305574\ttotal: 33.3s\tremaining: 22.6s\n",
      "2741:\tlearn: 1.5302277\ttotal: 33.3s\tremaining: 22.5s\n",
      "2742:\tlearn: 1.5301167\ttotal: 33.3s\tremaining: 22.5s\n",
      "2743:\tlearn: 1.5299628\ttotal: 33.3s\tremaining: 22.5s\n",
      "2744:\tlearn: 1.5293918\ttotal: 33.3s\tremaining: 22.5s\n",
      "2745:\tlearn: 1.5289783\ttotal: 33.4s\tremaining: 22.5s\n",
      "2746:\tlearn: 1.5288988\ttotal: 33.4s\tremaining: 22.5s\n",
      "2747:\tlearn: 1.5286993\ttotal: 33.4s\tremaining: 22.5s\n",
      "2748:\tlearn: 1.5284365\ttotal: 33.4s\tremaining: 22.5s\n",
      "2749:\tlearn: 1.5282467\ttotal: 33.4s\tremaining: 22.4s\n",
      "2750:\tlearn: 1.5278206\ttotal: 33.4s\tremaining: 22.4s\n",
      "2751:\tlearn: 1.5276636\ttotal: 33.4s\tremaining: 22.4s\n",
      "2752:\tlearn: 1.5274653\ttotal: 33.4s\tremaining: 22.4s\n",
      "2753:\tlearn: 1.5272465\ttotal: 33.4s\tremaining: 22.4s\n",
      "2754:\tlearn: 1.5269555\ttotal: 33.5s\tremaining: 22.4s\n",
      "2755:\tlearn: 1.5265424\ttotal: 33.5s\tremaining: 22.4s\n",
      "2756:\tlearn: 1.5263731\ttotal: 33.5s\tremaining: 22.4s\n",
      "2757:\tlearn: 1.5262814\ttotal: 33.5s\tremaining: 22.3s\n",
      "2758:\tlearn: 1.5259861\ttotal: 33.5s\tremaining: 22.3s\n",
      "2759:\tlearn: 1.5257302\ttotal: 33.5s\tremaining: 22.3s\n",
      "2760:\tlearn: 1.5254417\ttotal: 33.5s\tremaining: 22.3s\n",
      "2761:\tlearn: 1.5252876\ttotal: 33.5s\tremaining: 22.3s\n",
      "2762:\tlearn: 1.5249387\ttotal: 33.6s\tremaining: 22.3s\n",
      "2763:\tlearn: 1.5245237\ttotal: 33.6s\tremaining: 22.3s\n",
      "2764:\tlearn: 1.5242702\ttotal: 33.6s\tremaining: 22.3s\n",
      "2765:\tlearn: 1.5239192\ttotal: 33.6s\tremaining: 22.2s\n",
      "2766:\tlearn: 1.5237306\ttotal: 33.6s\tremaining: 22.2s\n",
      "2767:\tlearn: 1.5235337\ttotal: 33.6s\tremaining: 22.2s\n",
      "2768:\tlearn: 1.5233198\ttotal: 33.6s\tremaining: 22.2s\n",
      "2769:\tlearn: 1.5230545\ttotal: 33.6s\tremaining: 22.2s\n",
      "2770:\tlearn: 1.5226894\ttotal: 33.7s\tremaining: 22.2s\n",
      "2771:\tlearn: 1.5223398\ttotal: 33.7s\tremaining: 22.2s\n",
      "2772:\tlearn: 1.5220800\ttotal: 33.7s\tremaining: 22.2s\n",
      "2773:\tlearn: 1.5219460\ttotal: 33.7s\tremaining: 22.2s\n",
      "2774:\tlearn: 1.5216739\ttotal: 33.7s\tremaining: 22.1s\n",
      "2775:\tlearn: 1.5215524\ttotal: 33.7s\tremaining: 22.1s\n",
      "2776:\tlearn: 1.5213946\ttotal: 33.7s\tremaining: 22.1s\n",
      "2777:\tlearn: 1.5209143\ttotal: 33.7s\tremaining: 22.1s\n",
      "2778:\tlearn: 1.5206736\ttotal: 33.8s\tremaining: 22.1s\n",
      "2779:\tlearn: 1.5205198\ttotal: 33.8s\tremaining: 22.1s\n",
      "2780:\tlearn: 1.5203104\ttotal: 33.8s\tremaining: 22.1s\n",
      "2781:\tlearn: 1.5198770\ttotal: 33.8s\tremaining: 22.1s\n",
      "2782:\tlearn: 1.5195588\ttotal: 33.8s\tremaining: 22s\n",
      "2783:\tlearn: 1.5193448\ttotal: 33.8s\tremaining: 22s\n",
      "2784:\tlearn: 1.5190905\ttotal: 33.8s\tremaining: 22s\n",
      "2785:\tlearn: 1.5186733\ttotal: 33.8s\tremaining: 22s\n",
      "2786:\tlearn: 1.5181641\ttotal: 33.9s\tremaining: 22s\n",
      "2787:\tlearn: 1.5178417\ttotal: 33.9s\tremaining: 22s\n",
      "2788:\tlearn: 1.5175326\ttotal: 33.9s\tremaining: 22s\n",
      "2789:\tlearn: 1.5172289\ttotal: 33.9s\tremaining: 22s\n",
      "2790:\tlearn: 1.5170524\ttotal: 33.9s\tremaining: 21.9s\n",
      "2791:\tlearn: 1.5167841\ttotal: 33.9s\tremaining: 21.9s\n",
      "2792:\tlearn: 1.5163599\ttotal: 33.9s\tremaining: 21.9s\n",
      "2793:\tlearn: 1.5160518\ttotal: 33.9s\tremaining: 21.9s\n",
      "2794:\tlearn: 1.5158451\ttotal: 34s\tremaining: 21.9s\n",
      "2795:\tlearn: 1.5154301\ttotal: 34s\tremaining: 21.9s\n",
      "2796:\tlearn: 1.5149158\ttotal: 34s\tremaining: 21.9s\n",
      "2797:\tlearn: 1.5147135\ttotal: 34s\tremaining: 21.9s\n",
      "2798:\tlearn: 1.5142453\ttotal: 34s\tremaining: 21.9s\n",
      "2799:\tlearn: 1.5139471\ttotal: 34s\tremaining: 21.8s\n",
      "2800:\tlearn: 1.5139121\ttotal: 34s\tremaining: 21.8s\n",
      "2801:\tlearn: 1.5135841\ttotal: 34s\tremaining: 21.8s\n",
      "2802:\tlearn: 1.5132870\ttotal: 34s\tremaining: 21.8s\n",
      "2803:\tlearn: 1.5131026\ttotal: 34.1s\tremaining: 21.8s\n",
      "2804:\tlearn: 1.5130063\ttotal: 34.1s\tremaining: 21.8s\n",
      "2805:\tlearn: 1.5128434\ttotal: 34.1s\tremaining: 21.8s\n",
      "2806:\tlearn: 1.5123500\ttotal: 34.1s\tremaining: 21.8s\n",
      "2807:\tlearn: 1.5119883\ttotal: 34.1s\tremaining: 21.7s\n",
      "2808:\tlearn: 1.5118119\ttotal: 34.1s\tremaining: 21.7s\n",
      "2809:\tlearn: 1.5115131\ttotal: 34.1s\tremaining: 21.7s\n",
      "2810:\tlearn: 1.5113776\ttotal: 34.1s\tremaining: 21.7s\n",
      "2811:\tlearn: 1.5112289\ttotal: 34.2s\tremaining: 21.7s\n",
      "2812:\tlearn: 1.5108554\ttotal: 34.2s\tremaining: 21.7s\n",
      "2813:\tlearn: 1.5106714\ttotal: 34.2s\tremaining: 21.7s\n",
      "2814:\tlearn: 1.5103407\ttotal: 34.2s\tremaining: 21.7s\n",
      "2815:\tlearn: 1.5101497\ttotal: 34.2s\tremaining: 21.6s\n",
      "2816:\tlearn: 1.5100746\ttotal: 34.2s\tremaining: 21.6s\n",
      "2817:\tlearn: 1.5098186\ttotal: 34.2s\tremaining: 21.6s\n",
      "2818:\tlearn: 1.5097608\ttotal: 34.2s\tremaining: 21.6s\n",
      "2819:\tlearn: 1.5094638\ttotal: 34.3s\tremaining: 21.6s\n",
      "2820:\tlearn: 1.5092281\ttotal: 34.3s\tremaining: 21.6s\n",
      "2821:\tlearn: 1.5091168\ttotal: 34.3s\tremaining: 21.6s\n",
      "2822:\tlearn: 1.5089138\ttotal: 34.3s\tremaining: 21.6s\n",
      "2823:\tlearn: 1.5086834\ttotal: 34.3s\tremaining: 21.5s\n",
      "2824:\tlearn: 1.5083276\ttotal: 34.3s\tremaining: 21.5s\n",
      "2825:\tlearn: 1.5079671\ttotal: 34.3s\tremaining: 21.5s\n",
      "2826:\tlearn: 1.5077222\ttotal: 34.3s\tremaining: 21.5s\n",
      "2827:\tlearn: 1.5074712\ttotal: 34.3s\tremaining: 21.5s\n",
      "2828:\tlearn: 1.5072737\ttotal: 34.4s\tremaining: 21.5s\n",
      "2829:\tlearn: 1.5067666\ttotal: 34.4s\tremaining: 21.5s\n",
      "2830:\tlearn: 1.5063664\ttotal: 34.4s\tremaining: 21.5s\n",
      "2831:\tlearn: 1.5061568\ttotal: 34.4s\tremaining: 21.5s\n",
      "2832:\tlearn: 1.5058187\ttotal: 34.4s\tremaining: 21.4s\n",
      "2833:\tlearn: 1.5055438\ttotal: 34.4s\tremaining: 21.4s\n",
      "2834:\tlearn: 1.5053605\ttotal: 34.4s\tremaining: 21.4s\n",
      "2835:\tlearn: 1.5050969\ttotal: 34.4s\tremaining: 21.4s\n",
      "2836:\tlearn: 1.5048956\ttotal: 34.5s\tremaining: 21.4s\n",
      "2837:\tlearn: 1.5046489\ttotal: 34.5s\tremaining: 21.4s\n",
      "2838:\tlearn: 1.5042242\ttotal: 34.5s\tremaining: 21.4s\n",
      "2839:\tlearn: 1.5039928\ttotal: 34.5s\tremaining: 21.4s\n",
      "2840:\tlearn: 1.5036956\ttotal: 34.5s\tremaining: 21.3s\n",
      "2841:\tlearn: 1.5033821\ttotal: 34.5s\tremaining: 21.3s\n",
      "2842:\tlearn: 1.5031512\ttotal: 34.5s\tremaining: 21.3s\n",
      "2843:\tlearn: 1.5028535\ttotal: 34.5s\tremaining: 21.3s\n",
      "2844:\tlearn: 1.5027119\ttotal: 34.6s\tremaining: 21.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2845:\tlearn: 1.5024870\ttotal: 34.6s\tremaining: 21.3s\n",
      "2846:\tlearn: 1.5022201\ttotal: 34.6s\tremaining: 21.3s\n",
      "2847:\tlearn: 1.5020700\ttotal: 34.6s\tremaining: 21.3s\n",
      "2848:\tlearn: 1.5019565\ttotal: 34.6s\tremaining: 21.2s\n",
      "2849:\tlearn: 1.5017453\ttotal: 34.6s\tremaining: 21.2s\n",
      "2850:\tlearn: 1.5015835\ttotal: 34.6s\tremaining: 21.2s\n",
      "2851:\tlearn: 1.5012309\ttotal: 34.6s\tremaining: 21.2s\n",
      "2852:\tlearn: 1.5009783\ttotal: 34.7s\tremaining: 21.2s\n",
      "2853:\tlearn: 1.5007199\ttotal: 34.7s\tremaining: 21.2s\n",
      "2854:\tlearn: 1.5003747\ttotal: 34.7s\tremaining: 21.2s\n",
      "2855:\tlearn: 1.5001531\ttotal: 34.7s\tremaining: 21.2s\n",
      "2856:\tlearn: 1.4997468\ttotal: 34.7s\tremaining: 21.1s\n",
      "2857:\tlearn: 1.4994088\ttotal: 34.7s\tremaining: 21.1s\n",
      "2858:\tlearn: 1.4990360\ttotal: 34.7s\tremaining: 21.1s\n",
      "2859:\tlearn: 1.4988183\ttotal: 34.7s\tremaining: 21.1s\n",
      "2860:\tlearn: 1.4985490\ttotal: 34.8s\tremaining: 21.1s\n",
      "2861:\tlearn: 1.4983153\ttotal: 34.8s\tremaining: 21.1s\n",
      "2862:\tlearn: 1.4979911\ttotal: 34.8s\tremaining: 21.1s\n",
      "2863:\tlearn: 1.4975716\ttotal: 34.8s\tremaining: 21.1s\n",
      "2864:\tlearn: 1.4972611\ttotal: 34.8s\tremaining: 21.1s\n",
      "2865:\tlearn: 1.4969606\ttotal: 34.8s\tremaining: 21s\n",
      "2866:\tlearn: 1.4964358\ttotal: 34.8s\tremaining: 21s\n",
      "2867:\tlearn: 1.4961176\ttotal: 34.8s\tremaining: 21s\n",
      "2868:\tlearn: 1.4958013\ttotal: 34.9s\tremaining: 21s\n",
      "2869:\tlearn: 1.4956018\ttotal: 34.9s\tremaining: 21s\n",
      "2870:\tlearn: 1.4953510\ttotal: 34.9s\tremaining: 21s\n",
      "2871:\tlearn: 1.4951488\ttotal: 34.9s\tremaining: 21s\n",
      "2872:\tlearn: 1.4949869\ttotal: 34.9s\tremaining: 21s\n",
      "2873:\tlearn: 1.4944861\ttotal: 34.9s\tremaining: 20.9s\n",
      "2874:\tlearn: 1.4941850\ttotal: 34.9s\tremaining: 20.9s\n",
      "2875:\tlearn: 1.4940721\ttotal: 34.9s\tremaining: 20.9s\n",
      "2876:\tlearn: 1.4938760\ttotal: 35s\tremaining: 20.9s\n",
      "2877:\tlearn: 1.4937799\ttotal: 35s\tremaining: 20.9s\n",
      "2878:\tlearn: 1.4935626\ttotal: 35s\tremaining: 20.9s\n",
      "2879:\tlearn: 1.4934015\ttotal: 35s\tremaining: 20.9s\n",
      "2880:\tlearn: 1.4931183\ttotal: 35s\tremaining: 20.9s\n",
      "2881:\tlearn: 1.4929151\ttotal: 35s\tremaining: 20.8s\n",
      "2882:\tlearn: 1.4926406\ttotal: 35s\tremaining: 20.8s\n",
      "2883:\tlearn: 1.4923168\ttotal: 35s\tremaining: 20.8s\n",
      "2884:\tlearn: 1.4920656\ttotal: 35s\tremaining: 20.8s\n",
      "2885:\tlearn: 1.4916923\ttotal: 35.1s\tremaining: 20.8s\n",
      "2886:\tlearn: 1.4915717\ttotal: 35.1s\tremaining: 20.8s\n",
      "2887:\tlearn: 1.4912580\ttotal: 35.1s\tremaining: 20.8s\n",
      "2888:\tlearn: 1.4909514\ttotal: 35.1s\tremaining: 20.8s\n",
      "2889:\tlearn: 1.4906960\ttotal: 35.1s\tremaining: 20.7s\n",
      "2890:\tlearn: 1.4904501\ttotal: 35.1s\tremaining: 20.7s\n",
      "2891:\tlearn: 1.4900129\ttotal: 35.1s\tremaining: 20.7s\n",
      "2892:\tlearn: 1.4898333\ttotal: 35.1s\tremaining: 20.7s\n",
      "2893:\tlearn: 1.4894832\ttotal: 35.2s\tremaining: 20.7s\n",
      "2894:\tlearn: 1.4890893\ttotal: 35.2s\tremaining: 20.7s\n",
      "2895:\tlearn: 1.4888928\ttotal: 35.2s\tremaining: 20.7s\n",
      "2896:\tlearn: 1.4886655\ttotal: 35.2s\tremaining: 20.7s\n",
      "2897:\tlearn: 1.4882669\ttotal: 35.2s\tremaining: 20.7s\n",
      "2898:\tlearn: 1.4879219\ttotal: 35.2s\tremaining: 20.6s\n",
      "2899:\tlearn: 1.4877170\ttotal: 35.2s\tremaining: 20.6s\n",
      "2900:\tlearn: 1.4872477\ttotal: 35.2s\tremaining: 20.6s\n",
      "2901:\tlearn: 1.4871172\ttotal: 35.3s\tremaining: 20.6s\n",
      "2902:\tlearn: 1.4870432\ttotal: 35.3s\tremaining: 20.6s\n",
      "2903:\tlearn: 1.4868358\ttotal: 35.3s\tremaining: 20.6s\n",
      "2904:\tlearn: 1.4864851\ttotal: 35.3s\tremaining: 20.6s\n",
      "2905:\tlearn: 1.4860612\ttotal: 35.3s\tremaining: 20.6s\n",
      "2906:\tlearn: 1.4854039\ttotal: 35.3s\tremaining: 20.5s\n",
      "2907:\tlearn: 1.4852170\ttotal: 35.3s\tremaining: 20.5s\n",
      "2908:\tlearn: 1.4848465\ttotal: 35.3s\tremaining: 20.5s\n",
      "2909:\tlearn: 1.4844943\ttotal: 35.4s\tremaining: 20.5s\n",
      "2910:\tlearn: 1.4841324\ttotal: 35.4s\tremaining: 20.5s\n",
      "2911:\tlearn: 1.4840901\ttotal: 35.4s\tremaining: 20.5s\n",
      "2912:\tlearn: 1.4838067\ttotal: 35.4s\tremaining: 20.5s\n",
      "2913:\tlearn: 1.4836331\ttotal: 35.4s\tremaining: 20.5s\n",
      "2914:\tlearn: 1.4831964\ttotal: 35.4s\tremaining: 20.4s\n",
      "2915:\tlearn: 1.4830890\ttotal: 35.4s\tremaining: 20.4s\n",
      "2916:\tlearn: 1.4826558\ttotal: 35.4s\tremaining: 20.4s\n",
      "2917:\tlearn: 1.4822997\ttotal: 35.4s\tremaining: 20.4s\n",
      "2918:\tlearn: 1.4821863\ttotal: 35.5s\tremaining: 20.4s\n",
      "2919:\tlearn: 1.4819219\ttotal: 35.5s\tremaining: 20.4s\n",
      "2920:\tlearn: 1.4817713\ttotal: 35.5s\tremaining: 20.4s\n",
      "2921:\tlearn: 1.4815175\ttotal: 35.5s\tremaining: 20.4s\n",
      "2922:\tlearn: 1.4812250\ttotal: 35.5s\tremaining: 20.3s\n",
      "2923:\tlearn: 1.4808475\ttotal: 35.5s\tremaining: 20.3s\n",
      "2924:\tlearn: 1.4806450\ttotal: 35.5s\tremaining: 20.3s\n",
      "2925:\tlearn: 1.4803770\ttotal: 35.5s\tremaining: 20.3s\n",
      "2926:\tlearn: 1.4802627\ttotal: 35.6s\tremaining: 20.3s\n",
      "2927:\tlearn: 1.4799539\ttotal: 35.6s\tremaining: 20.3s\n",
      "2928:\tlearn: 1.4797675\ttotal: 35.6s\tremaining: 20.3s\n",
      "2929:\tlearn: 1.4795710\ttotal: 35.6s\tremaining: 20.3s\n",
      "2930:\tlearn: 1.4792987\ttotal: 35.6s\tremaining: 20.2s\n",
      "2931:\tlearn: 1.4790032\ttotal: 35.6s\tremaining: 20.2s\n",
      "2932:\tlearn: 1.4785426\ttotal: 35.6s\tremaining: 20.2s\n",
      "2933:\tlearn: 1.4784484\ttotal: 35.6s\tremaining: 20.2s\n",
      "2934:\tlearn: 1.4782352\ttotal: 35.6s\tremaining: 20.2s\n",
      "2935:\tlearn: 1.4779825\ttotal: 35.7s\tremaining: 20.2s\n",
      "2936:\tlearn: 1.4778809\ttotal: 35.7s\tremaining: 20.2s\n",
      "2937:\tlearn: 1.4778095\ttotal: 35.7s\tremaining: 20.2s\n",
      "2938:\tlearn: 1.4776260\ttotal: 35.7s\tremaining: 20.1s\n",
      "2939:\tlearn: 1.4773343\ttotal: 35.7s\tremaining: 20.1s\n",
      "2940:\tlearn: 1.4769724\ttotal: 35.7s\tremaining: 20.1s\n",
      "2941:\tlearn: 1.4766028\ttotal: 35.7s\tremaining: 20.1s\n",
      "2942:\tlearn: 1.4765070\ttotal: 35.7s\tremaining: 20.1s\n",
      "2943:\tlearn: 1.4762700\ttotal: 35.8s\tremaining: 20.1s\n",
      "2944:\tlearn: 1.4758557\ttotal: 35.8s\tremaining: 20.1s\n",
      "2945:\tlearn: 1.4752923\ttotal: 35.8s\tremaining: 20.1s\n",
      "2946:\tlearn: 1.4751551\ttotal: 35.8s\tremaining: 20.1s\n",
      "2947:\tlearn: 1.4746854\ttotal: 35.8s\tremaining: 20s\n",
      "2948:\tlearn: 1.4744018\ttotal: 35.8s\tremaining: 20s\n",
      "2949:\tlearn: 1.4739244\ttotal: 35.8s\tremaining: 20s\n",
      "2950:\tlearn: 1.4736102\ttotal: 35.8s\tremaining: 20s\n",
      "2951:\tlearn: 1.4734029\ttotal: 35.9s\tremaining: 20s\n",
      "2952:\tlearn: 1.4730002\ttotal: 35.9s\tremaining: 20s\n",
      "2953:\tlearn: 1.4728411\ttotal: 35.9s\tremaining: 20s\n",
      "2954:\tlearn: 1.4725840\ttotal: 35.9s\tremaining: 20s\n",
      "2955:\tlearn: 1.4724413\ttotal: 35.9s\tremaining: 19.9s\n",
      "2956:\tlearn: 1.4721725\ttotal: 35.9s\tremaining: 19.9s\n",
      "2957:\tlearn: 1.4720004\ttotal: 35.9s\tremaining: 19.9s\n",
      "2958:\tlearn: 1.4718894\ttotal: 35.9s\tremaining: 19.9s\n",
      "2959:\tlearn: 1.4716543\ttotal: 36s\tremaining: 19.9s\n",
      "2960:\tlearn: 1.4713008\ttotal: 36s\tremaining: 19.9s\n",
      "2961:\tlearn: 1.4710416\ttotal: 36s\tremaining: 19.9s\n",
      "2962:\tlearn: 1.4708450\ttotal: 36s\tremaining: 19.9s\n",
      "2963:\tlearn: 1.4706070\ttotal: 36s\tremaining: 19.8s\n",
      "2964:\tlearn: 1.4703629\ttotal: 36s\tremaining: 19.8s\n",
      "2965:\tlearn: 1.4700628\ttotal: 36s\tremaining: 19.8s\n",
      "2966:\tlearn: 1.4698593\ttotal: 36s\tremaining: 19.8s\n",
      "2967:\tlearn: 1.4696581\ttotal: 36s\tremaining: 19.8s\n",
      "2968:\tlearn: 1.4694789\ttotal: 36.1s\tremaining: 19.8s\n",
      "2969:\tlearn: 1.4692855\ttotal: 36.1s\tremaining: 19.8s\n",
      "2970:\tlearn: 1.4691983\ttotal: 36.1s\tremaining: 19.8s\n",
      "2971:\tlearn: 1.4690514\ttotal: 36.1s\tremaining: 19.7s\n",
      "2972:\tlearn: 1.4687147\ttotal: 36.1s\tremaining: 19.7s\n",
      "2973:\tlearn: 1.4683006\ttotal: 36.1s\tremaining: 19.7s\n",
      "2974:\tlearn: 1.4681517\ttotal: 36.1s\tremaining: 19.7s\n",
      "2975:\tlearn: 1.4677167\ttotal: 36.1s\tremaining: 19.7s\n",
      "2976:\tlearn: 1.4675132\ttotal: 36.2s\tremaining: 19.7s\n",
      "2977:\tlearn: 1.4671786\ttotal: 36.2s\tremaining: 19.7s\n",
      "2978:\tlearn: 1.4670586\ttotal: 36.2s\tremaining: 19.7s\n",
      "2979:\tlearn: 1.4669533\ttotal: 36.2s\tremaining: 19.7s\n",
      "2980:\tlearn: 1.4669172\ttotal: 36.2s\tremaining: 19.6s\n",
      "2981:\tlearn: 1.4666822\ttotal: 36.2s\tremaining: 19.6s\n",
      "2982:\tlearn: 1.4663837\ttotal: 36.2s\tremaining: 19.6s\n",
      "2983:\tlearn: 1.4662267\ttotal: 36.2s\tremaining: 19.6s\n",
      "2984:\tlearn: 1.4658508\ttotal: 36.3s\tremaining: 19.6s\n",
      "2985:\tlearn: 1.4656027\ttotal: 36.3s\tremaining: 19.6s\n",
      "2986:\tlearn: 1.4654048\ttotal: 36.3s\tremaining: 19.6s\n",
      "2987:\tlearn: 1.4651481\ttotal: 36.3s\tremaining: 19.6s\n",
      "2988:\tlearn: 1.4647577\ttotal: 36.3s\tremaining: 19.5s\n",
      "2989:\tlearn: 1.4642844\ttotal: 36.3s\tremaining: 19.5s\n",
      "2990:\tlearn: 1.4638742\ttotal: 36.3s\tremaining: 19.5s\n",
      "2991:\tlearn: 1.4634643\ttotal: 36.3s\tremaining: 19.5s\n",
      "2992:\tlearn: 1.4630474\ttotal: 36.4s\tremaining: 19.5s\n",
      "2993:\tlearn: 1.4626508\ttotal: 36.4s\tremaining: 19.5s\n",
      "2994:\tlearn: 1.4624437\ttotal: 36.4s\tremaining: 19.5s\n",
      "2995:\tlearn: 1.4622057\ttotal: 36.4s\tremaining: 19.5s\n",
      "2996:\tlearn: 1.4619572\ttotal: 36.4s\tremaining: 19.4s\n",
      "2997:\tlearn: 1.4617624\ttotal: 36.4s\tremaining: 19.4s\n",
      "2998:\tlearn: 1.4616833\ttotal: 36.4s\tremaining: 19.4s\n",
      "2999:\tlearn: 1.4614038\ttotal: 36.4s\tremaining: 19.4s\n",
      "3000:\tlearn: 1.4611664\ttotal: 36.4s\tremaining: 19.4s\n",
      "3001:\tlearn: 1.4608453\ttotal: 36.5s\tremaining: 19.4s\n",
      "3002:\tlearn: 1.4608445\ttotal: 36.5s\tremaining: 19.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3003:\tlearn: 1.4605437\ttotal: 36.5s\tremaining: 19.4s\n",
      "3004:\tlearn: 1.4603352\ttotal: 36.5s\tremaining: 19.3s\n",
      "3005:\tlearn: 1.4600366\ttotal: 36.5s\tremaining: 19.3s\n",
      "3006:\tlearn: 1.4597161\ttotal: 36.5s\tremaining: 19.3s\n",
      "3007:\tlearn: 1.4595253\ttotal: 36.5s\tremaining: 19.3s\n",
      "3008:\tlearn: 1.4592879\ttotal: 36.5s\tremaining: 19.3s\n",
      "3009:\tlearn: 1.4587891\ttotal: 36.6s\tremaining: 19.3s\n",
      "3010:\tlearn: 1.4585730\ttotal: 36.6s\tremaining: 19.3s\n",
      "3011:\tlearn: 1.4583502\ttotal: 36.6s\tremaining: 19.3s\n",
      "3012:\tlearn: 1.4579650\ttotal: 36.6s\tremaining: 19.3s\n",
      "3013:\tlearn: 1.4576680\ttotal: 36.6s\tremaining: 19.2s\n",
      "3014:\tlearn: 1.4576407\ttotal: 36.6s\tremaining: 19.2s\n",
      "3015:\tlearn: 1.4574956\ttotal: 36.6s\tremaining: 19.2s\n",
      "3016:\tlearn: 1.4573545\ttotal: 36.6s\tremaining: 19.2s\n",
      "3017:\tlearn: 1.4571564\ttotal: 36.6s\tremaining: 19.2s\n",
      "3018:\tlearn: 1.4571002\ttotal: 36.7s\tremaining: 19.2s\n",
      "3019:\tlearn: 1.4569226\ttotal: 36.7s\tremaining: 19.2s\n",
      "3020:\tlearn: 1.4568149\ttotal: 36.7s\tremaining: 19.1s\n",
      "3021:\tlearn: 1.4565207\ttotal: 36.7s\tremaining: 19.1s\n",
      "3022:\tlearn: 1.4563587\ttotal: 36.7s\tremaining: 19.1s\n",
      "3023:\tlearn: 1.4561730\ttotal: 36.7s\tremaining: 19.1s\n",
      "3024:\tlearn: 1.4559622\ttotal: 36.7s\tremaining: 19.1s\n",
      "3025:\tlearn: 1.4554209\ttotal: 36.7s\tremaining: 19.1s\n",
      "3026:\tlearn: 1.4550142\ttotal: 36.8s\tremaining: 19.1s\n",
      "3027:\tlearn: 1.4548819\ttotal: 36.8s\tremaining: 19.1s\n",
      "3028:\tlearn: 1.4544548\ttotal: 36.8s\tremaining: 19.1s\n",
      "3029:\tlearn: 1.4541418\ttotal: 36.8s\tremaining: 19s\n",
      "3030:\tlearn: 1.4537635\ttotal: 36.8s\tremaining: 19s\n",
      "3031:\tlearn: 1.4535252\ttotal: 36.8s\tremaining: 19s\n",
      "3032:\tlearn: 1.4533333\ttotal: 36.8s\tremaining: 19s\n",
      "3033:\tlearn: 1.4531260\ttotal: 36.8s\tremaining: 19s\n",
      "3034:\tlearn: 1.4529925\ttotal: 36.9s\tremaining: 19s\n",
      "3035:\tlearn: 1.4527384\ttotal: 36.9s\tremaining: 19s\n",
      "3036:\tlearn: 1.4525209\ttotal: 36.9s\tremaining: 19s\n",
      "3037:\tlearn: 1.4522620\ttotal: 36.9s\tremaining: 18.9s\n",
      "3038:\tlearn: 1.4518187\ttotal: 36.9s\tremaining: 18.9s\n",
      "3039:\tlearn: 1.4515391\ttotal: 36.9s\tremaining: 18.9s\n",
      "3040:\tlearn: 1.4512851\ttotal: 36.9s\tremaining: 18.9s\n",
      "3041:\tlearn: 1.4510952\ttotal: 36.9s\tremaining: 18.9s\n",
      "3042:\tlearn: 1.4508376\ttotal: 37s\tremaining: 18.9s\n",
      "3043:\tlearn: 1.4504935\ttotal: 37s\tremaining: 18.9s\n",
      "3044:\tlearn: 1.4502503\ttotal: 37s\tremaining: 18.9s\n",
      "3045:\tlearn: 1.4501154\ttotal: 37s\tremaining: 18.8s\n",
      "3046:\tlearn: 1.4496610\ttotal: 37s\tremaining: 18.8s\n",
      "3047:\tlearn: 1.4494149\ttotal: 37s\tremaining: 18.8s\n",
      "3048:\tlearn: 1.4491187\ttotal: 37s\tremaining: 18.8s\n",
      "3049:\tlearn: 1.4490009\ttotal: 37s\tremaining: 18.8s\n",
      "3050:\tlearn: 1.4488411\ttotal: 37s\tremaining: 18.8s\n",
      "3051:\tlearn: 1.4481970\ttotal: 37.1s\tremaining: 18.8s\n",
      "3052:\tlearn: 1.4478061\ttotal: 37.1s\tremaining: 18.8s\n",
      "3053:\tlearn: 1.4475811\ttotal: 37.1s\tremaining: 18.7s\n",
      "3054:\tlearn: 1.4473225\ttotal: 37.1s\tremaining: 18.7s\n",
      "3055:\tlearn: 1.4469584\ttotal: 37.1s\tremaining: 18.7s\n",
      "3056:\tlearn: 1.4468177\ttotal: 37.1s\tremaining: 18.7s\n",
      "3057:\tlearn: 1.4464317\ttotal: 37.1s\tremaining: 18.7s\n",
      "3058:\tlearn: 1.4463085\ttotal: 37.1s\tremaining: 18.7s\n",
      "3059:\tlearn: 1.4461437\ttotal: 37.2s\tremaining: 18.7s\n",
      "3060:\tlearn: 1.4459332\ttotal: 37.2s\tremaining: 18.7s\n",
      "3061:\tlearn: 1.4457692\ttotal: 37.2s\tremaining: 18.7s\n",
      "3062:\tlearn: 1.4453627\ttotal: 37.2s\tremaining: 18.6s\n",
      "3063:\tlearn: 1.4450133\ttotal: 37.2s\tremaining: 18.6s\n",
      "3064:\tlearn: 1.4447826\ttotal: 37.2s\tremaining: 18.6s\n",
      "3065:\tlearn: 1.4443820\ttotal: 37.2s\tremaining: 18.6s\n",
      "3066:\tlearn: 1.4441534\ttotal: 37.2s\tremaining: 18.6s\n",
      "3067:\tlearn: 1.4437442\ttotal: 37.3s\tremaining: 18.6s\n",
      "3068:\tlearn: 1.4434361\ttotal: 37.3s\tremaining: 18.6s\n",
      "3069:\tlearn: 1.4431810\ttotal: 37.3s\tremaining: 18.6s\n",
      "3070:\tlearn: 1.4429941\ttotal: 37.3s\tremaining: 18.5s\n",
      "3071:\tlearn: 1.4426231\ttotal: 37.3s\tremaining: 18.5s\n",
      "3072:\tlearn: 1.4423082\ttotal: 37.3s\tremaining: 18.5s\n",
      "3073:\tlearn: 1.4421129\ttotal: 37.3s\tremaining: 18.5s\n",
      "3074:\tlearn: 1.4419789\ttotal: 37.3s\tremaining: 18.5s\n",
      "3075:\tlearn: 1.4416772\ttotal: 37.4s\tremaining: 18.5s\n",
      "3076:\tlearn: 1.4414441\ttotal: 37.4s\tremaining: 18.5s\n",
      "3077:\tlearn: 1.4411560\ttotal: 37.4s\tremaining: 18.5s\n",
      "3078:\tlearn: 1.4407301\ttotal: 37.4s\tremaining: 18.4s\n",
      "3079:\tlearn: 1.4403292\ttotal: 37.4s\tremaining: 18.4s\n",
      "3080:\tlearn: 1.4401461\ttotal: 37.4s\tremaining: 18.4s\n",
      "3081:\tlearn: 1.4397540\ttotal: 37.4s\tremaining: 18.4s\n",
      "3082:\tlearn: 1.4394327\ttotal: 37.4s\tremaining: 18.4s\n",
      "3083:\tlearn: 1.4392111\ttotal: 37.5s\tremaining: 18.4s\n",
      "3084:\tlearn: 1.4389929\ttotal: 37.5s\tremaining: 18.4s\n",
      "3085:\tlearn: 1.4386542\ttotal: 37.5s\tremaining: 18.4s\n",
      "3086:\tlearn: 1.4385225\ttotal: 37.5s\tremaining: 18.3s\n",
      "3087:\tlearn: 1.4382014\ttotal: 37.5s\tremaining: 18.3s\n",
      "3088:\tlearn: 1.4379756\ttotal: 37.5s\tremaining: 18.3s\n",
      "3089:\tlearn: 1.4377456\ttotal: 37.5s\tremaining: 18.3s\n",
      "3090:\tlearn: 1.4376957\ttotal: 37.5s\tremaining: 18.3s\n",
      "3091:\tlearn: 1.4374105\ttotal: 37.5s\tremaining: 18.3s\n",
      "3092:\tlearn: 1.4370879\ttotal: 37.6s\tremaining: 18.3s\n",
      "3093:\tlearn: 1.4369151\ttotal: 37.6s\tremaining: 18.3s\n",
      "3094:\tlearn: 1.4367572\ttotal: 37.6s\tremaining: 18.3s\n",
      "3095:\tlearn: 1.4366424\ttotal: 37.6s\tremaining: 18.2s\n",
      "3096:\tlearn: 1.4365253\ttotal: 37.6s\tremaining: 18.2s\n",
      "3097:\tlearn: 1.4361585\ttotal: 37.6s\tremaining: 18.2s\n",
      "3098:\tlearn: 1.4358573\ttotal: 37.6s\tremaining: 18.2s\n",
      "3099:\tlearn: 1.4355954\ttotal: 37.6s\tremaining: 18.2s\n",
      "3100:\tlearn: 1.4355530\ttotal: 37.7s\tremaining: 18.2s\n",
      "3101:\tlearn: 1.4353680\ttotal: 37.7s\tremaining: 18.2s\n",
      "3102:\tlearn: 1.4352186\ttotal: 37.7s\tremaining: 18.2s\n",
      "3103:\tlearn: 1.4349722\ttotal: 37.7s\tremaining: 18.1s\n",
      "3104:\tlearn: 1.4347745\ttotal: 37.7s\tremaining: 18.1s\n",
      "3105:\tlearn: 1.4345930\ttotal: 37.7s\tremaining: 18.1s\n",
      "3106:\tlearn: 1.4342774\ttotal: 37.7s\tremaining: 18.1s\n",
      "3107:\tlearn: 1.4339025\ttotal: 37.7s\tremaining: 18.1s\n",
      "3108:\tlearn: 1.4336798\ttotal: 37.8s\tremaining: 18.1s\n",
      "3109:\tlearn: 1.4334168\ttotal: 37.8s\tremaining: 18.1s\n",
      "3110:\tlearn: 1.4330160\ttotal: 37.8s\tremaining: 18.1s\n",
      "3111:\tlearn: 1.4327002\ttotal: 37.8s\tremaining: 18s\n",
      "3112:\tlearn: 1.4321843\ttotal: 37.8s\tremaining: 18s\n",
      "3113:\tlearn: 1.4319711\ttotal: 37.8s\tremaining: 18s\n",
      "3114:\tlearn: 1.4316523\ttotal: 37.8s\tremaining: 18s\n",
      "3115:\tlearn: 1.4315601\ttotal: 37.8s\tremaining: 18s\n",
      "3116:\tlearn: 1.4313752\ttotal: 37.9s\tremaining: 18s\n",
      "3117:\tlearn: 1.4311363\ttotal: 37.9s\tremaining: 18s\n",
      "3118:\tlearn: 1.4308939\ttotal: 37.9s\tremaining: 18s\n",
      "3119:\tlearn: 1.4308387\ttotal: 37.9s\tremaining: 17.9s\n",
      "3120:\tlearn: 1.4304122\ttotal: 37.9s\tremaining: 17.9s\n",
      "3121:\tlearn: 1.4300674\ttotal: 37.9s\tremaining: 17.9s\n",
      "3122:\tlearn: 1.4297342\ttotal: 37.9s\tremaining: 17.9s\n",
      "3123:\tlearn: 1.4296648\ttotal: 37.9s\tremaining: 17.9s\n",
      "3124:\tlearn: 1.4293156\ttotal: 38s\tremaining: 17.9s\n",
      "3125:\tlearn: 1.4292271\ttotal: 38s\tremaining: 17.9s\n",
      "3126:\tlearn: 1.4289974\ttotal: 38s\tremaining: 17.9s\n",
      "3127:\tlearn: 1.4286101\ttotal: 38s\tremaining: 17.9s\n",
      "3128:\tlearn: 1.4283589\ttotal: 38s\tremaining: 17.8s\n",
      "3129:\tlearn: 1.4283302\ttotal: 38s\tremaining: 17.8s\n",
      "3130:\tlearn: 1.4279968\ttotal: 38s\tremaining: 17.8s\n",
      "3131:\tlearn: 1.4276653\ttotal: 38s\tremaining: 17.8s\n",
      "3132:\tlearn: 1.4271885\ttotal: 38.1s\tremaining: 17.8s\n",
      "3133:\tlearn: 1.4268211\ttotal: 38.1s\tremaining: 17.8s\n",
      "3134:\tlearn: 1.4266379\ttotal: 38.1s\tremaining: 17.8s\n",
      "3135:\tlearn: 1.4265391\ttotal: 38.1s\tremaining: 17.8s\n",
      "3136:\tlearn: 1.4262724\ttotal: 38.1s\tremaining: 17.7s\n",
      "3137:\tlearn: 1.4260805\ttotal: 38.1s\tremaining: 17.7s\n",
      "3138:\tlearn: 1.4259376\ttotal: 38.1s\tremaining: 17.7s\n",
      "3139:\tlearn: 1.4256587\ttotal: 38.1s\tremaining: 17.7s\n",
      "3140:\tlearn: 1.4251717\ttotal: 38.1s\tremaining: 17.7s\n",
      "3141:\tlearn: 1.4249928\ttotal: 38.2s\tremaining: 17.7s\n",
      "3142:\tlearn: 1.4246150\ttotal: 38.2s\tremaining: 17.7s\n",
      "3143:\tlearn: 1.4244326\ttotal: 38.2s\tremaining: 17.7s\n",
      "3144:\tlearn: 1.4242875\ttotal: 38.2s\tremaining: 17.6s\n",
      "3145:\tlearn: 1.4240501\ttotal: 38.2s\tremaining: 17.6s\n",
      "3146:\tlearn: 1.4239316\ttotal: 38.2s\tremaining: 17.6s\n",
      "3147:\tlearn: 1.4239008\ttotal: 38.2s\tremaining: 17.6s\n",
      "3148:\tlearn: 1.4236751\ttotal: 38.2s\tremaining: 17.6s\n",
      "3149:\tlearn: 1.4235031\ttotal: 38.3s\tremaining: 17.6s\n",
      "3150:\tlearn: 1.4233023\ttotal: 38.3s\tremaining: 17.6s\n",
      "3151:\tlearn: 1.4229689\ttotal: 38.3s\tremaining: 17.6s\n",
      "3152:\tlearn: 1.4229092\ttotal: 38.3s\tremaining: 17.5s\n",
      "3153:\tlearn: 1.4227787\ttotal: 38.3s\tremaining: 17.5s\n",
      "3154:\tlearn: 1.4223568\ttotal: 38.3s\tremaining: 17.5s\n",
      "3155:\tlearn: 1.4222212\ttotal: 38.3s\tremaining: 17.5s\n",
      "3156:\tlearn: 1.4219887\ttotal: 38.3s\tremaining: 17.5s\n",
      "3157:\tlearn: 1.4217358\ttotal: 38.3s\tremaining: 17.5s\n",
      "3158:\tlearn: 1.4214056\ttotal: 38.4s\tremaining: 17.5s\n",
      "3159:\tlearn: 1.4209771\ttotal: 38.4s\tremaining: 17.5s\n",
      "3160:\tlearn: 1.4206092\ttotal: 38.4s\tremaining: 17.5s\n",
      "3161:\tlearn: 1.4203784\ttotal: 38.4s\tremaining: 17.4s\n",
      "3162:\tlearn: 1.4203624\ttotal: 38.4s\tremaining: 17.4s\n",
      "3163:\tlearn: 1.4201478\ttotal: 38.4s\tremaining: 17.4s\n",
      "3164:\tlearn: 1.4196334\ttotal: 38.4s\tremaining: 17.4s\n",
      "3165:\tlearn: 1.4195438\ttotal: 38.4s\tremaining: 17.4s\n",
      "3166:\tlearn: 1.4193599\ttotal: 38.5s\tremaining: 17.4s\n",
      "3167:\tlearn: 1.4191040\ttotal: 38.5s\tremaining: 17.4s\n",
      "3168:\tlearn: 1.4190136\ttotal: 38.5s\tremaining: 17.4s\n",
      "3169:\tlearn: 1.4188181\ttotal: 38.5s\tremaining: 17.3s\n",
      "3170:\tlearn: 1.4186308\ttotal: 38.5s\tremaining: 17.3s\n",
      "3171:\tlearn: 1.4183935\ttotal: 38.5s\tremaining: 17.3s\n",
      "3172:\tlearn: 1.4182630\ttotal: 38.5s\tremaining: 17.3s\n",
      "3173:\tlearn: 1.4181648\ttotal: 38.5s\tremaining: 17.3s\n",
      "3174:\tlearn: 1.4177887\ttotal: 38.6s\tremaining: 17.3s\n",
      "3175:\tlearn: 1.4176934\ttotal: 38.6s\tremaining: 17.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3176:\tlearn: 1.4176213\ttotal: 38.6s\tremaining: 17.3s\n",
      "3177:\tlearn: 1.4174117\ttotal: 38.6s\tremaining: 17.2s\n",
      "3178:\tlearn: 1.4171755\ttotal: 38.6s\tremaining: 17.2s\n",
      "3179:\tlearn: 1.4168390\ttotal: 38.6s\tremaining: 17.2s\n",
      "3180:\tlearn: 1.4165282\ttotal: 38.6s\tremaining: 17.2s\n",
      "3181:\tlearn: 1.4163918\ttotal: 38.6s\tremaining: 17.2s\n",
      "3182:\tlearn: 1.4158629\ttotal: 38.7s\tremaining: 17.2s\n",
      "3183:\tlearn: 1.4157317\ttotal: 38.7s\tremaining: 17.2s\n",
      "3184:\tlearn: 1.4153924\ttotal: 38.7s\tremaining: 17.2s\n",
      "3185:\tlearn: 1.4152146\ttotal: 38.7s\tremaining: 17.1s\n",
      "3186:\tlearn: 1.4148689\ttotal: 38.7s\tremaining: 17.1s\n",
      "3187:\tlearn: 1.4145947\ttotal: 38.7s\tremaining: 17.1s\n",
      "3188:\tlearn: 1.4143575\ttotal: 38.7s\tremaining: 17.1s\n",
      "3189:\tlearn: 1.4140912\ttotal: 38.7s\tremaining: 17.1s\n",
      "3190:\tlearn: 1.4139492\ttotal: 38.7s\tremaining: 17.1s\n",
      "3191:\tlearn: 1.4136523\ttotal: 38.8s\tremaining: 17.1s\n",
      "3192:\tlearn: 1.4134703\ttotal: 38.8s\tremaining: 17.1s\n",
      "3193:\tlearn: 1.4132733\ttotal: 38.8s\tremaining: 17s\n",
      "3194:\tlearn: 1.4130926\ttotal: 38.8s\tremaining: 17s\n",
      "3195:\tlearn: 1.4127840\ttotal: 38.8s\tremaining: 17s\n",
      "3196:\tlearn: 1.4125114\ttotal: 38.8s\tremaining: 17s\n",
      "3197:\tlearn: 1.4121915\ttotal: 38.8s\tremaining: 17s\n",
      "3198:\tlearn: 1.4120674\ttotal: 38.8s\tremaining: 17s\n",
      "3199:\tlearn: 1.4118546\ttotal: 38.9s\tremaining: 17s\n",
      "3200:\tlearn: 1.4116171\ttotal: 38.9s\tremaining: 17s\n",
      "3201:\tlearn: 1.4114528\ttotal: 38.9s\tremaining: 17s\n",
      "3202:\tlearn: 1.4113232\ttotal: 38.9s\tremaining: 16.9s\n",
      "3203:\tlearn: 1.4110073\ttotal: 38.9s\tremaining: 16.9s\n",
      "3204:\tlearn: 1.4107307\ttotal: 38.9s\tremaining: 16.9s\n",
      "3205:\tlearn: 1.4106127\ttotal: 38.9s\tremaining: 16.9s\n",
      "3206:\tlearn: 1.4104376\ttotal: 38.9s\tremaining: 16.9s\n",
      "3207:\tlearn: 1.4101193\ttotal: 39s\tremaining: 16.9s\n",
      "3208:\tlearn: 1.4097962\ttotal: 39s\tremaining: 16.9s\n",
      "3209:\tlearn: 1.4095469\ttotal: 39s\tremaining: 16.9s\n",
      "3210:\tlearn: 1.4093077\ttotal: 39s\tremaining: 16.8s\n",
      "3211:\tlearn: 1.4089600\ttotal: 39s\tremaining: 16.8s\n",
      "3212:\tlearn: 1.4087536\ttotal: 39s\tremaining: 16.8s\n",
      "3213:\tlearn: 1.4085726\ttotal: 39s\tremaining: 16.8s\n",
      "3214:\tlearn: 1.4082977\ttotal: 39s\tremaining: 16.8s\n",
      "3215:\tlearn: 1.4078894\ttotal: 39.1s\tremaining: 16.8s\n",
      "3216:\tlearn: 1.4076330\ttotal: 39.1s\tremaining: 16.8s\n",
      "3217:\tlearn: 1.4073680\ttotal: 39.1s\tremaining: 16.8s\n",
      "3218:\tlearn: 1.4071485\ttotal: 39.1s\tremaining: 16.7s\n",
      "3219:\tlearn: 1.4068005\ttotal: 39.1s\tremaining: 16.7s\n",
      "3220:\tlearn: 1.4063256\ttotal: 39.1s\tremaining: 16.7s\n",
      "3221:\tlearn: 1.4061811\ttotal: 39.1s\tremaining: 16.7s\n",
      "3222:\tlearn: 1.4058470\ttotal: 39.1s\tremaining: 16.7s\n",
      "3223:\tlearn: 1.4057084\ttotal: 39.2s\tremaining: 16.7s\n",
      "3224:\tlearn: 1.4055547\ttotal: 39.2s\tremaining: 16.7s\n",
      "3225:\tlearn: 1.4054215\ttotal: 39.2s\tremaining: 16.7s\n",
      "3226:\tlearn: 1.4052260\ttotal: 39.2s\tremaining: 16.6s\n",
      "3227:\tlearn: 1.4050196\ttotal: 39.2s\tremaining: 16.6s\n",
      "3228:\tlearn: 1.4048682\ttotal: 39.2s\tremaining: 16.6s\n",
      "3229:\tlearn: 1.4046416\ttotal: 39.2s\tremaining: 16.6s\n",
      "3230:\tlearn: 1.4046234\ttotal: 39.2s\tremaining: 16.6s\n",
      "3231:\tlearn: 1.4043882\ttotal: 39.3s\tremaining: 16.6s\n",
      "3232:\tlearn: 1.4041665\ttotal: 39.3s\tremaining: 16.6s\n",
      "3233:\tlearn: 1.4039243\ttotal: 39.3s\tremaining: 16.6s\n",
      "3234:\tlearn: 1.4036333\ttotal: 39.3s\tremaining: 16.6s\n",
      "3235:\tlearn: 1.4034185\ttotal: 39.3s\tremaining: 16.5s\n",
      "3236:\tlearn: 1.4033321\ttotal: 39.3s\tremaining: 16.5s\n",
      "3237:\tlearn: 1.4030869\ttotal: 39.3s\tremaining: 16.5s\n",
      "3238:\tlearn: 1.4028296\ttotal: 39.3s\tremaining: 16.5s\n",
      "3239:\tlearn: 1.4027348\ttotal: 39.3s\tremaining: 16.5s\n",
      "3240:\tlearn: 1.4022683\ttotal: 39.4s\tremaining: 16.5s\n",
      "3241:\tlearn: 1.4020471\ttotal: 39.4s\tremaining: 16.5s\n",
      "3242:\tlearn: 1.4019131\ttotal: 39.4s\tremaining: 16.5s\n",
      "3243:\tlearn: 1.4015937\ttotal: 39.4s\tremaining: 16.4s\n",
      "3244:\tlearn: 1.4012681\ttotal: 39.4s\tremaining: 16.4s\n",
      "3245:\tlearn: 1.4011439\ttotal: 39.4s\tremaining: 16.4s\n",
      "3246:\tlearn: 1.4009708\ttotal: 39.4s\tremaining: 16.4s\n",
      "3247:\tlearn: 1.4007218\ttotal: 39.4s\tremaining: 16.4s\n",
      "3248:\tlearn: 1.4005501\ttotal: 39.5s\tremaining: 16.4s\n",
      "3249:\tlearn: 1.4002270\ttotal: 39.5s\tremaining: 16.4s\n",
      "3250:\tlearn: 1.4000585\ttotal: 39.5s\tremaining: 16.4s\n",
      "3251:\tlearn: 1.3998497\ttotal: 39.5s\tremaining: 16.3s\n",
      "3252:\tlearn: 1.3997687\ttotal: 39.5s\tremaining: 16.3s\n",
      "3253:\tlearn: 1.3994747\ttotal: 39.5s\tremaining: 16.3s\n",
      "3254:\tlearn: 1.3992969\ttotal: 39.5s\tremaining: 16.3s\n",
      "3255:\tlearn: 1.3990832\ttotal: 39.5s\tremaining: 16.3s\n",
      "3256:\tlearn: 1.3988961\ttotal: 39.6s\tremaining: 16.3s\n",
      "3257:\tlearn: 1.3987548\ttotal: 39.6s\tremaining: 16.3s\n",
      "3258:\tlearn: 1.3984533\ttotal: 39.6s\tremaining: 16.3s\n",
      "3259:\tlearn: 1.3982695\ttotal: 39.6s\tremaining: 16.3s\n",
      "3260:\tlearn: 1.3980579\ttotal: 39.6s\tremaining: 16.2s\n",
      "3261:\tlearn: 1.3978335\ttotal: 39.6s\tremaining: 16.2s\n",
      "3262:\tlearn: 1.3976682\ttotal: 39.6s\tremaining: 16.2s\n",
      "3263:\tlearn: 1.3974263\ttotal: 39.6s\tremaining: 16.2s\n",
      "3264:\tlearn: 1.3971559\ttotal: 39.7s\tremaining: 16.2s\n",
      "3265:\tlearn: 1.3968273\ttotal: 39.7s\tremaining: 16.2s\n",
      "3266:\tlearn: 1.3966259\ttotal: 39.7s\tremaining: 16.2s\n",
      "3267:\tlearn: 1.3962463\ttotal: 39.7s\tremaining: 16.2s\n",
      "3268:\tlearn: 1.3960582\ttotal: 39.7s\tremaining: 16.1s\n",
      "3269:\tlearn: 1.3959449\ttotal: 39.7s\tremaining: 16.1s\n",
      "3270:\tlearn: 1.3958589\ttotal: 39.7s\tremaining: 16.1s\n",
      "3271:\tlearn: 1.3956938\ttotal: 39.7s\tremaining: 16.1s\n",
      "3272:\tlearn: 1.3955021\ttotal: 39.8s\tremaining: 16.1s\n",
      "3273:\tlearn: 1.3953032\ttotal: 39.8s\tremaining: 16.1s\n",
      "3274:\tlearn: 1.3949950\ttotal: 39.8s\tremaining: 16.1s\n",
      "3275:\tlearn: 1.3947959\ttotal: 39.8s\tremaining: 16.1s\n",
      "3276:\tlearn: 1.3945424\ttotal: 39.8s\tremaining: 16s\n",
      "3277:\tlearn: 1.3943672\ttotal: 39.8s\tremaining: 16s\n",
      "3278:\tlearn: 1.3940413\ttotal: 39.8s\tremaining: 16s\n",
      "3279:\tlearn: 1.3938046\ttotal: 39.8s\tremaining: 16s\n",
      "3280:\tlearn: 1.3935763\ttotal: 39.8s\tremaining: 16s\n",
      "3281:\tlearn: 1.3935498\ttotal: 39.9s\tremaining: 16s\n",
      "3282:\tlearn: 1.3933299\ttotal: 39.9s\tremaining: 16s\n",
      "3283:\tlearn: 1.3931874\ttotal: 39.9s\tremaining: 16s\n",
      "3284:\tlearn: 1.3927367\ttotal: 39.9s\tremaining: 15.9s\n",
      "3285:\tlearn: 1.3925743\ttotal: 39.9s\tremaining: 15.9s\n",
      "3286:\tlearn: 1.3923110\ttotal: 39.9s\tremaining: 15.9s\n",
      "3287:\tlearn: 1.3921440\ttotal: 39.9s\tremaining: 15.9s\n",
      "3288:\tlearn: 1.3920069\ttotal: 39.9s\tremaining: 15.9s\n",
      "3289:\tlearn: 1.3917500\ttotal: 40s\tremaining: 15.9s\n",
      "3290:\tlearn: 1.3915517\ttotal: 40s\tremaining: 15.9s\n",
      "3291:\tlearn: 1.3912634\ttotal: 40s\tremaining: 15.9s\n",
      "3292:\tlearn: 1.3912162\ttotal: 40s\tremaining: 15.8s\n",
      "3293:\tlearn: 1.3911126\ttotal: 40s\tremaining: 15.8s\n",
      "3294:\tlearn: 1.3908488\ttotal: 40s\tremaining: 15.8s\n",
      "3295:\tlearn: 1.3906954\ttotal: 40s\tremaining: 15.8s\n",
      "3296:\tlearn: 1.3905807\ttotal: 40s\tremaining: 15.8s\n",
      "3297:\tlearn: 1.3904333\ttotal: 40.1s\tremaining: 15.8s\n",
      "3298:\tlearn: 1.3902026\ttotal: 40.1s\tremaining: 15.8s\n",
      "3299:\tlearn: 1.3900378\ttotal: 40.1s\tremaining: 15.8s\n",
      "3300:\tlearn: 1.3897166\ttotal: 40.1s\tremaining: 15.8s\n",
      "3301:\tlearn: 1.3895648\ttotal: 40.1s\tremaining: 15.7s\n",
      "3302:\tlearn: 1.3894559\ttotal: 40.1s\tremaining: 15.7s\n",
      "3303:\tlearn: 1.3891580\ttotal: 40.1s\tremaining: 15.7s\n",
      "3304:\tlearn: 1.3890239\ttotal: 40.1s\tremaining: 15.7s\n",
      "3305:\tlearn: 1.3888306\ttotal: 40.2s\tremaining: 15.7s\n",
      "3306:\tlearn: 1.3885606\ttotal: 40.2s\tremaining: 15.7s\n",
      "3307:\tlearn: 1.3883711\ttotal: 40.2s\tremaining: 15.7s\n",
      "3308:\tlearn: 1.3881592\ttotal: 40.2s\tremaining: 15.7s\n",
      "3309:\tlearn: 1.3880215\ttotal: 40.2s\tremaining: 15.6s\n",
      "3310:\tlearn: 1.3878383\ttotal: 40.2s\tremaining: 15.6s\n",
      "3311:\tlearn: 1.3876174\ttotal: 40.2s\tremaining: 15.6s\n",
      "3312:\tlearn: 1.3875313\ttotal: 40.2s\tremaining: 15.6s\n",
      "3313:\tlearn: 1.3874893\ttotal: 40.2s\tremaining: 15.6s\n",
      "3314:\tlearn: 1.3873369\ttotal: 40.3s\tremaining: 15.6s\n",
      "3315:\tlearn: 1.3872395\ttotal: 40.3s\tremaining: 15.6s\n",
      "3316:\tlearn: 1.3868259\ttotal: 40.3s\tremaining: 15.6s\n",
      "3317:\tlearn: 1.3865590\ttotal: 40.3s\tremaining: 15.5s\n",
      "3318:\tlearn: 1.3862605\ttotal: 40.3s\tremaining: 15.5s\n",
      "3319:\tlearn: 1.3861399\ttotal: 40.3s\tremaining: 15.5s\n",
      "3320:\tlearn: 1.3858206\ttotal: 40.3s\tremaining: 15.5s\n",
      "3321:\tlearn: 1.3856424\ttotal: 40.3s\tremaining: 15.5s\n",
      "3322:\tlearn: 1.3854607\ttotal: 40.4s\tremaining: 15.5s\n",
      "3323:\tlearn: 1.3852770\ttotal: 40.4s\tremaining: 15.5s\n",
      "3324:\tlearn: 1.3850111\ttotal: 40.4s\tremaining: 15.5s\n",
      "3325:\tlearn: 1.3848313\ttotal: 40.4s\tremaining: 15.4s\n",
      "3326:\tlearn: 1.3845606\ttotal: 40.4s\tremaining: 15.4s\n",
      "3327:\tlearn: 1.3843091\ttotal: 40.4s\tremaining: 15.4s\n",
      "3328:\tlearn: 1.3839858\ttotal: 40.4s\tremaining: 15.4s\n",
      "3329:\tlearn: 1.3838156\ttotal: 40.4s\tremaining: 15.4s\n",
      "3330:\tlearn: 1.3835648\ttotal: 40.5s\tremaining: 15.4s\n",
      "3331:\tlearn: 1.3833447\ttotal: 40.5s\tremaining: 15.4s\n",
      "3332:\tlearn: 1.3830072\ttotal: 40.5s\tremaining: 15.4s\n",
      "3333:\tlearn: 1.3828566\ttotal: 40.5s\tremaining: 15.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3334:\tlearn: 1.3827615\ttotal: 40.5s\tremaining: 15.3s\n",
      "3335:\tlearn: 1.3827339\ttotal: 40.5s\tremaining: 15.3s\n",
      "3336:\tlearn: 1.3826077\ttotal: 40.5s\tremaining: 15.3s\n",
      "3337:\tlearn: 1.3825001\ttotal: 40.5s\tremaining: 15.3s\n",
      "3338:\tlearn: 1.3823373\ttotal: 40.6s\tremaining: 15.3s\n",
      "3339:\tlearn: 1.3822057\ttotal: 40.6s\tremaining: 15.3s\n",
      "3340:\tlearn: 1.3819396\ttotal: 40.6s\tremaining: 15.3s\n",
      "3341:\tlearn: 1.3818080\ttotal: 40.6s\tremaining: 15.3s\n",
      "3342:\tlearn: 1.3813127\ttotal: 40.6s\tremaining: 15.2s\n",
      "3343:\tlearn: 1.3812113\ttotal: 40.6s\tremaining: 15.2s\n",
      "3344:\tlearn: 1.3809516\ttotal: 40.6s\tremaining: 15.2s\n",
      "3345:\tlearn: 1.3805884\ttotal: 40.6s\tremaining: 15.2s\n",
      "3346:\tlearn: 1.3804973\ttotal: 40.6s\tremaining: 15.2s\n",
      "3347:\tlearn: 1.3802397\ttotal: 40.7s\tremaining: 15.2s\n",
      "3348:\tlearn: 1.3799736\ttotal: 40.7s\tremaining: 15.2s\n",
      "3349:\tlearn: 1.3797719\ttotal: 40.7s\tremaining: 15.2s\n",
      "3350:\tlearn: 1.3796337\ttotal: 40.7s\tremaining: 15.1s\n",
      "3351:\tlearn: 1.3792372\ttotal: 40.7s\tremaining: 15.1s\n",
      "3352:\tlearn: 1.3788435\ttotal: 40.7s\tremaining: 15.1s\n",
      "3353:\tlearn: 1.3786659\ttotal: 40.7s\tremaining: 15.1s\n",
      "3354:\tlearn: 1.3784729\ttotal: 40.8s\tremaining: 15.1s\n",
      "3355:\tlearn: 1.3781640\ttotal: 40.8s\tremaining: 15.1s\n",
      "3356:\tlearn: 1.3781244\ttotal: 40.8s\tremaining: 15.1s\n",
      "3357:\tlearn: 1.3779780\ttotal: 40.8s\tremaining: 15.1s\n",
      "3358:\tlearn: 1.3778267\ttotal: 40.8s\tremaining: 15s\n",
      "3359:\tlearn: 1.3775471\ttotal: 40.8s\tremaining: 15s\n",
      "3360:\tlearn: 1.3771318\ttotal: 40.8s\tremaining: 15s\n",
      "3361:\tlearn: 1.3770021\ttotal: 40.8s\tremaining: 15s\n",
      "3362:\tlearn: 1.3768667\ttotal: 40.8s\tremaining: 15s\n",
      "3363:\tlearn: 1.3764048\ttotal: 40.9s\tremaining: 15s\n",
      "3364:\tlearn: 1.3761236\ttotal: 40.9s\tremaining: 15s\n",
      "3365:\tlearn: 1.3758770\ttotal: 40.9s\tremaining: 15s\n",
      "3366:\tlearn: 1.3757106\ttotal: 40.9s\tremaining: 15s\n",
      "3367:\tlearn: 1.3753495\ttotal: 40.9s\tremaining: 14.9s\n",
      "3368:\tlearn: 1.3751528\ttotal: 40.9s\tremaining: 14.9s\n",
      "3369:\tlearn: 1.3750930\ttotal: 40.9s\tremaining: 14.9s\n",
      "3370:\tlearn: 1.3748104\ttotal: 40.9s\tremaining: 14.9s\n",
      "3371:\tlearn: 1.3745853\ttotal: 41s\tremaining: 14.9s\n",
      "3372:\tlearn: 1.3745800\ttotal: 41s\tremaining: 14.9s\n",
      "3373:\tlearn: 1.3743553\ttotal: 41s\tremaining: 14.9s\n",
      "3374:\tlearn: 1.3742533\ttotal: 41s\tremaining: 14.9s\n",
      "3375:\tlearn: 1.3740793\ttotal: 41s\tremaining: 14.8s\n",
      "3376:\tlearn: 1.3739893\ttotal: 41s\tremaining: 14.8s\n",
      "3377:\tlearn: 1.3738183\ttotal: 41s\tremaining: 14.8s\n",
      "3378:\tlearn: 1.3736285\ttotal: 41s\tremaining: 14.8s\n",
      "3379:\tlearn: 1.3735203\ttotal: 41s\tremaining: 14.8s\n",
      "3380:\tlearn: 1.3733576\ttotal: 41.1s\tremaining: 14.8s\n",
      "3381:\tlearn: 1.3731964\ttotal: 41.1s\tremaining: 14.8s\n",
      "3382:\tlearn: 1.3730378\ttotal: 41.1s\tremaining: 14.8s\n",
      "3383:\tlearn: 1.3728159\ttotal: 41.1s\tremaining: 14.7s\n",
      "3384:\tlearn: 1.3727213\ttotal: 41.1s\tremaining: 14.7s\n",
      "3385:\tlearn: 1.3724677\ttotal: 41.1s\tremaining: 14.7s\n",
      "3386:\tlearn: 1.3722510\ttotal: 41.1s\tremaining: 14.7s\n",
      "3387:\tlearn: 1.3720550\ttotal: 41.1s\tremaining: 14.7s\n",
      "3388:\tlearn: 1.3718046\ttotal: 41.2s\tremaining: 14.7s\n",
      "3389:\tlearn: 1.3715583\ttotal: 41.2s\tremaining: 14.7s\n",
      "3390:\tlearn: 1.3714414\ttotal: 41.2s\tremaining: 14.7s\n",
      "3391:\tlearn: 1.3711082\ttotal: 41.2s\tremaining: 14.6s\n",
      "3392:\tlearn: 1.3710518\ttotal: 41.2s\tremaining: 14.6s\n",
      "3393:\tlearn: 1.3708809\ttotal: 41.2s\tremaining: 14.6s\n",
      "3394:\tlearn: 1.3707666\ttotal: 41.2s\tremaining: 14.6s\n",
      "3395:\tlearn: 1.3704199\ttotal: 41.2s\tremaining: 14.6s\n",
      "3396:\tlearn: 1.3701518\ttotal: 41.3s\tremaining: 14.6s\n",
      "3397:\tlearn: 1.3699224\ttotal: 41.3s\tremaining: 14.6s\n",
      "3398:\tlearn: 1.3696135\ttotal: 41.3s\tremaining: 14.6s\n",
      "3399:\tlearn: 1.3691088\ttotal: 41.3s\tremaining: 14.5s\n",
      "3400:\tlearn: 1.3688713\ttotal: 41.3s\tremaining: 14.5s\n",
      "3401:\tlearn: 1.3684758\ttotal: 41.3s\tremaining: 14.5s\n",
      "3402:\tlearn: 1.3683062\ttotal: 41.3s\tremaining: 14.5s\n",
      "3403:\tlearn: 1.3680752\ttotal: 41.3s\tremaining: 14.5s\n",
      "3404:\tlearn: 1.3677526\ttotal: 41.4s\tremaining: 14.5s\n",
      "3405:\tlearn: 1.3675606\ttotal: 41.4s\tremaining: 14.5s\n",
      "3406:\tlearn: 1.3672708\ttotal: 41.4s\tremaining: 14.5s\n",
      "3407:\tlearn: 1.3670816\ttotal: 41.4s\tremaining: 14.5s\n",
      "3408:\tlearn: 1.3670188\ttotal: 41.4s\tremaining: 14.4s\n",
      "3409:\tlearn: 1.3669894\ttotal: 41.4s\tremaining: 14.4s\n",
      "3410:\tlearn: 1.3667470\ttotal: 41.4s\tremaining: 14.4s\n",
      "3411:\tlearn: 1.3666708\ttotal: 41.4s\tremaining: 14.4s\n",
      "3412:\tlearn: 1.3666088\ttotal: 41.5s\tremaining: 14.4s\n",
      "3413:\tlearn: 1.3663687\ttotal: 41.5s\tremaining: 14.4s\n",
      "3414:\tlearn: 1.3660207\ttotal: 41.5s\tremaining: 14.4s\n",
      "3415:\tlearn: 1.3659002\ttotal: 41.5s\tremaining: 14.4s\n",
      "3416:\tlearn: 1.3657462\ttotal: 41.5s\tremaining: 14.3s\n",
      "3417:\tlearn: 1.3653820\ttotal: 41.5s\tremaining: 14.3s\n",
      "3418:\tlearn: 1.3652927\ttotal: 41.5s\tremaining: 14.3s\n",
      "3419:\tlearn: 1.3649978\ttotal: 41.5s\tremaining: 14.3s\n",
      "3420:\tlearn: 1.3649074\ttotal: 41.5s\tremaining: 14.3s\n",
      "3421:\tlearn: 1.3648447\ttotal: 41.6s\tremaining: 14.3s\n",
      "3422:\tlearn: 1.3644520\ttotal: 41.6s\tremaining: 14.3s\n",
      "3423:\tlearn: 1.3641896\ttotal: 41.6s\tremaining: 14.3s\n",
      "3424:\tlearn: 1.3640667\ttotal: 41.6s\tremaining: 14.2s\n",
      "3425:\tlearn: 1.3638914\ttotal: 41.6s\tremaining: 14.2s\n",
      "3426:\tlearn: 1.3637746\ttotal: 41.6s\tremaining: 14.2s\n",
      "3427:\tlearn: 1.3637512\ttotal: 41.6s\tremaining: 14.2s\n",
      "3428:\tlearn: 1.3635463\ttotal: 41.6s\tremaining: 14.2s\n",
      "3429:\tlearn: 1.3631574\ttotal: 41.7s\tremaining: 14.2s\n",
      "3430:\tlearn: 1.3627287\ttotal: 41.7s\tremaining: 14.2s\n",
      "3431:\tlearn: 1.3626363\ttotal: 41.7s\tremaining: 14.2s\n",
      "3432:\tlearn: 1.3624493\ttotal: 41.7s\tremaining: 14.1s\n",
      "3433:\tlearn: 1.3623060\ttotal: 41.7s\tremaining: 14.1s\n",
      "3434:\tlearn: 1.3620302\ttotal: 41.7s\tremaining: 14.1s\n",
      "3435:\tlearn: 1.3618591\ttotal: 41.7s\tremaining: 14.1s\n",
      "3436:\tlearn: 1.3617511\ttotal: 41.7s\tremaining: 14.1s\n",
      "3437:\tlearn: 1.3615635\ttotal: 41.8s\tremaining: 14.1s\n",
      "3438:\tlearn: 1.3615080\ttotal: 41.8s\tremaining: 14.1s\n",
      "3439:\tlearn: 1.3613414\ttotal: 41.8s\tremaining: 14.1s\n",
      "3440:\tlearn: 1.3609292\ttotal: 41.8s\tremaining: 14.1s\n",
      "3441:\tlearn: 1.3605786\ttotal: 41.8s\tremaining: 14s\n",
      "3442:\tlearn: 1.3603835\ttotal: 41.8s\tremaining: 14s\n",
      "3443:\tlearn: 1.3598931\ttotal: 41.8s\tremaining: 14s\n",
      "3444:\tlearn: 1.3598427\ttotal: 41.8s\tremaining: 14s\n",
      "3445:\tlearn: 1.3596111\ttotal: 41.9s\tremaining: 14s\n",
      "3446:\tlearn: 1.3595280\ttotal: 41.9s\tremaining: 14s\n",
      "3447:\tlearn: 1.3594393\ttotal: 41.9s\tremaining: 14s\n",
      "3448:\tlearn: 1.3592527\ttotal: 41.9s\tremaining: 14s\n",
      "3449:\tlearn: 1.3591195\ttotal: 41.9s\tremaining: 13.9s\n",
      "3450:\tlearn: 1.3589689\ttotal: 41.9s\tremaining: 13.9s\n",
      "3451:\tlearn: 1.3586298\ttotal: 41.9s\tremaining: 13.9s\n",
      "3452:\tlearn: 1.3583313\ttotal: 41.9s\tremaining: 13.9s\n",
      "3453:\tlearn: 1.3579799\ttotal: 42s\tremaining: 13.9s\n",
      "3454:\tlearn: 1.3575059\ttotal: 42s\tremaining: 13.9s\n",
      "3455:\tlearn: 1.3573251\ttotal: 42s\tremaining: 13.9s\n",
      "3456:\tlearn: 1.3571908\ttotal: 42s\tremaining: 13.9s\n",
      "3457:\tlearn: 1.3571273\ttotal: 42s\tremaining: 13.8s\n",
      "3458:\tlearn: 1.3568213\ttotal: 42s\tremaining: 13.8s\n",
      "3459:\tlearn: 1.3566356\ttotal: 42s\tremaining: 13.8s\n",
      "3460:\tlearn: 1.3563008\ttotal: 42s\tremaining: 13.8s\n",
      "3461:\tlearn: 1.3560798\ttotal: 42.1s\tremaining: 13.8s\n",
      "3462:\tlearn: 1.3558796\ttotal: 42.1s\tremaining: 13.8s\n",
      "3463:\tlearn: 1.3556923\ttotal: 42.1s\tremaining: 13.8s\n",
      "3464:\tlearn: 1.3553304\ttotal: 42.1s\tremaining: 13.8s\n",
      "3465:\tlearn: 1.3550795\ttotal: 42.1s\tremaining: 13.8s\n",
      "3466:\tlearn: 1.3548113\ttotal: 42.1s\tremaining: 13.7s\n",
      "3467:\tlearn: 1.3546489\ttotal: 42.1s\tremaining: 13.7s\n",
      "3468:\tlearn: 1.3544684\ttotal: 42.1s\tremaining: 13.7s\n",
      "3469:\tlearn: 1.3543118\ttotal: 42.1s\tremaining: 13.7s\n",
      "3470:\tlearn: 1.3541158\ttotal: 42.2s\tremaining: 13.7s\n",
      "3471:\tlearn: 1.3540718\ttotal: 42.2s\tremaining: 13.7s\n",
      "3472:\tlearn: 1.3538108\ttotal: 42.2s\tremaining: 13.7s\n",
      "3473:\tlearn: 1.3535584\ttotal: 42.2s\tremaining: 13.7s\n",
      "3474:\tlearn: 1.3534904\ttotal: 42.2s\tremaining: 13.6s\n",
      "3475:\tlearn: 1.3532900\ttotal: 42.2s\tremaining: 13.6s\n",
      "3476:\tlearn: 1.3531909\ttotal: 42.2s\tremaining: 13.6s\n",
      "3477:\tlearn: 1.3529845\ttotal: 42.2s\tremaining: 13.6s\n",
      "3478:\tlearn: 1.3528012\ttotal: 42.3s\tremaining: 13.6s\n",
      "3479:\tlearn: 1.3527010\ttotal: 42.3s\tremaining: 13.6s\n",
      "3480:\tlearn: 1.3525524\ttotal: 42.3s\tremaining: 13.6s\n",
      "3481:\tlearn: 1.3524657\ttotal: 42.3s\tremaining: 13.6s\n",
      "3482:\tlearn: 1.3521266\ttotal: 42.3s\tremaining: 13.5s\n",
      "3483:\tlearn: 1.3519453\ttotal: 42.3s\tremaining: 13.5s\n",
      "3484:\tlearn: 1.3516706\ttotal: 42.3s\tremaining: 13.5s\n",
      "3485:\tlearn: 1.3514543\ttotal: 42.3s\tremaining: 13.5s\n",
      "3486:\tlearn: 1.3512929\ttotal: 42.4s\tremaining: 13.5s\n",
      "3487:\tlearn: 1.3510428\ttotal: 42.4s\tremaining: 13.5s\n",
      "3488:\tlearn: 1.3508348\ttotal: 42.4s\tremaining: 13.5s\n",
      "3489:\tlearn: 1.3506992\ttotal: 42.4s\tremaining: 13.5s\n",
      "3490:\tlearn: 1.3504899\ttotal: 42.4s\tremaining: 13.4s\n",
      "3491:\tlearn: 1.3503659\ttotal: 42.4s\tremaining: 13.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3492:\tlearn: 1.3502550\ttotal: 42.4s\tremaining: 13.4s\n",
      "3493:\tlearn: 1.3500085\ttotal: 42.4s\tremaining: 13.4s\n",
      "3494:\tlearn: 1.3498521\ttotal: 42.5s\tremaining: 13.4s\n",
      "3495:\tlearn: 1.3495707\ttotal: 42.5s\tremaining: 13.4s\n",
      "3496:\tlearn: 1.3494828\ttotal: 42.5s\tremaining: 13.4s\n",
      "3497:\tlearn: 1.3493298\ttotal: 42.5s\tremaining: 13.4s\n",
      "3498:\tlearn: 1.3490148\ttotal: 42.5s\tremaining: 13.3s\n",
      "3499:\tlearn: 1.3488534\ttotal: 42.5s\tremaining: 13.3s\n",
      "3500:\tlearn: 1.3487120\ttotal: 42.5s\tremaining: 13.3s\n",
      "3501:\tlearn: 1.3485081\ttotal: 42.5s\tremaining: 13.3s\n",
      "3502:\tlearn: 1.3483553\ttotal: 42.5s\tremaining: 13.3s\n",
      "3503:\tlearn: 1.3482948\ttotal: 42.6s\tremaining: 13.3s\n",
      "3504:\tlearn: 1.3481970\ttotal: 42.6s\tremaining: 13.3s\n",
      "3505:\tlearn: 1.3480189\ttotal: 42.6s\tremaining: 13.3s\n",
      "3506:\tlearn: 1.3477570\ttotal: 42.6s\tremaining: 13.3s\n",
      "3507:\tlearn: 1.3475833\ttotal: 42.6s\tremaining: 13.2s\n",
      "3508:\tlearn: 1.3474867\ttotal: 42.6s\tremaining: 13.2s\n",
      "3509:\tlearn: 1.3473569\ttotal: 42.6s\tremaining: 13.2s\n",
      "3510:\tlearn: 1.3471625\ttotal: 42.6s\tremaining: 13.2s\n",
      "3511:\tlearn: 1.3470490\ttotal: 42.7s\tremaining: 13.2s\n",
      "3512:\tlearn: 1.3468338\ttotal: 42.7s\tremaining: 13.2s\n",
      "3513:\tlearn: 1.3466476\ttotal: 42.7s\tremaining: 13.2s\n",
      "3514:\tlearn: 1.3462021\ttotal: 42.7s\tremaining: 13.2s\n",
      "3515:\tlearn: 1.3459787\ttotal: 42.7s\tremaining: 13.1s\n",
      "3516:\tlearn: 1.3456496\ttotal: 42.7s\tremaining: 13.1s\n",
      "3517:\tlearn: 1.3453648\ttotal: 42.7s\tremaining: 13.1s\n",
      "3518:\tlearn: 1.3453324\ttotal: 42.7s\tremaining: 13.1s\n",
      "3519:\tlearn: 1.3451475\ttotal: 42.8s\tremaining: 13.1s\n",
      "3520:\tlearn: 1.3448327\ttotal: 42.8s\tremaining: 13.1s\n",
      "3521:\tlearn: 1.3445015\ttotal: 42.8s\tremaining: 13.1s\n",
      "3522:\tlearn: 1.3441949\ttotal: 42.8s\tremaining: 13.1s\n",
      "3523:\tlearn: 1.3439732\ttotal: 42.8s\tremaining: 13s\n",
      "3524:\tlearn: 1.3434642\ttotal: 42.8s\tremaining: 13s\n",
      "3525:\tlearn: 1.3433125\ttotal: 42.8s\tremaining: 13s\n",
      "3526:\tlearn: 1.3430855\ttotal: 42.8s\tremaining: 13s\n",
      "3527:\tlearn: 1.3428219\ttotal: 42.9s\tremaining: 13s\n",
      "3528:\tlearn: 1.3427178\ttotal: 42.9s\tremaining: 13s\n",
      "3529:\tlearn: 1.3425036\ttotal: 42.9s\tremaining: 13s\n",
      "3530:\tlearn: 1.3423154\ttotal: 42.9s\tremaining: 13s\n",
      "3531:\tlearn: 1.3422527\ttotal: 42.9s\tremaining: 12.9s\n",
      "3532:\tlearn: 1.3422164\ttotal: 42.9s\tremaining: 12.9s\n",
      "3533:\tlearn: 1.3418833\ttotal: 42.9s\tremaining: 12.9s\n",
      "3534:\tlearn: 1.3416664\ttotal: 42.9s\tremaining: 12.9s\n",
      "3535:\tlearn: 1.3414339\ttotal: 42.9s\tremaining: 12.9s\n",
      "3536:\tlearn: 1.3413233\ttotal: 43s\tremaining: 12.9s\n",
      "3537:\tlearn: 1.3409569\ttotal: 43s\tremaining: 12.9s\n",
      "3538:\tlearn: 1.3407199\ttotal: 43s\tremaining: 12.9s\n",
      "3539:\tlearn: 1.3406103\ttotal: 43s\tremaining: 12.8s\n",
      "3540:\tlearn: 1.3405174\ttotal: 43s\tremaining: 12.8s\n",
      "3541:\tlearn: 1.3403931\ttotal: 43s\tremaining: 12.8s\n",
      "3542:\tlearn: 1.3401697\ttotal: 43s\tremaining: 12.8s\n",
      "3543:\tlearn: 1.3400301\ttotal: 43s\tremaining: 12.8s\n",
      "3544:\tlearn: 1.3398766\ttotal: 43.1s\tremaining: 12.8s\n",
      "3545:\tlearn: 1.3395700\ttotal: 43.1s\tremaining: 12.8s\n",
      "3546:\tlearn: 1.3394851\ttotal: 43.1s\tremaining: 12.8s\n",
      "3547:\tlearn: 1.3392744\ttotal: 43.1s\tremaining: 12.8s\n",
      "3548:\tlearn: 1.3390945\ttotal: 43.1s\tremaining: 12.7s\n",
      "3549:\tlearn: 1.3388138\ttotal: 43.1s\tremaining: 12.7s\n",
      "3550:\tlearn: 1.3385783\ttotal: 43.1s\tremaining: 12.7s\n",
      "3551:\tlearn: 1.3383889\ttotal: 43.1s\tremaining: 12.7s\n",
      "3552:\tlearn: 1.3381763\ttotal: 43.2s\tremaining: 12.7s\n",
      "3553:\tlearn: 1.3379567\ttotal: 43.2s\tremaining: 12.7s\n",
      "3554:\tlearn: 1.3376048\ttotal: 43.2s\tremaining: 12.7s\n",
      "3555:\tlearn: 1.3375196\ttotal: 43.2s\tremaining: 12.7s\n",
      "3556:\tlearn: 1.3372765\ttotal: 43.2s\tremaining: 12.6s\n",
      "3557:\tlearn: 1.3369841\ttotal: 43.2s\tremaining: 12.6s\n",
      "3558:\tlearn: 1.3369226\ttotal: 43.2s\tremaining: 12.6s\n",
      "3559:\tlearn: 1.3367675\ttotal: 43.2s\tremaining: 12.6s\n",
      "3560:\tlearn: 1.3364872\ttotal: 43.3s\tremaining: 12.6s\n",
      "3561:\tlearn: 1.3363434\ttotal: 43.3s\tremaining: 12.6s\n",
      "3562:\tlearn: 1.3361749\ttotal: 43.3s\tremaining: 12.6s\n",
      "3563:\tlearn: 1.3360128\ttotal: 43.3s\tremaining: 12.6s\n",
      "3564:\tlearn: 1.3357978\ttotal: 43.3s\tremaining: 12.5s\n",
      "3565:\tlearn: 1.3356360\ttotal: 43.3s\tremaining: 12.5s\n",
      "3566:\tlearn: 1.3355468\ttotal: 43.3s\tremaining: 12.5s\n",
      "3567:\tlearn: 1.3353776\ttotal: 43.3s\tremaining: 12.5s\n",
      "3568:\tlearn: 1.3350115\ttotal: 43.4s\tremaining: 12.5s\n",
      "3569:\tlearn: 1.3347708\ttotal: 43.4s\tremaining: 12.5s\n",
      "3570:\tlearn: 1.3344031\ttotal: 43.4s\tremaining: 12.5s\n",
      "3571:\tlearn: 1.3342311\ttotal: 43.4s\tremaining: 12.5s\n",
      "3572:\tlearn: 1.3340993\ttotal: 43.4s\tremaining: 12.5s\n",
      "3573:\tlearn: 1.3338334\ttotal: 43.4s\tremaining: 12.4s\n",
      "3574:\tlearn: 1.3336178\ttotal: 43.4s\tremaining: 12.4s\n",
      "3575:\tlearn: 1.3332650\ttotal: 43.4s\tremaining: 12.4s\n",
      "3576:\tlearn: 1.3329868\ttotal: 43.5s\tremaining: 12.4s\n",
      "3577:\tlearn: 1.3328473\ttotal: 43.5s\tremaining: 12.4s\n",
      "3578:\tlearn: 1.3327283\ttotal: 43.5s\tremaining: 12.4s\n",
      "3579:\tlearn: 1.3325695\ttotal: 43.5s\tremaining: 12.4s\n",
      "3580:\tlearn: 1.3322862\ttotal: 43.5s\tremaining: 12.4s\n",
      "3581:\tlearn: 1.3320465\ttotal: 43.5s\tremaining: 12.3s\n",
      "3582:\tlearn: 1.3317854\ttotal: 43.5s\tremaining: 12.3s\n",
      "3583:\tlearn: 1.3314567\ttotal: 43.5s\tremaining: 12.3s\n",
      "3584:\tlearn: 1.3313281\ttotal: 43.6s\tremaining: 12.3s\n",
      "3585:\tlearn: 1.3310437\ttotal: 43.6s\tremaining: 12.3s\n",
      "3586:\tlearn: 1.3307247\ttotal: 43.6s\tremaining: 12.3s\n",
      "3587:\tlearn: 1.3306629\ttotal: 43.6s\tremaining: 12.3s\n",
      "3588:\tlearn: 1.3304817\ttotal: 43.6s\tremaining: 12.3s\n",
      "3589:\tlearn: 1.3304156\ttotal: 43.6s\tremaining: 12.2s\n",
      "3590:\tlearn: 1.3302908\ttotal: 43.6s\tremaining: 12.2s\n",
      "3591:\tlearn: 1.3299595\ttotal: 43.6s\tremaining: 12.2s\n",
      "3592:\tlearn: 1.3298027\ttotal: 43.6s\tremaining: 12.2s\n",
      "3593:\tlearn: 1.3297015\ttotal: 43.7s\tremaining: 12.2s\n",
      "3594:\tlearn: 1.3294907\ttotal: 43.7s\tremaining: 12.2s\n",
      "3595:\tlearn: 1.3292649\ttotal: 43.7s\tremaining: 12.2s\n",
      "3596:\tlearn: 1.3291067\ttotal: 43.7s\tremaining: 12.2s\n",
      "3597:\tlearn: 1.3289568\ttotal: 43.7s\tremaining: 12.1s\n",
      "3598:\tlearn: 1.3287185\ttotal: 43.7s\tremaining: 12.1s\n",
      "3599:\tlearn: 1.3285468\ttotal: 43.7s\tremaining: 12.1s\n",
      "3600:\tlearn: 1.3281980\ttotal: 43.7s\tremaining: 12.1s\n",
      "3601:\tlearn: 1.3279509\ttotal: 43.8s\tremaining: 12.1s\n",
      "3602:\tlearn: 1.3276369\ttotal: 43.8s\tremaining: 12.1s\n",
      "3603:\tlearn: 1.3274523\ttotal: 43.8s\tremaining: 12.1s\n",
      "3604:\tlearn: 1.3272808\ttotal: 43.8s\tremaining: 12.1s\n",
      "3605:\tlearn: 1.3269522\ttotal: 43.8s\tremaining: 12.1s\n",
      "3606:\tlearn: 1.3267527\ttotal: 43.8s\tremaining: 12s\n",
      "3607:\tlearn: 1.3264548\ttotal: 43.8s\tremaining: 12s\n",
      "3608:\tlearn: 1.3263096\ttotal: 43.8s\tremaining: 12s\n",
      "3609:\tlearn: 1.3262424\ttotal: 43.9s\tremaining: 12s\n",
      "3610:\tlearn: 1.3260623\ttotal: 43.9s\tremaining: 12s\n",
      "3611:\tlearn: 1.3259377\ttotal: 43.9s\tremaining: 12s\n",
      "3612:\tlearn: 1.3258462\ttotal: 43.9s\tremaining: 12s\n",
      "3613:\tlearn: 1.3256337\ttotal: 43.9s\tremaining: 12s\n",
      "3614:\tlearn: 1.3255073\ttotal: 43.9s\tremaining: 11.9s\n",
      "3615:\tlearn: 1.3252849\ttotal: 43.9s\tremaining: 11.9s\n",
      "3616:\tlearn: 1.3251140\ttotal: 43.9s\tremaining: 11.9s\n",
      "3617:\tlearn: 1.3249984\ttotal: 44s\tremaining: 11.9s\n",
      "3618:\tlearn: 1.3249047\ttotal: 44s\tremaining: 11.9s\n",
      "3619:\tlearn: 1.3247700\ttotal: 44s\tremaining: 11.9s\n",
      "3620:\tlearn: 1.3244893\ttotal: 44s\tremaining: 11.9s\n",
      "3621:\tlearn: 1.3241309\ttotal: 44s\tremaining: 11.9s\n",
      "3622:\tlearn: 1.3239876\ttotal: 44s\tremaining: 11.8s\n",
      "3623:\tlearn: 1.3238760\ttotal: 44s\tremaining: 11.8s\n",
      "3624:\tlearn: 1.3235937\ttotal: 44s\tremaining: 11.8s\n",
      "3625:\tlearn: 1.3234185\ttotal: 44.1s\tremaining: 11.8s\n",
      "3626:\tlearn: 1.3231802\ttotal: 44.1s\tremaining: 11.8s\n",
      "3627:\tlearn: 1.3230535\ttotal: 44.1s\tremaining: 11.8s\n",
      "3628:\tlearn: 1.3225915\ttotal: 44.1s\tremaining: 11.8s\n",
      "3629:\tlearn: 1.3225113\ttotal: 44.1s\tremaining: 11.8s\n",
      "3630:\tlearn: 1.3223768\ttotal: 44.1s\tremaining: 11.7s\n",
      "3631:\tlearn: 1.3222038\ttotal: 44.1s\tremaining: 11.7s\n",
      "3632:\tlearn: 1.3219457\ttotal: 44.1s\tremaining: 11.7s\n",
      "3633:\tlearn: 1.3219090\ttotal: 44.2s\tremaining: 11.7s\n",
      "3634:\tlearn: 1.3216911\ttotal: 44.2s\tremaining: 11.7s\n",
      "3635:\tlearn: 1.3214878\ttotal: 44.2s\tremaining: 11.7s\n",
      "3636:\tlearn: 1.3213530\ttotal: 44.2s\tremaining: 11.7s\n",
      "3637:\tlearn: 1.3210878\ttotal: 44.2s\tremaining: 11.7s\n",
      "3638:\tlearn: 1.3208469\ttotal: 44.2s\tremaining: 11.7s\n",
      "3639:\tlearn: 1.3205075\ttotal: 44.2s\tremaining: 11.6s\n",
      "3640:\tlearn: 1.3203522\ttotal: 44.2s\tremaining: 11.6s\n",
      "3641:\tlearn: 1.3201146\ttotal: 44.2s\tremaining: 11.6s\n",
      "3642:\tlearn: 1.3199764\ttotal: 44.3s\tremaining: 11.6s\n",
      "3643:\tlearn: 1.3196464\ttotal: 44.3s\tremaining: 11.6s\n",
      "3644:\tlearn: 1.3195393\ttotal: 44.3s\tremaining: 11.6s\n",
      "3645:\tlearn: 1.3193562\ttotal: 44.3s\tremaining: 11.6s\n",
      "3646:\tlearn: 1.3192070\ttotal: 44.3s\tremaining: 11.6s\n",
      "3647:\tlearn: 1.3190685\ttotal: 44.3s\tremaining: 11.5s\n",
      "3648:\tlearn: 1.3189848\ttotal: 44.3s\tremaining: 11.5s\n",
      "3649:\tlearn: 1.3188626\ttotal: 44.3s\tremaining: 11.5s\n",
      "3650:\tlearn: 1.3187400\ttotal: 44.4s\tremaining: 11.5s\n",
      "3651:\tlearn: 1.3184709\ttotal: 44.4s\tremaining: 11.5s\n",
      "3652:\tlearn: 1.3183328\ttotal: 44.4s\tremaining: 11.5s\n",
      "3653:\tlearn: 1.3181233\ttotal: 44.4s\tremaining: 11.5s\n",
      "3654:\tlearn: 1.3180143\ttotal: 44.4s\tremaining: 11.5s\n",
      "3655:\tlearn: 1.3177403\ttotal: 44.4s\tremaining: 11.4s\n",
      "3656:\tlearn: 1.3175697\ttotal: 44.4s\tremaining: 11.4s\n",
      "3657:\tlearn: 1.3174161\ttotal: 44.4s\tremaining: 11.4s\n",
      "3658:\tlearn: 1.3172176\ttotal: 44.5s\tremaining: 11.4s\n",
      "3659:\tlearn: 1.3171194\ttotal: 44.5s\tremaining: 11.4s\n",
      "3660:\tlearn: 1.3167919\ttotal: 44.5s\tremaining: 11.4s\n",
      "3661:\tlearn: 1.3166441\ttotal: 44.5s\tremaining: 11.4s\n",
      "3662:\tlearn: 1.3164647\ttotal: 44.5s\tremaining: 11.4s\n",
      "3663:\tlearn: 1.3163973\ttotal: 44.5s\tremaining: 11.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3664:\tlearn: 1.3162292\ttotal: 44.5s\tremaining: 11.3s\n",
      "3665:\tlearn: 1.3158583\ttotal: 44.5s\tremaining: 11.3s\n",
      "3666:\tlearn: 1.3157002\ttotal: 44.6s\tremaining: 11.3s\n",
      "3667:\tlearn: 1.3155573\ttotal: 44.6s\tremaining: 11.3s\n",
      "3668:\tlearn: 1.3152574\ttotal: 44.6s\tremaining: 11.3s\n",
      "3669:\tlearn: 1.3149827\ttotal: 44.6s\tremaining: 11.3s\n",
      "3670:\tlearn: 1.3148107\ttotal: 44.6s\tremaining: 11.3s\n",
      "3671:\tlearn: 1.3146300\ttotal: 44.6s\tremaining: 11.3s\n",
      "3672:\tlearn: 1.3145216\ttotal: 44.6s\tremaining: 11.2s\n",
      "3673:\tlearn: 1.3143729\ttotal: 44.7s\tremaining: 11.2s\n",
      "3674:\tlearn: 1.3141255\ttotal: 44.7s\tremaining: 11.2s\n",
      "3675:\tlearn: 1.3140623\ttotal: 44.7s\tremaining: 11.2s\n",
      "3676:\tlearn: 1.3140130\ttotal: 44.7s\tremaining: 11.2s\n",
      "3677:\tlearn: 1.3139102\ttotal: 44.7s\tremaining: 11.2s\n",
      "3678:\tlearn: 1.3136152\ttotal: 44.7s\tremaining: 11.2s\n",
      "3679:\tlearn: 1.3133927\ttotal: 44.7s\tremaining: 11.2s\n",
      "3680:\tlearn: 1.3130762\ttotal: 44.7s\tremaining: 11.1s\n",
      "3681:\tlearn: 1.3129336\ttotal: 44.8s\tremaining: 11.1s\n",
      "3682:\tlearn: 1.3127155\ttotal: 44.8s\tremaining: 11.1s\n",
      "3683:\tlearn: 1.3125810\ttotal: 44.8s\tremaining: 11.1s\n",
      "3684:\tlearn: 1.3124211\ttotal: 44.8s\tremaining: 11.1s\n",
      "3685:\tlearn: 1.3122856\ttotal: 44.8s\tremaining: 11.1s\n",
      "3686:\tlearn: 1.3121369\ttotal: 44.8s\tremaining: 11.1s\n",
      "3687:\tlearn: 1.3119689\ttotal: 44.8s\tremaining: 11.1s\n",
      "3688:\tlearn: 1.3118138\ttotal: 44.8s\tremaining: 11.1s\n",
      "3689:\tlearn: 1.3117424\ttotal: 44.9s\tremaining: 11s\n",
      "3690:\tlearn: 1.3116301\ttotal: 44.9s\tremaining: 11s\n",
      "3691:\tlearn: 1.3113169\ttotal: 44.9s\tremaining: 11s\n",
      "3692:\tlearn: 1.3111322\ttotal: 44.9s\tremaining: 11s\n",
      "3693:\tlearn: 1.3110398\ttotal: 44.9s\tremaining: 11s\n",
      "3694:\tlearn: 1.3109048\ttotal: 44.9s\tremaining: 11s\n",
      "3695:\tlearn: 1.3107088\ttotal: 44.9s\tremaining: 11s\n",
      "3696:\tlearn: 1.3106343\ttotal: 44.9s\tremaining: 11s\n",
      "3697:\tlearn: 1.3105561\ttotal: 44.9s\tremaining: 10.9s\n",
      "3698:\tlearn: 1.3103068\ttotal: 45s\tremaining: 10.9s\n",
      "3699:\tlearn: 1.3101560\ttotal: 45s\tremaining: 10.9s\n",
      "3700:\tlearn: 1.3099831\ttotal: 45s\tremaining: 10.9s\n",
      "3701:\tlearn: 1.3096241\ttotal: 45s\tremaining: 10.9s\n",
      "3702:\tlearn: 1.3094486\ttotal: 45s\tremaining: 10.9s\n",
      "3703:\tlearn: 1.3091526\ttotal: 45s\tremaining: 10.9s\n",
      "3704:\tlearn: 1.3091136\ttotal: 45s\tremaining: 10.9s\n",
      "3705:\tlearn: 1.3088887\ttotal: 45s\tremaining: 10.8s\n",
      "3706:\tlearn: 1.3087708\ttotal: 45.1s\tremaining: 10.8s\n",
      "3707:\tlearn: 1.3086447\ttotal: 45.1s\tremaining: 10.8s\n",
      "3708:\tlearn: 1.3084561\ttotal: 45.1s\tremaining: 10.8s\n",
      "3709:\tlearn: 1.3083060\ttotal: 45.1s\tremaining: 10.8s\n",
      "3710:\tlearn: 1.3081680\ttotal: 45.1s\tremaining: 10.8s\n",
      "3711:\tlearn: 1.3080110\ttotal: 45.1s\tremaining: 10.8s\n",
      "3712:\tlearn: 1.3078497\ttotal: 45.1s\tremaining: 10.8s\n",
      "3713:\tlearn: 1.3077335\ttotal: 45.1s\tremaining: 10.7s\n",
      "3714:\tlearn: 1.3074840\ttotal: 45.2s\tremaining: 10.7s\n",
      "3715:\tlearn: 1.3072703\ttotal: 45.2s\tremaining: 10.7s\n",
      "3716:\tlearn: 1.3071443\ttotal: 45.2s\tremaining: 10.7s\n",
      "3717:\tlearn: 1.3069997\ttotal: 45.2s\tremaining: 10.7s\n",
      "3718:\tlearn: 1.3069937\ttotal: 45.2s\tremaining: 10.7s\n",
      "3719:\tlearn: 1.3068523\ttotal: 45.2s\tremaining: 10.7s\n",
      "3720:\tlearn: 1.3066844\ttotal: 45.2s\tremaining: 10.7s\n",
      "3721:\tlearn: 1.3065055\ttotal: 45.2s\tremaining: 10.6s\n",
      "3722:\tlearn: 1.3063504\ttotal: 45.3s\tremaining: 10.6s\n",
      "3723:\tlearn: 1.3062789\ttotal: 45.3s\tremaining: 10.6s\n",
      "3724:\tlearn: 1.3060635\ttotal: 45.3s\tremaining: 10.6s\n",
      "3725:\tlearn: 1.3058336\ttotal: 45.3s\tremaining: 10.6s\n",
      "3726:\tlearn: 1.3055591\ttotal: 45.3s\tremaining: 10.6s\n",
      "3727:\tlearn: 1.3054953\ttotal: 45.3s\tremaining: 10.6s\n",
      "3728:\tlearn: 1.3052635\ttotal: 45.3s\tremaining: 10.6s\n",
      "3729:\tlearn: 1.3048307\ttotal: 45.3s\tremaining: 10.6s\n",
      "3730:\tlearn: 1.3047250\ttotal: 45.3s\tremaining: 10.5s\n",
      "3731:\tlearn: 1.3045983\ttotal: 45.4s\tremaining: 10.5s\n",
      "3732:\tlearn: 1.3044825\ttotal: 45.4s\tremaining: 10.5s\n",
      "3733:\tlearn: 1.3042517\ttotal: 45.4s\tremaining: 10.5s\n",
      "3734:\tlearn: 1.3040480\ttotal: 45.4s\tremaining: 10.5s\n",
      "3735:\tlearn: 1.3036933\ttotal: 45.4s\tremaining: 10.5s\n",
      "3736:\tlearn: 1.3035672\ttotal: 45.4s\tremaining: 10.5s\n",
      "3737:\tlearn: 1.3032993\ttotal: 45.5s\tremaining: 10.5s\n",
      "3738:\tlearn: 1.3031391\ttotal: 45.5s\tremaining: 10.4s\n",
      "3739:\tlearn: 1.3028751\ttotal: 45.5s\tremaining: 10.4s\n",
      "3740:\tlearn: 1.3025630\ttotal: 45.5s\tremaining: 10.4s\n",
      "3741:\tlearn: 1.3022691\ttotal: 45.5s\tremaining: 10.4s\n",
      "3742:\tlearn: 1.3019777\ttotal: 45.5s\tremaining: 10.4s\n",
      "3743:\tlearn: 1.3017838\ttotal: 45.5s\tremaining: 10.4s\n",
      "3744:\tlearn: 1.3014930\ttotal: 45.5s\tremaining: 10.4s\n",
      "3745:\tlearn: 1.3011282\ttotal: 45.6s\tremaining: 10.4s\n",
      "3746:\tlearn: 1.3009702\ttotal: 45.6s\tremaining: 10.3s\n",
      "3747:\tlearn: 1.3007516\ttotal: 45.6s\tremaining: 10.3s\n",
      "3748:\tlearn: 1.3005239\ttotal: 45.6s\tremaining: 10.3s\n",
      "3749:\tlearn: 1.3002786\ttotal: 45.6s\tremaining: 10.3s\n",
      "3750:\tlearn: 1.3000766\ttotal: 45.6s\tremaining: 10.3s\n",
      "3751:\tlearn: 1.2997201\ttotal: 45.6s\tremaining: 10.3s\n",
      "3752:\tlearn: 1.2994833\ttotal: 45.6s\tremaining: 10.3s\n",
      "3753:\tlearn: 1.2990196\ttotal: 45.7s\tremaining: 10.3s\n",
      "3754:\tlearn: 1.2989332\ttotal: 45.7s\tremaining: 10.3s\n",
      "3755:\tlearn: 1.2988412\ttotal: 45.7s\tremaining: 10.2s\n",
      "3756:\tlearn: 1.2984738\ttotal: 45.7s\tremaining: 10.2s\n",
      "3757:\tlearn: 1.2982456\ttotal: 45.7s\tremaining: 10.2s\n",
      "3758:\tlearn: 1.2981206\ttotal: 45.7s\tremaining: 10.2s\n",
      "3759:\tlearn: 1.2978436\ttotal: 45.7s\tremaining: 10.2s\n",
      "3760:\tlearn: 1.2977562\ttotal: 45.7s\tremaining: 10.2s\n",
      "3761:\tlearn: 1.2975611\ttotal: 45.8s\tremaining: 10.2s\n",
      "3762:\tlearn: 1.2973479\ttotal: 45.8s\tremaining: 10.2s\n",
      "3763:\tlearn: 1.2971654\ttotal: 45.8s\tremaining: 10.1s\n",
      "3764:\tlearn: 1.2970161\ttotal: 45.8s\tremaining: 10.1s\n",
      "3765:\tlearn: 1.2968081\ttotal: 45.8s\tremaining: 10.1s\n",
      "3766:\tlearn: 1.2967574\ttotal: 45.8s\tremaining: 10.1s\n",
      "3767:\tlearn: 1.2965623\ttotal: 45.8s\tremaining: 10.1s\n",
      "3768:\tlearn: 1.2964071\ttotal: 45.8s\tremaining: 10.1s\n",
      "3769:\tlearn: 1.2962639\ttotal: 45.9s\tremaining: 10.1s\n",
      "3770:\tlearn: 1.2961489\ttotal: 45.9s\tremaining: 10.1s\n",
      "3771:\tlearn: 1.2959356\ttotal: 45.9s\tremaining: 10s\n",
      "3772:\tlearn: 1.2957198\ttotal: 45.9s\tremaining: 10s\n",
      "3773:\tlearn: 1.2955401\ttotal: 45.9s\tremaining: 10s\n",
      "3774:\tlearn: 1.2953695\ttotal: 45.9s\tremaining: 10s\n",
      "3775:\tlearn: 1.2952602\ttotal: 45.9s\tremaining: 10s\n",
      "3776:\tlearn: 1.2951221\ttotal: 45.9s\tremaining: 9.98s\n",
      "3777:\tlearn: 1.2950550\ttotal: 45.9s\tremaining: 9.97s\n",
      "3778:\tlearn: 1.2949023\ttotal: 46s\tremaining: 9.96s\n",
      "3779:\tlearn: 1.2947076\ttotal: 46s\tremaining: 9.95s\n",
      "3780:\tlearn: 1.2944490\ttotal: 46s\tremaining: 9.94s\n",
      "3781:\tlearn: 1.2942452\ttotal: 46s\tremaining: 9.92s\n",
      "3782:\tlearn: 1.2938753\ttotal: 46s\tremaining: 9.91s\n",
      "3783:\tlearn: 1.2936819\ttotal: 46s\tremaining: 9.9s\n",
      "3784:\tlearn: 1.2935237\ttotal: 46s\tremaining: 9.89s\n",
      "3785:\tlearn: 1.2933317\ttotal: 46s\tremaining: 9.87s\n",
      "3786:\tlearn: 1.2930079\ttotal: 46.1s\tremaining: 9.86s\n",
      "3787:\tlearn: 1.2927795\ttotal: 46.1s\tremaining: 9.85s\n",
      "3788:\tlearn: 1.2925745\ttotal: 46.1s\tremaining: 9.84s\n",
      "3789:\tlearn: 1.2925007\ttotal: 46.1s\tremaining: 9.83s\n",
      "3790:\tlearn: 1.2923840\ttotal: 46.1s\tremaining: 9.81s\n",
      "3791:\tlearn: 1.2922336\ttotal: 46.1s\tremaining: 9.8s\n",
      "3792:\tlearn: 1.2921725\ttotal: 46.1s\tremaining: 9.79s\n",
      "3793:\tlearn: 1.2920255\ttotal: 46.1s\tremaining: 9.78s\n",
      "3794:\tlearn: 1.2919062\ttotal: 46.1s\tremaining: 9.76s\n",
      "3795:\tlearn: 1.2918978\ttotal: 46.2s\tremaining: 9.75s\n",
      "3796:\tlearn: 1.2917230\ttotal: 46.2s\tremaining: 9.74s\n",
      "3797:\tlearn: 1.2916368\ttotal: 46.2s\tremaining: 9.73s\n",
      "3798:\tlearn: 1.2914362\ttotal: 46.2s\tremaining: 9.71s\n",
      "3799:\tlearn: 1.2912251\ttotal: 46.2s\tremaining: 9.7s\n",
      "3800:\tlearn: 1.2910129\ttotal: 46.2s\tremaining: 9.69s\n",
      "3801:\tlearn: 1.2909498\ttotal: 46.2s\tremaining: 9.68s\n",
      "3802:\tlearn: 1.2908873\ttotal: 46.2s\tremaining: 9.66s\n",
      "3803:\tlearn: 1.2903829\ttotal: 46.3s\tremaining: 9.65s\n",
      "3804:\tlearn: 1.2902846\ttotal: 46.3s\tremaining: 9.64s\n",
      "3805:\tlearn: 1.2900897\ttotal: 46.3s\tremaining: 9.63s\n",
      "3806:\tlearn: 1.2899631\ttotal: 46.3s\tremaining: 9.62s\n",
      "3807:\tlearn: 1.2897342\ttotal: 46.3s\tremaining: 9.61s\n",
      "3808:\tlearn: 1.2896181\ttotal: 46.3s\tremaining: 9.59s\n",
      "3809:\tlearn: 1.2894626\ttotal: 46.3s\tremaining: 9.58s\n",
      "3810:\tlearn: 1.2892113\ttotal: 46.3s\tremaining: 9.57s\n",
      "3811:\tlearn: 1.2890008\ttotal: 46.3s\tremaining: 9.56s\n",
      "3812:\tlearn: 1.2889494\ttotal: 46.4s\tremaining: 9.54s\n",
      "3813:\tlearn: 1.2885633\ttotal: 46.4s\tremaining: 9.53s\n",
      "3814:\tlearn: 1.2883411\ttotal: 46.4s\tremaining: 9.52s\n",
      "3815:\tlearn: 1.2882492\ttotal: 46.4s\tremaining: 9.51s\n",
      "3816:\tlearn: 1.2881362\ttotal: 46.4s\tremaining: 9.49s\n",
      "3817:\tlearn: 1.2880060\ttotal: 46.4s\tremaining: 9.48s\n",
      "3818:\tlearn: 1.2877465\ttotal: 46.4s\tremaining: 9.47s\n",
      "3819:\tlearn: 1.2876268\ttotal: 46.4s\tremaining: 9.46s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3820:\tlearn: 1.2874376\ttotal: 46.5s\tremaining: 9.45s\n",
      "3821:\tlearn: 1.2871740\ttotal: 46.5s\tremaining: 9.44s\n",
      "3822:\tlearn: 1.2870512\ttotal: 46.5s\tremaining: 9.42s\n",
      "3823:\tlearn: 1.2868878\ttotal: 46.5s\tremaining: 9.41s\n",
      "3824:\tlearn: 1.2866762\ttotal: 46.5s\tremaining: 9.4s\n",
      "3825:\tlearn: 1.2865836\ttotal: 46.5s\tremaining: 9.39s\n",
      "3826:\tlearn: 1.2863434\ttotal: 46.5s\tremaining: 9.37s\n",
      "3827:\tlearn: 1.2862132\ttotal: 46.5s\tremaining: 9.36s\n",
      "3828:\tlearn: 1.2860915\ttotal: 46.6s\tremaining: 9.35s\n",
      "3829:\tlearn: 1.2860578\ttotal: 46.6s\tremaining: 9.34s\n",
      "3830:\tlearn: 1.2858785\ttotal: 46.6s\tremaining: 9.32s\n",
      "3831:\tlearn: 1.2857124\ttotal: 46.6s\tremaining: 9.31s\n",
      "3832:\tlearn: 1.2856120\ttotal: 46.6s\tremaining: 9.3s\n",
      "3833:\tlearn: 1.2854719\ttotal: 46.6s\tremaining: 9.29s\n",
      "3834:\tlearn: 1.2851872\ttotal: 46.6s\tremaining: 9.28s\n",
      "3835:\tlearn: 1.2848642\ttotal: 46.6s\tremaining: 9.26s\n",
      "3836:\tlearn: 1.2847155\ttotal: 46.6s\tremaining: 9.25s\n",
      "3837:\tlearn: 1.2846294\ttotal: 46.7s\tremaining: 9.24s\n",
      "3838:\tlearn: 1.2844662\ttotal: 46.7s\tremaining: 9.23s\n",
      "3839:\tlearn: 1.2842345\ttotal: 46.7s\tremaining: 9.21s\n",
      "3840:\tlearn: 1.2839354\ttotal: 46.7s\tremaining: 9.2s\n",
      "3841:\tlearn: 1.2837639\ttotal: 46.7s\tremaining: 9.19s\n",
      "3842:\tlearn: 1.2836349\ttotal: 46.7s\tremaining: 9.18s\n",
      "3843:\tlearn: 1.2835563\ttotal: 46.7s\tremaining: 9.17s\n",
      "3844:\tlearn: 1.2834394\ttotal: 46.7s\tremaining: 9.15s\n",
      "3845:\tlearn: 1.2833456\ttotal: 46.8s\tremaining: 9.14s\n",
      "3846:\tlearn: 1.2833154\ttotal: 46.8s\tremaining: 9.13s\n",
      "3847:\tlearn: 1.2832320\ttotal: 46.8s\tremaining: 9.12s\n",
      "3848:\tlearn: 1.2831071\ttotal: 46.8s\tremaining: 9.11s\n",
      "3849:\tlearn: 1.2828470\ttotal: 46.8s\tremaining: 9.09s\n",
      "3850:\tlearn: 1.2826915\ttotal: 46.8s\tremaining: 9.08s\n",
      "3851:\tlearn: 1.2824340\ttotal: 46.8s\tremaining: 9.07s\n",
      "3852:\tlearn: 1.2822632\ttotal: 46.8s\tremaining: 9.06s\n",
      "3853:\tlearn: 1.2821889\ttotal: 46.9s\tremaining: 9.04s\n",
      "3854:\tlearn: 1.2819991\ttotal: 46.9s\tremaining: 9.03s\n",
      "3855:\tlearn: 1.2817382\ttotal: 46.9s\tremaining: 9.02s\n",
      "3856:\tlearn: 1.2815082\ttotal: 46.9s\tremaining: 9.01s\n",
      "3857:\tlearn: 1.2813263\ttotal: 46.9s\tremaining: 9s\n",
      "3858:\tlearn: 1.2811921\ttotal: 46.9s\tremaining: 8.98s\n",
      "3859:\tlearn: 1.2808771\ttotal: 46.9s\tremaining: 8.97s\n",
      "3860:\tlearn: 1.2807830\ttotal: 46.9s\tremaining: 8.96s\n",
      "3861:\tlearn: 1.2806683\ttotal: 47s\tremaining: 8.95s\n",
      "3862:\tlearn: 1.2802570\ttotal: 47s\tremaining: 8.94s\n",
      "3863:\tlearn: 1.2801024\ttotal: 47s\tremaining: 8.92s\n",
      "3864:\tlearn: 1.2799260\ttotal: 47s\tremaining: 8.91s\n",
      "3865:\tlearn: 1.2797060\ttotal: 47s\tremaining: 8.9s\n",
      "3866:\tlearn: 1.2793515\ttotal: 47s\tremaining: 8.89s\n",
      "3867:\tlearn: 1.2789379\ttotal: 47s\tremaining: 8.88s\n",
      "3868:\tlearn: 1.2786862\ttotal: 47s\tremaining: 8.86s\n",
      "3869:\tlearn: 1.2785505\ttotal: 47s\tremaining: 8.85s\n",
      "3870:\tlearn: 1.2782729\ttotal: 47.1s\tremaining: 8.84s\n",
      "3871:\tlearn: 1.2781037\ttotal: 47.1s\tremaining: 8.83s\n",
      "3872:\tlearn: 1.2779827\ttotal: 47.1s\tremaining: 8.81s\n",
      "3873:\tlearn: 1.2778220\ttotal: 47.1s\tremaining: 8.8s\n",
      "3874:\tlearn: 1.2777459\ttotal: 47.1s\tremaining: 8.79s\n",
      "3875:\tlearn: 1.2775449\ttotal: 47.1s\tremaining: 8.78s\n",
      "3876:\tlearn: 1.2775244\ttotal: 47.1s\tremaining: 8.77s\n",
      "3877:\tlearn: 1.2773426\ttotal: 47.1s\tremaining: 8.75s\n",
      "3878:\tlearn: 1.2770812\ttotal: 47.2s\tremaining: 8.74s\n",
      "3879:\tlearn: 1.2768643\ttotal: 47.2s\tremaining: 8.73s\n",
      "3880:\tlearn: 1.2767650\ttotal: 47.2s\tremaining: 8.72s\n",
      "3881:\tlearn: 1.2765567\ttotal: 47.2s\tremaining: 8.7s\n",
      "3882:\tlearn: 1.2763558\ttotal: 47.2s\tremaining: 8.69s\n",
      "3883:\tlearn: 1.2762345\ttotal: 47.2s\tremaining: 8.68s\n",
      "3884:\tlearn: 1.2761383\ttotal: 47.2s\tremaining: 8.67s\n",
      "3885:\tlearn: 1.2759819\ttotal: 47.2s\tremaining: 8.65s\n",
      "3886:\tlearn: 1.2759141\ttotal: 47.3s\tremaining: 8.64s\n",
      "3887:\tlearn: 1.2757085\ttotal: 47.3s\tremaining: 8.63s\n",
      "3888:\tlearn: 1.2755247\ttotal: 47.3s\tremaining: 8.62s\n",
      "3889:\tlearn: 1.2754177\ttotal: 47.3s\tremaining: 8.61s\n",
      "3890:\tlearn: 1.2752315\ttotal: 47.3s\tremaining: 8.59s\n",
      "3891:\tlearn: 1.2751021\ttotal: 47.3s\tremaining: 8.58s\n",
      "3892:\tlearn: 1.2749234\ttotal: 47.3s\tremaining: 8.57s\n",
      "3893:\tlearn: 1.2747261\ttotal: 47.3s\tremaining: 8.56s\n",
      "3894:\tlearn: 1.2745608\ttotal: 47.3s\tremaining: 8.54s\n",
      "3895:\tlearn: 1.2744262\ttotal: 47.4s\tremaining: 8.53s\n",
      "3896:\tlearn: 1.2742739\ttotal: 47.4s\tremaining: 8.52s\n",
      "3897:\tlearn: 1.2741569\ttotal: 47.4s\tremaining: 8.51s\n",
      "3898:\tlearn: 1.2739684\ttotal: 47.4s\tremaining: 8.5s\n",
      "3899:\tlearn: 1.2738290\ttotal: 47.4s\tremaining: 8.48s\n",
      "3900:\tlearn: 1.2737341\ttotal: 47.4s\tremaining: 8.47s\n",
      "3901:\tlearn: 1.2735269\ttotal: 47.4s\tremaining: 8.46s\n",
      "3902:\tlearn: 1.2731994\ttotal: 47.4s\tremaining: 8.45s\n",
      "3903:\tlearn: 1.2730466\ttotal: 47.5s\tremaining: 8.44s\n",
      "3904:\tlearn: 1.2730063\ttotal: 47.5s\tremaining: 8.42s\n",
      "3905:\tlearn: 1.2728943\ttotal: 47.5s\tremaining: 8.41s\n",
      "3906:\tlearn: 1.2727400\ttotal: 47.5s\tremaining: 8.4s\n",
      "3907:\tlearn: 1.2726114\ttotal: 47.5s\tremaining: 8.39s\n",
      "3908:\tlearn: 1.2725450\ttotal: 47.5s\tremaining: 8.38s\n",
      "3909:\tlearn: 1.2723947\ttotal: 47.5s\tremaining: 8.36s\n",
      "3910:\tlearn: 1.2722048\ttotal: 47.5s\tremaining: 8.35s\n",
      "3911:\tlearn: 1.2720297\ttotal: 47.6s\tremaining: 8.34s\n",
      "3912:\tlearn: 1.2719149\ttotal: 47.6s\tremaining: 8.33s\n",
      "3913:\tlearn: 1.2717817\ttotal: 47.6s\tremaining: 8.31s\n",
      "3914:\tlearn: 1.2716281\ttotal: 47.6s\tremaining: 8.3s\n",
      "3915:\tlearn: 1.2714079\ttotal: 47.6s\tremaining: 8.29s\n",
      "3916:\tlearn: 1.2713616\ttotal: 47.6s\tremaining: 8.28s\n",
      "3917:\tlearn: 1.2712656\ttotal: 47.6s\tremaining: 8.27s\n",
      "3918:\tlearn: 1.2711250\ttotal: 47.6s\tremaining: 8.25s\n",
      "3919:\tlearn: 1.2710627\ttotal: 47.6s\tremaining: 8.24s\n",
      "3920:\tlearn: 1.2709616\ttotal: 47.7s\tremaining: 8.23s\n",
      "3921:\tlearn: 1.2707302\ttotal: 47.7s\tremaining: 8.22s\n",
      "3922:\tlearn: 1.2704725\ttotal: 47.7s\tremaining: 8.21s\n",
      "3923:\tlearn: 1.2702362\ttotal: 47.7s\tremaining: 8.19s\n",
      "3924:\tlearn: 1.2701468\ttotal: 47.7s\tremaining: 8.18s\n",
      "3925:\tlearn: 1.2698289\ttotal: 47.7s\tremaining: 8.17s\n",
      "3926:\tlearn: 1.2696931\ttotal: 47.7s\tremaining: 8.16s\n",
      "3927:\tlearn: 1.2694921\ttotal: 47.7s\tremaining: 8.14s\n",
      "3928:\tlearn: 1.2693616\ttotal: 47.8s\tremaining: 8.13s\n",
      "3929:\tlearn: 1.2691718\ttotal: 47.8s\tremaining: 8.12s\n",
      "3930:\tlearn: 1.2689134\ttotal: 47.8s\tremaining: 8.11s\n",
      "3931:\tlearn: 1.2686244\ttotal: 47.8s\tremaining: 8.1s\n",
      "3932:\tlearn: 1.2684036\ttotal: 47.8s\tremaining: 8.08s\n",
      "3933:\tlearn: 1.2682825\ttotal: 47.8s\tremaining: 8.07s\n",
      "3934:\tlearn: 1.2682295\ttotal: 47.8s\tremaining: 8.06s\n",
      "3935:\tlearn: 1.2681287\ttotal: 47.8s\tremaining: 8.05s\n",
      "3936:\tlearn: 1.2677242\ttotal: 47.9s\tremaining: 8.04s\n",
      "3937:\tlearn: 1.2676568\ttotal: 47.9s\tremaining: 8.02s\n",
      "3938:\tlearn: 1.2674683\ttotal: 47.9s\tremaining: 8.01s\n",
      "3939:\tlearn: 1.2671787\ttotal: 47.9s\tremaining: 8s\n",
      "3940:\tlearn: 1.2670744\ttotal: 47.9s\tremaining: 7.99s\n",
      "3941:\tlearn: 1.2668631\ttotal: 47.9s\tremaining: 7.97s\n",
      "3942:\tlearn: 1.2666170\ttotal: 47.9s\tremaining: 7.96s\n",
      "3943:\tlearn: 1.2664661\ttotal: 47.9s\tremaining: 7.95s\n",
      "3944:\tlearn: 1.2661093\ttotal: 48s\tremaining: 7.94s\n",
      "3945:\tlearn: 1.2660600\ttotal: 48s\tremaining: 7.92s\n",
      "3946:\tlearn: 1.2659244\ttotal: 48s\tremaining: 7.91s\n",
      "3947:\tlearn: 1.2658327\ttotal: 48s\tremaining: 7.9s\n",
      "3948:\tlearn: 1.2657232\ttotal: 48s\tremaining: 7.89s\n",
      "3949:\tlearn: 1.2655477\ttotal: 48s\tremaining: 7.88s\n",
      "3950:\tlearn: 1.2654518\ttotal: 48s\tremaining: 7.86s\n",
      "3951:\tlearn: 1.2653748\ttotal: 48s\tremaining: 7.85s\n",
      "3952:\tlearn: 1.2649347\ttotal: 48.1s\tremaining: 7.84s\n",
      "3953:\tlearn: 1.2647060\ttotal: 48.1s\tremaining: 7.83s\n",
      "3954:\tlearn: 1.2645667\ttotal: 48.1s\tremaining: 7.82s\n",
      "3955:\tlearn: 1.2643540\ttotal: 48.1s\tremaining: 7.8s\n",
      "3956:\tlearn: 1.2638263\ttotal: 48.1s\tremaining: 7.79s\n",
      "3957:\tlearn: 1.2635640\ttotal: 48.1s\tremaining: 7.78s\n",
      "3958:\tlearn: 1.2633058\ttotal: 48.1s\tremaining: 7.77s\n",
      "3959:\tlearn: 1.2632381\ttotal: 48.1s\tremaining: 7.75s\n",
      "3960:\tlearn: 1.2630776\ttotal: 48.1s\tremaining: 7.74s\n",
      "3961:\tlearn: 1.2629904\ttotal: 48.2s\tremaining: 7.73s\n",
      "3962:\tlearn: 1.2629227\ttotal: 48.2s\tremaining: 7.72s\n",
      "3963:\tlearn: 1.2627434\ttotal: 48.2s\tremaining: 7.71s\n",
      "3964:\tlearn: 1.2624607\ttotal: 48.2s\tremaining: 7.69s\n",
      "3965:\tlearn: 1.2622044\ttotal: 48.2s\tremaining: 7.68s\n",
      "3966:\tlearn: 1.2619914\ttotal: 48.2s\tremaining: 7.67s\n",
      "3967:\tlearn: 1.2617938\ttotal: 48.2s\tremaining: 7.66s\n",
      "3968:\tlearn: 1.2617067\ttotal: 48.2s\tremaining: 7.65s\n",
      "3969:\tlearn: 1.2614318\ttotal: 48.3s\tremaining: 7.63s\n",
      "3970:\tlearn: 1.2612847\ttotal: 48.3s\tremaining: 7.62s\n",
      "3971:\tlearn: 1.2609095\ttotal: 48.3s\tremaining: 7.61s\n",
      "3972:\tlearn: 1.2607020\ttotal: 48.3s\tremaining: 7.6s\n",
      "3973:\tlearn: 1.2604228\ttotal: 48.3s\tremaining: 7.58s\n",
      "3974:\tlearn: 1.2600332\ttotal: 48.3s\tremaining: 7.57s\n",
      "3975:\tlearn: 1.2599399\ttotal: 48.3s\tremaining: 7.56s\n",
      "3976:\tlearn: 1.2598045\ttotal: 48.3s\tremaining: 7.55s\n",
      "3977:\tlearn: 1.2597541\ttotal: 48.4s\tremaining: 7.54s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3978:\tlearn: 1.2594213\ttotal: 48.4s\tremaining: 7.52s\n",
      "3979:\tlearn: 1.2591448\ttotal: 48.4s\tremaining: 7.51s\n",
      "3980:\tlearn: 1.2589867\ttotal: 48.4s\tremaining: 7.5s\n",
      "3981:\tlearn: 1.2589195\ttotal: 48.4s\tremaining: 7.49s\n",
      "3982:\tlearn: 1.2587443\ttotal: 48.4s\tremaining: 7.48s\n",
      "3983:\tlearn: 1.2586034\ttotal: 48.4s\tremaining: 7.46s\n",
      "3984:\tlearn: 1.2584664\ttotal: 48.4s\tremaining: 7.45s\n",
      "3985:\tlearn: 1.2583865\ttotal: 48.5s\tremaining: 7.44s\n",
      "3986:\tlearn: 1.2582737\ttotal: 48.5s\tremaining: 7.43s\n",
      "3987:\tlearn: 1.2580606\ttotal: 48.5s\tremaining: 7.42s\n",
      "3988:\tlearn: 1.2578758\ttotal: 48.5s\tremaining: 7.4s\n",
      "3989:\tlearn: 1.2577472\ttotal: 48.5s\tremaining: 7.39s\n",
      "3990:\tlearn: 1.2575843\ttotal: 48.5s\tremaining: 7.38s\n",
      "3991:\tlearn: 1.2574192\ttotal: 48.5s\tremaining: 7.37s\n",
      "3992:\tlearn: 1.2571269\ttotal: 48.5s\tremaining: 7.35s\n",
      "3993:\tlearn: 1.2569747\ttotal: 48.6s\tremaining: 7.34s\n",
      "3994:\tlearn: 1.2568724\ttotal: 48.6s\tremaining: 7.33s\n",
      "3995:\tlearn: 1.2567252\ttotal: 48.6s\tremaining: 7.32s\n",
      "3996:\tlearn: 1.2565452\ttotal: 48.6s\tremaining: 7.31s\n",
      "3997:\tlearn: 1.2563765\ttotal: 48.6s\tremaining: 7.29s\n",
      "3998:\tlearn: 1.2562840\ttotal: 48.6s\tremaining: 7.28s\n",
      "3999:\tlearn: 1.2560963\ttotal: 48.6s\tremaining: 7.27s\n",
      "4000:\tlearn: 1.2558678\ttotal: 48.6s\tremaining: 7.26s\n",
      "4001:\tlearn: 1.2556835\ttotal: 48.6s\tremaining: 7.25s\n",
      "4002:\tlearn: 1.2555168\ttotal: 48.7s\tremaining: 7.23s\n",
      "4003:\tlearn: 1.2553652\ttotal: 48.7s\tremaining: 7.22s\n",
      "4004:\tlearn: 1.2552517\ttotal: 48.7s\tremaining: 7.21s\n",
      "4005:\tlearn: 1.2551535\ttotal: 48.7s\tremaining: 7.2s\n",
      "4006:\tlearn: 1.2550186\ttotal: 48.7s\tremaining: 7.18s\n",
      "4007:\tlearn: 1.2549376\ttotal: 48.7s\tremaining: 7.17s\n",
      "4008:\tlearn: 1.2547872\ttotal: 48.7s\tremaining: 7.16s\n",
      "4009:\tlearn: 1.2546027\ttotal: 48.7s\tremaining: 7.15s\n",
      "4010:\tlearn: 1.2544204\ttotal: 48.8s\tremaining: 7.13s\n",
      "4011:\tlearn: 1.2543501\ttotal: 48.8s\tremaining: 7.12s\n",
      "4012:\tlearn: 1.2542646\ttotal: 48.8s\tremaining: 7.11s\n",
      "4013:\tlearn: 1.2541046\ttotal: 48.8s\tremaining: 7.1s\n",
      "4014:\tlearn: 1.2537277\ttotal: 48.8s\tremaining: 7.09s\n",
      "4015:\tlearn: 1.2536629\ttotal: 48.8s\tremaining: 7.07s\n",
      "4016:\tlearn: 1.2534442\ttotal: 48.8s\tremaining: 7.06s\n",
      "4017:\tlearn: 1.2530647\ttotal: 48.8s\tremaining: 7.05s\n",
      "4018:\tlearn: 1.2528956\ttotal: 48.9s\tremaining: 7.04s\n",
      "4019:\tlearn: 1.2527575\ttotal: 48.9s\tremaining: 7.03s\n",
      "4020:\tlearn: 1.2525778\ttotal: 48.9s\tremaining: 7.01s\n",
      "4021:\tlearn: 1.2521688\ttotal: 48.9s\tremaining: 7s\n",
      "4022:\tlearn: 1.2520176\ttotal: 48.9s\tremaining: 6.99s\n",
      "4023:\tlearn: 1.2519849\ttotal: 48.9s\tremaining: 6.98s\n",
      "4024:\tlearn: 1.2519032\ttotal: 48.9s\tremaining: 6.96s\n",
      "4025:\tlearn: 1.2516438\ttotal: 48.9s\tremaining: 6.95s\n",
      "4026:\tlearn: 1.2515146\ttotal: 48.9s\tremaining: 6.94s\n",
      "4027:\tlearn: 1.2513662\ttotal: 49s\tremaining: 6.93s\n",
      "4028:\tlearn: 1.2512155\ttotal: 49s\tremaining: 6.92s\n",
      "4029:\tlearn: 1.2509257\ttotal: 49s\tremaining: 6.9s\n",
      "4030:\tlearn: 1.2507714\ttotal: 49s\tremaining: 6.89s\n",
      "4031:\tlearn: 1.2506583\ttotal: 49s\tremaining: 6.88s\n",
      "4032:\tlearn: 1.2505905\ttotal: 49s\tremaining: 6.87s\n",
      "4033:\tlearn: 1.2505112\ttotal: 49s\tremaining: 6.86s\n",
      "4034:\tlearn: 1.2502195\ttotal: 49s\tremaining: 6.84s\n",
      "4035:\tlearn: 1.2499790\ttotal: 49.1s\tremaining: 6.83s\n",
      "4036:\tlearn: 1.2498624\ttotal: 49.1s\tremaining: 6.82s\n",
      "4037:\tlearn: 1.2495743\ttotal: 49.1s\tremaining: 6.81s\n",
      "4038:\tlearn: 1.2492188\ttotal: 49.1s\tremaining: 6.79s\n",
      "4039:\tlearn: 1.2488905\ttotal: 49.1s\tremaining: 6.78s\n",
      "4040:\tlearn: 1.2487261\ttotal: 49.1s\tremaining: 6.77s\n",
      "4041:\tlearn: 1.2485344\ttotal: 49.1s\tremaining: 6.76s\n",
      "4042:\tlearn: 1.2483524\ttotal: 49.1s\tremaining: 6.75s\n",
      "4043:\tlearn: 1.2483305\ttotal: 49.2s\tremaining: 6.73s\n",
      "4044:\tlearn: 1.2482964\ttotal: 49.2s\tremaining: 6.72s\n",
      "4045:\tlearn: 1.2481345\ttotal: 49.2s\tremaining: 6.71s\n",
      "4046:\tlearn: 1.2477994\ttotal: 49.2s\tremaining: 6.7s\n",
      "4047:\tlearn: 1.2476395\ttotal: 49.2s\tremaining: 6.68s\n",
      "4048:\tlearn: 1.2474603\ttotal: 49.2s\tremaining: 6.67s\n",
      "4049:\tlearn: 1.2471688\ttotal: 49.2s\tremaining: 6.66s\n",
      "4050:\tlearn: 1.2470645\ttotal: 49.2s\tremaining: 6.65s\n",
      "4051:\tlearn: 1.2468712\ttotal: 49.3s\tremaining: 6.64s\n",
      "4052:\tlearn: 1.2466761\ttotal: 49.3s\tremaining: 6.62s\n",
      "4053:\tlearn: 1.2463103\ttotal: 49.3s\tremaining: 6.61s\n",
      "4054:\tlearn: 1.2460745\ttotal: 49.3s\tremaining: 6.6s\n",
      "4055:\tlearn: 1.2459163\ttotal: 49.3s\tremaining: 6.59s\n",
      "4056:\tlearn: 1.2457169\ttotal: 49.3s\tremaining: 6.58s\n",
      "4057:\tlearn: 1.2455468\ttotal: 49.3s\tremaining: 6.56s\n",
      "4058:\tlearn: 1.2454366\ttotal: 49.3s\tremaining: 6.55s\n",
      "4059:\tlearn: 1.2452247\ttotal: 49.4s\tremaining: 6.54s\n",
      "4060:\tlearn: 1.2451532\ttotal: 49.4s\tremaining: 6.53s\n",
      "4061:\tlearn: 1.2448699\ttotal: 49.4s\tremaining: 6.51s\n",
      "4062:\tlearn: 1.2447821\ttotal: 49.4s\tremaining: 6.5s\n",
      "4063:\tlearn: 1.2447248\ttotal: 49.4s\tremaining: 6.49s\n",
      "4064:\tlearn: 1.2445936\ttotal: 49.4s\tremaining: 6.48s\n",
      "4065:\tlearn: 1.2445222\ttotal: 49.4s\tremaining: 6.47s\n",
      "4066:\tlearn: 1.2443083\ttotal: 49.4s\tremaining: 6.45s\n",
      "4067:\tlearn: 1.2439602\ttotal: 49.4s\tremaining: 6.44s\n",
      "4068:\tlearn: 1.2439120\ttotal: 49.5s\tremaining: 6.43s\n",
      "4069:\tlearn: 1.2438224\ttotal: 49.5s\tremaining: 6.42s\n",
      "4070:\tlearn: 1.2435797\ttotal: 49.5s\tremaining: 6.41s\n",
      "4071:\tlearn: 1.2433129\ttotal: 49.5s\tremaining: 6.39s\n",
      "4072:\tlearn: 1.2431376\ttotal: 49.5s\tremaining: 6.38s\n",
      "4073:\tlearn: 1.2428994\ttotal: 49.5s\tremaining: 6.37s\n",
      "4074:\tlearn: 1.2428137\ttotal: 49.5s\tremaining: 6.36s\n",
      "4075:\tlearn: 1.2427314\ttotal: 49.5s\tremaining: 6.34s\n",
      "4076:\tlearn: 1.2426277\ttotal: 49.6s\tremaining: 6.33s\n",
      "4077:\tlearn: 1.2424699\ttotal: 49.6s\tremaining: 6.32s\n",
      "4078:\tlearn: 1.2423405\ttotal: 49.6s\tremaining: 6.31s\n",
      "4079:\tlearn: 1.2420606\ttotal: 49.6s\tremaining: 6.3s\n",
      "4080:\tlearn: 1.2419644\ttotal: 49.6s\tremaining: 6.28s\n",
      "4081:\tlearn: 1.2418345\ttotal: 49.6s\tremaining: 6.27s\n",
      "4082:\tlearn: 1.2416289\ttotal: 49.6s\tremaining: 6.26s\n",
      "4083:\tlearn: 1.2415481\ttotal: 49.6s\tremaining: 6.25s\n",
      "4084:\tlearn: 1.2414518\ttotal: 49.7s\tremaining: 6.24s\n",
      "4085:\tlearn: 1.2411657\ttotal: 49.7s\tremaining: 6.22s\n",
      "4086:\tlearn: 1.2411490\ttotal: 49.7s\tremaining: 6.21s\n",
      "4087:\tlearn: 1.2409135\ttotal: 49.7s\tremaining: 6.2s\n",
      "4088:\tlearn: 1.2408940\ttotal: 49.7s\tremaining: 6.19s\n",
      "4089:\tlearn: 1.2407214\ttotal: 49.7s\tremaining: 6.17s\n",
      "4090:\tlearn: 1.2405845\ttotal: 49.7s\tremaining: 6.16s\n",
      "4091:\tlearn: 1.2403565\ttotal: 49.7s\tremaining: 6.15s\n",
      "4092:\tlearn: 1.2402502\ttotal: 49.7s\tremaining: 6.14s\n",
      "4093:\tlearn: 1.2401042\ttotal: 49.8s\tremaining: 6.13s\n",
      "4094:\tlearn: 1.2400060\ttotal: 49.8s\tremaining: 6.11s\n",
      "4095:\tlearn: 1.2397739\ttotal: 49.8s\tremaining: 6.1s\n",
      "4096:\tlearn: 1.2394340\ttotal: 49.8s\tremaining: 6.09s\n",
      "4097:\tlearn: 1.2392057\ttotal: 49.8s\tremaining: 6.08s\n",
      "4098:\tlearn: 1.2391061\ttotal: 49.8s\tremaining: 6.06s\n",
      "4099:\tlearn: 1.2389942\ttotal: 49.8s\tremaining: 6.05s\n",
      "4100:\tlearn: 1.2388727\ttotal: 49.8s\tremaining: 6.04s\n",
      "4101:\tlearn: 1.2387234\ttotal: 49.9s\tremaining: 6.03s\n",
      "4102:\tlearn: 1.2384953\ttotal: 49.9s\tremaining: 6.02s\n",
      "4103:\tlearn: 1.2383411\ttotal: 49.9s\tremaining: 6s\n",
      "4104:\tlearn: 1.2381111\ttotal: 49.9s\tremaining: 5.99s\n",
      "4105:\tlearn: 1.2380118\ttotal: 49.9s\tremaining: 5.98s\n",
      "4106:\tlearn: 1.2377661\ttotal: 49.9s\tremaining: 5.97s\n",
      "4107:\tlearn: 1.2376669\ttotal: 49.9s\tremaining: 5.96s\n",
      "4108:\tlearn: 1.2374806\ttotal: 49.9s\tremaining: 5.94s\n",
      "4109:\tlearn: 1.2373876\ttotal: 50s\tremaining: 5.93s\n",
      "4110:\tlearn: 1.2371114\ttotal: 50s\tremaining: 5.92s\n",
      "4111:\tlearn: 1.2368579\ttotal: 50s\tremaining: 5.91s\n",
      "4112:\tlearn: 1.2367544\ttotal: 50s\tremaining: 5.89s\n",
      "4113:\tlearn: 1.2366396\ttotal: 50s\tremaining: 5.88s\n",
      "4114:\tlearn: 1.2365038\ttotal: 50s\tremaining: 5.87s\n",
      "4115:\tlearn: 1.2363898\ttotal: 50s\tremaining: 5.86s\n",
      "4116:\tlearn: 1.2363370\ttotal: 50s\tremaining: 5.84s\n",
      "4117:\tlearn: 1.2362501\ttotal: 50s\tremaining: 5.83s\n",
      "4118:\tlearn: 1.2361654\ttotal: 50.1s\tremaining: 5.82s\n",
      "4119:\tlearn: 1.2360230\ttotal: 50.1s\tremaining: 5.81s\n",
      "4120:\tlearn: 1.2359595\ttotal: 50.1s\tremaining: 5.8s\n",
      "4121:\tlearn: 1.2357437\ttotal: 50.1s\tremaining: 5.78s\n",
      "4122:\tlearn: 1.2356019\ttotal: 50.1s\tremaining: 5.77s\n",
      "4123:\tlearn: 1.2354215\ttotal: 50.1s\tremaining: 5.76s\n",
      "4124:\tlearn: 1.2352232\ttotal: 50.1s\tremaining: 5.75s\n",
      "4125:\tlearn: 1.2351049\ttotal: 50.1s\tremaining: 5.74s\n",
      "4126:\tlearn: 1.2349571\ttotal: 50.2s\tremaining: 5.72s\n",
      "4127:\tlearn: 1.2347124\ttotal: 50.2s\tremaining: 5.71s\n",
      "4128:\tlearn: 1.2347030\ttotal: 50.2s\tremaining: 5.7s\n",
      "4129:\tlearn: 1.2344654\ttotal: 50.2s\tremaining: 5.69s\n",
      "4130:\tlearn: 1.2343661\ttotal: 50.2s\tremaining: 5.67s\n",
      "4131:\tlearn: 1.2342192\ttotal: 50.2s\tremaining: 5.66s\n",
      "4132:\tlearn: 1.2340696\ttotal: 50.2s\tremaining: 5.65s\n",
      "4133:\tlearn: 1.2337951\ttotal: 50.2s\tremaining: 5.64s\n",
      "4134:\tlearn: 1.2336450\ttotal: 50.3s\tremaining: 5.63s\n",
      "4135:\tlearn: 1.2335673\ttotal: 50.3s\tremaining: 5.61s\n",
      "4136:\tlearn: 1.2334229\ttotal: 50.3s\tremaining: 5.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137:\tlearn: 1.2333641\ttotal: 50.3s\tremaining: 5.59s\n",
      "4138:\tlearn: 1.2331532\ttotal: 50.3s\tremaining: 5.58s\n",
      "4139:\tlearn: 1.2330305\ttotal: 50.3s\tremaining: 5.57s\n",
      "4140:\tlearn: 1.2329471\ttotal: 50.3s\tremaining: 5.55s\n",
      "4141:\tlearn: 1.2328144\ttotal: 50.3s\tremaining: 5.54s\n",
      "4142:\tlearn: 1.2327451\ttotal: 50.3s\tremaining: 5.53s\n",
      "4143:\tlearn: 1.2326624\ttotal: 50.4s\tremaining: 5.52s\n",
      "4144:\tlearn: 1.2324323\ttotal: 50.4s\tremaining: 5.5s\n",
      "4145:\tlearn: 1.2323598\ttotal: 50.4s\tremaining: 5.49s\n",
      "4146:\tlearn: 1.2321059\ttotal: 50.4s\tremaining: 5.48s\n",
      "4147:\tlearn: 1.2319607\ttotal: 50.4s\tremaining: 5.47s\n",
      "4148:\tlearn: 1.2318516\ttotal: 50.4s\tremaining: 5.46s\n",
      "4149:\tlearn: 1.2315509\ttotal: 50.4s\tremaining: 5.44s\n",
      "4150:\tlearn: 1.2313628\ttotal: 50.4s\tremaining: 5.43s\n",
      "4151:\tlearn: 1.2311606\ttotal: 50.5s\tremaining: 5.42s\n",
      "4152:\tlearn: 1.2310199\ttotal: 50.5s\tremaining: 5.41s\n",
      "4153:\tlearn: 1.2307708\ttotal: 50.5s\tremaining: 5.39s\n",
      "4154:\tlearn: 1.2306345\ttotal: 50.5s\tremaining: 5.38s\n",
      "4155:\tlearn: 1.2304764\ttotal: 50.5s\tremaining: 5.37s\n",
      "4156:\tlearn: 1.2300992\ttotal: 50.5s\tremaining: 5.36s\n",
      "4157:\tlearn: 1.2299241\ttotal: 50.5s\tremaining: 5.35s\n",
      "4158:\tlearn: 1.2296796\ttotal: 50.5s\tremaining: 5.33s\n",
      "4159:\tlearn: 1.2295404\ttotal: 50.6s\tremaining: 5.32s\n",
      "4160:\tlearn: 1.2293498\ttotal: 50.6s\tremaining: 5.31s\n",
      "4161:\tlearn: 1.2291640\ttotal: 50.6s\tremaining: 5.3s\n",
      "4162:\tlearn: 1.2291130\ttotal: 50.6s\tremaining: 5.29s\n",
      "4163:\tlearn: 1.2288868\ttotal: 50.6s\tremaining: 5.27s\n",
      "4164:\tlearn: 1.2288025\ttotal: 50.6s\tremaining: 5.26s\n",
      "4165:\tlearn: 1.2286852\ttotal: 50.6s\tremaining: 5.25s\n",
      "4166:\tlearn: 1.2286537\ttotal: 50.6s\tremaining: 5.24s\n",
      "4167:\tlearn: 1.2284112\ttotal: 50.6s\tremaining: 5.22s\n",
      "4168:\tlearn: 1.2283914\ttotal: 50.7s\tremaining: 5.21s\n",
      "4169:\tlearn: 1.2281876\ttotal: 50.7s\tremaining: 5.2s\n",
      "4170:\tlearn: 1.2281392\ttotal: 50.7s\tremaining: 5.19s\n",
      "4171:\tlearn: 1.2278773\ttotal: 50.7s\tremaining: 5.18s\n",
      "4172:\tlearn: 1.2276661\ttotal: 50.7s\tremaining: 5.16s\n",
      "4173:\tlearn: 1.2275457\ttotal: 50.7s\tremaining: 5.15s\n",
      "4174:\tlearn: 1.2273927\ttotal: 50.7s\tremaining: 5.14s\n",
      "4175:\tlearn: 1.2273087\ttotal: 50.7s\tremaining: 5.13s\n",
      "4176:\tlearn: 1.2272820\ttotal: 50.8s\tremaining: 5.12s\n",
      "4177:\tlearn: 1.2271848\ttotal: 50.8s\tremaining: 5.1s\n",
      "4178:\tlearn: 1.2271124\ttotal: 50.8s\tremaining: 5.09s\n",
      "4179:\tlearn: 1.2269630\ttotal: 50.8s\tremaining: 5.08s\n",
      "4180:\tlearn: 1.2268927\ttotal: 50.8s\tremaining: 5.07s\n",
      "4181:\tlearn: 1.2267533\ttotal: 50.8s\tremaining: 5.05s\n",
      "4182:\tlearn: 1.2267037\ttotal: 50.8s\tremaining: 5.04s\n",
      "4183:\tlearn: 1.2263826\ttotal: 50.8s\tremaining: 5.03s\n",
      "4184:\tlearn: 1.2262360\ttotal: 50.8s\tremaining: 5.02s\n",
      "4185:\tlearn: 1.2260340\ttotal: 50.9s\tremaining: 5s\n",
      "4186:\tlearn: 1.2258889\ttotal: 50.9s\tremaining: 4.99s\n",
      "4187:\tlearn: 1.2256984\ttotal: 50.9s\tremaining: 4.98s\n",
      "4188:\tlearn: 1.2255370\ttotal: 50.9s\tremaining: 4.97s\n",
      "4189:\tlearn: 1.2254029\ttotal: 50.9s\tremaining: 4.96s\n",
      "4190:\tlearn: 1.2252722\ttotal: 50.9s\tremaining: 4.95s\n",
      "4191:\tlearn: 1.2251466\ttotal: 50.9s\tremaining: 4.93s\n",
      "4192:\tlearn: 1.2248343\ttotal: 50.9s\tremaining: 4.92s\n",
      "4193:\tlearn: 1.2246496\ttotal: 51s\tremaining: 4.91s\n",
      "4194:\tlearn: 1.2245170\ttotal: 51s\tremaining: 4.9s\n",
      "4195:\tlearn: 1.2244238\ttotal: 51s\tremaining: 4.88s\n",
      "4196:\tlearn: 1.2243928\ttotal: 51s\tremaining: 4.87s\n",
      "4197:\tlearn: 1.2242587\ttotal: 51s\tremaining: 4.86s\n",
      "4198:\tlearn: 1.2239381\ttotal: 51s\tremaining: 4.85s\n",
      "4199:\tlearn: 1.2236609\ttotal: 51s\tremaining: 4.83s\n",
      "4200:\tlearn: 1.2234526\ttotal: 51s\tremaining: 4.82s\n",
      "4201:\tlearn: 1.2233739\ttotal: 51.1s\tremaining: 4.81s\n",
      "4202:\tlearn: 1.2233533\ttotal: 51.1s\tremaining: 4.8s\n",
      "4203:\tlearn: 1.2231036\ttotal: 51.1s\tremaining: 4.79s\n",
      "4204:\tlearn: 1.2228706\ttotal: 51.1s\tremaining: 4.77s\n",
      "4205:\tlearn: 1.2227736\ttotal: 51.1s\tremaining: 4.76s\n",
      "4206:\tlearn: 1.2225853\ttotal: 51.1s\tremaining: 4.75s\n",
      "4207:\tlearn: 1.2225218\ttotal: 51.1s\tremaining: 4.74s\n",
      "4208:\tlearn: 1.2223282\ttotal: 51.1s\tremaining: 4.73s\n",
      "4209:\tlearn: 1.2221624\ttotal: 51.1s\tremaining: 4.71s\n",
      "4210:\tlearn: 1.2219026\ttotal: 51.2s\tremaining: 4.7s\n",
      "4211:\tlearn: 1.2216956\ttotal: 51.2s\tremaining: 4.69s\n",
      "4212:\tlearn: 1.2216866\ttotal: 51.2s\tremaining: 4.68s\n",
      "4213:\tlearn: 1.2215688\ttotal: 51.2s\tremaining: 4.67s\n",
      "4214:\tlearn: 1.2213690\ttotal: 51.2s\tremaining: 4.65s\n",
      "4215:\tlearn: 1.2210646\ttotal: 51.2s\tremaining: 4.64s\n",
      "4216:\tlearn: 1.2208592\ttotal: 51.2s\tremaining: 4.63s\n",
      "4217:\tlearn: 1.2205828\ttotal: 51.2s\tremaining: 4.62s\n",
      "4218:\tlearn: 1.2204176\ttotal: 51.3s\tremaining: 4.6s\n",
      "4219:\tlearn: 1.2202992\ttotal: 51.3s\tremaining: 4.59s\n",
      "4220:\tlearn: 1.2200603\ttotal: 51.3s\tremaining: 4.58s\n",
      "4221:\tlearn: 1.2197835\ttotal: 51.3s\tremaining: 4.57s\n",
      "4222:\tlearn: 1.2196395\ttotal: 51.3s\tremaining: 4.55s\n",
      "4223:\tlearn: 1.2193663\ttotal: 51.3s\tremaining: 4.54s\n",
      "4224:\tlearn: 1.2192110\ttotal: 51.3s\tremaining: 4.53s\n",
      "4225:\tlearn: 1.2189461\ttotal: 51.3s\tremaining: 4.52s\n",
      "4226:\tlearn: 1.2188050\ttotal: 51.4s\tremaining: 4.51s\n",
      "4227:\tlearn: 1.2186856\ttotal: 51.4s\tremaining: 4.5s\n",
      "4228:\tlearn: 1.2186350\ttotal: 51.4s\tremaining: 4.48s\n",
      "4229:\tlearn: 1.2184558\ttotal: 51.4s\tremaining: 4.47s\n",
      "4230:\tlearn: 1.2183208\ttotal: 51.4s\tremaining: 4.46s\n",
      "4231:\tlearn: 1.2182203\ttotal: 51.4s\tremaining: 4.45s\n",
      "4232:\tlearn: 1.2180859\ttotal: 51.4s\tremaining: 4.43s\n",
      "4233:\tlearn: 1.2178099\ttotal: 51.4s\tremaining: 4.42s\n",
      "4234:\tlearn: 1.2176514\ttotal: 51.5s\tremaining: 4.41s\n",
      "4235:\tlearn: 1.2174737\ttotal: 51.5s\tremaining: 4.4s\n",
      "4236:\tlearn: 1.2173388\ttotal: 51.5s\tremaining: 4.38s\n",
      "4237:\tlearn: 1.2170145\ttotal: 51.5s\tremaining: 4.37s\n",
      "4238:\tlearn: 1.2169176\ttotal: 51.5s\tremaining: 4.36s\n",
      "4239:\tlearn: 1.2168268\ttotal: 51.5s\tremaining: 4.35s\n",
      "4240:\tlearn: 1.2167529\ttotal: 51.5s\tremaining: 4.34s\n",
      "4241:\tlearn: 1.2166168\ttotal: 51.5s\tremaining: 4.32s\n",
      "4242:\tlearn: 1.2164363\ttotal: 51.5s\tremaining: 4.31s\n",
      "4243:\tlearn: 1.2163029\ttotal: 51.6s\tremaining: 4.3s\n",
      "4244:\tlearn: 1.2162517\ttotal: 51.6s\tremaining: 4.29s\n",
      "4245:\tlearn: 1.2160571\ttotal: 51.6s\tremaining: 4.28s\n",
      "4246:\tlearn: 1.2158780\ttotal: 51.6s\tremaining: 4.26s\n",
      "4247:\tlearn: 1.2156975\ttotal: 51.6s\tremaining: 4.25s\n",
      "4248:\tlearn: 1.2154653\ttotal: 51.6s\tremaining: 4.24s\n",
      "4249:\tlearn: 1.2152950\ttotal: 51.6s\tremaining: 4.23s\n",
      "4250:\tlearn: 1.2151365\ttotal: 51.6s\tremaining: 4.21s\n",
      "4251:\tlearn: 1.2151027\ttotal: 51.7s\tremaining: 4.2s\n",
      "4252:\tlearn: 1.2149115\ttotal: 51.7s\tremaining: 4.19s\n",
      "4253:\tlearn: 1.2147591\ttotal: 51.7s\tremaining: 4.18s\n",
      "4254:\tlearn: 1.2147251\ttotal: 51.7s\tremaining: 4.17s\n",
      "4255:\tlearn: 1.2145586\ttotal: 51.7s\tremaining: 4.15s\n",
      "4256:\tlearn: 1.2143859\ttotal: 51.7s\tremaining: 4.14s\n",
      "4257:\tlearn: 1.2142567\ttotal: 51.7s\tremaining: 4.13s\n",
      "4258:\tlearn: 1.2140290\ttotal: 51.7s\tremaining: 4.12s\n",
      "4259:\tlearn: 1.2139308\ttotal: 51.8s\tremaining: 4.11s\n",
      "4260:\tlearn: 1.2138334\ttotal: 51.8s\tremaining: 4.09s\n",
      "4261:\tlearn: 1.2137156\ttotal: 51.8s\tremaining: 4.08s\n",
      "4262:\tlearn: 1.2136481\ttotal: 51.8s\tremaining: 4.07s\n",
      "4263:\tlearn: 1.2134580\ttotal: 51.8s\tremaining: 4.06s\n",
      "4264:\tlearn: 1.2131489\ttotal: 51.8s\tremaining: 4.04s\n",
      "4265:\tlearn: 1.2129912\ttotal: 51.8s\tremaining: 4.03s\n",
      "4266:\tlearn: 1.2126969\ttotal: 51.8s\tremaining: 4.02s\n",
      "4267:\tlearn: 1.2125177\ttotal: 51.8s\tremaining: 4.01s\n",
      "4268:\tlearn: 1.2123689\ttotal: 51.9s\tremaining: 4s\n",
      "4269:\tlearn: 1.2121886\ttotal: 51.9s\tremaining: 3.98s\n",
      "4270:\tlearn: 1.2120782\ttotal: 51.9s\tremaining: 3.97s\n",
      "4271:\tlearn: 1.2118296\ttotal: 51.9s\tremaining: 3.96s\n",
      "4272:\tlearn: 1.2117013\ttotal: 51.9s\tremaining: 3.95s\n",
      "4273:\tlearn: 1.2115377\ttotal: 51.9s\tremaining: 3.94s\n",
      "4274:\tlearn: 1.2112442\ttotal: 51.9s\tremaining: 3.92s\n",
      "4275:\tlearn: 1.2111925\ttotal: 51.9s\tremaining: 3.91s\n",
      "4276:\tlearn: 1.2109876\ttotal: 52s\tremaining: 3.9s\n",
      "4277:\tlearn: 1.2107913\ttotal: 52s\tremaining: 3.89s\n",
      "4278:\tlearn: 1.2106397\ttotal: 52s\tremaining: 3.88s\n",
      "4279:\tlearn: 1.2105982\ttotal: 52s\tremaining: 3.86s\n",
      "4280:\tlearn: 1.2105062\ttotal: 52s\tremaining: 3.85s\n",
      "4281:\tlearn: 1.2102006\ttotal: 52s\tremaining: 3.84s\n",
      "4282:\tlearn: 1.2101431\ttotal: 52s\tremaining: 3.83s\n",
      "4283:\tlearn: 1.2100107\ttotal: 52s\tremaining: 3.81s\n",
      "4284:\tlearn: 1.2098365\ttotal: 52.1s\tremaining: 3.8s\n",
      "4285:\tlearn: 1.2095871\ttotal: 52.1s\tremaining: 3.79s\n",
      "4286:\tlearn: 1.2095409\ttotal: 52.1s\tremaining: 3.78s\n",
      "4287:\tlearn: 1.2093412\ttotal: 52.1s\tremaining: 3.77s\n",
      "4288:\tlearn: 1.2092182\ttotal: 52.1s\tremaining: 3.75s\n",
      "4289:\tlearn: 1.2090842\ttotal: 52.1s\tremaining: 3.74s\n",
      "4290:\tlearn: 1.2089514\ttotal: 52.1s\tremaining: 3.73s\n",
      "4291:\tlearn: 1.2088681\ttotal: 52.1s\tremaining: 3.72s\n",
      "4292:\tlearn: 1.2085841\ttotal: 52.1s\tremaining: 3.71s\n",
      "4293:\tlearn: 1.2083520\ttotal: 52.2s\tremaining: 3.69s\n",
      "4294:\tlearn: 1.2081095\ttotal: 52.2s\tremaining: 3.68s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4295:\tlearn: 1.2079630\ttotal: 52.2s\tremaining: 3.67s\n",
      "4296:\tlearn: 1.2078068\ttotal: 52.2s\tremaining: 3.66s\n",
      "4297:\tlearn: 1.2077429\ttotal: 52.2s\tremaining: 3.64s\n",
      "4298:\tlearn: 1.2074965\ttotal: 52.2s\tremaining: 3.63s\n",
      "4299:\tlearn: 1.2072287\ttotal: 52.2s\tremaining: 3.62s\n",
      "4300:\tlearn: 1.2070231\ttotal: 52.2s\tremaining: 3.61s\n",
      "4301:\tlearn: 1.2068738\ttotal: 52.3s\tremaining: 3.6s\n",
      "4302:\tlearn: 1.2067381\ttotal: 52.3s\tremaining: 3.58s\n",
      "4303:\tlearn: 1.2063962\ttotal: 52.3s\tremaining: 3.57s\n",
      "4304:\tlearn: 1.2062433\ttotal: 52.3s\tremaining: 3.56s\n",
      "4305:\tlearn: 1.2061806\ttotal: 52.3s\tremaining: 3.55s\n",
      "4306:\tlearn: 1.2059574\ttotal: 52.3s\tremaining: 3.54s\n",
      "4307:\tlearn: 1.2057027\ttotal: 52.3s\tremaining: 3.52s\n",
      "4308:\tlearn: 1.2055533\ttotal: 52.3s\tremaining: 3.51s\n",
      "4309:\tlearn: 1.2052700\ttotal: 52.4s\tremaining: 3.5s\n",
      "4310:\tlearn: 1.2050809\ttotal: 52.4s\tremaining: 3.49s\n",
      "4311:\tlearn: 1.2049261\ttotal: 52.4s\tremaining: 3.47s\n",
      "4312:\tlearn: 1.2048926\ttotal: 52.4s\tremaining: 3.46s\n",
      "4313:\tlearn: 1.2047662\ttotal: 52.4s\tremaining: 3.45s\n",
      "4314:\tlearn: 1.2045768\ttotal: 52.4s\tremaining: 3.44s\n",
      "4315:\tlearn: 1.2044107\ttotal: 52.4s\tremaining: 3.42s\n",
      "4316:\tlearn: 1.2042603\ttotal: 52.4s\tremaining: 3.41s\n",
      "4317:\tlearn: 1.2040642\ttotal: 52.5s\tremaining: 3.4s\n",
      "4318:\tlearn: 1.2038640\ttotal: 52.5s\tremaining: 3.39s\n",
      "4319:\tlearn: 1.2037173\ttotal: 52.5s\tremaining: 3.38s\n",
      "4320:\tlearn: 1.2036964\ttotal: 52.5s\tremaining: 3.36s\n",
      "4321:\tlearn: 1.2035182\ttotal: 52.5s\tremaining: 3.35s\n",
      "4322:\tlearn: 1.2033923\ttotal: 52.5s\tremaining: 3.34s\n",
      "4323:\tlearn: 1.2033046\ttotal: 52.5s\tremaining: 3.33s\n",
      "4324:\tlearn: 1.2032049\ttotal: 52.5s\tremaining: 3.32s\n",
      "4325:\tlearn: 1.2030422\ttotal: 52.5s\tremaining: 3.3s\n",
      "4326:\tlearn: 1.2028339\ttotal: 52.6s\tremaining: 3.29s\n",
      "4327:\tlearn: 1.2027248\ttotal: 52.6s\tremaining: 3.28s\n",
      "4328:\tlearn: 1.2025943\ttotal: 52.6s\tremaining: 3.27s\n",
      "4329:\tlearn: 1.2024121\ttotal: 52.6s\tremaining: 3.25s\n",
      "4330:\tlearn: 1.2020907\ttotal: 52.6s\tremaining: 3.24s\n",
      "4331:\tlearn: 1.2019173\ttotal: 52.6s\tremaining: 3.23s\n",
      "4332:\tlearn: 1.2018460\ttotal: 52.6s\tremaining: 3.22s\n",
      "4333:\tlearn: 1.2016899\ttotal: 52.6s\tremaining: 3.21s\n",
      "4334:\tlearn: 1.2014986\ttotal: 52.7s\tremaining: 3.19s\n",
      "4335:\tlearn: 1.2013178\ttotal: 52.7s\tremaining: 3.18s\n",
      "4336:\tlearn: 1.2010942\ttotal: 52.7s\tremaining: 3.17s\n",
      "4337:\tlearn: 1.2008835\ttotal: 52.7s\tremaining: 3.16s\n",
      "4338:\tlearn: 1.2007241\ttotal: 52.7s\tremaining: 3.15s\n",
      "4339:\tlearn: 1.2004383\ttotal: 52.7s\tremaining: 3.13s\n",
      "4340:\tlearn: 1.2003063\ttotal: 52.7s\tremaining: 3.12s\n",
      "4341:\tlearn: 1.2000528\ttotal: 52.7s\tremaining: 3.11s\n",
      "4342:\tlearn: 1.1999329\ttotal: 52.8s\tremaining: 3.1s\n",
      "4343:\tlearn: 1.1997746\ttotal: 52.8s\tremaining: 3.08s\n",
      "4344:\tlearn: 1.1996563\ttotal: 52.8s\tremaining: 3.07s\n",
      "4345:\tlearn: 1.1995615\ttotal: 52.8s\tremaining: 3.06s\n",
      "4346:\tlearn: 1.1992365\ttotal: 52.8s\tremaining: 3.05s\n",
      "4347:\tlearn: 1.1991159\ttotal: 52.8s\tremaining: 3.04s\n",
      "4348:\tlearn: 1.1989914\ttotal: 52.8s\tremaining: 3.02s\n",
      "4349:\tlearn: 1.1989538\ttotal: 52.8s\tremaining: 3.01s\n",
      "4350:\tlearn: 1.1987901\ttotal: 52.9s\tremaining: 3s\n",
      "4351:\tlearn: 1.1987602\ttotal: 52.9s\tremaining: 2.99s\n",
      "4352:\tlearn: 1.1985754\ttotal: 52.9s\tremaining: 2.98s\n",
      "4353:\tlearn: 1.1984275\ttotal: 52.9s\tremaining: 2.96s\n",
      "4354:\tlearn: 1.1982767\ttotal: 52.9s\tremaining: 2.95s\n",
      "4355:\tlearn: 1.1980582\ttotal: 52.9s\tremaining: 2.94s\n",
      "4356:\tlearn: 1.1980403\ttotal: 52.9s\tremaining: 2.93s\n",
      "4357:\tlearn: 1.1977043\ttotal: 52.9s\tremaining: 2.92s\n",
      "4358:\tlearn: 1.1973543\ttotal: 52.9s\tremaining: 2.9s\n",
      "4359:\tlearn: 1.1970092\ttotal: 53s\tremaining: 2.89s\n",
      "4360:\tlearn: 1.1967678\ttotal: 53s\tremaining: 2.88s\n",
      "4361:\tlearn: 1.1966554\ttotal: 53s\tremaining: 2.87s\n",
      "4362:\tlearn: 1.1964510\ttotal: 53s\tremaining: 2.85s\n",
      "4363:\tlearn: 1.1961313\ttotal: 53s\tremaining: 2.84s\n",
      "4364:\tlearn: 1.1958657\ttotal: 53s\tremaining: 2.83s\n",
      "4365:\tlearn: 1.1956555\ttotal: 53s\tremaining: 2.82s\n",
      "4366:\tlearn: 1.1954540\ttotal: 53s\tremaining: 2.81s\n",
      "4367:\tlearn: 1.1952608\ttotal: 53.1s\tremaining: 2.79s\n",
      "4368:\tlearn: 1.1951088\ttotal: 53.1s\tremaining: 2.78s\n",
      "4369:\tlearn: 1.1949270\ttotal: 53.1s\tremaining: 2.77s\n",
      "4370:\tlearn: 1.1948473\ttotal: 53.1s\tremaining: 2.76s\n",
      "4371:\tlearn: 1.1946501\ttotal: 53.1s\tremaining: 2.75s\n",
      "4372:\tlearn: 1.1945603\ttotal: 53.1s\tremaining: 2.73s\n",
      "4373:\tlearn: 1.1945350\ttotal: 53.1s\tremaining: 2.72s\n",
      "4374:\tlearn: 1.1943909\ttotal: 53.1s\tremaining: 2.71s\n",
      "4375:\tlearn: 1.1941492\ttotal: 53.2s\tremaining: 2.7s\n",
      "4376:\tlearn: 1.1939272\ttotal: 53.2s\tremaining: 2.68s\n",
      "4377:\tlearn: 1.1938087\ttotal: 53.2s\tremaining: 2.67s\n",
      "4378:\tlearn: 1.1937518\ttotal: 53.2s\tremaining: 2.66s\n",
      "4379:\tlearn: 1.1936508\ttotal: 53.2s\tremaining: 2.65s\n",
      "4380:\tlearn: 1.1934636\ttotal: 53.2s\tremaining: 2.64s\n",
      "4381:\tlearn: 1.1931406\ttotal: 53.2s\tremaining: 2.62s\n",
      "4382:\tlearn: 1.1930663\ttotal: 53.2s\tremaining: 2.61s\n",
      "4383:\tlearn: 1.1930074\ttotal: 53.3s\tremaining: 2.6s\n",
      "4384:\tlearn: 1.1928548\ttotal: 53.3s\tremaining: 2.59s\n",
      "4385:\tlearn: 1.1927327\ttotal: 53.3s\tremaining: 2.58s\n",
      "4386:\tlearn: 1.1925808\ttotal: 53.3s\tremaining: 2.56s\n",
      "4387:\tlearn: 1.1924500\ttotal: 53.3s\tremaining: 2.55s\n",
      "4388:\tlearn: 1.1923777\ttotal: 53.3s\tremaining: 2.54s\n",
      "4389:\tlearn: 1.1922400\ttotal: 53.3s\tremaining: 2.53s\n",
      "4390:\tlearn: 1.1920126\ttotal: 53.3s\tremaining: 2.51s\n",
      "4391:\tlearn: 1.1918711\ttotal: 53.4s\tremaining: 2.5s\n",
      "4392:\tlearn: 1.1917725\ttotal: 53.4s\tremaining: 2.49s\n",
      "4393:\tlearn: 1.1916776\ttotal: 53.4s\tremaining: 2.48s\n",
      "4394:\tlearn: 1.1915269\ttotal: 53.4s\tremaining: 2.47s\n",
      "4395:\tlearn: 1.1913504\ttotal: 53.4s\tremaining: 2.45s\n",
      "4396:\tlearn: 1.1912559\ttotal: 53.4s\tremaining: 2.44s\n",
      "4397:\tlearn: 1.1909857\ttotal: 53.4s\tremaining: 2.43s\n",
      "4398:\tlearn: 1.1909132\ttotal: 53.4s\tremaining: 2.42s\n",
      "4399:\tlearn: 1.1907391\ttotal: 53.5s\tremaining: 2.4s\n",
      "4400:\tlearn: 1.1906731\ttotal: 53.5s\tremaining: 2.39s\n",
      "4401:\tlearn: 1.1904468\ttotal: 53.5s\tremaining: 2.38s\n",
      "4402:\tlearn: 1.1902792\ttotal: 53.5s\tremaining: 2.37s\n",
      "4403:\tlearn: 1.1901484\ttotal: 53.5s\tremaining: 2.36s\n",
      "4404:\tlearn: 1.1899836\ttotal: 53.5s\tremaining: 2.34s\n",
      "4405:\tlearn: 1.1898861\ttotal: 53.5s\tremaining: 2.33s\n",
      "4406:\tlearn: 1.1896867\ttotal: 53.5s\tremaining: 2.32s\n",
      "4407:\tlearn: 1.1895647\ttotal: 53.5s\tremaining: 2.31s\n",
      "4408:\tlearn: 1.1894697\ttotal: 53.6s\tremaining: 2.29s\n",
      "4409:\tlearn: 1.1892909\ttotal: 53.6s\tremaining: 2.28s\n",
      "4410:\tlearn: 1.1891735\ttotal: 53.6s\tremaining: 2.27s\n",
      "4411:\tlearn: 1.1890540\ttotal: 53.6s\tremaining: 2.26s\n",
      "4412:\tlearn: 1.1888877\ttotal: 53.6s\tremaining: 2.25s\n",
      "4413:\tlearn: 1.1887789\ttotal: 53.6s\tremaining: 2.23s\n",
      "4414:\tlearn: 1.1885456\ttotal: 53.6s\tremaining: 2.22s\n",
      "4415:\tlearn: 1.1884964\ttotal: 53.6s\tremaining: 2.21s\n",
      "4416:\tlearn: 1.1882109\ttotal: 53.7s\tremaining: 2.2s\n",
      "4417:\tlearn: 1.1880058\ttotal: 53.7s\tremaining: 2.19s\n",
      "4418:\tlearn: 1.1879377\ttotal: 53.7s\tremaining: 2.17s\n",
      "4419:\tlearn: 1.1876581\ttotal: 53.7s\tremaining: 2.16s\n",
      "4420:\tlearn: 1.1874202\ttotal: 53.7s\tremaining: 2.15s\n",
      "4421:\tlearn: 1.1871869\ttotal: 53.7s\tremaining: 2.14s\n",
      "4422:\tlearn: 1.1870346\ttotal: 53.7s\tremaining: 2.13s\n",
      "4423:\tlearn: 1.1869026\ttotal: 53.8s\tremaining: 2.11s\n",
      "4424:\tlearn: 1.1868693\ttotal: 53.8s\tremaining: 2.1s\n",
      "4425:\tlearn: 1.1867142\ttotal: 53.8s\tremaining: 2.09s\n",
      "4426:\tlearn: 1.1865794\ttotal: 53.8s\tremaining: 2.08s\n",
      "4427:\tlearn: 1.1863415\ttotal: 53.8s\tremaining: 2.06s\n",
      "4428:\tlearn: 1.1860338\ttotal: 53.8s\tremaining: 2.05s\n",
      "4429:\tlearn: 1.1858147\ttotal: 53.8s\tremaining: 2.04s\n",
      "4430:\tlearn: 1.1855877\ttotal: 53.8s\tremaining: 2.03s\n",
      "4431:\tlearn: 1.1854314\ttotal: 53.9s\tremaining: 2.02s\n",
      "4432:\tlearn: 1.1852345\ttotal: 53.9s\tremaining: 2s\n",
      "4433:\tlearn: 1.1850083\ttotal: 53.9s\tremaining: 1.99s\n",
      "4434:\tlearn: 1.1848338\ttotal: 53.9s\tremaining: 1.98s\n",
      "4435:\tlearn: 1.1846890\ttotal: 53.9s\tremaining: 1.97s\n",
      "4436:\tlearn: 1.1844771\ttotal: 53.9s\tremaining: 1.96s\n",
      "4437:\tlearn: 1.1843303\ttotal: 53.9s\tremaining: 1.94s\n",
      "4438:\tlearn: 1.1841165\ttotal: 53.9s\tremaining: 1.93s\n",
      "4439:\tlearn: 1.1839068\ttotal: 54s\tremaining: 1.92s\n",
      "4440:\tlearn: 1.1837703\ttotal: 54s\tremaining: 1.91s\n",
      "4441:\tlearn: 1.1835969\ttotal: 54s\tremaining: 1.9s\n",
      "4442:\tlearn: 1.1834276\ttotal: 54s\tremaining: 1.88s\n",
      "4443:\tlearn: 1.1833016\ttotal: 54s\tremaining: 1.87s\n",
      "4444:\tlearn: 1.1832498\ttotal: 54s\tremaining: 1.86s\n",
      "4445:\tlearn: 1.1830927\ttotal: 54s\tremaining: 1.85s\n",
      "4446:\tlearn: 1.1829797\ttotal: 54s\tremaining: 1.83s\n",
      "4447:\tlearn: 1.1828390\ttotal: 54s\tremaining: 1.82s\n",
      "4448:\tlearn: 1.1826716\ttotal: 54.1s\tremaining: 1.81s\n",
      "4449:\tlearn: 1.1825667\ttotal: 54.1s\tremaining: 1.8s\n",
      "4450:\tlearn: 1.1824134\ttotal: 54.1s\tremaining: 1.79s\n",
      "4451:\tlearn: 1.1822900\ttotal: 54.1s\tremaining: 1.77s\n",
      "4452:\tlearn: 1.1820765\ttotal: 54.1s\tremaining: 1.76s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4453:\tlearn: 1.1819359\ttotal: 54.1s\tremaining: 1.75s\n",
      "4454:\tlearn: 1.1817803\ttotal: 54.1s\tremaining: 1.74s\n",
      "4455:\tlearn: 1.1816513\ttotal: 54.1s\tremaining: 1.73s\n",
      "4456:\tlearn: 1.1816014\ttotal: 54.2s\tremaining: 1.71s\n",
      "4457:\tlearn: 1.1813986\ttotal: 54.2s\tremaining: 1.7s\n",
      "4458:\tlearn: 1.1812632\ttotal: 54.2s\tremaining: 1.69s\n",
      "4459:\tlearn: 1.1810648\ttotal: 54.2s\tremaining: 1.68s\n",
      "4460:\tlearn: 1.1809607\ttotal: 54.2s\tremaining: 1.66s\n",
      "4461:\tlearn: 1.1808321\ttotal: 54.2s\tremaining: 1.65s\n",
      "4462:\tlearn: 1.1807142\ttotal: 54.2s\tremaining: 1.64s\n",
      "4463:\tlearn: 1.1806159\ttotal: 54.2s\tremaining: 1.63s\n",
      "4464:\tlearn: 1.1804470\ttotal: 54.2s\tremaining: 1.61s\n",
      "4465:\tlearn: 1.1803899\ttotal: 54.3s\tremaining: 1.6s\n",
      "4466:\tlearn: 1.1802944\ttotal: 54.3s\tremaining: 1.59s\n",
      "4467:\tlearn: 1.1802110\ttotal: 54.3s\tremaining: 1.58s\n",
      "4468:\tlearn: 1.1800636\ttotal: 54.3s\tremaining: 1.57s\n",
      "4469:\tlearn: 1.1798942\ttotal: 54.3s\tremaining: 1.55s\n",
      "4470:\tlearn: 1.1797937\ttotal: 54.3s\tremaining: 1.54s\n",
      "4471:\tlearn: 1.1796668\ttotal: 54.3s\tremaining: 1.53s\n",
      "4472:\tlearn: 1.1794020\ttotal: 54.3s\tremaining: 1.52s\n",
      "4473:\tlearn: 1.1792205\ttotal: 54.4s\tremaining: 1.51s\n",
      "4474:\tlearn: 1.1790803\ttotal: 54.4s\tremaining: 1.49s\n",
      "4475:\tlearn: 1.1790358\ttotal: 54.4s\tremaining: 1.48s\n",
      "4476:\tlearn: 1.1788855\ttotal: 54.4s\tremaining: 1.47s\n",
      "4477:\tlearn: 1.1788562\ttotal: 54.4s\tremaining: 1.46s\n",
      "4478:\tlearn: 1.1787144\ttotal: 54.4s\tremaining: 1.45s\n",
      "4479:\tlearn: 1.1785714\ttotal: 54.4s\tremaining: 1.43s\n",
      "4480:\tlearn: 1.1784645\ttotal: 54.4s\tremaining: 1.42s\n",
      "4481:\tlearn: 1.1782959\ttotal: 54.5s\tremaining: 1.41s\n",
      "4482:\tlearn: 1.1781066\ttotal: 54.5s\tremaining: 1.4s\n",
      "4483:\tlearn: 1.1779467\ttotal: 54.5s\tremaining: 1.39s\n",
      "4484:\tlearn: 1.1778618\ttotal: 54.5s\tremaining: 1.37s\n",
      "4485:\tlearn: 1.1776892\ttotal: 54.5s\tremaining: 1.36s\n",
      "4486:\tlearn: 1.1775999\ttotal: 54.5s\tremaining: 1.35s\n",
      "4487:\tlearn: 1.1773549\ttotal: 54.5s\tremaining: 1.34s\n",
      "4488:\tlearn: 1.1772639\ttotal: 54.5s\tremaining: 1.32s\n",
      "4489:\tlearn: 1.1771826\ttotal: 54.5s\tremaining: 1.31s\n",
      "4490:\tlearn: 1.1770282\ttotal: 54.6s\tremaining: 1.3s\n",
      "4491:\tlearn: 1.1767967\ttotal: 54.6s\tremaining: 1.29s\n",
      "4492:\tlearn: 1.1765506\ttotal: 54.6s\tremaining: 1.27s\n",
      "4493:\tlearn: 1.1764024\ttotal: 54.6s\tremaining: 1.26s\n",
      "4494:\tlearn: 1.1763210\ttotal: 54.6s\tremaining: 1.25s\n",
      "4495:\tlearn: 1.1760258\ttotal: 54.6s\tremaining: 1.24s\n",
      "4496:\tlearn: 1.1759639\ttotal: 54.6s\tremaining: 1.23s\n",
      "4497:\tlearn: 1.1758645\ttotal: 54.6s\tremaining: 1.21s\n",
      "4498:\tlearn: 1.1756968\ttotal: 54.7s\tremaining: 1.2s\n",
      "4499:\tlearn: 1.1754553\ttotal: 54.7s\tremaining: 1.19s\n",
      "4500:\tlearn: 1.1753063\ttotal: 54.7s\tremaining: 1.18s\n",
      "4501:\tlearn: 1.1751872\ttotal: 54.7s\tremaining: 1.17s\n",
      "4502:\tlearn: 1.1750670\ttotal: 54.7s\tremaining: 1.15s\n",
      "4503:\tlearn: 1.1748751\ttotal: 54.7s\tremaining: 1.14s\n",
      "4504:\tlearn: 1.1747350\ttotal: 54.7s\tremaining: 1.13s\n",
      "4505:\tlearn: 1.1746915\ttotal: 54.7s\tremaining: 1.12s\n",
      "4506:\tlearn: 1.1745944\ttotal: 54.8s\tremaining: 1.1s\n",
      "4507:\tlearn: 1.1744653\ttotal: 54.8s\tremaining: 1.09s\n",
      "4508:\tlearn: 1.1741984\ttotal: 54.8s\tremaining: 1.08s\n",
      "4509:\tlearn: 1.1740789\ttotal: 54.8s\tremaining: 1.07s\n",
      "4510:\tlearn: 1.1740153\ttotal: 54.8s\tremaining: 1.06s\n",
      "4511:\tlearn: 1.1739443\ttotal: 54.8s\tremaining: 1.04s\n",
      "4512:\tlearn: 1.1737990\ttotal: 54.8s\tremaining: 1.03s\n",
      "4513:\tlearn: 1.1737727\ttotal: 54.9s\tremaining: 1.02s\n",
      "4514:\tlearn: 1.1735589\ttotal: 54.9s\tremaining: 1.01s\n",
      "4515:\tlearn: 1.1733881\ttotal: 54.9s\tremaining: 996ms\n",
      "4516:\tlearn: 1.1733038\ttotal: 54.9s\tremaining: 984ms\n",
      "4517:\tlearn: 1.1731612\ttotal: 54.9s\tremaining: 972ms\n",
      "4518:\tlearn: 1.1730560\ttotal: 54.9s\tremaining: 960ms\n",
      "4519:\tlearn: 1.1728629\ttotal: 54.9s\tremaining: 948ms\n",
      "4520:\tlearn: 1.1727337\ttotal: 54.9s\tremaining: 936ms\n",
      "4521:\tlearn: 1.1726239\ttotal: 55s\tremaining: 924ms\n",
      "4522:\tlearn: 1.1723456\ttotal: 55s\tremaining: 911ms\n",
      "4523:\tlearn: 1.1720578\ttotal: 55s\tremaining: 899ms\n",
      "4524:\tlearn: 1.1719403\ttotal: 55s\tremaining: 887ms\n",
      "4525:\tlearn: 1.1718561\ttotal: 55s\tremaining: 875ms\n",
      "4526:\tlearn: 1.1716691\ttotal: 55s\tremaining: 863ms\n",
      "4527:\tlearn: 1.1715403\ttotal: 55s\tremaining: 851ms\n",
      "4528:\tlearn: 1.1714036\ttotal: 55s\tremaining: 839ms\n",
      "4529:\tlearn: 1.1712228\ttotal: 55.1s\tremaining: 826ms\n",
      "4530:\tlearn: 1.1709404\ttotal: 55.1s\tremaining: 814ms\n",
      "4531:\tlearn: 1.1708055\ttotal: 55.1s\tremaining: 802ms\n",
      "4532:\tlearn: 1.1706503\ttotal: 55.1s\tremaining: 790ms\n",
      "4533:\tlearn: 1.1704028\ttotal: 55.1s\tremaining: 778ms\n",
      "4534:\tlearn: 1.1702554\ttotal: 55.1s\tremaining: 766ms\n",
      "4535:\tlearn: 1.1701537\ttotal: 55.1s\tremaining: 754ms\n",
      "4536:\tlearn: 1.1699681\ttotal: 55.1s\tremaining: 741ms\n",
      "4537:\tlearn: 1.1698506\ttotal: 55.1s\tremaining: 729ms\n",
      "4538:\tlearn: 1.1697685\ttotal: 55.2s\tremaining: 717ms\n",
      "4539:\tlearn: 1.1697036\ttotal: 55.2s\tremaining: 705ms\n",
      "4540:\tlearn: 1.1695380\ttotal: 55.2s\tremaining: 693ms\n",
      "4541:\tlearn: 1.1694184\ttotal: 55.2s\tremaining: 681ms\n",
      "4542:\tlearn: 1.1693147\ttotal: 55.2s\tremaining: 668ms\n",
      "4543:\tlearn: 1.1692156\ttotal: 55.2s\tremaining: 656ms\n",
      "4544:\tlearn: 1.1691137\ttotal: 55.2s\tremaining: 644ms\n",
      "4545:\tlearn: 1.1689266\ttotal: 55.2s\tremaining: 632ms\n",
      "4546:\tlearn: 1.1687185\ttotal: 55.3s\tremaining: 620ms\n",
      "4547:\tlearn: 1.1684503\ttotal: 55.3s\tremaining: 608ms\n",
      "4548:\tlearn: 1.1681779\ttotal: 55.3s\tremaining: 595ms\n",
      "4549:\tlearn: 1.1679266\ttotal: 55.3s\tremaining: 583ms\n",
      "4550:\tlearn: 1.1678042\ttotal: 55.3s\tremaining: 571ms\n",
      "4551:\tlearn: 1.1677160\ttotal: 55.3s\tremaining: 559ms\n",
      "4552:\tlearn: 1.1676208\ttotal: 55.3s\tremaining: 547ms\n",
      "4553:\tlearn: 1.1674295\ttotal: 55.3s\tremaining: 535ms\n",
      "4554:\tlearn: 1.1671323\ttotal: 55.3s\tremaining: 522ms\n",
      "4555:\tlearn: 1.1670263\ttotal: 55.4s\tremaining: 510ms\n",
      "4556:\tlearn: 1.1669360\ttotal: 55.4s\tremaining: 498ms\n",
      "4557:\tlearn: 1.1668173\ttotal: 55.4s\tremaining: 486ms\n",
      "4558:\tlearn: 1.1668071\ttotal: 55.4s\tremaining: 474ms\n",
      "4559:\tlearn: 1.1666852\ttotal: 55.4s\tremaining: 462ms\n",
      "4560:\tlearn: 1.1664841\ttotal: 55.4s\tremaining: 450ms\n",
      "4561:\tlearn: 1.1663782\ttotal: 55.4s\tremaining: 437ms\n",
      "4562:\tlearn: 1.1662819\ttotal: 55.4s\tremaining: 425ms\n",
      "4563:\tlearn: 1.1661225\ttotal: 55.5s\tremaining: 413ms\n",
      "4564:\tlearn: 1.1660470\ttotal: 55.5s\tremaining: 401ms\n",
      "4565:\tlearn: 1.1658962\ttotal: 55.5s\tremaining: 389ms\n",
      "4566:\tlearn: 1.1656563\ttotal: 55.5s\tremaining: 377ms\n",
      "4567:\tlearn: 1.1655481\ttotal: 55.5s\tremaining: 364ms\n",
      "4568:\tlearn: 1.1654626\ttotal: 55.5s\tremaining: 352ms\n",
      "4569:\tlearn: 1.1653668\ttotal: 55.5s\tremaining: 340ms\n",
      "4570:\tlearn: 1.1652409\ttotal: 55.5s\tremaining: 328ms\n",
      "4571:\tlearn: 1.1651388\ttotal: 55.5s\tremaining: 316ms\n",
      "4572:\tlearn: 1.1650708\ttotal: 55.6s\tremaining: 304ms\n",
      "4573:\tlearn: 1.1648723\ttotal: 55.6s\tremaining: 292ms\n",
      "4574:\tlearn: 1.1647777\ttotal: 55.6s\tremaining: 279ms\n",
      "4575:\tlearn: 1.1646107\ttotal: 55.6s\tremaining: 267ms\n",
      "4576:\tlearn: 1.1643577\ttotal: 55.6s\tremaining: 255ms\n",
      "4577:\tlearn: 1.1641612\ttotal: 55.6s\tremaining: 243ms\n",
      "4578:\tlearn: 1.1641037\ttotal: 55.6s\tremaining: 231ms\n",
      "4579:\tlearn: 1.1639712\ttotal: 55.6s\tremaining: 219ms\n",
      "4580:\tlearn: 1.1639573\ttotal: 55.7s\tremaining: 207ms\n",
      "4581:\tlearn: 1.1638361\ttotal: 55.7s\tremaining: 194ms\n",
      "4582:\tlearn: 1.1636278\ttotal: 55.7s\tremaining: 182ms\n",
      "4583:\tlearn: 1.1634686\ttotal: 55.7s\tremaining: 170ms\n",
      "4584:\tlearn: 1.1633704\ttotal: 55.7s\tremaining: 158ms\n",
      "4585:\tlearn: 1.1630862\ttotal: 55.7s\tremaining: 146ms\n",
      "4586:\tlearn: 1.1628916\ttotal: 55.7s\tremaining: 134ms\n",
      "4587:\tlearn: 1.1626129\ttotal: 55.7s\tremaining: 121ms\n",
      "4588:\tlearn: 1.1625127\ttotal: 55.7s\tremaining: 109ms\n",
      "4589:\tlearn: 1.1623225\ttotal: 55.8s\tremaining: 97.2ms\n",
      "4590:\tlearn: 1.1621998\ttotal: 55.8s\tremaining: 85ms\n",
      "4591:\tlearn: 1.1619782\ttotal: 55.8s\tremaining: 72.9ms\n",
      "4592:\tlearn: 1.1618077\ttotal: 55.8s\tremaining: 60.7ms\n",
      "4593:\tlearn: 1.1616625\ttotal: 55.8s\tremaining: 48.6ms\n",
      "4594:\tlearn: 1.1615521\ttotal: 55.8s\tremaining: 36.4ms\n",
      "4595:\tlearn: 1.1613636\ttotal: 55.8s\tremaining: 24.3ms\n",
      "4596:\tlearn: 1.1610640\ttotal: 55.8s\tremaining: 12.1ms\n",
      "4597:\tlearn: 1.1609191\ttotal: 55.9s\tremaining: 0us\n",
      "0:\tlearn: 14.7693776\ttotal: 11.2ms\tremaining: 51.3s\n",
      "1:\tlearn: 13.3639247\ttotal: 23.1ms\tremaining: 53.1s\n",
      "2:\tlearn: 12.1216980\ttotal: 35.4ms\tremaining: 54.3s\n",
      "3:\tlearn: 11.0256708\ttotal: 47.4ms\tremaining: 54.4s\n",
      "4:\tlearn: 10.0855944\ttotal: 59.4ms\tremaining: 54.5s\n",
      "5:\tlearn: 9.2608758\ttotal: 71.2ms\tremaining: 54.5s\n",
      "6:\tlearn: 8.5438334\ttotal: 83ms\tremaining: 54.4s\n",
      "7:\tlearn: 7.9283329\ttotal: 95ms\tremaining: 54.5s\n",
      "8:\tlearn: 7.4079942\ttotal: 107ms\tremaining: 54.6s\n",
      "9:\tlearn: 6.9580499\ttotal: 119ms\tremaining: 54.8s\n",
      "10:\tlearn: 6.5780179\ttotal: 132ms\tremaining: 54.8s\n",
      "11:\tlearn: 6.2553677\ttotal: 144ms\tremaining: 54.9s\n",
      "12:\tlearn: 5.9751502\ttotal: 157ms\tremaining: 55.2s\n",
      "13:\tlearn: 5.7483268\ttotal: 169ms\tremaining: 55.3s\n",
      "14:\tlearn: 5.5543067\ttotal: 182ms\tremaining: 55.5s\n",
      "15:\tlearn: 5.3884258\ttotal: 194ms\tremaining: 55.5s\n",
      "16:\tlearn: 5.2581186\ttotal: 206ms\tremaining: 55.5s\n",
      "17:\tlearn: 5.1408674\ttotal: 218ms\tremaining: 55.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:\tlearn: 5.0329714\ttotal: 233ms\tremaining: 56.2s\n",
      "19:\tlearn: 4.9435057\ttotal: 247ms\tremaining: 56.6s\n",
      "20:\tlearn: 4.8708740\ttotal: 260ms\tremaining: 56.7s\n",
      "21:\tlearn: 4.8143951\ttotal: 272ms\tremaining: 56.6s\n",
      "22:\tlearn: 4.7620466\ttotal: 284ms\tremaining: 56.5s\n",
      "23:\tlearn: 4.7179155\ttotal: 297ms\tremaining: 56.5s\n",
      "24:\tlearn: 4.6789363\ttotal: 309ms\tremaining: 56.6s\n",
      "25:\tlearn: 4.6451117\ttotal: 322ms\tremaining: 56.6s\n",
      "26:\tlearn: 4.6177630\ttotal: 334ms\tremaining: 56.5s\n",
      "27:\tlearn: 4.5976103\ttotal: 346ms\tremaining: 56.5s\n",
      "28:\tlearn: 4.5753915\ttotal: 357ms\tremaining: 56.3s\n",
      "29:\tlearn: 4.5594834\ttotal: 369ms\tremaining: 56.2s\n",
      "30:\tlearn: 4.5400390\ttotal: 381ms\tremaining: 56.2s\n",
      "31:\tlearn: 4.5272235\ttotal: 393ms\tremaining: 56.1s\n",
      "32:\tlearn: 4.5079753\ttotal: 406ms\tremaining: 56.2s\n",
      "33:\tlearn: 4.4977402\ttotal: 417ms\tremaining: 56s\n",
      "34:\tlearn: 4.4834048\ttotal: 429ms\tremaining: 56s\n",
      "35:\tlearn: 4.4747015\ttotal: 443ms\tremaining: 56.1s\n",
      "36:\tlearn: 4.4638468\ttotal: 457ms\tremaining: 56.3s\n",
      "37:\tlearn: 4.4530776\ttotal: 469ms\tremaining: 56.3s\n",
      "38:\tlearn: 4.4459020\ttotal: 481ms\tremaining: 56.2s\n",
      "39:\tlearn: 4.4386732\ttotal: 492ms\tremaining: 56.1s\n",
      "40:\tlearn: 4.4322376\ttotal: 503ms\tremaining: 55.9s\n",
      "41:\tlearn: 4.4235320\ttotal: 516ms\tremaining: 55.9s\n",
      "42:\tlearn: 4.4176151\ttotal: 528ms\tremaining: 55.9s\n",
      "43:\tlearn: 4.4092883\ttotal: 539ms\tremaining: 55.8s\n",
      "44:\tlearn: 4.4020513\ttotal: 551ms\tremaining: 55.8s\n",
      "45:\tlearn: 4.3952313\ttotal: 563ms\tremaining: 55.7s\n",
      "46:\tlearn: 4.3907714\ttotal: 574ms\tremaining: 55.6s\n",
      "47:\tlearn: 4.3792403\ttotal: 587ms\tremaining: 55.7s\n",
      "48:\tlearn: 4.3748083\ttotal: 599ms\tremaining: 55.6s\n",
      "49:\tlearn: 4.3680388\ttotal: 612ms\tremaining: 55.7s\n",
      "50:\tlearn: 4.3620792\ttotal: 625ms\tremaining: 55.7s\n",
      "51:\tlearn: 4.3563101\ttotal: 637ms\tremaining: 55.7s\n",
      "52:\tlearn: 4.3502541\ttotal: 649ms\tremaining: 55.7s\n",
      "53:\tlearn: 4.3426591\ttotal: 663ms\tremaining: 55.8s\n",
      "54:\tlearn: 4.3352457\ttotal: 677ms\tremaining: 56s\n",
      "55:\tlearn: 4.3281633\ttotal: 690ms\tremaining: 56s\n",
      "56:\tlearn: 4.3229888\ttotal: 702ms\tremaining: 55.9s\n",
      "57:\tlearn: 4.3168737\ttotal: 714ms\tremaining: 55.9s\n",
      "58:\tlearn: 4.3128855\ttotal: 725ms\tremaining: 55.8s\n",
      "59:\tlearn: 4.3077694\ttotal: 738ms\tremaining: 55.8s\n",
      "60:\tlearn: 4.3045084\ttotal: 750ms\tremaining: 55.8s\n",
      "61:\tlearn: 4.2990937\ttotal: 762ms\tremaining: 55.8s\n",
      "62:\tlearn: 4.2940330\ttotal: 774ms\tremaining: 55.7s\n",
      "63:\tlearn: 4.2893089\ttotal: 786ms\tremaining: 55.7s\n",
      "64:\tlearn: 4.2845303\ttotal: 798ms\tremaining: 55.7s\n",
      "65:\tlearn: 4.2822876\ttotal: 810ms\tremaining: 55.6s\n",
      "66:\tlearn: 4.2777522\ttotal: 822ms\tremaining: 55.6s\n",
      "67:\tlearn: 4.2748616\ttotal: 833ms\tremaining: 55.5s\n",
      "68:\tlearn: 4.2706511\ttotal: 845ms\tremaining: 55.5s\n",
      "69:\tlearn: 4.2656025\ttotal: 857ms\tremaining: 55.4s\n",
      "70:\tlearn: 4.2611481\ttotal: 869ms\tremaining: 55.4s\n",
      "71:\tlearn: 4.2583048\ttotal: 882ms\tremaining: 55.5s\n",
      "72:\tlearn: 4.2504868\ttotal: 896ms\tremaining: 55.5s\n",
      "73:\tlearn: 4.2462154\ttotal: 909ms\tremaining: 55.6s\n",
      "74:\tlearn: 4.2420067\ttotal: 922ms\tremaining: 55.6s\n",
      "75:\tlearn: 4.2380852\ttotal: 933ms\tremaining: 55.5s\n",
      "76:\tlearn: 4.2336135\ttotal: 946ms\tremaining: 55.5s\n",
      "77:\tlearn: 4.2308331\ttotal: 958ms\tremaining: 55.5s\n",
      "78:\tlearn: 4.2241844\ttotal: 969ms\tremaining: 55.4s\n",
      "79:\tlearn: 4.2210382\ttotal: 981ms\tremaining: 55.4s\n",
      "80:\tlearn: 4.2171456\ttotal: 994ms\tremaining: 55.4s\n",
      "81:\tlearn: 4.2138917\ttotal: 1s\tremaining: 55.4s\n",
      "82:\tlearn: 4.2106048\ttotal: 1.02s\tremaining: 55.4s\n",
      "83:\tlearn: 4.2057410\ttotal: 1.03s\tremaining: 55.4s\n",
      "84:\tlearn: 4.2025343\ttotal: 1.04s\tremaining: 55.4s\n",
      "85:\tlearn: 4.1934377\ttotal: 1.05s\tremaining: 55.4s\n",
      "86:\tlearn: 4.1893513\ttotal: 1.07s\tremaining: 55.4s\n",
      "87:\tlearn: 4.1867478\ttotal: 1.08s\tremaining: 55.3s\n",
      "88:\tlearn: 4.1833342\ttotal: 1.09s\tremaining: 55.3s\n",
      "89:\tlearn: 4.1803993\ttotal: 1.1s\tremaining: 55.4s\n",
      "90:\tlearn: 4.1770364\ttotal: 1.12s\tremaining: 55.4s\n",
      "91:\tlearn: 4.1736726\ttotal: 1.13s\tremaining: 55.3s\n",
      "92:\tlearn: 4.1664353\ttotal: 1.14s\tremaining: 55.3s\n",
      "93:\tlearn: 4.1616861\ttotal: 1.15s\tremaining: 55.3s\n",
      "94:\tlearn: 4.1591843\ttotal: 1.17s\tremaining: 55.2s\n",
      "95:\tlearn: 4.1566942\ttotal: 1.18s\tremaining: 55.2s\n",
      "96:\tlearn: 4.1539558\ttotal: 1.19s\tremaining: 55.2s\n",
      "97:\tlearn: 4.1500108\ttotal: 1.2s\tremaining: 55.2s\n",
      "98:\tlearn: 4.1464436\ttotal: 1.21s\tremaining: 55.2s\n",
      "99:\tlearn: 4.1435939\ttotal: 1.23s\tremaining: 55.2s\n",
      "100:\tlearn: 4.1365699\ttotal: 1.24s\tremaining: 55.3s\n",
      "101:\tlearn: 4.1328113\ttotal: 1.25s\tremaining: 55.2s\n",
      "102:\tlearn: 4.1279303\ttotal: 1.26s\tremaining: 55.2s\n",
      "103:\tlearn: 4.1246173\ttotal: 1.28s\tremaining: 55.2s\n",
      "104:\tlearn: 4.1205149\ttotal: 1.29s\tremaining: 55.2s\n",
      "105:\tlearn: 4.1155871\ttotal: 1.3s\tremaining: 55.2s\n",
      "106:\tlearn: 4.1137003\ttotal: 1.31s\tremaining: 55.2s\n",
      "107:\tlearn: 4.1099330\ttotal: 1.33s\tremaining: 55.3s\n",
      "108:\tlearn: 4.1057688\ttotal: 1.34s\tremaining: 55.3s\n",
      "109:\tlearn: 4.1019487\ttotal: 1.35s\tremaining: 55.3s\n",
      "110:\tlearn: 4.0986296\ttotal: 1.37s\tremaining: 55.2s\n",
      "111:\tlearn: 4.0948923\ttotal: 1.38s\tremaining: 55.2s\n",
      "112:\tlearn: 4.0924686\ttotal: 1.39s\tremaining: 55.2s\n",
      "113:\tlearn: 4.0902817\ttotal: 1.4s\tremaining: 55.1s\n",
      "114:\tlearn: 4.0860093\ttotal: 1.41s\tremaining: 55.1s\n",
      "115:\tlearn: 4.0830880\ttotal: 1.43s\tremaining: 55.1s\n",
      "116:\tlearn: 4.0789921\ttotal: 1.44s\tremaining: 55.1s\n",
      "117:\tlearn: 4.0761686\ttotal: 1.45s\tremaining: 55.1s\n",
      "118:\tlearn: 4.0731149\ttotal: 1.46s\tremaining: 55s\n",
      "119:\tlearn: 4.0705841\ttotal: 1.47s\tremaining: 55s\n",
      "120:\tlearn: 4.0684380\ttotal: 1.49s\tremaining: 55s\n",
      "121:\tlearn: 4.0608147\ttotal: 1.5s\tremaining: 55s\n",
      "122:\tlearn: 4.0587563\ttotal: 1.51s\tremaining: 54.9s\n",
      "123:\tlearn: 4.0551248\ttotal: 1.52s\tremaining: 54.9s\n",
      "124:\tlearn: 4.0521328\ttotal: 1.53s\tremaining: 54.9s\n",
      "125:\tlearn: 4.0482750\ttotal: 1.55s\tremaining: 55s\n",
      "126:\tlearn: 4.0462034\ttotal: 1.56s\tremaining: 55s\n",
      "127:\tlearn: 4.0426945\ttotal: 1.57s\tremaining: 55s\n",
      "128:\tlearn: 4.0405822\ttotal: 1.59s\tremaining: 55s\n",
      "129:\tlearn: 4.0374970\ttotal: 1.6s\tremaining: 55s\n",
      "130:\tlearn: 4.0354953\ttotal: 1.61s\tremaining: 55s\n",
      "131:\tlearn: 4.0337047\ttotal: 1.62s\tremaining: 55s\n",
      "132:\tlearn: 4.0299347\ttotal: 1.64s\tremaining: 54.9s\n",
      "133:\tlearn: 4.0268852\ttotal: 1.65s\tremaining: 54.9s\n",
      "134:\tlearn: 4.0246022\ttotal: 1.66s\tremaining: 54.9s\n",
      "135:\tlearn: 4.0210609\ttotal: 1.67s\tremaining: 54.9s\n",
      "136:\tlearn: 4.0189168\ttotal: 1.68s\tremaining: 54.9s\n",
      "137:\tlearn: 4.0157513\ttotal: 1.7s\tremaining: 54.8s\n",
      "138:\tlearn: 4.0128463\ttotal: 1.71s\tremaining: 54.8s\n",
      "139:\tlearn: 4.0084730\ttotal: 1.72s\tremaining: 54.8s\n",
      "140:\tlearn: 4.0058777\ttotal: 1.73s\tremaining: 54.8s\n",
      "141:\tlearn: 4.0031778\ttotal: 1.75s\tremaining: 54.8s\n",
      "142:\tlearn: 4.0006834\ttotal: 1.76s\tremaining: 54.8s\n",
      "143:\tlearn: 3.9974370\ttotal: 1.77s\tremaining: 54.8s\n",
      "144:\tlearn: 3.9942115\ttotal: 1.78s\tremaining: 54.7s\n",
      "145:\tlearn: 3.9921707\ttotal: 1.79s\tremaining: 54.7s\n",
      "146:\tlearn: 3.9896557\ttotal: 1.81s\tremaining: 54.7s\n",
      "147:\tlearn: 3.9866921\ttotal: 1.82s\tremaining: 54.7s\n",
      "148:\tlearn: 3.9835809\ttotal: 1.83s\tremaining: 54.7s\n",
      "149:\tlearn: 3.9812448\ttotal: 1.84s\tremaining: 54.7s\n",
      "150:\tlearn: 3.9784960\ttotal: 1.85s\tremaining: 54.7s\n",
      "151:\tlearn: 3.9752362\ttotal: 1.87s\tremaining: 54.6s\n",
      "152:\tlearn: 3.9720239\ttotal: 1.88s\tremaining: 54.6s\n",
      "153:\tlearn: 3.9694704\ttotal: 1.89s\tremaining: 54.6s\n",
      "154:\tlearn: 3.9680721\ttotal: 1.9s\tremaining: 54.6s\n",
      "155:\tlearn: 3.9655146\ttotal: 1.92s\tremaining: 54.6s\n",
      "156:\tlearn: 3.9616813\ttotal: 1.93s\tremaining: 54.6s\n",
      "157:\tlearn: 3.9598021\ttotal: 1.94s\tremaining: 54.6s\n",
      "158:\tlearn: 3.9569810\ttotal: 1.96s\tremaining: 54.6s\n",
      "159:\tlearn: 3.9540946\ttotal: 1.97s\tremaining: 54.6s\n",
      "160:\tlearn: 3.9510482\ttotal: 1.98s\tremaining: 54.6s\n",
      "161:\tlearn: 3.9478769\ttotal: 1.99s\tremaining: 54.6s\n",
      "162:\tlearn: 3.9452244\ttotal: 2s\tremaining: 54.6s\n",
      "163:\tlearn: 3.9433780\ttotal: 2.02s\tremaining: 54.6s\n",
      "164:\tlearn: 3.9412941\ttotal: 2.03s\tremaining: 54.5s\n",
      "165:\tlearn: 3.9378899\ttotal: 2.04s\tremaining: 54.5s\n",
      "166:\tlearn: 3.9357894\ttotal: 2.05s\tremaining: 54.5s\n",
      "167:\tlearn: 3.9326629\ttotal: 2.07s\tremaining: 54.5s\n",
      "168:\tlearn: 3.9307863\ttotal: 2.08s\tremaining: 54.5s\n",
      "169:\tlearn: 3.9287592\ttotal: 2.09s\tremaining: 54.4s\n",
      "170:\tlearn: 3.9271245\ttotal: 2.1s\tremaining: 54.4s\n",
      "171:\tlearn: 3.9256789\ttotal: 2.11s\tremaining: 54.4s\n",
      "172:\tlearn: 3.9231276\ttotal: 2.12s\tremaining: 54.4s\n",
      "173:\tlearn: 3.9200947\ttotal: 2.14s\tremaining: 54.4s\n",
      "174:\tlearn: 3.9179934\ttotal: 2.15s\tremaining: 54.4s\n",
      "175:\tlearn: 3.9153758\ttotal: 2.16s\tremaining: 54.4s\n",
      "176:\tlearn: 3.9118750\ttotal: 2.18s\tremaining: 54.4s\n",
      "177:\tlearn: 3.9088997\ttotal: 2.19s\tremaining: 54.4s\n",
      "178:\tlearn: 3.9052265\ttotal: 2.2s\tremaining: 54.4s\n",
      "179:\tlearn: 3.9028049\ttotal: 2.22s\tremaining: 54.4s\n",
      "180:\tlearn: 3.9008825\ttotal: 2.23s\tremaining: 54.4s\n",
      "181:\tlearn: 3.8967115\ttotal: 2.24s\tremaining: 54.4s\n",
      "182:\tlearn: 3.8953872\ttotal: 2.25s\tremaining: 54.4s\n",
      "183:\tlearn: 3.8933682\ttotal: 2.27s\tremaining: 54.4s\n",
      "184:\tlearn: 3.8910226\ttotal: 2.28s\tremaining: 54.3s\n",
      "185:\tlearn: 3.8893512\ttotal: 2.29s\tremaining: 54.3s\n",
      "186:\tlearn: 3.8862691\ttotal: 2.3s\tremaining: 54.3s\n",
      "187:\tlearn: 3.8843910\ttotal: 2.31s\tremaining: 54.3s\n",
      "188:\tlearn: 3.8823153\ttotal: 2.32s\tremaining: 54.2s\n",
      "189:\tlearn: 3.8794928\ttotal: 2.34s\tremaining: 54.2s\n",
      "190:\tlearn: 3.8764359\ttotal: 2.35s\tremaining: 54.2s\n",
      "191:\tlearn: 3.8750129\ttotal: 2.36s\tremaining: 54.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192:\tlearn: 3.8726942\ttotal: 2.38s\tremaining: 54.2s\n",
      "193:\tlearn: 3.8708520\ttotal: 2.39s\tremaining: 54.2s\n",
      "194:\tlearn: 3.8691568\ttotal: 2.4s\tremaining: 54.2s\n",
      "195:\tlearn: 3.8669887\ttotal: 2.41s\tremaining: 54.2s\n",
      "196:\tlearn: 3.8645965\ttotal: 2.42s\tremaining: 54.2s\n",
      "197:\tlearn: 3.8624749\ttotal: 2.44s\tremaining: 54.2s\n",
      "198:\tlearn: 3.8597289\ttotal: 2.45s\tremaining: 54.1s\n",
      "199:\tlearn: 3.8577176\ttotal: 2.46s\tremaining: 54.1s\n",
      "200:\tlearn: 3.8555070\ttotal: 2.47s\tremaining: 54.1s\n",
      "201:\tlearn: 3.8524434\ttotal: 2.49s\tremaining: 54.1s\n",
      "202:\tlearn: 3.8488529\ttotal: 2.5s\tremaining: 54.1s\n",
      "203:\tlearn: 3.8446513\ttotal: 2.51s\tremaining: 54.1s\n",
      "204:\tlearn: 3.8426513\ttotal: 2.52s\tremaining: 54.1s\n",
      "205:\tlearn: 3.8403471\ttotal: 2.53s\tremaining: 54s\n",
      "206:\tlearn: 3.8383200\ttotal: 2.55s\tremaining: 54s\n",
      "207:\tlearn: 3.8360437\ttotal: 2.56s\tremaining: 54s\n",
      "208:\tlearn: 3.8349412\ttotal: 2.57s\tremaining: 54s\n",
      "209:\tlearn: 3.8330335\ttotal: 2.58s\tremaining: 53.9s\n",
      "210:\tlearn: 3.8299026\ttotal: 2.6s\tremaining: 54s\n",
      "211:\tlearn: 3.8272957\ttotal: 2.61s\tremaining: 54s\n",
      "212:\tlearn: 3.8254585\ttotal: 2.62s\tremaining: 54s\n",
      "213:\tlearn: 3.8239756\ttotal: 2.63s\tremaining: 54s\n",
      "214:\tlearn: 3.8219616\ttotal: 2.65s\tremaining: 54s\n",
      "215:\tlearn: 3.8187860\ttotal: 2.66s\tremaining: 54s\n",
      "216:\tlearn: 3.8174253\ttotal: 2.67s\tremaining: 54s\n",
      "217:\tlearn: 3.8157129\ttotal: 2.68s\tremaining: 53.9s\n",
      "218:\tlearn: 3.8129162\ttotal: 2.7s\tremaining: 53.9s\n",
      "219:\tlearn: 3.8107822\ttotal: 2.71s\tremaining: 53.9s\n",
      "220:\tlearn: 3.8060277\ttotal: 2.72s\tremaining: 53.9s\n",
      "221:\tlearn: 3.8043762\ttotal: 2.73s\tremaining: 53.9s\n",
      "222:\tlearn: 3.8013981\ttotal: 2.75s\tremaining: 53.9s\n",
      "223:\tlearn: 3.7999989\ttotal: 2.76s\tremaining: 53.9s\n",
      "224:\tlearn: 3.7986876\ttotal: 2.77s\tremaining: 53.9s\n",
      "225:\tlearn: 3.7962707\ttotal: 2.78s\tremaining: 53.8s\n",
      "226:\tlearn: 3.7936396\ttotal: 2.79s\tremaining: 53.8s\n",
      "227:\tlearn: 3.7910351\ttotal: 2.81s\tremaining: 53.8s\n",
      "228:\tlearn: 3.7880303\ttotal: 2.82s\tremaining: 53.8s\n",
      "229:\tlearn: 3.7860411\ttotal: 2.83s\tremaining: 53.8s\n",
      "230:\tlearn: 3.7839865\ttotal: 2.84s\tremaining: 53.8s\n",
      "231:\tlearn: 3.7813202\ttotal: 2.86s\tremaining: 53.8s\n",
      "232:\tlearn: 3.7787778\ttotal: 2.87s\tremaining: 53.7s\n",
      "233:\tlearn: 3.7761939\ttotal: 2.88s\tremaining: 53.7s\n",
      "234:\tlearn: 3.7730389\ttotal: 2.89s\tremaining: 53.7s\n",
      "235:\tlearn: 3.7706132\ttotal: 2.9s\tremaining: 53.7s\n",
      "236:\tlearn: 3.7690479\ttotal: 2.92s\tremaining: 53.7s\n",
      "237:\tlearn: 3.7677746\ttotal: 2.93s\tremaining: 53.6s\n",
      "238:\tlearn: 3.7657983\ttotal: 2.94s\tremaining: 53.6s\n",
      "239:\tlearn: 3.7636431\ttotal: 2.95s\tremaining: 53.6s\n",
      "240:\tlearn: 3.7619688\ttotal: 2.96s\tremaining: 53.5s\n",
      "241:\tlearn: 3.7599340\ttotal: 2.97s\tremaining: 53.5s\n",
      "242:\tlearn: 3.7576981\ttotal: 2.98s\tremaining: 53.5s\n",
      "243:\tlearn: 3.7556227\ttotal: 3s\tremaining: 53.5s\n",
      "244:\tlearn: 3.7535339\ttotal: 3.01s\tremaining: 53.5s\n",
      "245:\tlearn: 3.7513064\ttotal: 3.02s\tremaining: 53.5s\n",
      "246:\tlearn: 3.7489330\ttotal: 3.04s\tremaining: 53.5s\n",
      "247:\tlearn: 3.7476250\ttotal: 3.05s\tremaining: 53.5s\n",
      "248:\tlearn: 3.7440370\ttotal: 3.06s\tremaining: 53.5s\n",
      "249:\tlearn: 3.7425386\ttotal: 3.07s\tremaining: 53.5s\n",
      "250:\tlearn: 3.7405478\ttotal: 3.08s\tremaining: 53.4s\n",
      "251:\tlearn: 3.7388775\ttotal: 3.1s\tremaining: 53.4s\n",
      "252:\tlearn: 3.7368586\ttotal: 3.11s\tremaining: 53.4s\n",
      "253:\tlearn: 3.7335688\ttotal: 3.12s\tremaining: 53.4s\n",
      "254:\tlearn: 3.7316573\ttotal: 3.13s\tremaining: 53.4s\n",
      "255:\tlearn: 3.7283165\ttotal: 3.15s\tremaining: 53.3s\n",
      "256:\tlearn: 3.7269261\ttotal: 3.16s\tremaining: 53.3s\n",
      "257:\tlearn: 3.7250534\ttotal: 3.17s\tremaining: 53.3s\n",
      "258:\tlearn: 3.7235168\ttotal: 3.18s\tremaining: 53.3s\n",
      "259:\tlearn: 3.7214798\ttotal: 3.19s\tremaining: 53.3s\n",
      "260:\tlearn: 3.7201524\ttotal: 3.21s\tremaining: 53.3s\n",
      "261:\tlearn: 3.7181154\ttotal: 3.22s\tremaining: 53.3s\n",
      "262:\tlearn: 3.7163881\ttotal: 3.23s\tremaining: 53.3s\n",
      "263:\tlearn: 3.7155871\ttotal: 3.24s\tremaining: 53.2s\n",
      "264:\tlearn: 3.7135570\ttotal: 3.26s\tremaining: 53.2s\n",
      "265:\tlearn: 3.7118757\ttotal: 3.27s\tremaining: 53.2s\n",
      "266:\tlearn: 3.7103265\ttotal: 3.28s\tremaining: 53.2s\n",
      "267:\tlearn: 3.7091167\ttotal: 3.29s\tremaining: 53.2s\n",
      "268:\tlearn: 3.7070121\ttotal: 3.3s\tremaining: 53.2s\n",
      "269:\tlearn: 3.7031705\ttotal: 3.32s\tremaining: 53.2s\n",
      "270:\tlearn: 3.7021166\ttotal: 3.33s\tremaining: 53.1s\n",
      "271:\tlearn: 3.6997389\ttotal: 3.34s\tremaining: 53.1s\n",
      "272:\tlearn: 3.6979182\ttotal: 3.35s\tremaining: 53.1s\n",
      "273:\tlearn: 3.6955252\ttotal: 3.36s\tremaining: 53.1s\n",
      "274:\tlearn: 3.6925772\ttotal: 3.37s\tremaining: 53.1s\n",
      "275:\tlearn: 3.6907803\ttotal: 3.39s\tremaining: 53s\n",
      "276:\tlearn: 3.6895505\ttotal: 3.4s\tremaining: 53s\n",
      "277:\tlearn: 3.6868995\ttotal: 3.41s\tremaining: 53s\n",
      "278:\tlearn: 3.6858178\ttotal: 3.42s\tremaining: 53s\n",
      "279:\tlearn: 3.6848960\ttotal: 3.43s\tremaining: 52.9s\n",
      "280:\tlearn: 3.6827814\ttotal: 3.44s\tremaining: 52.9s\n",
      "281:\tlearn: 3.6817200\ttotal: 3.46s\tremaining: 53s\n",
      "282:\tlearn: 3.6801787\ttotal: 3.47s\tremaining: 53s\n",
      "283:\tlearn: 3.6779163\ttotal: 3.48s\tremaining: 53s\n",
      "284:\tlearn: 3.6753177\ttotal: 3.5s\tremaining: 53s\n",
      "285:\tlearn: 3.6734676\ttotal: 3.51s\tremaining: 52.9s\n",
      "286:\tlearn: 3.6718229\ttotal: 3.52s\tremaining: 52.9s\n",
      "287:\tlearn: 3.6694787\ttotal: 3.53s\tremaining: 52.9s\n",
      "288:\tlearn: 3.6684071\ttotal: 3.54s\tremaining: 52.9s\n",
      "289:\tlearn: 3.6666086\ttotal: 3.56s\tremaining: 52.8s\n",
      "290:\tlearn: 3.6652339\ttotal: 3.57s\tremaining: 52.8s\n",
      "291:\tlearn: 3.6638436\ttotal: 3.58s\tremaining: 52.8s\n",
      "292:\tlearn: 3.6627320\ttotal: 3.59s\tremaining: 52.8s\n",
      "293:\tlearn: 3.6610921\ttotal: 3.6s\tremaining: 52.8s\n",
      "294:\tlearn: 3.6586239\ttotal: 3.62s\tremaining: 52.8s\n",
      "295:\tlearn: 3.6569141\ttotal: 3.63s\tremaining: 52.8s\n",
      "296:\tlearn: 3.6549652\ttotal: 3.64s\tremaining: 52.7s\n",
      "297:\tlearn: 3.6533458\ttotal: 3.65s\tremaining: 52.8s\n",
      "298:\tlearn: 3.6523959\ttotal: 3.67s\tremaining: 52.8s\n",
      "299:\tlearn: 3.6511415\ttotal: 3.68s\tremaining: 52.7s\n",
      "300:\tlearn: 3.6492805\ttotal: 3.69s\tremaining: 52.8s\n",
      "301:\tlearn: 3.6471386\ttotal: 3.71s\tremaining: 52.8s\n",
      "302:\tlearn: 3.6446400\ttotal: 3.72s\tremaining: 52.8s\n",
      "303:\tlearn: 3.6421246\ttotal: 3.73s\tremaining: 52.7s\n",
      "304:\tlearn: 3.6397903\ttotal: 3.75s\tremaining: 52.7s\n",
      "305:\tlearn: 3.6382698\ttotal: 3.76s\tremaining: 52.7s\n",
      "306:\tlearn: 3.6372688\ttotal: 3.77s\tremaining: 52.7s\n",
      "307:\tlearn: 3.6358596\ttotal: 3.78s\tremaining: 52.7s\n",
      "308:\tlearn: 3.6332795\ttotal: 3.79s\tremaining: 52.7s\n",
      "309:\tlearn: 3.6317739\ttotal: 3.81s\tremaining: 52.6s\n",
      "310:\tlearn: 3.6297942\ttotal: 3.82s\tremaining: 52.6s\n",
      "311:\tlearn: 3.6284694\ttotal: 3.83s\tremaining: 52.6s\n",
      "312:\tlearn: 3.6271463\ttotal: 3.84s\tremaining: 52.6s\n",
      "313:\tlearn: 3.6256666\ttotal: 3.85s\tremaining: 52.6s\n",
      "314:\tlearn: 3.6248984\ttotal: 3.87s\tremaining: 52.6s\n",
      "315:\tlearn: 3.6231295\ttotal: 3.88s\tremaining: 52.6s\n",
      "316:\tlearn: 3.6219740\ttotal: 3.89s\tremaining: 52.6s\n",
      "317:\tlearn: 3.6202160\ttotal: 3.9s\tremaining: 52.5s\n",
      "318:\tlearn: 3.6190348\ttotal: 3.92s\tremaining: 52.5s\n",
      "319:\tlearn: 3.6164408\ttotal: 3.93s\tremaining: 52.5s\n",
      "320:\tlearn: 3.6149686\ttotal: 3.94s\tremaining: 52.5s\n",
      "321:\tlearn: 3.6129961\ttotal: 3.95s\tremaining: 52.5s\n",
      "322:\tlearn: 3.6114671\ttotal: 3.96s\tremaining: 52.5s\n",
      "323:\tlearn: 3.6103511\ttotal: 3.98s\tremaining: 52.4s\n",
      "324:\tlearn: 3.6081702\ttotal: 3.99s\tremaining: 52.4s\n",
      "325:\tlearn: 3.6062578\ttotal: 4s\tremaining: 52.4s\n",
      "326:\tlearn: 3.6042445\ttotal: 4.01s\tremaining: 52.4s\n",
      "327:\tlearn: 3.6025404\ttotal: 4.03s\tremaining: 52.4s\n",
      "328:\tlearn: 3.6004971\ttotal: 4.04s\tremaining: 52.4s\n",
      "329:\tlearn: 3.5997189\ttotal: 4.05s\tremaining: 52.4s\n",
      "330:\tlearn: 3.5985787\ttotal: 4.06s\tremaining: 52.4s\n",
      "331:\tlearn: 3.5985529\ttotal: 4.07s\tremaining: 52.3s\n",
      "332:\tlearn: 3.5970112\ttotal: 4.09s\tremaining: 52.4s\n",
      "333:\tlearn: 3.5955855\ttotal: 4.1s\tremaining: 52.4s\n",
      "334:\tlearn: 3.5941315\ttotal: 4.11s\tremaining: 52.3s\n",
      "335:\tlearn: 3.5908056\ttotal: 4.13s\tremaining: 52.3s\n",
      "336:\tlearn: 3.5896001\ttotal: 4.14s\tremaining: 52.3s\n",
      "337:\tlearn: 3.5881405\ttotal: 4.15s\tremaining: 52.3s\n",
      "338:\tlearn: 3.5867237\ttotal: 4.17s\tremaining: 52.3s\n",
      "339:\tlearn: 3.5851214\ttotal: 4.18s\tremaining: 52.3s\n",
      "340:\tlearn: 3.5836728\ttotal: 4.19s\tremaining: 52.3s\n",
      "341:\tlearn: 3.5835485\ttotal: 4.2s\tremaining: 52.3s\n",
      "342:\tlearn: 3.5818606\ttotal: 4.22s\tremaining: 52.3s\n",
      "343:\tlearn: 3.5800730\ttotal: 4.23s\tremaining: 52.3s\n",
      "344:\tlearn: 3.5792537\ttotal: 4.24s\tremaining: 52.3s\n",
      "345:\tlearn: 3.5781261\ttotal: 4.26s\tremaining: 52.3s\n",
      "346:\tlearn: 3.5750519\ttotal: 4.27s\tremaining: 52.3s\n",
      "347:\tlearn: 3.5734520\ttotal: 4.28s\tremaining: 52.3s\n",
      "348:\tlearn: 3.5715823\ttotal: 4.3s\tremaining: 52.3s\n",
      "349:\tlearn: 3.5702084\ttotal: 4.31s\tremaining: 52.3s\n",
      "350:\tlearn: 3.5700777\ttotal: 4.32s\tremaining: 52.3s\n",
      "351:\tlearn: 3.5685357\ttotal: 4.33s\tremaining: 52.3s\n",
      "352:\tlearn: 3.5674566\ttotal: 4.34s\tremaining: 52.2s\n",
      "353:\tlearn: 3.5651126\ttotal: 4.36s\tremaining: 52.2s\n",
      "354:\tlearn: 3.5639689\ttotal: 4.37s\tremaining: 52.2s\n",
      "355:\tlearn: 3.5621243\ttotal: 4.38s\tremaining: 52.2s\n",
      "356:\tlearn: 3.5605553\ttotal: 4.39s\tremaining: 52.2s\n",
      "357:\tlearn: 3.5588185\ttotal: 4.41s\tremaining: 52.2s\n",
      "358:\tlearn: 3.5570469\ttotal: 4.42s\tremaining: 52.2s\n",
      "359:\tlearn: 3.5553074\ttotal: 4.43s\tremaining: 52.2s\n",
      "360:\tlearn: 3.5532999\ttotal: 4.44s\tremaining: 52.1s\n",
      "361:\tlearn: 3.5521254\ttotal: 4.46s\tremaining: 52.1s\n",
      "362:\tlearn: 3.5510511\ttotal: 4.47s\tremaining: 52.1s\n",
      "363:\tlearn: 3.5488590\ttotal: 4.48s\tremaining: 52.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364:\tlearn: 3.5478363\ttotal: 4.49s\tremaining: 52.1s\n",
      "365:\tlearn: 3.5458421\ttotal: 4.51s\tremaining: 52.1s\n",
      "366:\tlearn: 3.5447264\ttotal: 4.52s\tremaining: 52.1s\n",
      "367:\tlearn: 3.5427872\ttotal: 4.53s\tremaining: 52.1s\n",
      "368:\tlearn: 3.5410611\ttotal: 4.54s\tremaining: 52.1s\n",
      "369:\tlearn: 3.5395881\ttotal: 4.56s\tremaining: 52.1s\n",
      "370:\tlearn: 3.5385511\ttotal: 4.57s\tremaining: 52.1s\n",
      "371:\tlearn: 3.5370668\ttotal: 4.58s\tremaining: 52.1s\n",
      "372:\tlearn: 3.5357764\ttotal: 4.59s\tremaining: 52s\n",
      "373:\tlearn: 3.5339566\ttotal: 4.61s\tremaining: 52s\n",
      "374:\tlearn: 3.5326339\ttotal: 4.62s\tremaining: 52s\n",
      "375:\tlearn: 3.5310441\ttotal: 4.63s\tremaining: 52s\n",
      "376:\tlearn: 3.5296879\ttotal: 4.64s\tremaining: 52s\n",
      "377:\tlearn: 3.5284186\ttotal: 4.65s\tremaining: 52s\n",
      "378:\tlearn: 3.5268405\ttotal: 4.67s\tremaining: 51.9s\n",
      "379:\tlearn: 3.5247689\ttotal: 4.68s\tremaining: 51.9s\n",
      "380:\tlearn: 3.5233182\ttotal: 4.69s\tremaining: 51.9s\n",
      "381:\tlearn: 3.5219261\ttotal: 4.7s\tremaining: 51.9s\n",
      "382:\tlearn: 3.5205189\ttotal: 4.71s\tremaining: 51.9s\n",
      "383:\tlearn: 3.5187583\ttotal: 4.73s\tremaining: 51.9s\n",
      "384:\tlearn: 3.5172566\ttotal: 4.74s\tremaining: 51.9s\n",
      "385:\tlearn: 3.5150690\ttotal: 4.75s\tremaining: 51.8s\n",
      "386:\tlearn: 3.5130018\ttotal: 4.76s\tremaining: 51.8s\n",
      "387:\tlearn: 3.5118200\ttotal: 4.78s\tremaining: 51.8s\n",
      "388:\tlearn: 3.5103914\ttotal: 4.79s\tremaining: 51.8s\n",
      "389:\tlearn: 3.5095440\ttotal: 4.8s\tremaining: 51.8s\n",
      "390:\tlearn: 3.5083112\ttotal: 4.81s\tremaining: 51.8s\n",
      "391:\tlearn: 3.5070459\ttotal: 4.82s\tremaining: 51.8s\n",
      "392:\tlearn: 3.5060348\ttotal: 4.83s\tremaining: 51.7s\n",
      "393:\tlearn: 3.5048263\ttotal: 4.85s\tremaining: 51.7s\n",
      "394:\tlearn: 3.5036718\ttotal: 4.86s\tremaining: 51.7s\n",
      "395:\tlearn: 3.5020363\ttotal: 4.87s\tremaining: 51.7s\n",
      "396:\tlearn: 3.5010353\ttotal: 4.88s\tremaining: 51.7s\n",
      "397:\tlearn: 3.5002093\ttotal: 4.89s\tremaining: 51.6s\n",
      "398:\tlearn: 3.4991909\ttotal: 4.9s\tremaining: 51.6s\n",
      "399:\tlearn: 3.4974500\ttotal: 4.92s\tremaining: 51.6s\n",
      "400:\tlearn: 3.4962384\ttotal: 4.93s\tremaining: 51.6s\n",
      "401:\tlearn: 3.4949302\ttotal: 4.94s\tremaining: 51.6s\n",
      "402:\tlearn: 3.4937017\ttotal: 4.95s\tremaining: 51.6s\n",
      "403:\tlearn: 3.4926049\ttotal: 4.96s\tremaining: 51.5s\n",
      "404:\tlearn: 3.4911417\ttotal: 4.98s\tremaining: 51.5s\n",
      "405:\tlearn: 3.4897628\ttotal: 4.99s\tremaining: 51.5s\n",
      "406:\tlearn: 3.4882560\ttotal: 5s\tremaining: 51.5s\n",
      "407:\tlearn: 3.4868325\ttotal: 5.01s\tremaining: 51.5s\n",
      "408:\tlearn: 3.4848501\ttotal: 5.03s\tremaining: 51.5s\n",
      "409:\tlearn: 3.4836305\ttotal: 5.04s\tremaining: 51.4s\n",
      "410:\tlearn: 3.4821721\ttotal: 5.05s\tremaining: 51.4s\n",
      "411:\tlearn: 3.4810060\ttotal: 5.06s\tremaining: 51.4s\n",
      "412:\tlearn: 3.4789680\ttotal: 5.07s\tremaining: 51.4s\n",
      "413:\tlearn: 3.4788642\ttotal: 5.08s\tremaining: 51.4s\n",
      "414:\tlearn: 3.4775278\ttotal: 5.09s\tremaining: 51.4s\n",
      "415:\tlearn: 3.4759005\ttotal: 5.11s\tremaining: 51.3s\n",
      "416:\tlearn: 3.4747685\ttotal: 5.12s\tremaining: 51.3s\n",
      "417:\tlearn: 3.4732194\ttotal: 5.13s\tremaining: 51.3s\n",
      "418:\tlearn: 3.4721816\ttotal: 5.15s\tremaining: 51.3s\n",
      "419:\tlearn: 3.4712389\ttotal: 5.16s\tremaining: 51.3s\n",
      "420:\tlearn: 3.4698544\ttotal: 5.17s\tremaining: 51.3s\n",
      "421:\tlearn: 3.4690589\ttotal: 5.18s\tremaining: 51.3s\n",
      "422:\tlearn: 3.4675794\ttotal: 5.2s\tremaining: 51.3s\n",
      "423:\tlearn: 3.4661353\ttotal: 5.21s\tremaining: 51.3s\n",
      "424:\tlearn: 3.4651802\ttotal: 5.22s\tremaining: 51.3s\n",
      "425:\tlearn: 3.4639303\ttotal: 5.23s\tremaining: 51.2s\n",
      "426:\tlearn: 3.4625690\ttotal: 5.24s\tremaining: 51.2s\n",
      "427:\tlearn: 3.4601958\ttotal: 5.26s\tremaining: 51.2s\n",
      "428:\tlearn: 3.4585161\ttotal: 5.27s\tremaining: 51.2s\n",
      "429:\tlearn: 3.4565397\ttotal: 5.28s\tremaining: 51.2s\n",
      "430:\tlearn: 3.4557326\ttotal: 5.29s\tremaining: 51.2s\n",
      "431:\tlearn: 3.4548390\ttotal: 5.3s\tremaining: 51.2s\n",
      "432:\tlearn: 3.4533142\ttotal: 5.32s\tremaining: 51.1s\n",
      "433:\tlearn: 3.4521139\ttotal: 5.33s\tremaining: 51.1s\n",
      "434:\tlearn: 3.4508970\ttotal: 5.34s\tremaining: 51.1s\n",
      "435:\tlearn: 3.4492559\ttotal: 5.36s\tremaining: 51.1s\n",
      "436:\tlearn: 3.4477650\ttotal: 5.37s\tremaining: 51.1s\n",
      "437:\tlearn: 3.4469448\ttotal: 5.38s\tremaining: 51.1s\n",
      "438:\tlearn: 3.4459266\ttotal: 5.39s\tremaining: 51.1s\n",
      "439:\tlearn: 3.4437119\ttotal: 5.4s\tremaining: 51.1s\n",
      "440:\tlearn: 3.4426596\ttotal: 5.41s\tremaining: 51s\n",
      "441:\tlearn: 3.4411761\ttotal: 5.43s\tremaining: 51s\n",
      "442:\tlearn: 3.4396715\ttotal: 5.44s\tremaining: 51s\n",
      "443:\tlearn: 3.4386855\ttotal: 5.45s\tremaining: 51s\n",
      "444:\tlearn: 3.4379743\ttotal: 5.46s\tremaining: 51s\n",
      "445:\tlearn: 3.4373479\ttotal: 5.47s\tremaining: 50.9s\n",
      "446:\tlearn: 3.4364076\ttotal: 5.48s\tremaining: 50.9s\n",
      "447:\tlearn: 3.4346886\ttotal: 5.49s\tremaining: 50.9s\n",
      "448:\tlearn: 3.4331231\ttotal: 5.51s\tremaining: 50.9s\n",
      "449:\tlearn: 3.4323598\ttotal: 5.52s\tremaining: 50.9s\n",
      "450:\tlearn: 3.4310864\ttotal: 5.53s\tremaining: 50.9s\n",
      "451:\tlearn: 3.4304783\ttotal: 5.54s\tremaining: 50.8s\n",
      "452:\tlearn: 3.4296179\ttotal: 5.56s\tremaining: 50.8s\n",
      "453:\tlearn: 3.4278558\ttotal: 5.57s\tremaining: 50.8s\n",
      "454:\tlearn: 3.4276375\ttotal: 5.58s\tremaining: 50.8s\n",
      "455:\tlearn: 3.4268647\ttotal: 5.59s\tremaining: 50.8s\n",
      "456:\tlearn: 3.4260292\ttotal: 5.61s\tremaining: 50.8s\n",
      "457:\tlearn: 3.4253062\ttotal: 5.62s\tremaining: 50.8s\n",
      "458:\tlearn: 3.4243056\ttotal: 5.63s\tremaining: 50.8s\n",
      "459:\tlearn: 3.4226893\ttotal: 5.64s\tremaining: 50.8s\n",
      "460:\tlearn: 3.4213585\ttotal: 5.66s\tremaining: 50.8s\n",
      "461:\tlearn: 3.4200510\ttotal: 5.67s\tremaining: 50.8s\n",
      "462:\tlearn: 3.4189338\ttotal: 5.68s\tremaining: 50.7s\n",
      "463:\tlearn: 3.4183750\ttotal: 5.69s\tremaining: 50.7s\n",
      "464:\tlearn: 3.4163438\ttotal: 5.71s\tremaining: 50.7s\n",
      "465:\tlearn: 3.4153725\ttotal: 5.72s\tremaining: 50.7s\n",
      "466:\tlearn: 3.4140160\ttotal: 5.73s\tremaining: 50.7s\n",
      "467:\tlearn: 3.4133517\ttotal: 5.74s\tremaining: 50.7s\n",
      "468:\tlearn: 3.4124455\ttotal: 5.75s\tremaining: 50.7s\n",
      "469:\tlearn: 3.4107677\ttotal: 5.77s\tremaining: 50.7s\n",
      "470:\tlearn: 3.4100743\ttotal: 5.78s\tremaining: 50.6s\n",
      "471:\tlearn: 3.4088547\ttotal: 5.79s\tremaining: 50.6s\n",
      "472:\tlearn: 3.4074433\ttotal: 5.8s\tremaining: 50.6s\n",
      "473:\tlearn: 3.4064808\ttotal: 5.82s\tremaining: 50.6s\n",
      "474:\tlearn: 3.4044036\ttotal: 5.83s\tremaining: 50.6s\n",
      "475:\tlearn: 3.4026590\ttotal: 5.84s\tremaining: 50.6s\n",
      "476:\tlearn: 3.4008378\ttotal: 5.86s\tremaining: 50.6s\n",
      "477:\tlearn: 3.3990901\ttotal: 5.87s\tremaining: 50.6s\n",
      "478:\tlearn: 3.3980114\ttotal: 5.88s\tremaining: 50.6s\n",
      "479:\tlearn: 3.3977583\ttotal: 5.89s\tremaining: 50.5s\n",
      "480:\tlearn: 3.3971585\ttotal: 5.9s\tremaining: 50.5s\n",
      "481:\tlearn: 3.3958772\ttotal: 5.91s\tremaining: 50.5s\n",
      "482:\tlearn: 3.3940537\ttotal: 5.92s\tremaining: 50.5s\n",
      "483:\tlearn: 3.3930830\ttotal: 5.93s\tremaining: 50.5s\n",
      "484:\tlearn: 3.3920040\ttotal: 5.95s\tremaining: 50.4s\n",
      "485:\tlearn: 3.3908161\ttotal: 5.96s\tremaining: 50.4s\n",
      "486:\tlearn: 3.3888777\ttotal: 5.97s\tremaining: 50.4s\n",
      "487:\tlearn: 3.3876558\ttotal: 5.99s\tremaining: 50.4s\n",
      "488:\tlearn: 3.3869871\ttotal: 6s\tremaining: 50.4s\n",
      "489:\tlearn: 3.3860411\ttotal: 6.01s\tremaining: 50.4s\n",
      "490:\tlearn: 3.3841226\ttotal: 6.03s\tremaining: 50.4s\n",
      "491:\tlearn: 3.3830007\ttotal: 6.04s\tremaining: 50.4s\n",
      "492:\tlearn: 3.3817690\ttotal: 6.05s\tremaining: 50.4s\n",
      "493:\tlearn: 3.3806681\ttotal: 6.06s\tremaining: 50.4s\n",
      "494:\tlearn: 3.3797859\ttotal: 6.07s\tremaining: 50.3s\n",
      "495:\tlearn: 3.3788955\ttotal: 6.08s\tremaining: 50.3s\n",
      "496:\tlearn: 3.3770584\ttotal: 6.1s\tremaining: 50.3s\n",
      "497:\tlearn: 3.3752694\ttotal: 6.11s\tremaining: 50.3s\n",
      "498:\tlearn: 3.3736132\ttotal: 6.12s\tremaining: 50.3s\n",
      "499:\tlearn: 3.3725376\ttotal: 6.13s\tremaining: 50.3s\n",
      "500:\tlearn: 3.3706546\ttotal: 6.15s\tremaining: 50.3s\n",
      "501:\tlearn: 3.3694249\ttotal: 6.16s\tremaining: 50.3s\n",
      "502:\tlearn: 3.3683750\ttotal: 6.17s\tremaining: 50.2s\n",
      "503:\tlearn: 3.3663184\ttotal: 6.18s\tremaining: 50.2s\n",
      "504:\tlearn: 3.3643851\ttotal: 6.2s\tremaining: 50.2s\n",
      "505:\tlearn: 3.3632796\ttotal: 6.21s\tremaining: 50.2s\n",
      "506:\tlearn: 3.3623322\ttotal: 6.22s\tremaining: 50.2s\n",
      "507:\tlearn: 3.3612508\ttotal: 6.23s\tremaining: 50.2s\n",
      "508:\tlearn: 3.3603814\ttotal: 6.24s\tremaining: 50.2s\n",
      "509:\tlearn: 3.3589936\ttotal: 6.26s\tremaining: 50.2s\n",
      "510:\tlearn: 3.3581004\ttotal: 6.27s\tremaining: 50.1s\n",
      "511:\tlearn: 3.3567873\ttotal: 6.28s\tremaining: 50.1s\n",
      "512:\tlearn: 3.3555045\ttotal: 6.29s\tremaining: 50.1s\n",
      "513:\tlearn: 3.3539311\ttotal: 6.3s\tremaining: 50.1s\n",
      "514:\tlearn: 3.3538477\ttotal: 6.31s\tremaining: 50.1s\n",
      "515:\tlearn: 3.3529754\ttotal: 6.33s\tremaining: 50s\n",
      "516:\tlearn: 3.3529683\ttotal: 6.33s\tremaining: 50s\n",
      "517:\tlearn: 3.3513992\ttotal: 6.35s\tremaining: 50s\n",
      "518:\tlearn: 3.3501017\ttotal: 6.36s\tremaining: 50s\n",
      "519:\tlearn: 3.3488562\ttotal: 6.37s\tremaining: 50s\n",
      "520:\tlearn: 3.3478554\ttotal: 6.38s\tremaining: 49.9s\n",
      "521:\tlearn: 3.3464431\ttotal: 6.39s\tremaining: 49.9s\n",
      "522:\tlearn: 3.3448631\ttotal: 6.41s\tremaining: 49.9s\n",
      "523:\tlearn: 3.3436735\ttotal: 6.42s\tremaining: 49.9s\n",
      "524:\tlearn: 3.3435790\ttotal: 6.43s\tremaining: 49.9s\n",
      "525:\tlearn: 3.3423123\ttotal: 6.45s\tremaining: 49.9s\n",
      "526:\tlearn: 3.3414670\ttotal: 6.46s\tremaining: 49.9s\n",
      "527:\tlearn: 3.3404298\ttotal: 6.47s\tremaining: 49.9s\n",
      "528:\tlearn: 3.3397064\ttotal: 6.48s\tremaining: 49.8s\n",
      "529:\tlearn: 3.3387378\ttotal: 6.49s\tremaining: 49.8s\n",
      "530:\tlearn: 3.3376534\ttotal: 6.5s\tremaining: 49.8s\n",
      "531:\tlearn: 3.3368689\ttotal: 6.52s\tremaining: 49.8s\n",
      "532:\tlearn: 3.3354457\ttotal: 6.53s\tremaining: 49.8s\n",
      "533:\tlearn: 3.3354367\ttotal: 6.54s\tremaining: 49.8s\n",
      "534:\tlearn: 3.3339611\ttotal: 6.55s\tremaining: 49.7s\n",
      "535:\tlearn: 3.3325772\ttotal: 6.56s\tremaining: 49.7s\n",
      "536:\tlearn: 3.3314426\ttotal: 6.57s\tremaining: 49.7s\n",
      "537:\tlearn: 3.3306956\ttotal: 6.58s\tremaining: 49.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538:\tlearn: 3.3294646\ttotal: 6.6s\tremaining: 49.7s\n",
      "539:\tlearn: 3.3286807\ttotal: 6.61s\tremaining: 49.7s\n",
      "540:\tlearn: 3.3272273\ttotal: 6.62s\tremaining: 49.7s\n",
      "541:\tlearn: 3.3258762\ttotal: 6.64s\tremaining: 49.7s\n",
      "542:\tlearn: 3.3244052\ttotal: 6.65s\tremaining: 49.7s\n",
      "543:\tlearn: 3.3233363\ttotal: 6.66s\tremaining: 49.6s\n",
      "544:\tlearn: 3.3218488\ttotal: 6.67s\tremaining: 49.6s\n",
      "545:\tlearn: 3.3210712\ttotal: 6.68s\tremaining: 49.6s\n",
      "546:\tlearn: 3.3204757\ttotal: 6.7s\tremaining: 49.6s\n",
      "547:\tlearn: 3.3192964\ttotal: 6.71s\tremaining: 49.6s\n",
      "548:\tlearn: 3.3184594\ttotal: 6.72s\tremaining: 49.6s\n",
      "549:\tlearn: 3.3169511\ttotal: 6.73s\tremaining: 49.6s\n",
      "550:\tlearn: 3.3157297\ttotal: 6.75s\tremaining: 49.6s\n",
      "551:\tlearn: 3.3144817\ttotal: 6.76s\tremaining: 49.5s\n",
      "552:\tlearn: 3.3142449\ttotal: 6.77s\tremaining: 49.5s\n",
      "553:\tlearn: 3.3124851\ttotal: 6.78s\tremaining: 49.5s\n",
      "554:\tlearn: 3.3111024\ttotal: 6.79s\tremaining: 49.5s\n",
      "555:\tlearn: 3.3096943\ttotal: 6.81s\tremaining: 49.5s\n",
      "556:\tlearn: 3.3082725\ttotal: 6.82s\tremaining: 49.5s\n",
      "557:\tlearn: 3.3082078\ttotal: 6.83s\tremaining: 49.5s\n",
      "558:\tlearn: 3.3075955\ttotal: 6.84s\tremaining: 49.5s\n",
      "559:\tlearn: 3.3060643\ttotal: 6.86s\tremaining: 49.4s\n",
      "560:\tlearn: 3.3043950\ttotal: 6.87s\tremaining: 49.4s\n",
      "561:\tlearn: 3.3028210\ttotal: 6.88s\tremaining: 49.4s\n",
      "562:\tlearn: 3.3015299\ttotal: 6.89s\tremaining: 49.4s\n",
      "563:\tlearn: 3.3003241\ttotal: 6.9s\tremaining: 49.4s\n",
      "564:\tlearn: 3.2993856\ttotal: 6.92s\tremaining: 49.4s\n",
      "565:\tlearn: 3.2979554\ttotal: 6.93s\tremaining: 49.4s\n",
      "566:\tlearn: 3.2959101\ttotal: 6.94s\tremaining: 49.3s\n",
      "567:\tlearn: 3.2946976\ttotal: 6.95s\tremaining: 49.3s\n",
      "568:\tlearn: 3.2938867\ttotal: 6.96s\tremaining: 49.3s\n",
      "569:\tlearn: 3.2925255\ttotal: 6.98s\tremaining: 49.3s\n",
      "570:\tlearn: 3.2918136\ttotal: 6.99s\tremaining: 49.3s\n",
      "571:\tlearn: 3.2906448\ttotal: 7s\tremaining: 49.3s\n",
      "572:\tlearn: 3.2896331\ttotal: 7.01s\tremaining: 49.3s\n",
      "573:\tlearn: 3.2886172\ttotal: 7.03s\tremaining: 49.3s\n",
      "574:\tlearn: 3.2866031\ttotal: 7.04s\tremaining: 49.3s\n",
      "575:\tlearn: 3.2852773\ttotal: 7.05s\tremaining: 49.3s\n",
      "576:\tlearn: 3.2842592\ttotal: 7.07s\tremaining: 49.3s\n",
      "577:\tlearn: 3.2828906\ttotal: 7.08s\tremaining: 49.2s\n",
      "578:\tlearn: 3.2819505\ttotal: 7.09s\tremaining: 49.2s\n",
      "579:\tlearn: 3.2803524\ttotal: 7.11s\tremaining: 49.3s\n",
      "580:\tlearn: 3.2795467\ttotal: 7.13s\tremaining: 49.3s\n",
      "581:\tlearn: 3.2791333\ttotal: 7.14s\tremaining: 49.3s\n",
      "582:\tlearn: 3.2777800\ttotal: 7.15s\tremaining: 49.3s\n",
      "583:\tlearn: 3.2762537\ttotal: 7.17s\tremaining: 49.3s\n",
      "584:\tlearn: 3.2752369\ttotal: 7.18s\tremaining: 49.2s\n",
      "585:\tlearn: 3.2741618\ttotal: 7.19s\tremaining: 49.2s\n",
      "586:\tlearn: 3.2734237\ttotal: 7.2s\tremaining: 49.2s\n",
      "587:\tlearn: 3.2725330\ttotal: 7.21s\tremaining: 49.2s\n",
      "588:\tlearn: 3.2713720\ttotal: 7.23s\tremaining: 49.2s\n",
      "589:\tlearn: 3.2709219\ttotal: 7.24s\tremaining: 49.2s\n",
      "590:\tlearn: 3.2700656\ttotal: 7.25s\tremaining: 49.2s\n",
      "591:\tlearn: 3.2690584\ttotal: 7.26s\tremaining: 49.2s\n",
      "592:\tlearn: 3.2681507\ttotal: 7.28s\tremaining: 49.1s\n",
      "593:\tlearn: 3.2670839\ttotal: 7.29s\tremaining: 49.1s\n",
      "594:\tlearn: 3.2658172\ttotal: 7.3s\tremaining: 49.1s\n",
      "595:\tlearn: 3.2646667\ttotal: 7.31s\tremaining: 49.1s\n",
      "596:\tlearn: 3.2639545\ttotal: 7.33s\tremaining: 49.1s\n",
      "597:\tlearn: 3.2630507\ttotal: 7.34s\tremaining: 49.1s\n",
      "598:\tlearn: 3.2615168\ttotal: 7.35s\tremaining: 49.1s\n",
      "599:\tlearn: 3.2603245\ttotal: 7.36s\tremaining: 49.1s\n",
      "600:\tlearn: 3.2601477\ttotal: 7.37s\tremaining: 49s\n",
      "601:\tlearn: 3.2587392\ttotal: 7.39s\tremaining: 49s\n",
      "602:\tlearn: 3.2577837\ttotal: 7.4s\tremaining: 49s\n",
      "603:\tlearn: 3.2568513\ttotal: 7.41s\tremaining: 49s\n",
      "604:\tlearn: 3.2554615\ttotal: 7.42s\tremaining: 49s\n",
      "605:\tlearn: 3.2546878\ttotal: 7.43s\tremaining: 49s\n",
      "606:\tlearn: 3.2535622\ttotal: 7.45s\tremaining: 49s\n",
      "607:\tlearn: 3.2524558\ttotal: 7.46s\tremaining: 49s\n",
      "608:\tlearn: 3.2514477\ttotal: 7.47s\tremaining: 49s\n",
      "609:\tlearn: 3.2505803\ttotal: 7.49s\tremaining: 48.9s\n",
      "610:\tlearn: 3.2485482\ttotal: 7.5s\tremaining: 48.9s\n",
      "611:\tlearn: 3.2472806\ttotal: 7.51s\tremaining: 48.9s\n",
      "612:\tlearn: 3.2459708\ttotal: 7.52s\tremaining: 48.9s\n",
      "613:\tlearn: 3.2459631\ttotal: 7.53s\tremaining: 48.9s\n",
      "614:\tlearn: 3.2440332\ttotal: 7.54s\tremaining: 48.9s\n",
      "615:\tlearn: 3.2435165\ttotal: 7.56s\tremaining: 48.8s\n",
      "616:\tlearn: 3.2423181\ttotal: 7.57s\tremaining: 48.8s\n",
      "617:\tlearn: 3.2413020\ttotal: 7.58s\tremaining: 48.8s\n",
      "618:\tlearn: 3.2404065\ttotal: 7.59s\tremaining: 48.8s\n",
      "619:\tlearn: 3.2387642\ttotal: 7.6s\tremaining: 48.8s\n",
      "620:\tlearn: 3.2375564\ttotal: 7.62s\tremaining: 48.8s\n",
      "621:\tlearn: 3.2362938\ttotal: 7.63s\tremaining: 48.8s\n",
      "622:\tlearn: 3.2352514\ttotal: 7.64s\tremaining: 48.7s\n",
      "623:\tlearn: 3.2347441\ttotal: 7.65s\tremaining: 48.7s\n",
      "624:\tlearn: 3.2339233\ttotal: 7.66s\tremaining: 48.7s\n",
      "625:\tlearn: 3.2327565\ttotal: 7.68s\tremaining: 48.7s\n",
      "626:\tlearn: 3.2323076\ttotal: 7.71s\tremaining: 48.8s\n",
      "627:\tlearn: 3.2314457\ttotal: 7.72s\tremaining: 48.8s\n",
      "628:\tlearn: 3.2312648\ttotal: 7.73s\tremaining: 48.8s\n",
      "629:\tlearn: 3.2300785\ttotal: 7.74s\tremaining: 48.8s\n",
      "630:\tlearn: 3.2283122\ttotal: 7.76s\tremaining: 48.8s\n",
      "631:\tlearn: 3.2282428\ttotal: 7.77s\tremaining: 48.7s\n",
      "632:\tlearn: 3.2272776\ttotal: 7.78s\tremaining: 48.7s\n",
      "633:\tlearn: 3.2262666\ttotal: 7.79s\tremaining: 48.7s\n",
      "634:\tlearn: 3.2255899\ttotal: 7.8s\tremaining: 48.7s\n",
      "635:\tlearn: 3.2244062\ttotal: 7.82s\tremaining: 48.7s\n",
      "636:\tlearn: 3.2236746\ttotal: 7.83s\tremaining: 48.7s\n",
      "637:\tlearn: 3.2220733\ttotal: 7.84s\tremaining: 48.7s\n",
      "638:\tlearn: 3.2209342\ttotal: 7.85s\tremaining: 48.6s\n",
      "639:\tlearn: 3.2197345\ttotal: 7.87s\tremaining: 48.6s\n",
      "640:\tlearn: 3.2183382\ttotal: 7.88s\tremaining: 48.7s\n",
      "641:\tlearn: 3.2170401\ttotal: 7.9s\tremaining: 48.7s\n",
      "642:\tlearn: 3.2159306\ttotal: 7.91s\tremaining: 48.7s\n",
      "643:\tlearn: 3.2153238\ttotal: 7.92s\tremaining: 48.7s\n",
      "644:\tlearn: 3.2141419\ttotal: 7.94s\tremaining: 48.7s\n",
      "645:\tlearn: 3.2129801\ttotal: 7.95s\tremaining: 48.7s\n",
      "646:\tlearn: 3.2122092\ttotal: 7.97s\tremaining: 48.7s\n",
      "647:\tlearn: 3.2111904\ttotal: 7.98s\tremaining: 48.6s\n",
      "648:\tlearn: 3.2101582\ttotal: 7.99s\tremaining: 48.6s\n",
      "649:\tlearn: 3.2089348\ttotal: 8.01s\tremaining: 48.6s\n",
      "650:\tlearn: 3.2078793\ttotal: 8.02s\tremaining: 48.6s\n",
      "651:\tlearn: 3.2068942\ttotal: 8.03s\tremaining: 48.6s\n",
      "652:\tlearn: 3.2060246\ttotal: 8.05s\tremaining: 48.6s\n",
      "653:\tlearn: 3.2048939\ttotal: 8.06s\tremaining: 48.6s\n",
      "654:\tlearn: 3.2035182\ttotal: 8.07s\tremaining: 48.6s\n",
      "655:\tlearn: 3.2022794\ttotal: 8.09s\tremaining: 48.6s\n",
      "656:\tlearn: 3.2015731\ttotal: 8.1s\tremaining: 48.6s\n",
      "657:\tlearn: 3.2006872\ttotal: 8.11s\tremaining: 48.6s\n",
      "658:\tlearn: 3.1995764\ttotal: 8.12s\tremaining: 48.6s\n",
      "659:\tlearn: 3.1985155\ttotal: 8.14s\tremaining: 48.6s\n",
      "660:\tlearn: 3.1975701\ttotal: 8.15s\tremaining: 48.5s\n",
      "661:\tlearn: 3.1966307\ttotal: 8.16s\tremaining: 48.5s\n",
      "662:\tlearn: 3.1959530\ttotal: 8.17s\tremaining: 48.5s\n",
      "663:\tlearn: 3.1939496\ttotal: 8.19s\tremaining: 48.5s\n",
      "664:\tlearn: 3.1929598\ttotal: 8.2s\tremaining: 48.5s\n",
      "665:\tlearn: 3.1909838\ttotal: 8.21s\tremaining: 48.5s\n",
      "666:\tlearn: 3.1899187\ttotal: 8.22s\tremaining: 48.5s\n",
      "667:\tlearn: 3.1893934\ttotal: 8.23s\tremaining: 48.4s\n",
      "668:\tlearn: 3.1887250\ttotal: 8.25s\tremaining: 48.4s\n",
      "669:\tlearn: 3.1878577\ttotal: 8.26s\tremaining: 48.4s\n",
      "670:\tlearn: 3.1868993\ttotal: 8.27s\tremaining: 48.4s\n",
      "671:\tlearn: 3.1855957\ttotal: 8.29s\tremaining: 48.4s\n",
      "672:\tlearn: 3.1843168\ttotal: 8.3s\tremaining: 48.4s\n",
      "673:\tlearn: 3.1834073\ttotal: 8.31s\tremaining: 48.4s\n",
      "674:\tlearn: 3.1822893\ttotal: 8.32s\tremaining: 48.4s\n",
      "675:\tlearn: 3.1815297\ttotal: 8.33s\tremaining: 48.4s\n",
      "676:\tlearn: 3.1807603\ttotal: 8.35s\tremaining: 48.3s\n",
      "677:\tlearn: 3.1801818\ttotal: 8.36s\tremaining: 48.3s\n",
      "678:\tlearn: 3.1794700\ttotal: 8.37s\tremaining: 48.3s\n",
      "679:\tlearn: 3.1787257\ttotal: 8.38s\tremaining: 48.3s\n",
      "680:\tlearn: 3.1778670\ttotal: 8.39s\tremaining: 48.3s\n",
      "681:\tlearn: 3.1772452\ttotal: 8.4s\tremaining: 48.3s\n",
      "682:\tlearn: 3.1764538\ttotal: 8.41s\tremaining: 48.2s\n",
      "683:\tlearn: 3.1755786\ttotal: 8.43s\tremaining: 48.2s\n",
      "684:\tlearn: 3.1747988\ttotal: 8.44s\tremaining: 48.2s\n",
      "685:\tlearn: 3.1738882\ttotal: 8.45s\tremaining: 48.2s\n",
      "686:\tlearn: 3.1726816\ttotal: 8.46s\tremaining: 48.2s\n",
      "687:\tlearn: 3.1713941\ttotal: 8.47s\tremaining: 48.1s\n",
      "688:\tlearn: 3.1706510\ttotal: 8.48s\tremaining: 48.1s\n",
      "689:\tlearn: 3.1704503\ttotal: 8.49s\tremaining: 48.1s\n",
      "690:\tlearn: 3.1697092\ttotal: 8.51s\tremaining: 48.1s\n",
      "691:\tlearn: 3.1685434\ttotal: 8.52s\tremaining: 48.1s\n",
      "692:\tlearn: 3.1679407\ttotal: 8.53s\tremaining: 48.1s\n",
      "693:\tlearn: 3.1673704\ttotal: 8.54s\tremaining: 48.1s\n",
      "694:\tlearn: 3.1664072\ttotal: 8.55s\tremaining: 48s\n",
      "695:\tlearn: 3.1654452\ttotal: 8.56s\tremaining: 48s\n",
      "696:\tlearn: 3.1641860\ttotal: 8.58s\tremaining: 48s\n",
      "697:\tlearn: 3.1635138\ttotal: 8.59s\tremaining: 48s\n",
      "698:\tlearn: 3.1627058\ttotal: 8.6s\tremaining: 48s\n",
      "699:\tlearn: 3.1617545\ttotal: 8.61s\tremaining: 48s\n",
      "700:\tlearn: 3.1611458\ttotal: 8.62s\tremaining: 47.9s\n",
      "701:\tlearn: 3.1606998\ttotal: 8.63s\tremaining: 47.9s\n",
      "702:\tlearn: 3.1595253\ttotal: 8.64s\tremaining: 47.9s\n",
      "703:\tlearn: 3.1581433\ttotal: 8.66s\tremaining: 47.9s\n",
      "704:\tlearn: 3.1568963\ttotal: 8.67s\tremaining: 47.9s\n",
      "705:\tlearn: 3.1556266\ttotal: 8.68s\tremaining: 47.9s\n",
      "706:\tlearn: 3.1551599\ttotal: 8.69s\tremaining: 47.8s\n",
      "707:\tlearn: 3.1542706\ttotal: 8.7s\tremaining: 47.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "708:\tlearn: 3.1527305\ttotal: 8.72s\tremaining: 47.8s\n",
      "709:\tlearn: 3.1513943\ttotal: 8.73s\tremaining: 47.8s\n",
      "710:\tlearn: 3.1507548\ttotal: 8.74s\tremaining: 47.8s\n",
      "711:\tlearn: 3.1490973\ttotal: 8.76s\tremaining: 47.8s\n",
      "712:\tlearn: 3.1477444\ttotal: 8.77s\tremaining: 47.8s\n",
      "713:\tlearn: 3.1460085\ttotal: 8.78s\tremaining: 47.8s\n",
      "714:\tlearn: 3.1453365\ttotal: 8.79s\tremaining: 47.7s\n",
      "715:\tlearn: 3.1443644\ttotal: 8.8s\tremaining: 47.7s\n",
      "716:\tlearn: 3.1432680\ttotal: 8.81s\tremaining: 47.7s\n",
      "717:\tlearn: 3.1419308\ttotal: 8.83s\tremaining: 47.7s\n",
      "718:\tlearn: 3.1403993\ttotal: 8.84s\tremaining: 47.7s\n",
      "719:\tlearn: 3.1389816\ttotal: 8.85s\tremaining: 47.7s\n",
      "720:\tlearn: 3.1381488\ttotal: 8.86s\tremaining: 47.7s\n",
      "721:\tlearn: 3.1372348\ttotal: 8.88s\tremaining: 47.6s\n",
      "722:\tlearn: 3.1364860\ttotal: 8.89s\tremaining: 47.6s\n",
      "723:\tlearn: 3.1356327\ttotal: 8.9s\tremaining: 47.6s\n",
      "724:\tlearn: 3.1345281\ttotal: 8.91s\tremaining: 47.6s\n",
      "725:\tlearn: 3.1336668\ttotal: 8.92s\tremaining: 47.6s\n",
      "726:\tlearn: 3.1329340\ttotal: 8.94s\tremaining: 47.6s\n",
      "727:\tlearn: 3.1319242\ttotal: 8.95s\tremaining: 47.6s\n",
      "728:\tlearn: 3.1303370\ttotal: 8.97s\tremaining: 47.6s\n",
      "729:\tlearn: 3.1293255\ttotal: 8.98s\tremaining: 47.6s\n",
      "730:\tlearn: 3.1287598\ttotal: 8.99s\tremaining: 47.6s\n",
      "731:\tlearn: 3.1276056\ttotal: 9.01s\tremaining: 47.6s\n",
      "732:\tlearn: 3.1261398\ttotal: 9.02s\tremaining: 47.6s\n",
      "733:\tlearn: 3.1249959\ttotal: 9.04s\tremaining: 47.6s\n",
      "734:\tlearn: 3.1244003\ttotal: 9.05s\tremaining: 47.6s\n",
      "735:\tlearn: 3.1231298\ttotal: 9.06s\tremaining: 47.5s\n",
      "736:\tlearn: 3.1223158\ttotal: 9.07s\tremaining: 47.5s\n",
      "737:\tlearn: 3.1207377\ttotal: 9.09s\tremaining: 47.5s\n",
      "738:\tlearn: 3.1203227\ttotal: 9.1s\tremaining: 47.5s\n",
      "739:\tlearn: 3.1187330\ttotal: 9.11s\tremaining: 47.5s\n",
      "740:\tlearn: 3.1179493\ttotal: 9.13s\tremaining: 47.5s\n",
      "741:\tlearn: 3.1166117\ttotal: 9.14s\tremaining: 47.5s\n",
      "742:\tlearn: 3.1152446\ttotal: 9.15s\tremaining: 47.5s\n",
      "743:\tlearn: 3.1143622\ttotal: 9.17s\tremaining: 47.5s\n",
      "744:\tlearn: 3.1130243\ttotal: 9.18s\tremaining: 47.5s\n",
      "745:\tlearn: 3.1124004\ttotal: 9.19s\tremaining: 47.5s\n",
      "746:\tlearn: 3.1114953\ttotal: 9.2s\tremaining: 47.4s\n",
      "747:\tlearn: 3.1100675\ttotal: 9.21s\tremaining: 47.4s\n",
      "748:\tlearn: 3.1092147\ttotal: 9.23s\tremaining: 47.4s\n",
      "749:\tlearn: 3.1084805\ttotal: 9.24s\tremaining: 47.4s\n",
      "750:\tlearn: 3.1077626\ttotal: 9.25s\tremaining: 47.4s\n",
      "751:\tlearn: 3.1065805\ttotal: 9.26s\tremaining: 47.4s\n",
      "752:\tlearn: 3.1060044\ttotal: 9.28s\tremaining: 47.4s\n",
      "753:\tlearn: 3.1050364\ttotal: 9.29s\tremaining: 47.3s\n",
      "754:\tlearn: 3.1042456\ttotal: 9.3s\tremaining: 47.3s\n",
      "755:\tlearn: 3.1029583\ttotal: 9.31s\tremaining: 47.3s\n",
      "756:\tlearn: 3.1023545\ttotal: 9.32s\tremaining: 47.3s\n",
      "757:\tlearn: 3.1015565\ttotal: 9.33s\tremaining: 47.3s\n",
      "758:\tlearn: 3.1010392\ttotal: 9.35s\tremaining: 47.3s\n",
      "759:\tlearn: 3.1000316\ttotal: 9.36s\tremaining: 47.3s\n",
      "760:\tlearn: 3.0986179\ttotal: 9.37s\tremaining: 47.3s\n",
      "761:\tlearn: 3.0972781\ttotal: 9.38s\tremaining: 47.2s\n",
      "762:\tlearn: 3.0965344\ttotal: 9.39s\tremaining: 47.2s\n",
      "763:\tlearn: 3.0955333\ttotal: 9.41s\tremaining: 47.2s\n",
      "764:\tlearn: 3.0944381\ttotal: 9.42s\tremaining: 47.2s\n",
      "765:\tlearn: 3.0935304\ttotal: 9.43s\tremaining: 47.2s\n",
      "766:\tlearn: 3.0920890\ttotal: 9.44s\tremaining: 47.2s\n",
      "767:\tlearn: 3.0912654\ttotal: 9.46s\tremaining: 47.2s\n",
      "768:\tlearn: 3.0904608\ttotal: 9.47s\tremaining: 47.1s\n",
      "769:\tlearn: 3.0895574\ttotal: 9.48s\tremaining: 47.1s\n",
      "770:\tlearn: 3.0888112\ttotal: 9.49s\tremaining: 47.1s\n",
      "771:\tlearn: 3.0878061\ttotal: 9.51s\tremaining: 47.1s\n",
      "772:\tlearn: 3.0872451\ttotal: 9.52s\tremaining: 47.1s\n",
      "773:\tlearn: 3.0854993\ttotal: 9.53s\tremaining: 47.1s\n",
      "774:\tlearn: 3.0840693\ttotal: 9.54s\tremaining: 47.1s\n",
      "775:\tlearn: 3.0825247\ttotal: 9.55s\tremaining: 47.1s\n",
      "776:\tlearn: 3.0813496\ttotal: 9.57s\tremaining: 47s\n",
      "777:\tlearn: 3.0806477\ttotal: 9.58s\tremaining: 47s\n",
      "778:\tlearn: 3.0794882\ttotal: 9.59s\tremaining: 47s\n",
      "779:\tlearn: 3.0784026\ttotal: 9.61s\tremaining: 47s\n",
      "780:\tlearn: 3.0776853\ttotal: 9.62s\tremaining: 47s\n",
      "781:\tlearn: 3.0766650\ttotal: 9.63s\tremaining: 47s\n",
      "782:\tlearn: 3.0757832\ttotal: 9.64s\tremaining: 47s\n",
      "783:\tlearn: 3.0748207\ttotal: 9.65s\tremaining: 47s\n",
      "784:\tlearn: 3.0738667\ttotal: 9.66s\tremaining: 46.9s\n",
      "785:\tlearn: 3.0726064\ttotal: 9.67s\tremaining: 46.9s\n",
      "786:\tlearn: 3.0711941\ttotal: 9.69s\tremaining: 46.9s\n",
      "787:\tlearn: 3.0705763\ttotal: 9.7s\tremaining: 46.9s\n",
      "788:\tlearn: 3.0698283\ttotal: 9.71s\tremaining: 46.9s\n",
      "789:\tlearn: 3.0685239\ttotal: 9.72s\tremaining: 46.9s\n",
      "790:\tlearn: 3.0676921\ttotal: 9.73s\tremaining: 46.8s\n",
      "791:\tlearn: 3.0668895\ttotal: 9.74s\tremaining: 46.8s\n",
      "792:\tlearn: 3.0666911\ttotal: 9.76s\tremaining: 46.8s\n",
      "793:\tlearn: 3.0659265\ttotal: 9.77s\tremaining: 46.8s\n",
      "794:\tlearn: 3.0647086\ttotal: 9.78s\tremaining: 46.8s\n",
      "795:\tlearn: 3.0637230\ttotal: 9.79s\tremaining: 46.8s\n",
      "796:\tlearn: 3.0633900\ttotal: 9.81s\tremaining: 46.8s\n",
      "797:\tlearn: 3.0626427\ttotal: 9.82s\tremaining: 46.8s\n",
      "798:\tlearn: 3.0613033\ttotal: 9.83s\tremaining: 46.7s\n",
      "799:\tlearn: 3.0606356\ttotal: 9.84s\tremaining: 46.7s\n",
      "800:\tlearn: 3.0595850\ttotal: 9.85s\tremaining: 46.7s\n",
      "801:\tlearn: 3.0583405\ttotal: 9.87s\tremaining: 46.7s\n",
      "802:\tlearn: 3.0579421\ttotal: 9.88s\tremaining: 46.7s\n",
      "803:\tlearn: 3.0572437\ttotal: 9.89s\tremaining: 46.7s\n",
      "804:\tlearn: 3.0559293\ttotal: 9.9s\tremaining: 46.7s\n",
      "805:\tlearn: 3.0551888\ttotal: 9.91s\tremaining: 46.6s\n",
      "806:\tlearn: 3.0543632\ttotal: 9.93s\tremaining: 46.6s\n",
      "807:\tlearn: 3.0536561\ttotal: 9.94s\tremaining: 46.6s\n",
      "808:\tlearn: 3.0527858\ttotal: 9.95s\tremaining: 46.6s\n",
      "809:\tlearn: 3.0513627\ttotal: 9.96s\tremaining: 46.6s\n",
      "810:\tlearn: 3.0501548\ttotal: 9.97s\tremaining: 46.6s\n",
      "811:\tlearn: 3.0496623\ttotal: 9.99s\tremaining: 46.6s\n",
      "812:\tlearn: 3.0487596\ttotal: 10s\tremaining: 46.6s\n",
      "813:\tlearn: 3.0474281\ttotal: 10s\tremaining: 46.5s\n",
      "814:\tlearn: 3.0467229\ttotal: 10s\tremaining: 46.5s\n",
      "815:\tlearn: 3.0460564\ttotal: 10s\tremaining: 46.5s\n",
      "816:\tlearn: 3.0456877\ttotal: 10s\tremaining: 46.5s\n",
      "817:\tlearn: 3.0452590\ttotal: 10.1s\tremaining: 46.5s\n",
      "818:\tlearn: 3.0448903\ttotal: 10.1s\tremaining: 46.5s\n",
      "819:\tlearn: 3.0440196\ttotal: 10.1s\tremaining: 46.5s\n",
      "820:\tlearn: 3.0432601\ttotal: 10.1s\tremaining: 46.4s\n",
      "821:\tlearn: 3.0426304\ttotal: 10.1s\tremaining: 46.4s\n",
      "822:\tlearn: 3.0418280\ttotal: 10.1s\tremaining: 46.4s\n",
      "823:\tlearn: 3.0411891\ttotal: 10.1s\tremaining: 46.4s\n",
      "824:\tlearn: 3.0403460\ttotal: 10.1s\tremaining: 46.4s\n",
      "825:\tlearn: 3.0400340\ttotal: 10.2s\tremaining: 46.4s\n",
      "826:\tlearn: 3.0399290\ttotal: 10.2s\tremaining: 46.3s\n",
      "827:\tlearn: 3.0390831\ttotal: 10.2s\tremaining: 46.3s\n",
      "828:\tlearn: 3.0384190\ttotal: 10.2s\tremaining: 46.3s\n",
      "829:\tlearn: 3.0373667\ttotal: 10.2s\tremaining: 46.3s\n",
      "830:\tlearn: 3.0363094\ttotal: 10.2s\tremaining: 46.3s\n",
      "831:\tlearn: 3.0354329\ttotal: 10.2s\tremaining: 46.3s\n",
      "832:\tlearn: 3.0345674\ttotal: 10.2s\tremaining: 46.3s\n",
      "833:\tlearn: 3.0342829\ttotal: 10.2s\tremaining: 46.3s\n",
      "834:\tlearn: 3.0334312\ttotal: 10.3s\tremaining: 46.2s\n",
      "835:\tlearn: 3.0324426\ttotal: 10.3s\tremaining: 46.2s\n",
      "836:\tlearn: 3.0314385\ttotal: 10.3s\tremaining: 46.2s\n",
      "837:\tlearn: 3.0305285\ttotal: 10.3s\tremaining: 46.2s\n",
      "838:\tlearn: 3.0295586\ttotal: 10.3s\tremaining: 46.2s\n",
      "839:\tlearn: 3.0288819\ttotal: 10.3s\tremaining: 46.2s\n",
      "840:\tlearn: 3.0282200\ttotal: 10.3s\tremaining: 46.1s\n",
      "841:\tlearn: 3.0281069\ttotal: 10.3s\tremaining: 46.1s\n",
      "842:\tlearn: 3.0274698\ttotal: 10.4s\tremaining: 46.1s\n",
      "843:\tlearn: 3.0262836\ttotal: 10.4s\tremaining: 46.1s\n",
      "844:\tlearn: 3.0247885\ttotal: 10.4s\tremaining: 46.1s\n",
      "845:\tlearn: 3.0243020\ttotal: 10.4s\tremaining: 46.1s\n",
      "846:\tlearn: 3.0234524\ttotal: 10.4s\tremaining: 46.1s\n",
      "847:\tlearn: 3.0228326\ttotal: 10.4s\tremaining: 46.1s\n",
      "848:\tlearn: 3.0218496\ttotal: 10.4s\tremaining: 46.1s\n",
      "849:\tlearn: 3.0212683\ttotal: 10.4s\tremaining: 46s\n",
      "850:\tlearn: 3.0202056\ttotal: 10.5s\tremaining: 46s\n",
      "851:\tlearn: 3.0199365\ttotal: 10.5s\tremaining: 46s\n",
      "852:\tlearn: 3.0199126\ttotal: 10.5s\tremaining: 46s\n",
      "853:\tlearn: 3.0192786\ttotal: 10.5s\tremaining: 46s\n",
      "854:\tlearn: 3.0179840\ttotal: 10.5s\tremaining: 46s\n",
      "855:\tlearn: 3.0171577\ttotal: 10.5s\tremaining: 46s\n",
      "856:\tlearn: 3.0164793\ttotal: 10.5s\tremaining: 45.9s\n",
      "857:\tlearn: 3.0155881\ttotal: 10.5s\tremaining: 45.9s\n",
      "858:\tlearn: 3.0150564\ttotal: 10.5s\tremaining: 45.9s\n",
      "859:\tlearn: 3.0137391\ttotal: 10.6s\tremaining: 45.9s\n",
      "860:\tlearn: 3.0132425\ttotal: 10.6s\tremaining: 45.9s\n",
      "861:\tlearn: 3.0121855\ttotal: 10.6s\tremaining: 45.9s\n",
      "862:\tlearn: 3.0108518\ttotal: 10.6s\tremaining: 45.9s\n",
      "863:\tlearn: 3.0104317\ttotal: 10.6s\tremaining: 45.8s\n",
      "864:\tlearn: 3.0094365\ttotal: 10.6s\tremaining: 45.8s\n",
      "865:\tlearn: 3.0085575\ttotal: 10.6s\tremaining: 45.8s\n",
      "866:\tlearn: 3.0074579\ttotal: 10.6s\tremaining: 45.8s\n",
      "867:\tlearn: 3.0072317\ttotal: 10.7s\tremaining: 45.8s\n",
      "868:\tlearn: 3.0064429\ttotal: 10.7s\tremaining: 45.8s\n",
      "869:\tlearn: 3.0053441\ttotal: 10.7s\tremaining: 45.8s\n",
      "870:\tlearn: 3.0039481\ttotal: 10.7s\tremaining: 45.8s\n",
      "871:\tlearn: 3.0022796\ttotal: 10.7s\tremaining: 45.8s\n",
      "872:\tlearn: 3.0014291\ttotal: 10.7s\tremaining: 45.7s\n",
      "873:\tlearn: 3.0005611\ttotal: 10.7s\tremaining: 45.7s\n",
      "874:\tlearn: 3.0002196\ttotal: 10.7s\tremaining: 45.7s\n",
      "875:\tlearn: 2.9988162\ttotal: 10.8s\tremaining: 45.7s\n",
      "876:\tlearn: 2.9980053\ttotal: 10.8s\tremaining: 45.7s\n",
      "877:\tlearn: 2.9972480\ttotal: 10.8s\tremaining: 45.7s\n",
      "878:\tlearn: 2.9965578\ttotal: 10.8s\tremaining: 45.7s\n",
      "879:\tlearn: 2.9959676\ttotal: 10.8s\tremaining: 45.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880:\tlearn: 2.9955165\ttotal: 10.8s\tremaining: 45.6s\n",
      "881:\tlearn: 2.9946841\ttotal: 10.8s\tremaining: 45.6s\n",
      "882:\tlearn: 2.9942086\ttotal: 10.8s\tremaining: 45.6s\n",
      "883:\tlearn: 2.9936288\ttotal: 10.9s\tremaining: 45.6s\n",
      "884:\tlearn: 2.9924157\ttotal: 10.9s\tremaining: 45.6s\n",
      "885:\tlearn: 2.9915521\ttotal: 10.9s\tremaining: 45.6s\n",
      "886:\tlearn: 2.9905776\ttotal: 10.9s\tremaining: 45.6s\n",
      "887:\tlearn: 2.9890296\ttotal: 10.9s\tremaining: 45.6s\n",
      "888:\tlearn: 2.9879289\ttotal: 10.9s\tremaining: 45.6s\n",
      "889:\tlearn: 2.9866979\ttotal: 10.9s\tremaining: 45.6s\n",
      "890:\tlearn: 2.9854457\ttotal: 10.9s\tremaining: 45.5s\n",
      "891:\tlearn: 2.9850263\ttotal: 11s\tremaining: 45.5s\n",
      "892:\tlearn: 2.9847794\ttotal: 11s\tremaining: 45.5s\n",
      "893:\tlearn: 2.9842848\ttotal: 11s\tremaining: 45.5s\n",
      "894:\tlearn: 2.9836279\ttotal: 11s\tremaining: 45.5s\n",
      "895:\tlearn: 2.9829276\ttotal: 11s\tremaining: 45.5s\n",
      "896:\tlearn: 2.9820235\ttotal: 11s\tremaining: 45.4s\n",
      "897:\tlearn: 2.9811622\ttotal: 11s\tremaining: 45.4s\n",
      "898:\tlearn: 2.9805679\ttotal: 11s\tremaining: 45.4s\n",
      "899:\tlearn: 2.9801653\ttotal: 11.1s\tremaining: 45.4s\n",
      "900:\tlearn: 2.9801022\ttotal: 11.1s\tremaining: 45.4s\n",
      "901:\tlearn: 2.9797340\ttotal: 11.1s\tremaining: 45.4s\n",
      "902:\tlearn: 2.9783775\ttotal: 11.1s\tremaining: 45.4s\n",
      "903:\tlearn: 2.9775040\ttotal: 11.1s\tremaining: 45.4s\n",
      "904:\tlearn: 2.9769711\ttotal: 11.1s\tremaining: 45.4s\n",
      "905:\tlearn: 2.9761941\ttotal: 11.1s\tremaining: 45.3s\n",
      "906:\tlearn: 2.9755045\ttotal: 11.1s\tremaining: 45.3s\n",
      "907:\tlearn: 2.9746438\ttotal: 11.2s\tremaining: 45.3s\n",
      "908:\tlearn: 2.9730039\ttotal: 11.2s\tremaining: 45.3s\n",
      "909:\tlearn: 2.9728419\ttotal: 11.2s\tremaining: 45.3s\n",
      "910:\tlearn: 2.9717084\ttotal: 11.2s\tremaining: 45.3s\n",
      "911:\tlearn: 2.9707390\ttotal: 11.2s\tremaining: 45.3s\n",
      "912:\tlearn: 2.9699807\ttotal: 11.2s\tremaining: 45.2s\n",
      "913:\tlearn: 2.9688365\ttotal: 11.2s\tremaining: 45.2s\n",
      "914:\tlearn: 2.9681430\ttotal: 11.2s\tremaining: 45.2s\n",
      "915:\tlearn: 2.9676880\ttotal: 11.2s\tremaining: 45.2s\n",
      "916:\tlearn: 2.9670699\ttotal: 11.3s\tremaining: 45.2s\n",
      "917:\tlearn: 2.9655208\ttotal: 11.3s\tremaining: 45.2s\n",
      "918:\tlearn: 2.9648989\ttotal: 11.3s\tremaining: 45.2s\n",
      "919:\tlearn: 2.9638980\ttotal: 11.3s\tremaining: 45.2s\n",
      "920:\tlearn: 2.9626559\ttotal: 11.3s\tremaining: 45.2s\n",
      "921:\tlearn: 2.9615941\ttotal: 11.3s\tremaining: 45.1s\n",
      "922:\tlearn: 2.9606416\ttotal: 11.3s\tremaining: 45.1s\n",
      "923:\tlearn: 2.9598651\ttotal: 11.3s\tremaining: 45.1s\n",
      "924:\tlearn: 2.9591823\ttotal: 11.4s\tremaining: 45.1s\n",
      "925:\tlearn: 2.9587229\ttotal: 11.4s\tremaining: 45.1s\n",
      "926:\tlearn: 2.9578719\ttotal: 11.4s\tremaining: 45.1s\n",
      "927:\tlearn: 2.9565361\ttotal: 11.4s\tremaining: 45.1s\n",
      "928:\tlearn: 2.9563025\ttotal: 11.4s\tremaining: 45s\n",
      "929:\tlearn: 2.9550353\ttotal: 11.4s\tremaining: 45s\n",
      "930:\tlearn: 2.9541865\ttotal: 11.4s\tremaining: 45s\n",
      "931:\tlearn: 2.9534570\ttotal: 11.4s\tremaining: 45s\n",
      "932:\tlearn: 2.9527546\ttotal: 11.5s\tremaining: 45s\n",
      "933:\tlearn: 2.9525255\ttotal: 11.5s\tremaining: 45s\n",
      "934:\tlearn: 2.9520225\ttotal: 11.5s\tremaining: 45s\n",
      "935:\tlearn: 2.9508552\ttotal: 11.5s\tremaining: 45s\n",
      "936:\tlearn: 2.9499219\ttotal: 11.5s\tremaining: 44.9s\n",
      "937:\tlearn: 2.9493078\ttotal: 11.5s\tremaining: 44.9s\n",
      "938:\tlearn: 2.9488187\ttotal: 11.5s\tremaining: 44.9s\n",
      "939:\tlearn: 2.9477510\ttotal: 11.5s\tremaining: 44.9s\n",
      "940:\tlearn: 2.9467665\ttotal: 11.6s\tremaining: 44.9s\n",
      "941:\tlearn: 2.9462309\ttotal: 11.6s\tremaining: 44.9s\n",
      "942:\tlearn: 2.9456415\ttotal: 11.6s\tremaining: 44.9s\n",
      "943:\tlearn: 2.9449962\ttotal: 11.6s\tremaining: 44.9s\n",
      "944:\tlearn: 2.9443785\ttotal: 11.6s\tremaining: 44.9s\n",
      "945:\tlearn: 2.9433896\ttotal: 11.6s\tremaining: 44.8s\n",
      "946:\tlearn: 2.9423545\ttotal: 11.6s\tremaining: 44.8s\n",
      "947:\tlearn: 2.9420237\ttotal: 11.6s\tremaining: 44.8s\n",
      "948:\tlearn: 2.9416043\ttotal: 11.7s\tremaining: 44.8s\n",
      "949:\tlearn: 2.9407473\ttotal: 11.7s\tremaining: 44.8s\n",
      "950:\tlearn: 2.9404302\ttotal: 11.7s\tremaining: 44.8s\n",
      "951:\tlearn: 2.9395736\ttotal: 11.7s\tremaining: 44.8s\n",
      "952:\tlearn: 2.9395214\ttotal: 11.7s\tremaining: 44.8s\n",
      "953:\tlearn: 2.9386804\ttotal: 11.7s\tremaining: 44.7s\n",
      "954:\tlearn: 2.9378820\ttotal: 11.7s\tremaining: 44.7s\n",
      "955:\tlearn: 2.9375233\ttotal: 11.7s\tremaining: 44.7s\n",
      "956:\tlearn: 2.9362102\ttotal: 11.7s\tremaining: 44.7s\n",
      "957:\tlearn: 2.9353428\ttotal: 11.8s\tremaining: 44.7s\n",
      "958:\tlearn: 2.9346283\ttotal: 11.8s\tremaining: 44.7s\n",
      "959:\tlearn: 2.9335394\ttotal: 11.8s\tremaining: 44.7s\n",
      "960:\tlearn: 2.9330021\ttotal: 11.8s\tremaining: 44.6s\n",
      "961:\tlearn: 2.9321540\ttotal: 11.8s\tremaining: 44.6s\n",
      "962:\tlearn: 2.9313068\ttotal: 11.8s\tremaining: 44.6s\n",
      "963:\tlearn: 2.9306058\ttotal: 11.8s\tremaining: 44.6s\n",
      "964:\tlearn: 2.9292959\ttotal: 11.8s\tremaining: 44.6s\n",
      "965:\tlearn: 2.9279025\ttotal: 11.9s\tremaining: 44.6s\n",
      "966:\tlearn: 2.9272570\ttotal: 11.9s\tremaining: 44.6s\n",
      "967:\tlearn: 2.9264696\ttotal: 11.9s\tremaining: 44.6s\n",
      "968:\tlearn: 2.9262074\ttotal: 11.9s\tremaining: 44.5s\n",
      "969:\tlearn: 2.9255309\ttotal: 11.9s\tremaining: 44.5s\n",
      "970:\tlearn: 2.9250924\ttotal: 11.9s\tremaining: 44.5s\n",
      "971:\tlearn: 2.9241737\ttotal: 11.9s\tremaining: 44.5s\n",
      "972:\tlearn: 2.9237195\ttotal: 11.9s\tremaining: 44.5s\n",
      "973:\tlearn: 2.9237161\ttotal: 11.9s\tremaining: 44.5s\n",
      "974:\tlearn: 2.9229209\ttotal: 12s\tremaining: 44.4s\n",
      "975:\tlearn: 2.9226708\ttotal: 12s\tremaining: 44.4s\n",
      "976:\tlearn: 2.9222426\ttotal: 12s\tremaining: 44.4s\n",
      "977:\tlearn: 2.9212931\ttotal: 12s\tremaining: 44.4s\n",
      "978:\tlearn: 2.9203328\ttotal: 12s\tremaining: 44.4s\n",
      "979:\tlearn: 2.9200063\ttotal: 12s\tremaining: 44.4s\n",
      "980:\tlearn: 2.9193967\ttotal: 12s\tremaining: 44.4s\n",
      "981:\tlearn: 2.9189772\ttotal: 12s\tremaining: 44.3s\n",
      "982:\tlearn: 2.9182783\ttotal: 12.1s\tremaining: 44.3s\n",
      "983:\tlearn: 2.9178536\ttotal: 12.1s\tremaining: 44.3s\n",
      "984:\tlearn: 2.9169640\ttotal: 12.1s\tremaining: 44.3s\n",
      "985:\tlearn: 2.9160887\ttotal: 12.1s\tremaining: 44.3s\n",
      "986:\tlearn: 2.9154478\ttotal: 12.1s\tremaining: 44.3s\n",
      "987:\tlearn: 2.9150362\ttotal: 12.1s\tremaining: 44.3s\n",
      "988:\tlearn: 2.9150331\ttotal: 12.1s\tremaining: 44.2s\n",
      "989:\tlearn: 2.9145433\ttotal: 12.1s\tremaining: 44.2s\n",
      "990:\tlearn: 2.9139445\ttotal: 12.1s\tremaining: 44.2s\n",
      "991:\tlearn: 2.9131025\ttotal: 12.2s\tremaining: 44.2s\n",
      "992:\tlearn: 2.9121818\ttotal: 12.2s\tremaining: 44.2s\n",
      "993:\tlearn: 2.9118409\ttotal: 12.2s\tremaining: 44.2s\n",
      "994:\tlearn: 2.9110542\ttotal: 12.2s\tremaining: 44.2s\n",
      "995:\tlearn: 2.9109670\ttotal: 12.2s\tremaining: 44.1s\n",
      "996:\tlearn: 2.9103694\ttotal: 12.2s\tremaining: 44.1s\n",
      "997:\tlearn: 2.9098835\ttotal: 12.2s\tremaining: 44.1s\n",
      "998:\tlearn: 2.9097326\ttotal: 12.2s\tremaining: 44.1s\n",
      "999:\tlearn: 2.9092936\ttotal: 12.3s\tremaining: 44.1s\n",
      "1000:\tlearn: 2.9087017\ttotal: 12.3s\tremaining: 44.1s\n",
      "1001:\tlearn: 2.9080039\ttotal: 12.3s\tremaining: 44.1s\n",
      "1002:\tlearn: 2.9066157\ttotal: 12.3s\tremaining: 44s\n",
      "1003:\tlearn: 2.9056468\ttotal: 12.3s\tremaining: 44s\n",
      "1004:\tlearn: 2.9052830\ttotal: 12.3s\tremaining: 44s\n",
      "1005:\tlearn: 2.9044170\ttotal: 12.3s\tremaining: 44s\n",
      "1006:\tlearn: 2.9036178\ttotal: 12.3s\tremaining: 44s\n",
      "1007:\tlearn: 2.9036139\ttotal: 12.3s\tremaining: 44s\n",
      "1008:\tlearn: 2.9028586\ttotal: 12.4s\tremaining: 44s\n",
      "1009:\tlearn: 2.9024080\ttotal: 12.4s\tremaining: 43.9s\n",
      "1010:\tlearn: 2.9014599\ttotal: 12.4s\tremaining: 43.9s\n",
      "1011:\tlearn: 2.9005078\ttotal: 12.4s\tremaining: 43.9s\n",
      "1012:\tlearn: 2.9003577\ttotal: 12.4s\tremaining: 43.9s\n",
      "1013:\tlearn: 2.8991813\ttotal: 12.4s\tremaining: 43.9s\n",
      "1014:\tlearn: 2.8987958\ttotal: 12.4s\tremaining: 43.9s\n",
      "1015:\tlearn: 2.8980052\ttotal: 12.4s\tremaining: 43.9s\n",
      "1016:\tlearn: 2.8971574\ttotal: 12.5s\tremaining: 43.9s\n",
      "1017:\tlearn: 2.8963508\ttotal: 12.5s\tremaining: 43.8s\n",
      "1018:\tlearn: 2.8954650\ttotal: 12.5s\tremaining: 43.8s\n",
      "1019:\tlearn: 2.8945331\ttotal: 12.5s\tremaining: 43.8s\n",
      "1020:\tlearn: 2.8939073\ttotal: 12.5s\tremaining: 43.8s\n",
      "1021:\tlearn: 2.8935238\ttotal: 12.5s\tremaining: 43.8s\n",
      "1022:\tlearn: 2.8929833\ttotal: 12.5s\tremaining: 43.8s\n",
      "1023:\tlearn: 2.8925675\ttotal: 12.5s\tremaining: 43.8s\n",
      "1024:\tlearn: 2.8919455\ttotal: 12.6s\tremaining: 43.8s\n",
      "1025:\tlearn: 2.8910926\ttotal: 12.6s\tremaining: 43.8s\n",
      "1026:\tlearn: 2.8900934\ttotal: 12.6s\tremaining: 43.8s\n",
      "1027:\tlearn: 2.8894960\ttotal: 12.6s\tremaining: 43.7s\n",
      "1028:\tlearn: 2.8890930\ttotal: 12.6s\tremaining: 43.7s\n",
      "1029:\tlearn: 2.8884558\ttotal: 12.6s\tremaining: 43.7s\n",
      "1030:\tlearn: 2.8872621\ttotal: 12.6s\tremaining: 43.7s\n",
      "1031:\tlearn: 2.8872161\ttotal: 12.6s\tremaining: 43.7s\n",
      "1032:\tlearn: 2.8872123\ttotal: 12.6s\tremaining: 43.7s\n",
      "1033:\tlearn: 2.8872092\ttotal: 12.7s\tremaining: 43.6s\n",
      "1034:\tlearn: 2.8868661\ttotal: 12.7s\tremaining: 43.6s\n",
      "1035:\tlearn: 2.8860490\ttotal: 12.7s\tremaining: 43.6s\n",
      "1036:\tlearn: 2.8849927\ttotal: 12.7s\tremaining: 43.6s\n",
      "1037:\tlearn: 2.8842825\ttotal: 12.7s\tremaining: 43.6s\n",
      "1038:\tlearn: 2.8837857\ttotal: 12.7s\tremaining: 43.6s\n",
      "1039:\tlearn: 2.8830448\ttotal: 12.7s\tremaining: 43.6s\n",
      "1040:\tlearn: 2.8820609\ttotal: 12.7s\tremaining: 43.6s\n",
      "1041:\tlearn: 2.8809953\ttotal: 12.8s\tremaining: 43.5s\n",
      "1042:\tlearn: 2.8805030\ttotal: 12.8s\tremaining: 43.5s\n",
      "1043:\tlearn: 2.8796007\ttotal: 12.8s\tremaining: 43.5s\n",
      "1044:\tlearn: 2.8791926\ttotal: 12.8s\tremaining: 43.5s\n",
      "1045:\tlearn: 2.8785635\ttotal: 12.8s\tremaining: 43.5s\n",
      "1046:\tlearn: 2.8782567\ttotal: 12.8s\tremaining: 43.5s\n",
      "1047:\tlearn: 2.8773587\ttotal: 12.8s\tremaining: 43.5s\n",
      "1048:\tlearn: 2.8768315\ttotal: 12.8s\tremaining: 43.4s\n",
      "1049:\tlearn: 2.8760310\ttotal: 12.9s\tremaining: 43.4s\n",
      "1050:\tlearn: 2.8750831\ttotal: 12.9s\tremaining: 43.4s\n",
      "1051:\tlearn: 2.8743288\ttotal: 12.9s\tremaining: 43.4s\n",
      "1052:\tlearn: 2.8731441\ttotal: 12.9s\tremaining: 43.4s\n",
      "1053:\tlearn: 2.8726407\ttotal: 12.9s\tremaining: 43.4s\n",
      "1054:\tlearn: 2.8719546\ttotal: 12.9s\tremaining: 43.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1055:\tlearn: 2.8714037\ttotal: 12.9s\tremaining: 43.4s\n",
      "1056:\tlearn: 2.8706542\ttotal: 12.9s\tremaining: 43.3s\n",
      "1057:\tlearn: 2.8697748\ttotal: 12.9s\tremaining: 43.3s\n",
      "1058:\tlearn: 2.8697675\ttotal: 13s\tremaining: 43.3s\n",
      "1059:\tlearn: 2.8689557\ttotal: 13s\tremaining: 43.3s\n",
      "1060:\tlearn: 2.8679066\ttotal: 13s\tremaining: 43.3s\n",
      "1061:\tlearn: 2.8678998\ttotal: 13s\tremaining: 43.3s\n",
      "1062:\tlearn: 2.8666289\ttotal: 13s\tremaining: 43.3s\n",
      "1063:\tlearn: 2.8657826\ttotal: 13s\tremaining: 43.3s\n",
      "1064:\tlearn: 2.8651096\ttotal: 13s\tremaining: 43.2s\n",
      "1065:\tlearn: 2.8638730\ttotal: 13s\tremaining: 43.2s\n",
      "1066:\tlearn: 2.8635483\ttotal: 13.1s\tremaining: 43.2s\n",
      "1067:\tlearn: 2.8630599\ttotal: 13.1s\tremaining: 43.2s\n",
      "1068:\tlearn: 2.8620853\ttotal: 13.1s\tremaining: 43.2s\n",
      "1069:\tlearn: 2.8606781\ttotal: 13.1s\tremaining: 43.2s\n",
      "1070:\tlearn: 2.8595757\ttotal: 13.1s\tremaining: 43.2s\n",
      "1071:\tlearn: 2.8584647\ttotal: 13.1s\tremaining: 43.2s\n",
      "1072:\tlearn: 2.8574058\ttotal: 13.1s\tremaining: 43.2s\n",
      "1073:\tlearn: 2.8566499\ttotal: 13.2s\tremaining: 43.2s\n",
      "1074:\tlearn: 2.8561853\ttotal: 13.2s\tremaining: 43.1s\n",
      "1075:\tlearn: 2.8553441\ttotal: 13.2s\tremaining: 43.1s\n",
      "1076:\tlearn: 2.8547622\ttotal: 13.2s\tremaining: 43.1s\n",
      "1077:\tlearn: 2.8539203\ttotal: 13.2s\tremaining: 43.1s\n",
      "1078:\tlearn: 2.8530056\ttotal: 13.2s\tremaining: 43.1s\n",
      "1079:\tlearn: 2.8519248\ttotal: 13.2s\tremaining: 43.1s\n",
      "1080:\tlearn: 2.8509057\ttotal: 13.2s\tremaining: 43.1s\n",
      "1081:\tlearn: 2.8502399\ttotal: 13.3s\tremaining: 43.1s\n",
      "1082:\tlearn: 2.8497264\ttotal: 13.3s\tremaining: 43s\n",
      "1083:\tlearn: 2.8486867\ttotal: 13.3s\tremaining: 43s\n",
      "1084:\tlearn: 2.8478235\ttotal: 13.3s\tremaining: 43s\n",
      "1085:\tlearn: 2.8469231\ttotal: 13.3s\tremaining: 43s\n",
      "1086:\tlearn: 2.8461485\ttotal: 13.3s\tremaining: 43s\n",
      "1087:\tlearn: 2.8455146\ttotal: 13.3s\tremaining: 43s\n",
      "1088:\tlearn: 2.8446446\ttotal: 13.3s\tremaining: 43s\n",
      "1089:\tlearn: 2.8439136\ttotal: 13.4s\tremaining: 43s\n",
      "1090:\tlearn: 2.8432509\ttotal: 13.4s\tremaining: 43s\n",
      "1091:\tlearn: 2.8426621\ttotal: 13.4s\tremaining: 43s\n",
      "1092:\tlearn: 2.8419206\ttotal: 13.4s\tremaining: 42.9s\n",
      "1093:\tlearn: 2.8413787\ttotal: 13.4s\tremaining: 42.9s\n",
      "1094:\tlearn: 2.8409724\ttotal: 13.4s\tremaining: 42.9s\n",
      "1095:\tlearn: 2.8405008\ttotal: 13.4s\tremaining: 42.9s\n",
      "1096:\tlearn: 2.8398716\ttotal: 13.4s\tremaining: 42.9s\n",
      "1097:\tlearn: 2.8386045\ttotal: 13.5s\tremaining: 42.9s\n",
      "1098:\tlearn: 2.8373761\ttotal: 13.5s\tremaining: 42.9s\n",
      "1099:\tlearn: 2.8362784\ttotal: 13.5s\tremaining: 42.9s\n",
      "1100:\tlearn: 2.8353592\ttotal: 13.5s\tremaining: 42.8s\n",
      "1101:\tlearn: 2.8349972\ttotal: 13.5s\tremaining: 42.8s\n",
      "1102:\tlearn: 2.8338776\ttotal: 13.5s\tremaining: 42.8s\n",
      "1103:\tlearn: 2.8331009\ttotal: 13.5s\tremaining: 42.8s\n",
      "1104:\tlearn: 2.8321422\ttotal: 13.5s\tremaining: 42.8s\n",
      "1105:\tlearn: 2.8313917\ttotal: 13.6s\tremaining: 42.8s\n",
      "1106:\tlearn: 2.8302601\ttotal: 13.6s\tremaining: 42.8s\n",
      "1107:\tlearn: 2.8294769\ttotal: 13.6s\tremaining: 42.8s\n",
      "1108:\tlearn: 2.8282161\ttotal: 13.6s\tremaining: 42.8s\n",
      "1109:\tlearn: 2.8271224\ttotal: 13.6s\tremaining: 42.7s\n",
      "1110:\tlearn: 2.8262769\ttotal: 13.6s\tremaining: 42.7s\n",
      "1111:\tlearn: 2.8257870\ttotal: 13.6s\tremaining: 42.7s\n",
      "1112:\tlearn: 2.8253501\ttotal: 13.6s\tremaining: 42.7s\n",
      "1113:\tlearn: 2.8246602\ttotal: 13.7s\tremaining: 42.7s\n",
      "1114:\tlearn: 2.8238674\ttotal: 13.7s\tremaining: 42.7s\n",
      "1115:\tlearn: 2.8234715\ttotal: 13.7s\tremaining: 42.7s\n",
      "1116:\tlearn: 2.8228308\ttotal: 13.7s\tremaining: 42.7s\n",
      "1117:\tlearn: 2.8224653\ttotal: 13.7s\tremaining: 42.6s\n",
      "1118:\tlearn: 2.8213446\ttotal: 13.7s\tremaining: 42.6s\n",
      "1119:\tlearn: 2.8207739\ttotal: 13.7s\tremaining: 42.6s\n",
      "1120:\tlearn: 2.8202777\ttotal: 13.7s\tremaining: 42.6s\n",
      "1121:\tlearn: 2.8191031\ttotal: 13.7s\tremaining: 42.6s\n",
      "1122:\tlearn: 2.8183205\ttotal: 13.8s\tremaining: 42.6s\n",
      "1123:\tlearn: 2.8176939\ttotal: 13.8s\tremaining: 42.6s\n",
      "1124:\tlearn: 2.8172052\ttotal: 13.8s\tremaining: 42.6s\n",
      "1125:\tlearn: 2.8166326\ttotal: 13.8s\tremaining: 42.5s\n",
      "1126:\tlearn: 2.8161553\ttotal: 13.8s\tremaining: 42.5s\n",
      "1127:\tlearn: 2.8158013\ttotal: 13.8s\tremaining: 42.5s\n",
      "1128:\tlearn: 2.8148500\ttotal: 13.8s\tremaining: 42.5s\n",
      "1129:\tlearn: 2.8141524\ttotal: 13.8s\tremaining: 42.5s\n",
      "1130:\tlearn: 2.8132482\ttotal: 13.9s\tremaining: 42.5s\n",
      "1131:\tlearn: 2.8122117\ttotal: 13.9s\tremaining: 42.5s\n",
      "1132:\tlearn: 2.8114357\ttotal: 13.9s\tremaining: 42.5s\n",
      "1133:\tlearn: 2.8109716\ttotal: 13.9s\tremaining: 42.4s\n",
      "1134:\tlearn: 2.8104522\ttotal: 13.9s\tremaining: 42.4s\n",
      "1135:\tlearn: 2.8099751\ttotal: 13.9s\tremaining: 42.4s\n",
      "1136:\tlearn: 2.8091774\ttotal: 13.9s\tremaining: 42.4s\n",
      "1137:\tlearn: 2.8084318\ttotal: 13.9s\tremaining: 42.4s\n",
      "1138:\tlearn: 2.8077540\ttotal: 13.9s\tremaining: 42.4s\n",
      "1139:\tlearn: 2.8073471\ttotal: 14s\tremaining: 42.4s\n",
      "1140:\tlearn: 2.8068305\ttotal: 14s\tremaining: 42.3s\n",
      "1141:\tlearn: 2.8063433\ttotal: 14s\tremaining: 42.3s\n",
      "1142:\tlearn: 2.8056516\ttotal: 14s\tremaining: 42.3s\n",
      "1143:\tlearn: 2.8049514\ttotal: 14s\tremaining: 42.3s\n",
      "1144:\tlearn: 2.8043428\ttotal: 14s\tremaining: 42.3s\n",
      "1145:\tlearn: 2.8040012\ttotal: 14s\tremaining: 42.3s\n",
      "1146:\tlearn: 2.8036014\ttotal: 14.1s\tremaining: 42.3s\n",
      "1147:\tlearn: 2.8021779\ttotal: 14.1s\tremaining: 42.3s\n",
      "1148:\tlearn: 2.8013500\ttotal: 14.1s\tremaining: 42.3s\n",
      "1149:\tlearn: 2.8006753\ttotal: 14.1s\tremaining: 42.2s\n",
      "1150:\tlearn: 2.8003350\ttotal: 14.1s\tremaining: 42.2s\n",
      "1151:\tlearn: 2.7997337\ttotal: 14.1s\tremaining: 42.2s\n",
      "1152:\tlearn: 2.7990153\ttotal: 14.1s\tremaining: 42.2s\n",
      "1153:\tlearn: 2.7985301\ttotal: 14.1s\tremaining: 42.2s\n",
      "1154:\tlearn: 2.7978805\ttotal: 14.1s\tremaining: 42.2s\n",
      "1155:\tlearn: 2.7971178\ttotal: 14.2s\tremaining: 42.2s\n",
      "1156:\tlearn: 2.7966848\ttotal: 14.2s\tremaining: 42.1s\n",
      "1157:\tlearn: 2.7964110\ttotal: 14.2s\tremaining: 42.1s\n",
      "1158:\tlearn: 2.7960871\ttotal: 14.2s\tremaining: 42.1s\n",
      "1159:\tlearn: 2.7957407\ttotal: 14.2s\tremaining: 42.1s\n",
      "1160:\tlearn: 2.7948352\ttotal: 14.2s\tremaining: 42.1s\n",
      "1161:\tlearn: 2.7939614\ttotal: 14.2s\tremaining: 42.1s\n",
      "1162:\tlearn: 2.7934753\ttotal: 14.2s\tremaining: 42.1s\n",
      "1163:\tlearn: 2.7927895\ttotal: 14.3s\tremaining: 42.1s\n",
      "1164:\tlearn: 2.7922484\ttotal: 14.3s\tremaining: 42.1s\n",
      "1165:\tlearn: 2.7916414\ttotal: 14.3s\tremaining: 42s\n",
      "1166:\tlearn: 2.7906646\ttotal: 14.3s\tremaining: 42s\n",
      "1167:\tlearn: 2.7903131\ttotal: 14.3s\tremaining: 42s\n",
      "1168:\tlearn: 2.7895931\ttotal: 14.3s\tremaining: 42s\n",
      "1169:\tlearn: 2.7890824\ttotal: 14.3s\tremaining: 42s\n",
      "1170:\tlearn: 2.7884356\ttotal: 14.3s\tremaining: 42s\n",
      "1171:\tlearn: 2.7876534\ttotal: 14.4s\tremaining: 42s\n",
      "1172:\tlearn: 2.7865337\ttotal: 14.4s\tremaining: 42s\n",
      "1173:\tlearn: 2.7859106\ttotal: 14.4s\tremaining: 42s\n",
      "1174:\tlearn: 2.7852523\ttotal: 14.4s\tremaining: 41.9s\n",
      "1175:\tlearn: 2.7847490\ttotal: 14.4s\tremaining: 41.9s\n",
      "1176:\tlearn: 2.7841462\ttotal: 14.4s\tremaining: 41.9s\n",
      "1177:\tlearn: 2.7838053\ttotal: 14.4s\tremaining: 41.9s\n",
      "1178:\tlearn: 2.7828412\ttotal: 14.4s\tremaining: 41.9s\n",
      "1179:\tlearn: 2.7819444\ttotal: 14.5s\tremaining: 41.9s\n",
      "1180:\tlearn: 2.7806851\ttotal: 14.5s\tremaining: 41.9s\n",
      "1181:\tlearn: 2.7802676\ttotal: 14.5s\tremaining: 41.9s\n",
      "1182:\tlearn: 2.7793761\ttotal: 14.5s\tremaining: 41.9s\n",
      "1183:\tlearn: 2.7789085\ttotal: 14.5s\tremaining: 41.8s\n",
      "1184:\tlearn: 2.7783871\ttotal: 14.5s\tremaining: 41.8s\n",
      "1185:\tlearn: 2.7776184\ttotal: 14.5s\tremaining: 41.8s\n",
      "1186:\tlearn: 2.7766561\ttotal: 14.5s\tremaining: 41.8s\n",
      "1187:\tlearn: 2.7752598\ttotal: 14.6s\tremaining: 41.8s\n",
      "1188:\tlearn: 2.7742578\ttotal: 14.6s\tremaining: 41.8s\n",
      "1189:\tlearn: 2.7737977\ttotal: 14.6s\tremaining: 41.8s\n",
      "1190:\tlearn: 2.7733753\ttotal: 14.6s\tremaining: 41.7s\n",
      "1191:\tlearn: 2.7728421\ttotal: 14.6s\tremaining: 41.7s\n",
      "1192:\tlearn: 2.7722902\ttotal: 14.6s\tremaining: 41.7s\n",
      "1193:\tlearn: 2.7716767\ttotal: 14.6s\tremaining: 41.7s\n",
      "1194:\tlearn: 2.7710634\ttotal: 14.6s\tremaining: 41.7s\n",
      "1195:\tlearn: 2.7706419\ttotal: 14.7s\tremaining: 41.7s\n",
      "1196:\tlearn: 2.7701008\ttotal: 14.7s\tremaining: 41.7s\n",
      "1197:\tlearn: 2.7693611\ttotal: 14.7s\tremaining: 41.7s\n",
      "1198:\tlearn: 2.7687924\ttotal: 14.7s\tremaining: 41.7s\n",
      "1199:\tlearn: 2.7677157\ttotal: 14.7s\tremaining: 41.6s\n",
      "1200:\tlearn: 2.7670576\ttotal: 14.7s\tremaining: 41.6s\n",
      "1201:\tlearn: 2.7666567\ttotal: 14.7s\tremaining: 41.6s\n",
      "1202:\tlearn: 2.7654143\ttotal: 14.7s\tremaining: 41.6s\n",
      "1203:\tlearn: 2.7648184\ttotal: 14.8s\tremaining: 41.6s\n",
      "1204:\tlearn: 2.7642296\ttotal: 14.8s\tremaining: 41.6s\n",
      "1205:\tlearn: 2.7632105\ttotal: 14.8s\tremaining: 41.6s\n",
      "1206:\tlearn: 2.7623881\ttotal: 14.8s\tremaining: 41.6s\n",
      "1207:\tlearn: 2.7620646\ttotal: 14.8s\tremaining: 41.5s\n",
      "1208:\tlearn: 2.7610473\ttotal: 14.8s\tremaining: 41.5s\n",
      "1209:\tlearn: 2.7603043\ttotal: 14.8s\tremaining: 41.5s\n",
      "1210:\tlearn: 2.7602963\ttotal: 14.8s\tremaining: 41.5s\n",
      "1211:\tlearn: 2.7597964\ttotal: 14.8s\tremaining: 41.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1212:\tlearn: 2.7588712\ttotal: 14.9s\tremaining: 41.5s\n",
      "1213:\tlearn: 2.7584899\ttotal: 14.9s\tremaining: 41.5s\n",
      "1214:\tlearn: 2.7579077\ttotal: 14.9s\tremaining: 41.5s\n",
      "1215:\tlearn: 2.7569989\ttotal: 14.9s\tremaining: 41.4s\n",
      "1216:\tlearn: 2.7566291\ttotal: 14.9s\tremaining: 41.4s\n",
      "1217:\tlearn: 2.7555001\ttotal: 14.9s\tremaining: 41.4s\n",
      "1218:\tlearn: 2.7549862\ttotal: 14.9s\tremaining: 41.4s\n",
      "1219:\tlearn: 2.7544561\ttotal: 15s\tremaining: 41.4s\n",
      "1220:\tlearn: 2.7533890\ttotal: 15s\tremaining: 41.4s\n",
      "1221:\tlearn: 2.7524759\ttotal: 15s\tremaining: 41.4s\n",
      "1222:\tlearn: 2.7513585\ttotal: 15s\tremaining: 41.4s\n",
      "1223:\tlearn: 2.7508095\ttotal: 15s\tremaining: 41.4s\n",
      "1224:\tlearn: 2.7497529\ttotal: 15s\tremaining: 41.3s\n",
      "1225:\tlearn: 2.7489070\ttotal: 15s\tremaining: 41.3s\n",
      "1226:\tlearn: 2.7479959\ttotal: 15s\tremaining: 41.3s\n",
      "1227:\tlearn: 2.7474352\ttotal: 15s\tremaining: 41.3s\n",
      "1228:\tlearn: 2.7469373\ttotal: 15.1s\tremaining: 41.3s\n",
      "1229:\tlearn: 2.7462361\ttotal: 15.1s\tremaining: 41.3s\n",
      "1230:\tlearn: 2.7453946\ttotal: 15.1s\tremaining: 41.3s\n",
      "1231:\tlearn: 2.7448602\ttotal: 15.1s\tremaining: 41.3s\n",
      "1232:\tlearn: 2.7441513\ttotal: 15.1s\tremaining: 41.2s\n",
      "1233:\tlearn: 2.7429461\ttotal: 15.1s\tremaining: 41.2s\n",
      "1234:\tlearn: 2.7421802\ttotal: 15.1s\tremaining: 41.2s\n",
      "1235:\tlearn: 2.7418675\ttotal: 15.1s\tremaining: 41.2s\n",
      "1236:\tlearn: 2.7413073\ttotal: 15.2s\tremaining: 41.2s\n",
      "1237:\tlearn: 2.7406546\ttotal: 15.2s\tremaining: 41.2s\n",
      "1238:\tlearn: 2.7400608\ttotal: 15.2s\tremaining: 41.2s\n",
      "1239:\tlearn: 2.7392815\ttotal: 15.2s\tremaining: 41.2s\n",
      "1240:\tlearn: 2.7390274\ttotal: 15.2s\tremaining: 41.1s\n",
      "1241:\tlearn: 2.7386485\ttotal: 15.2s\tremaining: 41.1s\n",
      "1242:\tlearn: 2.7377986\ttotal: 15.2s\tremaining: 41.1s\n",
      "1243:\tlearn: 2.7372647\ttotal: 15.2s\tremaining: 41.1s\n",
      "1244:\tlearn: 2.7367957\ttotal: 15.3s\tremaining: 41.1s\n",
      "1245:\tlearn: 2.7362606\ttotal: 15.3s\tremaining: 41.1s\n",
      "1246:\tlearn: 2.7352280\ttotal: 15.3s\tremaining: 41.1s\n",
      "1247:\tlearn: 2.7345253\ttotal: 15.3s\tremaining: 41.1s\n",
      "1248:\tlearn: 2.7341712\ttotal: 15.3s\tremaining: 41s\n",
      "1249:\tlearn: 2.7337035\ttotal: 15.3s\tremaining: 41s\n",
      "1250:\tlearn: 2.7328780\ttotal: 15.3s\tremaining: 41s\n",
      "1251:\tlearn: 2.7324324\ttotal: 15.3s\tremaining: 41s\n",
      "1252:\tlearn: 2.7319371\ttotal: 15.4s\tremaining: 41s\n",
      "1253:\tlearn: 2.7314691\ttotal: 15.4s\tremaining: 41s\n",
      "1254:\tlearn: 2.7309339\ttotal: 15.4s\tremaining: 41s\n",
      "1255:\tlearn: 2.7298863\ttotal: 15.4s\tremaining: 41s\n",
      "1256:\tlearn: 2.7288001\ttotal: 15.4s\tremaining: 40.9s\n",
      "1257:\tlearn: 2.7282311\ttotal: 15.4s\tremaining: 40.9s\n",
      "1258:\tlearn: 2.7277712\ttotal: 15.4s\tremaining: 40.9s\n",
      "1259:\tlearn: 2.7271523\ttotal: 15.4s\tremaining: 40.9s\n",
      "1260:\tlearn: 2.7259244\ttotal: 15.5s\tremaining: 40.9s\n",
      "1261:\tlearn: 2.7254548\ttotal: 15.5s\tremaining: 40.9s\n",
      "1262:\tlearn: 2.7247750\ttotal: 15.5s\tremaining: 40.9s\n",
      "1263:\tlearn: 2.7239212\ttotal: 15.5s\tremaining: 40.9s\n",
      "1264:\tlearn: 2.7234129\ttotal: 15.5s\tremaining: 40.8s\n",
      "1265:\tlearn: 2.7227277\ttotal: 15.5s\tremaining: 40.8s\n",
      "1266:\tlearn: 2.7218511\ttotal: 15.5s\tremaining: 40.8s\n",
      "1267:\tlearn: 2.7212963\ttotal: 15.5s\tremaining: 40.8s\n",
      "1268:\tlearn: 2.7209259\ttotal: 15.5s\tremaining: 40.8s\n",
      "1269:\tlearn: 2.7203579\ttotal: 15.6s\tremaining: 40.8s\n",
      "1270:\tlearn: 2.7197078\ttotal: 15.6s\tremaining: 40.8s\n",
      "1271:\tlearn: 2.7187708\ttotal: 15.6s\tremaining: 40.8s\n",
      "1272:\tlearn: 2.7181901\ttotal: 15.6s\tremaining: 40.7s\n",
      "1273:\tlearn: 2.7173055\ttotal: 15.6s\tremaining: 40.7s\n",
      "1274:\tlearn: 2.7161961\ttotal: 15.6s\tremaining: 40.7s\n",
      "1275:\tlearn: 2.7154487\ttotal: 15.6s\tremaining: 40.7s\n",
      "1276:\tlearn: 2.7152525\ttotal: 15.6s\tremaining: 40.7s\n",
      "1277:\tlearn: 2.7147398\ttotal: 15.7s\tremaining: 40.7s\n",
      "1278:\tlearn: 2.7139912\ttotal: 15.7s\tremaining: 40.7s\n",
      "1279:\tlearn: 2.7133273\ttotal: 15.7s\tremaining: 40.7s\n",
      "1280:\tlearn: 2.7127583\ttotal: 15.7s\tremaining: 40.6s\n",
      "1281:\tlearn: 2.7118159\ttotal: 15.7s\tremaining: 40.6s\n",
      "1282:\tlearn: 2.7112949\ttotal: 15.7s\tremaining: 40.6s\n",
      "1283:\tlearn: 2.7108749\ttotal: 15.7s\tremaining: 40.6s\n",
      "1284:\tlearn: 2.7105870\ttotal: 15.7s\tremaining: 40.6s\n",
      "1285:\tlearn: 2.7101898\ttotal: 15.8s\tremaining: 40.6s\n",
      "1286:\tlearn: 2.7098502\ttotal: 15.8s\tremaining: 40.6s\n",
      "1287:\tlearn: 2.7093971\ttotal: 15.8s\tremaining: 40.6s\n",
      "1288:\tlearn: 2.7089586\ttotal: 15.8s\tremaining: 40.6s\n",
      "1289:\tlearn: 2.7080816\ttotal: 15.8s\tremaining: 40.5s\n",
      "1290:\tlearn: 2.7074520\ttotal: 15.8s\tremaining: 40.5s\n",
      "1291:\tlearn: 2.7066865\ttotal: 15.8s\tremaining: 40.5s\n",
      "1292:\tlearn: 2.7065251\ttotal: 15.8s\tremaining: 40.5s\n",
      "1293:\tlearn: 2.7057514\ttotal: 15.9s\tremaining: 40.5s\n",
      "1294:\tlearn: 2.7050456\ttotal: 15.9s\tremaining: 40.5s\n",
      "1295:\tlearn: 2.7046219\ttotal: 15.9s\tremaining: 40.5s\n",
      "1296:\tlearn: 2.7041171\ttotal: 15.9s\tremaining: 40.4s\n",
      "1297:\tlearn: 2.7033515\ttotal: 15.9s\tremaining: 40.4s\n",
      "1298:\tlearn: 2.7030260\ttotal: 15.9s\tremaining: 40.4s\n",
      "1299:\tlearn: 2.7024653\ttotal: 15.9s\tremaining: 40.4s\n",
      "1300:\tlearn: 2.7017757\ttotal: 15.9s\tremaining: 40.4s\n",
      "1301:\tlearn: 2.7011060\ttotal: 16s\tremaining: 40.4s\n",
      "1302:\tlearn: 2.7003961\ttotal: 16s\tremaining: 40.4s\n",
      "1303:\tlearn: 2.6992360\ttotal: 16s\tremaining: 40.4s\n",
      "1304:\tlearn: 2.6990866\ttotal: 16s\tremaining: 40.3s\n",
      "1305:\tlearn: 2.6986868\ttotal: 16s\tremaining: 40.3s\n",
      "1306:\tlearn: 2.6979021\ttotal: 16s\tremaining: 40.3s\n",
      "1307:\tlearn: 2.6975916\ttotal: 16s\tremaining: 40.3s\n",
      "1308:\tlearn: 2.6970841\ttotal: 16s\tremaining: 40.3s\n",
      "1309:\tlearn: 2.6965092\ttotal: 16.1s\tremaining: 40.3s\n",
      "1310:\tlearn: 2.6953365\ttotal: 16.1s\tremaining: 40.3s\n",
      "1311:\tlearn: 2.6946492\ttotal: 16.1s\tremaining: 40.3s\n",
      "1312:\tlearn: 2.6937727\ttotal: 16.1s\tremaining: 40.2s\n",
      "1313:\tlearn: 2.6923924\ttotal: 16.1s\tremaining: 40.2s\n",
      "1314:\tlearn: 2.6915919\ttotal: 16.1s\tremaining: 40.2s\n",
      "1315:\tlearn: 2.6912470\ttotal: 16.1s\tremaining: 40.2s\n",
      "1316:\tlearn: 2.6902906\ttotal: 16.1s\tremaining: 40.2s\n",
      "1317:\tlearn: 2.6891202\ttotal: 16.2s\tremaining: 40.2s\n",
      "1318:\tlearn: 2.6887815\ttotal: 16.2s\tremaining: 40.2s\n",
      "1319:\tlearn: 2.6880110\ttotal: 16.2s\tremaining: 40.2s\n",
      "1320:\tlearn: 2.6872401\ttotal: 16.2s\tremaining: 40.2s\n",
      "1321:\tlearn: 2.6869287\ttotal: 16.2s\tremaining: 40.1s\n",
      "1322:\tlearn: 2.6861623\ttotal: 16.2s\tremaining: 40.1s\n",
      "1323:\tlearn: 2.6854668\ttotal: 16.2s\tremaining: 40.1s\n",
      "1324:\tlearn: 2.6847221\ttotal: 16.2s\tremaining: 40.1s\n",
      "1325:\tlearn: 2.6834911\ttotal: 16.3s\tremaining: 40.1s\n",
      "1326:\tlearn: 2.6825181\ttotal: 16.3s\tremaining: 40.1s\n",
      "1327:\tlearn: 2.6814866\ttotal: 16.3s\tremaining: 40.1s\n",
      "1328:\tlearn: 2.6809319\ttotal: 16.3s\tremaining: 40.1s\n",
      "1329:\tlearn: 2.6802482\ttotal: 16.3s\tremaining: 40s\n",
      "1330:\tlearn: 2.6791532\ttotal: 16.3s\tremaining: 40s\n",
      "1331:\tlearn: 2.6785160\ttotal: 16.3s\tremaining: 40s\n",
      "1332:\tlearn: 2.6779166\ttotal: 16.3s\tremaining: 40s\n",
      "1333:\tlearn: 2.6773805\ttotal: 16.4s\tremaining: 40s\n",
      "1334:\tlearn: 2.6767148\ttotal: 16.4s\tremaining: 40s\n",
      "1335:\tlearn: 2.6758092\ttotal: 16.4s\tremaining: 40s\n",
      "1336:\tlearn: 2.6750240\ttotal: 16.4s\tremaining: 40s\n",
      "1337:\tlearn: 2.6739412\ttotal: 16.4s\tremaining: 40s\n",
      "1338:\tlearn: 2.6733116\ttotal: 16.4s\tremaining: 39.9s\n",
      "1339:\tlearn: 2.6726088\ttotal: 16.4s\tremaining: 39.9s\n",
      "1340:\tlearn: 2.6722371\ttotal: 16.4s\tremaining: 39.9s\n",
      "1341:\tlearn: 2.6720131\ttotal: 16.4s\tremaining: 39.9s\n",
      "1342:\tlearn: 2.6715376\ttotal: 16.5s\tremaining: 39.9s\n",
      "1343:\tlearn: 2.6707132\ttotal: 16.5s\tremaining: 39.9s\n",
      "1344:\tlearn: 2.6702834\ttotal: 16.5s\tremaining: 39.9s\n",
      "1345:\tlearn: 2.6696782\ttotal: 16.5s\tremaining: 39.9s\n",
      "1346:\tlearn: 2.6690454\ttotal: 16.5s\tremaining: 39.8s\n",
      "1347:\tlearn: 2.6682525\ttotal: 16.5s\tremaining: 39.8s\n",
      "1348:\tlearn: 2.6674858\ttotal: 16.5s\tremaining: 39.8s\n",
      "1349:\tlearn: 2.6668391\ttotal: 16.5s\tremaining: 39.8s\n",
      "1350:\tlearn: 2.6657691\ttotal: 16.6s\tremaining: 39.8s\n",
      "1351:\tlearn: 2.6656321\ttotal: 16.6s\tremaining: 39.8s\n",
      "1352:\tlearn: 2.6650900\ttotal: 16.6s\tremaining: 39.8s\n",
      "1353:\tlearn: 2.6645427\ttotal: 16.6s\tremaining: 39.8s\n",
      "1354:\tlearn: 2.6636707\ttotal: 16.6s\tremaining: 39.8s\n",
      "1355:\tlearn: 2.6631556\ttotal: 16.6s\tremaining: 39.7s\n",
      "1356:\tlearn: 2.6625516\ttotal: 16.6s\tremaining: 39.7s\n",
      "1357:\tlearn: 2.6618298\ttotal: 16.6s\tremaining: 39.7s\n",
      "1358:\tlearn: 2.6612488\ttotal: 16.7s\tremaining: 39.7s\n",
      "1359:\tlearn: 2.6607690\ttotal: 16.7s\tremaining: 39.7s\n",
      "1360:\tlearn: 2.6605595\ttotal: 16.7s\tremaining: 39.7s\n",
      "1361:\tlearn: 2.6597318\ttotal: 16.7s\tremaining: 39.7s\n",
      "1362:\tlearn: 2.6589036\ttotal: 16.7s\tremaining: 39.7s\n",
      "1363:\tlearn: 2.6578615\ttotal: 16.7s\tremaining: 39.7s\n",
      "1364:\tlearn: 2.6573705\ttotal: 16.7s\tremaining: 39.6s\n",
      "1365:\tlearn: 2.6569100\ttotal: 16.8s\tremaining: 39.6s\n",
      "1366:\tlearn: 2.6560205\ttotal: 16.8s\tremaining: 39.6s\n",
      "1367:\tlearn: 2.6554167\ttotal: 16.8s\tremaining: 39.6s\n",
      "1368:\tlearn: 2.6549051\ttotal: 16.8s\tremaining: 39.6s\n",
      "1369:\tlearn: 2.6546325\ttotal: 16.8s\tremaining: 39.6s\n",
      "1370:\tlearn: 2.6541329\ttotal: 16.8s\tremaining: 39.6s\n",
      "1371:\tlearn: 2.6530994\ttotal: 16.8s\tremaining: 39.6s\n",
      "1372:\tlearn: 2.6524812\ttotal: 16.8s\tremaining: 39.5s\n",
      "1373:\tlearn: 2.6521093\ttotal: 16.8s\tremaining: 39.5s\n",
      "1374:\tlearn: 2.6512265\ttotal: 16.9s\tremaining: 39.5s\n",
      "1375:\tlearn: 2.6503795\ttotal: 16.9s\tremaining: 39.5s\n",
      "1376:\tlearn: 2.6502023\ttotal: 16.9s\tremaining: 39.5s\n",
      "1377:\tlearn: 2.6496435\ttotal: 16.9s\tremaining: 39.5s\n",
      "1378:\tlearn: 2.6489980\ttotal: 16.9s\tremaining: 39.5s\n",
      "1379:\tlearn: 2.6481438\ttotal: 16.9s\tremaining: 39.5s\n",
      "1380:\tlearn: 2.6476332\ttotal: 16.9s\tremaining: 39.4s\n",
      "1381:\tlearn: 2.6471815\ttotal: 16.9s\tremaining: 39.4s\n",
      "1382:\tlearn: 2.6469824\ttotal: 17s\tremaining: 39.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1383:\tlearn: 2.6463104\ttotal: 17s\tremaining: 39.4s\n",
      "1384:\tlearn: 2.6458941\ttotal: 17s\tremaining: 39.4s\n",
      "1385:\tlearn: 2.6452407\ttotal: 17s\tremaining: 39.4s\n",
      "1386:\tlearn: 2.6447341\ttotal: 17s\tremaining: 39.4s\n",
      "1387:\tlearn: 2.6443376\ttotal: 17s\tremaining: 39.4s\n",
      "1388:\tlearn: 2.6437149\ttotal: 17s\tremaining: 39.3s\n",
      "1389:\tlearn: 2.6432504\ttotal: 17s\tremaining: 39.3s\n",
      "1390:\tlearn: 2.6430778\ttotal: 17.1s\tremaining: 39.3s\n",
      "1391:\tlearn: 2.6425253\ttotal: 17.1s\tremaining: 39.3s\n",
      "1392:\tlearn: 2.6420192\ttotal: 17.1s\tremaining: 39.3s\n",
      "1393:\tlearn: 2.6416222\ttotal: 17.1s\tremaining: 39.3s\n",
      "1394:\tlearn: 2.6409579\ttotal: 17.1s\tremaining: 39.3s\n",
      "1395:\tlearn: 2.6403719\ttotal: 17.1s\tremaining: 39.3s\n",
      "1396:\tlearn: 2.6398553\ttotal: 17.1s\tremaining: 39.2s\n",
      "1397:\tlearn: 2.6395049\ttotal: 17.1s\tremaining: 39.2s\n",
      "1398:\tlearn: 2.6384261\ttotal: 17.1s\tremaining: 39.2s\n",
      "1399:\tlearn: 2.6378423\ttotal: 17.2s\tremaining: 39.2s\n",
      "1400:\tlearn: 2.6371312\ttotal: 17.2s\tremaining: 39.2s\n",
      "1401:\tlearn: 2.6369183\ttotal: 17.2s\tremaining: 39.2s\n",
      "1402:\tlearn: 2.6361980\ttotal: 17.2s\tremaining: 39.2s\n",
      "1403:\tlearn: 2.6360581\ttotal: 17.2s\tremaining: 39.2s\n",
      "1404:\tlearn: 2.6353721\ttotal: 17.2s\tremaining: 39.1s\n",
      "1405:\tlearn: 2.6347289\ttotal: 17.2s\tremaining: 39.1s\n",
      "1406:\tlearn: 2.6344835\ttotal: 17.2s\tremaining: 39.1s\n",
      "1407:\tlearn: 2.6340327\ttotal: 17.3s\tremaining: 39.1s\n",
      "1408:\tlearn: 2.6336403\ttotal: 17.3s\tremaining: 39.1s\n",
      "1409:\tlearn: 2.6332472\ttotal: 17.3s\tremaining: 39.1s\n",
      "1410:\tlearn: 2.6328349\ttotal: 17.3s\tremaining: 39.1s\n",
      "1411:\tlearn: 2.6324898\ttotal: 17.3s\tremaining: 39.1s\n",
      "1412:\tlearn: 2.6321233\ttotal: 17.3s\tremaining: 39s\n",
      "1413:\tlearn: 2.6313991\ttotal: 17.3s\tremaining: 39s\n",
      "1414:\tlearn: 2.6308193\ttotal: 17.3s\tremaining: 39s\n",
      "1415:\tlearn: 2.6303740\ttotal: 17.4s\tremaining: 39s\n",
      "1416:\tlearn: 2.6297152\ttotal: 17.4s\tremaining: 39s\n",
      "1417:\tlearn: 2.6291360\ttotal: 17.4s\tremaining: 39s\n",
      "1418:\tlearn: 2.6288825\ttotal: 17.4s\tremaining: 39s\n",
      "1419:\tlearn: 2.6285392\ttotal: 17.4s\tremaining: 39s\n",
      "1420:\tlearn: 2.6274151\ttotal: 17.4s\tremaining: 38.9s\n",
      "1421:\tlearn: 2.6269895\ttotal: 17.4s\tremaining: 38.9s\n",
      "1422:\tlearn: 2.6265350\ttotal: 17.4s\tremaining: 38.9s\n",
      "1423:\tlearn: 2.6257363\ttotal: 17.5s\tremaining: 38.9s\n",
      "1424:\tlearn: 2.6252991\ttotal: 17.5s\tremaining: 38.9s\n",
      "1425:\tlearn: 2.6242034\ttotal: 17.5s\tremaining: 38.9s\n",
      "1426:\tlearn: 2.6235609\ttotal: 17.5s\tremaining: 38.9s\n",
      "1427:\tlearn: 2.6227953\ttotal: 17.5s\tremaining: 38.9s\n",
      "1428:\tlearn: 2.6221442\ttotal: 17.5s\tremaining: 38.8s\n",
      "1429:\tlearn: 2.6213257\ttotal: 17.5s\tremaining: 38.8s\n",
      "1430:\tlearn: 2.6211484\ttotal: 17.5s\tremaining: 38.8s\n",
      "1431:\tlearn: 2.6208355\ttotal: 17.6s\tremaining: 38.8s\n",
      "1432:\tlearn: 2.6200597\ttotal: 17.6s\tremaining: 38.8s\n",
      "1433:\tlearn: 2.6193339\ttotal: 17.6s\tremaining: 38.8s\n",
      "1434:\tlearn: 2.6189423\ttotal: 17.6s\tremaining: 38.8s\n",
      "1435:\tlearn: 2.6178371\ttotal: 17.6s\tremaining: 38.8s\n",
      "1436:\tlearn: 2.6176476\ttotal: 17.6s\tremaining: 38.7s\n",
      "1437:\tlearn: 2.6172231\ttotal: 17.6s\tremaining: 38.7s\n",
      "1438:\tlearn: 2.6169376\ttotal: 17.6s\tremaining: 38.7s\n",
      "1439:\tlearn: 2.6163996\ttotal: 17.6s\tremaining: 38.7s\n",
      "1440:\tlearn: 2.6157818\ttotal: 17.7s\tremaining: 38.7s\n",
      "1441:\tlearn: 2.6153034\ttotal: 17.7s\tremaining: 38.7s\n",
      "1442:\tlearn: 2.6149541\ttotal: 17.7s\tremaining: 38.7s\n",
      "1443:\tlearn: 2.6146162\ttotal: 17.7s\tremaining: 38.7s\n",
      "1444:\tlearn: 2.6141826\ttotal: 17.7s\tremaining: 38.6s\n",
      "1445:\tlearn: 2.6129850\ttotal: 17.7s\tremaining: 38.6s\n",
      "1446:\tlearn: 2.6125512\ttotal: 17.7s\tremaining: 38.6s\n",
      "1447:\tlearn: 2.6117320\ttotal: 17.7s\tremaining: 38.6s\n",
      "1448:\tlearn: 2.6111110\ttotal: 17.8s\tremaining: 38.6s\n",
      "1449:\tlearn: 2.6103118\ttotal: 17.8s\tremaining: 38.6s\n",
      "1450:\tlearn: 2.6101682\ttotal: 17.8s\tremaining: 38.6s\n",
      "1451:\tlearn: 2.6095259\ttotal: 17.8s\tremaining: 38.6s\n",
      "1452:\tlearn: 2.6091807\ttotal: 17.8s\tremaining: 38.5s\n",
      "1453:\tlearn: 2.6084577\ttotal: 17.8s\tremaining: 38.5s\n",
      "1454:\tlearn: 2.6075765\ttotal: 17.8s\tremaining: 38.5s\n",
      "1455:\tlearn: 2.6072293\ttotal: 17.8s\tremaining: 38.5s\n",
      "1456:\tlearn: 2.6067642\ttotal: 17.9s\tremaining: 38.5s\n",
      "1457:\tlearn: 2.6055074\ttotal: 17.9s\tremaining: 38.5s\n",
      "1458:\tlearn: 2.6050317\ttotal: 17.9s\tremaining: 38.5s\n",
      "1459:\tlearn: 2.6044303\ttotal: 17.9s\tremaining: 38.5s\n",
      "1460:\tlearn: 2.6036429\ttotal: 17.9s\tremaining: 38.4s\n",
      "1461:\tlearn: 2.6034805\ttotal: 17.9s\tremaining: 38.4s\n",
      "1462:\tlearn: 2.6026553\ttotal: 17.9s\tremaining: 38.4s\n",
      "1463:\tlearn: 2.6017696\ttotal: 17.9s\tremaining: 38.4s\n",
      "1464:\tlearn: 2.6009038\ttotal: 18s\tremaining: 38.4s\n",
      "1465:\tlearn: 2.6006135\ttotal: 18s\tremaining: 38.4s\n",
      "1466:\tlearn: 2.6000489\ttotal: 18s\tremaining: 38.4s\n",
      "1467:\tlearn: 2.5993828\ttotal: 18s\tremaining: 38.4s\n",
      "1468:\tlearn: 2.5987255\ttotal: 18s\tremaining: 38.4s\n",
      "1469:\tlearn: 2.5980285\ttotal: 18s\tremaining: 38.3s\n",
      "1470:\tlearn: 2.5976964\ttotal: 18s\tremaining: 38.3s\n",
      "1471:\tlearn: 2.5966896\ttotal: 18s\tremaining: 38.3s\n",
      "1472:\tlearn: 2.5966525\ttotal: 18.1s\tremaining: 38.3s\n",
      "1473:\tlearn: 2.5961472\ttotal: 18.1s\tremaining: 38.3s\n",
      "1474:\tlearn: 2.5954919\ttotal: 18.1s\tremaining: 38.3s\n",
      "1475:\tlearn: 2.5946777\ttotal: 18.1s\tremaining: 38.3s\n",
      "1476:\tlearn: 2.5939782\ttotal: 18.1s\tremaining: 38.3s\n",
      "1477:\tlearn: 2.5935608\ttotal: 18.1s\tremaining: 38.3s\n",
      "1478:\tlearn: 2.5929624\ttotal: 18.1s\tremaining: 38.3s\n",
      "1479:\tlearn: 2.5924856\ttotal: 18.2s\tremaining: 38.2s\n",
      "1480:\tlearn: 2.5918222\ttotal: 18.2s\tremaining: 38.2s\n",
      "1481:\tlearn: 2.5915955\ttotal: 18.2s\tremaining: 38.2s\n",
      "1482:\tlearn: 2.5913452\ttotal: 18.2s\tremaining: 38.2s\n",
      "1483:\tlearn: 2.5905607\ttotal: 18.2s\tremaining: 38.2s\n",
      "1484:\tlearn: 2.5902347\ttotal: 18.2s\tremaining: 38.2s\n",
      "1485:\tlearn: 2.5898949\ttotal: 18.2s\tremaining: 38.2s\n",
      "1486:\tlearn: 2.5893465\ttotal: 18.2s\tremaining: 38.2s\n",
      "1487:\tlearn: 2.5889590\ttotal: 18.3s\tremaining: 38.2s\n",
      "1488:\tlearn: 2.5886235\ttotal: 18.3s\tremaining: 38.1s\n",
      "1489:\tlearn: 2.5883218\ttotal: 18.3s\tremaining: 38.1s\n",
      "1490:\tlearn: 2.5873552\ttotal: 18.3s\tremaining: 38.1s\n",
      "1491:\tlearn: 2.5867159\ttotal: 18.3s\tremaining: 38.1s\n",
      "1492:\tlearn: 2.5865635\ttotal: 18.3s\tremaining: 38.1s\n",
      "1493:\tlearn: 2.5858599\ttotal: 18.3s\tremaining: 38.1s\n",
      "1494:\tlearn: 2.5855261\ttotal: 18.3s\tremaining: 38.1s\n",
      "1495:\tlearn: 2.5851869\ttotal: 18.3s\tremaining: 38s\n",
      "1496:\tlearn: 2.5846181\ttotal: 18.4s\tremaining: 38s\n",
      "1497:\tlearn: 2.5836864\ttotal: 18.4s\tremaining: 38s\n",
      "1498:\tlearn: 2.5834773\ttotal: 18.4s\tremaining: 38s\n",
      "1499:\tlearn: 2.5830806\ttotal: 18.4s\tremaining: 38s\n",
      "1500:\tlearn: 2.5827197\ttotal: 18.4s\tremaining: 38s\n",
      "1501:\tlearn: 2.5821848\ttotal: 18.4s\tremaining: 38s\n",
      "1502:\tlearn: 2.5815266\ttotal: 18.4s\tremaining: 38s\n",
      "1503:\tlearn: 2.5806811\ttotal: 18.4s\tremaining: 37.9s\n",
      "1504:\tlearn: 2.5804270\ttotal: 18.5s\tremaining: 37.9s\n",
      "1505:\tlearn: 2.5802380\ttotal: 18.5s\tremaining: 37.9s\n",
      "1506:\tlearn: 2.5799041\ttotal: 18.5s\tremaining: 37.9s\n",
      "1507:\tlearn: 2.5793235\ttotal: 18.5s\tremaining: 37.9s\n",
      "1508:\tlearn: 2.5788218\ttotal: 18.5s\tremaining: 37.9s\n",
      "1509:\tlearn: 2.5784783\ttotal: 18.5s\tremaining: 37.9s\n",
      "1510:\tlearn: 2.5776687\ttotal: 18.5s\tremaining: 37.8s\n",
      "1511:\tlearn: 2.5767408\ttotal: 18.5s\tremaining: 37.8s\n",
      "1512:\tlearn: 2.5766144\ttotal: 18.5s\tremaining: 37.8s\n",
      "1513:\tlearn: 2.5753820\ttotal: 18.6s\tremaining: 37.8s\n",
      "1514:\tlearn: 2.5746684\ttotal: 18.6s\tremaining: 37.8s\n",
      "1515:\tlearn: 2.5742857\ttotal: 18.6s\tremaining: 37.8s\n",
      "1516:\tlearn: 2.5736379\ttotal: 18.6s\tremaining: 37.8s\n",
      "1517:\tlearn: 2.5726900\ttotal: 18.6s\tremaining: 37.8s\n",
      "1518:\tlearn: 2.5717612\ttotal: 18.6s\tremaining: 37.7s\n",
      "1519:\tlearn: 2.5715833\ttotal: 18.6s\tremaining: 37.7s\n",
      "1520:\tlearn: 2.5712440\ttotal: 18.6s\tremaining: 37.7s\n",
      "1521:\tlearn: 2.5707941\ttotal: 18.7s\tremaining: 37.7s\n",
      "1522:\tlearn: 2.5699549\ttotal: 18.7s\tremaining: 37.7s\n",
      "1523:\tlearn: 2.5697387\ttotal: 18.7s\tremaining: 37.7s\n",
      "1524:\tlearn: 2.5692305\ttotal: 18.7s\tremaining: 37.7s\n",
      "1525:\tlearn: 2.5683120\ttotal: 18.7s\tremaining: 37.7s\n",
      "1526:\tlearn: 2.5677404\ttotal: 18.7s\tremaining: 37.6s\n",
      "1527:\tlearn: 2.5669763\ttotal: 18.7s\tremaining: 37.6s\n",
      "1528:\tlearn: 2.5663487\ttotal: 18.7s\tremaining: 37.6s\n",
      "1529:\tlearn: 2.5659030\ttotal: 18.8s\tremaining: 37.6s\n",
      "1530:\tlearn: 2.5651231\ttotal: 18.8s\tremaining: 37.6s\n",
      "1531:\tlearn: 2.5645569\ttotal: 18.8s\tremaining: 37.6s\n",
      "1532:\tlearn: 2.5639598\ttotal: 18.8s\tremaining: 37.6s\n",
      "1533:\tlearn: 2.5633264\ttotal: 18.8s\tremaining: 37.6s\n",
      "1534:\tlearn: 2.5629925\ttotal: 18.8s\tremaining: 37.5s\n",
      "1535:\tlearn: 2.5626183\ttotal: 18.8s\tremaining: 37.5s\n",
      "1536:\tlearn: 2.5620447\ttotal: 18.8s\tremaining: 37.5s\n",
      "1537:\tlearn: 2.5617378\ttotal: 18.9s\tremaining: 37.5s\n",
      "1538:\tlearn: 2.5606010\ttotal: 18.9s\tremaining: 37.5s\n",
      "1539:\tlearn: 2.5603100\ttotal: 18.9s\tremaining: 37.5s\n",
      "1540:\tlearn: 2.5601167\ttotal: 18.9s\tremaining: 37.5s\n",
      "1541:\tlearn: 2.5593470\ttotal: 18.9s\tremaining: 37.5s\n",
      "1542:\tlearn: 2.5590093\ttotal: 18.9s\tremaining: 37.5s\n",
      "1543:\tlearn: 2.5584126\ttotal: 18.9s\tremaining: 37.4s\n",
      "1544:\tlearn: 2.5581561\ttotal: 18.9s\tremaining: 37.4s\n",
      "1545:\tlearn: 2.5572813\ttotal: 19s\tremaining: 37.4s\n",
      "1546:\tlearn: 2.5564865\ttotal: 19s\tremaining: 37.4s\n",
      "1547:\tlearn: 2.5560310\ttotal: 19s\tremaining: 37.4s\n",
      "1548:\tlearn: 2.5555523\ttotal: 19s\tremaining: 37.4s\n",
      "1549:\tlearn: 2.5550362\ttotal: 19s\tremaining: 37.4s\n",
      "1550:\tlearn: 2.5549609\ttotal: 19s\tremaining: 37.3s\n",
      "1551:\tlearn: 2.5541346\ttotal: 19s\tremaining: 37.3s\n",
      "1552:\tlearn: 2.5535704\ttotal: 19s\tremaining: 37.3s\n",
      "1553:\tlearn: 2.5532180\ttotal: 19s\tremaining: 37.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1554:\tlearn: 2.5527814\ttotal: 19.1s\tremaining: 37.3s\n",
      "1555:\tlearn: 2.5524275\ttotal: 19.1s\tremaining: 37.3s\n",
      "1556:\tlearn: 2.5518806\ttotal: 19.1s\tremaining: 37.3s\n",
      "1557:\tlearn: 2.5514540\ttotal: 19.1s\tremaining: 37.3s\n",
      "1558:\tlearn: 2.5511013\ttotal: 19.1s\tremaining: 37.3s\n",
      "1559:\tlearn: 2.5506040\ttotal: 19.1s\tremaining: 37.2s\n",
      "1560:\tlearn: 2.5500104\ttotal: 19.1s\tremaining: 37.2s\n",
      "1561:\tlearn: 2.5498792\ttotal: 19.1s\tremaining: 37.2s\n",
      "1562:\tlearn: 2.5493647\ttotal: 19.2s\tremaining: 37.2s\n",
      "1563:\tlearn: 2.5486269\ttotal: 19.2s\tremaining: 37.2s\n",
      "1564:\tlearn: 2.5481574\ttotal: 19.2s\tremaining: 37.2s\n",
      "1565:\tlearn: 2.5479992\ttotal: 19.2s\tremaining: 37.2s\n",
      "1566:\tlearn: 2.5475914\ttotal: 19.2s\tremaining: 37.1s\n",
      "1567:\tlearn: 2.5468550\ttotal: 19.2s\tremaining: 37.1s\n",
      "1568:\tlearn: 2.5463830\ttotal: 19.2s\tremaining: 37.1s\n",
      "1569:\tlearn: 2.5458712\ttotal: 19.2s\tremaining: 37.1s\n",
      "1570:\tlearn: 2.5453473\ttotal: 19.3s\tremaining: 37.1s\n",
      "1571:\tlearn: 2.5450022\ttotal: 19.3s\tremaining: 37.1s\n",
      "1572:\tlearn: 2.5442335\ttotal: 19.3s\tremaining: 37.1s\n",
      "1573:\tlearn: 2.5434414\ttotal: 19.3s\tremaining: 37.1s\n",
      "1574:\tlearn: 2.5429240\ttotal: 19.3s\tremaining: 37s\n",
      "1575:\tlearn: 2.5426588\ttotal: 19.3s\tremaining: 37s\n",
      "1576:\tlearn: 2.5424228\ttotal: 19.3s\tremaining: 37s\n",
      "1577:\tlearn: 2.5418723\ttotal: 19.3s\tremaining: 37s\n",
      "1578:\tlearn: 2.5414996\ttotal: 19.3s\tremaining: 37s\n",
      "1579:\tlearn: 2.5408805\ttotal: 19.4s\tremaining: 37s\n",
      "1580:\tlearn: 2.5403279\ttotal: 19.4s\tremaining: 37s\n",
      "1581:\tlearn: 2.5399979\ttotal: 19.4s\tremaining: 37s\n",
      "1582:\tlearn: 2.5395409\ttotal: 19.4s\tremaining: 36.9s\n",
      "1583:\tlearn: 2.5391094\ttotal: 19.4s\tremaining: 36.9s\n",
      "1584:\tlearn: 2.5387583\ttotal: 19.4s\tremaining: 36.9s\n",
      "1585:\tlearn: 2.5381508\ttotal: 19.4s\tremaining: 36.9s\n",
      "1586:\tlearn: 2.5378481\ttotal: 19.4s\tremaining: 36.9s\n",
      "1587:\tlearn: 2.5371343\ttotal: 19.5s\tremaining: 36.9s\n",
      "1588:\tlearn: 2.5362349\ttotal: 19.5s\tremaining: 36.9s\n",
      "1589:\tlearn: 2.5359124\ttotal: 19.5s\tremaining: 36.9s\n",
      "1590:\tlearn: 2.5355708\ttotal: 19.5s\tremaining: 36.8s\n",
      "1591:\tlearn: 2.5348743\ttotal: 19.5s\tremaining: 36.8s\n",
      "1592:\tlearn: 2.5347651\ttotal: 19.5s\tremaining: 36.8s\n",
      "1593:\tlearn: 2.5344273\ttotal: 19.5s\tremaining: 36.8s\n",
      "1594:\tlearn: 2.5339933\ttotal: 19.5s\tremaining: 36.8s\n",
      "1595:\tlearn: 2.5332550\ttotal: 19.6s\tremaining: 36.8s\n",
      "1596:\tlearn: 2.5328266\ttotal: 19.6s\tremaining: 36.8s\n",
      "1597:\tlearn: 2.5327998\ttotal: 19.6s\tremaining: 36.8s\n",
      "1598:\tlearn: 2.5326241\ttotal: 19.6s\tremaining: 36.7s\n",
      "1599:\tlearn: 2.5322344\ttotal: 19.6s\tremaining: 36.7s\n",
      "1600:\tlearn: 2.5321318\ttotal: 19.6s\tremaining: 36.7s\n",
      "1601:\tlearn: 2.5316625\ttotal: 19.6s\tremaining: 36.7s\n",
      "1602:\tlearn: 2.5311488\ttotal: 19.6s\tremaining: 36.7s\n",
      "1603:\tlearn: 2.5307022\ttotal: 19.6s\tremaining: 36.7s\n",
      "1604:\tlearn: 2.5304133\ttotal: 19.7s\tremaining: 36.7s\n",
      "1605:\tlearn: 2.5298698\ttotal: 19.7s\tremaining: 36.6s\n",
      "1606:\tlearn: 2.5294042\ttotal: 19.7s\tremaining: 36.6s\n",
      "1607:\tlearn: 2.5288076\ttotal: 19.7s\tremaining: 36.6s\n",
      "1608:\tlearn: 2.5284256\ttotal: 19.7s\tremaining: 36.6s\n",
      "1609:\tlearn: 2.5275429\ttotal: 19.7s\tremaining: 36.6s\n",
      "1610:\tlearn: 2.5267745\ttotal: 19.7s\tremaining: 36.6s\n",
      "1611:\tlearn: 2.5261431\ttotal: 19.7s\tremaining: 36.6s\n",
      "1612:\tlearn: 2.5255874\ttotal: 19.8s\tremaining: 36.6s\n",
      "1613:\tlearn: 2.5249389\ttotal: 19.8s\tremaining: 36.5s\n",
      "1614:\tlearn: 2.5245878\ttotal: 19.8s\tremaining: 36.5s\n",
      "1615:\tlearn: 2.5240364\ttotal: 19.8s\tremaining: 36.5s\n",
      "1616:\tlearn: 2.5234305\ttotal: 19.8s\tremaining: 36.5s\n",
      "1617:\tlearn: 2.5232184\ttotal: 19.8s\tremaining: 36.5s\n",
      "1618:\tlearn: 2.5227965\ttotal: 19.8s\tremaining: 36.5s\n",
      "1619:\tlearn: 2.5224945\ttotal: 19.8s\tremaining: 36.5s\n",
      "1620:\tlearn: 2.5217303\ttotal: 19.9s\tremaining: 36.5s\n",
      "1621:\tlearn: 2.5214340\ttotal: 19.9s\tremaining: 36.4s\n",
      "1622:\tlearn: 2.5205007\ttotal: 19.9s\tremaining: 36.4s\n",
      "1623:\tlearn: 2.5201130\ttotal: 19.9s\tremaining: 36.4s\n",
      "1624:\tlearn: 2.5199183\ttotal: 19.9s\tremaining: 36.4s\n",
      "1625:\tlearn: 2.5195320\ttotal: 19.9s\tremaining: 36.4s\n",
      "1626:\tlearn: 2.5186434\ttotal: 19.9s\tremaining: 36.4s\n",
      "1627:\tlearn: 2.5180314\ttotal: 19.9s\tremaining: 36.4s\n",
      "1628:\tlearn: 2.5176340\ttotal: 20s\tremaining: 36.4s\n",
      "1629:\tlearn: 2.5171296\ttotal: 20s\tremaining: 36.4s\n",
      "1630:\tlearn: 2.5163466\ttotal: 20s\tremaining: 36.3s\n",
      "1631:\tlearn: 2.5158822\ttotal: 20s\tremaining: 36.3s\n",
      "1632:\tlearn: 2.5155074\ttotal: 20s\tremaining: 36.3s\n",
      "1633:\tlearn: 2.5148761\ttotal: 20s\tremaining: 36.3s\n",
      "1634:\tlearn: 2.5144072\ttotal: 20s\tremaining: 36.3s\n",
      "1635:\tlearn: 2.5138657\ttotal: 20s\tremaining: 36.3s\n",
      "1636:\tlearn: 2.5131550\ttotal: 20.1s\tremaining: 36.3s\n",
      "1637:\tlearn: 2.5123935\ttotal: 20.1s\tremaining: 36.3s\n",
      "1638:\tlearn: 2.5113895\ttotal: 20.1s\tremaining: 36.2s\n",
      "1639:\tlearn: 2.5109080\ttotal: 20.1s\tremaining: 36.2s\n",
      "1640:\tlearn: 2.5107009\ttotal: 20.1s\tremaining: 36.2s\n",
      "1641:\tlearn: 2.5098916\ttotal: 20.1s\tremaining: 36.2s\n",
      "1642:\tlearn: 2.5095267\ttotal: 20.1s\tremaining: 36.2s\n",
      "1643:\tlearn: 2.5090388\ttotal: 20.1s\tremaining: 36.2s\n",
      "1644:\tlearn: 2.5085684\ttotal: 20.1s\tremaining: 36.2s\n",
      "1645:\tlearn: 2.5078618\ttotal: 20.2s\tremaining: 36.2s\n",
      "1646:\tlearn: 2.5071686\ttotal: 20.2s\tremaining: 36.1s\n",
      "1647:\tlearn: 2.5070153\ttotal: 20.2s\tremaining: 36.1s\n",
      "1648:\tlearn: 2.5064336\ttotal: 20.2s\tremaining: 36.1s\n",
      "1649:\tlearn: 2.5059991\ttotal: 20.2s\tremaining: 36.1s\n",
      "1650:\tlearn: 2.5055538\ttotal: 20.2s\tremaining: 36.1s\n",
      "1651:\tlearn: 2.5054976\ttotal: 20.2s\tremaining: 36.1s\n",
      "1652:\tlearn: 2.5049017\ttotal: 20.2s\tremaining: 36.1s\n",
      "1653:\tlearn: 2.5044336\ttotal: 20.3s\tremaining: 36s\n",
      "1654:\tlearn: 2.5040019\ttotal: 20.3s\tremaining: 36s\n",
      "1655:\tlearn: 2.5035170\ttotal: 20.3s\tremaining: 36s\n",
      "1656:\tlearn: 2.5032236\ttotal: 20.3s\tremaining: 36s\n",
      "1657:\tlearn: 2.5026636\ttotal: 20.3s\tremaining: 36s\n",
      "1658:\tlearn: 2.5022576\ttotal: 20.3s\tremaining: 36s\n",
      "1659:\tlearn: 2.5018880\ttotal: 20.3s\tremaining: 36s\n",
      "1660:\tlearn: 2.5014461\ttotal: 20.3s\tremaining: 36s\n",
      "1661:\tlearn: 2.5013516\ttotal: 20.3s\tremaining: 35.9s\n",
      "1662:\tlearn: 2.5005696\ttotal: 20.4s\tremaining: 35.9s\n",
      "1663:\tlearn: 2.4999374\ttotal: 20.4s\tremaining: 35.9s\n",
      "1664:\tlearn: 2.4991797\ttotal: 20.4s\tremaining: 35.9s\n",
      "1665:\tlearn: 2.4987248\ttotal: 20.4s\tremaining: 35.9s\n",
      "1666:\tlearn: 2.4984168\ttotal: 20.4s\tremaining: 35.9s\n",
      "1667:\tlearn: 2.4977374\ttotal: 20.4s\tremaining: 35.9s\n",
      "1668:\tlearn: 2.4973974\ttotal: 20.4s\tremaining: 35.9s\n",
      "1669:\tlearn: 2.4966719\ttotal: 20.4s\tremaining: 35.9s\n",
      "1670:\tlearn: 2.4964238\ttotal: 20.5s\tremaining: 35.8s\n",
      "1671:\tlearn: 2.4960179\ttotal: 20.5s\tremaining: 35.8s\n",
      "1672:\tlearn: 2.4954054\ttotal: 20.5s\tremaining: 35.8s\n",
      "1673:\tlearn: 2.4944924\ttotal: 20.5s\tremaining: 35.8s\n",
      "1674:\tlearn: 2.4937556\ttotal: 20.5s\tremaining: 35.8s\n",
      "1675:\tlearn: 2.4933320\ttotal: 20.5s\tremaining: 35.8s\n",
      "1676:\tlearn: 2.4930557\ttotal: 20.5s\tremaining: 35.8s\n",
      "1677:\tlearn: 2.4920881\ttotal: 20.5s\tremaining: 35.8s\n",
      "1678:\tlearn: 2.4914706\ttotal: 20.6s\tremaining: 35.7s\n",
      "1679:\tlearn: 2.4909321\ttotal: 20.6s\tremaining: 35.7s\n",
      "1680:\tlearn: 2.4906648\ttotal: 20.6s\tremaining: 35.7s\n",
      "1681:\tlearn: 2.4899124\ttotal: 20.6s\tremaining: 35.7s\n",
      "1682:\tlearn: 2.4891744\ttotal: 20.6s\tremaining: 35.7s\n",
      "1683:\tlearn: 2.4884753\ttotal: 20.6s\tremaining: 35.7s\n",
      "1684:\tlearn: 2.4879820\ttotal: 20.6s\tremaining: 35.7s\n",
      "1685:\tlearn: 2.4870072\ttotal: 20.6s\tremaining: 35.7s\n",
      "1686:\tlearn: 2.4864630\ttotal: 20.7s\tremaining: 35.7s\n",
      "1687:\tlearn: 2.4856484\ttotal: 20.7s\tremaining: 35.6s\n",
      "1688:\tlearn: 2.4854224\ttotal: 20.7s\tremaining: 35.6s\n",
      "1689:\tlearn: 2.4848927\ttotal: 20.7s\tremaining: 35.6s\n",
      "1690:\tlearn: 2.4845057\ttotal: 20.7s\tremaining: 35.6s\n",
      "1691:\tlearn: 2.4839420\ttotal: 20.7s\tremaining: 35.6s\n",
      "1692:\tlearn: 2.4835269\ttotal: 20.7s\tremaining: 35.6s\n",
      "1693:\tlearn: 2.4830674\ttotal: 20.7s\tremaining: 35.6s\n",
      "1694:\tlearn: 2.4822887\ttotal: 20.8s\tremaining: 35.5s\n",
      "1695:\tlearn: 2.4814180\ttotal: 20.8s\tremaining: 35.5s\n",
      "1696:\tlearn: 2.4810651\ttotal: 20.8s\tremaining: 35.5s\n",
      "1697:\tlearn: 2.4802986\ttotal: 20.8s\tremaining: 35.5s\n",
      "1698:\tlearn: 2.4799130\ttotal: 20.8s\tremaining: 35.5s\n",
      "1699:\tlearn: 2.4792191\ttotal: 20.8s\tremaining: 35.5s\n",
      "1700:\tlearn: 2.4787117\ttotal: 20.8s\tremaining: 35.5s\n",
      "1701:\tlearn: 2.4781303\ttotal: 20.8s\tremaining: 35.5s\n",
      "1702:\tlearn: 2.4775878\ttotal: 20.9s\tremaining: 35.5s\n",
      "1703:\tlearn: 2.4767542\ttotal: 20.9s\tremaining: 35.4s\n",
      "1704:\tlearn: 2.4763721\ttotal: 20.9s\tremaining: 35.4s\n",
      "1705:\tlearn: 2.4758917\ttotal: 20.9s\tremaining: 35.4s\n",
      "1706:\tlearn: 2.4754897\ttotal: 20.9s\tremaining: 35.4s\n",
      "1707:\tlearn: 2.4746621\ttotal: 20.9s\tremaining: 35.4s\n",
      "1708:\tlearn: 2.4740364\ttotal: 20.9s\tremaining: 35.4s\n",
      "1709:\tlearn: 2.4733355\ttotal: 20.9s\tremaining: 35.4s\n",
      "1710:\tlearn: 2.4726363\ttotal: 21s\tremaining: 35.4s\n",
      "1711:\tlearn: 2.4721592\ttotal: 21s\tremaining: 35.4s\n",
      "1712:\tlearn: 2.4713685\ttotal: 21s\tremaining: 35.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1713:\tlearn: 2.4710480\ttotal: 21s\tremaining: 35.3s\n",
      "1714:\tlearn: 2.4706073\ttotal: 21s\tremaining: 35.3s\n",
      "1715:\tlearn: 2.4699384\ttotal: 21s\tremaining: 35.3s\n",
      "1716:\tlearn: 2.4692719\ttotal: 21s\tremaining: 35.3s\n",
      "1717:\tlearn: 2.4684733\ttotal: 21s\tremaining: 35.3s\n",
      "1718:\tlearn: 2.4681278\ttotal: 21.1s\tremaining: 35.3s\n",
      "1719:\tlearn: 2.4678188\ttotal: 21.1s\tremaining: 35.3s\n",
      "1720:\tlearn: 2.4676642\ttotal: 21.1s\tremaining: 35.2s\n",
      "1721:\tlearn: 2.4673694\ttotal: 21.1s\tremaining: 35.2s\n",
      "1722:\tlearn: 2.4670634\ttotal: 21.1s\tremaining: 35.2s\n",
      "1723:\tlearn: 2.4667662\ttotal: 21.1s\tremaining: 35.2s\n",
      "1724:\tlearn: 2.4661769\ttotal: 21.1s\tremaining: 35.2s\n",
      "1725:\tlearn: 2.4658946\ttotal: 21.1s\tremaining: 35.2s\n",
      "1726:\tlearn: 2.4655690\ttotal: 21.2s\tremaining: 35.2s\n",
      "1727:\tlearn: 2.4649693\ttotal: 21.2s\tremaining: 35.2s\n",
      "1728:\tlearn: 2.4643912\ttotal: 21.2s\tremaining: 35.1s\n",
      "1729:\tlearn: 2.4641632\ttotal: 21.2s\tremaining: 35.1s\n",
      "1730:\tlearn: 2.4635607\ttotal: 21.2s\tremaining: 35.1s\n",
      "1731:\tlearn: 2.4629153\ttotal: 21.2s\tremaining: 35.1s\n",
      "1732:\tlearn: 2.4623143\ttotal: 21.2s\tremaining: 35.1s\n",
      "1733:\tlearn: 2.4618871\ttotal: 21.2s\tremaining: 35.1s\n",
      "1734:\tlearn: 2.4612754\ttotal: 21.3s\tremaining: 35.1s\n",
      "1735:\tlearn: 2.4608997\ttotal: 21.3s\tremaining: 35.1s\n",
      "1736:\tlearn: 2.4605486\ttotal: 21.3s\tremaining: 35s\n",
      "1737:\tlearn: 2.4593351\ttotal: 21.3s\tremaining: 35s\n",
      "1738:\tlearn: 2.4588235\ttotal: 21.3s\tremaining: 35s\n",
      "1739:\tlearn: 2.4580294\ttotal: 21.3s\tremaining: 35s\n",
      "1740:\tlearn: 2.4576173\ttotal: 21.3s\tremaining: 35s\n",
      "1741:\tlearn: 2.4574714\ttotal: 21.3s\tremaining: 35s\n",
      "1742:\tlearn: 2.4566717\ttotal: 21.3s\tremaining: 35s\n",
      "1743:\tlearn: 2.4564435\ttotal: 21.4s\tremaining: 35s\n",
      "1744:\tlearn: 2.4560583\ttotal: 21.4s\tremaining: 34.9s\n",
      "1745:\tlearn: 2.4557472\ttotal: 21.4s\tremaining: 34.9s\n",
      "1746:\tlearn: 2.4550213\ttotal: 21.4s\tremaining: 34.9s\n",
      "1747:\tlearn: 2.4547561\ttotal: 21.4s\tremaining: 34.9s\n",
      "1748:\tlearn: 2.4541092\ttotal: 21.4s\tremaining: 34.9s\n",
      "1749:\tlearn: 2.4534320\ttotal: 21.4s\tremaining: 34.9s\n",
      "1750:\tlearn: 2.4529991\ttotal: 21.4s\tremaining: 34.9s\n",
      "1751:\tlearn: 2.4526707\ttotal: 21.5s\tremaining: 34.9s\n",
      "1752:\tlearn: 2.4520706\ttotal: 21.5s\tremaining: 34.9s\n",
      "1753:\tlearn: 2.4511974\ttotal: 21.5s\tremaining: 34.8s\n",
      "1754:\tlearn: 2.4506067\ttotal: 21.5s\tremaining: 34.8s\n",
      "1755:\tlearn: 2.4503191\ttotal: 21.5s\tremaining: 34.8s\n",
      "1756:\tlearn: 2.4500516\ttotal: 21.5s\tremaining: 34.8s\n",
      "1757:\tlearn: 2.4492240\ttotal: 21.5s\tremaining: 34.8s\n",
      "1758:\tlearn: 2.4485393\ttotal: 21.5s\tremaining: 34.8s\n",
      "1759:\tlearn: 2.4482398\ttotal: 21.6s\tremaining: 34.8s\n",
      "1760:\tlearn: 2.4480282\ttotal: 21.6s\tremaining: 34.7s\n",
      "1761:\tlearn: 2.4474468\ttotal: 21.6s\tremaining: 34.7s\n",
      "1762:\tlearn: 2.4469627\ttotal: 21.6s\tremaining: 34.7s\n",
      "1763:\tlearn: 2.4466468\ttotal: 21.6s\tremaining: 34.7s\n",
      "1764:\tlearn: 2.4458957\ttotal: 21.6s\tremaining: 34.7s\n",
      "1765:\tlearn: 2.4455828\ttotal: 21.6s\tremaining: 34.7s\n",
      "1766:\tlearn: 2.4448678\ttotal: 21.6s\tremaining: 34.7s\n",
      "1767:\tlearn: 2.4445597\ttotal: 21.7s\tremaining: 34.7s\n",
      "1768:\tlearn: 2.4441890\ttotal: 21.7s\tremaining: 34.6s\n",
      "1769:\tlearn: 2.4437017\ttotal: 21.7s\tremaining: 34.6s\n",
      "1770:\tlearn: 2.4433751\ttotal: 21.7s\tremaining: 34.6s\n",
      "1771:\tlearn: 2.4428525\ttotal: 21.7s\tremaining: 34.6s\n",
      "1772:\tlearn: 2.4424635\ttotal: 21.7s\tremaining: 34.6s\n",
      "1773:\tlearn: 2.4421024\ttotal: 21.7s\tremaining: 34.6s\n",
      "1774:\tlearn: 2.4418425\ttotal: 21.7s\tremaining: 34.6s\n",
      "1775:\tlearn: 2.4412830\ttotal: 21.8s\tremaining: 34.6s\n",
      "1776:\tlearn: 2.4403888\ttotal: 21.8s\tremaining: 34.6s\n",
      "1777:\tlearn: 2.4397573\ttotal: 21.8s\tremaining: 34.5s\n",
      "1778:\tlearn: 2.4390389\ttotal: 21.8s\tremaining: 34.5s\n",
      "1779:\tlearn: 2.4383756\ttotal: 21.8s\tremaining: 34.5s\n",
      "1780:\tlearn: 2.4376215\ttotal: 21.8s\tremaining: 34.5s\n",
      "1781:\tlearn: 2.4371241\ttotal: 21.8s\tremaining: 34.5s\n",
      "1782:\tlearn: 2.4368898\ttotal: 21.8s\tremaining: 34.5s\n",
      "1783:\tlearn: 2.4365645\ttotal: 21.9s\tremaining: 34.5s\n",
      "1784:\tlearn: 2.4359944\ttotal: 21.9s\tremaining: 34.5s\n",
      "1785:\tlearn: 2.4355936\ttotal: 21.9s\tremaining: 34.4s\n",
      "1786:\tlearn: 2.4351940\ttotal: 21.9s\tremaining: 34.4s\n",
      "1787:\tlearn: 2.4348491\ttotal: 21.9s\tremaining: 34.4s\n",
      "1788:\tlearn: 2.4341602\ttotal: 21.9s\tremaining: 34.4s\n",
      "1789:\tlearn: 2.4336987\ttotal: 21.9s\tremaining: 34.4s\n",
      "1790:\tlearn: 2.4334334\ttotal: 21.9s\tremaining: 34.4s\n",
      "1791:\tlearn: 2.4331873\ttotal: 21.9s\tremaining: 34.4s\n",
      "1792:\tlearn: 2.4324074\ttotal: 22s\tremaining: 34.4s\n",
      "1793:\tlearn: 2.4317617\ttotal: 22s\tremaining: 34.3s\n",
      "1794:\tlearn: 2.4313628\ttotal: 22s\tremaining: 34.3s\n",
      "1795:\tlearn: 2.4308136\ttotal: 22s\tremaining: 34.3s\n",
      "1796:\tlearn: 2.4303731\ttotal: 22s\tremaining: 34.3s\n",
      "1797:\tlearn: 2.4302171\ttotal: 22s\tremaining: 34.3s\n",
      "1798:\tlearn: 2.4298574\ttotal: 22s\tremaining: 34.3s\n",
      "1799:\tlearn: 2.4292451\ttotal: 22s\tremaining: 34.3s\n",
      "1800:\tlearn: 2.4287071\ttotal: 22.1s\tremaining: 34.3s\n",
      "1801:\tlearn: 2.4279817\ttotal: 22.1s\tremaining: 34.2s\n",
      "1802:\tlearn: 2.4275016\ttotal: 22.1s\tremaining: 34.2s\n",
      "1803:\tlearn: 2.4269487\ttotal: 22.1s\tremaining: 34.2s\n",
      "1804:\tlearn: 2.4267327\ttotal: 22.1s\tremaining: 34.2s\n",
      "1805:\tlearn: 2.4259807\ttotal: 22.1s\tremaining: 34.2s\n",
      "1806:\tlearn: 2.4255582\ttotal: 22.1s\tremaining: 34.2s\n",
      "1807:\tlearn: 2.4253248\ttotal: 22.1s\tremaining: 34.2s\n",
      "1808:\tlearn: 2.4242361\ttotal: 22.2s\tremaining: 34.2s\n",
      "1809:\tlearn: 2.4239037\ttotal: 22.2s\tremaining: 34.1s\n",
      "1810:\tlearn: 2.4232830\ttotal: 22.2s\tremaining: 34.1s\n",
      "1811:\tlearn: 2.4226350\ttotal: 22.2s\tremaining: 34.1s\n",
      "1812:\tlearn: 2.4223671\ttotal: 22.2s\tremaining: 34.1s\n",
      "1813:\tlearn: 2.4220595\ttotal: 22.2s\tremaining: 34.1s\n",
      "1814:\tlearn: 2.4216753\ttotal: 22.2s\tremaining: 34.1s\n",
      "1815:\tlearn: 2.4213924\ttotal: 22.2s\tremaining: 34.1s\n",
      "1816:\tlearn: 2.4208467\ttotal: 22.3s\tremaining: 34.1s\n",
      "1817:\tlearn: 2.4205035\ttotal: 22.3s\tremaining: 34s\n",
      "1818:\tlearn: 2.4197364\ttotal: 22.3s\tremaining: 34s\n",
      "1819:\tlearn: 2.4193252\ttotal: 22.3s\tremaining: 34s\n",
      "1820:\tlearn: 2.4186927\ttotal: 22.3s\tremaining: 34s\n",
      "1821:\tlearn: 2.4180726\ttotal: 22.3s\tremaining: 34s\n",
      "1822:\tlearn: 2.4175209\ttotal: 22.3s\tremaining: 34s\n",
      "1823:\tlearn: 2.4168757\ttotal: 22.3s\tremaining: 34s\n",
      "1824:\tlearn: 2.4166437\ttotal: 22.4s\tremaining: 34s\n",
      "1825:\tlearn: 2.4162353\ttotal: 22.4s\tremaining: 34s\n",
      "1826:\tlearn: 2.4157249\ttotal: 22.4s\tremaining: 33.9s\n",
      "1827:\tlearn: 2.4152653\ttotal: 22.4s\tremaining: 33.9s\n",
      "1828:\tlearn: 2.4149525\ttotal: 22.4s\tremaining: 33.9s\n",
      "1829:\tlearn: 2.4145015\ttotal: 22.4s\tremaining: 33.9s\n",
      "1830:\tlearn: 2.4141689\ttotal: 22.4s\tremaining: 33.9s\n",
      "1831:\tlearn: 2.4139125\ttotal: 22.4s\tremaining: 33.9s\n",
      "1832:\tlearn: 2.4130382\ttotal: 22.4s\tremaining: 33.9s\n",
      "1833:\tlearn: 2.4126780\ttotal: 22.5s\tremaining: 33.9s\n",
      "1834:\tlearn: 2.4124711\ttotal: 22.5s\tremaining: 33.8s\n",
      "1835:\tlearn: 2.4119434\ttotal: 22.5s\tremaining: 33.8s\n",
      "1836:\tlearn: 2.4114703\ttotal: 22.5s\tremaining: 33.8s\n",
      "1837:\tlearn: 2.4108302\ttotal: 22.5s\tremaining: 33.8s\n",
      "1838:\tlearn: 2.4105427\ttotal: 22.5s\tremaining: 33.8s\n",
      "1839:\tlearn: 2.4101536\ttotal: 22.5s\tremaining: 33.8s\n",
      "1840:\tlearn: 2.4099125\ttotal: 22.5s\tremaining: 33.8s\n",
      "1841:\tlearn: 2.4092045\ttotal: 22.6s\tremaining: 33.8s\n",
      "1842:\tlearn: 2.4088509\ttotal: 22.6s\tremaining: 33.7s\n",
      "1843:\tlearn: 2.4085269\ttotal: 22.6s\tremaining: 33.7s\n",
      "1844:\tlearn: 2.4077390\ttotal: 22.6s\tremaining: 33.7s\n",
      "1845:\tlearn: 2.4075515\ttotal: 22.6s\tremaining: 33.7s\n",
      "1846:\tlearn: 2.4068465\ttotal: 22.6s\tremaining: 33.7s\n",
      "1847:\tlearn: 2.4061416\ttotal: 22.6s\tremaining: 33.7s\n",
      "1848:\tlearn: 2.4057457\ttotal: 22.6s\tremaining: 33.7s\n",
      "1849:\tlearn: 2.4052282\ttotal: 22.7s\tremaining: 33.7s\n",
      "1850:\tlearn: 2.4048359\ttotal: 22.7s\tremaining: 33.6s\n",
      "1851:\tlearn: 2.4043555\ttotal: 22.7s\tremaining: 33.6s\n",
      "1852:\tlearn: 2.4041799\ttotal: 22.7s\tremaining: 33.6s\n",
      "1853:\tlearn: 2.4039424\ttotal: 22.7s\tremaining: 33.6s\n",
      "1854:\tlearn: 2.4036156\ttotal: 22.7s\tremaining: 33.6s\n",
      "1855:\tlearn: 2.4031703\ttotal: 22.7s\tremaining: 33.6s\n",
      "1856:\tlearn: 2.4025082\ttotal: 22.7s\tremaining: 33.6s\n",
      "1857:\tlearn: 2.4023250\ttotal: 22.8s\tremaining: 33.6s\n",
      "1858:\tlearn: 2.4017985\ttotal: 22.8s\tremaining: 33.5s\n",
      "1859:\tlearn: 2.4011676\ttotal: 22.8s\tremaining: 33.5s\n",
      "1860:\tlearn: 2.4007029\ttotal: 22.8s\tremaining: 33.5s\n",
      "1861:\tlearn: 2.4004470\ttotal: 22.8s\tremaining: 33.5s\n",
      "1862:\tlearn: 2.3999252\ttotal: 22.8s\tremaining: 33.5s\n",
      "1863:\tlearn: 2.3993000\ttotal: 22.8s\tremaining: 33.5s\n",
      "1864:\tlearn: 2.3987961\ttotal: 22.8s\tremaining: 33.5s\n",
      "1865:\tlearn: 2.3981372\ttotal: 22.8s\tremaining: 33.5s\n",
      "1866:\tlearn: 2.3975228\ttotal: 22.9s\tremaining: 33.4s\n",
      "1867:\tlearn: 2.3967876\ttotal: 22.9s\tremaining: 33.4s\n",
      "1868:\tlearn: 2.3966828\ttotal: 22.9s\tremaining: 33.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1869:\tlearn: 2.3963618\ttotal: 22.9s\tremaining: 33.4s\n",
      "1870:\tlearn: 2.3959567\ttotal: 22.9s\tremaining: 33.4s\n",
      "1871:\tlearn: 2.3956678\ttotal: 22.9s\tremaining: 33.4s\n",
      "1872:\tlearn: 2.3955441\ttotal: 22.9s\tremaining: 33.4s\n",
      "1873:\tlearn: 2.3949902\ttotal: 22.9s\tremaining: 33.4s\n",
      "1874:\tlearn: 2.3947323\ttotal: 23s\tremaining: 33.3s\n",
      "1875:\tlearn: 2.3939305\ttotal: 23s\tremaining: 33.3s\n",
      "1876:\tlearn: 2.3936749\ttotal: 23s\tremaining: 33.3s\n",
      "1877:\tlearn: 2.3932044\ttotal: 23s\tremaining: 33.3s\n",
      "1878:\tlearn: 2.3921446\ttotal: 23s\tremaining: 33.3s\n",
      "1879:\tlearn: 2.3916856\ttotal: 23s\tremaining: 33.3s\n",
      "1880:\tlearn: 2.3911445\ttotal: 23s\tremaining: 33.3s\n",
      "1881:\tlearn: 2.3908138\ttotal: 23s\tremaining: 33.3s\n",
      "1882:\tlearn: 2.3905081\ttotal: 23.1s\tremaining: 33.2s\n",
      "1883:\tlearn: 2.3902051\ttotal: 23.1s\tremaining: 33.2s\n",
      "1884:\tlearn: 2.3895096\ttotal: 23.1s\tremaining: 33.2s\n",
      "1885:\tlearn: 2.3887062\ttotal: 23.1s\tremaining: 33.2s\n",
      "1886:\tlearn: 2.3884585\ttotal: 23.1s\tremaining: 33.2s\n",
      "1887:\tlearn: 2.3877158\ttotal: 23.1s\tremaining: 33.2s\n",
      "1888:\tlearn: 2.3874408\ttotal: 23.1s\tremaining: 33.2s\n",
      "1889:\tlearn: 2.3869039\ttotal: 23.1s\tremaining: 33.2s\n",
      "1890:\tlearn: 2.3864276\ttotal: 23.2s\tremaining: 33.2s\n",
      "1891:\tlearn: 2.3859733\ttotal: 23.2s\tremaining: 33.1s\n",
      "1892:\tlearn: 2.3857948\ttotal: 23.2s\tremaining: 33.1s\n",
      "1893:\tlearn: 2.3853826\ttotal: 23.2s\tremaining: 33.1s\n",
      "1894:\tlearn: 2.3847826\ttotal: 23.2s\tremaining: 33.1s\n",
      "1895:\tlearn: 2.3842293\ttotal: 23.2s\tremaining: 33.1s\n",
      "1896:\tlearn: 2.3838786\ttotal: 23.2s\tremaining: 33.1s\n",
      "1897:\tlearn: 2.3836131\ttotal: 23.2s\tremaining: 33.1s\n",
      "1898:\tlearn: 2.3833988\ttotal: 23.3s\tremaining: 33s\n",
      "1899:\tlearn: 2.3829453\ttotal: 23.3s\tremaining: 33s\n",
      "1900:\tlearn: 2.3828785\ttotal: 23.3s\tremaining: 33s\n",
      "1901:\tlearn: 2.3823972\ttotal: 23.3s\tremaining: 33s\n",
      "1902:\tlearn: 2.3820725\ttotal: 23.3s\tremaining: 33s\n",
      "1903:\tlearn: 2.3815545\ttotal: 23.3s\tremaining: 33s\n",
      "1904:\tlearn: 2.3813642\ttotal: 23.3s\tremaining: 33s\n",
      "1905:\tlearn: 2.3806076\ttotal: 23.3s\tremaining: 33s\n",
      "1906:\tlearn: 2.3801915\ttotal: 23.3s\tremaining: 32.9s\n",
      "1907:\tlearn: 2.3793649\ttotal: 23.4s\tremaining: 32.9s\n",
      "1908:\tlearn: 2.3791711\ttotal: 23.4s\tremaining: 32.9s\n",
      "1909:\tlearn: 2.3789511\ttotal: 23.4s\tremaining: 32.9s\n",
      "1910:\tlearn: 2.3781261\ttotal: 23.4s\tremaining: 32.9s\n",
      "1911:\tlearn: 2.3778329\ttotal: 23.4s\tremaining: 32.9s\n",
      "1912:\tlearn: 2.3771549\ttotal: 23.4s\tremaining: 32.9s\n",
      "1913:\tlearn: 2.3770935\ttotal: 23.4s\tremaining: 32.9s\n",
      "1914:\tlearn: 2.3766784\ttotal: 23.4s\tremaining: 32.8s\n",
      "1915:\tlearn: 2.3761445\ttotal: 23.5s\tremaining: 32.8s\n",
      "1916:\tlearn: 2.3758296\ttotal: 23.5s\tremaining: 32.8s\n",
      "1917:\tlearn: 2.3755584\ttotal: 23.5s\tremaining: 32.8s\n",
      "1918:\tlearn: 2.3749225\ttotal: 23.5s\tremaining: 32.8s\n",
      "1919:\tlearn: 2.3741363\ttotal: 23.5s\tremaining: 32.8s\n",
      "1920:\tlearn: 2.3738287\ttotal: 23.5s\tremaining: 32.8s\n",
      "1921:\tlearn: 2.3732645\ttotal: 23.5s\tremaining: 32.8s\n",
      "1922:\tlearn: 2.3728161\ttotal: 23.5s\tremaining: 32.7s\n",
      "1923:\tlearn: 2.3722061\ttotal: 23.6s\tremaining: 32.7s\n",
      "1924:\tlearn: 2.3718509\ttotal: 23.6s\tremaining: 32.7s\n",
      "1925:\tlearn: 2.3714694\ttotal: 23.6s\tremaining: 32.7s\n",
      "1926:\tlearn: 2.3709720\ttotal: 23.6s\tremaining: 32.7s\n",
      "1927:\tlearn: 2.3706907\ttotal: 23.6s\tremaining: 32.7s\n",
      "1928:\tlearn: 2.3703775\ttotal: 23.6s\tremaining: 32.7s\n",
      "1929:\tlearn: 2.3698610\ttotal: 23.6s\tremaining: 32.7s\n",
      "1930:\tlearn: 2.3692090\ttotal: 23.6s\tremaining: 32.6s\n",
      "1931:\tlearn: 2.3689513\ttotal: 23.6s\tremaining: 32.6s\n",
      "1932:\tlearn: 2.3687191\ttotal: 23.7s\tremaining: 32.6s\n",
      "1933:\tlearn: 2.3681233\ttotal: 23.7s\tremaining: 32.6s\n",
      "1934:\tlearn: 2.3675741\ttotal: 23.7s\tremaining: 32.6s\n",
      "1935:\tlearn: 2.3665853\ttotal: 23.7s\tremaining: 32.6s\n",
      "1936:\tlearn: 2.3659707\ttotal: 23.7s\tremaining: 32.6s\n",
      "1937:\tlearn: 2.3655854\ttotal: 23.7s\tremaining: 32.6s\n",
      "1938:\tlearn: 2.3650541\ttotal: 23.7s\tremaining: 32.5s\n",
      "1939:\tlearn: 2.3644291\ttotal: 23.7s\tremaining: 32.5s\n",
      "1940:\tlearn: 2.3638747\ttotal: 23.8s\tremaining: 32.5s\n",
      "1941:\tlearn: 2.3632606\ttotal: 23.8s\tremaining: 32.5s\n",
      "1942:\tlearn: 2.3629688\ttotal: 23.8s\tremaining: 32.5s\n",
      "1943:\tlearn: 2.3625716\ttotal: 23.8s\tremaining: 32.5s\n",
      "1944:\tlearn: 2.3621190\ttotal: 23.8s\tremaining: 32.5s\n",
      "1945:\tlearn: 2.3617274\ttotal: 23.8s\tremaining: 32.5s\n",
      "1946:\tlearn: 2.3611486\ttotal: 23.8s\tremaining: 32.4s\n",
      "1947:\tlearn: 2.3604775\ttotal: 23.8s\tremaining: 32.4s\n",
      "1948:\tlearn: 2.3598437\ttotal: 23.9s\tremaining: 32.4s\n",
      "1949:\tlearn: 2.3593225\ttotal: 23.9s\tremaining: 32.4s\n",
      "1950:\tlearn: 2.3585811\ttotal: 23.9s\tremaining: 32.4s\n",
      "1951:\tlearn: 2.3577571\ttotal: 23.9s\tremaining: 32.4s\n",
      "1952:\tlearn: 2.3573938\ttotal: 23.9s\tremaining: 32.4s\n",
      "1953:\tlearn: 2.3568681\ttotal: 23.9s\tremaining: 32.4s\n",
      "1954:\tlearn: 2.3564287\ttotal: 23.9s\tremaining: 32.3s\n",
      "1955:\tlearn: 2.3562487\ttotal: 23.9s\tremaining: 32.3s\n",
      "1956:\tlearn: 2.3559626\ttotal: 23.9s\tremaining: 32.3s\n",
      "1957:\tlearn: 2.3554712\ttotal: 24s\tremaining: 32.3s\n",
      "1958:\tlearn: 2.3551714\ttotal: 24s\tremaining: 32.3s\n",
      "1959:\tlearn: 2.3548390\ttotal: 24s\tremaining: 32.3s\n",
      "1960:\tlearn: 2.3544095\ttotal: 24s\tremaining: 32.3s\n",
      "1961:\tlearn: 2.3541615\ttotal: 24s\tremaining: 32.3s\n",
      "1962:\tlearn: 2.3534944\ttotal: 24s\tremaining: 32.2s\n",
      "1963:\tlearn: 2.3532052\ttotal: 24s\tremaining: 32.2s\n",
      "1964:\tlearn: 2.3530205\ttotal: 24s\tremaining: 32.2s\n",
      "1965:\tlearn: 2.3526353\ttotal: 24.1s\tremaining: 32.2s\n",
      "1966:\tlearn: 2.3520408\ttotal: 24.1s\tremaining: 32.2s\n",
      "1967:\tlearn: 2.3516791\ttotal: 24.1s\tremaining: 32.2s\n",
      "1968:\tlearn: 2.3510700\ttotal: 24.1s\tremaining: 32.2s\n",
      "1969:\tlearn: 2.3507344\ttotal: 24.1s\tremaining: 32.2s\n",
      "1970:\tlearn: 2.3502411\ttotal: 24.1s\tremaining: 32.1s\n",
      "1971:\tlearn: 2.3497474\ttotal: 24.1s\tremaining: 32.1s\n",
      "1972:\tlearn: 2.3494742\ttotal: 24.1s\tremaining: 32.1s\n",
      "1973:\tlearn: 2.3488851\ttotal: 24.2s\tremaining: 32.1s\n",
      "1974:\tlearn: 2.3484773\ttotal: 24.2s\tremaining: 32.1s\n",
      "1975:\tlearn: 2.3480005\ttotal: 24.2s\tremaining: 32.1s\n",
      "1976:\tlearn: 2.3476780\ttotal: 24.2s\tremaining: 32.1s\n",
      "1977:\tlearn: 2.3473412\ttotal: 24.2s\tremaining: 32.1s\n",
      "1978:\tlearn: 2.3469778\ttotal: 24.2s\tremaining: 32s\n",
      "1979:\tlearn: 2.3463275\ttotal: 24.2s\tremaining: 32s\n",
      "1980:\tlearn: 2.3460249\ttotal: 24.2s\tremaining: 32s\n",
      "1981:\tlearn: 2.3455502\ttotal: 24.3s\tremaining: 32s\n",
      "1982:\tlearn: 2.3450815\ttotal: 24.3s\tremaining: 32s\n",
      "1983:\tlearn: 2.3450129\ttotal: 24.3s\tremaining: 32s\n",
      "1984:\tlearn: 2.3446876\ttotal: 24.3s\tremaining: 32s\n",
      "1985:\tlearn: 2.3444317\ttotal: 24.3s\tremaining: 32s\n",
      "1986:\tlearn: 2.3442271\ttotal: 24.3s\tremaining: 31.9s\n",
      "1987:\tlearn: 2.3437570\ttotal: 24.3s\tremaining: 31.9s\n",
      "1988:\tlearn: 2.3432523\ttotal: 24.3s\tremaining: 31.9s\n",
      "1989:\tlearn: 2.3428274\ttotal: 24.3s\tremaining: 31.9s\n",
      "1990:\tlearn: 2.3423486\ttotal: 24.4s\tremaining: 31.9s\n",
      "1991:\tlearn: 2.3418026\ttotal: 24.4s\tremaining: 31.9s\n",
      "1992:\tlearn: 2.3412353\ttotal: 24.4s\tremaining: 31.9s\n",
      "1993:\tlearn: 2.3404019\ttotal: 24.4s\tremaining: 31.9s\n",
      "1994:\tlearn: 2.3401803\ttotal: 24.4s\tremaining: 31.8s\n",
      "1995:\tlearn: 2.3396941\ttotal: 24.4s\tremaining: 31.8s\n",
      "1996:\tlearn: 2.3393107\ttotal: 24.4s\tremaining: 31.8s\n",
      "1997:\tlearn: 2.3390453\ttotal: 24.4s\tremaining: 31.8s\n",
      "1998:\tlearn: 2.3384311\ttotal: 24.5s\tremaining: 31.8s\n",
      "1999:\tlearn: 2.3379663\ttotal: 24.5s\tremaining: 31.8s\n",
      "2000:\tlearn: 2.3374417\ttotal: 24.5s\tremaining: 31.8s\n",
      "2001:\tlearn: 2.3368351\ttotal: 24.5s\tremaining: 31.8s\n",
      "2002:\tlearn: 2.3365882\ttotal: 24.5s\tremaining: 31.7s\n",
      "2003:\tlearn: 2.3362545\ttotal: 24.5s\tremaining: 31.7s\n",
      "2004:\tlearn: 2.3358870\ttotal: 24.5s\tremaining: 31.7s\n",
      "2005:\tlearn: 2.3356577\ttotal: 24.5s\tremaining: 31.7s\n",
      "2006:\tlearn: 2.3350964\ttotal: 24.5s\tremaining: 31.7s\n",
      "2007:\tlearn: 2.3343403\ttotal: 24.6s\tremaining: 31.7s\n",
      "2008:\tlearn: 2.3337692\ttotal: 24.6s\tremaining: 31.7s\n",
      "2009:\tlearn: 2.3333650\ttotal: 24.6s\tremaining: 31.7s\n",
      "2010:\tlearn: 2.3327047\ttotal: 24.6s\tremaining: 31.6s\n",
      "2011:\tlearn: 2.3321752\ttotal: 24.6s\tremaining: 31.6s\n",
      "2012:\tlearn: 2.3316635\ttotal: 24.6s\tremaining: 31.6s\n",
      "2013:\tlearn: 2.3313045\ttotal: 24.6s\tremaining: 31.6s\n",
      "2014:\tlearn: 2.3309388\ttotal: 24.6s\tremaining: 31.6s\n",
      "2015:\tlearn: 2.3303915\ttotal: 24.7s\tremaining: 31.6s\n",
      "2016:\tlearn: 2.3298094\ttotal: 24.7s\tremaining: 31.6s\n",
      "2017:\tlearn: 2.3292220\ttotal: 24.7s\tremaining: 31.6s\n",
      "2018:\tlearn: 2.3282340\ttotal: 24.7s\tremaining: 31.5s\n",
      "2019:\tlearn: 2.3278125\ttotal: 24.7s\tremaining: 31.5s\n",
      "2020:\tlearn: 2.3272061\ttotal: 24.7s\tremaining: 31.5s\n",
      "2021:\tlearn: 2.3266849\ttotal: 24.7s\tremaining: 31.5s\n",
      "2022:\tlearn: 2.3263298\ttotal: 24.7s\tremaining: 31.5s\n",
      "2023:\tlearn: 2.3257352\ttotal: 24.8s\tremaining: 31.5s\n",
      "2024:\tlearn: 2.3253934\ttotal: 24.8s\tremaining: 31.5s\n",
      "2025:\tlearn: 2.3251483\ttotal: 24.8s\tremaining: 31.5s\n",
      "2026:\tlearn: 2.3244684\ttotal: 24.8s\tremaining: 31.5s\n",
      "2027:\tlearn: 2.3239720\ttotal: 24.8s\tremaining: 31.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2028:\tlearn: 2.3237947\ttotal: 24.8s\tremaining: 31.4s\n",
      "2029:\tlearn: 2.3228956\ttotal: 24.8s\tremaining: 31.4s\n",
      "2030:\tlearn: 2.3227417\ttotal: 24.8s\tremaining: 31.4s\n",
      "2031:\tlearn: 2.3223832\ttotal: 24.9s\tremaining: 31.4s\n",
      "2032:\tlearn: 2.3216033\ttotal: 24.9s\tremaining: 31.4s\n",
      "2033:\tlearn: 2.3208464\ttotal: 24.9s\tremaining: 31.4s\n",
      "2034:\tlearn: 2.3201525\ttotal: 24.9s\tremaining: 31.4s\n",
      "2035:\tlearn: 2.3195972\ttotal: 24.9s\tremaining: 31.3s\n",
      "2036:\tlearn: 2.3192517\ttotal: 24.9s\tremaining: 31.3s\n",
      "2037:\tlearn: 2.3188273\ttotal: 24.9s\tremaining: 31.3s\n",
      "2038:\tlearn: 2.3183773\ttotal: 24.9s\tremaining: 31.3s\n",
      "2039:\tlearn: 2.3177802\ttotal: 25s\tremaining: 31.3s\n",
      "2040:\tlearn: 2.3175842\ttotal: 25s\tremaining: 31.3s\n",
      "2041:\tlearn: 2.3169733\ttotal: 25s\tremaining: 31.3s\n",
      "2042:\tlearn: 2.3164212\ttotal: 25s\tremaining: 31.3s\n",
      "2043:\tlearn: 2.3160518\ttotal: 25s\tremaining: 31.2s\n",
      "2044:\tlearn: 2.3156944\ttotal: 25s\tremaining: 31.2s\n",
      "2045:\tlearn: 2.3154595\ttotal: 25s\tremaining: 31.2s\n",
      "2046:\tlearn: 2.3150390\ttotal: 25s\tremaining: 31.2s\n",
      "2047:\tlearn: 2.3146956\ttotal: 25.1s\tremaining: 31.2s\n",
      "2048:\tlearn: 2.3143260\ttotal: 25.1s\tremaining: 31.2s\n",
      "2049:\tlearn: 2.3141973\ttotal: 25.1s\tremaining: 31.2s\n",
      "2050:\tlearn: 2.3137254\ttotal: 25.1s\tremaining: 31.2s\n",
      "2051:\tlearn: 2.3134720\ttotal: 25.1s\tremaining: 31.1s\n",
      "2052:\tlearn: 2.3130280\ttotal: 25.1s\tremaining: 31.1s\n",
      "2053:\tlearn: 2.3125363\ttotal: 25.1s\tremaining: 31.1s\n",
      "2054:\tlearn: 2.3123181\ttotal: 25.1s\tremaining: 31.1s\n",
      "2055:\tlearn: 2.3120701\ttotal: 25.2s\tremaining: 31.1s\n",
      "2056:\tlearn: 2.3114595\ttotal: 25.2s\tremaining: 31.1s\n",
      "2057:\tlearn: 2.3109417\ttotal: 25.2s\tremaining: 31.1s\n",
      "2058:\tlearn: 2.3103815\ttotal: 25.2s\tremaining: 31.1s\n",
      "2059:\tlearn: 2.3098077\ttotal: 25.2s\tremaining: 31s\n",
      "2060:\tlearn: 2.3090217\ttotal: 25.2s\tremaining: 31s\n",
      "2061:\tlearn: 2.3088155\ttotal: 25.2s\tremaining: 31s\n",
      "2062:\tlearn: 2.3083122\ttotal: 25.2s\tremaining: 31s\n",
      "2063:\tlearn: 2.3077250\ttotal: 25.2s\tremaining: 31s\n",
      "2064:\tlearn: 2.3072242\ttotal: 25.3s\tremaining: 31s\n",
      "2065:\tlearn: 2.3068749\ttotal: 25.3s\tremaining: 31s\n",
      "2066:\tlearn: 2.3065947\ttotal: 25.3s\tremaining: 31s\n",
      "2067:\tlearn: 2.3063149\ttotal: 25.3s\tremaining: 31s\n",
      "2068:\tlearn: 2.3059944\ttotal: 25.3s\tremaining: 30.9s\n",
      "2069:\tlearn: 2.3056052\ttotal: 25.3s\tremaining: 30.9s\n",
      "2070:\tlearn: 2.3050619\ttotal: 25.3s\tremaining: 30.9s\n",
      "2071:\tlearn: 2.3047632\ttotal: 25.3s\tremaining: 30.9s\n",
      "2072:\tlearn: 2.3044804\ttotal: 25.4s\tremaining: 30.9s\n",
      "2073:\tlearn: 2.3036582\ttotal: 25.4s\tremaining: 30.9s\n",
      "2074:\tlearn: 2.3034260\ttotal: 25.4s\tremaining: 30.9s\n",
      "2075:\tlearn: 2.3030825\ttotal: 25.4s\tremaining: 30.9s\n",
      "2076:\tlearn: 2.3024279\ttotal: 25.4s\tremaining: 30.8s\n",
      "2077:\tlearn: 2.3018631\ttotal: 25.4s\tremaining: 30.8s\n",
      "2078:\tlearn: 2.3013650\ttotal: 25.4s\tremaining: 30.8s\n",
      "2079:\tlearn: 2.3009938\ttotal: 25.4s\tremaining: 30.8s\n",
      "2080:\tlearn: 2.3006267\ttotal: 25.5s\tremaining: 30.8s\n",
      "2081:\tlearn: 2.2999638\ttotal: 25.5s\tremaining: 30.8s\n",
      "2082:\tlearn: 2.2993684\ttotal: 25.5s\tremaining: 30.8s\n",
      "2083:\tlearn: 2.2991136\ttotal: 25.5s\tremaining: 30.8s\n",
      "2084:\tlearn: 2.2986481\ttotal: 25.5s\tremaining: 30.7s\n",
      "2085:\tlearn: 2.2983711\ttotal: 25.5s\tremaining: 30.7s\n",
      "2086:\tlearn: 2.2980770\ttotal: 25.5s\tremaining: 30.7s\n",
      "2087:\tlearn: 2.2977024\ttotal: 25.5s\tremaining: 30.7s\n",
      "2088:\tlearn: 2.2972201\ttotal: 25.6s\tremaining: 30.7s\n",
      "2089:\tlearn: 2.2968900\ttotal: 25.6s\tremaining: 30.7s\n",
      "2090:\tlearn: 2.2965102\ttotal: 25.6s\tremaining: 30.7s\n",
      "2091:\tlearn: 2.2962399\ttotal: 25.6s\tremaining: 30.7s\n",
      "2092:\tlearn: 2.2958452\ttotal: 25.6s\tremaining: 30.6s\n",
      "2093:\tlearn: 2.2951073\ttotal: 25.6s\tremaining: 30.6s\n",
      "2094:\tlearn: 2.2947899\ttotal: 25.6s\tremaining: 30.6s\n",
      "2095:\tlearn: 2.2944413\ttotal: 25.6s\tremaining: 30.6s\n",
      "2096:\tlearn: 2.2939498\ttotal: 25.7s\tremaining: 30.6s\n",
      "2097:\tlearn: 2.2934107\ttotal: 25.7s\tremaining: 30.6s\n",
      "2098:\tlearn: 2.2931447\ttotal: 25.7s\tremaining: 30.6s\n",
      "2099:\tlearn: 2.2925943\ttotal: 25.7s\tremaining: 30.6s\n",
      "2100:\tlearn: 2.2917401\ttotal: 25.7s\tremaining: 30.6s\n",
      "2101:\tlearn: 2.2914484\ttotal: 25.7s\tremaining: 30.5s\n",
      "2102:\tlearn: 2.2909837\ttotal: 25.7s\tremaining: 30.5s\n",
      "2103:\tlearn: 2.2903315\ttotal: 25.7s\tremaining: 30.5s\n",
      "2104:\tlearn: 2.2901181\ttotal: 25.8s\tremaining: 30.5s\n",
      "2105:\tlearn: 2.2895208\ttotal: 25.8s\tremaining: 30.5s\n",
      "2106:\tlearn: 2.2890986\ttotal: 25.8s\tremaining: 30.5s\n",
      "2107:\tlearn: 2.2886773\ttotal: 25.8s\tremaining: 30.5s\n",
      "2108:\tlearn: 2.2883291\ttotal: 25.8s\tremaining: 30.5s\n",
      "2109:\tlearn: 2.2880913\ttotal: 25.8s\tremaining: 30.4s\n",
      "2110:\tlearn: 2.2876550\ttotal: 25.8s\tremaining: 30.4s\n",
      "2111:\tlearn: 2.2872847\ttotal: 25.8s\tremaining: 30.4s\n",
      "2112:\tlearn: 2.2867572\ttotal: 25.9s\tremaining: 30.4s\n",
      "2113:\tlearn: 2.2865492\ttotal: 25.9s\tremaining: 30.4s\n",
      "2114:\tlearn: 2.2860106\ttotal: 25.9s\tremaining: 30.4s\n",
      "2115:\tlearn: 2.2856206\ttotal: 25.9s\tremaining: 30.4s\n",
      "2116:\tlearn: 2.2850446\ttotal: 25.9s\tremaining: 30.4s\n",
      "2117:\tlearn: 2.2847108\ttotal: 25.9s\tremaining: 30.3s\n",
      "2118:\tlearn: 2.2843680\ttotal: 25.9s\tremaining: 30.3s\n",
      "2119:\tlearn: 2.2842209\ttotal: 25.9s\tremaining: 30.3s\n",
      "2120:\tlearn: 2.2836410\ttotal: 26s\tremaining: 30.3s\n",
      "2121:\tlearn: 2.2831298\ttotal: 26s\tremaining: 30.3s\n",
      "2122:\tlearn: 2.2828223\ttotal: 26s\tremaining: 30.3s\n",
      "2123:\tlearn: 2.2826091\ttotal: 26s\tremaining: 30.3s\n",
      "2124:\tlearn: 2.2822501\ttotal: 26s\tremaining: 30.3s\n",
      "2125:\tlearn: 2.2819480\ttotal: 26s\tremaining: 30.2s\n",
      "2126:\tlearn: 2.2814769\ttotal: 26s\tremaining: 30.2s\n",
      "2127:\tlearn: 2.2809982\ttotal: 26s\tremaining: 30.2s\n",
      "2128:\tlearn: 2.2805841\ttotal: 26s\tremaining: 30.2s\n",
      "2129:\tlearn: 2.2800849\ttotal: 26.1s\tremaining: 30.2s\n",
      "2130:\tlearn: 2.2796783\ttotal: 26.1s\tremaining: 30.2s\n",
      "2131:\tlearn: 2.2793974\ttotal: 26.1s\tremaining: 30.2s\n",
      "2132:\tlearn: 2.2790937\ttotal: 26.1s\tremaining: 30.2s\n",
      "2133:\tlearn: 2.2789567\ttotal: 26.1s\tremaining: 30.1s\n",
      "2134:\tlearn: 2.2785561\ttotal: 26.1s\tremaining: 30.1s\n",
      "2135:\tlearn: 2.2779790\ttotal: 26.1s\tremaining: 30.1s\n",
      "2136:\tlearn: 2.2773900\ttotal: 26.1s\tremaining: 30.1s\n",
      "2137:\tlearn: 2.2768643\ttotal: 26.2s\tremaining: 30.1s\n",
      "2138:\tlearn: 2.2764145\ttotal: 26.2s\tremaining: 30.1s\n",
      "2139:\tlearn: 2.2762038\ttotal: 26.2s\tremaining: 30.1s\n",
      "2140:\tlearn: 2.2759165\ttotal: 26.2s\tremaining: 30.1s\n",
      "2141:\tlearn: 2.2754462\ttotal: 26.2s\tremaining: 30s\n",
      "2142:\tlearn: 2.2751156\ttotal: 26.2s\tremaining: 30s\n",
      "2143:\tlearn: 2.2747934\ttotal: 26.2s\tremaining: 30s\n",
      "2144:\tlearn: 2.2744714\ttotal: 26.2s\tremaining: 30s\n",
      "2145:\tlearn: 2.2740196\ttotal: 26.3s\tremaining: 30s\n",
      "2146:\tlearn: 2.2736343\ttotal: 26.3s\tremaining: 30s\n",
      "2147:\tlearn: 2.2733161\ttotal: 26.3s\tremaining: 30s\n",
      "2148:\tlearn: 2.2726964\ttotal: 26.3s\tremaining: 30s\n",
      "2149:\tlearn: 2.2725024\ttotal: 26.3s\tremaining: 30s\n",
      "2150:\tlearn: 2.2722244\ttotal: 26.3s\tremaining: 29.9s\n",
      "2151:\tlearn: 2.2717775\ttotal: 26.3s\tremaining: 29.9s\n",
      "2152:\tlearn: 2.2713702\ttotal: 26.3s\tremaining: 29.9s\n",
      "2153:\tlearn: 2.2707002\ttotal: 26.4s\tremaining: 29.9s\n",
      "2154:\tlearn: 2.2701764\ttotal: 26.4s\tremaining: 29.9s\n",
      "2155:\tlearn: 2.2697187\ttotal: 26.4s\tremaining: 29.9s\n",
      "2156:\tlearn: 2.2691793\ttotal: 26.4s\tremaining: 29.9s\n",
      "2157:\tlearn: 2.2689152\ttotal: 26.4s\tremaining: 29.9s\n",
      "2158:\tlearn: 2.2684355\ttotal: 26.4s\tremaining: 29.8s\n",
      "2159:\tlearn: 2.2681321\ttotal: 26.4s\tremaining: 29.8s\n",
      "2160:\tlearn: 2.2675733\ttotal: 26.4s\tremaining: 29.8s\n",
      "2161:\tlearn: 2.2670697\ttotal: 26.5s\tremaining: 29.8s\n",
      "2162:\tlearn: 2.2666926\ttotal: 26.5s\tremaining: 29.8s\n",
      "2163:\tlearn: 2.2663662\ttotal: 26.5s\tremaining: 29.8s\n",
      "2164:\tlearn: 2.2659551\ttotal: 26.5s\tremaining: 29.8s\n",
      "2165:\tlearn: 2.2654989\ttotal: 26.5s\tremaining: 29.8s\n",
      "2166:\tlearn: 2.2650872\ttotal: 26.5s\tremaining: 29.7s\n",
      "2167:\tlearn: 2.2648681\ttotal: 26.5s\tremaining: 29.7s\n",
      "2168:\tlearn: 2.2643342\ttotal: 26.5s\tremaining: 29.7s\n",
      "2169:\tlearn: 2.2640350\ttotal: 26.6s\tremaining: 29.7s\n",
      "2170:\tlearn: 2.2636531\ttotal: 26.6s\tremaining: 29.7s\n",
      "2171:\tlearn: 2.2634626\ttotal: 26.6s\tremaining: 29.7s\n",
      "2172:\tlearn: 2.2631951\ttotal: 26.6s\tremaining: 29.7s\n",
      "2173:\tlearn: 2.2625286\ttotal: 26.6s\tremaining: 29.7s\n",
      "2174:\tlearn: 2.2621141\ttotal: 26.6s\tremaining: 29.6s\n",
      "2175:\tlearn: 2.2618471\ttotal: 26.6s\tremaining: 29.6s\n",
      "2176:\tlearn: 2.2616861\ttotal: 26.6s\tremaining: 29.6s\n",
      "2177:\tlearn: 2.2612304\ttotal: 26.6s\tremaining: 29.6s\n",
      "2178:\tlearn: 2.2609326\ttotal: 26.7s\tremaining: 29.6s\n",
      "2179:\tlearn: 2.2605736\ttotal: 26.7s\tremaining: 29.6s\n",
      "2180:\tlearn: 2.2603765\ttotal: 26.7s\tremaining: 29.6s\n",
      "2181:\tlearn: 2.2600500\ttotal: 26.7s\tremaining: 29.6s\n",
      "2182:\tlearn: 2.2596874\ttotal: 26.7s\tremaining: 29.5s\n",
      "2183:\tlearn: 2.2589936\ttotal: 26.7s\tremaining: 29.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2184:\tlearn: 2.2584956\ttotal: 26.7s\tremaining: 29.5s\n",
      "2185:\tlearn: 2.2581616\ttotal: 26.7s\tremaining: 29.5s\n",
      "2186:\tlearn: 2.2578798\ttotal: 26.8s\tremaining: 29.5s\n",
      "2187:\tlearn: 2.2576206\ttotal: 26.8s\tremaining: 29.5s\n",
      "2188:\tlearn: 2.2568528\ttotal: 26.8s\tremaining: 29.5s\n",
      "2189:\tlearn: 2.2565016\ttotal: 26.8s\tremaining: 29.5s\n",
      "2190:\tlearn: 2.2559929\ttotal: 26.8s\tremaining: 29.5s\n",
      "2191:\tlearn: 2.2554650\ttotal: 26.8s\tremaining: 29.4s\n",
      "2192:\tlearn: 2.2550910\ttotal: 26.8s\tremaining: 29.4s\n",
      "2193:\tlearn: 2.2548890\ttotal: 26.8s\tremaining: 29.4s\n",
      "2194:\tlearn: 2.2540597\ttotal: 26.9s\tremaining: 29.4s\n",
      "2195:\tlearn: 2.2536230\ttotal: 26.9s\tremaining: 29.4s\n",
      "2196:\tlearn: 2.2531521\ttotal: 26.9s\tremaining: 29.4s\n",
      "2197:\tlearn: 2.2527439\ttotal: 26.9s\tremaining: 29.4s\n",
      "2198:\tlearn: 2.2521147\ttotal: 26.9s\tremaining: 29.4s\n",
      "2199:\tlearn: 2.2515404\ttotal: 26.9s\tremaining: 29.3s\n",
      "2200:\tlearn: 2.2511145\ttotal: 26.9s\tremaining: 29.3s\n",
      "2201:\tlearn: 2.2507611\ttotal: 26.9s\tremaining: 29.3s\n",
      "2202:\tlearn: 2.2501149\ttotal: 27s\tremaining: 29.3s\n",
      "2203:\tlearn: 2.2494071\ttotal: 27s\tremaining: 29.3s\n",
      "2204:\tlearn: 2.2490429\ttotal: 27s\tremaining: 29.3s\n",
      "2205:\tlearn: 2.2487560\ttotal: 27s\tremaining: 29.3s\n",
      "2206:\tlearn: 2.2485427\ttotal: 27s\tremaining: 29.3s\n",
      "2207:\tlearn: 2.2481853\ttotal: 27s\tremaining: 29.2s\n",
      "2208:\tlearn: 2.2477662\ttotal: 27s\tremaining: 29.2s\n",
      "2209:\tlearn: 2.2471312\ttotal: 27s\tremaining: 29.2s\n",
      "2210:\tlearn: 2.2467310\ttotal: 27.1s\tremaining: 29.2s\n",
      "2211:\tlearn: 2.2461545\ttotal: 27.1s\tremaining: 29.2s\n",
      "2212:\tlearn: 2.2454882\ttotal: 27.1s\tremaining: 29.2s\n",
      "2213:\tlearn: 2.2449531\ttotal: 27.1s\tremaining: 29.2s\n",
      "2214:\tlearn: 2.2445087\ttotal: 27.1s\tremaining: 29.2s\n",
      "2215:\tlearn: 2.2441609\ttotal: 27.1s\tremaining: 29.1s\n",
      "2216:\tlearn: 2.2439086\ttotal: 27.1s\tremaining: 29.1s\n",
      "2217:\tlearn: 2.2434254\ttotal: 27.1s\tremaining: 29.1s\n",
      "2218:\tlearn: 2.2430678\ttotal: 27.2s\tremaining: 29.1s\n",
      "2219:\tlearn: 2.2427772\ttotal: 27.2s\tremaining: 29.1s\n",
      "2220:\tlearn: 2.2425027\ttotal: 27.2s\tremaining: 29.1s\n",
      "2221:\tlearn: 2.2420969\ttotal: 27.2s\tremaining: 29.1s\n",
      "2222:\tlearn: 2.2418896\ttotal: 27.2s\tremaining: 29.1s\n",
      "2223:\tlearn: 2.2414194\ttotal: 27.2s\tremaining: 29.1s\n",
      "2224:\tlearn: 2.2411808\ttotal: 27.2s\tremaining: 29s\n",
      "2225:\tlearn: 2.2407072\ttotal: 27.2s\tremaining: 29s\n",
      "2226:\tlearn: 2.2404570\ttotal: 27.3s\tremaining: 29s\n",
      "2227:\tlearn: 2.2400792\ttotal: 27.3s\tremaining: 29s\n",
      "2228:\tlearn: 2.2395399\ttotal: 27.3s\tremaining: 29s\n",
      "2229:\tlearn: 2.2393729\ttotal: 27.3s\tremaining: 29s\n",
      "2230:\tlearn: 2.2391006\ttotal: 27.3s\tremaining: 29s\n",
      "2231:\tlearn: 2.2385017\ttotal: 27.3s\tremaining: 29s\n",
      "2232:\tlearn: 2.2382867\ttotal: 27.3s\tremaining: 28.9s\n",
      "2233:\tlearn: 2.2378982\ttotal: 27.3s\tremaining: 28.9s\n",
      "2234:\tlearn: 2.2373647\ttotal: 27.3s\tremaining: 28.9s\n",
      "2235:\tlearn: 2.2368619\ttotal: 27.4s\tremaining: 28.9s\n",
      "2236:\tlearn: 2.2365003\ttotal: 27.4s\tremaining: 28.9s\n",
      "2237:\tlearn: 2.2362685\ttotal: 27.4s\tremaining: 28.9s\n",
      "2238:\tlearn: 2.2358940\ttotal: 27.4s\tremaining: 28.9s\n",
      "2239:\tlearn: 2.2355547\ttotal: 27.4s\tremaining: 28.9s\n",
      "2240:\tlearn: 2.2352204\ttotal: 27.4s\tremaining: 28.8s\n",
      "2241:\tlearn: 2.2350434\ttotal: 27.4s\tremaining: 28.8s\n",
      "2242:\tlearn: 2.2348790\ttotal: 27.4s\tremaining: 28.8s\n",
      "2243:\tlearn: 2.2345069\ttotal: 27.5s\tremaining: 28.8s\n",
      "2244:\tlearn: 2.2340373\ttotal: 27.5s\tremaining: 28.8s\n",
      "2245:\tlearn: 2.2334325\ttotal: 27.5s\tremaining: 28.8s\n",
      "2246:\tlearn: 2.2329684\ttotal: 27.5s\tremaining: 28.8s\n",
      "2247:\tlearn: 2.2325617\ttotal: 27.5s\tremaining: 28.8s\n",
      "2248:\tlearn: 2.2320730\ttotal: 27.5s\tremaining: 28.7s\n",
      "2249:\tlearn: 2.2318095\ttotal: 27.5s\tremaining: 28.7s\n",
      "2250:\tlearn: 2.2314703\ttotal: 27.5s\tremaining: 28.7s\n",
      "2251:\tlearn: 2.2310927\ttotal: 27.6s\tremaining: 28.7s\n",
      "2252:\tlearn: 2.2307300\ttotal: 27.6s\tremaining: 28.7s\n",
      "2253:\tlearn: 2.2301460\ttotal: 27.6s\tremaining: 28.7s\n",
      "2254:\tlearn: 2.2296760\ttotal: 27.6s\tremaining: 28.7s\n",
      "2255:\tlearn: 2.2293183\ttotal: 27.6s\tremaining: 28.7s\n",
      "2256:\tlearn: 2.2289207\ttotal: 27.6s\tremaining: 28.6s\n",
      "2257:\tlearn: 2.2285079\ttotal: 27.6s\tremaining: 28.6s\n",
      "2258:\tlearn: 2.2278397\ttotal: 27.6s\tremaining: 28.6s\n",
      "2259:\tlearn: 2.2274032\ttotal: 27.7s\tremaining: 28.6s\n",
      "2260:\tlearn: 2.2271906\ttotal: 27.7s\tremaining: 28.6s\n",
      "2261:\tlearn: 2.2267974\ttotal: 27.7s\tremaining: 28.6s\n",
      "2262:\tlearn: 2.2263818\ttotal: 27.7s\tremaining: 28.6s\n",
      "2263:\tlearn: 2.2259289\ttotal: 27.7s\tremaining: 28.6s\n",
      "2264:\tlearn: 2.2256010\ttotal: 27.7s\tremaining: 28.5s\n",
      "2265:\tlearn: 2.2253569\ttotal: 27.7s\tremaining: 28.5s\n",
      "2266:\tlearn: 2.2250011\ttotal: 27.7s\tremaining: 28.5s\n",
      "2267:\tlearn: 2.2247236\ttotal: 27.8s\tremaining: 28.5s\n",
      "2268:\tlearn: 2.2246283\ttotal: 27.8s\tremaining: 28.5s\n",
      "2269:\tlearn: 2.2243011\ttotal: 27.8s\tremaining: 28.5s\n",
      "2270:\tlearn: 2.2240416\ttotal: 27.8s\tremaining: 28.5s\n",
      "2271:\tlearn: 2.2238292\ttotal: 27.8s\tremaining: 28.5s\n",
      "2272:\tlearn: 2.2234776\ttotal: 27.8s\tremaining: 28.4s\n",
      "2273:\tlearn: 2.2231525\ttotal: 27.8s\tremaining: 28.4s\n",
      "2274:\tlearn: 2.2226595\ttotal: 27.8s\tremaining: 28.4s\n",
      "2275:\tlearn: 2.2222957\ttotal: 27.9s\tremaining: 28.4s\n",
      "2276:\tlearn: 2.2218207\ttotal: 27.9s\tremaining: 28.4s\n",
      "2277:\tlearn: 2.2214012\ttotal: 27.9s\tremaining: 28.4s\n",
      "2278:\tlearn: 2.2208435\ttotal: 27.9s\tremaining: 28.4s\n",
      "2279:\tlearn: 2.2205172\ttotal: 27.9s\tremaining: 28.4s\n",
      "2280:\tlearn: 2.2201593\ttotal: 27.9s\tremaining: 28.4s\n",
      "2281:\tlearn: 2.2199154\ttotal: 27.9s\tremaining: 28.3s\n",
      "2282:\tlearn: 2.2194366\ttotal: 27.9s\tremaining: 28.3s\n",
      "2283:\tlearn: 2.2190464\ttotal: 27.9s\tremaining: 28.3s\n",
      "2284:\tlearn: 2.2186112\ttotal: 28s\tremaining: 28.3s\n",
      "2285:\tlearn: 2.2178234\ttotal: 28s\tremaining: 28.3s\n",
      "2286:\tlearn: 2.2176169\ttotal: 28s\tremaining: 28.3s\n",
      "2287:\tlearn: 2.2171769\ttotal: 28s\tremaining: 28.3s\n",
      "2288:\tlearn: 2.2169536\ttotal: 28s\tremaining: 28.3s\n",
      "2289:\tlearn: 2.2163831\ttotal: 28s\tremaining: 28.2s\n",
      "2290:\tlearn: 2.2162174\ttotal: 28s\tremaining: 28.2s\n",
      "2291:\tlearn: 2.2159687\ttotal: 28s\tremaining: 28.2s\n",
      "2292:\tlearn: 2.2156193\ttotal: 28.1s\tremaining: 28.2s\n",
      "2293:\tlearn: 2.2151395\ttotal: 28.1s\tremaining: 28.2s\n",
      "2294:\tlearn: 2.2149471\ttotal: 28.1s\tremaining: 28.2s\n",
      "2295:\tlearn: 2.2145233\ttotal: 28.1s\tremaining: 28.2s\n",
      "2296:\tlearn: 2.2142455\ttotal: 28.1s\tremaining: 28.2s\n",
      "2297:\tlearn: 2.2140979\ttotal: 28.1s\tremaining: 28.1s\n",
      "2298:\tlearn: 2.2136224\ttotal: 28.1s\tremaining: 28.1s\n",
      "2299:\tlearn: 2.2131943\ttotal: 28.1s\tremaining: 28.1s\n",
      "2300:\tlearn: 2.2128905\ttotal: 28.2s\tremaining: 28.1s\n",
      "2301:\tlearn: 2.2126765\ttotal: 28.2s\tremaining: 28.1s\n",
      "2302:\tlearn: 2.2124377\ttotal: 28.2s\tremaining: 28.1s\n",
      "2303:\tlearn: 2.2122261\ttotal: 28.2s\tremaining: 28.1s\n",
      "2304:\tlearn: 2.2120249\ttotal: 28.2s\tremaining: 28.1s\n",
      "2305:\tlearn: 2.2117518\ttotal: 28.2s\tremaining: 28s\n",
      "2306:\tlearn: 2.2114626\ttotal: 28.2s\tremaining: 28s\n",
      "2307:\tlearn: 2.2107755\ttotal: 28.2s\tremaining: 28s\n",
      "2308:\tlearn: 2.2103384\ttotal: 28.3s\tremaining: 28s\n",
      "2309:\tlearn: 2.2101475\ttotal: 28.3s\tremaining: 28s\n",
      "2310:\tlearn: 2.2097800\ttotal: 28.3s\tremaining: 28s\n",
      "2311:\tlearn: 2.2094903\ttotal: 28.3s\tremaining: 28s\n",
      "2312:\tlearn: 2.2089751\ttotal: 28.3s\tremaining: 28s\n",
      "2313:\tlearn: 2.2085830\ttotal: 28.3s\tremaining: 27.9s\n",
      "2314:\tlearn: 2.2083303\ttotal: 28.3s\tremaining: 27.9s\n",
      "2315:\tlearn: 2.2078612\ttotal: 28.3s\tremaining: 27.9s\n",
      "2316:\tlearn: 2.2074664\ttotal: 28.3s\tremaining: 27.9s\n",
      "2317:\tlearn: 2.2071090\ttotal: 28.4s\tremaining: 27.9s\n",
      "2318:\tlearn: 2.2068148\ttotal: 28.4s\tremaining: 27.9s\n",
      "2319:\tlearn: 2.2065337\ttotal: 28.4s\tremaining: 27.9s\n",
      "2320:\tlearn: 2.2061128\ttotal: 28.4s\tremaining: 27.9s\n",
      "2321:\tlearn: 2.2055875\ttotal: 28.4s\tremaining: 27.8s\n",
      "2322:\tlearn: 2.2051359\ttotal: 28.4s\tremaining: 27.8s\n",
      "2323:\tlearn: 2.2046241\ttotal: 28.4s\tremaining: 27.8s\n",
      "2324:\tlearn: 2.2043587\ttotal: 28.4s\tremaining: 27.8s\n",
      "2325:\tlearn: 2.2040020\ttotal: 28.5s\tremaining: 27.8s\n",
      "2326:\tlearn: 2.2038095\ttotal: 28.5s\tremaining: 27.8s\n",
      "2327:\tlearn: 2.2035102\ttotal: 28.5s\tremaining: 27.8s\n",
      "2328:\tlearn: 2.2032191\ttotal: 28.5s\tremaining: 27.8s\n",
      "2329:\tlearn: 2.2030137\ttotal: 28.5s\tremaining: 27.7s\n",
      "2330:\tlearn: 2.2028243\ttotal: 28.5s\tremaining: 27.7s\n",
      "2331:\tlearn: 2.2026741\ttotal: 28.5s\tremaining: 27.7s\n",
      "2332:\tlearn: 2.2024711\ttotal: 28.5s\tremaining: 27.7s\n",
      "2333:\tlearn: 2.2020992\ttotal: 28.6s\tremaining: 27.7s\n",
      "2334:\tlearn: 2.2016357\ttotal: 28.6s\tremaining: 27.7s\n",
      "2335:\tlearn: 2.2012052\ttotal: 28.6s\tremaining: 27.7s\n",
      "2336:\tlearn: 2.2007399\ttotal: 28.6s\tremaining: 27.7s\n",
      "2337:\tlearn: 2.2001678\ttotal: 28.6s\tremaining: 27.6s\n",
      "2338:\tlearn: 2.1996334\ttotal: 28.6s\tremaining: 27.6s\n",
      "2339:\tlearn: 2.1994816\ttotal: 28.6s\tremaining: 27.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2340:\tlearn: 2.1990326\ttotal: 28.6s\tremaining: 27.6s\n",
      "2341:\tlearn: 2.1987006\ttotal: 28.7s\tremaining: 27.6s\n",
      "2342:\tlearn: 2.1983934\ttotal: 28.7s\tremaining: 27.6s\n",
      "2343:\tlearn: 2.1978483\ttotal: 28.7s\tremaining: 27.6s\n",
      "2344:\tlearn: 2.1973852\ttotal: 28.7s\tremaining: 27.6s\n",
      "2345:\tlearn: 2.1967346\ttotal: 28.7s\tremaining: 27.6s\n",
      "2346:\tlearn: 2.1962747\ttotal: 28.7s\tremaining: 27.5s\n",
      "2347:\tlearn: 2.1958491\ttotal: 28.7s\tremaining: 27.5s\n",
      "2348:\tlearn: 2.1952419\ttotal: 28.7s\tremaining: 27.5s\n",
      "2349:\tlearn: 2.1948071\ttotal: 28.8s\tremaining: 27.5s\n",
      "2350:\tlearn: 2.1945461\ttotal: 28.8s\tremaining: 27.5s\n",
      "2351:\tlearn: 2.1940037\ttotal: 28.8s\tremaining: 27.5s\n",
      "2352:\tlearn: 2.1931115\ttotal: 28.8s\tremaining: 27.5s\n",
      "2353:\tlearn: 2.1926248\ttotal: 28.8s\tremaining: 27.5s\n",
      "2354:\tlearn: 2.1921740\ttotal: 28.8s\tremaining: 27.4s\n",
      "2355:\tlearn: 2.1918278\ttotal: 28.8s\tremaining: 27.4s\n",
      "2356:\tlearn: 2.1916040\ttotal: 28.8s\tremaining: 27.4s\n",
      "2357:\tlearn: 2.1911552\ttotal: 28.8s\tremaining: 27.4s\n",
      "2358:\tlearn: 2.1909055\ttotal: 28.9s\tremaining: 27.4s\n",
      "2359:\tlearn: 2.1905973\ttotal: 28.9s\tremaining: 27.4s\n",
      "2360:\tlearn: 2.1901169\ttotal: 28.9s\tremaining: 27.4s\n",
      "2361:\tlearn: 2.1900368\ttotal: 28.9s\tremaining: 27.4s\n",
      "2362:\tlearn: 2.1896573\ttotal: 28.9s\tremaining: 27.3s\n",
      "2363:\tlearn: 2.1890208\ttotal: 28.9s\tremaining: 27.3s\n",
      "2364:\tlearn: 2.1885715\ttotal: 28.9s\tremaining: 27.3s\n",
      "2365:\tlearn: 2.1877157\ttotal: 28.9s\tremaining: 27.3s\n",
      "2366:\tlearn: 2.1873493\ttotal: 29s\tremaining: 27.3s\n",
      "2367:\tlearn: 2.1868745\ttotal: 29s\tremaining: 27.3s\n",
      "2368:\tlearn: 2.1867685\ttotal: 29s\tremaining: 27.3s\n",
      "2369:\tlearn: 2.1865610\ttotal: 29s\tremaining: 27.3s\n",
      "2370:\tlearn: 2.1862568\ttotal: 29s\tremaining: 27.2s\n",
      "2371:\tlearn: 2.1857285\ttotal: 29s\tremaining: 27.2s\n",
      "2372:\tlearn: 2.1852242\ttotal: 29s\tremaining: 27.2s\n",
      "2373:\tlearn: 2.1847085\ttotal: 29s\tremaining: 27.2s\n",
      "2374:\tlearn: 2.1840483\ttotal: 29.1s\tremaining: 27.2s\n",
      "2375:\tlearn: 2.1834611\ttotal: 29.1s\tremaining: 27.2s\n",
      "2376:\tlearn: 2.1830795\ttotal: 29.1s\tremaining: 27.2s\n",
      "2377:\tlearn: 2.1826451\ttotal: 29.1s\tremaining: 27.2s\n",
      "2378:\tlearn: 2.1822779\ttotal: 29.1s\tremaining: 27.1s\n",
      "2379:\tlearn: 2.1818298\ttotal: 29.1s\tremaining: 27.1s\n",
      "2380:\tlearn: 2.1814992\ttotal: 29.1s\tremaining: 27.1s\n",
      "2381:\tlearn: 2.1812434\ttotal: 29.1s\tremaining: 27.1s\n",
      "2382:\tlearn: 2.1807683\ttotal: 29.2s\tremaining: 27.1s\n",
      "2383:\tlearn: 2.1800685\ttotal: 29.2s\tremaining: 27.1s\n",
      "2384:\tlearn: 2.1798475\ttotal: 29.2s\tremaining: 27.1s\n",
      "2385:\tlearn: 2.1795173\ttotal: 29.2s\tremaining: 27.1s\n",
      "2386:\tlearn: 2.1791392\ttotal: 29.2s\tremaining: 27s\n",
      "2387:\tlearn: 2.1785799\ttotal: 29.2s\tremaining: 27s\n",
      "2388:\tlearn: 2.1781368\ttotal: 29.2s\tremaining: 27s\n",
      "2389:\tlearn: 2.1778291\ttotal: 29.2s\tremaining: 27s\n",
      "2390:\tlearn: 2.1773006\ttotal: 29.2s\tremaining: 27s\n",
      "2391:\tlearn: 2.1768163\ttotal: 29.3s\tremaining: 27s\n",
      "2392:\tlearn: 2.1763293\ttotal: 29.3s\tremaining: 27s\n",
      "2393:\tlearn: 2.1759701\ttotal: 29.3s\tremaining: 27s\n",
      "2394:\tlearn: 2.1754060\ttotal: 29.3s\tremaining: 26.9s\n",
      "2395:\tlearn: 2.1750077\ttotal: 29.3s\tremaining: 26.9s\n",
      "2396:\tlearn: 2.1746521\ttotal: 29.3s\tremaining: 26.9s\n",
      "2397:\tlearn: 2.1742540\ttotal: 29.3s\tremaining: 26.9s\n",
      "2398:\tlearn: 2.1739466\ttotal: 29.3s\tremaining: 26.9s\n",
      "2399:\tlearn: 2.1737123\ttotal: 29.4s\tremaining: 26.9s\n",
      "2400:\tlearn: 2.1733338\ttotal: 29.4s\tremaining: 26.9s\n",
      "2401:\tlearn: 2.1728958\ttotal: 29.4s\tremaining: 26.9s\n",
      "2402:\tlearn: 2.1725028\ttotal: 29.4s\tremaining: 26.8s\n",
      "2403:\tlearn: 2.1720675\ttotal: 29.4s\tremaining: 26.8s\n",
      "2404:\tlearn: 2.1717578\ttotal: 29.4s\tremaining: 26.8s\n",
      "2405:\tlearn: 2.1714105\ttotal: 29.4s\tremaining: 26.8s\n",
      "2406:\tlearn: 2.1707779\ttotal: 29.4s\tremaining: 26.8s\n",
      "2407:\tlearn: 2.1699963\ttotal: 29.5s\tremaining: 26.8s\n",
      "2408:\tlearn: 2.1696242\ttotal: 29.5s\tremaining: 26.8s\n",
      "2409:\tlearn: 2.1693077\ttotal: 29.5s\tremaining: 26.8s\n",
      "2410:\tlearn: 2.1691195\ttotal: 29.5s\tremaining: 26.8s\n",
      "2411:\tlearn: 2.1684415\ttotal: 29.5s\tremaining: 26.7s\n",
      "2412:\tlearn: 2.1680711\ttotal: 29.5s\tremaining: 26.7s\n",
      "2413:\tlearn: 2.1675725\ttotal: 29.5s\tremaining: 26.7s\n",
      "2414:\tlearn: 2.1669121\ttotal: 29.5s\tremaining: 26.7s\n",
      "2415:\tlearn: 2.1664477\ttotal: 29.6s\tremaining: 26.7s\n",
      "2416:\tlearn: 2.1659711\ttotal: 29.6s\tremaining: 26.7s\n",
      "2417:\tlearn: 2.1656302\ttotal: 29.6s\tremaining: 26.7s\n",
      "2418:\tlearn: 2.1651929\ttotal: 29.6s\tremaining: 26.7s\n",
      "2419:\tlearn: 2.1650381\ttotal: 29.6s\tremaining: 26.6s\n",
      "2420:\tlearn: 2.1648578\ttotal: 29.6s\tremaining: 26.6s\n",
      "2421:\tlearn: 2.1642253\ttotal: 29.6s\tremaining: 26.6s\n",
      "2422:\tlearn: 2.1637915\ttotal: 29.6s\tremaining: 26.6s\n",
      "2423:\tlearn: 2.1636739\ttotal: 29.6s\tremaining: 26.6s\n",
      "2424:\tlearn: 2.1632863\ttotal: 29.7s\tremaining: 26.6s\n",
      "2425:\tlearn: 2.1629921\ttotal: 29.7s\tremaining: 26.6s\n",
      "2426:\tlearn: 2.1627723\ttotal: 29.7s\tremaining: 26.6s\n",
      "2427:\tlearn: 2.1624228\ttotal: 29.7s\tremaining: 26.5s\n",
      "2428:\tlearn: 2.1620548\ttotal: 29.7s\tremaining: 26.5s\n",
      "2429:\tlearn: 2.1619343\ttotal: 29.7s\tremaining: 26.5s\n",
      "2430:\tlearn: 2.1615532\ttotal: 29.7s\tremaining: 26.5s\n",
      "2431:\tlearn: 2.1610976\ttotal: 29.7s\tremaining: 26.5s\n",
      "2432:\tlearn: 2.1609661\ttotal: 29.8s\tremaining: 26.5s\n",
      "2433:\tlearn: 2.1607738\ttotal: 29.8s\tremaining: 26.5s\n",
      "2434:\tlearn: 2.1604923\ttotal: 29.8s\tremaining: 26.5s\n",
      "2435:\tlearn: 2.1602360\ttotal: 29.8s\tremaining: 26.4s\n",
      "2436:\tlearn: 2.1599625\ttotal: 29.8s\tremaining: 26.4s\n",
      "2437:\tlearn: 2.1594419\ttotal: 29.8s\tremaining: 26.4s\n",
      "2438:\tlearn: 2.1590943\ttotal: 29.8s\tremaining: 26.4s\n",
      "2439:\tlearn: 2.1586585\ttotal: 29.8s\tremaining: 26.4s\n",
      "2440:\tlearn: 2.1583922\ttotal: 29.8s\tremaining: 26.4s\n",
      "2441:\tlearn: 2.1578694\ttotal: 29.9s\tremaining: 26.4s\n",
      "2442:\tlearn: 2.1576965\ttotal: 29.9s\tremaining: 26.4s\n",
      "2443:\tlearn: 2.1570995\ttotal: 29.9s\tremaining: 26.3s\n",
      "2444:\tlearn: 2.1566627\ttotal: 29.9s\tremaining: 26.3s\n",
      "2445:\tlearn: 2.1564722\ttotal: 29.9s\tremaining: 26.3s\n",
      "2446:\tlearn: 2.1562068\ttotal: 29.9s\tremaining: 26.3s\n",
      "2447:\tlearn: 2.1558891\ttotal: 29.9s\tremaining: 26.3s\n",
      "2448:\tlearn: 2.1555609\ttotal: 29.9s\tremaining: 26.3s\n",
      "2449:\tlearn: 2.1553201\ttotal: 30s\tremaining: 26.3s\n",
      "2450:\tlearn: 2.1551709\ttotal: 30s\tremaining: 26.3s\n",
      "2451:\tlearn: 2.1548711\ttotal: 30s\tremaining: 26.2s\n",
      "2452:\tlearn: 2.1547219\ttotal: 30s\tremaining: 26.2s\n",
      "2453:\tlearn: 2.1546077\ttotal: 30s\tremaining: 26.2s\n",
      "2454:\tlearn: 2.1543807\ttotal: 30s\tremaining: 26.2s\n",
      "2455:\tlearn: 2.1538861\ttotal: 30s\tremaining: 26.2s\n",
      "2456:\tlearn: 2.1535401\ttotal: 30s\tremaining: 26.2s\n",
      "2457:\tlearn: 2.1531836\ttotal: 30.1s\tremaining: 26.2s\n",
      "2458:\tlearn: 2.1528312\ttotal: 30.1s\tremaining: 26.1s\n",
      "2459:\tlearn: 2.1521745\ttotal: 30.1s\tremaining: 26.1s\n",
      "2460:\tlearn: 2.1519045\ttotal: 30.1s\tremaining: 26.1s\n",
      "2461:\tlearn: 2.1515558\ttotal: 30.1s\tremaining: 26.1s\n",
      "2462:\tlearn: 2.1513634\ttotal: 30.1s\tremaining: 26.1s\n",
      "2463:\tlearn: 2.1506592\ttotal: 30.1s\tremaining: 26.1s\n",
      "2464:\tlearn: 2.1502761\ttotal: 30.1s\tremaining: 26.1s\n",
      "2465:\tlearn: 2.1494751\ttotal: 30.2s\tremaining: 26.1s\n",
      "2466:\tlearn: 2.1489740\ttotal: 30.2s\tremaining: 26.1s\n",
      "2467:\tlearn: 2.1487267\ttotal: 30.2s\tremaining: 26s\n",
      "2468:\tlearn: 2.1483026\ttotal: 30.2s\tremaining: 26s\n",
      "2469:\tlearn: 2.1479387\ttotal: 30.2s\tremaining: 26s\n",
      "2470:\tlearn: 2.1475534\ttotal: 30.2s\tremaining: 26s\n",
      "2471:\tlearn: 2.1471620\ttotal: 30.2s\tremaining: 26s\n",
      "2472:\tlearn: 2.1468556\ttotal: 30.2s\tremaining: 26s\n",
      "2473:\tlearn: 2.1466014\ttotal: 30.2s\tremaining: 26s\n",
      "2474:\tlearn: 2.1463391\ttotal: 30.3s\tremaining: 26s\n",
      "2475:\tlearn: 2.1460877\ttotal: 30.3s\tremaining: 25.9s\n",
      "2476:\tlearn: 2.1458590\ttotal: 30.3s\tremaining: 25.9s\n",
      "2477:\tlearn: 2.1450276\ttotal: 30.3s\tremaining: 25.9s\n",
      "2478:\tlearn: 2.1444930\ttotal: 30.3s\tremaining: 25.9s\n",
      "2479:\tlearn: 2.1439199\ttotal: 30.3s\tremaining: 25.9s\n",
      "2480:\tlearn: 2.1436031\ttotal: 30.3s\tremaining: 25.9s\n",
      "2481:\tlearn: 2.1433226\ttotal: 30.3s\tremaining: 25.9s\n",
      "2482:\tlearn: 2.1430494\ttotal: 30.4s\tremaining: 25.9s\n",
      "2483:\tlearn: 2.1426999\ttotal: 30.4s\tremaining: 25.8s\n",
      "2484:\tlearn: 2.1420005\ttotal: 30.4s\tremaining: 25.8s\n",
      "2485:\tlearn: 2.1415314\ttotal: 30.4s\tremaining: 25.8s\n",
      "2486:\tlearn: 2.1413812\ttotal: 30.4s\tremaining: 25.8s\n",
      "2487:\tlearn: 2.1412083\ttotal: 30.4s\tremaining: 25.8s\n",
      "2488:\tlearn: 2.1408460\ttotal: 30.4s\tremaining: 25.8s\n",
      "2489:\tlearn: 2.1402047\ttotal: 30.4s\tremaining: 25.8s\n",
      "2490:\tlearn: 2.1399697\ttotal: 30.5s\tremaining: 25.8s\n",
      "2491:\tlearn: 2.1396743\ttotal: 30.5s\tremaining: 25.7s\n",
      "2492:\tlearn: 2.1393500\ttotal: 30.5s\tremaining: 25.7s\n",
      "2493:\tlearn: 2.1391216\ttotal: 30.5s\tremaining: 25.7s\n",
      "2494:\tlearn: 2.1386018\ttotal: 30.5s\tremaining: 25.7s\n",
      "2495:\tlearn: 2.1380879\ttotal: 30.5s\tremaining: 25.7s\n",
      "2496:\tlearn: 2.1374252\ttotal: 30.5s\tremaining: 25.7s\n",
      "2497:\tlearn: 2.1370682\ttotal: 30.5s\tremaining: 25.7s\n",
      "2498:\tlearn: 2.1368649\ttotal: 30.6s\tremaining: 25.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2499:\tlearn: 2.1365931\ttotal: 30.6s\tremaining: 25.7s\n",
      "2500:\tlearn: 2.1362465\ttotal: 30.6s\tremaining: 25.6s\n",
      "2501:\tlearn: 2.1359731\ttotal: 30.6s\tremaining: 25.6s\n",
      "2502:\tlearn: 2.1356616\ttotal: 30.6s\tremaining: 25.6s\n",
      "2503:\tlearn: 2.1351897\ttotal: 30.6s\tremaining: 25.6s\n",
      "2504:\tlearn: 2.1349273\ttotal: 30.6s\tremaining: 25.6s\n",
      "2505:\tlearn: 2.1346441\ttotal: 30.6s\tremaining: 25.6s\n",
      "2506:\tlearn: 2.1342509\ttotal: 30.7s\tremaining: 25.6s\n",
      "2507:\tlearn: 2.1339904\ttotal: 30.7s\tremaining: 25.6s\n",
      "2508:\tlearn: 2.1336425\ttotal: 30.7s\tremaining: 25.5s\n",
      "2509:\tlearn: 2.1333968\ttotal: 30.7s\tremaining: 25.5s\n",
      "2510:\tlearn: 2.1333953\ttotal: 30.7s\tremaining: 25.5s\n",
      "2511:\tlearn: 2.1327694\ttotal: 30.7s\tremaining: 25.5s\n",
      "2512:\tlearn: 2.1323495\ttotal: 30.7s\tremaining: 25.5s\n",
      "2513:\tlearn: 2.1320792\ttotal: 30.7s\tremaining: 25.5s\n",
      "2514:\tlearn: 2.1317780\ttotal: 30.7s\tremaining: 25.5s\n",
      "2515:\tlearn: 2.1313594\ttotal: 30.8s\tremaining: 25.5s\n",
      "2516:\tlearn: 2.1312237\ttotal: 30.8s\tremaining: 25.4s\n",
      "2517:\tlearn: 2.1310281\ttotal: 30.8s\tremaining: 25.4s\n",
      "2518:\tlearn: 2.1309361\ttotal: 30.8s\tremaining: 25.4s\n",
      "2519:\tlearn: 2.1305547\ttotal: 30.8s\tremaining: 25.4s\n",
      "2520:\tlearn: 2.1303059\ttotal: 30.8s\tremaining: 25.4s\n",
      "2521:\tlearn: 2.1296070\ttotal: 30.8s\tremaining: 25.4s\n",
      "2522:\tlearn: 2.1293545\ttotal: 30.8s\tremaining: 25.4s\n",
      "2523:\tlearn: 2.1290990\ttotal: 30.9s\tremaining: 25.4s\n",
      "2524:\tlearn: 2.1289385\ttotal: 30.9s\tremaining: 25.3s\n",
      "2525:\tlearn: 2.1285584\ttotal: 30.9s\tremaining: 25.3s\n",
      "2526:\tlearn: 2.1284118\ttotal: 30.9s\tremaining: 25.3s\n",
      "2527:\tlearn: 2.1282783\ttotal: 30.9s\tremaining: 25.3s\n",
      "2528:\tlearn: 2.1280216\ttotal: 30.9s\tremaining: 25.3s\n",
      "2529:\tlearn: 2.1277424\ttotal: 30.9s\tremaining: 25.3s\n",
      "2530:\tlearn: 2.1274831\ttotal: 30.9s\tremaining: 25.3s\n",
      "2531:\tlearn: 2.1271106\ttotal: 31s\tremaining: 25.3s\n",
      "2532:\tlearn: 2.1268336\ttotal: 31s\tremaining: 25.2s\n",
      "2533:\tlearn: 2.1264924\ttotal: 31s\tremaining: 25.2s\n",
      "2534:\tlearn: 2.1259379\ttotal: 31s\tremaining: 25.2s\n",
      "2535:\tlearn: 2.1255974\ttotal: 31s\tremaining: 25.2s\n",
      "2536:\tlearn: 2.1254263\ttotal: 31s\tremaining: 25.2s\n",
      "2537:\tlearn: 2.1251424\ttotal: 31s\tremaining: 25.2s\n",
      "2538:\tlearn: 2.1248431\ttotal: 31s\tremaining: 25.2s\n",
      "2539:\tlearn: 2.1245303\ttotal: 31s\tremaining: 25.2s\n",
      "2540:\tlearn: 2.1243308\ttotal: 31.1s\tremaining: 25.1s\n",
      "2541:\tlearn: 2.1237861\ttotal: 31.1s\tremaining: 25.1s\n",
      "2542:\tlearn: 2.1234994\ttotal: 31.1s\tremaining: 25.1s\n",
      "2543:\tlearn: 2.1229775\ttotal: 31.1s\tremaining: 25.1s\n",
      "2544:\tlearn: 2.1226370\ttotal: 31.1s\tremaining: 25.1s\n",
      "2545:\tlearn: 2.1221339\ttotal: 31.1s\tremaining: 25.1s\n",
      "2546:\tlearn: 2.1218266\ttotal: 31.1s\tremaining: 25.1s\n",
      "2547:\tlearn: 2.1215505\ttotal: 31.1s\tremaining: 25.1s\n",
      "2548:\tlearn: 2.1213138\ttotal: 31.2s\tremaining: 25s\n",
      "2549:\tlearn: 2.1212307\ttotal: 31.2s\tremaining: 25s\n",
      "2550:\tlearn: 2.1209234\ttotal: 31.2s\tremaining: 25s\n",
      "2551:\tlearn: 2.1206736\ttotal: 31.2s\tremaining: 25s\n",
      "2552:\tlearn: 2.1201933\ttotal: 31.2s\tremaining: 25s\n",
      "2553:\tlearn: 2.1199494\ttotal: 31.2s\tremaining: 25s\n",
      "2554:\tlearn: 2.1196043\ttotal: 31.2s\tremaining: 25s\n",
      "2555:\tlearn: 2.1192699\ttotal: 31.2s\tremaining: 25s\n",
      "2556:\tlearn: 2.1191085\ttotal: 31.3s\tremaining: 24.9s\n",
      "2557:\tlearn: 2.1188359\ttotal: 31.3s\tremaining: 24.9s\n",
      "2558:\tlearn: 2.1186381\ttotal: 31.3s\tremaining: 24.9s\n",
      "2559:\tlearn: 2.1183244\ttotal: 31.3s\tremaining: 24.9s\n",
      "2560:\tlearn: 2.1180074\ttotal: 31.3s\tremaining: 24.9s\n",
      "2561:\tlearn: 2.1179767\ttotal: 31.3s\tremaining: 24.9s\n",
      "2562:\tlearn: 2.1177063\ttotal: 31.3s\tremaining: 24.9s\n",
      "2563:\tlearn: 2.1170981\ttotal: 31.3s\tremaining: 24.9s\n",
      "2564:\tlearn: 2.1166635\ttotal: 31.3s\tremaining: 24.8s\n",
      "2565:\tlearn: 2.1161980\ttotal: 31.4s\tremaining: 24.8s\n",
      "2566:\tlearn: 2.1155112\ttotal: 31.4s\tremaining: 24.8s\n",
      "2567:\tlearn: 2.1152277\ttotal: 31.4s\tremaining: 24.8s\n",
      "2568:\tlearn: 2.1150095\ttotal: 31.4s\tremaining: 24.8s\n",
      "2569:\tlearn: 2.1143938\ttotal: 31.4s\tremaining: 24.8s\n",
      "2570:\tlearn: 2.1140038\ttotal: 31.4s\tremaining: 24.8s\n",
      "2571:\tlearn: 2.1134548\ttotal: 31.4s\tremaining: 24.8s\n",
      "2572:\tlearn: 2.1129673\ttotal: 31.4s\tremaining: 24.8s\n",
      "2573:\tlearn: 2.1127262\ttotal: 31.5s\tremaining: 24.7s\n",
      "2574:\tlearn: 2.1124252\ttotal: 31.5s\tremaining: 24.7s\n",
      "2575:\tlearn: 2.1118327\ttotal: 31.5s\tremaining: 24.7s\n",
      "2576:\tlearn: 2.1112095\ttotal: 31.5s\tremaining: 24.7s\n",
      "2577:\tlearn: 2.1108807\ttotal: 31.5s\tremaining: 24.7s\n",
      "2578:\tlearn: 2.1104531\ttotal: 31.5s\tremaining: 24.7s\n",
      "2579:\tlearn: 2.1103401\ttotal: 31.5s\tremaining: 24.7s\n",
      "2580:\tlearn: 2.1098449\ttotal: 31.5s\tremaining: 24.7s\n",
      "2581:\tlearn: 2.1094660\ttotal: 31.6s\tremaining: 24.6s\n",
      "2582:\tlearn: 2.1088508\ttotal: 31.6s\tremaining: 24.6s\n",
      "2583:\tlearn: 2.1084098\ttotal: 31.6s\tremaining: 24.6s\n",
      "2584:\tlearn: 2.1080199\ttotal: 31.6s\tremaining: 24.6s\n",
      "2585:\tlearn: 2.1077761\ttotal: 31.6s\tremaining: 24.6s\n",
      "2586:\tlearn: 2.1075623\ttotal: 31.6s\tremaining: 24.6s\n",
      "2587:\tlearn: 2.1072572\ttotal: 31.6s\tremaining: 24.6s\n",
      "2588:\tlearn: 2.1067044\ttotal: 31.6s\tremaining: 24.6s\n",
      "2589:\tlearn: 2.1065353\ttotal: 31.7s\tremaining: 24.5s\n",
      "2590:\tlearn: 2.1063055\ttotal: 31.7s\tremaining: 24.5s\n",
      "2591:\tlearn: 2.1059233\ttotal: 31.7s\tremaining: 24.5s\n",
      "2592:\tlearn: 2.1057824\ttotal: 31.7s\tremaining: 24.5s\n",
      "2593:\tlearn: 2.1052848\ttotal: 31.7s\tremaining: 24.5s\n",
      "2594:\tlearn: 2.1046316\ttotal: 31.7s\tremaining: 24.5s\n",
      "2595:\tlearn: 2.1044224\ttotal: 31.7s\tremaining: 24.5s\n",
      "2596:\tlearn: 2.1041705\ttotal: 31.7s\tremaining: 24.5s\n",
      "2597:\tlearn: 2.1037614\ttotal: 31.8s\tremaining: 24.4s\n",
      "2598:\tlearn: 2.1034471\ttotal: 31.8s\tremaining: 24.4s\n",
      "2599:\tlearn: 2.1030359\ttotal: 31.8s\tremaining: 24.4s\n",
      "2600:\tlearn: 2.1025691\ttotal: 31.8s\tremaining: 24.4s\n",
      "2601:\tlearn: 2.1021439\ttotal: 31.8s\tremaining: 24.4s\n",
      "2602:\tlearn: 2.1019043\ttotal: 31.8s\tremaining: 24.4s\n",
      "2603:\tlearn: 2.1015828\ttotal: 31.8s\tremaining: 24.4s\n",
      "2604:\tlearn: 2.1011417\ttotal: 31.8s\tremaining: 24.4s\n",
      "2605:\tlearn: 2.1003740\ttotal: 31.9s\tremaining: 24.3s\n",
      "2606:\tlearn: 2.1001018\ttotal: 31.9s\tremaining: 24.3s\n",
      "2607:\tlearn: 2.0999580\ttotal: 31.9s\tremaining: 24.3s\n",
      "2608:\tlearn: 2.0996530\ttotal: 31.9s\tremaining: 24.3s\n",
      "2609:\tlearn: 2.0994861\ttotal: 31.9s\tremaining: 24.3s\n",
      "2610:\tlearn: 2.0988053\ttotal: 31.9s\tremaining: 24.3s\n",
      "2611:\tlearn: 2.0985978\ttotal: 31.9s\tremaining: 24.3s\n",
      "2612:\tlearn: 2.0979853\ttotal: 31.9s\tremaining: 24.3s\n",
      "2613:\tlearn: 2.0976196\ttotal: 31.9s\tremaining: 24.2s\n",
      "2614:\tlearn: 2.0972809\ttotal: 32s\tremaining: 24.2s\n",
      "2615:\tlearn: 2.0969546\ttotal: 32s\tremaining: 24.2s\n",
      "2616:\tlearn: 2.0965440\ttotal: 32s\tremaining: 24.2s\n",
      "2617:\tlearn: 2.0960364\ttotal: 32s\tremaining: 24.2s\n",
      "2618:\tlearn: 2.0957346\ttotal: 32s\tremaining: 24.2s\n",
      "2619:\tlearn: 2.0952743\ttotal: 32s\tremaining: 24.2s\n",
      "2620:\tlearn: 2.0949526\ttotal: 32s\tremaining: 24.2s\n",
      "2621:\tlearn: 2.0947805\ttotal: 32s\tremaining: 24.1s\n",
      "2622:\tlearn: 2.0946789\ttotal: 32.1s\tremaining: 24.1s\n",
      "2623:\tlearn: 2.0940735\ttotal: 32.1s\tremaining: 24.1s\n",
      "2624:\tlearn: 2.0938081\ttotal: 32.1s\tremaining: 24.1s\n",
      "2625:\tlearn: 2.0932639\ttotal: 32.1s\tremaining: 24.1s\n",
      "2626:\tlearn: 2.0929483\ttotal: 32.1s\tremaining: 24.1s\n",
      "2627:\tlearn: 2.0923991\ttotal: 32.1s\tremaining: 24.1s\n",
      "2628:\tlearn: 2.0918955\ttotal: 32.1s\tremaining: 24.1s\n",
      "2629:\tlearn: 2.0916403\ttotal: 32.1s\tremaining: 24.1s\n",
      "2630:\tlearn: 2.0911641\ttotal: 32.2s\tremaining: 24s\n",
      "2631:\tlearn: 2.0911627\ttotal: 32.2s\tremaining: 24s\n",
      "2632:\tlearn: 2.0909973\ttotal: 32.2s\tremaining: 24s\n",
      "2633:\tlearn: 2.0907312\ttotal: 32.2s\tremaining: 24s\n",
      "2634:\tlearn: 2.0903059\ttotal: 32.2s\tremaining: 24s\n",
      "2635:\tlearn: 2.0898709\ttotal: 32.2s\tremaining: 24s\n",
      "2636:\tlearn: 2.0893842\ttotal: 32.2s\tremaining: 24s\n",
      "2637:\tlearn: 2.0891114\ttotal: 32.2s\tremaining: 24s\n",
      "2638:\tlearn: 2.0888664\ttotal: 32.3s\tremaining: 23.9s\n",
      "2639:\tlearn: 2.0885126\ttotal: 32.3s\tremaining: 23.9s\n",
      "2640:\tlearn: 2.0881088\ttotal: 32.3s\tremaining: 23.9s\n",
      "2641:\tlearn: 2.0876469\ttotal: 32.3s\tremaining: 23.9s\n",
      "2642:\tlearn: 2.0872491\ttotal: 32.3s\tremaining: 23.9s\n",
      "2643:\tlearn: 2.0870430\ttotal: 32.3s\tremaining: 23.9s\n",
      "2644:\tlearn: 2.0864491\ttotal: 32.3s\tremaining: 23.9s\n",
      "2645:\tlearn: 2.0860401\ttotal: 32.3s\tremaining: 23.9s\n",
      "2646:\tlearn: 2.0855107\ttotal: 32.4s\tremaining: 23.8s\n",
      "2647:\tlearn: 2.0853262\ttotal: 32.4s\tremaining: 23.8s\n",
      "2648:\tlearn: 2.0846327\ttotal: 32.4s\tremaining: 23.8s\n",
      "2649:\tlearn: 2.0842488\ttotal: 32.4s\tremaining: 23.8s\n",
      "2650:\tlearn: 2.0840620\ttotal: 32.4s\tremaining: 23.8s\n",
      "2651:\tlearn: 2.0836667\ttotal: 32.4s\tremaining: 23.8s\n",
      "2652:\tlearn: 2.0834281\ttotal: 32.4s\tremaining: 23.8s\n",
      "2653:\tlearn: 2.0831093\ttotal: 32.4s\tremaining: 23.8s\n",
      "2654:\tlearn: 2.0825466\ttotal: 32.4s\tremaining: 23.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2655:\tlearn: 2.0821110\ttotal: 32.5s\tremaining: 23.7s\n",
      "2656:\tlearn: 2.0817899\ttotal: 32.5s\tremaining: 23.7s\n",
      "2657:\tlearn: 2.0814715\ttotal: 32.5s\tremaining: 23.7s\n",
      "2658:\tlearn: 2.0812249\ttotal: 32.5s\tremaining: 23.7s\n",
      "2659:\tlearn: 2.0807504\ttotal: 32.5s\tremaining: 23.7s\n",
      "2660:\tlearn: 2.0804846\ttotal: 32.5s\tremaining: 23.7s\n",
      "2661:\tlearn: 2.0799639\ttotal: 32.5s\tremaining: 23.7s\n",
      "2662:\tlearn: 2.0795584\ttotal: 32.5s\tremaining: 23.7s\n",
      "2663:\tlearn: 2.0789861\ttotal: 32.6s\tremaining: 23.6s\n",
      "2664:\tlearn: 2.0786315\ttotal: 32.6s\tremaining: 23.6s\n",
      "2665:\tlearn: 2.0784078\ttotal: 32.6s\tremaining: 23.6s\n",
      "2666:\tlearn: 2.0780406\ttotal: 32.6s\tremaining: 23.6s\n",
      "2667:\tlearn: 2.0778998\ttotal: 32.6s\tremaining: 23.6s\n",
      "2668:\tlearn: 2.0773517\ttotal: 32.6s\tremaining: 23.6s\n",
      "2669:\tlearn: 2.0769744\ttotal: 32.6s\tremaining: 23.6s\n",
      "2670:\tlearn: 2.0768421\ttotal: 32.6s\tremaining: 23.5s\n",
      "2671:\tlearn: 2.0763866\ttotal: 32.7s\tremaining: 23.5s\n",
      "2672:\tlearn: 2.0761087\ttotal: 32.7s\tremaining: 23.5s\n",
      "2673:\tlearn: 2.0755871\ttotal: 32.7s\tremaining: 23.5s\n",
      "2674:\tlearn: 2.0752811\ttotal: 32.7s\tremaining: 23.5s\n",
      "2675:\tlearn: 2.0751942\ttotal: 32.7s\tremaining: 23.5s\n",
      "2676:\tlearn: 2.0746910\ttotal: 32.7s\tremaining: 23.5s\n",
      "2677:\tlearn: 2.0745321\ttotal: 32.7s\tremaining: 23.5s\n",
      "2678:\tlearn: 2.0741664\ttotal: 32.7s\tremaining: 23.5s\n",
      "2679:\tlearn: 2.0736441\ttotal: 32.8s\tremaining: 23.4s\n",
      "2680:\tlearn: 2.0733648\ttotal: 32.8s\tremaining: 23.4s\n",
      "2681:\tlearn: 2.0729119\ttotal: 32.8s\tremaining: 23.4s\n",
      "2682:\tlearn: 2.0724143\ttotal: 32.8s\tremaining: 23.4s\n",
      "2683:\tlearn: 2.0720524\ttotal: 32.8s\tremaining: 23.4s\n",
      "2684:\tlearn: 2.0717825\ttotal: 32.8s\tremaining: 23.4s\n",
      "2685:\tlearn: 2.0714365\ttotal: 32.8s\tremaining: 23.4s\n",
      "2686:\tlearn: 2.0708052\ttotal: 32.8s\tremaining: 23.4s\n",
      "2687:\tlearn: 2.0705160\ttotal: 32.9s\tremaining: 23.3s\n",
      "2688:\tlearn: 2.0701053\ttotal: 32.9s\tremaining: 23.3s\n",
      "2689:\tlearn: 2.0699163\ttotal: 32.9s\tremaining: 23.3s\n",
      "2690:\tlearn: 2.0695988\ttotal: 32.9s\tremaining: 23.3s\n",
      "2691:\tlearn: 2.0693024\ttotal: 32.9s\tremaining: 23.3s\n",
      "2692:\tlearn: 2.0690212\ttotal: 32.9s\tremaining: 23.3s\n",
      "2693:\tlearn: 2.0688351\ttotal: 32.9s\tremaining: 23.3s\n",
      "2694:\tlearn: 2.0682903\ttotal: 32.9s\tremaining: 23.3s\n",
      "2695:\tlearn: 2.0678052\ttotal: 33s\tremaining: 23.2s\n",
      "2696:\tlearn: 2.0674134\ttotal: 33s\tremaining: 23.2s\n",
      "2697:\tlearn: 2.0672674\ttotal: 33s\tremaining: 23.2s\n",
      "2698:\tlearn: 2.0670894\ttotal: 33s\tremaining: 23.2s\n",
      "2699:\tlearn: 2.0666165\ttotal: 33s\tremaining: 23.2s\n",
      "2700:\tlearn: 2.0661415\ttotal: 33s\tremaining: 23.2s\n",
      "2701:\tlearn: 2.0657356\ttotal: 33s\tremaining: 23.2s\n",
      "2702:\tlearn: 2.0654839\ttotal: 33s\tremaining: 23.2s\n",
      "2703:\tlearn: 2.0650812\ttotal: 33s\tremaining: 23.1s\n",
      "2704:\tlearn: 2.0645632\ttotal: 33.1s\tremaining: 23.1s\n",
      "2705:\tlearn: 2.0641994\ttotal: 33.1s\tremaining: 23.1s\n",
      "2706:\tlearn: 2.0637133\ttotal: 33.1s\tremaining: 23.1s\n",
      "2707:\tlearn: 2.0633108\ttotal: 33.1s\tremaining: 23.1s\n",
      "2708:\tlearn: 2.0629057\ttotal: 33.1s\tremaining: 23.1s\n",
      "2709:\tlearn: 2.0623756\ttotal: 33.1s\tremaining: 23.1s\n",
      "2710:\tlearn: 2.0620078\ttotal: 33.1s\tremaining: 23.1s\n",
      "2711:\tlearn: 2.0617733\ttotal: 33.1s\tremaining: 23s\n",
      "2712:\tlearn: 2.0615557\ttotal: 33.2s\tremaining: 23s\n",
      "2713:\tlearn: 2.0613892\ttotal: 33.2s\tremaining: 23s\n",
      "2714:\tlearn: 2.0611057\ttotal: 33.2s\tremaining: 23s\n",
      "2715:\tlearn: 2.0605903\ttotal: 33.2s\tremaining: 23s\n",
      "2716:\tlearn: 2.0601229\ttotal: 33.2s\tremaining: 23s\n",
      "2717:\tlearn: 2.0598251\ttotal: 33.2s\tremaining: 23s\n",
      "2718:\tlearn: 2.0595601\ttotal: 33.2s\tremaining: 23s\n",
      "2719:\tlearn: 2.0594725\ttotal: 33.2s\tremaining: 22.9s\n",
      "2720:\tlearn: 2.0593040\ttotal: 33.3s\tremaining: 22.9s\n",
      "2721:\tlearn: 2.0588307\ttotal: 33.3s\tremaining: 22.9s\n",
      "2722:\tlearn: 2.0581368\ttotal: 33.3s\tremaining: 22.9s\n",
      "2723:\tlearn: 2.0580354\ttotal: 33.3s\tremaining: 22.9s\n",
      "2724:\tlearn: 2.0576951\ttotal: 33.3s\tremaining: 22.9s\n",
      "2725:\tlearn: 2.0570841\ttotal: 33.3s\tremaining: 22.9s\n",
      "2726:\tlearn: 2.0568289\ttotal: 33.3s\tremaining: 22.9s\n",
      "2727:\tlearn: 2.0564766\ttotal: 33.3s\tremaining: 22.9s\n",
      "2728:\tlearn: 2.0561991\ttotal: 33.3s\tremaining: 22.8s\n",
      "2729:\tlearn: 2.0559651\ttotal: 33.4s\tremaining: 22.8s\n",
      "2730:\tlearn: 2.0553677\ttotal: 33.4s\tremaining: 22.8s\n",
      "2731:\tlearn: 2.0547780\ttotal: 33.4s\tremaining: 22.8s\n",
      "2732:\tlearn: 2.0544171\ttotal: 33.4s\tremaining: 22.8s\n",
      "2733:\tlearn: 2.0540279\ttotal: 33.4s\tremaining: 22.8s\n",
      "2734:\tlearn: 2.0535388\ttotal: 33.4s\tremaining: 22.8s\n",
      "2735:\tlearn: 2.0534365\ttotal: 33.4s\tremaining: 22.8s\n",
      "2736:\tlearn: 2.0533316\ttotal: 33.4s\tremaining: 22.7s\n",
      "2737:\tlearn: 2.0530749\ttotal: 33.5s\tremaining: 22.7s\n",
      "2738:\tlearn: 2.0528231\ttotal: 33.5s\tremaining: 22.7s\n",
      "2739:\tlearn: 2.0524714\ttotal: 33.5s\tremaining: 22.7s\n",
      "2740:\tlearn: 2.0520446\ttotal: 33.5s\tremaining: 22.7s\n",
      "2741:\tlearn: 2.0516036\ttotal: 33.5s\tremaining: 22.7s\n",
      "2742:\tlearn: 2.0510826\ttotal: 33.5s\tremaining: 22.7s\n",
      "2743:\tlearn: 2.0505622\ttotal: 33.5s\tremaining: 22.7s\n",
      "2744:\tlearn: 2.0500504\ttotal: 33.5s\tremaining: 22.6s\n",
      "2745:\tlearn: 2.0497201\ttotal: 33.6s\tremaining: 22.6s\n",
      "2746:\tlearn: 2.0492965\ttotal: 33.6s\tremaining: 22.6s\n",
      "2747:\tlearn: 2.0486218\ttotal: 33.6s\tremaining: 22.6s\n",
      "2748:\tlearn: 2.0481843\ttotal: 33.6s\tremaining: 22.6s\n",
      "2749:\tlearn: 2.0477625\ttotal: 33.6s\tremaining: 22.6s\n",
      "2750:\tlearn: 2.0474813\ttotal: 33.6s\tremaining: 22.6s\n",
      "2751:\tlearn: 2.0471527\ttotal: 33.6s\tremaining: 22.6s\n",
      "2752:\tlearn: 2.0467703\ttotal: 33.6s\tremaining: 22.6s\n",
      "2753:\tlearn: 2.0463357\ttotal: 33.7s\tremaining: 22.5s\n",
      "2754:\tlearn: 2.0460069\ttotal: 33.7s\tremaining: 22.5s\n",
      "2755:\tlearn: 2.0457009\ttotal: 33.7s\tremaining: 22.5s\n",
      "2756:\tlearn: 2.0454630\ttotal: 33.7s\tremaining: 22.5s\n",
      "2757:\tlearn: 2.0449758\ttotal: 33.7s\tremaining: 22.5s\n",
      "2758:\tlearn: 2.0444931\ttotal: 33.7s\tremaining: 22.5s\n",
      "2759:\tlearn: 2.0444650\ttotal: 33.7s\tremaining: 22.5s\n",
      "2760:\tlearn: 2.0440622\ttotal: 33.7s\tremaining: 22.5s\n",
      "2761:\tlearn: 2.0437589\ttotal: 33.8s\tremaining: 22.4s\n",
      "2762:\tlearn: 2.0436134\ttotal: 33.8s\tremaining: 22.4s\n",
      "2763:\tlearn: 2.0430399\ttotal: 33.8s\tremaining: 22.4s\n",
      "2764:\tlearn: 2.0426632\ttotal: 33.8s\tremaining: 22.4s\n",
      "2765:\tlearn: 2.0423551\ttotal: 33.8s\tremaining: 22.4s\n",
      "2766:\tlearn: 2.0421654\ttotal: 33.8s\tremaining: 22.4s\n",
      "2767:\tlearn: 2.0417709\ttotal: 33.8s\tremaining: 22.4s\n",
      "2768:\tlearn: 2.0413778\ttotal: 33.9s\tremaining: 22.4s\n",
      "2769:\tlearn: 2.0412319\ttotal: 33.9s\tremaining: 22.4s\n",
      "2770:\tlearn: 2.0408680\ttotal: 33.9s\tremaining: 22.3s\n",
      "2771:\tlearn: 2.0404897\ttotal: 33.9s\tremaining: 22.3s\n",
      "2772:\tlearn: 2.0402584\ttotal: 33.9s\tremaining: 22.3s\n",
      "2773:\tlearn: 2.0398874\ttotal: 33.9s\tremaining: 22.3s\n",
      "2774:\tlearn: 2.0395098\ttotal: 33.9s\tremaining: 22.3s\n",
      "2775:\tlearn: 2.0390282\ttotal: 33.9s\tremaining: 22.3s\n",
      "2776:\tlearn: 2.0385529\ttotal: 34s\tremaining: 22.3s\n",
      "2777:\tlearn: 2.0382526\ttotal: 34s\tremaining: 22.3s\n",
      "2778:\tlearn: 2.0377737\ttotal: 34s\tremaining: 22.2s\n",
      "2779:\tlearn: 2.0377487\ttotal: 34s\tremaining: 22.2s\n",
      "2780:\tlearn: 2.0373480\ttotal: 34s\tremaining: 22.2s\n",
      "2781:\tlearn: 2.0367681\ttotal: 34s\tremaining: 22.2s\n",
      "2782:\tlearn: 2.0365199\ttotal: 34s\tremaining: 22.2s\n",
      "2783:\tlearn: 2.0362698\ttotal: 34s\tremaining: 22.2s\n",
      "2784:\tlearn: 2.0360588\ttotal: 34.1s\tremaining: 22.2s\n",
      "2785:\tlearn: 2.0357189\ttotal: 34.1s\tremaining: 22.2s\n",
      "2786:\tlearn: 2.0350710\ttotal: 34.1s\tremaining: 22.1s\n",
      "2787:\tlearn: 2.0349589\ttotal: 34.1s\tremaining: 22.1s\n",
      "2788:\tlearn: 2.0347012\ttotal: 34.1s\tremaining: 22.1s\n",
      "2789:\tlearn: 2.0345517\ttotal: 34.1s\tremaining: 22.1s\n",
      "2790:\tlearn: 2.0342797\ttotal: 34.1s\tremaining: 22.1s\n",
      "2791:\tlearn: 2.0340242\ttotal: 34.1s\tremaining: 22.1s\n",
      "2792:\tlearn: 2.0337805\ttotal: 34.2s\tremaining: 22.1s\n",
      "2793:\tlearn: 2.0337611\ttotal: 34.2s\tremaining: 22.1s\n",
      "2794:\tlearn: 2.0334406\ttotal: 34.2s\tremaining: 22.1s\n",
      "2795:\tlearn: 2.0332868\ttotal: 34.2s\tremaining: 22s\n",
      "2796:\tlearn: 2.0327448\ttotal: 34.2s\tremaining: 22s\n",
      "2797:\tlearn: 2.0325525\ttotal: 34.2s\tremaining: 22s\n",
      "2798:\tlearn: 2.0322911\ttotal: 34.2s\tremaining: 22s\n",
      "2799:\tlearn: 2.0320286\ttotal: 34.2s\tremaining: 22s\n",
      "2800:\tlearn: 2.0317977\ttotal: 34.3s\tremaining: 22s\n",
      "2801:\tlearn: 2.0311775\ttotal: 34.3s\tremaining: 22s\n",
      "2802:\tlearn: 2.0309307\ttotal: 34.3s\tremaining: 22s\n",
      "2803:\tlearn: 2.0303994\ttotal: 34.3s\tremaining: 21.9s\n",
      "2804:\tlearn: 2.0300374\ttotal: 34.3s\tremaining: 21.9s\n",
      "2805:\tlearn: 2.0296944\ttotal: 34.3s\tremaining: 21.9s\n",
      "2806:\tlearn: 2.0293617\ttotal: 34.3s\tremaining: 21.9s\n",
      "2807:\tlearn: 2.0289180\ttotal: 34.3s\tremaining: 21.9s\n",
      "2808:\tlearn: 2.0287188\ttotal: 34.4s\tremaining: 21.9s\n",
      "2809:\tlearn: 2.0283366\ttotal: 34.4s\tremaining: 21.9s\n",
      "2810:\tlearn: 2.0278011\ttotal: 34.4s\tremaining: 21.9s\n",
      "2811:\tlearn: 2.0271529\ttotal: 34.4s\tremaining: 21.8s\n",
      "2812:\tlearn: 2.0265819\ttotal: 34.4s\tremaining: 21.8s\n",
      "2813:\tlearn: 2.0265641\ttotal: 34.4s\tremaining: 21.8s\n",
      "2814:\tlearn: 2.0262410\ttotal: 34.4s\tremaining: 21.8s\n",
      "2815:\tlearn: 2.0258849\ttotal: 34.4s\tremaining: 21.8s\n",
      "2816:\tlearn: 2.0255834\ttotal: 34.5s\tremaining: 21.8s\n",
      "2817:\tlearn: 2.0253486\ttotal: 34.5s\tremaining: 21.8s\n",
      "2818:\tlearn: 2.0251579\ttotal: 34.5s\tremaining: 21.8s\n",
      "2819:\tlearn: 2.0248515\ttotal: 34.5s\tremaining: 21.7s\n",
      "2820:\tlearn: 2.0245335\ttotal: 34.5s\tremaining: 21.7s\n",
      "2821:\tlearn: 2.0242175\ttotal: 34.5s\tremaining: 21.7s\n",
      "2822:\tlearn: 2.0238471\ttotal: 34.5s\tremaining: 21.7s\n",
      "2823:\tlearn: 2.0234422\ttotal: 34.5s\tremaining: 21.7s\n",
      "2824:\tlearn: 2.0230339\ttotal: 34.6s\tremaining: 21.7s\n",
      "2825:\tlearn: 2.0226359\ttotal: 34.6s\tremaining: 21.7s\n",
      "2826:\tlearn: 2.0223529\ttotal: 34.6s\tremaining: 21.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2827:\tlearn: 2.0221698\ttotal: 34.6s\tremaining: 21.6s\n",
      "2828:\tlearn: 2.0217243\ttotal: 34.6s\tremaining: 21.6s\n",
      "2829:\tlearn: 2.0214240\ttotal: 34.6s\tremaining: 21.6s\n",
      "2830:\tlearn: 2.0211255\ttotal: 34.6s\tremaining: 21.6s\n",
      "2831:\tlearn: 2.0209637\ttotal: 34.6s\tremaining: 21.6s\n",
      "2832:\tlearn: 2.0206524\ttotal: 34.7s\tremaining: 21.6s\n",
      "2833:\tlearn: 2.0204015\ttotal: 34.7s\tremaining: 21.6s\n",
      "2834:\tlearn: 2.0199371\ttotal: 34.7s\tremaining: 21.6s\n",
      "2835:\tlearn: 2.0194878\ttotal: 34.7s\tremaining: 21.6s\n",
      "2836:\tlearn: 2.0193348\ttotal: 34.7s\tremaining: 21.5s\n",
      "2837:\tlearn: 2.0191246\ttotal: 34.7s\tremaining: 21.5s\n",
      "2838:\tlearn: 2.0185839\ttotal: 34.7s\tremaining: 21.5s\n",
      "2839:\tlearn: 2.0181708\ttotal: 34.7s\tremaining: 21.5s\n",
      "2840:\tlearn: 2.0179504\ttotal: 34.7s\tremaining: 21.5s\n",
      "2841:\tlearn: 2.0174838\ttotal: 34.8s\tremaining: 21.5s\n",
      "2842:\tlearn: 2.0169304\ttotal: 34.8s\tremaining: 21.5s\n",
      "2843:\tlearn: 2.0167429\ttotal: 34.8s\tremaining: 21.5s\n",
      "2844:\tlearn: 2.0163323\ttotal: 34.8s\tremaining: 21.4s\n",
      "2845:\tlearn: 2.0159004\ttotal: 34.8s\tremaining: 21.4s\n",
      "2846:\tlearn: 2.0156156\ttotal: 34.8s\tremaining: 21.4s\n",
      "2847:\tlearn: 2.0154485\ttotal: 34.8s\tremaining: 21.4s\n",
      "2848:\tlearn: 2.0152087\ttotal: 34.9s\tremaining: 21.4s\n",
      "2849:\tlearn: 2.0150994\ttotal: 34.9s\tremaining: 21.4s\n",
      "2850:\tlearn: 2.0148309\ttotal: 34.9s\tremaining: 21.4s\n",
      "2851:\tlearn: 2.0145472\ttotal: 34.9s\tremaining: 21.4s\n",
      "2852:\tlearn: 2.0143868\ttotal: 34.9s\tremaining: 21.3s\n",
      "2853:\tlearn: 2.0143125\ttotal: 34.9s\tremaining: 21.3s\n",
      "2854:\tlearn: 2.0137944\ttotal: 34.9s\tremaining: 21.3s\n",
      "2855:\tlearn: 2.0134231\ttotal: 34.9s\tremaining: 21.3s\n",
      "2856:\tlearn: 2.0131830\ttotal: 34.9s\tremaining: 21.3s\n",
      "2857:\tlearn: 2.0126131\ttotal: 35s\tremaining: 21.3s\n",
      "2858:\tlearn: 2.0123081\ttotal: 35s\tremaining: 21.3s\n",
      "2859:\tlearn: 2.0116778\ttotal: 35s\tremaining: 21.3s\n",
      "2860:\tlearn: 2.0113874\ttotal: 35s\tremaining: 21.2s\n",
      "2861:\tlearn: 2.0112802\ttotal: 35s\tremaining: 21.2s\n",
      "2862:\tlearn: 2.0109154\ttotal: 35s\tremaining: 21.2s\n",
      "2863:\tlearn: 2.0107364\ttotal: 35s\tremaining: 21.2s\n",
      "2864:\tlearn: 2.0105603\ttotal: 35s\tremaining: 21.2s\n",
      "2865:\tlearn: 2.0102964\ttotal: 35.1s\tremaining: 21.2s\n",
      "2866:\tlearn: 2.0099609\ttotal: 35.1s\tremaining: 21.2s\n",
      "2867:\tlearn: 2.0097456\ttotal: 35.1s\tremaining: 21.2s\n",
      "2868:\tlearn: 2.0094023\ttotal: 35.1s\tremaining: 21.1s\n",
      "2869:\tlearn: 2.0091078\ttotal: 35.1s\tremaining: 21.1s\n",
      "2870:\tlearn: 2.0087550\ttotal: 35.1s\tremaining: 21.1s\n",
      "2871:\tlearn: 2.0084250\ttotal: 35.1s\tremaining: 21.1s\n",
      "2872:\tlearn: 2.0079385\ttotal: 35.1s\tremaining: 21.1s\n",
      "2873:\tlearn: 2.0079018\ttotal: 35.1s\tremaining: 21.1s\n",
      "2874:\tlearn: 2.0076807\ttotal: 35.2s\tremaining: 21.1s\n",
      "2875:\tlearn: 2.0075404\ttotal: 35.2s\tremaining: 21.1s\n",
      "2876:\tlearn: 2.0073097\ttotal: 35.2s\tremaining: 21s\n",
      "2877:\tlearn: 2.0070767\ttotal: 35.2s\tremaining: 21s\n",
      "2878:\tlearn: 2.0067475\ttotal: 35.2s\tremaining: 21s\n",
      "2879:\tlearn: 2.0065036\ttotal: 35.2s\tremaining: 21s\n",
      "2880:\tlearn: 2.0062130\ttotal: 35.2s\tremaining: 21s\n",
      "2881:\tlearn: 2.0061318\ttotal: 35.3s\tremaining: 21s\n",
      "2882:\tlearn: 2.0058538\ttotal: 35.3s\tremaining: 21s\n",
      "2883:\tlearn: 2.0055457\ttotal: 35.3s\tremaining: 21s\n",
      "2884:\tlearn: 2.0051810\ttotal: 35.3s\tremaining: 20.9s\n",
      "2885:\tlearn: 2.0049650\ttotal: 35.3s\tremaining: 20.9s\n",
      "2886:\tlearn: 2.0047716\ttotal: 35.3s\tremaining: 20.9s\n",
      "2887:\tlearn: 2.0046375\ttotal: 35.3s\tremaining: 20.9s\n",
      "2888:\tlearn: 2.0043259\ttotal: 35.3s\tremaining: 20.9s\n",
      "2889:\tlearn: 2.0040224\ttotal: 35.3s\tremaining: 20.9s\n",
      "2890:\tlearn: 2.0037520\ttotal: 35.4s\tremaining: 20.9s\n",
      "2891:\tlearn: 2.0035042\ttotal: 35.4s\tremaining: 20.9s\n",
      "2892:\tlearn: 2.0031230\ttotal: 35.4s\tremaining: 20.9s\n",
      "2893:\tlearn: 2.0028751\ttotal: 35.4s\tremaining: 20.8s\n",
      "2894:\tlearn: 2.0024825\ttotal: 35.4s\tremaining: 20.8s\n",
      "2895:\tlearn: 2.0023611\ttotal: 35.4s\tremaining: 20.8s\n",
      "2896:\tlearn: 2.0021487\ttotal: 35.4s\tremaining: 20.8s\n",
      "2897:\tlearn: 2.0017560\ttotal: 35.4s\tremaining: 20.8s\n",
      "2898:\tlearn: 2.0015491\ttotal: 35.5s\tremaining: 20.8s\n",
      "2899:\tlearn: 2.0011389\ttotal: 35.5s\tremaining: 20.8s\n",
      "2900:\tlearn: 2.0007040\ttotal: 35.5s\tremaining: 20.8s\n",
      "2901:\tlearn: 2.0004172\ttotal: 35.5s\tremaining: 20.7s\n",
      "2902:\tlearn: 2.0001790\ttotal: 35.5s\tremaining: 20.7s\n",
      "2903:\tlearn: 1.9998962\ttotal: 35.5s\tremaining: 20.7s\n",
      "2904:\tlearn: 1.9995664\ttotal: 35.5s\tremaining: 20.7s\n",
      "2905:\tlearn: 1.9993868\ttotal: 35.5s\tremaining: 20.7s\n",
      "2906:\tlearn: 1.9987016\ttotal: 35.5s\tremaining: 20.7s\n",
      "2907:\tlearn: 1.9986116\ttotal: 35.6s\tremaining: 20.7s\n",
      "2908:\tlearn: 1.9981922\ttotal: 35.6s\tremaining: 20.7s\n",
      "2909:\tlearn: 1.9979413\ttotal: 35.6s\tremaining: 20.6s\n",
      "2910:\tlearn: 1.9975881\ttotal: 35.6s\tremaining: 20.6s\n",
      "2911:\tlearn: 1.9973223\ttotal: 35.6s\tremaining: 20.6s\n",
      "2912:\tlearn: 1.9972528\ttotal: 35.6s\tremaining: 20.6s\n",
      "2913:\tlearn: 1.9968757\ttotal: 35.6s\tremaining: 20.6s\n",
      "2914:\tlearn: 1.9964827\ttotal: 35.6s\tremaining: 20.6s\n",
      "2915:\tlearn: 1.9962883\ttotal: 35.7s\tremaining: 20.6s\n",
      "2916:\tlearn: 1.9959549\ttotal: 35.7s\tremaining: 20.6s\n",
      "2917:\tlearn: 1.9957083\ttotal: 35.7s\tremaining: 20.5s\n",
      "2918:\tlearn: 1.9951930\ttotal: 35.7s\tremaining: 20.5s\n",
      "2919:\tlearn: 1.9948083\ttotal: 35.7s\tremaining: 20.5s\n",
      "2920:\tlearn: 1.9945901\ttotal: 35.7s\tremaining: 20.5s\n",
      "2921:\tlearn: 1.9942099\ttotal: 35.7s\tremaining: 20.5s\n",
      "2922:\tlearn: 1.9937934\ttotal: 35.7s\tremaining: 20.5s\n",
      "2923:\tlearn: 1.9933042\ttotal: 35.8s\tremaining: 20.5s\n",
      "2924:\tlearn: 1.9929804\ttotal: 35.8s\tremaining: 20.5s\n",
      "2925:\tlearn: 1.9923888\ttotal: 35.8s\tremaining: 20.4s\n",
      "2926:\tlearn: 1.9920717\ttotal: 35.8s\tremaining: 20.4s\n",
      "2927:\tlearn: 1.9918961\ttotal: 35.8s\tremaining: 20.4s\n",
      "2928:\tlearn: 1.9916481\ttotal: 35.8s\tremaining: 20.4s\n",
      "2929:\tlearn: 1.9914093\ttotal: 35.8s\tremaining: 20.4s\n",
      "2930:\tlearn: 1.9909584\ttotal: 35.8s\tremaining: 20.4s\n",
      "2931:\tlearn: 1.9906615\ttotal: 35.9s\tremaining: 20.4s\n",
      "2932:\tlearn: 1.9901621\ttotal: 35.9s\tremaining: 20.4s\n",
      "2933:\tlearn: 1.9899626\ttotal: 35.9s\tremaining: 20.3s\n",
      "2934:\tlearn: 1.9894476\ttotal: 35.9s\tremaining: 20.3s\n",
      "2935:\tlearn: 1.9891468\ttotal: 35.9s\tremaining: 20.3s\n",
      "2936:\tlearn: 1.9890415\ttotal: 35.9s\tremaining: 20.3s\n",
      "2937:\tlearn: 1.9885327\ttotal: 35.9s\tremaining: 20.3s\n",
      "2938:\tlearn: 1.9883136\ttotal: 35.9s\tremaining: 20.3s\n",
      "2939:\tlearn: 1.9880401\ttotal: 35.9s\tremaining: 20.3s\n",
      "2940:\tlearn: 1.9877673\ttotal: 36s\tremaining: 20.3s\n",
      "2941:\tlearn: 1.9874337\ttotal: 36s\tremaining: 20.2s\n",
      "2942:\tlearn: 1.9868909\ttotal: 36s\tremaining: 20.2s\n",
      "2943:\tlearn: 1.9865247\ttotal: 36s\tremaining: 20.2s\n",
      "2944:\tlearn: 1.9863639\ttotal: 36s\tremaining: 20.2s\n",
      "2945:\tlearn: 1.9860144\ttotal: 36s\tremaining: 20.2s\n",
      "2946:\tlearn: 1.9858604\ttotal: 36s\tremaining: 20.2s\n",
      "2947:\tlearn: 1.9855258\ttotal: 36s\tremaining: 20.2s\n",
      "2948:\tlearn: 1.9853243\ttotal: 36.1s\tremaining: 20.2s\n",
      "2949:\tlearn: 1.9849294\ttotal: 36.1s\tremaining: 20.1s\n",
      "2950:\tlearn: 1.9846640\ttotal: 36.1s\tremaining: 20.1s\n",
      "2951:\tlearn: 1.9842104\ttotal: 36.1s\tremaining: 20.1s\n",
      "2952:\tlearn: 1.9837956\ttotal: 36.1s\tremaining: 20.1s\n",
      "2953:\tlearn: 1.9833538\ttotal: 36.1s\tremaining: 20.1s\n",
      "2954:\tlearn: 1.9830467\ttotal: 36.1s\tremaining: 20.1s\n",
      "2955:\tlearn: 1.9827722\ttotal: 36.1s\tremaining: 20.1s\n",
      "2956:\tlearn: 1.9823693\ttotal: 36.2s\tremaining: 20.1s\n",
      "2957:\tlearn: 1.9820881\ttotal: 36.2s\tremaining: 20.1s\n",
      "2958:\tlearn: 1.9817959\ttotal: 36.2s\tremaining: 20s\n",
      "2959:\tlearn: 1.9815398\ttotal: 36.2s\tremaining: 20s\n",
      "2960:\tlearn: 1.9813877\ttotal: 36.2s\tremaining: 20s\n",
      "2961:\tlearn: 1.9810971\ttotal: 36.2s\tremaining: 20s\n",
      "2962:\tlearn: 1.9809075\ttotal: 36.2s\tremaining: 20s\n",
      "2963:\tlearn: 1.9804728\ttotal: 36.2s\tremaining: 20s\n",
      "2964:\tlearn: 1.9803189\ttotal: 36.3s\tremaining: 20s\n",
      "2965:\tlearn: 1.9799927\ttotal: 36.3s\tremaining: 20s\n",
      "2966:\tlearn: 1.9795306\ttotal: 36.3s\tremaining: 19.9s\n",
      "2967:\tlearn: 1.9792089\ttotal: 36.3s\tremaining: 19.9s\n",
      "2968:\tlearn: 1.9788360\ttotal: 36.3s\tremaining: 19.9s\n",
      "2969:\tlearn: 1.9784272\ttotal: 36.3s\tremaining: 19.9s\n",
      "2970:\tlearn: 1.9780868\ttotal: 36.3s\tremaining: 19.9s\n",
      "2971:\tlearn: 1.9778785\ttotal: 36.3s\tremaining: 19.9s\n",
      "2972:\tlearn: 1.9773885\ttotal: 36.4s\tremaining: 19.9s\n",
      "2973:\tlearn: 1.9769267\ttotal: 36.4s\tremaining: 19.9s\n",
      "2974:\tlearn: 1.9766445\ttotal: 36.4s\tremaining: 19.8s\n",
      "2975:\tlearn: 1.9763262\ttotal: 36.4s\tremaining: 19.8s\n",
      "2976:\tlearn: 1.9760567\ttotal: 36.4s\tremaining: 19.8s\n",
      "2977:\tlearn: 1.9756375\ttotal: 36.4s\tremaining: 19.8s\n",
      "2978:\tlearn: 1.9751420\ttotal: 36.4s\tremaining: 19.8s\n",
      "2979:\tlearn: 1.9747421\ttotal: 36.4s\tremaining: 19.8s\n",
      "2980:\tlearn: 1.9743461\ttotal: 36.5s\tremaining: 19.8s\n",
      "2981:\tlearn: 1.9740517\ttotal: 36.5s\tremaining: 19.8s\n",
      "2982:\tlearn: 1.9737976\ttotal: 36.5s\tremaining: 19.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2983:\tlearn: 1.9734402\ttotal: 36.5s\tremaining: 19.7s\n",
      "2984:\tlearn: 1.9730963\ttotal: 36.5s\tremaining: 19.7s\n",
      "2985:\tlearn: 1.9728986\ttotal: 36.5s\tremaining: 19.7s\n",
      "2986:\tlearn: 1.9726373\ttotal: 36.5s\tremaining: 19.7s\n",
      "2987:\tlearn: 1.9724453\ttotal: 36.5s\tremaining: 19.7s\n",
      "2988:\tlearn: 1.9721585\ttotal: 36.6s\tremaining: 19.7s\n",
      "2989:\tlearn: 1.9719362\ttotal: 36.6s\tremaining: 19.7s\n",
      "2990:\tlearn: 1.9715757\ttotal: 36.6s\tremaining: 19.7s\n",
      "2991:\tlearn: 1.9714396\ttotal: 36.6s\tremaining: 19.6s\n",
      "2992:\tlearn: 1.9708776\ttotal: 36.6s\tremaining: 19.6s\n",
      "2993:\tlearn: 1.9703818\ttotal: 36.6s\tremaining: 19.6s\n",
      "2994:\tlearn: 1.9702413\ttotal: 36.6s\tremaining: 19.6s\n",
      "2995:\tlearn: 1.9699345\ttotal: 36.6s\tremaining: 19.6s\n",
      "2996:\tlearn: 1.9698342\ttotal: 36.7s\tremaining: 19.6s\n",
      "2997:\tlearn: 1.9695668\ttotal: 36.7s\tremaining: 19.6s\n",
      "2998:\tlearn: 1.9693481\ttotal: 36.7s\tremaining: 19.6s\n",
      "2999:\tlearn: 1.9690392\ttotal: 36.7s\tremaining: 19.5s\n",
      "3000:\tlearn: 1.9686316\ttotal: 36.7s\tremaining: 19.5s\n",
      "3001:\tlearn: 1.9684787\ttotal: 36.7s\tremaining: 19.5s\n",
      "3002:\tlearn: 1.9682754\ttotal: 36.7s\tremaining: 19.5s\n",
      "3003:\tlearn: 1.9680688\ttotal: 36.7s\tremaining: 19.5s\n",
      "3004:\tlearn: 1.9675735\ttotal: 36.8s\tremaining: 19.5s\n",
      "3005:\tlearn: 1.9674233\ttotal: 36.8s\tremaining: 19.5s\n",
      "3006:\tlearn: 1.9672003\ttotal: 36.8s\tremaining: 19.5s\n",
      "3007:\tlearn: 1.9667840\ttotal: 36.8s\tremaining: 19.4s\n",
      "3008:\tlearn: 1.9666224\ttotal: 36.8s\tremaining: 19.4s\n",
      "3009:\tlearn: 1.9664451\ttotal: 36.8s\tremaining: 19.4s\n",
      "3010:\tlearn: 1.9658948\ttotal: 36.8s\tremaining: 19.4s\n",
      "3011:\tlearn: 1.9657790\ttotal: 36.8s\tremaining: 19.4s\n",
      "3012:\tlearn: 1.9652047\ttotal: 36.9s\tremaining: 19.4s\n",
      "3013:\tlearn: 1.9648823\ttotal: 36.9s\tremaining: 19.4s\n",
      "3014:\tlearn: 1.9645567\ttotal: 36.9s\tremaining: 19.4s\n",
      "3015:\tlearn: 1.9643907\ttotal: 36.9s\tremaining: 19.4s\n",
      "3016:\tlearn: 1.9638608\ttotal: 36.9s\tremaining: 19.3s\n",
      "3017:\tlearn: 1.9635443\ttotal: 36.9s\tremaining: 19.3s\n",
      "3018:\tlearn: 1.9632930\ttotal: 36.9s\tremaining: 19.3s\n",
      "3019:\tlearn: 1.9630937\ttotal: 36.9s\tremaining: 19.3s\n",
      "3020:\tlearn: 1.9627609\ttotal: 37s\tremaining: 19.3s\n",
      "3021:\tlearn: 1.9624947\ttotal: 37s\tremaining: 19.3s\n",
      "3022:\tlearn: 1.9623817\ttotal: 37s\tremaining: 19.3s\n",
      "3023:\tlearn: 1.9621293\ttotal: 37s\tremaining: 19.3s\n",
      "3024:\tlearn: 1.9616599\ttotal: 37s\tremaining: 19.2s\n",
      "3025:\tlearn: 1.9613116\ttotal: 37s\tremaining: 19.2s\n",
      "3026:\tlearn: 1.9611387\ttotal: 37s\tremaining: 19.2s\n",
      "3027:\tlearn: 1.9609028\ttotal: 37s\tremaining: 19.2s\n",
      "3028:\tlearn: 1.9606072\ttotal: 37.1s\tremaining: 19.2s\n",
      "3029:\tlearn: 1.9603065\ttotal: 37.1s\tremaining: 19.2s\n",
      "3030:\tlearn: 1.9600529\ttotal: 37.1s\tremaining: 19.2s\n",
      "3031:\tlearn: 1.9598727\ttotal: 37.1s\tremaining: 19.2s\n",
      "3032:\tlearn: 1.9595949\ttotal: 37.1s\tremaining: 19.1s\n",
      "3033:\tlearn: 1.9595766\ttotal: 37.1s\tremaining: 19.1s\n",
      "3034:\tlearn: 1.9594764\ttotal: 37.1s\tremaining: 19.1s\n",
      "3035:\tlearn: 1.9590107\ttotal: 37.1s\tremaining: 19.1s\n",
      "3036:\tlearn: 1.9586454\ttotal: 37.1s\tremaining: 19.1s\n",
      "3037:\tlearn: 1.9584089\ttotal: 37.2s\tremaining: 19.1s\n",
      "3038:\tlearn: 1.9579396\ttotal: 37.2s\tremaining: 19.1s\n",
      "3039:\tlearn: 1.9576387\ttotal: 37.2s\tremaining: 19.1s\n",
      "3040:\tlearn: 1.9575565\ttotal: 37.2s\tremaining: 19s\n",
      "3041:\tlearn: 1.9573392\ttotal: 37.2s\tremaining: 19s\n",
      "3042:\tlearn: 1.9571579\ttotal: 37.2s\tremaining: 19s\n",
      "3043:\tlearn: 1.9569389\ttotal: 37.2s\tremaining: 19s\n",
      "3044:\tlearn: 1.9566702\ttotal: 37.2s\tremaining: 19s\n",
      "3045:\tlearn: 1.9562791\ttotal: 37.3s\tremaining: 19s\n",
      "3046:\tlearn: 1.9559640\ttotal: 37.3s\tremaining: 19s\n",
      "3047:\tlearn: 1.9553878\ttotal: 37.3s\tremaining: 19s\n",
      "3048:\tlearn: 1.9551885\ttotal: 37.3s\tremaining: 18.9s\n",
      "3049:\tlearn: 1.9546654\ttotal: 37.3s\tremaining: 18.9s\n",
      "3050:\tlearn: 1.9541383\ttotal: 37.3s\tremaining: 18.9s\n",
      "3051:\tlearn: 1.9536529\ttotal: 37.3s\tremaining: 18.9s\n",
      "3052:\tlearn: 1.9534927\ttotal: 37.3s\tremaining: 18.9s\n",
      "3053:\tlearn: 1.9528773\ttotal: 37.4s\tremaining: 18.9s\n",
      "3054:\tlearn: 1.9526890\ttotal: 37.4s\tremaining: 18.9s\n",
      "3055:\tlearn: 1.9523756\ttotal: 37.4s\tremaining: 18.9s\n",
      "3056:\tlearn: 1.9520793\ttotal: 37.4s\tremaining: 18.9s\n",
      "3057:\tlearn: 1.9518988\ttotal: 37.4s\tremaining: 18.8s\n",
      "3058:\tlearn: 1.9515200\ttotal: 37.4s\tremaining: 18.8s\n",
      "3059:\tlearn: 1.9512843\ttotal: 37.4s\tremaining: 18.8s\n",
      "3060:\tlearn: 1.9510722\ttotal: 37.4s\tremaining: 18.8s\n",
      "3061:\tlearn: 1.9509078\ttotal: 37.5s\tremaining: 18.8s\n",
      "3062:\tlearn: 1.9506712\ttotal: 37.5s\tremaining: 18.8s\n",
      "3063:\tlearn: 1.9502447\ttotal: 37.5s\tremaining: 18.8s\n",
      "3064:\tlearn: 1.9501023\ttotal: 37.5s\tremaining: 18.8s\n",
      "3065:\tlearn: 1.9497725\ttotal: 37.5s\tremaining: 18.7s\n",
      "3066:\tlearn: 1.9493921\ttotal: 37.5s\tremaining: 18.7s\n",
      "3067:\tlearn: 1.9490951\ttotal: 37.5s\tremaining: 18.7s\n",
      "3068:\tlearn: 1.9489475\ttotal: 37.5s\tremaining: 18.7s\n",
      "3069:\tlearn: 1.9486282\ttotal: 37.6s\tremaining: 18.7s\n",
      "3070:\tlearn: 1.9484041\ttotal: 37.6s\tremaining: 18.7s\n",
      "3071:\tlearn: 1.9482431\ttotal: 37.6s\tremaining: 18.7s\n",
      "3072:\tlearn: 1.9478645\ttotal: 37.6s\tremaining: 18.7s\n",
      "3073:\tlearn: 1.9475734\ttotal: 37.6s\tremaining: 18.6s\n",
      "3074:\tlearn: 1.9472009\ttotal: 37.6s\tremaining: 18.6s\n",
      "3075:\tlearn: 1.9469963\ttotal: 37.6s\tremaining: 18.6s\n",
      "3076:\tlearn: 1.9466260\ttotal: 37.6s\tremaining: 18.6s\n",
      "3077:\tlearn: 1.9461910\ttotal: 37.7s\tremaining: 18.6s\n",
      "3078:\tlearn: 1.9460389\ttotal: 37.7s\tremaining: 18.6s\n",
      "3079:\tlearn: 1.9458715\ttotal: 37.7s\tremaining: 18.6s\n",
      "3080:\tlearn: 1.9454356\ttotal: 37.7s\tremaining: 18.6s\n",
      "3081:\tlearn: 1.9453270\ttotal: 37.7s\tremaining: 18.5s\n",
      "3082:\tlearn: 1.9451913\ttotal: 37.7s\tremaining: 18.5s\n",
      "3083:\tlearn: 1.9446665\ttotal: 37.7s\tremaining: 18.5s\n",
      "3084:\tlearn: 1.9444831\ttotal: 37.7s\tremaining: 18.5s\n",
      "3085:\tlearn: 1.9442845\ttotal: 37.7s\tremaining: 18.5s\n",
      "3086:\tlearn: 1.9440038\ttotal: 37.8s\tremaining: 18.5s\n",
      "3087:\tlearn: 1.9439223\ttotal: 37.8s\tremaining: 18.5s\n",
      "3088:\tlearn: 1.9436963\ttotal: 37.8s\tremaining: 18.5s\n",
      "3089:\tlearn: 1.9433731\ttotal: 37.8s\tremaining: 18.4s\n",
      "3090:\tlearn: 1.9432073\ttotal: 37.8s\tremaining: 18.4s\n",
      "3091:\tlearn: 1.9427395\ttotal: 37.8s\tremaining: 18.4s\n",
      "3092:\tlearn: 1.9426356\ttotal: 37.8s\tremaining: 18.4s\n",
      "3093:\tlearn: 1.9422731\ttotal: 37.9s\tremaining: 18.4s\n",
      "3094:\tlearn: 1.9420325\ttotal: 37.9s\tremaining: 18.4s\n",
      "3095:\tlearn: 1.9417390\ttotal: 37.9s\tremaining: 18.4s\n",
      "3096:\tlearn: 1.9412419\ttotal: 37.9s\tremaining: 18.4s\n",
      "3097:\tlearn: 1.9410195\ttotal: 37.9s\tremaining: 18.4s\n",
      "3098:\tlearn: 1.9407607\ttotal: 37.9s\tremaining: 18.3s\n",
      "3099:\tlearn: 1.9403536\ttotal: 37.9s\tremaining: 18.3s\n",
      "3100:\tlearn: 1.9401777\ttotal: 37.9s\tremaining: 18.3s\n",
      "3101:\tlearn: 1.9398892\ttotal: 37.9s\tremaining: 18.3s\n",
      "3102:\tlearn: 1.9396420\ttotal: 38s\tremaining: 18.3s\n",
      "3103:\tlearn: 1.9393587\ttotal: 38s\tremaining: 18.3s\n",
      "3104:\tlearn: 1.9391013\ttotal: 38s\tremaining: 18.3s\n",
      "3105:\tlearn: 1.9387879\ttotal: 38s\tremaining: 18.3s\n",
      "3106:\tlearn: 1.9383539\ttotal: 38s\tremaining: 18.2s\n",
      "3107:\tlearn: 1.9381108\ttotal: 38s\tremaining: 18.2s\n",
      "3108:\tlearn: 1.9377773\ttotal: 38s\tremaining: 18.2s\n",
      "3109:\tlearn: 1.9376497\ttotal: 38s\tremaining: 18.2s\n",
      "3110:\tlearn: 1.9374740\ttotal: 38.1s\tremaining: 18.2s\n",
      "3111:\tlearn: 1.9372819\ttotal: 38.1s\tremaining: 18.2s\n",
      "3112:\tlearn: 1.9371059\ttotal: 38.1s\tremaining: 18.2s\n",
      "3113:\tlearn: 1.9369175\ttotal: 38.1s\tremaining: 18.2s\n",
      "3114:\tlearn: 1.9368194\ttotal: 38.1s\tremaining: 18.1s\n",
      "3115:\tlearn: 1.9365888\ttotal: 38.1s\tremaining: 18.1s\n",
      "3116:\tlearn: 1.9362885\ttotal: 38.1s\tremaining: 18.1s\n",
      "3117:\tlearn: 1.9359995\ttotal: 38.1s\tremaining: 18.1s\n",
      "3118:\tlearn: 1.9358144\ttotal: 38.2s\tremaining: 18.1s\n",
      "3119:\tlearn: 1.9355627\ttotal: 38.2s\tremaining: 18.1s\n",
      "3120:\tlearn: 1.9352776\ttotal: 38.2s\tremaining: 18.1s\n",
      "3121:\tlearn: 1.9351154\ttotal: 38.2s\tremaining: 18.1s\n",
      "3122:\tlearn: 1.9347512\ttotal: 38.2s\tremaining: 18s\n",
      "3123:\tlearn: 1.9346412\ttotal: 38.2s\tremaining: 18s\n",
      "3124:\tlearn: 1.9344764\ttotal: 38.2s\tremaining: 18s\n",
      "3125:\tlearn: 1.9341496\ttotal: 38.2s\tremaining: 18s\n",
      "3126:\tlearn: 1.9339186\ttotal: 38.3s\tremaining: 18s\n",
      "3127:\tlearn: 1.9338048\ttotal: 38.3s\tremaining: 18s\n",
      "3128:\tlearn: 1.9335571\ttotal: 38.3s\tremaining: 18s\n",
      "3129:\tlearn: 1.9332046\ttotal: 38.3s\tremaining: 18s\n",
      "3130:\tlearn: 1.9328576\ttotal: 38.3s\tremaining: 17.9s\n",
      "3131:\tlearn: 1.9325327\ttotal: 38.3s\tremaining: 17.9s\n",
      "3132:\tlearn: 1.9321674\ttotal: 38.3s\tremaining: 17.9s\n",
      "3133:\tlearn: 1.9319149\ttotal: 38.3s\tremaining: 17.9s\n",
      "3134:\tlearn: 1.9315810\ttotal: 38.4s\tremaining: 17.9s\n",
      "3135:\tlearn: 1.9310996\ttotal: 38.4s\tremaining: 17.9s\n",
      "3136:\tlearn: 1.9308005\ttotal: 38.4s\tremaining: 17.9s\n",
      "3137:\tlearn: 1.9300969\ttotal: 38.4s\tremaining: 17.9s\n",
      "3138:\tlearn: 1.9298467\ttotal: 38.4s\tremaining: 17.9s\n",
      "3139:\tlearn: 1.9295102\ttotal: 38.4s\tremaining: 17.8s\n",
      "3140:\tlearn: 1.9294172\ttotal: 38.4s\tremaining: 17.8s\n",
      "3141:\tlearn: 1.9292048\ttotal: 38.4s\tremaining: 17.8s\n",
      "3142:\tlearn: 1.9287875\ttotal: 38.5s\tremaining: 17.8s\n",
      "3143:\tlearn: 1.9286052\ttotal: 38.5s\tremaining: 17.8s\n",
      "3144:\tlearn: 1.9283137\ttotal: 38.5s\tremaining: 17.8s\n",
      "3145:\tlearn: 1.9279706\ttotal: 38.5s\tremaining: 17.8s\n",
      "3146:\tlearn: 1.9277380\ttotal: 38.5s\tremaining: 17.8s\n",
      "3147:\tlearn: 1.9273552\ttotal: 38.5s\tremaining: 17.7s\n",
      "3148:\tlearn: 1.9265324\ttotal: 38.5s\tremaining: 17.7s\n",
      "3149:\tlearn: 1.9261006\ttotal: 38.5s\tremaining: 17.7s\n",
      "3150:\tlearn: 1.9260359\ttotal: 38.5s\tremaining: 17.7s\n",
      "3151:\tlearn: 1.9258784\ttotal: 38.6s\tremaining: 17.7s\n",
      "3152:\tlearn: 1.9256117\ttotal: 38.6s\tremaining: 17.7s\n",
      "3153:\tlearn: 1.9254299\ttotal: 38.6s\tremaining: 17.7s\n",
      "3154:\tlearn: 1.9251727\ttotal: 38.6s\tremaining: 17.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3155:\tlearn: 1.9247489\ttotal: 38.6s\tremaining: 17.6s\n",
      "3156:\tlearn: 1.9246599\ttotal: 38.6s\tremaining: 17.6s\n",
      "3157:\tlearn: 1.9241186\ttotal: 38.6s\tremaining: 17.6s\n",
      "3158:\tlearn: 1.9239990\ttotal: 38.6s\tremaining: 17.6s\n",
      "3159:\tlearn: 1.9238787\ttotal: 38.7s\tremaining: 17.6s\n",
      "3160:\tlearn: 1.9237791\ttotal: 38.7s\tremaining: 17.6s\n",
      "3161:\tlearn: 1.9234217\ttotal: 38.7s\tremaining: 17.6s\n",
      "3162:\tlearn: 1.9231905\ttotal: 38.7s\tremaining: 17.6s\n",
      "3163:\tlearn: 1.9229649\ttotal: 38.7s\tremaining: 17.5s\n",
      "3164:\tlearn: 1.9228255\ttotal: 38.7s\tremaining: 17.5s\n",
      "3165:\tlearn: 1.9225216\ttotal: 38.7s\tremaining: 17.5s\n",
      "3166:\tlearn: 1.9221760\ttotal: 38.7s\tremaining: 17.5s\n",
      "3167:\tlearn: 1.9220334\ttotal: 38.8s\tremaining: 17.5s\n",
      "3168:\tlearn: 1.9218745\ttotal: 38.8s\tremaining: 17.5s\n",
      "3169:\tlearn: 1.9215666\ttotal: 38.8s\tremaining: 17.5s\n",
      "3170:\tlearn: 1.9212070\ttotal: 38.8s\tremaining: 17.5s\n",
      "3171:\tlearn: 1.9209181\ttotal: 38.8s\tremaining: 17.4s\n",
      "3172:\tlearn: 1.9207188\ttotal: 38.8s\tremaining: 17.4s\n",
      "3173:\tlearn: 1.9205754\ttotal: 38.8s\tremaining: 17.4s\n",
      "3174:\tlearn: 1.9203984\ttotal: 38.8s\tremaining: 17.4s\n",
      "3175:\tlearn: 1.9202576\ttotal: 38.9s\tremaining: 17.4s\n",
      "3176:\tlearn: 1.9201050\ttotal: 38.9s\tremaining: 17.4s\n",
      "3177:\tlearn: 1.9197401\ttotal: 38.9s\tremaining: 17.4s\n",
      "3178:\tlearn: 1.9194553\ttotal: 38.9s\tremaining: 17.4s\n",
      "3179:\tlearn: 1.9193101\ttotal: 38.9s\tremaining: 17.3s\n",
      "3180:\tlearn: 1.9189011\ttotal: 38.9s\tremaining: 17.3s\n",
      "3181:\tlearn: 1.9187985\ttotal: 38.9s\tremaining: 17.3s\n",
      "3182:\tlearn: 1.9185841\ttotal: 38.9s\tremaining: 17.3s\n",
      "3183:\tlearn: 1.9181932\ttotal: 38.9s\tremaining: 17.3s\n",
      "3184:\tlearn: 1.9179571\ttotal: 39s\tremaining: 17.3s\n",
      "3185:\tlearn: 1.9177661\ttotal: 39s\tremaining: 17.3s\n",
      "3186:\tlearn: 1.9172600\ttotal: 39s\tremaining: 17.3s\n",
      "3187:\tlearn: 1.9168563\ttotal: 39s\tremaining: 17.2s\n",
      "3188:\tlearn: 1.9163979\ttotal: 39s\tremaining: 17.2s\n",
      "3189:\tlearn: 1.9161992\ttotal: 39s\tremaining: 17.2s\n",
      "3190:\tlearn: 1.9158057\ttotal: 39s\tremaining: 17.2s\n",
      "3191:\tlearn: 1.9155946\ttotal: 39s\tremaining: 17.2s\n",
      "3192:\tlearn: 1.9154327\ttotal: 39.1s\tremaining: 17.2s\n",
      "3193:\tlearn: 1.9150709\ttotal: 39.1s\tremaining: 17.2s\n",
      "3194:\tlearn: 1.9149612\ttotal: 39.1s\tremaining: 17.2s\n",
      "3195:\tlearn: 1.9146331\ttotal: 39.1s\tremaining: 17.1s\n",
      "3196:\tlearn: 1.9145340\ttotal: 39.1s\tremaining: 17.1s\n",
      "3197:\tlearn: 1.9142273\ttotal: 39.1s\tremaining: 17.1s\n",
      "3198:\tlearn: 1.9140779\ttotal: 39.1s\tremaining: 17.1s\n",
      "3199:\tlearn: 1.9136418\ttotal: 39.1s\tremaining: 17.1s\n",
      "3200:\tlearn: 1.9134616\ttotal: 39.2s\tremaining: 17.1s\n",
      "3201:\tlearn: 1.9131252\ttotal: 39.2s\tremaining: 17.1s\n",
      "3202:\tlearn: 1.9129236\ttotal: 39.2s\tremaining: 17.1s\n",
      "3203:\tlearn: 1.9124839\ttotal: 39.2s\tremaining: 17.1s\n",
      "3204:\tlearn: 1.9121964\ttotal: 39.2s\tremaining: 17s\n",
      "3205:\tlearn: 1.9116428\ttotal: 39.2s\tremaining: 17s\n",
      "3206:\tlearn: 1.9114084\ttotal: 39.2s\tremaining: 17s\n",
      "3207:\tlearn: 1.9110640\ttotal: 39.2s\tremaining: 17s\n",
      "3208:\tlearn: 1.9107114\ttotal: 39.2s\tremaining: 17s\n",
      "3209:\tlearn: 1.9103027\ttotal: 39.3s\tremaining: 17s\n",
      "3210:\tlearn: 1.9098746\ttotal: 39.3s\tremaining: 17s\n",
      "3211:\tlearn: 1.9097098\ttotal: 39.3s\tremaining: 17s\n",
      "3212:\tlearn: 1.9095360\ttotal: 39.3s\tremaining: 16.9s\n",
      "3213:\tlearn: 1.9093245\ttotal: 39.3s\tremaining: 16.9s\n",
      "3214:\tlearn: 1.9091262\ttotal: 39.3s\tremaining: 16.9s\n",
      "3215:\tlearn: 1.9089351\ttotal: 39.3s\tremaining: 16.9s\n",
      "3216:\tlearn: 1.9085994\ttotal: 39.3s\tremaining: 16.9s\n",
      "3217:\tlearn: 1.9083689\ttotal: 39.4s\tremaining: 16.9s\n",
      "3218:\tlearn: 1.9080839\ttotal: 39.4s\tremaining: 16.9s\n",
      "3219:\tlearn: 1.9078325\ttotal: 39.4s\tremaining: 16.9s\n",
      "3220:\tlearn: 1.9075550\ttotal: 39.4s\tremaining: 16.8s\n",
      "3221:\tlearn: 1.9074221\ttotal: 39.4s\tremaining: 16.8s\n",
      "3222:\tlearn: 1.9071772\ttotal: 39.4s\tremaining: 16.8s\n",
      "3223:\tlearn: 1.9068721\ttotal: 39.4s\tremaining: 16.8s\n",
      "3224:\tlearn: 1.9065163\ttotal: 39.4s\tremaining: 16.8s\n",
      "3225:\tlearn: 1.9062578\ttotal: 39.5s\tremaining: 16.8s\n",
      "3226:\tlearn: 1.9061734\ttotal: 39.5s\tremaining: 16.8s\n",
      "3227:\tlearn: 1.9054604\ttotal: 39.5s\tremaining: 16.8s\n",
      "3228:\tlearn: 1.9053519\ttotal: 39.5s\tremaining: 16.7s\n",
      "3229:\tlearn: 1.9052333\ttotal: 39.5s\tremaining: 16.7s\n",
      "3230:\tlearn: 1.9049396\ttotal: 39.5s\tremaining: 16.7s\n",
      "3231:\tlearn: 1.9046673\ttotal: 39.5s\tremaining: 16.7s\n",
      "3232:\tlearn: 1.9044794\ttotal: 39.5s\tremaining: 16.7s\n",
      "3233:\tlearn: 1.9042168\ttotal: 39.6s\tremaining: 16.7s\n",
      "3234:\tlearn: 1.9040784\ttotal: 39.6s\tremaining: 16.7s\n",
      "3235:\tlearn: 1.9038773\ttotal: 39.6s\tremaining: 16.7s\n",
      "3236:\tlearn: 1.9032100\ttotal: 39.6s\tremaining: 16.6s\n",
      "3237:\tlearn: 1.9030020\ttotal: 39.6s\tremaining: 16.6s\n",
      "3238:\tlearn: 1.9027678\ttotal: 39.6s\tremaining: 16.6s\n",
      "3239:\tlearn: 1.9025587\ttotal: 39.6s\tremaining: 16.6s\n",
      "3240:\tlearn: 1.9021333\ttotal: 39.6s\tremaining: 16.6s\n",
      "3241:\tlearn: 1.9018924\ttotal: 39.6s\tremaining: 16.6s\n",
      "3242:\tlearn: 1.9016757\ttotal: 39.7s\tremaining: 16.6s\n",
      "3243:\tlearn: 1.9012512\ttotal: 39.7s\tremaining: 16.6s\n",
      "3244:\tlearn: 1.9009036\ttotal: 39.7s\tremaining: 16.5s\n",
      "3245:\tlearn: 1.9005723\ttotal: 39.7s\tremaining: 16.5s\n",
      "3246:\tlearn: 1.9004823\ttotal: 39.7s\tremaining: 16.5s\n",
      "3247:\tlearn: 1.9002026\ttotal: 39.7s\tremaining: 16.5s\n",
      "3248:\tlearn: 1.8999664\ttotal: 39.7s\tremaining: 16.5s\n",
      "3249:\tlearn: 1.8996929\ttotal: 39.8s\tremaining: 16.5s\n",
      "3250:\tlearn: 1.8993333\ttotal: 39.8s\tremaining: 16.5s\n",
      "3251:\tlearn: 1.8990294\ttotal: 39.8s\tremaining: 16.5s\n",
      "3252:\tlearn: 1.8990283\ttotal: 39.8s\tremaining: 16.4s\n",
      "3253:\tlearn: 1.8990082\ttotal: 39.8s\tremaining: 16.4s\n",
      "3254:\tlearn: 1.8987175\ttotal: 39.8s\tremaining: 16.4s\n",
      "3255:\tlearn: 1.8984513\ttotal: 39.8s\tremaining: 16.4s\n",
      "3256:\tlearn: 1.8982871\ttotal: 39.8s\tremaining: 16.4s\n",
      "3257:\tlearn: 1.8980398\ttotal: 39.8s\tremaining: 16.4s\n",
      "3258:\tlearn: 1.8978171\ttotal: 39.9s\tremaining: 16.4s\n",
      "3259:\tlearn: 1.8974974\ttotal: 39.9s\tremaining: 16.4s\n",
      "3260:\tlearn: 1.8973296\ttotal: 39.9s\tremaining: 16.4s\n",
      "3261:\tlearn: 1.8970709\ttotal: 39.9s\tremaining: 16.3s\n",
      "3262:\tlearn: 1.8968391\ttotal: 39.9s\tremaining: 16.3s\n",
      "3263:\tlearn: 1.8963977\ttotal: 39.9s\tremaining: 16.3s\n",
      "3264:\tlearn: 1.8960143\ttotal: 39.9s\tremaining: 16.3s\n",
      "3265:\tlearn: 1.8956325\ttotal: 39.9s\tremaining: 16.3s\n",
      "3266:\tlearn: 1.8954582\ttotal: 40s\tremaining: 16.3s\n",
      "3267:\tlearn: 1.8952242\ttotal: 40s\tremaining: 16.3s\n",
      "3268:\tlearn: 1.8949656\ttotal: 40s\tremaining: 16.3s\n",
      "3269:\tlearn: 1.8947303\ttotal: 40s\tremaining: 16.2s\n",
      "3270:\tlearn: 1.8943356\ttotal: 40s\tremaining: 16.2s\n",
      "3271:\tlearn: 1.8941097\ttotal: 40s\tremaining: 16.2s\n",
      "3272:\tlearn: 1.8938794\ttotal: 40s\tremaining: 16.2s\n",
      "3273:\tlearn: 1.8934341\ttotal: 40s\tremaining: 16.2s\n",
      "3274:\tlearn: 1.8930293\ttotal: 40.1s\tremaining: 16.2s\n",
      "3275:\tlearn: 1.8927143\ttotal: 40.1s\tremaining: 16.2s\n",
      "3276:\tlearn: 1.8922732\ttotal: 40.1s\tremaining: 16.2s\n",
      "3277:\tlearn: 1.8921013\ttotal: 40.1s\tremaining: 16.1s\n",
      "3278:\tlearn: 1.8917426\ttotal: 40.1s\tremaining: 16.1s\n",
      "3279:\tlearn: 1.8915236\ttotal: 40.1s\tremaining: 16.1s\n",
      "3280:\tlearn: 1.8912444\ttotal: 40.1s\tremaining: 16.1s\n",
      "3281:\tlearn: 1.8910919\ttotal: 40.1s\tremaining: 16.1s\n",
      "3282:\tlearn: 1.8908468\ttotal: 40.2s\tremaining: 16.1s\n",
      "3283:\tlearn: 1.8908024\ttotal: 40.2s\tremaining: 16.1s\n",
      "3284:\tlearn: 1.8907699\ttotal: 40.2s\tremaining: 16.1s\n",
      "3285:\tlearn: 1.8904218\ttotal: 40.2s\tremaining: 16s\n",
      "3286:\tlearn: 1.8902239\ttotal: 40.2s\tremaining: 16s\n",
      "3287:\tlearn: 1.8897222\ttotal: 40.2s\tremaining: 16s\n",
      "3288:\tlearn: 1.8895718\ttotal: 40.2s\tremaining: 16s\n",
      "3289:\tlearn: 1.8892967\ttotal: 40.2s\tremaining: 16s\n",
      "3290:\tlearn: 1.8890311\ttotal: 40.3s\tremaining: 16s\n",
      "3291:\tlearn: 1.8888825\ttotal: 40.3s\tremaining: 16s\n",
      "3292:\tlearn: 1.8884651\ttotal: 40.3s\tremaining: 16s\n",
      "3293:\tlearn: 1.8882448\ttotal: 40.3s\tremaining: 15.9s\n",
      "3294:\tlearn: 1.8879457\ttotal: 40.3s\tremaining: 15.9s\n",
      "3295:\tlearn: 1.8874003\ttotal: 40.3s\tremaining: 15.9s\n",
      "3296:\tlearn: 1.8871612\ttotal: 40.3s\tremaining: 15.9s\n",
      "3297:\tlearn: 1.8871322\ttotal: 40.3s\tremaining: 15.9s\n",
      "3298:\tlearn: 1.8867529\ttotal: 40.4s\tremaining: 15.9s\n",
      "3299:\tlearn: 1.8864933\ttotal: 40.4s\tremaining: 15.9s\n",
      "3300:\tlearn: 1.8861414\ttotal: 40.4s\tremaining: 15.9s\n",
      "3301:\tlearn: 1.8858836\ttotal: 40.4s\tremaining: 15.9s\n",
      "3302:\tlearn: 1.8855109\ttotal: 40.4s\tremaining: 15.8s\n",
      "3303:\tlearn: 1.8853086\ttotal: 40.4s\tremaining: 15.8s\n",
      "3304:\tlearn: 1.8850583\ttotal: 40.4s\tremaining: 15.8s\n",
      "3305:\tlearn: 1.8847014\ttotal: 40.4s\tremaining: 15.8s\n",
      "3306:\tlearn: 1.8842416\ttotal: 40.4s\tremaining: 15.8s\n",
      "3307:\tlearn: 1.8838901\ttotal: 40.5s\tremaining: 15.8s\n",
      "3308:\tlearn: 1.8837931\ttotal: 40.5s\tremaining: 15.8s\n",
      "3309:\tlearn: 1.8833327\ttotal: 40.5s\tremaining: 15.8s\n",
      "3310:\tlearn: 1.8832521\ttotal: 40.5s\tremaining: 15.7s\n",
      "3311:\tlearn: 1.8829347\ttotal: 40.5s\tremaining: 15.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3312:\tlearn: 1.8826787\ttotal: 40.5s\tremaining: 15.7s\n",
      "3313:\tlearn: 1.8826228\ttotal: 40.5s\tremaining: 15.7s\n",
      "3314:\tlearn: 1.8825177\ttotal: 40.5s\tremaining: 15.7s\n",
      "3315:\tlearn: 1.8823237\ttotal: 40.6s\tremaining: 15.7s\n",
      "3316:\tlearn: 1.8819656\ttotal: 40.6s\tremaining: 15.7s\n",
      "3317:\tlearn: 1.8819150\ttotal: 40.6s\tremaining: 15.7s\n",
      "3318:\tlearn: 1.8816704\ttotal: 40.6s\tremaining: 15.6s\n",
      "3319:\tlearn: 1.8814057\ttotal: 40.6s\tremaining: 15.6s\n",
      "3320:\tlearn: 1.8811748\ttotal: 40.6s\tremaining: 15.6s\n",
      "3321:\tlearn: 1.8809089\ttotal: 40.6s\tremaining: 15.6s\n",
      "3322:\tlearn: 1.8809080\ttotal: 40.6s\tremaining: 15.6s\n",
      "3323:\tlearn: 1.8809071\ttotal: 40.7s\tremaining: 15.6s\n",
      "3324:\tlearn: 1.8805206\ttotal: 40.7s\tremaining: 15.6s\n",
      "3325:\tlearn: 1.8803251\ttotal: 40.7s\tremaining: 15.6s\n",
      "3326:\tlearn: 1.8800431\ttotal: 40.7s\tremaining: 15.5s\n",
      "3327:\tlearn: 1.8797551\ttotal: 40.7s\tremaining: 15.5s\n",
      "3328:\tlearn: 1.8795999\ttotal: 40.7s\tremaining: 15.5s\n",
      "3329:\tlearn: 1.8791024\ttotal: 40.7s\tremaining: 15.5s\n",
      "3330:\tlearn: 1.8789568\ttotal: 40.7s\tremaining: 15.5s\n",
      "3331:\tlearn: 1.8783746\ttotal: 40.8s\tremaining: 15.5s\n",
      "3332:\tlearn: 1.8782066\ttotal: 40.8s\tremaining: 15.5s\n",
      "3333:\tlearn: 1.8780048\ttotal: 40.8s\tremaining: 15.5s\n",
      "3334:\tlearn: 1.8777066\ttotal: 40.8s\tremaining: 15.4s\n",
      "3335:\tlearn: 1.8773828\ttotal: 40.8s\tremaining: 15.4s\n",
      "3336:\tlearn: 1.8769958\ttotal: 40.8s\tremaining: 15.4s\n",
      "3337:\tlearn: 1.8767194\ttotal: 40.8s\tremaining: 15.4s\n",
      "3338:\tlearn: 1.8766070\ttotal: 40.8s\tremaining: 15.4s\n",
      "3339:\tlearn: 1.8763880\ttotal: 40.8s\tremaining: 15.4s\n",
      "3340:\tlearn: 1.8761596\ttotal: 40.9s\tremaining: 15.4s\n",
      "3341:\tlearn: 1.8760733\ttotal: 40.9s\tremaining: 15.4s\n",
      "3342:\tlearn: 1.8758952\ttotal: 40.9s\tremaining: 15.3s\n",
      "3343:\tlearn: 1.8756648\ttotal: 40.9s\tremaining: 15.3s\n",
      "3344:\tlearn: 1.8754334\ttotal: 40.9s\tremaining: 15.3s\n",
      "3345:\tlearn: 1.8749753\ttotal: 40.9s\tremaining: 15.3s\n",
      "3346:\tlearn: 1.8746464\ttotal: 40.9s\tremaining: 15.3s\n",
      "3347:\tlearn: 1.8742977\ttotal: 40.9s\tremaining: 15.3s\n",
      "3348:\tlearn: 1.8740038\ttotal: 41s\tremaining: 15.3s\n",
      "3349:\tlearn: 1.8736764\ttotal: 41s\tremaining: 15.3s\n",
      "3350:\tlearn: 1.8732662\ttotal: 41s\tremaining: 15.2s\n",
      "3351:\tlearn: 1.8730117\ttotal: 41s\tremaining: 15.2s\n",
      "3352:\tlearn: 1.8727498\ttotal: 41s\tremaining: 15.2s\n",
      "3353:\tlearn: 1.8723087\ttotal: 41s\tremaining: 15.2s\n",
      "3354:\tlearn: 1.8720167\ttotal: 41s\tremaining: 15.2s\n",
      "3355:\tlearn: 1.8719403\ttotal: 41s\tremaining: 15.2s\n",
      "3356:\tlearn: 1.8715934\ttotal: 41s\tremaining: 15.2s\n",
      "3357:\tlearn: 1.8713309\ttotal: 41.1s\tremaining: 15.2s\n",
      "3358:\tlearn: 1.8711493\ttotal: 41.1s\tremaining: 15.1s\n",
      "3359:\tlearn: 1.8710995\ttotal: 41.1s\tremaining: 15.1s\n",
      "3360:\tlearn: 1.8709117\ttotal: 41.1s\tremaining: 15.1s\n",
      "3361:\tlearn: 1.8706925\ttotal: 41.1s\tremaining: 15.1s\n",
      "3362:\tlearn: 1.8704936\ttotal: 41.1s\tremaining: 15.1s\n",
      "3363:\tlearn: 1.8701778\ttotal: 41.1s\tremaining: 15.1s\n",
      "3364:\tlearn: 1.8700744\ttotal: 41.1s\tremaining: 15.1s\n",
      "3365:\tlearn: 1.8699132\ttotal: 41.2s\tremaining: 15.1s\n",
      "3366:\tlearn: 1.8695682\ttotal: 41.2s\tremaining: 15.1s\n",
      "3367:\tlearn: 1.8693154\ttotal: 41.2s\tremaining: 15s\n",
      "3368:\tlearn: 1.8690505\ttotal: 41.2s\tremaining: 15s\n",
      "3369:\tlearn: 1.8687625\ttotal: 41.2s\tremaining: 15s\n",
      "3370:\tlearn: 1.8685816\ttotal: 41.2s\tremaining: 15s\n",
      "3371:\tlearn: 1.8685086\ttotal: 41.2s\tremaining: 15s\n",
      "3372:\tlearn: 1.8682866\ttotal: 41.2s\tremaining: 15s\n",
      "3373:\tlearn: 1.8680541\ttotal: 41.3s\tremaining: 15s\n",
      "3374:\tlearn: 1.8678504\ttotal: 41.3s\tremaining: 15s\n",
      "3375:\tlearn: 1.8676466\ttotal: 41.3s\tremaining: 14.9s\n",
      "3376:\tlearn: 1.8673205\ttotal: 41.3s\tremaining: 14.9s\n",
      "3377:\tlearn: 1.8671908\ttotal: 41.3s\tremaining: 14.9s\n",
      "3378:\tlearn: 1.8670654\ttotal: 41.3s\tremaining: 14.9s\n",
      "3379:\tlearn: 1.8668872\ttotal: 41.3s\tremaining: 14.9s\n",
      "3380:\tlearn: 1.8666758\ttotal: 41.3s\tremaining: 14.9s\n",
      "3381:\tlearn: 1.8665761\ttotal: 41.4s\tremaining: 14.9s\n",
      "3382:\tlearn: 1.8663692\ttotal: 41.4s\tremaining: 14.9s\n",
      "3383:\tlearn: 1.8661632\ttotal: 41.4s\tremaining: 14.8s\n",
      "3384:\tlearn: 1.8658280\ttotal: 41.4s\tremaining: 14.8s\n",
      "3385:\tlearn: 1.8654243\ttotal: 41.4s\tremaining: 14.8s\n",
      "3386:\tlearn: 1.8651327\ttotal: 41.4s\tremaining: 14.8s\n",
      "3387:\tlearn: 1.8649613\ttotal: 41.4s\tremaining: 14.8s\n",
      "3388:\tlearn: 1.8647560\ttotal: 41.5s\tremaining: 14.8s\n",
      "3389:\tlearn: 1.8645658\ttotal: 41.5s\tremaining: 14.8s\n",
      "3390:\tlearn: 1.8641675\ttotal: 41.5s\tremaining: 14.8s\n",
      "3391:\tlearn: 1.8637075\ttotal: 41.5s\tremaining: 14.8s\n",
      "3392:\tlearn: 1.8634867\ttotal: 41.5s\tremaining: 14.7s\n",
      "3393:\tlearn: 1.8632485\ttotal: 41.5s\tremaining: 14.7s\n",
      "3394:\tlearn: 1.8628004\ttotal: 41.5s\tremaining: 14.7s\n",
      "3395:\tlearn: 1.8626062\ttotal: 41.5s\tremaining: 14.7s\n",
      "3396:\tlearn: 1.8623782\ttotal: 41.5s\tremaining: 14.7s\n",
      "3397:\tlearn: 1.8621028\ttotal: 41.6s\tremaining: 14.7s\n",
      "3398:\tlearn: 1.8617763\ttotal: 41.6s\tremaining: 14.7s\n",
      "3399:\tlearn: 1.8616079\ttotal: 41.6s\tremaining: 14.7s\n",
      "3400:\tlearn: 1.8614804\ttotal: 41.6s\tremaining: 14.6s\n",
      "3401:\tlearn: 1.8611773\ttotal: 41.6s\tremaining: 14.6s\n",
      "3402:\tlearn: 1.8610454\ttotal: 41.6s\tremaining: 14.6s\n",
      "3403:\tlearn: 1.8608329\ttotal: 41.6s\tremaining: 14.6s\n",
      "3404:\tlearn: 1.8605667\ttotal: 41.6s\tremaining: 14.6s\n",
      "3405:\tlearn: 1.8601323\ttotal: 41.7s\tremaining: 14.6s\n",
      "3406:\tlearn: 1.8599623\ttotal: 41.7s\tremaining: 14.6s\n",
      "3407:\tlearn: 1.8596741\ttotal: 41.7s\tremaining: 14.6s\n",
      "3408:\tlearn: 1.8593488\ttotal: 41.7s\tremaining: 14.5s\n",
      "3409:\tlearn: 1.8591474\ttotal: 41.7s\tremaining: 14.5s\n",
      "3410:\tlearn: 1.8590305\ttotal: 41.7s\tremaining: 14.5s\n",
      "3411:\tlearn: 1.8587357\ttotal: 41.7s\tremaining: 14.5s\n",
      "3412:\tlearn: 1.8581151\ttotal: 41.7s\tremaining: 14.5s\n",
      "3413:\tlearn: 1.8579476\ttotal: 41.8s\tremaining: 14.5s\n",
      "3414:\tlearn: 1.8576803\ttotal: 41.8s\tremaining: 14.5s\n",
      "3415:\tlearn: 1.8574462\ttotal: 41.8s\tremaining: 14.5s\n",
      "3416:\tlearn: 1.8568376\ttotal: 41.8s\tremaining: 14.4s\n",
      "3417:\tlearn: 1.8563841\ttotal: 41.8s\tremaining: 14.4s\n",
      "3418:\tlearn: 1.8561636\ttotal: 41.8s\tremaining: 14.4s\n",
      "3419:\tlearn: 1.8558736\ttotal: 41.8s\tremaining: 14.4s\n",
      "3420:\tlearn: 1.8555343\ttotal: 41.8s\tremaining: 14.4s\n",
      "3421:\tlearn: 1.8552035\ttotal: 41.9s\tremaining: 14.4s\n",
      "3422:\tlearn: 1.8550627\ttotal: 41.9s\tremaining: 14.4s\n",
      "3423:\tlearn: 1.8549232\ttotal: 41.9s\tremaining: 14.4s\n",
      "3424:\tlearn: 1.8546238\ttotal: 41.9s\tremaining: 14.3s\n",
      "3425:\tlearn: 1.8542928\ttotal: 41.9s\tremaining: 14.3s\n",
      "3426:\tlearn: 1.8539236\ttotal: 41.9s\tremaining: 14.3s\n",
      "3427:\tlearn: 1.8534427\ttotal: 41.9s\tremaining: 14.3s\n",
      "3428:\tlearn: 1.8533485\ttotal: 41.9s\tremaining: 14.3s\n",
      "3429:\tlearn: 1.8532028\ttotal: 42s\tremaining: 14.3s\n",
      "3430:\tlearn: 1.8529355\ttotal: 42s\tremaining: 14.3s\n",
      "3431:\tlearn: 1.8526779\ttotal: 42s\tremaining: 14.3s\n",
      "3432:\tlearn: 1.8524683\ttotal: 42s\tremaining: 14.3s\n",
      "3433:\tlearn: 1.8522210\ttotal: 42s\tremaining: 14.2s\n",
      "3434:\tlearn: 1.8520659\ttotal: 42s\tremaining: 14.2s\n",
      "3435:\tlearn: 1.8518950\ttotal: 42s\tremaining: 14.2s\n",
      "3436:\tlearn: 1.8516752\ttotal: 42s\tremaining: 14.2s\n",
      "3437:\tlearn: 1.8515108\ttotal: 42.1s\tremaining: 14.2s\n",
      "3438:\tlearn: 1.8513468\ttotal: 42.1s\tremaining: 14.2s\n",
      "3439:\tlearn: 1.8507695\ttotal: 42.1s\tremaining: 14.2s\n",
      "3440:\tlearn: 1.8505455\ttotal: 42.1s\tremaining: 14.2s\n",
      "3441:\tlearn: 1.8503210\ttotal: 42.1s\tremaining: 14.1s\n",
      "3442:\tlearn: 1.8499796\ttotal: 42.1s\tremaining: 14.1s\n",
      "3443:\tlearn: 1.8497757\ttotal: 42.1s\tremaining: 14.1s\n",
      "3444:\tlearn: 1.8496011\ttotal: 42.2s\tremaining: 14.1s\n",
      "3445:\tlearn: 1.8492944\ttotal: 42.2s\tremaining: 14.1s\n",
      "3446:\tlearn: 1.8492812\ttotal: 42.2s\tremaining: 14.1s\n",
      "3447:\tlearn: 1.8489165\ttotal: 42.2s\tremaining: 14.1s\n",
      "3448:\tlearn: 1.8484355\ttotal: 42.2s\tremaining: 14.1s\n",
      "3449:\tlearn: 1.8482644\ttotal: 42.2s\tremaining: 14.1s\n",
      "3450:\tlearn: 1.8478906\ttotal: 42.3s\tremaining: 14s\n",
      "3451:\tlearn: 1.8476974\ttotal: 42.3s\tremaining: 14s\n",
      "3452:\tlearn: 1.8475448\ttotal: 42.3s\tremaining: 14s\n",
      "3453:\tlearn: 1.8469441\ttotal: 42.3s\tremaining: 14s\n",
      "3454:\tlearn: 1.8465248\ttotal: 42.3s\tremaining: 14s\n",
      "3455:\tlearn: 1.8463278\ttotal: 42.3s\tremaining: 14s\n",
      "3456:\tlearn: 1.8461211\ttotal: 42.3s\tremaining: 14s\n",
      "3457:\tlearn: 1.8459226\ttotal: 42.4s\tremaining: 14s\n",
      "3458:\tlearn: 1.8455668\ttotal: 42.4s\tremaining: 14s\n",
      "3459:\tlearn: 1.8453417\ttotal: 42.4s\tremaining: 13.9s\n",
      "3460:\tlearn: 1.8451422\ttotal: 42.4s\tremaining: 13.9s\n",
      "3461:\tlearn: 1.8448799\ttotal: 42.4s\tremaining: 13.9s\n",
      "3462:\tlearn: 1.8446250\ttotal: 42.4s\tremaining: 13.9s\n",
      "3463:\tlearn: 1.8443008\ttotal: 42.4s\tremaining: 13.9s\n",
      "3464:\tlearn: 1.8439122\ttotal: 42.5s\tremaining: 13.9s\n",
      "3465:\tlearn: 1.8434767\ttotal: 42.5s\tremaining: 13.9s\n",
      "3466:\tlearn: 1.8431712\ttotal: 42.5s\tremaining: 13.9s\n",
      "3467:\tlearn: 1.8429463\ttotal: 42.5s\tremaining: 13.8s\n",
      "3468:\tlearn: 1.8423576\ttotal: 42.5s\tremaining: 13.8s\n",
      "3469:\tlearn: 1.8420926\ttotal: 42.5s\tremaining: 13.8s\n",
      "3470:\tlearn: 1.8418053\ttotal: 42.5s\tremaining: 13.8s\n",
      "3471:\tlearn: 1.8413992\ttotal: 42.5s\tremaining: 13.8s\n",
      "3472:\tlearn: 1.8409255\ttotal: 42.6s\tremaining: 13.8s\n",
      "3473:\tlearn: 1.8407881\ttotal: 42.6s\tremaining: 13.8s\n",
      "3474:\tlearn: 1.8403146\ttotal: 42.6s\tremaining: 13.8s\n",
      "3475:\tlearn: 1.8401514\ttotal: 42.6s\tremaining: 13.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3476:\tlearn: 1.8398072\ttotal: 42.6s\tremaining: 13.7s\n",
      "3477:\tlearn: 1.8395717\ttotal: 42.6s\tremaining: 13.7s\n",
      "3478:\tlearn: 1.8393370\ttotal: 42.6s\tremaining: 13.7s\n",
      "3479:\tlearn: 1.8390917\ttotal: 42.6s\tremaining: 13.7s\n",
      "3480:\tlearn: 1.8386305\ttotal: 42.7s\tremaining: 13.7s\n",
      "3481:\tlearn: 1.8384629\ttotal: 42.7s\tremaining: 13.7s\n",
      "3482:\tlearn: 1.8383997\ttotal: 42.7s\tremaining: 13.7s\n",
      "3483:\tlearn: 1.8381364\ttotal: 42.7s\tremaining: 13.7s\n",
      "3484:\tlearn: 1.8377546\ttotal: 42.7s\tremaining: 13.6s\n",
      "3485:\tlearn: 1.8373377\ttotal: 42.7s\tremaining: 13.6s\n",
      "3486:\tlearn: 1.8371439\ttotal: 42.7s\tremaining: 13.6s\n",
      "3487:\tlearn: 1.8368278\ttotal: 42.7s\tremaining: 13.6s\n",
      "3488:\tlearn: 1.8366390\ttotal: 42.8s\tremaining: 13.6s\n",
      "3489:\tlearn: 1.8363280\ttotal: 42.8s\tremaining: 13.6s\n",
      "3490:\tlearn: 1.8361082\ttotal: 42.8s\tremaining: 13.6s\n",
      "3491:\tlearn: 1.8359389\ttotal: 42.8s\tremaining: 13.6s\n",
      "3492:\tlearn: 1.8356243\ttotal: 42.8s\tremaining: 13.5s\n",
      "3493:\tlearn: 1.8351967\ttotal: 42.8s\tremaining: 13.5s\n",
      "3494:\tlearn: 1.8347560\ttotal: 42.8s\tremaining: 13.5s\n",
      "3495:\tlearn: 1.8341384\ttotal: 42.8s\tremaining: 13.5s\n",
      "3496:\tlearn: 1.8340582\ttotal: 42.9s\tremaining: 13.5s\n",
      "3497:\tlearn: 1.8338444\ttotal: 42.9s\tremaining: 13.5s\n",
      "3498:\tlearn: 1.8334864\ttotal: 42.9s\tremaining: 13.5s\n",
      "3499:\tlearn: 1.8330849\ttotal: 42.9s\tremaining: 13.5s\n",
      "3500:\tlearn: 1.8325735\ttotal: 42.9s\tremaining: 13.4s\n",
      "3501:\tlearn: 1.8323229\ttotal: 42.9s\tremaining: 13.4s\n",
      "3502:\tlearn: 1.8320617\ttotal: 42.9s\tremaining: 13.4s\n",
      "3503:\tlearn: 1.8318664\ttotal: 42.9s\tremaining: 13.4s\n",
      "3504:\tlearn: 1.8317201\ttotal: 42.9s\tremaining: 13.4s\n",
      "3505:\tlearn: 1.8314878\ttotal: 43s\tremaining: 13.4s\n",
      "3506:\tlearn: 1.8311903\ttotal: 43s\tremaining: 13.4s\n",
      "3507:\tlearn: 1.8308178\ttotal: 43s\tremaining: 13.4s\n",
      "3508:\tlearn: 1.8306149\ttotal: 43s\tremaining: 13.3s\n",
      "3509:\tlearn: 1.8304473\ttotal: 43s\tremaining: 13.3s\n",
      "3510:\tlearn: 1.8302746\ttotal: 43s\tremaining: 13.3s\n",
      "3511:\tlearn: 1.8301392\ttotal: 43s\tremaining: 13.3s\n",
      "3512:\tlearn: 1.8301228\ttotal: 43s\tremaining: 13.3s\n",
      "3513:\tlearn: 1.8297440\ttotal: 43.1s\tremaining: 13.3s\n",
      "3514:\tlearn: 1.8294441\ttotal: 43.1s\tremaining: 13.3s\n",
      "3515:\tlearn: 1.8291083\ttotal: 43.1s\tremaining: 13.3s\n",
      "3516:\tlearn: 1.8287279\ttotal: 43.1s\tremaining: 13.2s\n",
      "3517:\tlearn: 1.8285656\ttotal: 43.1s\tremaining: 13.2s\n",
      "3518:\tlearn: 1.8284449\ttotal: 43.1s\tremaining: 13.2s\n",
      "3519:\tlearn: 1.8281219\ttotal: 43.1s\tremaining: 13.2s\n",
      "3520:\tlearn: 1.8278480\ttotal: 43.1s\tremaining: 13.2s\n",
      "3521:\tlearn: 1.8274954\ttotal: 43.2s\tremaining: 13.2s\n",
      "3522:\tlearn: 1.8270346\ttotal: 43.2s\tremaining: 13.2s\n",
      "3523:\tlearn: 1.8268346\ttotal: 43.2s\tremaining: 13.2s\n",
      "3524:\tlearn: 1.8266739\ttotal: 43.2s\tremaining: 13.1s\n",
      "3525:\tlearn: 1.8260809\ttotal: 43.2s\tremaining: 13.1s\n",
      "3526:\tlearn: 1.8259574\ttotal: 43.2s\tremaining: 13.1s\n",
      "3527:\tlearn: 1.8256428\ttotal: 43.2s\tremaining: 13.1s\n",
      "3528:\tlearn: 1.8256418\ttotal: 43.2s\tremaining: 13.1s\n",
      "3529:\tlearn: 1.8251736\ttotal: 43.3s\tremaining: 13.1s\n",
      "3530:\tlearn: 1.8250059\ttotal: 43.3s\tremaining: 13.1s\n",
      "3531:\tlearn: 1.8247661\ttotal: 43.3s\tremaining: 13.1s\n",
      "3532:\tlearn: 1.8245832\ttotal: 43.3s\tremaining: 13.1s\n",
      "3533:\tlearn: 1.8245522\ttotal: 43.3s\tremaining: 13s\n",
      "3534:\tlearn: 1.8242894\ttotal: 43.3s\tremaining: 13s\n",
      "3535:\tlearn: 1.8237513\ttotal: 43.3s\tremaining: 13s\n",
      "3536:\tlearn: 1.8234711\ttotal: 43.3s\tremaining: 13s\n",
      "3537:\tlearn: 1.8234265\ttotal: 43.4s\tremaining: 13s\n",
      "3538:\tlearn: 1.8231378\ttotal: 43.4s\tremaining: 13s\n",
      "3539:\tlearn: 1.8230366\ttotal: 43.4s\tremaining: 13s\n",
      "3540:\tlearn: 1.8226992\ttotal: 43.4s\tremaining: 13s\n",
      "3541:\tlearn: 1.8225090\ttotal: 43.4s\tremaining: 12.9s\n",
      "3542:\tlearn: 1.8222352\ttotal: 43.4s\tremaining: 12.9s\n",
      "3543:\tlearn: 1.8219708\ttotal: 43.4s\tremaining: 12.9s\n",
      "3544:\tlearn: 1.8217139\ttotal: 43.5s\tremaining: 12.9s\n",
      "3545:\tlearn: 1.8213618\ttotal: 43.5s\tremaining: 12.9s\n",
      "3546:\tlearn: 1.8210167\ttotal: 43.5s\tremaining: 12.9s\n",
      "3547:\tlearn: 1.8207429\ttotal: 43.5s\tremaining: 12.9s\n",
      "3548:\tlearn: 1.8205018\ttotal: 43.5s\tremaining: 12.9s\n",
      "3549:\tlearn: 1.8202560\ttotal: 43.5s\tremaining: 12.8s\n",
      "3550:\tlearn: 1.8200818\ttotal: 43.5s\tremaining: 12.8s\n",
      "3551:\tlearn: 1.8199688\ttotal: 43.5s\tremaining: 12.8s\n",
      "3552:\tlearn: 1.8196750\ttotal: 43.6s\tremaining: 12.8s\n",
      "3553:\tlearn: 1.8193539\ttotal: 43.6s\tremaining: 12.8s\n",
      "3554:\tlearn: 1.8192427\ttotal: 43.6s\tremaining: 12.8s\n",
      "3555:\tlearn: 1.8187410\ttotal: 43.6s\tremaining: 12.8s\n",
      "3556:\tlearn: 1.8185612\ttotal: 43.6s\tremaining: 12.8s\n",
      "3557:\tlearn: 1.8182935\ttotal: 43.6s\tremaining: 12.7s\n",
      "3558:\tlearn: 1.8180499\ttotal: 43.6s\tremaining: 12.7s\n",
      "3559:\tlearn: 1.8177841\ttotal: 43.6s\tremaining: 12.7s\n",
      "3560:\tlearn: 1.8173442\ttotal: 43.6s\tremaining: 12.7s\n",
      "3561:\tlearn: 1.8170964\ttotal: 43.7s\tremaining: 12.7s\n",
      "3562:\tlearn: 1.8168629\ttotal: 43.7s\tremaining: 12.7s\n",
      "3563:\tlearn: 1.8167831\ttotal: 43.7s\tremaining: 12.7s\n",
      "3564:\tlearn: 1.8165646\ttotal: 43.7s\tremaining: 12.7s\n",
      "3565:\tlearn: 1.8161673\ttotal: 43.7s\tremaining: 12.7s\n",
      "3566:\tlearn: 1.8160046\ttotal: 43.7s\tremaining: 12.6s\n",
      "3567:\tlearn: 1.8158439\ttotal: 43.7s\tremaining: 12.6s\n",
      "3568:\tlearn: 1.8156203\ttotal: 43.7s\tremaining: 12.6s\n",
      "3569:\tlearn: 1.8154232\ttotal: 43.8s\tremaining: 12.6s\n",
      "3570:\tlearn: 1.8151913\ttotal: 43.8s\tremaining: 12.6s\n",
      "3571:\tlearn: 1.8147388\ttotal: 43.8s\tremaining: 12.6s\n",
      "3572:\tlearn: 1.8143607\ttotal: 43.8s\tremaining: 12.6s\n",
      "3573:\tlearn: 1.8140461\ttotal: 43.8s\tremaining: 12.6s\n",
      "3574:\tlearn: 1.8137993\ttotal: 43.8s\tremaining: 12.5s\n",
      "3575:\tlearn: 1.8136811\ttotal: 43.8s\tremaining: 12.5s\n",
      "3576:\tlearn: 1.8134831\ttotal: 43.8s\tremaining: 12.5s\n",
      "3577:\tlearn: 1.8129322\ttotal: 43.9s\tremaining: 12.5s\n",
      "3578:\tlearn: 1.8127314\ttotal: 43.9s\tremaining: 12.5s\n",
      "3579:\tlearn: 1.8125415\ttotal: 43.9s\tremaining: 12.5s\n",
      "3580:\tlearn: 1.8121564\ttotal: 43.9s\tremaining: 12.5s\n",
      "3581:\tlearn: 1.8117434\ttotal: 43.9s\tremaining: 12.5s\n",
      "3582:\tlearn: 1.8115486\ttotal: 43.9s\tremaining: 12.4s\n",
      "3583:\tlearn: 1.8110663\ttotal: 43.9s\tremaining: 12.4s\n",
      "3584:\tlearn: 1.8109342\ttotal: 43.9s\tremaining: 12.4s\n",
      "3585:\tlearn: 1.8107952\ttotal: 43.9s\tremaining: 12.4s\n",
      "3586:\tlearn: 1.8104305\ttotal: 44s\tremaining: 12.4s\n",
      "3587:\tlearn: 1.8102415\ttotal: 44s\tremaining: 12.4s\n",
      "3588:\tlearn: 1.8100830\ttotal: 44s\tremaining: 12.4s\n",
      "3589:\tlearn: 1.8098874\ttotal: 44s\tremaining: 12.4s\n",
      "3590:\tlearn: 1.8096533\ttotal: 44s\tremaining: 12.3s\n",
      "3591:\tlearn: 1.8095284\ttotal: 44s\tremaining: 12.3s\n",
      "3592:\tlearn: 1.8092799\ttotal: 44s\tremaining: 12.3s\n",
      "3593:\tlearn: 1.8089423\ttotal: 44s\tremaining: 12.3s\n",
      "3594:\tlearn: 1.8085481\ttotal: 44.1s\tremaining: 12.3s\n",
      "3595:\tlearn: 1.8082916\ttotal: 44.1s\tremaining: 12.3s\n",
      "3596:\tlearn: 1.8080130\ttotal: 44.1s\tremaining: 12.3s\n",
      "3597:\tlearn: 1.8074840\ttotal: 44.1s\tremaining: 12.3s\n",
      "3598:\tlearn: 1.8071248\ttotal: 44.1s\tremaining: 12.2s\n",
      "3599:\tlearn: 1.8068893\ttotal: 44.1s\tremaining: 12.2s\n",
      "3600:\tlearn: 1.8065393\ttotal: 44.1s\tremaining: 12.2s\n",
      "3601:\tlearn: 1.8062620\ttotal: 44.1s\tremaining: 12.2s\n",
      "3602:\tlearn: 1.8059897\ttotal: 44.2s\tremaining: 12.2s\n",
      "3603:\tlearn: 1.8058009\ttotal: 44.2s\tremaining: 12.2s\n",
      "3604:\tlearn: 1.8056065\ttotal: 44.2s\tremaining: 12.2s\n",
      "3605:\tlearn: 1.8053814\ttotal: 44.2s\tremaining: 12.2s\n",
      "3606:\tlearn: 1.8052878\ttotal: 44.2s\tremaining: 12.1s\n",
      "3607:\tlearn: 1.8051267\ttotal: 44.2s\tremaining: 12.1s\n",
      "3608:\tlearn: 1.8051258\ttotal: 44.2s\tremaining: 12.1s\n",
      "3609:\tlearn: 1.8049087\ttotal: 44.2s\tremaining: 12.1s\n",
      "3610:\tlearn: 1.8049080\ttotal: 44.2s\tremaining: 12.1s\n",
      "3611:\tlearn: 1.8045311\ttotal: 44.3s\tremaining: 12.1s\n",
      "3612:\tlearn: 1.8043872\ttotal: 44.3s\tremaining: 12.1s\n",
      "3613:\tlearn: 1.8040649\ttotal: 44.3s\tremaining: 12.1s\n",
      "3614:\tlearn: 1.8036661\ttotal: 44.3s\tremaining: 12s\n",
      "3615:\tlearn: 1.8034467\ttotal: 44.3s\tremaining: 12s\n",
      "3616:\tlearn: 1.8032825\ttotal: 44.3s\tremaining: 12s\n",
      "3617:\tlearn: 1.8029598\ttotal: 44.3s\tremaining: 12s\n",
      "3618:\tlearn: 1.8026765\ttotal: 44.3s\tremaining: 12s\n",
      "3619:\tlearn: 1.8024402\ttotal: 44.4s\tremaining: 12s\n",
      "3620:\tlearn: 1.8021579\ttotal: 44.4s\tremaining: 12s\n",
      "3621:\tlearn: 1.8017035\ttotal: 44.4s\tremaining: 12s\n",
      "3622:\tlearn: 1.8015096\ttotal: 44.4s\tremaining: 11.9s\n",
      "3623:\tlearn: 1.8011281\ttotal: 44.4s\tremaining: 11.9s\n",
      "3624:\tlearn: 1.8009349\ttotal: 44.4s\tremaining: 11.9s\n",
      "3625:\tlearn: 1.8004587\ttotal: 44.4s\tremaining: 11.9s\n",
      "3626:\tlearn: 1.8002521\ttotal: 44.5s\tremaining: 11.9s\n",
      "3627:\tlearn: 1.8001479\ttotal: 44.5s\tremaining: 11.9s\n",
      "3628:\tlearn: 1.7998121\ttotal: 44.5s\tremaining: 11.9s\n",
      "3629:\tlearn: 1.7996032\ttotal: 44.5s\tremaining: 11.9s\n",
      "3630:\tlearn: 1.7993009\ttotal: 44.5s\tremaining: 11.9s\n",
      "3631:\tlearn: 1.7992369\ttotal: 44.5s\tremaining: 11.8s\n",
      "3632:\tlearn: 1.7989542\ttotal: 44.5s\tremaining: 11.8s\n",
      "3633:\tlearn: 1.7988021\ttotal: 44.5s\tremaining: 11.8s\n",
      "3634:\tlearn: 1.7984307\ttotal: 44.6s\tremaining: 11.8s\n",
      "3635:\tlearn: 1.7981244\ttotal: 44.6s\tremaining: 11.8s\n",
      "3636:\tlearn: 1.7977874\ttotal: 44.6s\tremaining: 11.8s\n",
      "3637:\tlearn: 1.7974748\ttotal: 44.6s\tremaining: 11.8s\n",
      "3638:\tlearn: 1.7970629\ttotal: 44.6s\tremaining: 11.8s\n",
      "3639:\tlearn: 1.7967552\ttotal: 44.6s\tremaining: 11.7s\n",
      "3640:\tlearn: 1.7965854\ttotal: 44.6s\tremaining: 11.7s\n",
      "3641:\tlearn: 1.7964678\ttotal: 44.6s\tremaining: 11.7s\n",
      "3642:\tlearn: 1.7964671\ttotal: 44.6s\tremaining: 11.7s\n",
      "3643:\tlearn: 1.7964240\ttotal: 44.7s\tremaining: 11.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3644:\tlearn: 1.7960989\ttotal: 44.7s\tremaining: 11.7s\n",
      "3645:\tlearn: 1.7960982\ttotal: 44.7s\tremaining: 11.7s\n",
      "3646:\tlearn: 1.7958344\ttotal: 44.7s\tremaining: 11.7s\n",
      "3647:\tlearn: 1.7957042\ttotal: 44.7s\tremaining: 11.6s\n",
      "3648:\tlearn: 1.7953263\ttotal: 44.7s\tremaining: 11.6s\n",
      "3649:\tlearn: 1.7950777\ttotal: 44.7s\tremaining: 11.6s\n",
      "3650:\tlearn: 1.7948406\ttotal: 44.7s\tremaining: 11.6s\n",
      "3651:\tlearn: 1.7946593\ttotal: 44.8s\tremaining: 11.6s\n",
      "3652:\tlearn: 1.7943470\ttotal: 44.8s\tremaining: 11.6s\n",
      "3653:\tlearn: 1.7940498\ttotal: 44.8s\tremaining: 11.6s\n",
      "3654:\tlearn: 1.7936976\ttotal: 44.8s\tremaining: 11.6s\n",
      "3655:\tlearn: 1.7935546\ttotal: 44.8s\tremaining: 11.5s\n",
      "3656:\tlearn: 1.7933434\ttotal: 44.8s\tremaining: 11.5s\n",
      "3657:\tlearn: 1.7931878\ttotal: 44.8s\tremaining: 11.5s\n",
      "3658:\tlearn: 1.7927487\ttotal: 44.8s\tremaining: 11.5s\n",
      "3659:\tlearn: 1.7924285\ttotal: 44.9s\tremaining: 11.5s\n",
      "3660:\tlearn: 1.7921701\ttotal: 44.9s\tremaining: 11.5s\n",
      "3661:\tlearn: 1.7919907\ttotal: 44.9s\tremaining: 11.5s\n",
      "3662:\tlearn: 1.7917365\ttotal: 44.9s\tremaining: 11.5s\n",
      "3663:\tlearn: 1.7913201\ttotal: 44.9s\tremaining: 11.4s\n",
      "3664:\tlearn: 1.7909576\ttotal: 44.9s\tremaining: 11.4s\n",
      "3665:\tlearn: 1.7904434\ttotal: 44.9s\tremaining: 11.4s\n",
      "3666:\tlearn: 1.7900940\ttotal: 45s\tremaining: 11.4s\n",
      "3667:\tlearn: 1.7899230\ttotal: 45s\tremaining: 11.4s\n",
      "3668:\tlearn: 1.7895651\ttotal: 45s\tremaining: 11.4s\n",
      "3669:\tlearn: 1.7892899\ttotal: 45s\tremaining: 11.4s\n",
      "3670:\tlearn: 1.7889935\ttotal: 45s\tremaining: 11.4s\n",
      "3671:\tlearn: 1.7888025\ttotal: 45s\tremaining: 11.4s\n",
      "3672:\tlearn: 1.7884564\ttotal: 45s\tremaining: 11.3s\n",
      "3673:\tlearn: 1.7883058\ttotal: 45s\tremaining: 11.3s\n",
      "3674:\tlearn: 1.7880681\ttotal: 45s\tremaining: 11.3s\n",
      "3675:\tlearn: 1.7878158\ttotal: 45.1s\tremaining: 11.3s\n",
      "3676:\tlearn: 1.7876430\ttotal: 45.1s\tremaining: 11.3s\n",
      "3677:\tlearn: 1.7876422\ttotal: 45.1s\tremaining: 11.3s\n",
      "3678:\tlearn: 1.7874008\ttotal: 45.1s\tremaining: 11.3s\n",
      "3679:\tlearn: 1.7871363\ttotal: 45.1s\tremaining: 11.3s\n",
      "3680:\tlearn: 1.7868869\ttotal: 45.1s\tremaining: 11.2s\n",
      "3681:\tlearn: 1.7866848\ttotal: 45.1s\tremaining: 11.2s\n",
      "3682:\tlearn: 1.7863446\ttotal: 45.1s\tremaining: 11.2s\n",
      "3683:\tlearn: 1.7862616\ttotal: 45.2s\tremaining: 11.2s\n",
      "3684:\tlearn: 1.7859667\ttotal: 45.2s\tremaining: 11.2s\n",
      "3685:\tlearn: 1.7854826\ttotal: 45.2s\tremaining: 11.2s\n",
      "3686:\tlearn: 1.7851559\ttotal: 45.2s\tremaining: 11.2s\n",
      "3687:\tlearn: 1.7848828\ttotal: 45.2s\tremaining: 11.2s\n",
      "3688:\tlearn: 1.7844049\ttotal: 45.2s\tremaining: 11.1s\n",
      "3689:\tlearn: 1.7842898\ttotal: 45.2s\tremaining: 11.1s\n",
      "3690:\tlearn: 1.7839152\ttotal: 45.2s\tremaining: 11.1s\n",
      "3691:\tlearn: 1.7834633\ttotal: 45.3s\tremaining: 11.1s\n",
      "3692:\tlearn: 1.7833084\ttotal: 45.3s\tremaining: 11.1s\n",
      "3693:\tlearn: 1.7831075\ttotal: 45.3s\tremaining: 11.1s\n",
      "3694:\tlearn: 1.7829488\ttotal: 45.3s\tremaining: 11.1s\n",
      "3695:\tlearn: 1.7827906\ttotal: 45.3s\tremaining: 11.1s\n",
      "3696:\tlearn: 1.7826025\ttotal: 45.3s\tremaining: 11s\n",
      "3697:\tlearn: 1.7822293\ttotal: 45.3s\tremaining: 11s\n",
      "3698:\tlearn: 1.7820968\ttotal: 45.3s\tremaining: 11s\n",
      "3699:\tlearn: 1.7819289\ttotal: 45.4s\tremaining: 11s\n",
      "3700:\tlearn: 1.7817381\ttotal: 45.4s\tremaining: 11s\n",
      "3701:\tlearn: 1.7816050\ttotal: 45.4s\tremaining: 11s\n",
      "3702:\tlearn: 1.7812287\ttotal: 45.4s\tremaining: 11s\n",
      "3703:\tlearn: 1.7809650\ttotal: 45.4s\tremaining: 11s\n",
      "3704:\tlearn: 1.7804589\ttotal: 45.4s\tremaining: 10.9s\n",
      "3705:\tlearn: 1.7801183\ttotal: 45.4s\tremaining: 10.9s\n",
      "3706:\tlearn: 1.7799313\ttotal: 45.4s\tremaining: 10.9s\n",
      "3707:\tlearn: 1.7795863\ttotal: 45.5s\tremaining: 10.9s\n",
      "3708:\tlearn: 1.7793387\ttotal: 45.5s\tremaining: 10.9s\n",
      "3709:\tlearn: 1.7790784\ttotal: 45.5s\tremaining: 10.9s\n",
      "3710:\tlearn: 1.7788150\ttotal: 45.5s\tremaining: 10.9s\n",
      "3711:\tlearn: 1.7785816\ttotal: 45.5s\tremaining: 10.9s\n",
      "3712:\tlearn: 1.7781671\ttotal: 45.5s\tremaining: 10.8s\n",
      "3713:\tlearn: 1.7777456\ttotal: 45.5s\tremaining: 10.8s\n",
      "3714:\tlearn: 1.7777449\ttotal: 45.5s\tremaining: 10.8s\n",
      "3715:\tlearn: 1.7775829\ttotal: 45.5s\tremaining: 10.8s\n",
      "3716:\tlearn: 1.7772810\ttotal: 45.6s\tremaining: 10.8s\n",
      "3717:\tlearn: 1.7768113\ttotal: 45.6s\tremaining: 10.8s\n",
      "3718:\tlearn: 1.7766737\ttotal: 45.6s\tremaining: 10.8s\n",
      "3719:\tlearn: 1.7763826\ttotal: 45.6s\tremaining: 10.8s\n",
      "3720:\tlearn: 1.7761425\ttotal: 45.6s\tremaining: 10.8s\n",
      "3721:\tlearn: 1.7758654\ttotal: 45.6s\tremaining: 10.7s\n",
      "3722:\tlearn: 1.7758647\ttotal: 45.6s\tremaining: 10.7s\n",
      "3723:\tlearn: 1.7758515\ttotal: 45.6s\tremaining: 10.7s\n",
      "3724:\tlearn: 1.7756746\ttotal: 45.7s\tremaining: 10.7s\n",
      "3725:\tlearn: 1.7754781\ttotal: 45.7s\tremaining: 10.7s\n",
      "3726:\tlearn: 1.7752512\ttotal: 45.7s\tremaining: 10.7s\n",
      "3727:\tlearn: 1.7751557\ttotal: 45.7s\tremaining: 10.7s\n",
      "3728:\tlearn: 1.7749380\ttotal: 45.7s\tremaining: 10.7s\n",
      "3729:\tlearn: 1.7749205\ttotal: 45.7s\tremaining: 10.6s\n",
      "3730:\tlearn: 1.7748211\ttotal: 45.7s\tremaining: 10.6s\n",
      "3731:\tlearn: 1.7744803\ttotal: 45.7s\tremaining: 10.6s\n",
      "3732:\tlearn: 1.7743630\ttotal: 45.7s\tremaining: 10.6s\n",
      "3733:\tlearn: 1.7740724\ttotal: 45.8s\tremaining: 10.6s\n",
      "3734:\tlearn: 1.7737344\ttotal: 45.8s\tremaining: 10.6s\n",
      "3735:\tlearn: 1.7735741\ttotal: 45.8s\tremaining: 10.6s\n",
      "3736:\tlearn: 1.7732536\ttotal: 45.8s\tremaining: 10.6s\n",
      "3737:\tlearn: 1.7730130\ttotal: 45.8s\tremaining: 10.5s\n",
      "3738:\tlearn: 1.7728836\ttotal: 45.8s\tremaining: 10.5s\n",
      "3739:\tlearn: 1.7723644\ttotal: 45.8s\tremaining: 10.5s\n",
      "3740:\tlearn: 1.7721240\ttotal: 45.9s\tremaining: 10.5s\n",
      "3741:\tlearn: 1.7717529\ttotal: 45.9s\tremaining: 10.5s\n",
      "3742:\tlearn: 1.7714832\ttotal: 45.9s\tremaining: 10.5s\n",
      "3743:\tlearn: 1.7711771\ttotal: 45.9s\tremaining: 10.5s\n",
      "3744:\tlearn: 1.7710634\ttotal: 45.9s\tremaining: 10.5s\n",
      "3745:\tlearn: 1.7707880\ttotal: 45.9s\tremaining: 10.4s\n",
      "3746:\tlearn: 1.7704175\ttotal: 45.9s\tremaining: 10.4s\n",
      "3747:\tlearn: 1.7700492\ttotal: 45.9s\tremaining: 10.4s\n",
      "3748:\tlearn: 1.7699079\ttotal: 46s\tremaining: 10.4s\n",
      "3749:\tlearn: 1.7696627\ttotal: 46s\tremaining: 10.4s\n",
      "3750:\tlearn: 1.7690798\ttotal: 46s\tremaining: 10.4s\n",
      "3751:\tlearn: 1.7687965\ttotal: 46s\tremaining: 10.4s\n",
      "3752:\tlearn: 1.7685895\ttotal: 46s\tremaining: 10.4s\n",
      "3753:\tlearn: 1.7684813\ttotal: 46s\tremaining: 10.3s\n",
      "3754:\tlearn: 1.7683704\ttotal: 46s\tremaining: 10.3s\n",
      "3755:\tlearn: 1.7681910\ttotal: 46s\tremaining: 10.3s\n",
      "3756:\tlearn: 1.7680073\ttotal: 46.1s\tremaining: 10.3s\n",
      "3757:\tlearn: 1.7675715\ttotal: 46.1s\tremaining: 10.3s\n",
      "3758:\tlearn: 1.7674846\ttotal: 46.1s\tremaining: 10.3s\n",
      "3759:\tlearn: 1.7672496\ttotal: 46.1s\tremaining: 10.3s\n",
      "3760:\tlearn: 1.7671445\ttotal: 46.1s\tremaining: 10.3s\n",
      "3761:\tlearn: 1.7671438\ttotal: 46.1s\tremaining: 10.2s\n",
      "3762:\tlearn: 1.7668958\ttotal: 46.1s\tremaining: 10.2s\n",
      "3763:\tlearn: 1.7666750\ttotal: 46.1s\tremaining: 10.2s\n",
      "3764:\tlearn: 1.7664829\ttotal: 46.1s\tremaining: 10.2s\n",
      "3765:\tlearn: 1.7663538\ttotal: 46.2s\tremaining: 10.2s\n",
      "3766:\tlearn: 1.7660142\ttotal: 46.2s\tremaining: 10.2s\n",
      "3767:\tlearn: 1.7658243\ttotal: 46.2s\tremaining: 10.2s\n",
      "3768:\tlearn: 1.7656377\ttotal: 46.2s\tremaining: 10.2s\n",
      "3769:\tlearn: 1.7654367\ttotal: 46.2s\tremaining: 10.1s\n",
      "3770:\tlearn: 1.7652162\ttotal: 46.2s\tremaining: 10.1s\n",
      "3771:\tlearn: 1.7649723\ttotal: 46.2s\tremaining: 10.1s\n",
      "3772:\tlearn: 1.7646940\ttotal: 46.2s\tremaining: 10.1s\n",
      "3773:\tlearn: 1.7645013\ttotal: 46.3s\tremaining: 10.1s\n",
      "3774:\tlearn: 1.7642598\ttotal: 46.3s\tremaining: 10.1s\n",
      "3775:\tlearn: 1.7640935\ttotal: 46.3s\tremaining: 10.1s\n",
      "3776:\tlearn: 1.7636920\ttotal: 46.3s\tremaining: 10.1s\n",
      "3777:\tlearn: 1.7633687\ttotal: 46.3s\tremaining: 10.1s\n",
      "3778:\tlearn: 1.7632003\ttotal: 46.3s\tremaining: 10s\n",
      "3779:\tlearn: 1.7631476\ttotal: 46.3s\tremaining: 10s\n",
      "3780:\tlearn: 1.7628035\ttotal: 46.3s\tremaining: 10s\n",
      "3781:\tlearn: 1.7625609\ttotal: 46.4s\tremaining: 10s\n",
      "3782:\tlearn: 1.7621350\ttotal: 46.4s\tremaining: 9.99s\n",
      "3783:\tlearn: 1.7619846\ttotal: 46.4s\tremaining: 9.98s\n",
      "3784:\tlearn: 1.7618302\ttotal: 46.4s\tremaining: 9.96s\n",
      "3785:\tlearn: 1.7615275\ttotal: 46.4s\tremaining: 9.95s\n",
      "3786:\tlearn: 1.7613555\ttotal: 46.4s\tremaining: 9.94s\n",
      "3787:\tlearn: 1.7612426\ttotal: 46.4s\tremaining: 9.93s\n",
      "3788:\tlearn: 1.7609844\ttotal: 46.4s\tremaining: 9.91s\n",
      "3789:\tlearn: 1.7606960\ttotal: 46.5s\tremaining: 9.9s\n",
      "3790:\tlearn: 1.7605601\ttotal: 46.5s\tremaining: 9.89s\n",
      "3791:\tlearn: 1.7601963\ttotal: 46.5s\tremaining: 9.88s\n",
      "3792:\tlearn: 1.7599628\ttotal: 46.5s\tremaining: 9.87s\n",
      "3793:\tlearn: 1.7596011\ttotal: 46.5s\tremaining: 9.85s\n",
      "3794:\tlearn: 1.7592288\ttotal: 46.5s\tremaining: 9.84s\n",
      "3795:\tlearn: 1.7590277\ttotal: 46.5s\tremaining: 9.83s\n",
      "3796:\tlearn: 1.7588107\ttotal: 46.5s\tremaining: 9.82s\n",
      "3797:\tlearn: 1.7586079\ttotal: 46.5s\tremaining: 9.8s\n",
      "3798:\tlearn: 1.7583210\ttotal: 46.6s\tremaining: 9.79s\n",
      "3799:\tlearn: 1.7580991\ttotal: 46.6s\tremaining: 9.78s\n",
      "3800:\tlearn: 1.7577330\ttotal: 46.6s\tremaining: 9.77s\n",
      "3801:\tlearn: 1.7575846\ttotal: 46.6s\tremaining: 9.76s\n",
      "3802:\tlearn: 1.7574694\ttotal: 46.6s\tremaining: 9.74s\n",
      "3803:\tlearn: 1.7572376\ttotal: 46.6s\tremaining: 9.73s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3804:\tlearn: 1.7569209\ttotal: 46.6s\tremaining: 9.72s\n",
      "3805:\tlearn: 1.7566626\ttotal: 46.6s\tremaining: 9.71s\n",
      "3806:\tlearn: 1.7564309\ttotal: 46.7s\tremaining: 9.69s\n",
      "3807:\tlearn: 1.7561286\ttotal: 46.7s\tremaining: 9.68s\n",
      "3808:\tlearn: 1.7559836\ttotal: 46.7s\tremaining: 9.67s\n",
      "3809:\tlearn: 1.7557776\ttotal: 46.7s\tremaining: 9.66s\n",
      "3810:\tlearn: 1.7554957\ttotal: 46.7s\tremaining: 9.64s\n",
      "3811:\tlearn: 1.7552801\ttotal: 46.7s\tremaining: 9.63s\n",
      "3812:\tlearn: 1.7549802\ttotal: 46.7s\tremaining: 9.62s\n",
      "3813:\tlearn: 1.7546577\ttotal: 46.7s\tremaining: 9.61s\n",
      "3814:\tlearn: 1.7544038\ttotal: 46.8s\tremaining: 9.6s\n",
      "3815:\tlearn: 1.7542021\ttotal: 46.8s\tremaining: 9.58s\n",
      "3816:\tlearn: 1.7541076\ttotal: 46.8s\tremaining: 9.57s\n",
      "3817:\tlearn: 1.7539929\ttotal: 46.8s\tremaining: 9.56s\n",
      "3818:\tlearn: 1.7537101\ttotal: 46.8s\tremaining: 9.55s\n",
      "3819:\tlearn: 1.7533889\ttotal: 46.8s\tremaining: 9.53s\n",
      "3820:\tlearn: 1.7530998\ttotal: 46.8s\tremaining: 9.52s\n",
      "3821:\tlearn: 1.7529900\ttotal: 46.8s\tremaining: 9.51s\n",
      "3822:\tlearn: 1.7526932\ttotal: 46.9s\tremaining: 9.5s\n",
      "3823:\tlearn: 1.7524402\ttotal: 46.9s\tremaining: 9.48s\n",
      "3824:\tlearn: 1.7522622\ttotal: 46.9s\tremaining: 9.47s\n",
      "3825:\tlearn: 1.7518699\ttotal: 46.9s\tremaining: 9.46s\n",
      "3826:\tlearn: 1.7517539\ttotal: 46.9s\tremaining: 9.45s\n",
      "3827:\tlearn: 1.7515044\ttotal: 46.9s\tremaining: 9.44s\n",
      "3828:\tlearn: 1.7512413\ttotal: 46.9s\tremaining: 9.42s\n",
      "3829:\tlearn: 1.7510627\ttotal: 46.9s\tremaining: 9.41s\n",
      "3830:\tlearn: 1.7509659\ttotal: 46.9s\tremaining: 9.4s\n",
      "3831:\tlearn: 1.7507556\ttotal: 47s\tremaining: 9.39s\n",
      "3832:\tlearn: 1.7504291\ttotal: 47s\tremaining: 9.38s\n",
      "3833:\tlearn: 1.7501770\ttotal: 47s\tremaining: 9.36s\n",
      "3834:\tlearn: 1.7499947\ttotal: 47s\tremaining: 9.35s\n",
      "3835:\tlearn: 1.7497442\ttotal: 47s\tremaining: 9.34s\n",
      "3836:\tlearn: 1.7495232\ttotal: 47s\tremaining: 9.33s\n",
      "3837:\tlearn: 1.7492853\ttotal: 47s\tremaining: 9.31s\n",
      "3838:\tlearn: 1.7490258\ttotal: 47s\tremaining: 9.3s\n",
      "3839:\tlearn: 1.7484871\ttotal: 47.1s\tremaining: 9.29s\n",
      "3840:\tlearn: 1.7483686\ttotal: 47.1s\tremaining: 9.28s\n",
      "3841:\tlearn: 1.7481640\ttotal: 47.1s\tremaining: 9.27s\n",
      "3842:\tlearn: 1.7476827\ttotal: 47.1s\tremaining: 9.25s\n",
      "3843:\tlearn: 1.7473425\ttotal: 47.1s\tremaining: 9.24s\n",
      "3844:\tlearn: 1.7473418\ttotal: 47.1s\tremaining: 9.23s\n",
      "3845:\tlearn: 1.7472688\ttotal: 47.1s\tremaining: 9.21s\n",
      "3846:\tlearn: 1.7469829\ttotal: 47.1s\tremaining: 9.2s\n",
      "3847:\tlearn: 1.7467787\ttotal: 47.2s\tremaining: 9.19s\n",
      "3848:\tlearn: 1.7465768\ttotal: 47.2s\tremaining: 9.18s\n",
      "3849:\tlearn: 1.7463512\ttotal: 47.2s\tremaining: 9.17s\n",
      "3850:\tlearn: 1.7461039\ttotal: 47.2s\tremaining: 9.15s\n",
      "3851:\tlearn: 1.7455791\ttotal: 47.2s\tremaining: 9.14s\n",
      "3852:\tlearn: 1.7452364\ttotal: 47.2s\tremaining: 9.13s\n",
      "3853:\tlearn: 1.7449313\ttotal: 47.2s\tremaining: 9.12s\n",
      "3854:\tlearn: 1.7446808\ttotal: 47.2s\tremaining: 9.11s\n",
      "3855:\tlearn: 1.7446086\ttotal: 47.3s\tremaining: 9.09s\n",
      "3856:\tlearn: 1.7443201\ttotal: 47.3s\tremaining: 9.08s\n",
      "3857:\tlearn: 1.7441736\ttotal: 47.3s\tremaining: 9.07s\n",
      "3858:\tlearn: 1.7438711\ttotal: 47.3s\tremaining: 9.06s\n",
      "3859:\tlearn: 1.7436596\ttotal: 47.3s\tremaining: 9.04s\n",
      "3860:\tlearn: 1.7433894\ttotal: 47.3s\tremaining: 9.03s\n",
      "3861:\tlearn: 1.7431671\ttotal: 47.3s\tremaining: 9.02s\n",
      "3862:\tlearn: 1.7429952\ttotal: 47.3s\tremaining: 9.01s\n",
      "3863:\tlearn: 1.7425069\ttotal: 47.4s\tremaining: 8.99s\n",
      "3864:\tlearn: 1.7423556\ttotal: 47.4s\tremaining: 8.98s\n",
      "3865:\tlearn: 1.7418946\ttotal: 47.4s\tremaining: 8.97s\n",
      "3866:\tlearn: 1.7417617\ttotal: 47.4s\tremaining: 8.96s\n",
      "3867:\tlearn: 1.7414056\ttotal: 47.4s\tremaining: 8.95s\n",
      "3868:\tlearn: 1.7412666\ttotal: 47.4s\tremaining: 8.93s\n",
      "3869:\tlearn: 1.7411623\ttotal: 47.4s\tremaining: 8.92s\n",
      "3870:\tlearn: 1.7409576\ttotal: 47.4s\tremaining: 8.91s\n",
      "3871:\tlearn: 1.7408386\ttotal: 47.4s\tremaining: 8.9s\n",
      "3872:\tlearn: 1.7403642\ttotal: 47.5s\tremaining: 8.88s\n",
      "3873:\tlearn: 1.7401360\ttotal: 47.5s\tremaining: 8.87s\n",
      "3874:\tlearn: 1.7397549\ttotal: 47.5s\tremaining: 8.86s\n",
      "3875:\tlearn: 1.7395146\ttotal: 47.5s\tremaining: 8.85s\n",
      "3876:\tlearn: 1.7393649\ttotal: 47.5s\tremaining: 8.84s\n",
      "3877:\tlearn: 1.7388470\ttotal: 47.5s\tremaining: 8.82s\n",
      "3878:\tlearn: 1.7387596\ttotal: 47.5s\tremaining: 8.81s\n",
      "3879:\tlearn: 1.7383885\ttotal: 47.5s\tremaining: 8.8s\n",
      "3880:\tlearn: 1.7381380\ttotal: 47.6s\tremaining: 8.79s\n",
      "3881:\tlearn: 1.7379570\ttotal: 47.6s\tremaining: 8.77s\n",
      "3882:\tlearn: 1.7375539\ttotal: 47.6s\tremaining: 8.76s\n",
      "3883:\tlearn: 1.7371267\ttotal: 47.6s\tremaining: 8.75s\n",
      "3884:\tlearn: 1.7366552\ttotal: 47.6s\tremaining: 8.74s\n",
      "3885:\tlearn: 1.7364313\ttotal: 47.6s\tremaining: 8.73s\n",
      "3886:\tlearn: 1.7362659\ttotal: 47.6s\tremaining: 8.72s\n",
      "3887:\tlearn: 1.7359684\ttotal: 47.7s\tremaining: 8.7s\n",
      "3888:\tlearn: 1.7358574\ttotal: 47.7s\tremaining: 8.69s\n",
      "3889:\tlearn: 1.7356308\ttotal: 47.7s\tremaining: 8.68s\n",
      "3890:\tlearn: 1.7355139\ttotal: 47.7s\tremaining: 8.67s\n",
      "3891:\tlearn: 1.7350521\ttotal: 47.7s\tremaining: 8.65s\n",
      "3892:\tlearn: 1.7347011\ttotal: 47.7s\tremaining: 8.64s\n",
      "3893:\tlearn: 1.7341490\ttotal: 47.7s\tremaining: 8.63s\n",
      "3894:\tlearn: 1.7339074\ttotal: 47.8s\tremaining: 8.62s\n",
      "3895:\tlearn: 1.7337408\ttotal: 47.8s\tremaining: 8.61s\n",
      "3896:\tlearn: 1.7335672\ttotal: 47.8s\tremaining: 8.59s\n",
      "3897:\tlearn: 1.7332218\ttotal: 47.8s\tremaining: 8.58s\n",
      "3898:\tlearn: 1.7328232\ttotal: 47.8s\tremaining: 8.57s\n",
      "3899:\tlearn: 1.7326201\ttotal: 47.8s\tremaining: 8.56s\n",
      "3900:\tlearn: 1.7323227\ttotal: 47.8s\tremaining: 8.54s\n",
      "3901:\tlearn: 1.7321354\ttotal: 47.8s\tremaining: 8.53s\n",
      "3902:\tlearn: 1.7318192\ttotal: 47.9s\tremaining: 8.52s\n",
      "3903:\tlearn: 1.7315146\ttotal: 47.9s\tremaining: 8.51s\n",
      "3904:\tlearn: 1.7313540\ttotal: 47.9s\tremaining: 8.5s\n",
      "3905:\tlearn: 1.7312774\ttotal: 47.9s\tremaining: 8.48s\n",
      "3906:\tlearn: 1.7312217\ttotal: 47.9s\tremaining: 8.47s\n",
      "3907:\tlearn: 1.7310187\ttotal: 47.9s\tremaining: 8.46s\n",
      "3908:\tlearn: 1.7309024\ttotal: 47.9s\tremaining: 8.45s\n",
      "3909:\tlearn: 1.7307006\ttotal: 47.9s\tremaining: 8.44s\n",
      "3910:\tlearn: 1.7305280\ttotal: 48s\tremaining: 8.42s\n",
      "3911:\tlearn: 1.7304602\ttotal: 48s\tremaining: 8.41s\n",
      "3912:\tlearn: 1.7302509\ttotal: 48s\tremaining: 8.4s\n",
      "3913:\tlearn: 1.7300799\ttotal: 48s\tremaining: 8.38s\n",
      "3914:\tlearn: 1.7299414\ttotal: 48s\tremaining: 8.37s\n",
      "3915:\tlearn: 1.7296468\ttotal: 48s\tremaining: 8.36s\n",
      "3916:\tlearn: 1.7293637\ttotal: 48s\tremaining: 8.35s\n",
      "3917:\tlearn: 1.7291730\ttotal: 48s\tremaining: 8.34s\n",
      "3918:\tlearn: 1.7290416\ttotal: 48s\tremaining: 8.32s\n",
      "3919:\tlearn: 1.7287362\ttotal: 48.1s\tremaining: 8.31s\n",
      "3920:\tlearn: 1.7284018\ttotal: 48.1s\tremaining: 8.3s\n",
      "3921:\tlearn: 1.7280700\ttotal: 48.1s\tremaining: 8.29s\n",
      "3922:\tlearn: 1.7278381\ttotal: 48.1s\tremaining: 8.28s\n",
      "3923:\tlearn: 1.7275925\ttotal: 48.1s\tremaining: 8.26s\n",
      "3924:\tlearn: 1.7274265\ttotal: 48.1s\tremaining: 8.25s\n",
      "3925:\tlearn: 1.7269728\ttotal: 48.1s\tremaining: 8.24s\n",
      "3926:\tlearn: 1.7268090\ttotal: 48.1s\tremaining: 8.23s\n",
      "3927:\tlearn: 1.7266795\ttotal: 48.2s\tremaining: 8.21s\n",
      "3928:\tlearn: 1.7262141\ttotal: 48.2s\tremaining: 8.2s\n",
      "3929:\tlearn: 1.7259221\ttotal: 48.2s\tremaining: 8.19s\n",
      "3930:\tlearn: 1.7256586\ttotal: 48.2s\tremaining: 8.18s\n",
      "3931:\tlearn: 1.7254653\ttotal: 48.2s\tremaining: 8.16s\n",
      "3932:\tlearn: 1.7252434\ttotal: 48.2s\tremaining: 8.15s\n",
      "3933:\tlearn: 1.7249833\ttotal: 48.2s\tremaining: 8.14s\n",
      "3934:\tlearn: 1.7246884\ttotal: 48.2s\tremaining: 8.13s\n",
      "3935:\tlearn: 1.7244955\ttotal: 48.3s\tremaining: 8.12s\n",
      "3936:\tlearn: 1.7243380\ttotal: 48.3s\tremaining: 8.1s\n",
      "3937:\tlearn: 1.7240356\ttotal: 48.3s\tremaining: 8.09s\n",
      "3938:\tlearn: 1.7238894\ttotal: 48.3s\tremaining: 8.08s\n",
      "3939:\tlearn: 1.7236217\ttotal: 48.3s\tremaining: 8.07s\n",
      "3940:\tlearn: 1.7233365\ttotal: 48.3s\tremaining: 8.05s\n",
      "3941:\tlearn: 1.7232227\ttotal: 48.3s\tremaining: 8.04s\n",
      "3942:\tlearn: 1.7230433\ttotal: 48.3s\tremaining: 8.03s\n",
      "3943:\tlearn: 1.7228296\ttotal: 48.4s\tremaining: 8.02s\n",
      "3944:\tlearn: 1.7224793\ttotal: 48.4s\tremaining: 8.01s\n",
      "3945:\tlearn: 1.7223487\ttotal: 48.4s\tremaining: 7.99s\n",
      "3946:\tlearn: 1.7220584\ttotal: 48.4s\tremaining: 7.98s\n",
      "3947:\tlearn: 1.7219164\ttotal: 48.4s\tremaining: 7.97s\n",
      "3948:\tlearn: 1.7218189\ttotal: 48.4s\tremaining: 7.96s\n",
      "3949:\tlearn: 1.7216157\ttotal: 48.4s\tremaining: 7.94s\n",
      "3950:\tlearn: 1.7213223\ttotal: 48.4s\tremaining: 7.93s\n",
      "3951:\tlearn: 1.7212630\ttotal: 48.5s\tremaining: 7.92s\n",
      "3952:\tlearn: 1.7209897\ttotal: 48.5s\tremaining: 7.91s\n",
      "3953:\tlearn: 1.7207242\ttotal: 48.5s\tremaining: 7.89s\n",
      "3954:\tlearn: 1.7205205\ttotal: 48.5s\tremaining: 7.88s\n",
      "3955:\tlearn: 1.7203565\ttotal: 48.5s\tremaining: 7.87s\n",
      "3956:\tlearn: 1.7200316\ttotal: 48.5s\tremaining: 7.86s\n",
      "3957:\tlearn: 1.7199214\ttotal: 48.5s\tremaining: 7.85s\n",
      "3958:\tlearn: 1.7196801\ttotal: 48.5s\tremaining: 7.83s\n",
      "3959:\tlearn: 1.7194173\ttotal: 48.5s\tremaining: 7.82s\n",
      "3960:\tlearn: 1.7190135\ttotal: 48.6s\tremaining: 7.81s\n",
      "3961:\tlearn: 1.7189205\ttotal: 48.6s\tremaining: 7.8s\n",
      "3962:\tlearn: 1.7185799\ttotal: 48.6s\tremaining: 7.79s\n",
      "3963:\tlearn: 1.7183695\ttotal: 48.6s\tremaining: 7.77s\n",
      "3964:\tlearn: 1.7181671\ttotal: 48.6s\tremaining: 7.76s\n",
      "3965:\tlearn: 1.7177910\ttotal: 48.6s\tremaining: 7.75s\n",
      "3966:\tlearn: 1.7174130\ttotal: 48.6s\tremaining: 7.74s\n",
      "3967:\tlearn: 1.7169972\ttotal: 48.6s\tremaining: 7.72s\n",
      "3968:\tlearn: 1.7168376\ttotal: 48.7s\tremaining: 7.71s\n",
      "3969:\tlearn: 1.7166582\ttotal: 48.7s\tremaining: 7.7s\n",
      "3970:\tlearn: 1.7164603\ttotal: 48.7s\tremaining: 7.69s\n",
      "3971:\tlearn: 1.7161815\ttotal: 48.7s\tremaining: 7.67s\n",
      "3972:\tlearn: 1.7160025\ttotal: 48.7s\tremaining: 7.66s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3973:\tlearn: 1.7158050\ttotal: 48.7s\tremaining: 7.65s\n",
      "3974:\tlearn: 1.7155908\ttotal: 48.7s\tremaining: 7.64s\n",
      "3975:\tlearn: 1.7154663\ttotal: 48.7s\tremaining: 7.63s\n",
      "3976:\tlearn: 1.7152996\ttotal: 48.8s\tremaining: 7.61s\n",
      "3977:\tlearn: 1.7151281\ttotal: 48.8s\tremaining: 7.6s\n",
      "3978:\tlearn: 1.7147950\ttotal: 48.8s\tremaining: 7.59s\n",
      "3979:\tlearn: 1.7146369\ttotal: 48.8s\tremaining: 7.58s\n",
      "3980:\tlearn: 1.7144850\ttotal: 48.8s\tremaining: 7.56s\n",
      "3981:\tlearn: 1.7142913\ttotal: 48.8s\tremaining: 7.55s\n",
      "3982:\tlearn: 1.7140765\ttotal: 48.8s\tremaining: 7.54s\n",
      "3983:\tlearn: 1.7139007\ttotal: 48.8s\tremaining: 7.53s\n",
      "3984:\tlearn: 1.7138412\ttotal: 48.9s\tremaining: 7.51s\n",
      "3985:\tlearn: 1.7136739\ttotal: 48.9s\tremaining: 7.5s\n",
      "3986:\tlearn: 1.7134679\ttotal: 48.9s\tremaining: 7.49s\n",
      "3987:\tlearn: 1.7132247\ttotal: 48.9s\tremaining: 7.48s\n",
      "3988:\tlearn: 1.7131232\ttotal: 48.9s\tremaining: 7.46s\n",
      "3989:\tlearn: 1.7129984\ttotal: 48.9s\tremaining: 7.45s\n",
      "3990:\tlearn: 1.7126351\ttotal: 48.9s\tremaining: 7.44s\n",
      "3991:\tlearn: 1.7125093\ttotal: 48.9s\tremaining: 7.43s\n",
      "3992:\tlearn: 1.7121987\ttotal: 49s\tremaining: 7.42s\n",
      "3993:\tlearn: 1.7119492\ttotal: 49s\tremaining: 7.4s\n",
      "3994:\tlearn: 1.7117249\ttotal: 49s\tremaining: 7.39s\n",
      "3995:\tlearn: 1.7115040\ttotal: 49s\tremaining: 7.38s\n",
      "3996:\tlearn: 1.7111409\ttotal: 49s\tremaining: 7.37s\n",
      "3997:\tlearn: 1.7108960\ttotal: 49s\tremaining: 7.36s\n",
      "3998:\tlearn: 1.7105933\ttotal: 49s\tremaining: 7.34s\n",
      "3999:\tlearn: 1.7103743\ttotal: 49s\tremaining: 7.33s\n",
      "4000:\tlearn: 1.7102254\ttotal: 49s\tremaining: 7.32s\n",
      "4001:\tlearn: 1.7100543\ttotal: 49.1s\tremaining: 7.31s\n",
      "4002:\tlearn: 1.7097510\ttotal: 49.1s\tremaining: 7.29s\n",
      "4003:\tlearn: 1.7096845\ttotal: 49.1s\tremaining: 7.28s\n",
      "4004:\tlearn: 1.7093538\ttotal: 49.1s\tremaining: 7.27s\n",
      "4005:\tlearn: 1.7090511\ttotal: 49.1s\tremaining: 7.26s\n",
      "4006:\tlearn: 1.7089449\ttotal: 49.1s\tremaining: 7.24s\n",
      "4007:\tlearn: 1.7088625\ttotal: 49.1s\tremaining: 7.23s\n",
      "4008:\tlearn: 1.7085034\ttotal: 49.1s\tremaining: 7.22s\n",
      "4009:\tlearn: 1.7082226\ttotal: 49.2s\tremaining: 7.21s\n",
      "4010:\tlearn: 1.7077948\ttotal: 49.2s\tremaining: 7.2s\n",
      "4011:\tlearn: 1.7075329\ttotal: 49.2s\tremaining: 7.18s\n",
      "4012:\tlearn: 1.7073622\ttotal: 49.2s\tremaining: 7.17s\n",
      "4013:\tlearn: 1.7071817\ttotal: 49.2s\tremaining: 7.16s\n",
      "4014:\tlearn: 1.7070076\ttotal: 49.2s\tremaining: 7.15s\n",
      "4015:\tlearn: 1.7068296\ttotal: 49.2s\tremaining: 7.13s\n",
      "4016:\tlearn: 1.7067249\ttotal: 49.2s\tremaining: 7.12s\n",
      "4017:\tlearn: 1.7065080\ttotal: 49.3s\tremaining: 7.11s\n",
      "4018:\tlearn: 1.7062015\ttotal: 49.3s\tremaining: 7.1s\n",
      "4019:\tlearn: 1.7060209\ttotal: 49.3s\tremaining: 7.08s\n",
      "4020:\tlearn: 1.7056121\ttotal: 49.3s\tremaining: 7.07s\n",
      "4021:\tlearn: 1.7053027\ttotal: 49.3s\tremaining: 7.06s\n",
      "4022:\tlearn: 1.7050991\ttotal: 49.3s\tremaining: 7.05s\n",
      "4023:\tlearn: 1.7049711\ttotal: 49.3s\tremaining: 7.04s\n",
      "4024:\tlearn: 1.7046907\ttotal: 49.3s\tremaining: 7.02s\n",
      "4025:\tlearn: 1.7046036\ttotal: 49.3s\tremaining: 7.01s\n",
      "4026:\tlearn: 1.7043585\ttotal: 49.4s\tremaining: 7s\n",
      "4027:\tlearn: 1.7039715\ttotal: 49.4s\tremaining: 6.99s\n",
      "4028:\tlearn: 1.7038381\ttotal: 49.4s\tremaining: 6.97s\n",
      "4029:\tlearn: 1.7033432\ttotal: 49.4s\tremaining: 6.96s\n",
      "4030:\tlearn: 1.7029513\ttotal: 49.4s\tremaining: 6.95s\n",
      "4031:\tlearn: 1.7026172\ttotal: 49.4s\tremaining: 6.94s\n",
      "4032:\tlearn: 1.7024292\ttotal: 49.4s\tremaining: 6.92s\n",
      "4033:\tlearn: 1.7022561\ttotal: 49.4s\tremaining: 6.91s\n",
      "4034:\tlearn: 1.7020850\ttotal: 49.5s\tremaining: 6.9s\n",
      "4035:\tlearn: 1.7019368\ttotal: 49.5s\tremaining: 6.89s\n",
      "4036:\tlearn: 1.7017175\ttotal: 49.5s\tremaining: 6.88s\n",
      "4037:\tlearn: 1.7014939\ttotal: 49.5s\tremaining: 6.86s\n",
      "4038:\tlearn: 1.7011561\ttotal: 49.5s\tremaining: 6.85s\n",
      "4039:\tlearn: 1.7008488\ttotal: 49.5s\tremaining: 6.84s\n",
      "4040:\tlearn: 1.7005474\ttotal: 49.5s\tremaining: 6.83s\n",
      "4041:\tlearn: 1.7002101\ttotal: 49.5s\tremaining: 6.82s\n",
      "4042:\tlearn: 1.6998024\ttotal: 49.6s\tremaining: 6.8s\n",
      "4043:\tlearn: 1.6995890\ttotal: 49.6s\tremaining: 6.79s\n",
      "4044:\tlearn: 1.6991345\ttotal: 49.6s\tremaining: 6.78s\n",
      "4045:\tlearn: 1.6989432\ttotal: 49.6s\tremaining: 6.77s\n",
      "4046:\tlearn: 1.6985812\ttotal: 49.6s\tremaining: 6.75s\n",
      "4047:\tlearn: 1.6982408\ttotal: 49.6s\tremaining: 6.74s\n",
      "4048:\tlearn: 1.6979856\ttotal: 49.6s\tremaining: 6.73s\n",
      "4049:\tlearn: 1.6977921\ttotal: 49.6s\tremaining: 6.72s\n",
      "4050:\tlearn: 1.6977169\ttotal: 49.7s\tremaining: 6.7s\n",
      "4051:\tlearn: 1.6975674\ttotal: 49.7s\tremaining: 6.69s\n",
      "4052:\tlearn: 1.6972138\ttotal: 49.7s\tremaining: 6.68s\n",
      "4053:\tlearn: 1.6968831\ttotal: 49.7s\tremaining: 6.67s\n",
      "4054:\tlearn: 1.6967191\ttotal: 49.7s\tremaining: 6.66s\n",
      "4055:\tlearn: 1.6965234\ttotal: 49.7s\tremaining: 6.64s\n",
      "4056:\tlearn: 1.6960517\ttotal: 49.7s\tremaining: 6.63s\n",
      "4057:\tlearn: 1.6959634\ttotal: 49.7s\tremaining: 6.62s\n",
      "4058:\tlearn: 1.6958478\ttotal: 49.8s\tremaining: 6.61s\n",
      "4059:\tlearn: 1.6956815\ttotal: 49.8s\tremaining: 6.59s\n",
      "4060:\tlearn: 1.6953175\ttotal: 49.8s\tremaining: 6.58s\n",
      "4061:\tlearn: 1.6951711\ttotal: 49.8s\tremaining: 6.57s\n",
      "4062:\tlearn: 1.6951273\ttotal: 49.8s\tremaining: 6.56s\n",
      "4063:\tlearn: 1.6950064\ttotal: 49.8s\tremaining: 6.54s\n",
      "4064:\tlearn: 1.6943593\ttotal: 49.8s\tremaining: 6.53s\n",
      "4065:\tlearn: 1.6939928\ttotal: 49.8s\tremaining: 6.52s\n",
      "4066:\tlearn: 1.6939476\ttotal: 49.9s\tremaining: 6.51s\n",
      "4067:\tlearn: 1.6936492\ttotal: 49.9s\tremaining: 6.5s\n",
      "4068:\tlearn: 1.6934572\ttotal: 49.9s\tremaining: 6.48s\n",
      "4069:\tlearn: 1.6930225\ttotal: 49.9s\tremaining: 6.47s\n",
      "4070:\tlearn: 1.6928968\ttotal: 49.9s\tremaining: 6.46s\n",
      "4071:\tlearn: 1.6927490\ttotal: 49.9s\tremaining: 6.45s\n",
      "4072:\tlearn: 1.6924990\ttotal: 49.9s\tremaining: 6.43s\n",
      "4073:\tlearn: 1.6923054\ttotal: 49.9s\tremaining: 6.42s\n",
      "4074:\tlearn: 1.6920124\ttotal: 50s\tremaining: 6.41s\n",
      "4075:\tlearn: 1.6916775\ttotal: 50s\tremaining: 6.4s\n",
      "4076:\tlearn: 1.6914212\ttotal: 50s\tremaining: 6.39s\n",
      "4077:\tlearn: 1.6910426\ttotal: 50s\tremaining: 6.37s\n",
      "4078:\tlearn: 1.6907095\ttotal: 50s\tremaining: 6.36s\n",
      "4079:\tlearn: 1.6904094\ttotal: 50s\tremaining: 6.35s\n",
      "4080:\tlearn: 1.6903137\ttotal: 50s\tremaining: 6.34s\n",
      "4081:\tlearn: 1.6901684\ttotal: 50s\tremaining: 6.33s\n",
      "4082:\tlearn: 1.6898791\ttotal: 50.1s\tremaining: 6.31s\n",
      "4083:\tlearn: 1.6895670\ttotal: 50.1s\tremaining: 6.3s\n",
      "4084:\tlearn: 1.6892811\ttotal: 50.1s\tremaining: 6.29s\n",
      "4085:\tlearn: 1.6890743\ttotal: 50.1s\tremaining: 6.28s\n",
      "4086:\tlearn: 1.6888607\ttotal: 50.1s\tremaining: 6.26s\n",
      "4087:\tlearn: 1.6886547\ttotal: 50.1s\tremaining: 6.25s\n",
      "4088:\tlearn: 1.6884608\ttotal: 50.1s\tremaining: 6.24s\n",
      "4089:\tlearn: 1.6882734\ttotal: 50.1s\tremaining: 6.23s\n",
      "4090:\tlearn: 1.6881446\ttotal: 50.1s\tremaining: 6.21s\n",
      "4091:\tlearn: 1.6880225\ttotal: 50.2s\tremaining: 6.2s\n",
      "4092:\tlearn: 1.6875328\ttotal: 50.2s\tremaining: 6.19s\n",
      "4093:\tlearn: 1.6871972\ttotal: 50.2s\tremaining: 6.18s\n",
      "4094:\tlearn: 1.6870517\ttotal: 50.2s\tremaining: 6.17s\n",
      "4095:\tlearn: 1.6868046\ttotal: 50.2s\tremaining: 6.15s\n",
      "4096:\tlearn: 1.6866219\ttotal: 50.2s\tremaining: 6.14s\n",
      "4097:\tlearn: 1.6863543\ttotal: 50.2s\tremaining: 6.13s\n",
      "4098:\tlearn: 1.6862753\ttotal: 50.2s\tremaining: 6.12s\n",
      "4099:\tlearn: 1.6860109\ttotal: 50.3s\tremaining: 6.1s\n",
      "4100:\tlearn: 1.6858977\ttotal: 50.3s\tremaining: 6.09s\n",
      "4101:\tlearn: 1.6856212\ttotal: 50.3s\tremaining: 6.08s\n",
      "4102:\tlearn: 1.6850749\ttotal: 50.3s\tremaining: 6.07s\n",
      "4103:\tlearn: 1.6846593\ttotal: 50.3s\tremaining: 6.05s\n",
      "4104:\tlearn: 1.6843690\ttotal: 50.3s\tremaining: 6.04s\n",
      "4105:\tlearn: 1.6840799\ttotal: 50.3s\tremaining: 6.03s\n",
      "4106:\tlearn: 1.6838213\ttotal: 50.3s\tremaining: 6.02s\n",
      "4107:\tlearn: 1.6834056\ttotal: 50.4s\tremaining: 6.01s\n",
      "4108:\tlearn: 1.6831473\ttotal: 50.4s\tremaining: 5.99s\n",
      "4109:\tlearn: 1.6829641\ttotal: 50.4s\tremaining: 5.98s\n",
      "4110:\tlearn: 1.6828749\ttotal: 50.4s\tremaining: 5.97s\n",
      "4111:\tlearn: 1.6826347\ttotal: 50.4s\tremaining: 5.96s\n",
      "4112:\tlearn: 1.6822972\ttotal: 50.4s\tremaining: 5.94s\n",
      "4113:\tlearn: 1.6820138\ttotal: 50.4s\tremaining: 5.93s\n",
      "4114:\tlearn: 1.6818367\ttotal: 50.4s\tremaining: 5.92s\n",
      "4115:\tlearn: 1.6816751\ttotal: 50.5s\tremaining: 5.91s\n",
      "4116:\tlearn: 1.6815718\ttotal: 50.5s\tremaining: 5.9s\n",
      "4117:\tlearn: 1.6812198\ttotal: 50.5s\tremaining: 5.88s\n",
      "4118:\tlearn: 1.6810605\ttotal: 50.5s\tremaining: 5.87s\n",
      "4119:\tlearn: 1.6807881\ttotal: 50.5s\tremaining: 5.86s\n",
      "4120:\tlearn: 1.6806488\ttotal: 50.5s\tremaining: 5.85s\n",
      "4121:\tlearn: 1.6803068\ttotal: 50.5s\tremaining: 5.83s\n",
      "4122:\tlearn: 1.6799233\ttotal: 50.5s\tremaining: 5.82s\n",
      "4123:\tlearn: 1.6796925\ttotal: 50.6s\tremaining: 5.81s\n",
      "4124:\tlearn: 1.6795077\ttotal: 50.6s\tremaining: 5.8s\n",
      "4125:\tlearn: 1.6793484\ttotal: 50.6s\tremaining: 5.79s\n",
      "4126:\tlearn: 1.6789963\ttotal: 50.6s\tremaining: 5.77s\n",
      "4127:\tlearn: 1.6785559\ttotal: 50.6s\tremaining: 5.76s\n",
      "4128:\tlearn: 1.6784196\ttotal: 50.6s\tremaining: 5.75s\n",
      "4129:\tlearn: 1.6782972\ttotal: 50.6s\tremaining: 5.74s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4130:\tlearn: 1.6779114\ttotal: 50.6s\tremaining: 5.72s\n",
      "4131:\tlearn: 1.6777360\ttotal: 50.6s\tremaining: 5.71s\n",
      "4132:\tlearn: 1.6774715\ttotal: 50.7s\tremaining: 5.7s\n",
      "4133:\tlearn: 1.6773105\ttotal: 50.7s\tremaining: 5.69s\n",
      "4134:\tlearn: 1.6770570\ttotal: 50.7s\tremaining: 5.67s\n",
      "4135:\tlearn: 1.6766354\ttotal: 50.7s\tremaining: 5.66s\n",
      "4136:\tlearn: 1.6762562\ttotal: 50.7s\tremaining: 5.65s\n",
      "4137:\tlearn: 1.6759952\ttotal: 50.7s\tremaining: 5.64s\n",
      "4138:\tlearn: 1.6758358\ttotal: 50.7s\tremaining: 5.63s\n",
      "4139:\tlearn: 1.6755896\ttotal: 50.7s\tremaining: 5.61s\n",
      "4140:\tlearn: 1.6753897\ttotal: 50.8s\tremaining: 5.6s\n",
      "4141:\tlearn: 1.6752671\ttotal: 50.8s\tremaining: 5.59s\n",
      "4142:\tlearn: 1.6749276\ttotal: 50.8s\tremaining: 5.58s\n",
      "4143:\tlearn: 1.6746394\ttotal: 50.8s\tremaining: 5.56s\n",
      "4144:\tlearn: 1.6744178\ttotal: 50.8s\tremaining: 5.55s\n",
      "4145:\tlearn: 1.6742866\ttotal: 50.8s\tremaining: 5.54s\n",
      "4146:\tlearn: 1.6739748\ttotal: 50.8s\tremaining: 5.53s\n",
      "4147:\tlearn: 1.6737613\ttotal: 50.8s\tremaining: 5.51s\n",
      "4148:\tlearn: 1.6734508\ttotal: 50.9s\tremaining: 5.5s\n",
      "4149:\tlearn: 1.6731830\ttotal: 50.9s\tremaining: 5.49s\n",
      "4150:\tlearn: 1.6728902\ttotal: 50.9s\tremaining: 5.48s\n",
      "4151:\tlearn: 1.6727575\ttotal: 50.9s\tremaining: 5.47s\n",
      "4152:\tlearn: 1.6723882\ttotal: 50.9s\tremaining: 5.45s\n",
      "4153:\tlearn: 1.6721788\ttotal: 50.9s\tremaining: 5.44s\n",
      "4154:\tlearn: 1.6718045\ttotal: 50.9s\tremaining: 5.43s\n",
      "4155:\tlearn: 1.6716652\ttotal: 50.9s\tremaining: 5.42s\n",
      "4156:\tlearn: 1.6715695\ttotal: 51s\tremaining: 5.41s\n",
      "4157:\tlearn: 1.6711812\ttotal: 51s\tremaining: 5.39s\n",
      "4158:\tlearn: 1.6708609\ttotal: 51s\tremaining: 5.38s\n",
      "4159:\tlearn: 1.6705282\ttotal: 51s\tremaining: 5.37s\n",
      "4160:\tlearn: 1.6704358\ttotal: 51s\tremaining: 5.36s\n",
      "4161:\tlearn: 1.6700373\ttotal: 51s\tremaining: 5.34s\n",
      "4162:\tlearn: 1.6699123\ttotal: 51s\tremaining: 5.33s\n",
      "4163:\tlearn: 1.6696027\ttotal: 51s\tremaining: 5.32s\n",
      "4164:\tlearn: 1.6692845\ttotal: 51s\tremaining: 5.31s\n",
      "4165:\tlearn: 1.6691222\ttotal: 51.1s\tremaining: 5.29s\n",
      "4166:\tlearn: 1.6687138\ttotal: 51.1s\tremaining: 5.28s\n",
      "4167:\tlearn: 1.6685626\ttotal: 51.1s\tremaining: 5.27s\n",
      "4168:\tlearn: 1.6683220\ttotal: 51.1s\tremaining: 5.26s\n",
      "4169:\tlearn: 1.6680676\ttotal: 51.1s\tremaining: 5.25s\n",
      "4170:\tlearn: 1.6678572\ttotal: 51.1s\tremaining: 5.23s\n",
      "4171:\tlearn: 1.6677368\ttotal: 51.1s\tremaining: 5.22s\n",
      "4172:\tlearn: 1.6673688\ttotal: 51.2s\tremaining: 5.21s\n",
      "4173:\tlearn: 1.6672759\ttotal: 51.2s\tremaining: 5.2s\n",
      "4174:\tlearn: 1.6671741\ttotal: 51.2s\tremaining: 5.18s\n",
      "4175:\tlearn: 1.6669131\ttotal: 51.2s\tremaining: 5.17s\n",
      "4176:\tlearn: 1.6667799\ttotal: 51.2s\tremaining: 5.16s\n",
      "4177:\tlearn: 1.6665541\ttotal: 51.2s\tremaining: 5.15s\n",
      "4178:\tlearn: 1.6664097\ttotal: 51.2s\tremaining: 5.14s\n",
      "4179:\tlearn: 1.6662899\ttotal: 51.2s\tremaining: 5.12s\n",
      "4180:\tlearn: 1.6661013\ttotal: 51.3s\tremaining: 5.11s\n",
      "4181:\tlearn: 1.6658673\ttotal: 51.3s\tremaining: 5.1s\n",
      "4182:\tlearn: 1.6654965\ttotal: 51.3s\tremaining: 5.09s\n",
      "4183:\tlearn: 1.6653359\ttotal: 51.3s\tremaining: 5.08s\n",
      "4184:\tlearn: 1.6651068\ttotal: 51.3s\tremaining: 5.06s\n",
      "4185:\tlearn: 1.6647630\ttotal: 51.3s\tremaining: 5.05s\n",
      "4186:\tlearn: 1.6645894\ttotal: 51.3s\tremaining: 5.04s\n",
      "4187:\tlearn: 1.6644568\ttotal: 51.3s\tremaining: 5.03s\n",
      "4188:\tlearn: 1.6643650\ttotal: 51.3s\tremaining: 5.01s\n",
      "4189:\tlearn: 1.6640685\ttotal: 51.4s\tremaining: 5s\n",
      "4190:\tlearn: 1.6638970\ttotal: 51.4s\tremaining: 4.99s\n",
      "4191:\tlearn: 1.6634830\ttotal: 51.4s\tremaining: 4.98s\n",
      "4192:\tlearn: 1.6630005\ttotal: 51.4s\tremaining: 4.96s\n",
      "4193:\tlearn: 1.6629067\ttotal: 51.4s\tremaining: 4.95s\n",
      "4194:\tlearn: 1.6627727\ttotal: 51.4s\tremaining: 4.94s\n",
      "4195:\tlearn: 1.6625400\ttotal: 51.4s\tremaining: 4.93s\n",
      "4196:\tlearn: 1.6623100\ttotal: 51.4s\tremaining: 4.92s\n",
      "4197:\tlearn: 1.6621821\ttotal: 51.5s\tremaining: 4.9s\n",
      "4198:\tlearn: 1.6619118\ttotal: 51.5s\tremaining: 4.89s\n",
      "4199:\tlearn: 1.6618402\ttotal: 51.5s\tremaining: 4.88s\n",
      "4200:\tlearn: 1.6616226\ttotal: 51.5s\tremaining: 4.87s\n",
      "4201:\tlearn: 1.6614385\ttotal: 51.5s\tremaining: 4.85s\n",
      "4202:\tlearn: 1.6612690\ttotal: 51.5s\tremaining: 4.84s\n",
      "4203:\tlearn: 1.6611718\ttotal: 51.5s\tremaining: 4.83s\n",
      "4204:\tlearn: 1.6609497\ttotal: 51.5s\tremaining: 4.82s\n",
      "4205:\tlearn: 1.6607235\ttotal: 51.6s\tremaining: 4.8s\n",
      "4206:\tlearn: 1.6604398\ttotal: 51.6s\tremaining: 4.79s\n",
      "4207:\tlearn: 1.6602559\ttotal: 51.6s\tremaining: 4.78s\n",
      "4208:\tlearn: 1.6600090\ttotal: 51.6s\tremaining: 4.77s\n",
      "4209:\tlearn: 1.6598049\ttotal: 51.6s\tremaining: 4.75s\n",
      "4210:\tlearn: 1.6596366\ttotal: 51.6s\tremaining: 4.74s\n",
      "4211:\tlearn: 1.6595096\ttotal: 51.6s\tremaining: 4.73s\n",
      "4212:\tlearn: 1.6592984\ttotal: 51.6s\tremaining: 4.72s\n",
      "4213:\tlearn: 1.6591688\ttotal: 51.7s\tremaining: 4.71s\n",
      "4214:\tlearn: 1.6589531\ttotal: 51.7s\tremaining: 4.69s\n",
      "4215:\tlearn: 1.6587164\ttotal: 51.7s\tremaining: 4.68s\n",
      "4216:\tlearn: 1.6585424\ttotal: 51.7s\tremaining: 4.67s\n",
      "4217:\tlearn: 1.6582974\ttotal: 51.7s\tremaining: 4.66s\n",
      "4218:\tlearn: 1.6580774\ttotal: 51.7s\tremaining: 4.64s\n",
      "4219:\tlearn: 1.6578387\ttotal: 51.7s\tremaining: 4.63s\n",
      "4220:\tlearn: 1.6576864\ttotal: 51.7s\tremaining: 4.62s\n",
      "4221:\tlearn: 1.6574037\ttotal: 51.7s\tremaining: 4.61s\n",
      "4222:\tlearn: 1.6571471\ttotal: 51.8s\tremaining: 4.6s\n",
      "4223:\tlearn: 1.6569624\ttotal: 51.8s\tremaining: 4.58s\n",
      "4224:\tlearn: 1.6566205\ttotal: 51.8s\tremaining: 4.57s\n",
      "4225:\tlearn: 1.6563087\ttotal: 51.8s\tremaining: 4.56s\n",
      "4226:\tlearn: 1.6560380\ttotal: 51.8s\tremaining: 4.55s\n",
      "4227:\tlearn: 1.6557767\ttotal: 51.8s\tremaining: 4.54s\n",
      "4228:\tlearn: 1.6556440\ttotal: 51.8s\tremaining: 4.52s\n",
      "4229:\tlearn: 1.6555031\ttotal: 51.8s\tremaining: 4.51s\n",
      "4230:\tlearn: 1.6553863\ttotal: 51.9s\tremaining: 4.5s\n",
      "4231:\tlearn: 1.6552132\ttotal: 51.9s\tremaining: 4.49s\n",
      "4232:\tlearn: 1.6549869\ttotal: 51.9s\tremaining: 4.47s\n",
      "4233:\tlearn: 1.6547846\ttotal: 51.9s\tremaining: 4.46s\n",
      "4234:\tlearn: 1.6544962\ttotal: 51.9s\tremaining: 4.45s\n",
      "4235:\tlearn: 1.6542046\ttotal: 51.9s\tremaining: 4.44s\n",
      "4236:\tlearn: 1.6539566\ttotal: 51.9s\tremaining: 4.42s\n",
      "4237:\tlearn: 1.6536657\ttotal: 51.9s\tremaining: 4.41s\n",
      "4238:\tlearn: 1.6533579\ttotal: 52s\tremaining: 4.4s\n",
      "4239:\tlearn: 1.6530995\ttotal: 52s\tremaining: 4.39s\n",
      "4240:\tlearn: 1.6529786\ttotal: 52s\tremaining: 4.38s\n",
      "4241:\tlearn: 1.6528071\ttotal: 52s\tremaining: 4.36s\n",
      "4242:\tlearn: 1.6527094\ttotal: 52s\tremaining: 4.35s\n",
      "4243:\tlearn: 1.6523071\ttotal: 52s\tremaining: 4.34s\n",
      "4244:\tlearn: 1.6520765\ttotal: 52s\tremaining: 4.33s\n",
      "4245:\tlearn: 1.6517688\ttotal: 52s\tremaining: 4.31s\n",
      "4246:\tlearn: 1.6513655\ttotal: 52.1s\tremaining: 4.3s\n",
      "4247:\tlearn: 1.6510603\ttotal: 52.1s\tremaining: 4.29s\n",
      "4248:\tlearn: 1.6506474\ttotal: 52.1s\tremaining: 4.28s\n",
      "4249:\tlearn: 1.6503987\ttotal: 52.1s\tremaining: 4.26s\n",
      "4250:\tlearn: 1.6501509\ttotal: 52.1s\tremaining: 4.25s\n",
      "4251:\tlearn: 1.6497620\ttotal: 52.1s\tremaining: 4.24s\n",
      "4252:\tlearn: 1.6496207\ttotal: 52.1s\tremaining: 4.23s\n",
      "4253:\tlearn: 1.6495289\ttotal: 52.1s\tremaining: 4.22s\n",
      "4254:\tlearn: 1.6493456\ttotal: 52.2s\tremaining: 4.2s\n",
      "4255:\tlearn: 1.6489106\ttotal: 52.2s\tremaining: 4.19s\n",
      "4256:\tlearn: 1.6487639\ttotal: 52.2s\tremaining: 4.18s\n",
      "4257:\tlearn: 1.6485948\ttotal: 52.2s\tremaining: 4.17s\n",
      "4258:\tlearn: 1.6484870\ttotal: 52.2s\tremaining: 4.16s\n",
      "4259:\tlearn: 1.6483496\ttotal: 52.2s\tremaining: 4.14s\n",
      "4260:\tlearn: 1.6480622\ttotal: 52.2s\tremaining: 4.13s\n",
      "4261:\tlearn: 1.6475111\ttotal: 52.2s\tremaining: 4.12s\n",
      "4262:\tlearn: 1.6472652\ttotal: 52.3s\tremaining: 4.11s\n",
      "4263:\tlearn: 1.6470702\ttotal: 52.3s\tremaining: 4.09s\n",
      "4264:\tlearn: 1.6468526\ttotal: 52.3s\tremaining: 4.08s\n",
      "4265:\tlearn: 1.6466080\ttotal: 52.3s\tremaining: 4.07s\n",
      "4266:\tlearn: 1.6463414\ttotal: 52.3s\tremaining: 4.06s\n",
      "4267:\tlearn: 1.6460571\ttotal: 52.3s\tremaining: 4.04s\n",
      "4268:\tlearn: 1.6459106\ttotal: 52.3s\tremaining: 4.03s\n",
      "4269:\tlearn: 1.6457490\ttotal: 52.3s\tremaining: 4.02s\n",
      "4270:\tlearn: 1.6454817\ttotal: 52.4s\tremaining: 4.01s\n",
      "4271:\tlearn: 1.6451001\ttotal: 52.4s\tremaining: 4s\n",
      "4272:\tlearn: 1.6449719\ttotal: 52.4s\tremaining: 3.98s\n",
      "4273:\tlearn: 1.6448567\ttotal: 52.4s\tremaining: 3.97s\n",
      "4274:\tlearn: 1.6445327\ttotal: 52.4s\tremaining: 3.96s\n",
      "4275:\tlearn: 1.6443572\ttotal: 52.4s\tremaining: 3.95s\n",
      "4276:\tlearn: 1.6441148\ttotal: 52.4s\tremaining: 3.93s\n",
      "4277:\tlearn: 1.6438414\ttotal: 52.4s\tremaining: 3.92s\n",
      "4278:\tlearn: 1.6436445\ttotal: 52.4s\tremaining: 3.91s\n",
      "4279:\tlearn: 1.6434974\ttotal: 52.5s\tremaining: 3.9s\n",
      "4280:\tlearn: 1.6431785\ttotal: 52.5s\tremaining: 3.88s\n",
      "4281:\tlearn: 1.6428705\ttotal: 52.5s\tremaining: 3.87s\n",
      "4282:\tlearn: 1.6426804\ttotal: 52.5s\tremaining: 3.86s\n",
      "4283:\tlearn: 1.6424152\ttotal: 52.5s\tremaining: 3.85s\n",
      "4284:\tlearn: 1.6421380\ttotal: 52.5s\tremaining: 3.84s\n",
      "4285:\tlearn: 1.6417855\ttotal: 52.5s\tremaining: 3.82s\n",
      "4286:\tlearn: 1.6415568\ttotal: 52.5s\tremaining: 3.81s\n",
      "4287:\tlearn: 1.6413291\ttotal: 52.6s\tremaining: 3.8s\n",
      "4288:\tlearn: 1.6409881\ttotal: 52.6s\tremaining: 3.79s\n",
      "4289:\tlearn: 1.6408275\ttotal: 52.6s\tremaining: 3.77s\n",
      "4290:\tlearn: 1.6405643\ttotal: 52.6s\tremaining: 3.76s\n",
      "4291:\tlearn: 1.6403255\ttotal: 52.6s\tremaining: 3.75s\n",
      "4292:\tlearn: 1.6402289\ttotal: 52.6s\tremaining: 3.74s\n",
      "4293:\tlearn: 1.6398687\ttotal: 52.6s\tremaining: 3.73s\n",
      "4294:\tlearn: 1.6394798\ttotal: 52.6s\tremaining: 3.71s\n",
      "4295:\tlearn: 1.6392874\ttotal: 52.7s\tremaining: 3.7s\n",
      "4296:\tlearn: 1.6392102\ttotal: 52.7s\tremaining: 3.69s\n",
      "4297:\tlearn: 1.6390425\ttotal: 52.7s\tremaining: 3.68s\n",
      "4298:\tlearn: 1.6389004\ttotal: 52.7s\tremaining: 3.66s\n",
      "4299:\tlearn: 1.6386892\ttotal: 52.7s\tremaining: 3.65s\n",
      "4300:\tlearn: 1.6385548\ttotal: 52.7s\tremaining: 3.64s\n",
      "4301:\tlearn: 1.6383080\ttotal: 52.7s\tremaining: 3.63s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4302:\tlearn: 1.6381022\ttotal: 52.7s\tremaining: 3.62s\n",
      "4303:\tlearn: 1.6378062\ttotal: 52.8s\tremaining: 3.6s\n",
      "4304:\tlearn: 1.6376679\ttotal: 52.8s\tremaining: 3.59s\n",
      "4305:\tlearn: 1.6374732\ttotal: 52.8s\tremaining: 3.58s\n",
      "4306:\tlearn: 1.6373003\ttotal: 52.8s\tremaining: 3.57s\n",
      "4307:\tlearn: 1.6369094\ttotal: 52.8s\tremaining: 3.55s\n",
      "4308:\tlearn: 1.6368672\ttotal: 52.8s\tremaining: 3.54s\n",
      "4309:\tlearn: 1.6367302\ttotal: 52.8s\tremaining: 3.53s\n",
      "4310:\tlearn: 1.6365399\ttotal: 52.8s\tremaining: 3.52s\n",
      "4311:\tlearn: 1.6364317\ttotal: 52.8s\tremaining: 3.5s\n",
      "4312:\tlearn: 1.6361736\ttotal: 52.9s\tremaining: 3.49s\n",
      "4313:\tlearn: 1.6359067\ttotal: 52.9s\tremaining: 3.48s\n",
      "4314:\tlearn: 1.6356901\ttotal: 52.9s\tremaining: 3.47s\n",
      "4315:\tlearn: 1.6354405\ttotal: 52.9s\tremaining: 3.46s\n",
      "4316:\tlearn: 1.6353090\ttotal: 52.9s\tremaining: 3.44s\n",
      "4317:\tlearn: 1.6349517\ttotal: 52.9s\tremaining: 3.43s\n",
      "4318:\tlearn: 1.6348785\ttotal: 52.9s\tremaining: 3.42s\n",
      "4319:\tlearn: 1.6346247\ttotal: 52.9s\tremaining: 3.41s\n",
      "4320:\tlearn: 1.6343927\ttotal: 53s\tremaining: 3.4s\n",
      "4321:\tlearn: 1.6342330\ttotal: 53s\tremaining: 3.38s\n",
      "4322:\tlearn: 1.6339021\ttotal: 53s\tremaining: 3.37s\n",
      "4323:\tlearn: 1.6338100\ttotal: 53s\tremaining: 3.36s\n",
      "4324:\tlearn: 1.6333551\ttotal: 53s\tremaining: 3.35s\n",
      "4325:\tlearn: 1.6332465\ttotal: 53s\tremaining: 3.33s\n",
      "4326:\tlearn: 1.6329239\ttotal: 53s\tremaining: 3.32s\n",
      "4327:\tlearn: 1.6327539\ttotal: 53s\tremaining: 3.31s\n",
      "4328:\tlearn: 1.6325871\ttotal: 53.1s\tremaining: 3.3s\n",
      "4329:\tlearn: 1.6322438\ttotal: 53.1s\tremaining: 3.28s\n",
      "4330:\tlearn: 1.6321326\ttotal: 53.1s\tremaining: 3.27s\n",
      "4331:\tlearn: 1.6318466\ttotal: 53.1s\tremaining: 3.26s\n",
      "4332:\tlearn: 1.6314816\ttotal: 53.1s\tremaining: 3.25s\n",
      "4333:\tlearn: 1.6313541\ttotal: 53.1s\tremaining: 3.23s\n",
      "4334:\tlearn: 1.6311565\ttotal: 53.1s\tremaining: 3.22s\n",
      "4335:\tlearn: 1.6309596\ttotal: 53.1s\tremaining: 3.21s\n",
      "4336:\tlearn: 1.6306416\ttotal: 53.2s\tremaining: 3.2s\n",
      "4337:\tlearn: 1.6304263\ttotal: 53.2s\tremaining: 3.19s\n",
      "4338:\tlearn: 1.6301673\ttotal: 53.2s\tremaining: 3.17s\n",
      "4339:\tlearn: 1.6298995\ttotal: 53.2s\tremaining: 3.16s\n",
      "4340:\tlearn: 1.6296872\ttotal: 53.2s\tremaining: 3.15s\n",
      "4341:\tlearn: 1.6295982\ttotal: 53.2s\tremaining: 3.14s\n",
      "4342:\tlearn: 1.6292333\ttotal: 53.2s\tremaining: 3.13s\n",
      "4343:\tlearn: 1.6290105\ttotal: 53.2s\tremaining: 3.11s\n",
      "4344:\tlearn: 1.6286300\ttotal: 53.3s\tremaining: 3.1s\n",
      "4345:\tlearn: 1.6282188\ttotal: 53.3s\tremaining: 3.09s\n",
      "4346:\tlearn: 1.6279073\ttotal: 53.3s\tremaining: 3.08s\n",
      "4347:\tlearn: 1.6277167\ttotal: 53.3s\tremaining: 3.06s\n",
      "4348:\tlearn: 1.6275351\ttotal: 53.3s\tremaining: 3.05s\n",
      "4349:\tlearn: 1.6273359\ttotal: 53.3s\tremaining: 3.04s\n",
      "4350:\tlearn: 1.6271969\ttotal: 53.3s\tremaining: 3.03s\n",
      "4351:\tlearn: 1.6268863\ttotal: 53.4s\tremaining: 3.02s\n",
      "4352:\tlearn: 1.6266034\ttotal: 53.4s\tremaining: 3s\n",
      "4353:\tlearn: 1.6262582\ttotal: 53.4s\tremaining: 2.99s\n",
      "4354:\tlearn: 1.6259908\ttotal: 53.4s\tremaining: 2.98s\n",
      "4355:\tlearn: 1.6257936\ttotal: 53.4s\tremaining: 2.97s\n",
      "4356:\tlearn: 1.6255249\ttotal: 53.4s\tremaining: 2.96s\n",
      "4357:\tlearn: 1.6252282\ttotal: 53.4s\tremaining: 2.94s\n",
      "4358:\tlearn: 1.6248431\ttotal: 53.5s\tremaining: 2.93s\n",
      "4359:\tlearn: 1.6245503\ttotal: 53.5s\tremaining: 2.92s\n",
      "4360:\tlearn: 1.6244405\ttotal: 53.5s\tremaining: 2.91s\n",
      "4361:\tlearn: 1.6241726\ttotal: 53.5s\tremaining: 2.89s\n",
      "4362:\tlearn: 1.6240729\ttotal: 53.5s\tremaining: 2.88s\n",
      "4363:\tlearn: 1.6238639\ttotal: 53.5s\tremaining: 2.87s\n",
      "4364:\tlearn: 1.6237627\ttotal: 53.5s\tremaining: 2.86s\n",
      "4365:\tlearn: 1.6235568\ttotal: 53.6s\tremaining: 2.85s\n",
      "4366:\tlearn: 1.6233947\ttotal: 53.6s\tremaining: 2.83s\n",
      "4367:\tlearn: 1.6232884\ttotal: 53.6s\tremaining: 2.82s\n",
      "4368:\tlearn: 1.6229425\ttotal: 53.6s\tremaining: 2.81s\n",
      "4369:\tlearn: 1.6226476\ttotal: 53.6s\tremaining: 2.8s\n",
      "4370:\tlearn: 1.6225119\ttotal: 53.6s\tremaining: 2.79s\n",
      "4371:\tlearn: 1.6223484\ttotal: 53.6s\tremaining: 2.77s\n",
      "4372:\tlearn: 1.6222594\ttotal: 53.7s\tremaining: 2.76s\n",
      "4373:\tlearn: 1.6219277\ttotal: 53.7s\tremaining: 2.75s\n",
      "4374:\tlearn: 1.6216453\ttotal: 53.7s\tremaining: 2.74s\n",
      "4375:\tlearn: 1.6214468\ttotal: 53.7s\tremaining: 2.72s\n",
      "4376:\tlearn: 1.6210691\ttotal: 53.7s\tremaining: 2.71s\n",
      "4377:\tlearn: 1.6207784\ttotal: 53.7s\tremaining: 2.7s\n",
      "4378:\tlearn: 1.6207459\ttotal: 53.7s\tremaining: 2.69s\n",
      "4379:\tlearn: 1.6205943\ttotal: 53.8s\tremaining: 2.67s\n",
      "4380:\tlearn: 1.6202968\ttotal: 53.8s\tremaining: 2.66s\n",
      "4381:\tlearn: 1.6201678\ttotal: 53.8s\tremaining: 2.65s\n",
      "4382:\tlearn: 1.6198157\ttotal: 53.8s\tremaining: 2.64s\n",
      "4383:\tlearn: 1.6195072\ttotal: 53.8s\tremaining: 2.63s\n",
      "4384:\tlearn: 1.6192599\ttotal: 53.8s\tremaining: 2.61s\n",
      "4385:\tlearn: 1.6190905\ttotal: 53.8s\tremaining: 2.6s\n",
      "4386:\tlearn: 1.6185910\ttotal: 53.8s\tremaining: 2.59s\n",
      "4387:\tlearn: 1.6182984\ttotal: 53.9s\tremaining: 2.58s\n",
      "4388:\tlearn: 1.6181753\ttotal: 53.9s\tremaining: 2.56s\n",
      "4389:\tlearn: 1.6180668\ttotal: 53.9s\tremaining: 2.55s\n",
      "4390:\tlearn: 1.6178834\ttotal: 53.9s\tremaining: 2.54s\n",
      "4391:\tlearn: 1.6177671\ttotal: 53.9s\tremaining: 2.53s\n",
      "4392:\tlearn: 1.6175153\ttotal: 53.9s\tremaining: 2.52s\n",
      "4393:\tlearn: 1.6171660\ttotal: 53.9s\tremaining: 2.5s\n",
      "4394:\tlearn: 1.6169827\ttotal: 53.9s\tremaining: 2.49s\n",
      "4395:\tlearn: 1.6166955\ttotal: 54s\tremaining: 2.48s\n",
      "4396:\tlearn: 1.6165252\ttotal: 54s\tremaining: 2.47s\n",
      "4397:\tlearn: 1.6163753\ttotal: 54s\tremaining: 2.45s\n",
      "4398:\tlearn: 1.6161866\ttotal: 54s\tremaining: 2.44s\n",
      "4399:\tlearn: 1.6158119\ttotal: 54s\tremaining: 2.43s\n",
      "4400:\tlearn: 1.6155695\ttotal: 54s\tremaining: 2.42s\n",
      "4401:\tlearn: 1.6154730\ttotal: 54s\tremaining: 2.4s\n",
      "4402:\tlearn: 1.6150600\ttotal: 54s\tremaining: 2.39s\n",
      "4403:\tlearn: 1.6149548\ttotal: 54.1s\tremaining: 2.38s\n",
      "4404:\tlearn: 1.6145624\ttotal: 54.1s\tremaining: 2.37s\n",
      "4405:\tlearn: 1.6145010\ttotal: 54.1s\tremaining: 2.36s\n",
      "4406:\tlearn: 1.6142367\ttotal: 54.1s\tremaining: 2.34s\n",
      "4407:\tlearn: 1.6139846\ttotal: 54.1s\tremaining: 2.33s\n",
      "4408:\tlearn: 1.6137001\ttotal: 54.1s\tremaining: 2.32s\n",
      "4409:\tlearn: 1.6134450\ttotal: 54.1s\tremaining: 2.31s\n",
      "4410:\tlearn: 1.6132866\ttotal: 54.1s\tremaining: 2.29s\n",
      "4411:\tlearn: 1.6130928\ttotal: 54.2s\tremaining: 2.28s\n",
      "4412:\tlearn: 1.6129260\ttotal: 54.2s\tremaining: 2.27s\n",
      "4413:\tlearn: 1.6126770\ttotal: 54.2s\tremaining: 2.26s\n",
      "4414:\tlearn: 1.6123525\ttotal: 54.2s\tremaining: 2.25s\n",
      "4415:\tlearn: 1.6122895\ttotal: 54.2s\tremaining: 2.23s\n",
      "4416:\tlearn: 1.6121747\ttotal: 54.2s\tremaining: 2.22s\n",
      "4417:\tlearn: 1.6119140\ttotal: 54.2s\tremaining: 2.21s\n",
      "4418:\tlearn: 1.6116465\ttotal: 54.2s\tremaining: 2.2s\n",
      "4419:\tlearn: 1.6114856\ttotal: 54.3s\tremaining: 2.18s\n",
      "4420:\tlearn: 1.6112690\ttotal: 54.3s\tremaining: 2.17s\n",
      "4421:\tlearn: 1.6111515\ttotal: 54.3s\tremaining: 2.16s\n",
      "4422:\tlearn: 1.6109516\ttotal: 54.3s\tremaining: 2.15s\n",
      "4423:\tlearn: 1.6105266\ttotal: 54.3s\tremaining: 2.13s\n",
      "4424:\tlearn: 1.6103457\ttotal: 54.3s\tremaining: 2.12s\n",
      "4425:\tlearn: 1.6101487\ttotal: 54.3s\tremaining: 2.11s\n",
      "4426:\tlearn: 1.6099807\ttotal: 54.3s\tremaining: 2.1s\n",
      "4427:\tlearn: 1.6098111\ttotal: 54.4s\tremaining: 2.09s\n",
      "4428:\tlearn: 1.6097176\ttotal: 54.4s\tremaining: 2.07s\n",
      "4429:\tlearn: 1.6096300\ttotal: 54.4s\tremaining: 2.06s\n",
      "4430:\tlearn: 1.6094093\ttotal: 54.4s\tremaining: 2.05s\n",
      "4431:\tlearn: 1.6091449\ttotal: 54.4s\tremaining: 2.04s\n",
      "4432:\tlearn: 1.6089436\ttotal: 54.4s\tremaining: 2.02s\n",
      "4433:\tlearn: 1.6087322\ttotal: 54.4s\tremaining: 2.01s\n",
      "4434:\tlearn: 1.6084833\ttotal: 54.4s\tremaining: 2s\n",
      "4435:\tlearn: 1.6082774\ttotal: 54.5s\tremaining: 1.99s\n",
      "4436:\tlearn: 1.6080264\ttotal: 54.5s\tremaining: 1.98s\n",
      "4437:\tlearn: 1.6077820\ttotal: 54.5s\tremaining: 1.96s\n",
      "4438:\tlearn: 1.6076822\ttotal: 54.5s\tremaining: 1.95s\n",
      "4439:\tlearn: 1.6074593\ttotal: 54.5s\tremaining: 1.94s\n",
      "4440:\tlearn: 1.6072200\ttotal: 54.5s\tremaining: 1.93s\n",
      "4441:\tlearn: 1.6069988\ttotal: 54.5s\tremaining: 1.92s\n",
      "4442:\tlearn: 1.6069046\ttotal: 54.5s\tremaining: 1.9s\n",
      "4443:\tlearn: 1.6067448\ttotal: 54.6s\tremaining: 1.89s\n",
      "4444:\tlearn: 1.6064394\ttotal: 54.6s\tremaining: 1.88s\n",
      "4445:\tlearn: 1.6062059\ttotal: 54.6s\tremaining: 1.86s\n",
      "4446:\tlearn: 1.6061514\ttotal: 54.6s\tremaining: 1.85s\n",
      "4447:\tlearn: 1.6057021\ttotal: 54.6s\tremaining: 1.84s\n",
      "4448:\tlearn: 1.6055482\ttotal: 54.6s\tremaining: 1.83s\n",
      "4449:\tlearn: 1.6054680\ttotal: 54.6s\tremaining: 1.82s\n",
      "4450:\tlearn: 1.6052627\ttotal: 54.6s\tremaining: 1.8s\n",
      "4451:\tlearn: 1.6050963\ttotal: 54.6s\tremaining: 1.79s\n",
      "4452:\tlearn: 1.6047737\ttotal: 54.7s\tremaining: 1.78s\n",
      "4453:\tlearn: 1.6046270\ttotal: 54.7s\tremaining: 1.77s\n",
      "4454:\tlearn: 1.6044126\ttotal: 54.7s\tremaining: 1.75s\n",
      "4455:\tlearn: 1.6040971\ttotal: 54.7s\tremaining: 1.74s\n",
      "4456:\tlearn: 1.6039420\ttotal: 54.7s\tremaining: 1.73s\n",
      "4457:\tlearn: 1.6037734\ttotal: 54.7s\tremaining: 1.72s\n",
      "4458:\tlearn: 1.6035920\ttotal: 54.7s\tremaining: 1.71s\n",
      "4459:\tlearn: 1.6033598\ttotal: 54.7s\tremaining: 1.69s\n",
      "4460:\tlearn: 1.6032824\ttotal: 54.8s\tremaining: 1.68s\n",
      "4461:\tlearn: 1.6031019\ttotal: 54.8s\tremaining: 1.67s\n",
      "4462:\tlearn: 1.6028679\ttotal: 54.8s\tremaining: 1.66s\n",
      "4463:\tlearn: 1.6027524\ttotal: 54.8s\tremaining: 1.64s\n",
      "4464:\tlearn: 1.6026244\ttotal: 54.8s\tremaining: 1.63s\n",
      "4465:\tlearn: 1.6022640\ttotal: 54.8s\tremaining: 1.62s\n",
      "4466:\tlearn: 1.6021869\ttotal: 54.8s\tremaining: 1.61s\n",
      "4467:\tlearn: 1.6019765\ttotal: 54.8s\tremaining: 1.59s\n",
      "4468:\tlearn: 1.6016598\ttotal: 54.9s\tremaining: 1.58s\n",
      "4469:\tlearn: 1.6014307\ttotal: 54.9s\tremaining: 1.57s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4470:\tlearn: 1.6011880\ttotal: 54.9s\tremaining: 1.56s\n",
      "4471:\tlearn: 1.6010805\ttotal: 54.9s\tremaining: 1.55s\n",
      "4472:\tlearn: 1.6007404\ttotal: 54.9s\tremaining: 1.53s\n",
      "4473:\tlearn: 1.6005134\ttotal: 54.9s\tremaining: 1.52s\n",
      "4474:\tlearn: 1.6000964\ttotal: 54.9s\tremaining: 1.51s\n",
      "4475:\tlearn: 1.5999850\ttotal: 54.9s\tremaining: 1.5s\n",
      "4476:\tlearn: 1.5997629\ttotal: 55s\tremaining: 1.49s\n",
      "4477:\tlearn: 1.5994814\ttotal: 55s\tremaining: 1.47s\n",
      "4478:\tlearn: 1.5991546\ttotal: 55s\tremaining: 1.46s\n",
      "4479:\tlearn: 1.5990103\ttotal: 55s\tremaining: 1.45s\n",
      "4480:\tlearn: 1.5988311\ttotal: 55s\tremaining: 1.44s\n",
      "4481:\tlearn: 1.5986763\ttotal: 55s\tremaining: 1.42s\n",
      "4482:\tlearn: 1.5984285\ttotal: 55s\tremaining: 1.41s\n",
      "4483:\tlearn: 1.5983691\ttotal: 55s\tremaining: 1.4s\n",
      "4484:\tlearn: 1.5982487\ttotal: 55.1s\tremaining: 1.39s\n",
      "4485:\tlearn: 1.5981511\ttotal: 55.1s\tremaining: 1.37s\n",
      "4486:\tlearn: 1.5978553\ttotal: 55.1s\tremaining: 1.36s\n",
      "4487:\tlearn: 1.5976122\ttotal: 55.1s\tremaining: 1.35s\n",
      "4488:\tlearn: 1.5975482\ttotal: 55.1s\tremaining: 1.34s\n",
      "4489:\tlearn: 1.5973821\ttotal: 55.1s\tremaining: 1.32s\n",
      "4490:\tlearn: 1.5971574\ttotal: 55.1s\tremaining: 1.31s\n",
      "4491:\tlearn: 1.5969000\ttotal: 55.1s\tremaining: 1.3s\n",
      "4492:\tlearn: 1.5967009\ttotal: 55.2s\tremaining: 1.29s\n",
      "4493:\tlearn: 1.5963696\ttotal: 55.2s\tremaining: 1.28s\n",
      "4494:\tlearn: 1.5960432\ttotal: 55.2s\tremaining: 1.26s\n",
      "4495:\tlearn: 1.5958314\ttotal: 55.2s\tremaining: 1.25s\n",
      "4496:\tlearn: 1.5955837\ttotal: 55.2s\tremaining: 1.24s\n",
      "4497:\tlearn: 1.5952607\ttotal: 55.2s\tremaining: 1.23s\n",
      "4498:\tlearn: 1.5951283\ttotal: 55.2s\tremaining: 1.22s\n",
      "4499:\tlearn: 1.5949498\ttotal: 55.2s\tremaining: 1.2s\n",
      "4500:\tlearn: 1.5947841\ttotal: 55.3s\tremaining: 1.19s\n",
      "4501:\tlearn: 1.5946099\ttotal: 55.3s\tremaining: 1.18s\n",
      "4502:\tlearn: 1.5945343\ttotal: 55.3s\tremaining: 1.17s\n",
      "4503:\tlearn: 1.5943327\ttotal: 55.3s\tremaining: 1.15s\n",
      "4504:\tlearn: 1.5941763\ttotal: 55.3s\tremaining: 1.14s\n",
      "4505:\tlearn: 1.5940539\ttotal: 55.3s\tremaining: 1.13s\n",
      "4506:\tlearn: 1.5938086\ttotal: 55.3s\tremaining: 1.12s\n",
      "4507:\tlearn: 1.5934840\ttotal: 55.3s\tremaining: 1.1s\n",
      "4508:\tlearn: 1.5931002\ttotal: 55.4s\tremaining: 1.09s\n",
      "4509:\tlearn: 1.5926958\ttotal: 55.4s\tremaining: 1.08s\n",
      "4510:\tlearn: 1.5925419\ttotal: 55.4s\tremaining: 1.07s\n",
      "4511:\tlearn: 1.5924214\ttotal: 55.4s\tremaining: 1.05s\n",
      "4512:\tlearn: 1.5920241\ttotal: 55.4s\tremaining: 1.04s\n",
      "4513:\tlearn: 1.5917076\ttotal: 55.4s\tremaining: 1.03s\n",
      "4514:\tlearn: 1.5914131\ttotal: 55.4s\tremaining: 1.02s\n",
      "4515:\tlearn: 1.5912618\ttotal: 55.4s\tremaining: 1.01s\n",
      "4516:\tlearn: 1.5911340\ttotal: 55.5s\tremaining: 994ms\n",
      "4517:\tlearn: 1.5909731\ttotal: 55.5s\tremaining: 982ms\n",
      "4518:\tlearn: 1.5908441\ttotal: 55.5s\tremaining: 970ms\n",
      "4519:\tlearn: 1.5906366\ttotal: 55.5s\tremaining: 958ms\n",
      "4520:\tlearn: 1.5904138\ttotal: 55.5s\tremaining: 945ms\n",
      "4521:\tlearn: 1.5902086\ttotal: 55.5s\tremaining: 933ms\n",
      "4522:\tlearn: 1.5900817\ttotal: 55.5s\tremaining: 921ms\n",
      "4523:\tlearn: 1.5898638\ttotal: 55.5s\tremaining: 908ms\n",
      "4524:\tlearn: 1.5898272\ttotal: 55.5s\tremaining: 896ms\n",
      "4525:\tlearn: 1.5895477\ttotal: 55.6s\tremaining: 884ms\n",
      "4526:\tlearn: 1.5893815\ttotal: 55.6s\tremaining: 872ms\n",
      "4527:\tlearn: 1.5890135\ttotal: 55.6s\tremaining: 859ms\n",
      "4528:\tlearn: 1.5886456\ttotal: 55.6s\tremaining: 847ms\n",
      "4529:\tlearn: 1.5884504\ttotal: 55.6s\tremaining: 835ms\n",
      "4530:\tlearn: 1.5880939\ttotal: 55.6s\tremaining: 823ms\n",
      "4531:\tlearn: 1.5880041\ttotal: 55.6s\tremaining: 810ms\n",
      "4532:\tlearn: 1.5878592\ttotal: 55.6s\tremaining: 798ms\n",
      "4533:\tlearn: 1.5877749\ttotal: 55.7s\tremaining: 786ms\n",
      "4534:\tlearn: 1.5875101\ttotal: 55.7s\tremaining: 773ms\n",
      "4535:\tlearn: 1.5873723\ttotal: 55.7s\tremaining: 761ms\n",
      "4536:\tlearn: 1.5871665\ttotal: 55.7s\tremaining: 749ms\n",
      "4537:\tlearn: 1.5869566\ttotal: 55.7s\tremaining: 737ms\n",
      "4538:\tlearn: 1.5867376\ttotal: 55.7s\tremaining: 724ms\n",
      "4539:\tlearn: 1.5866323\ttotal: 55.7s\tremaining: 712ms\n",
      "4540:\tlearn: 1.5863649\ttotal: 55.8s\tremaining: 700ms\n",
      "4541:\tlearn: 1.5862424\ttotal: 55.8s\tremaining: 688ms\n",
      "4542:\tlearn: 1.5859059\ttotal: 55.8s\tremaining: 675ms\n",
      "4543:\tlearn: 1.5857600\ttotal: 55.8s\tremaining: 663ms\n",
      "4544:\tlearn: 1.5855524\ttotal: 55.8s\tremaining: 651ms\n",
      "4545:\tlearn: 1.5851618\ttotal: 55.8s\tremaining: 638ms\n",
      "4546:\tlearn: 1.5850021\ttotal: 55.8s\tremaining: 626ms\n",
      "4547:\tlearn: 1.5846916\ttotal: 55.8s\tremaining: 614ms\n",
      "4548:\tlearn: 1.5844850\ttotal: 55.8s\tremaining: 602ms\n",
      "4549:\tlearn: 1.5842078\ttotal: 55.9s\tremaining: 589ms\n",
      "4550:\tlearn: 1.5841075\ttotal: 55.9s\tremaining: 577ms\n",
      "4551:\tlearn: 1.5840003\ttotal: 55.9s\tremaining: 565ms\n",
      "4552:\tlearn: 1.5838514\ttotal: 55.9s\tremaining: 552ms\n",
      "4553:\tlearn: 1.5837505\ttotal: 55.9s\tremaining: 540ms\n",
      "4554:\tlearn: 1.5836781\ttotal: 55.9s\tremaining: 528ms\n",
      "4555:\tlearn: 1.5835670\ttotal: 55.9s\tremaining: 516ms\n",
      "4556:\tlearn: 1.5833653\ttotal: 56s\tremaining: 503ms\n",
      "4557:\tlearn: 1.5830170\ttotal: 56s\tremaining: 491ms\n",
      "4558:\tlearn: 1.5829155\ttotal: 56s\tremaining: 479ms\n",
      "4559:\tlearn: 1.5828175\ttotal: 56s\tremaining: 467ms\n",
      "4560:\tlearn: 1.5827474\ttotal: 56s\tremaining: 454ms\n",
      "4561:\tlearn: 1.5825214\ttotal: 56s\tremaining: 442ms\n",
      "4562:\tlearn: 1.5822567\ttotal: 56s\tremaining: 430ms\n",
      "4563:\tlearn: 1.5821298\ttotal: 56s\tremaining: 417ms\n",
      "4564:\tlearn: 1.5818646\ttotal: 56s\tremaining: 405ms\n",
      "4565:\tlearn: 1.5817671\ttotal: 56.1s\tremaining: 393ms\n",
      "4566:\tlearn: 1.5817172\ttotal: 56.1s\tremaining: 381ms\n",
      "4567:\tlearn: 1.5813623\ttotal: 56.1s\tremaining: 368ms\n",
      "4568:\tlearn: 1.5812839\ttotal: 56.1s\tremaining: 356ms\n",
      "4569:\tlearn: 1.5812602\ttotal: 56.1s\tremaining: 344ms\n",
      "4570:\tlearn: 1.5809253\ttotal: 56.1s\tremaining: 331ms\n",
      "4571:\tlearn: 1.5807045\ttotal: 56.1s\tremaining: 319ms\n",
      "4572:\tlearn: 1.5806474\ttotal: 56.1s\tremaining: 307ms\n",
      "4573:\tlearn: 1.5802626\ttotal: 56.2s\tremaining: 295ms\n",
      "4574:\tlearn: 1.5800538\ttotal: 56.2s\tremaining: 282ms\n",
      "4575:\tlearn: 1.5798662\ttotal: 56.2s\tremaining: 270ms\n",
      "4576:\tlearn: 1.5797043\ttotal: 56.2s\tremaining: 258ms\n",
      "4577:\tlearn: 1.5795111\ttotal: 56.2s\tremaining: 246ms\n",
      "4578:\tlearn: 1.5793502\ttotal: 56.2s\tremaining: 233ms\n",
      "4579:\tlearn: 1.5792116\ttotal: 56.2s\tremaining: 221ms\n",
      "4580:\tlearn: 1.5789280\ttotal: 56.2s\tremaining: 209ms\n",
      "4581:\tlearn: 1.5786455\ttotal: 56.3s\tremaining: 196ms\n",
      "4582:\tlearn: 1.5784975\ttotal: 56.3s\tremaining: 184ms\n",
      "4583:\tlearn: 1.5782763\ttotal: 56.3s\tremaining: 172ms\n",
      "4584:\tlearn: 1.5779803\ttotal: 56.3s\tremaining: 160ms\n",
      "4585:\tlearn: 1.5777435\ttotal: 56.3s\tremaining: 147ms\n",
      "4586:\tlearn: 1.5775260\ttotal: 56.3s\tremaining: 135ms\n",
      "4587:\tlearn: 1.5773431\ttotal: 56.3s\tremaining: 123ms\n",
      "4588:\tlearn: 1.5771846\ttotal: 56.3s\tremaining: 111ms\n",
      "4589:\tlearn: 1.5770652\ttotal: 56.4s\tremaining: 98.2ms\n",
      "4590:\tlearn: 1.5768189\ttotal: 56.4s\tremaining: 86ms\n",
      "4591:\tlearn: 1.5766200\ttotal: 56.4s\tremaining: 73.7ms\n",
      "4592:\tlearn: 1.5764108\ttotal: 56.4s\tremaining: 61.4ms\n",
      "4593:\tlearn: 1.5761879\ttotal: 56.4s\tremaining: 49.1ms\n",
      "4594:\tlearn: 1.5760262\ttotal: 56.4s\tremaining: 36.8ms\n",
      "4595:\tlearn: 1.5759068\ttotal: 56.4s\tremaining: 24.6ms\n",
      "4596:\tlearn: 1.5757199\ttotal: 56.4s\tremaining: 12.3ms\n",
      "4597:\tlearn: 1.5754194\ttotal: 56.5s\tremaining: 0us\n",
      "0:\tlearn: 14.8337840\ttotal: 12.9ms\tremaining: 59.2s\n",
      "1:\tlearn: 13.4036219\ttotal: 28.7ms\tremaining: 1m 5s\n",
      "2:\tlearn: 12.1550547\ttotal: 44.5ms\tremaining: 1m 8s\n",
      "3:\tlearn: 11.0544670\ttotal: 59.4ms\tremaining: 1m 8s\n",
      "4:\tlearn: 10.1040393\ttotal: 74.4ms\tremaining: 1m 8s\n",
      "5:\tlearn: 9.2892960\ttotal: 89.1ms\tremaining: 1m 8s\n",
      "6:\tlearn: 8.5747663\ttotal: 104ms\tremaining: 1m 8s\n",
      "7:\tlearn: 7.9560515\ttotal: 119ms\tremaining: 1m 8s\n",
      "8:\tlearn: 7.4315902\ttotal: 134ms\tremaining: 1m 8s\n",
      "9:\tlearn: 6.9758874\ttotal: 148ms\tremaining: 1m 8s\n",
      "10:\tlearn: 6.5954665\ttotal: 164ms\tremaining: 1m 8s\n",
      "11:\tlearn: 6.2684323\ttotal: 178ms\tremaining: 1m 8s\n",
      "12:\tlearn: 5.9987183\ttotal: 193ms\tremaining: 1m 7s\n",
      "13:\tlearn: 5.7719606\ttotal: 206ms\tremaining: 1m 7s\n",
      "14:\tlearn: 5.5780313\ttotal: 222ms\tremaining: 1m 7s\n",
      "15:\tlearn: 5.4221757\ttotal: 236ms\tremaining: 1m 7s\n",
      "16:\tlearn: 5.2851995\ttotal: 252ms\tremaining: 1m 7s\n",
      "17:\tlearn: 5.1721146\ttotal: 265ms\tremaining: 1m 7s\n",
      "18:\tlearn: 5.0704718\ttotal: 279ms\tremaining: 1m 7s\n",
      "19:\tlearn: 4.9918556\ttotal: 293ms\tremaining: 1m 7s\n",
      "20:\tlearn: 4.9210448\ttotal: 306ms\tremaining: 1m 6s\n",
      "21:\tlearn: 4.8617570\ttotal: 320ms\tremaining: 1m 6s\n",
      "22:\tlearn: 4.8133935\ttotal: 334ms\tremaining: 1m 6s\n",
      "23:\tlearn: 4.7677802\ttotal: 347ms\tremaining: 1m 6s\n",
      "24:\tlearn: 4.7275376\ttotal: 359ms\tremaining: 1m 5s\n",
      "25:\tlearn: 4.6942753\ttotal: 373ms\tremaining: 1m 5s\n",
      "26:\tlearn: 4.6704653\ttotal: 385ms\tremaining: 1m 5s\n",
      "27:\tlearn: 4.6480800\ttotal: 398ms\tremaining: 1m 4s\n",
      "28:\tlearn: 4.6272643\ttotal: 411ms\tremaining: 1m 4s\n",
      "29:\tlearn: 4.6066919\ttotal: 425ms\tremaining: 1m 4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30:\tlearn: 4.5891203\ttotal: 438ms\tremaining: 1m 4s\n",
      "31:\tlearn: 4.5737497\ttotal: 454ms\tremaining: 1m 4s\n",
      "32:\tlearn: 4.5598877\ttotal: 468ms\tremaining: 1m 4s\n",
      "33:\tlearn: 4.5481095\ttotal: 480ms\tremaining: 1m 4s\n",
      "34:\tlearn: 4.5346747\ttotal: 493ms\tremaining: 1m 4s\n",
      "35:\tlearn: 4.5236821\ttotal: 506ms\tremaining: 1m 4s\n",
      "36:\tlearn: 4.5142217\ttotal: 519ms\tremaining: 1m 3s\n",
      "37:\tlearn: 4.5046002\ttotal: 532ms\tremaining: 1m 3s\n",
      "38:\tlearn: 4.4935200\ttotal: 545ms\tremaining: 1m 3s\n",
      "39:\tlearn: 4.4859597\ttotal: 558ms\tremaining: 1m 3s\n",
      "40:\tlearn: 4.4784243\ttotal: 570ms\tremaining: 1m 3s\n",
      "41:\tlearn: 4.4632031\ttotal: 584ms\tremaining: 1m 3s\n",
      "42:\tlearn: 4.4568934\ttotal: 597ms\tremaining: 1m 3s\n",
      "43:\tlearn: 4.4484592\ttotal: 610ms\tremaining: 1m 3s\n",
      "44:\tlearn: 4.4392106\ttotal: 623ms\tremaining: 1m 3s\n",
      "45:\tlearn: 4.4313174\ttotal: 636ms\tremaining: 1m 2s\n",
      "46:\tlearn: 4.4239909\ttotal: 650ms\tremaining: 1m 2s\n",
      "47:\tlearn: 4.4179016\ttotal: 665ms\tremaining: 1m 3s\n",
      "48:\tlearn: 4.4079909\ttotal: 678ms\tremaining: 1m 2s\n",
      "49:\tlearn: 4.4006547\ttotal: 692ms\tremaining: 1m 2s\n",
      "50:\tlearn: 4.3920854\ttotal: 706ms\tremaining: 1m 2s\n",
      "51:\tlearn: 4.3884088\ttotal: 718ms\tremaining: 1m 2s\n",
      "52:\tlearn: 4.3823190\ttotal: 731ms\tremaining: 1m 2s\n",
      "53:\tlearn: 4.3786131\ttotal: 744ms\tremaining: 1m 2s\n",
      "54:\tlearn: 4.3733554\ttotal: 757ms\tremaining: 1m 2s\n",
      "55:\tlearn: 4.3668648\ttotal: 771ms\tremaining: 1m 2s\n",
      "56:\tlearn: 4.3582359\ttotal: 784ms\tremaining: 1m 2s\n",
      "57:\tlearn: 4.3517482\ttotal: 797ms\tremaining: 1m 2s\n",
      "58:\tlearn: 4.3481564\ttotal: 809ms\tremaining: 1m 2s\n",
      "59:\tlearn: 4.3430966\ttotal: 822ms\tremaining: 1m 2s\n",
      "60:\tlearn: 4.3384284\ttotal: 835ms\tremaining: 1m 2s\n",
      "61:\tlearn: 4.3346855\ttotal: 847ms\tremaining: 1m 1s\n",
      "62:\tlearn: 4.3271330\ttotal: 862ms\tremaining: 1m 2s\n",
      "63:\tlearn: 4.3228200\ttotal: 876ms\tremaining: 1m 2s\n",
      "64:\tlearn: 4.3187543\ttotal: 890ms\tremaining: 1m 2s\n",
      "65:\tlearn: 4.3143096\ttotal: 905ms\tremaining: 1m 2s\n",
      "66:\tlearn: 4.3085146\ttotal: 918ms\tremaining: 1m 2s\n",
      "67:\tlearn: 4.3040041\ttotal: 932ms\tremaining: 1m 2s\n",
      "68:\tlearn: 4.3005091\ttotal: 946ms\tremaining: 1m 2s\n",
      "69:\tlearn: 4.2978508\ttotal: 959ms\tremaining: 1m 2s\n",
      "70:\tlearn: 4.2933953\ttotal: 973ms\tremaining: 1m 2s\n",
      "71:\tlearn: 4.2894014\ttotal: 985ms\tremaining: 1m 1s\n",
      "72:\tlearn: 4.2851592\ttotal: 999ms\tremaining: 1m 1s\n",
      "73:\tlearn: 4.2825511\ttotal: 1.01s\tremaining: 1m 1s\n",
      "74:\tlearn: 4.2788413\ttotal: 1.02s\tremaining: 1m 1s\n",
      "75:\tlearn: 4.2757613\ttotal: 1.04s\tremaining: 1m 1s\n",
      "76:\tlearn: 4.2718289\ttotal: 1.05s\tremaining: 1m 1s\n",
      "77:\tlearn: 4.2688436\ttotal: 1.07s\tremaining: 1m 1s\n",
      "78:\tlearn: 4.2640475\ttotal: 1.08s\tremaining: 1m 1s\n",
      "79:\tlearn: 4.2598869\ttotal: 1.1s\tremaining: 1m 2s\n",
      "80:\tlearn: 4.2510972\ttotal: 1.11s\tremaining: 1m 2s\n",
      "81:\tlearn: 4.2467477\ttotal: 1.13s\tremaining: 1m 2s\n",
      "82:\tlearn: 4.2428240\ttotal: 1.14s\tremaining: 1m 2s\n",
      "83:\tlearn: 4.2372803\ttotal: 1.16s\tremaining: 1m 2s\n",
      "84:\tlearn: 4.2338878\ttotal: 1.18s\tremaining: 1m 2s\n",
      "85:\tlearn: 4.2259871\ttotal: 1.19s\tremaining: 1m 2s\n",
      "86:\tlearn: 4.2221505\ttotal: 1.21s\tremaining: 1m 2s\n",
      "87:\tlearn: 4.2183439\ttotal: 1.22s\tremaining: 1m 2s\n",
      "88:\tlearn: 4.2162166\ttotal: 1.23s\tremaining: 1m 2s\n",
      "89:\tlearn: 4.2140252\ttotal: 1.25s\tremaining: 1m 2s\n",
      "90:\tlearn: 4.2103380\ttotal: 1.26s\tremaining: 1m 2s\n",
      "91:\tlearn: 4.2085219\ttotal: 1.28s\tremaining: 1m 2s\n",
      "92:\tlearn: 4.2014825\ttotal: 1.29s\tremaining: 1m 2s\n",
      "93:\tlearn: 4.1992533\ttotal: 1.31s\tremaining: 1m 2s\n",
      "94:\tlearn: 4.1950249\ttotal: 1.32s\tremaining: 1m 2s\n",
      "95:\tlearn: 4.1917669\ttotal: 1.33s\tremaining: 1m 2s\n",
      "96:\tlearn: 4.1868291\ttotal: 1.35s\tremaining: 1m 2s\n",
      "97:\tlearn: 4.1834544\ttotal: 1.36s\tremaining: 1m 2s\n",
      "98:\tlearn: 4.1784536\ttotal: 1.37s\tremaining: 1m 2s\n",
      "99:\tlearn: 4.1762831\ttotal: 1.39s\tremaining: 1m 2s\n",
      "100:\tlearn: 4.1725763\ttotal: 1.4s\tremaining: 1m 2s\n",
      "101:\tlearn: 4.1710162\ttotal: 1.41s\tremaining: 1m 2s\n",
      "102:\tlearn: 4.1670159\ttotal: 1.43s\tremaining: 1m 2s\n",
      "103:\tlearn: 4.1645026\ttotal: 1.44s\tremaining: 1m 2s\n",
      "104:\tlearn: 4.1604872\ttotal: 1.45s\tremaining: 1m 2s\n",
      "105:\tlearn: 4.1576440\ttotal: 1.47s\tremaining: 1m 2s\n",
      "106:\tlearn: 4.1543212\ttotal: 1.48s\tremaining: 1m 2s\n",
      "107:\tlearn: 4.1496882\ttotal: 1.5s\tremaining: 1m 2s\n",
      "108:\tlearn: 4.1456947\ttotal: 1.51s\tremaining: 1m 2s\n",
      "109:\tlearn: 4.1424608\ttotal: 1.52s\tremaining: 1m 2s\n",
      "110:\tlearn: 4.1377722\ttotal: 1.54s\tremaining: 1m 2s\n",
      "111:\tlearn: 4.1334915\ttotal: 1.55s\tremaining: 1m 2s\n",
      "112:\tlearn: 4.1278433\ttotal: 1.56s\tremaining: 1m 2s\n",
      "113:\tlearn: 4.1228190\ttotal: 1.58s\tremaining: 1m 2s\n",
      "114:\tlearn: 4.1194846\ttotal: 1.59s\tremaining: 1m 1s\n",
      "115:\tlearn: 4.1159130\ttotal: 1.6s\tremaining: 1m 1s\n",
      "116:\tlearn: 4.1127153\ttotal: 1.61s\tremaining: 1m 1s\n",
      "117:\tlearn: 4.1095834\ttotal: 1.63s\tremaining: 1m 1s\n",
      "118:\tlearn: 4.1045138\ttotal: 1.64s\tremaining: 1m 1s\n",
      "119:\tlearn: 4.1018448\ttotal: 1.66s\tremaining: 1m 1s\n",
      "120:\tlearn: 4.0998760\ttotal: 1.67s\tremaining: 1m 1s\n",
      "121:\tlearn: 4.0973078\ttotal: 1.68s\tremaining: 1m 1s\n",
      "122:\tlearn: 4.0950441\ttotal: 1.69s\tremaining: 1m 1s\n",
      "123:\tlearn: 4.0914342\ttotal: 1.71s\tremaining: 1m 1s\n",
      "124:\tlearn: 4.0870555\ttotal: 1.72s\tremaining: 1m 1s\n",
      "125:\tlearn: 4.0849914\ttotal: 1.73s\tremaining: 1m 1s\n",
      "126:\tlearn: 4.0823288\ttotal: 1.75s\tremaining: 1m 1s\n",
      "127:\tlearn: 4.0793809\ttotal: 1.76s\tremaining: 1m 1s\n",
      "128:\tlearn: 4.0766434\ttotal: 1.77s\tremaining: 1m 1s\n",
      "129:\tlearn: 4.0732665\ttotal: 1.78s\tremaining: 1m 1s\n",
      "130:\tlearn: 4.0697607\ttotal: 1.79s\tremaining: 1m 1s\n",
      "131:\tlearn: 4.0667908\ttotal: 1.81s\tremaining: 1m 1s\n",
      "132:\tlearn: 4.0621413\ttotal: 1.82s\tremaining: 1m 1s\n",
      "133:\tlearn: 4.0594529\ttotal: 1.83s\tremaining: 1m 1s\n",
      "134:\tlearn: 4.0551077\ttotal: 1.85s\tremaining: 1m 1s\n",
      "135:\tlearn: 4.0504383\ttotal: 1.86s\tremaining: 1m 1s\n",
      "136:\tlearn: 4.0470175\ttotal: 1.88s\tremaining: 1m 1s\n",
      "137:\tlearn: 4.0445192\ttotal: 1.89s\tremaining: 1m 1s\n",
      "138:\tlearn: 4.0416012\ttotal: 1.9s\tremaining: 1m 1s\n",
      "139:\tlearn: 4.0374506\ttotal: 1.92s\tremaining: 1m 1s\n",
      "140:\tlearn: 4.0345296\ttotal: 1.93s\tremaining: 1m 1s\n",
      "141:\tlearn: 4.0319615\ttotal: 1.94s\tremaining: 1m 1s\n",
      "142:\tlearn: 4.0290886\ttotal: 1.96s\tremaining: 1m 1s\n",
      "143:\tlearn: 4.0244560\ttotal: 1.97s\tremaining: 1m\n",
      "144:\tlearn: 4.0218951\ttotal: 1.98s\tremaining: 1m\n",
      "145:\tlearn: 4.0190424\ttotal: 2s\tremaining: 1m\n",
      "146:\tlearn: 4.0165183\ttotal: 2.01s\tremaining: 1m\n",
      "147:\tlearn: 4.0140648\ttotal: 2.02s\tremaining: 1m\n",
      "148:\tlearn: 4.0104053\ttotal: 2.04s\tremaining: 1m\n",
      "149:\tlearn: 4.0064116\ttotal: 2.05s\tremaining: 1m\n",
      "150:\tlearn: 4.0030204\ttotal: 2.07s\tremaining: 1m\n",
      "151:\tlearn: 4.0005587\ttotal: 2.08s\tremaining: 1m\n",
      "152:\tlearn: 3.9976230\ttotal: 2.1s\tremaining: 1m 1s\n",
      "153:\tlearn: 3.9939822\ttotal: 2.12s\tremaining: 1m 1s\n",
      "154:\tlearn: 3.9912072\ttotal: 2.13s\tremaining: 1m 1s\n",
      "155:\tlearn: 3.9885163\ttotal: 2.15s\tremaining: 1m 1s\n",
      "156:\tlearn: 3.9865116\ttotal: 2.17s\tremaining: 1m 1s\n",
      "157:\tlearn: 3.9844330\ttotal: 2.18s\tremaining: 1m 1s\n",
      "158:\tlearn: 3.9781538\ttotal: 2.19s\tremaining: 1m 1s\n",
      "159:\tlearn: 3.9755677\ttotal: 2.21s\tremaining: 1m 1s\n",
      "160:\tlearn: 3.9733870\ttotal: 2.22s\tremaining: 1m 1s\n",
      "161:\tlearn: 3.9706150\ttotal: 2.23s\tremaining: 1m 1s\n",
      "162:\tlearn: 3.9671211\ttotal: 2.25s\tremaining: 1m 1s\n",
      "163:\tlearn: 3.9636602\ttotal: 2.26s\tremaining: 1m 1s\n",
      "164:\tlearn: 3.9615829\ttotal: 2.27s\tremaining: 1m 1s\n",
      "165:\tlearn: 3.9575629\ttotal: 2.28s\tremaining: 1m\n",
      "166:\tlearn: 3.9555082\ttotal: 2.29s\tremaining: 1m\n",
      "167:\tlearn: 3.9518072\ttotal: 2.31s\tremaining: 1m\n",
      "168:\tlearn: 3.9496532\ttotal: 2.32s\tremaining: 1m\n",
      "169:\tlearn: 3.9464957\ttotal: 2.33s\tremaining: 1m\n",
      "170:\tlearn: 3.9435034\ttotal: 2.35s\tremaining: 1m\n",
      "171:\tlearn: 3.9408045\ttotal: 2.36s\tremaining: 1m\n",
      "172:\tlearn: 3.9375081\ttotal: 2.37s\tremaining: 1m\n",
      "173:\tlearn: 3.9353809\ttotal: 2.38s\tremaining: 1m\n",
      "174:\tlearn: 3.9329263\ttotal: 2.4s\tremaining: 1m\n",
      "175:\tlearn: 3.9306885\ttotal: 2.41s\tremaining: 1m\n",
      "176:\tlearn: 3.9292616\ttotal: 2.42s\tremaining: 1m\n",
      "177:\tlearn: 3.9274792\ttotal: 2.43s\tremaining: 1m\n",
      "178:\tlearn: 3.9256503\ttotal: 2.44s\tremaining: 1m\n",
      "179:\tlearn: 3.9236510\ttotal: 2.46s\tremaining: 1m\n",
      "180:\tlearn: 3.9217252\ttotal: 2.47s\tremaining: 1m\n",
      "181:\tlearn: 3.9191918\ttotal: 2.48s\tremaining: 1m\n",
      "182:\tlearn: 3.9172249\ttotal: 2.49s\tremaining: 1m\n",
      "183:\tlearn: 3.9146477\ttotal: 2.5s\tremaining: 1m\n",
      "184:\tlearn: 3.9120395\ttotal: 2.52s\tremaining: 1m\n",
      "185:\tlearn: 3.9100818\ttotal: 2.53s\tremaining: 59.9s\n",
      "186:\tlearn: 3.9066556\ttotal: 2.54s\tremaining: 59.9s\n",
      "187:\tlearn: 3.9047468\ttotal: 2.55s\tremaining: 59.9s\n",
      "188:\tlearn: 3.9018362\ttotal: 2.57s\tremaining: 59.9s\n",
      "189:\tlearn: 3.9002706\ttotal: 2.58s\tremaining: 59.8s\n",
      "190:\tlearn: 3.8958377\ttotal: 2.59s\tremaining: 59.8s\n",
      "191:\tlearn: 3.8931265\ttotal: 2.6s\tremaining: 59.7s\n",
      "192:\tlearn: 3.8906927\ttotal: 2.62s\tremaining: 59.7s\n",
      "193:\tlearn: 3.8887496\ttotal: 2.63s\tremaining: 59.6s\n",
      "194:\tlearn: 3.8873287\ttotal: 2.64s\tremaining: 59.6s\n",
      "195:\tlearn: 3.8839722\ttotal: 2.65s\tremaining: 59.6s\n",
      "196:\tlearn: 3.8815958\ttotal: 2.66s\tremaining: 59.5s\n",
      "197:\tlearn: 3.8779061\ttotal: 2.67s\tremaining: 59.4s\n",
      "198:\tlearn: 3.8754215\ttotal: 2.69s\tremaining: 59.4s\n",
      "199:\tlearn: 3.8739335\ttotal: 2.7s\tremaining: 59.3s\n",
      "200:\tlearn: 3.8719714\ttotal: 2.71s\tremaining: 59.3s\n",
      "201:\tlearn: 3.8699867\ttotal: 2.72s\tremaining: 59.2s\n",
      "202:\tlearn: 3.8675226\ttotal: 2.73s\tremaining: 59.2s\n",
      "203:\tlearn: 3.8657885\ttotal: 2.75s\tremaining: 59.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204:\tlearn: 3.8639002\ttotal: 2.76s\tremaining: 59.2s\n",
      "205:\tlearn: 3.8596886\ttotal: 2.77s\tremaining: 59.2s\n",
      "206:\tlearn: 3.8573311\ttotal: 2.79s\tremaining: 59.1s\n",
      "207:\tlearn: 3.8558685\ttotal: 2.8s\tremaining: 59.1s\n",
      "208:\tlearn: 3.8546097\ttotal: 2.81s\tremaining: 59.1s\n",
      "209:\tlearn: 3.8517559\ttotal: 2.82s\tremaining: 59s\n",
      "210:\tlearn: 3.8494614\ttotal: 2.83s\tremaining: 59s\n",
      "211:\tlearn: 3.8476268\ttotal: 2.85s\tremaining: 58.9s\n",
      "212:\tlearn: 3.8460819\ttotal: 2.86s\tremaining: 58.8s\n",
      "213:\tlearn: 3.8430250\ttotal: 2.87s\tremaining: 58.8s\n",
      "214:\tlearn: 3.8413140\ttotal: 2.88s\tremaining: 58.8s\n",
      "215:\tlearn: 3.8396416\ttotal: 2.89s\tremaining: 58.7s\n",
      "216:\tlearn: 3.8369680\ttotal: 2.91s\tremaining: 58.7s\n",
      "217:\tlearn: 3.8357660\ttotal: 2.92s\tremaining: 58.6s\n",
      "218:\tlearn: 3.8344393\ttotal: 2.93s\tremaining: 58.6s\n",
      "219:\tlearn: 3.8330086\ttotal: 2.94s\tremaining: 58.6s\n",
      "220:\tlearn: 3.8304125\ttotal: 2.96s\tremaining: 58.5s\n",
      "221:\tlearn: 3.8277356\ttotal: 2.97s\tremaining: 58.5s\n",
      "222:\tlearn: 3.8259140\ttotal: 2.98s\tremaining: 58.5s\n",
      "223:\tlearn: 3.8239157\ttotal: 2.99s\tremaining: 58.4s\n",
      "224:\tlearn: 3.8222716\ttotal: 3s\tremaining: 58.4s\n",
      "225:\tlearn: 3.8208504\ttotal: 3.02s\tremaining: 58.3s\n",
      "226:\tlearn: 3.8184184\ttotal: 3.03s\tremaining: 58.3s\n",
      "227:\tlearn: 3.8158504\ttotal: 3.04s\tremaining: 58.3s\n",
      "228:\tlearn: 3.8138110\ttotal: 3.05s\tremaining: 58.2s\n",
      "229:\tlearn: 3.8113765\ttotal: 3.06s\tremaining: 58.2s\n",
      "230:\tlearn: 3.8096574\ttotal: 3.08s\tremaining: 58.2s\n",
      "231:\tlearn: 3.8076195\ttotal: 3.09s\tremaining: 58.1s\n",
      "232:\tlearn: 3.8044329\ttotal: 3.1s\tremaining: 58.1s\n",
      "233:\tlearn: 3.8023620\ttotal: 3.11s\tremaining: 58s\n",
      "234:\tlearn: 3.7987852\ttotal: 3.12s\tremaining: 58s\n",
      "235:\tlearn: 3.7970826\ttotal: 3.13s\tremaining: 58s\n",
      "236:\tlearn: 3.7943727\ttotal: 3.15s\tremaining: 57.9s\n",
      "237:\tlearn: 3.7937922\ttotal: 3.16s\tremaining: 57.8s\n",
      "238:\tlearn: 3.7918772\ttotal: 3.17s\tremaining: 57.8s\n",
      "239:\tlearn: 3.7898499\ttotal: 3.18s\tremaining: 57.8s\n",
      "240:\tlearn: 3.7878173\ttotal: 3.2s\tremaining: 57.8s\n",
      "241:\tlearn: 3.7853974\ttotal: 3.21s\tremaining: 57.8s\n",
      "242:\tlearn: 3.7833736\ttotal: 3.22s\tremaining: 57.8s\n",
      "243:\tlearn: 3.7808404\ttotal: 3.23s\tremaining: 57.7s\n",
      "244:\tlearn: 3.7791915\ttotal: 3.25s\tremaining: 57.7s\n",
      "245:\tlearn: 3.7773909\ttotal: 3.26s\tremaining: 57.7s\n",
      "246:\tlearn: 3.7756667\ttotal: 3.27s\tremaining: 57.6s\n",
      "247:\tlearn: 3.7743208\ttotal: 3.28s\tremaining: 57.6s\n",
      "248:\tlearn: 3.7724504\ttotal: 3.29s\tremaining: 57.5s\n",
      "249:\tlearn: 3.7709710\ttotal: 3.3s\tremaining: 57.5s\n",
      "250:\tlearn: 3.7695080\ttotal: 3.32s\tremaining: 57.4s\n",
      "251:\tlearn: 3.7680815\ttotal: 3.33s\tremaining: 57.4s\n",
      "252:\tlearn: 3.7651162\ttotal: 3.34s\tremaining: 57.4s\n",
      "253:\tlearn: 3.7628491\ttotal: 3.35s\tremaining: 57.3s\n",
      "254:\tlearn: 3.7608913\ttotal: 3.36s\tremaining: 57.3s\n",
      "255:\tlearn: 3.7587901\ttotal: 3.37s\tremaining: 57.2s\n",
      "256:\tlearn: 3.7570264\ttotal: 3.39s\tremaining: 57.2s\n",
      "257:\tlearn: 3.7543409\ttotal: 3.4s\tremaining: 57.2s\n",
      "258:\tlearn: 3.7526023\ttotal: 3.41s\tremaining: 57.2s\n",
      "259:\tlearn: 3.7499947\ttotal: 3.42s\tremaining: 57.1s\n",
      "260:\tlearn: 3.7478507\ttotal: 3.44s\tremaining: 57.1s\n",
      "261:\tlearn: 3.7453519\ttotal: 3.45s\tremaining: 57.1s\n",
      "262:\tlearn: 3.7441668\ttotal: 3.46s\tremaining: 57.1s\n",
      "263:\tlearn: 3.7416429\ttotal: 3.47s\tremaining: 57s\n",
      "264:\tlearn: 3.7404186\ttotal: 3.48s\tremaining: 57s\n",
      "265:\tlearn: 3.7391571\ttotal: 3.5s\tremaining: 56.9s\n",
      "266:\tlearn: 3.7374113\ttotal: 3.51s\tremaining: 56.9s\n",
      "267:\tlearn: 3.7363358\ttotal: 3.52s\tremaining: 56.9s\n",
      "268:\tlearn: 3.7345379\ttotal: 3.53s\tremaining: 56.8s\n",
      "269:\tlearn: 3.7330765\ttotal: 3.54s\tremaining: 56.8s\n",
      "270:\tlearn: 3.7318914\ttotal: 3.55s\tremaining: 56.8s\n",
      "271:\tlearn: 3.7299534\ttotal: 3.57s\tremaining: 56.7s\n",
      "272:\tlearn: 3.7284250\ttotal: 3.58s\tremaining: 56.7s\n",
      "273:\tlearn: 3.7258551\ttotal: 3.59s\tremaining: 56.7s\n",
      "274:\tlearn: 3.7237535\ttotal: 3.6s\tremaining: 56.7s\n",
      "275:\tlearn: 3.7223498\ttotal: 3.62s\tremaining: 56.7s\n",
      "276:\tlearn: 3.7205846\ttotal: 3.63s\tremaining: 56.7s\n",
      "277:\tlearn: 3.7186530\ttotal: 3.64s\tremaining: 56.6s\n",
      "278:\tlearn: 3.7180265\ttotal: 3.66s\tremaining: 56.6s\n",
      "279:\tlearn: 3.7168704\ttotal: 3.67s\tremaining: 56.6s\n",
      "280:\tlearn: 3.7159939\ttotal: 3.68s\tremaining: 56.5s\n",
      "281:\tlearn: 3.7126846\ttotal: 3.69s\tremaining: 56.5s\n",
      "282:\tlearn: 3.7111392\ttotal: 3.71s\tremaining: 56.5s\n",
      "283:\tlearn: 3.7089517\ttotal: 3.72s\tremaining: 56.5s\n",
      "284:\tlearn: 3.7066653\ttotal: 3.73s\tremaining: 56.5s\n",
      "285:\tlearn: 3.7035692\ttotal: 3.74s\tremaining: 56.4s\n",
      "286:\tlearn: 3.7013240\ttotal: 3.76s\tremaining: 56.4s\n",
      "287:\tlearn: 3.6997210\ttotal: 3.77s\tremaining: 56.4s\n",
      "288:\tlearn: 3.6983139\ttotal: 3.78s\tremaining: 56.4s\n",
      "289:\tlearn: 3.6970759\ttotal: 3.79s\tremaining: 56.3s\n",
      "290:\tlearn: 3.6957755\ttotal: 3.8s\tremaining: 56.3s\n",
      "291:\tlearn: 3.6939016\ttotal: 3.82s\tremaining: 56.3s\n",
      "292:\tlearn: 3.6934410\ttotal: 3.83s\tremaining: 56.3s\n",
      "293:\tlearn: 3.6913136\ttotal: 3.84s\tremaining: 56.2s\n",
      "294:\tlearn: 3.6896585\ttotal: 3.85s\tremaining: 56.2s\n",
      "295:\tlearn: 3.6879188\ttotal: 3.86s\tremaining: 56.2s\n",
      "296:\tlearn: 3.6857567\ttotal: 3.88s\tremaining: 56.2s\n",
      "297:\tlearn: 3.6838237\ttotal: 3.89s\tremaining: 56.1s\n",
      "298:\tlearn: 3.6822971\ttotal: 3.9s\tremaining: 56.1s\n",
      "299:\tlearn: 3.6803583\ttotal: 3.92s\tremaining: 56.1s\n",
      "300:\tlearn: 3.6790121\ttotal: 3.93s\tremaining: 56.1s\n",
      "301:\tlearn: 3.6780228\ttotal: 3.94s\tremaining: 56.1s\n",
      "302:\tlearn: 3.6764944\ttotal: 3.95s\tremaining: 56s\n",
      "303:\tlearn: 3.6751428\ttotal: 3.96s\tremaining: 56s\n",
      "304:\tlearn: 3.6741226\ttotal: 3.98s\tremaining: 56s\n",
      "305:\tlearn: 3.6728470\ttotal: 3.99s\tremaining: 56s\n",
      "306:\tlearn: 3.6705963\ttotal: 4s\tremaining: 55.9s\n",
      "307:\tlearn: 3.6692075\ttotal: 4.01s\tremaining: 55.9s\n",
      "308:\tlearn: 3.6674515\ttotal: 4.03s\tremaining: 55.9s\n",
      "309:\tlearn: 3.6655250\ttotal: 4.04s\tremaining: 55.9s\n",
      "310:\tlearn: 3.6641305\ttotal: 4.05s\tremaining: 55.9s\n",
      "311:\tlearn: 3.6621077\ttotal: 4.07s\tremaining: 55.8s\n",
      "312:\tlearn: 3.6589642\ttotal: 4.08s\tremaining: 55.8s\n",
      "313:\tlearn: 3.6581528\ttotal: 4.09s\tremaining: 55.8s\n",
      "314:\tlearn: 3.6568592\ttotal: 4.1s\tremaining: 55.8s\n",
      "315:\tlearn: 3.6552609\ttotal: 4.11s\tremaining: 55.7s\n",
      "316:\tlearn: 3.6534462\ttotal: 4.13s\tremaining: 55.7s\n",
      "317:\tlearn: 3.6519720\ttotal: 4.14s\tremaining: 55.7s\n",
      "318:\tlearn: 3.6513430\ttotal: 4.15s\tremaining: 55.6s\n",
      "319:\tlearn: 3.6490240\ttotal: 4.16s\tremaining: 55.6s\n",
      "320:\tlearn: 3.6479546\ttotal: 4.17s\tremaining: 55.6s\n",
      "321:\tlearn: 3.6459865\ttotal: 4.18s\tremaining: 55.6s\n",
      "322:\tlearn: 3.6445777\ttotal: 4.2s\tremaining: 55.5s\n",
      "323:\tlearn: 3.6419552\ttotal: 4.21s\tremaining: 55.5s\n",
      "324:\tlearn: 3.6402462\ttotal: 4.22s\tremaining: 55.5s\n",
      "325:\tlearn: 3.6386444\ttotal: 4.24s\tremaining: 55.5s\n",
      "326:\tlearn: 3.6366220\ttotal: 4.25s\tremaining: 55.5s\n",
      "327:\tlearn: 3.6346309\ttotal: 4.26s\tremaining: 55.5s\n",
      "328:\tlearn: 3.6334555\ttotal: 4.27s\tremaining: 55.4s\n",
      "329:\tlearn: 3.6316399\ttotal: 4.29s\tremaining: 55.4s\n",
      "330:\tlearn: 3.6302528\ttotal: 4.3s\tremaining: 55.4s\n",
      "331:\tlearn: 3.6284589\ttotal: 4.31s\tremaining: 55.4s\n",
      "332:\tlearn: 3.6269335\ttotal: 4.32s\tremaining: 55.4s\n",
      "333:\tlearn: 3.6247486\ttotal: 4.33s\tremaining: 55.3s\n",
      "334:\tlearn: 3.6238699\ttotal: 4.35s\tremaining: 55.3s\n",
      "335:\tlearn: 3.6224694\ttotal: 4.36s\tremaining: 55.3s\n",
      "336:\tlearn: 3.6215121\ttotal: 4.37s\tremaining: 55.3s\n",
      "337:\tlearn: 3.6199970\ttotal: 4.38s\tremaining: 55.2s\n",
      "338:\tlearn: 3.6189846\ttotal: 4.39s\tremaining: 55.2s\n",
      "339:\tlearn: 3.6179142\ttotal: 4.41s\tremaining: 55.2s\n",
      "340:\tlearn: 3.6173379\ttotal: 4.42s\tremaining: 55.2s\n",
      "341:\tlearn: 3.6161248\ttotal: 4.43s\tremaining: 55.1s\n",
      "342:\tlearn: 3.6135066\ttotal: 4.44s\tremaining: 55.1s\n",
      "343:\tlearn: 3.6120767\ttotal: 4.46s\tremaining: 55.1s\n",
      "344:\tlearn: 3.6106173\ttotal: 4.47s\tremaining: 55.1s\n",
      "345:\tlearn: 3.6093588\ttotal: 4.48s\tremaining: 55.1s\n",
      "346:\tlearn: 3.6081500\ttotal: 4.5s\tremaining: 55.1s\n",
      "347:\tlearn: 3.6068257\ttotal: 4.51s\tremaining: 55.1s\n",
      "348:\tlearn: 3.6044162\ttotal: 4.52s\tremaining: 55.1s\n",
      "349:\tlearn: 3.6037469\ttotal: 4.53s\tremaining: 55s\n",
      "350:\tlearn: 3.6014396\ttotal: 4.55s\tremaining: 55s\n",
      "351:\tlearn: 3.6005966\ttotal: 4.56s\tremaining: 55s\n",
      "352:\tlearn: 3.5988632\ttotal: 4.57s\tremaining: 54.9s\n",
      "353:\tlearn: 3.5971930\ttotal: 4.58s\tremaining: 54.9s\n",
      "354:\tlearn: 3.5955164\ttotal: 4.59s\tremaining: 54.9s\n",
      "355:\tlearn: 3.5937260\ttotal: 4.61s\tremaining: 54.9s\n",
      "356:\tlearn: 3.5923414\ttotal: 4.62s\tremaining: 54.9s\n",
      "357:\tlearn: 3.5910472\ttotal: 4.63s\tremaining: 54.8s\n",
      "358:\tlearn: 3.5895785\ttotal: 4.64s\tremaining: 54.8s\n",
      "359:\tlearn: 3.5873539\ttotal: 4.66s\tremaining: 54.8s\n",
      "360:\tlearn: 3.5862765\ttotal: 4.67s\tremaining: 54.8s\n",
      "361:\tlearn: 3.5845538\ttotal: 4.68s\tremaining: 54.8s\n",
      "362:\tlearn: 3.5827257\ttotal: 4.7s\tremaining: 54.8s\n",
      "363:\tlearn: 3.5810487\ttotal: 4.71s\tremaining: 54.8s\n",
      "364:\tlearn: 3.5795499\ttotal: 4.72s\tremaining: 54.8s\n",
      "365:\tlearn: 3.5782010\ttotal: 4.73s\tremaining: 54.7s\n",
      "366:\tlearn: 3.5762049\ttotal: 4.75s\tremaining: 54.7s\n",
      "367:\tlearn: 3.5740759\ttotal: 4.76s\tremaining: 54.7s\n",
      "368:\tlearn: 3.5730132\ttotal: 4.77s\tremaining: 54.7s\n",
      "369:\tlearn: 3.5720259\ttotal: 4.78s\tremaining: 54.6s\n",
      "370:\tlearn: 3.5709853\ttotal: 4.79s\tremaining: 54.6s\n",
      "371:\tlearn: 3.5700328\ttotal: 4.81s\tremaining: 54.6s\n",
      "372:\tlearn: 3.5684483\ttotal: 4.82s\tremaining: 54.6s\n",
      "373:\tlearn: 3.5671807\ttotal: 4.83s\tremaining: 54.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374:\tlearn: 3.5654911\ttotal: 4.84s\tremaining: 54.5s\n",
      "375:\tlearn: 3.5641487\ttotal: 4.85s\tremaining: 54.5s\n",
      "376:\tlearn: 3.5628500\ttotal: 4.87s\tremaining: 54.5s\n",
      "377:\tlearn: 3.5616804\ttotal: 4.88s\tremaining: 54.5s\n",
      "378:\tlearn: 3.5595404\ttotal: 4.89s\tremaining: 54.5s\n",
      "379:\tlearn: 3.5581395\ttotal: 4.91s\tremaining: 54.5s\n",
      "380:\tlearn: 3.5559202\ttotal: 4.92s\tremaining: 54.4s\n",
      "381:\tlearn: 3.5548273\ttotal: 4.93s\tremaining: 54.4s\n",
      "382:\tlearn: 3.5535980\ttotal: 4.94s\tremaining: 54.4s\n",
      "383:\tlearn: 3.5520558\ttotal: 4.95s\tremaining: 54.4s\n",
      "384:\tlearn: 3.5498960\ttotal: 4.97s\tremaining: 54.4s\n",
      "385:\tlearn: 3.5480611\ttotal: 4.98s\tremaining: 54.3s\n",
      "386:\tlearn: 3.5459590\ttotal: 4.99s\tremaining: 54.3s\n",
      "387:\tlearn: 3.5444429\ttotal: 5s\tremaining: 54.3s\n",
      "388:\tlearn: 3.5426160\ttotal: 5.01s\tremaining: 54.3s\n",
      "389:\tlearn: 3.5413920\ttotal: 5.03s\tremaining: 54.2s\n",
      "390:\tlearn: 3.5399011\ttotal: 5.04s\tremaining: 54.2s\n",
      "391:\tlearn: 3.5384024\ttotal: 5.05s\tremaining: 54.2s\n",
      "392:\tlearn: 3.5367850\ttotal: 5.07s\tremaining: 54.2s\n",
      "393:\tlearn: 3.5353752\ttotal: 5.08s\tremaining: 54.2s\n",
      "394:\tlearn: 3.5337717\ttotal: 5.09s\tremaining: 54.2s\n",
      "395:\tlearn: 3.5323593\ttotal: 5.1s\tremaining: 54.2s\n",
      "396:\tlearn: 3.5310270\ttotal: 5.12s\tremaining: 54.1s\n",
      "397:\tlearn: 3.5308340\ttotal: 5.13s\tremaining: 54.1s\n",
      "398:\tlearn: 3.5295711\ttotal: 5.14s\tremaining: 54.1s\n",
      "399:\tlearn: 3.5289526\ttotal: 5.15s\tremaining: 54s\n",
      "400:\tlearn: 3.5273663\ttotal: 5.16s\tremaining: 54s\n",
      "401:\tlearn: 3.5263176\ttotal: 5.17s\tremaining: 54s\n",
      "402:\tlearn: 3.5250165\ttotal: 5.18s\tremaining: 54s\n",
      "403:\tlearn: 3.5236762\ttotal: 5.2s\tremaining: 53.9s\n",
      "404:\tlearn: 3.5232004\ttotal: 5.21s\tremaining: 53.9s\n",
      "405:\tlearn: 3.5225275\ttotal: 5.22s\tremaining: 53.9s\n",
      "406:\tlearn: 3.5203088\ttotal: 5.23s\tremaining: 53.9s\n",
      "407:\tlearn: 3.5187930\ttotal: 5.24s\tremaining: 53.8s\n",
      "408:\tlearn: 3.5168209\ttotal: 5.25s\tremaining: 53.8s\n",
      "409:\tlearn: 3.5154657\ttotal: 5.27s\tremaining: 53.8s\n",
      "410:\tlearn: 3.5146383\ttotal: 5.28s\tremaining: 53.8s\n",
      "411:\tlearn: 3.5135564\ttotal: 5.29s\tremaining: 53.8s\n",
      "412:\tlearn: 3.5121252\ttotal: 5.31s\tremaining: 53.8s\n",
      "413:\tlearn: 3.5106131\ttotal: 5.32s\tremaining: 53.8s\n",
      "414:\tlearn: 3.5096037\ttotal: 5.33s\tremaining: 53.7s\n",
      "415:\tlearn: 3.5084375\ttotal: 5.34s\tremaining: 53.7s\n",
      "416:\tlearn: 3.5076194\ttotal: 5.35s\tremaining: 53.7s\n",
      "417:\tlearn: 3.5056418\ttotal: 5.37s\tremaining: 53.7s\n",
      "418:\tlearn: 3.5043632\ttotal: 5.38s\tremaining: 53.6s\n",
      "419:\tlearn: 3.5041855\ttotal: 5.39s\tremaining: 53.6s\n",
      "420:\tlearn: 3.5023871\ttotal: 5.4s\tremaining: 53.6s\n",
      "421:\tlearn: 3.5000340\ttotal: 5.41s\tremaining: 53.6s\n",
      "422:\tlearn: 3.4990601\ttotal: 5.42s\tremaining: 53.5s\n",
      "423:\tlearn: 3.4984382\ttotal: 5.43s\tremaining: 53.5s\n",
      "424:\tlearn: 3.4971077\ttotal: 5.45s\tremaining: 53.5s\n",
      "425:\tlearn: 3.4954005\ttotal: 5.46s\tremaining: 53.5s\n",
      "426:\tlearn: 3.4937582\ttotal: 5.47s\tremaining: 53.4s\n",
      "427:\tlearn: 3.4929216\ttotal: 5.48s\tremaining: 53.4s\n",
      "428:\tlearn: 3.4918824\ttotal: 5.5s\tremaining: 53.4s\n",
      "429:\tlearn: 3.4907589\ttotal: 5.51s\tremaining: 53.4s\n",
      "430:\tlearn: 3.4895004\ttotal: 5.52s\tremaining: 53.4s\n",
      "431:\tlearn: 3.4886416\ttotal: 5.53s\tremaining: 53.3s\n",
      "432:\tlearn: 3.4875123\ttotal: 5.54s\tremaining: 53.3s\n",
      "433:\tlearn: 3.4873723\ttotal: 5.55s\tremaining: 53.3s\n",
      "434:\tlearn: 3.4862850\ttotal: 5.57s\tremaining: 53.3s\n",
      "435:\tlearn: 3.4839903\ttotal: 5.58s\tremaining: 53.2s\n",
      "436:\tlearn: 3.4829647\ttotal: 5.59s\tremaining: 53.2s\n",
      "437:\tlearn: 3.4824699\ttotal: 5.6s\tremaining: 53.2s\n",
      "438:\tlearn: 3.4809874\ttotal: 5.61s\tremaining: 53.2s\n",
      "439:\tlearn: 3.4795693\ttotal: 5.62s\tremaining: 53.2s\n",
      "440:\tlearn: 3.4781081\ttotal: 5.64s\tremaining: 53.1s\n",
      "441:\tlearn: 3.4771542\ttotal: 5.65s\tremaining: 53.1s\n",
      "442:\tlearn: 3.4759680\ttotal: 5.66s\tremaining: 53.1s\n",
      "443:\tlearn: 3.4738164\ttotal: 5.67s\tremaining: 53.1s\n",
      "444:\tlearn: 3.4722289\ttotal: 5.68s\tremaining: 53s\n",
      "445:\tlearn: 3.4714346\ttotal: 5.7s\tremaining: 53s\n",
      "446:\tlearn: 3.4711727\ttotal: 5.71s\tremaining: 53s\n",
      "447:\tlearn: 3.4701364\ttotal: 5.72s\tremaining: 53s\n",
      "448:\tlearn: 3.4690137\ttotal: 5.73s\tremaining: 53s\n",
      "449:\tlearn: 3.4679115\ttotal: 5.75s\tremaining: 53s\n",
      "450:\tlearn: 3.4671103\ttotal: 5.76s\tremaining: 52.9s\n",
      "451:\tlearn: 3.4649983\ttotal: 5.77s\tremaining: 52.9s\n",
      "452:\tlearn: 3.4647340\ttotal: 5.78s\tremaining: 52.9s\n",
      "453:\tlearn: 3.4636716\ttotal: 5.79s\tremaining: 52.9s\n",
      "454:\tlearn: 3.4620772\ttotal: 5.8s\tremaining: 52.8s\n",
      "455:\tlearn: 3.4606508\ttotal: 5.82s\tremaining: 52.8s\n",
      "456:\tlearn: 3.4595450\ttotal: 5.83s\tremaining: 52.8s\n",
      "457:\tlearn: 3.4582883\ttotal: 5.84s\tremaining: 52.8s\n",
      "458:\tlearn: 3.4558876\ttotal: 5.85s\tremaining: 52.8s\n",
      "459:\tlearn: 3.4533326\ttotal: 5.87s\tremaining: 52.8s\n",
      "460:\tlearn: 3.4524621\ttotal: 5.88s\tremaining: 52.7s\n",
      "461:\tlearn: 3.4511065\ttotal: 5.89s\tremaining: 52.7s\n",
      "462:\tlearn: 3.4499957\ttotal: 5.9s\tremaining: 52.7s\n",
      "463:\tlearn: 3.4490052\ttotal: 5.91s\tremaining: 52.7s\n",
      "464:\tlearn: 3.4468284\ttotal: 5.93s\tremaining: 52.7s\n",
      "465:\tlearn: 3.4459136\ttotal: 5.94s\tremaining: 52.7s\n",
      "466:\tlearn: 3.4441485\ttotal: 5.95s\tremaining: 52.7s\n",
      "467:\tlearn: 3.4417860\ttotal: 5.97s\tremaining: 52.7s\n",
      "468:\tlearn: 3.4406530\ttotal: 5.98s\tremaining: 52.6s\n",
      "469:\tlearn: 3.4396895\ttotal: 5.99s\tremaining: 52.6s\n",
      "470:\tlearn: 3.4383607\ttotal: 6s\tremaining: 52.6s\n",
      "471:\tlearn: 3.4371240\ttotal: 6.02s\tremaining: 52.6s\n",
      "472:\tlearn: 3.4365750\ttotal: 6.03s\tremaining: 52.6s\n",
      "473:\tlearn: 3.4344460\ttotal: 6.04s\tremaining: 52.6s\n",
      "474:\tlearn: 3.4330982\ttotal: 6.05s\tremaining: 52.5s\n",
      "475:\tlearn: 3.4310343\ttotal: 6.07s\tremaining: 52.5s\n",
      "476:\tlearn: 3.4292161\ttotal: 6.08s\tremaining: 52.5s\n",
      "477:\tlearn: 3.4276171\ttotal: 6.09s\tremaining: 52.5s\n",
      "478:\tlearn: 3.4264731\ttotal: 6.1s\tremaining: 52.5s\n",
      "479:\tlearn: 3.4240259\ttotal: 6.12s\tremaining: 52.5s\n",
      "480:\tlearn: 3.4225129\ttotal: 6.13s\tremaining: 52.5s\n",
      "481:\tlearn: 3.4211236\ttotal: 6.14s\tremaining: 52.5s\n",
      "482:\tlearn: 3.4192370\ttotal: 6.16s\tremaining: 52.4s\n",
      "483:\tlearn: 3.4186097\ttotal: 6.17s\tremaining: 52.4s\n",
      "484:\tlearn: 3.4178142\ttotal: 6.18s\tremaining: 52.4s\n",
      "485:\tlearn: 3.4164935\ttotal: 6.19s\tremaining: 52.4s\n",
      "486:\tlearn: 3.4149060\ttotal: 6.2s\tremaining: 52.4s\n",
      "487:\tlearn: 3.4136388\ttotal: 6.21s\tremaining: 52.3s\n",
      "488:\tlearn: 3.4131786\ttotal: 6.22s\tremaining: 52.3s\n",
      "489:\tlearn: 3.4113077\ttotal: 6.24s\tremaining: 52.3s\n",
      "490:\tlearn: 3.4099193\ttotal: 6.25s\tremaining: 52.3s\n",
      "491:\tlearn: 3.4089934\ttotal: 6.26s\tremaining: 52.3s\n",
      "492:\tlearn: 3.4077053\ttotal: 6.27s\tremaining: 52.2s\n",
      "493:\tlearn: 3.4068207\ttotal: 6.29s\tremaining: 52.2s\n",
      "494:\tlearn: 3.4051660\ttotal: 6.3s\tremaining: 52.2s\n",
      "495:\tlearn: 3.4043115\ttotal: 6.31s\tremaining: 52.2s\n",
      "496:\tlearn: 3.4030232\ttotal: 6.32s\tremaining: 52.2s\n",
      "497:\tlearn: 3.4023852\ttotal: 6.33s\tremaining: 52.1s\n",
      "498:\tlearn: 3.4008117\ttotal: 6.35s\tremaining: 52.1s\n",
      "499:\tlearn: 3.3998423\ttotal: 6.36s\tremaining: 52.1s\n",
      "500:\tlearn: 3.3986841\ttotal: 6.37s\tremaining: 52.1s\n",
      "501:\tlearn: 3.3976633\ttotal: 6.38s\tremaining: 52.1s\n",
      "502:\tlearn: 3.3964886\ttotal: 6.4s\tremaining: 52.1s\n",
      "503:\tlearn: 3.3954482\ttotal: 6.41s\tremaining: 52.1s\n",
      "504:\tlearn: 3.3938222\ttotal: 6.42s\tremaining: 52s\n",
      "505:\tlearn: 3.3920341\ttotal: 6.43s\tremaining: 52s\n",
      "506:\tlearn: 3.3899856\ttotal: 6.45s\tremaining: 52s\n",
      "507:\tlearn: 3.3891080\ttotal: 6.46s\tremaining: 52s\n",
      "508:\tlearn: 3.3883193\ttotal: 6.47s\tremaining: 52s\n",
      "509:\tlearn: 3.3872663\ttotal: 6.48s\tremaining: 52s\n",
      "510:\tlearn: 3.3861061\ttotal: 6.5s\tremaining: 52s\n",
      "511:\tlearn: 3.3846861\ttotal: 6.51s\tremaining: 51.9s\n",
      "512:\tlearn: 3.3840300\ttotal: 6.52s\tremaining: 51.9s\n",
      "513:\tlearn: 3.3827209\ttotal: 6.53s\tremaining: 51.9s\n",
      "514:\tlearn: 3.3812125\ttotal: 6.54s\tremaining: 51.9s\n",
      "515:\tlearn: 3.3794272\ttotal: 6.56s\tremaining: 51.9s\n",
      "516:\tlearn: 3.3787156\ttotal: 6.57s\tremaining: 51.9s\n",
      "517:\tlearn: 3.3787093\ttotal: 6.58s\tremaining: 51.8s\n",
      "518:\tlearn: 3.3784335\ttotal: 6.59s\tremaining: 51.8s\n",
      "519:\tlearn: 3.3772290\ttotal: 6.61s\tremaining: 51.8s\n",
      "520:\tlearn: 3.3762251\ttotal: 6.62s\tremaining: 51.8s\n",
      "521:\tlearn: 3.3747304\ttotal: 6.63s\tremaining: 51.8s\n",
      "522:\tlearn: 3.3736943\ttotal: 6.64s\tremaining: 51.8s\n",
      "523:\tlearn: 3.3731853\ttotal: 6.65s\tremaining: 51.7s\n",
      "524:\tlearn: 3.3723041\ttotal: 6.67s\tremaining: 51.7s\n",
      "525:\tlearn: 3.3714721\ttotal: 6.68s\tremaining: 51.7s\n",
      "526:\tlearn: 3.3706662\ttotal: 6.69s\tremaining: 51.7s\n",
      "527:\tlearn: 3.3693332\ttotal: 6.7s\tremaining: 51.7s\n",
      "528:\tlearn: 3.3684738\ttotal: 6.71s\tremaining: 51.6s\n",
      "529:\tlearn: 3.3673523\ttotal: 6.72s\tremaining: 51.6s\n",
      "530:\tlearn: 3.3659500\ttotal: 6.74s\tremaining: 51.6s\n",
      "531:\tlearn: 3.3632656\ttotal: 6.75s\tremaining: 51.6s\n",
      "532:\tlearn: 3.3620519\ttotal: 6.76s\tremaining: 51.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533:\tlearn: 3.3602662\ttotal: 6.78s\tremaining: 51.6s\n",
      "534:\tlearn: 3.3588897\ttotal: 6.79s\tremaining: 51.6s\n",
      "535:\tlearn: 3.3574275\ttotal: 6.81s\tremaining: 51.6s\n",
      "536:\tlearn: 3.3561244\ttotal: 6.82s\tremaining: 51.6s\n",
      "537:\tlearn: 3.3548768\ttotal: 6.84s\tremaining: 51.6s\n",
      "538:\tlearn: 3.3535426\ttotal: 6.85s\tremaining: 51.6s\n",
      "539:\tlearn: 3.3516564\ttotal: 6.87s\tremaining: 51.6s\n",
      "540:\tlearn: 3.3500128\ttotal: 6.88s\tremaining: 51.6s\n",
      "541:\tlearn: 3.3486228\ttotal: 6.89s\tremaining: 51.6s\n",
      "542:\tlearn: 3.3471434\ttotal: 6.91s\tremaining: 51.6s\n",
      "543:\tlearn: 3.3453609\ttotal: 6.92s\tremaining: 51.6s\n",
      "544:\tlearn: 3.3447708\ttotal: 6.93s\tremaining: 51.6s\n",
      "545:\tlearn: 3.3435827\ttotal: 6.95s\tremaining: 51.5s\n",
      "546:\tlearn: 3.3420210\ttotal: 6.96s\tremaining: 51.5s\n",
      "547:\tlearn: 3.3408125\ttotal: 6.97s\tremaining: 51.5s\n",
      "548:\tlearn: 3.3397042\ttotal: 6.98s\tremaining: 51.5s\n",
      "549:\tlearn: 3.3392153\ttotal: 7s\tremaining: 51.5s\n",
      "550:\tlearn: 3.3392090\ttotal: 7.01s\tremaining: 51.5s\n",
      "551:\tlearn: 3.3383259\ttotal: 7.02s\tremaining: 51.4s\n",
      "552:\tlearn: 3.3372313\ttotal: 7.03s\tremaining: 51.4s\n",
      "553:\tlearn: 3.3363679\ttotal: 7.04s\tremaining: 51.4s\n",
      "554:\tlearn: 3.3351167\ttotal: 7.05s\tremaining: 51.4s\n",
      "555:\tlearn: 3.3344749\ttotal: 7.07s\tremaining: 51.4s\n",
      "556:\tlearn: 3.3334287\ttotal: 7.08s\tremaining: 51.4s\n",
      "557:\tlearn: 3.3325248\ttotal: 7.09s\tremaining: 51.3s\n",
      "558:\tlearn: 3.3312661\ttotal: 7.1s\tremaining: 51.3s\n",
      "559:\tlearn: 3.3309818\ttotal: 7.11s\tremaining: 51.3s\n",
      "560:\tlearn: 3.3301728\ttotal: 7.13s\tremaining: 51.3s\n",
      "561:\tlearn: 3.3292248\ttotal: 7.14s\tremaining: 51.3s\n",
      "562:\tlearn: 3.3280864\ttotal: 7.15s\tremaining: 51.2s\n",
      "563:\tlearn: 3.3268864\ttotal: 7.16s\tremaining: 51.2s\n",
      "564:\tlearn: 3.3257709\ttotal: 7.17s\tremaining: 51.2s\n",
      "565:\tlearn: 3.3250783\ttotal: 7.18s\tremaining: 51.2s\n",
      "566:\tlearn: 3.3236526\ttotal: 7.2s\tremaining: 51.2s\n",
      "567:\tlearn: 3.3220081\ttotal: 7.21s\tremaining: 51.2s\n",
      "568:\tlearn: 3.3209248\ttotal: 7.22s\tremaining: 51.2s\n",
      "569:\tlearn: 3.3200193\ttotal: 7.24s\tremaining: 51.1s\n",
      "570:\tlearn: 3.3194771\ttotal: 7.25s\tremaining: 51.1s\n",
      "571:\tlearn: 3.3187378\ttotal: 7.26s\tremaining: 51.1s\n",
      "572:\tlearn: 3.3163079\ttotal: 7.27s\tremaining: 51.1s\n",
      "573:\tlearn: 3.3155941\ttotal: 7.28s\tremaining: 51.1s\n",
      "574:\tlearn: 3.3140819\ttotal: 7.3s\tremaining: 51.1s\n",
      "575:\tlearn: 3.3133289\ttotal: 7.31s\tremaining: 51s\n",
      "576:\tlearn: 3.3124281\ttotal: 7.32s\tremaining: 51s\n",
      "577:\tlearn: 3.3114371\ttotal: 7.33s\tremaining: 51s\n",
      "578:\tlearn: 3.3101833\ttotal: 7.34s\tremaining: 51s\n",
      "579:\tlearn: 3.3093950\ttotal: 7.36s\tremaining: 51s\n",
      "580:\tlearn: 3.3082077\ttotal: 7.37s\tremaining: 50.9s\n",
      "581:\tlearn: 3.3067251\ttotal: 7.38s\tremaining: 50.9s\n",
      "582:\tlearn: 3.3048118\ttotal: 7.39s\tremaining: 50.9s\n",
      "583:\tlearn: 3.3047667\ttotal: 7.4s\tremaining: 50.9s\n",
      "584:\tlearn: 3.3037536\ttotal: 7.42s\tremaining: 50.9s\n",
      "585:\tlearn: 3.3018461\ttotal: 7.43s\tremaining: 50.9s\n",
      "586:\tlearn: 3.3003677\ttotal: 7.44s\tremaining: 50.9s\n",
      "587:\tlearn: 3.2991114\ttotal: 7.46s\tremaining: 50.8s\n",
      "588:\tlearn: 3.2986414\ttotal: 7.47s\tremaining: 50.8s\n",
      "589:\tlearn: 3.2973996\ttotal: 7.48s\tremaining: 50.8s\n",
      "590:\tlearn: 3.2968035\ttotal: 7.49s\tremaining: 50.8s\n",
      "591:\tlearn: 3.2956536\ttotal: 7.5s\tremaining: 50.8s\n",
      "592:\tlearn: 3.2945480\ttotal: 7.52s\tremaining: 50.8s\n",
      "593:\tlearn: 3.2929809\ttotal: 7.53s\tremaining: 50.8s\n",
      "594:\tlearn: 3.2917641\ttotal: 7.54s\tremaining: 50.7s\n",
      "595:\tlearn: 3.2907413\ttotal: 7.55s\tremaining: 50.7s\n",
      "596:\tlearn: 3.2898934\ttotal: 7.57s\tremaining: 50.7s\n",
      "597:\tlearn: 3.2883932\ttotal: 7.58s\tremaining: 50.7s\n",
      "598:\tlearn: 3.2871434\ttotal: 7.59s\tremaining: 50.7s\n",
      "599:\tlearn: 3.2863702\ttotal: 7.6s\tremaining: 50.7s\n",
      "600:\tlearn: 3.2845250\ttotal: 7.62s\tremaining: 50.6s\n",
      "601:\tlearn: 3.2832567\ttotal: 7.63s\tremaining: 50.6s\n",
      "602:\tlearn: 3.2826181\ttotal: 7.64s\tremaining: 50.6s\n",
      "603:\tlearn: 3.2813106\ttotal: 7.65s\tremaining: 50.6s\n",
      "604:\tlearn: 3.2800950\ttotal: 7.67s\tremaining: 50.6s\n",
      "605:\tlearn: 3.2785287\ttotal: 7.68s\tremaining: 50.6s\n",
      "606:\tlearn: 3.2776552\ttotal: 7.69s\tremaining: 50.6s\n",
      "607:\tlearn: 3.2770011\ttotal: 7.7s\tremaining: 50.6s\n",
      "608:\tlearn: 3.2758602\ttotal: 7.71s\tremaining: 50.5s\n",
      "609:\tlearn: 3.2746880\ttotal: 7.73s\tremaining: 50.5s\n",
      "610:\tlearn: 3.2738347\ttotal: 7.74s\tremaining: 50.5s\n",
      "611:\tlearn: 3.2732397\ttotal: 7.75s\tremaining: 50.5s\n",
      "612:\tlearn: 3.2723469\ttotal: 7.76s\tremaining: 50.5s\n",
      "613:\tlearn: 3.2705457\ttotal: 7.77s\tremaining: 50.4s\n",
      "614:\tlearn: 3.2705401\ttotal: 7.79s\tremaining: 50.4s\n",
      "615:\tlearn: 3.2698596\ttotal: 7.8s\tremaining: 50.4s\n",
      "616:\tlearn: 3.2683236\ttotal: 7.81s\tremaining: 50.4s\n",
      "617:\tlearn: 3.2674728\ttotal: 7.82s\tremaining: 50.4s\n",
      "618:\tlearn: 3.2658881\ttotal: 7.84s\tremaining: 50.4s\n",
      "619:\tlearn: 3.2652009\ttotal: 7.85s\tremaining: 50.4s\n",
      "620:\tlearn: 3.2641381\ttotal: 7.86s\tremaining: 50.4s\n",
      "621:\tlearn: 3.2632516\ttotal: 7.88s\tremaining: 50.3s\n",
      "622:\tlearn: 3.2626110\ttotal: 7.89s\tremaining: 50.3s\n",
      "623:\tlearn: 3.2616432\ttotal: 7.9s\tremaining: 50.3s\n",
      "624:\tlearn: 3.2603573\ttotal: 7.91s\tremaining: 50.3s\n",
      "625:\tlearn: 3.2590247\ttotal: 7.92s\tremaining: 50.3s\n",
      "626:\tlearn: 3.2583695\ttotal: 7.93s\tremaining: 50.2s\n",
      "627:\tlearn: 3.2574346\ttotal: 7.94s\tremaining: 50.2s\n",
      "628:\tlearn: 3.2572605\ttotal: 7.95s\tremaining: 50.2s\n",
      "629:\tlearn: 3.2560694\ttotal: 7.97s\tremaining: 50.2s\n",
      "630:\tlearn: 3.2552121\ttotal: 7.98s\tremaining: 50.2s\n",
      "631:\tlearn: 3.2544769\ttotal: 7.99s\tremaining: 50.1s\n",
      "632:\tlearn: 3.2537815\ttotal: 8s\tremaining: 50.1s\n",
      "633:\tlearn: 3.2516802\ttotal: 8.01s\tremaining: 50.1s\n",
      "634:\tlearn: 3.2508412\ttotal: 8.03s\tremaining: 50.1s\n",
      "635:\tlearn: 3.2497975\ttotal: 8.04s\tremaining: 50.1s\n",
      "636:\tlearn: 3.2489462\ttotal: 8.05s\tremaining: 50.1s\n",
      "637:\tlearn: 3.2475072\ttotal: 8.06s\tremaining: 50.1s\n",
      "638:\tlearn: 3.2473111\ttotal: 8.08s\tremaining: 50s\n",
      "639:\tlearn: 3.2461109\ttotal: 8.09s\tremaining: 50s\n",
      "640:\tlearn: 3.2447486\ttotal: 8.1s\tremaining: 50s\n",
      "641:\tlearn: 3.2440133\ttotal: 8.11s\tremaining: 50s\n",
      "642:\tlearn: 3.2435974\ttotal: 8.12s\tremaining: 50s\n",
      "643:\tlearn: 3.2403025\ttotal: 8.14s\tremaining: 50s\n",
      "644:\tlearn: 3.2390182\ttotal: 8.15s\tremaining: 49.9s\n",
      "645:\tlearn: 3.2376921\ttotal: 8.16s\tremaining: 49.9s\n",
      "646:\tlearn: 3.2368116\ttotal: 8.17s\tremaining: 49.9s\n",
      "647:\tlearn: 3.2354127\ttotal: 8.19s\tremaining: 49.9s\n",
      "648:\tlearn: 3.2338969\ttotal: 8.2s\tremaining: 49.9s\n",
      "649:\tlearn: 3.2332108\ttotal: 8.21s\tremaining: 49.9s\n",
      "650:\tlearn: 3.2324431\ttotal: 8.22s\tremaining: 49.8s\n",
      "651:\tlearn: 3.2310244\ttotal: 8.23s\tremaining: 49.8s\n",
      "652:\tlearn: 3.2298465\ttotal: 8.24s\tremaining: 49.8s\n",
      "653:\tlearn: 3.2286314\ttotal: 8.26s\tremaining: 49.8s\n",
      "654:\tlearn: 3.2274453\ttotal: 8.27s\tremaining: 49.8s\n",
      "655:\tlearn: 3.2265690\ttotal: 8.29s\tremaining: 49.8s\n",
      "656:\tlearn: 3.2255311\ttotal: 8.3s\tremaining: 49.8s\n",
      "657:\tlearn: 3.2245330\ttotal: 8.31s\tremaining: 49.8s\n",
      "658:\tlearn: 3.2244822\ttotal: 8.32s\tremaining: 49.7s\n",
      "659:\tlearn: 3.2235000\ttotal: 8.33s\tremaining: 49.7s\n",
      "660:\tlearn: 3.2225798\ttotal: 8.35s\tremaining: 49.7s\n",
      "661:\tlearn: 3.2218837\ttotal: 8.36s\tremaining: 49.7s\n",
      "662:\tlearn: 3.2214830\ttotal: 8.37s\tremaining: 49.7s\n",
      "663:\tlearn: 3.2199789\ttotal: 8.38s\tremaining: 49.7s\n",
      "664:\tlearn: 3.2188114\ttotal: 8.39s\tremaining: 49.7s\n",
      "665:\tlearn: 3.2182301\ttotal: 8.41s\tremaining: 49.6s\n",
      "666:\tlearn: 3.2170918\ttotal: 8.42s\tremaining: 49.6s\n",
      "667:\tlearn: 3.2162125\ttotal: 8.43s\tremaining: 49.6s\n",
      "668:\tlearn: 3.2147769\ttotal: 8.44s\tremaining: 49.6s\n",
      "669:\tlearn: 3.2136359\ttotal: 8.45s\tremaining: 49.6s\n",
      "670:\tlearn: 3.2123619\ttotal: 8.47s\tremaining: 49.6s\n",
      "671:\tlearn: 3.2122892\ttotal: 8.48s\tremaining: 49.5s\n",
      "672:\tlearn: 3.2115245\ttotal: 8.49s\tremaining: 49.5s\n",
      "673:\tlearn: 3.2087816\ttotal: 8.51s\tremaining: 49.5s\n",
      "674:\tlearn: 3.2078581\ttotal: 8.52s\tremaining: 49.5s\n",
      "675:\tlearn: 3.2063051\ttotal: 8.53s\tremaining: 49.5s\n",
      "676:\tlearn: 3.2054038\ttotal: 8.54s\tremaining: 49.5s\n",
      "677:\tlearn: 3.2045726\ttotal: 8.55s\tremaining: 49.5s\n",
      "678:\tlearn: 3.2038467\ttotal: 8.56s\tremaining: 49.4s\n",
      "679:\tlearn: 3.2028586\ttotal: 8.58s\tremaining: 49.4s\n",
      "680:\tlearn: 3.2017534\ttotal: 8.59s\tremaining: 49.4s\n",
      "681:\tlearn: 3.2001999\ttotal: 8.6s\tremaining: 49.4s\n",
      "682:\tlearn: 3.1993146\ttotal: 8.61s\tremaining: 49.4s\n",
      "683:\tlearn: 3.1984720\ttotal: 8.63s\tremaining: 49.4s\n",
      "684:\tlearn: 3.1975453\ttotal: 8.64s\tremaining: 49.3s\n",
      "685:\tlearn: 3.1967496\ttotal: 8.65s\tremaining: 49.3s\n",
      "686:\tlearn: 3.1955777\ttotal: 8.66s\tremaining: 49.3s\n",
      "687:\tlearn: 3.1944492\ttotal: 8.67s\tremaining: 49.3s\n",
      "688:\tlearn: 3.1931186\ttotal: 8.69s\tremaining: 49.3s\n",
      "689:\tlearn: 3.1921145\ttotal: 8.7s\tremaining: 49.3s\n",
      "690:\tlearn: 3.1910002\ttotal: 8.71s\tremaining: 49.3s\n",
      "691:\tlearn: 3.1900106\ttotal: 8.73s\tremaining: 49.3s\n",
      "692:\tlearn: 3.1885027\ttotal: 8.74s\tremaining: 49.2s\n",
      "693:\tlearn: 3.1873285\ttotal: 8.75s\tremaining: 49.2s\n",
      "694:\tlearn: 3.1861131\ttotal: 8.76s\tremaining: 49.2s\n",
      "695:\tlearn: 3.1849014\ttotal: 8.78s\tremaining: 49.2s\n",
      "696:\tlearn: 3.1839205\ttotal: 8.79s\tremaining: 49.2s\n",
      "697:\tlearn: 3.1828133\ttotal: 8.8s\tremaining: 49.2s\n",
      "698:\tlearn: 3.1813862\ttotal: 8.81s\tremaining: 49.2s\n",
      "699:\tlearn: 3.1801682\ttotal: 8.83s\tremaining: 49.1s\n",
      "700:\tlearn: 3.1792998\ttotal: 8.84s\tremaining: 49.1s\n",
      "701:\tlearn: 3.1778245\ttotal: 8.85s\tremaining: 49.1s\n",
      "702:\tlearn: 3.1766184\ttotal: 8.86s\tremaining: 49.1s\n",
      "703:\tlearn: 3.1751740\ttotal: 8.87s\tremaining: 49.1s\n",
      "704:\tlearn: 3.1746933\ttotal: 8.89s\tremaining: 49.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705:\tlearn: 3.1735401\ttotal: 8.9s\tremaining: 49.1s\n",
      "706:\tlearn: 3.1724924\ttotal: 8.91s\tremaining: 49s\n",
      "707:\tlearn: 3.1718743\ttotal: 8.93s\tremaining: 49s\n",
      "708:\tlearn: 3.1712370\ttotal: 8.94s\tremaining: 49s\n",
      "709:\tlearn: 3.1704732\ttotal: 8.95s\tremaining: 49s\n",
      "710:\tlearn: 3.1696889\ttotal: 8.96s\tremaining: 49s\n",
      "711:\tlearn: 3.1688995\ttotal: 8.97s\tremaining: 49s\n",
      "712:\tlearn: 3.1676299\ttotal: 8.99s\tremaining: 49s\n",
      "713:\tlearn: 3.1657643\ttotal: 9s\tremaining: 49s\n",
      "714:\tlearn: 3.1642084\ttotal: 9.01s\tremaining: 49s\n",
      "715:\tlearn: 3.1632572\ttotal: 9.03s\tremaining: 48.9s\n",
      "716:\tlearn: 3.1626492\ttotal: 9.04s\tremaining: 48.9s\n",
      "717:\tlearn: 3.1620347\ttotal: 9.05s\tremaining: 48.9s\n",
      "718:\tlearn: 3.1613440\ttotal: 9.06s\tremaining: 48.9s\n",
      "719:\tlearn: 3.1611972\ttotal: 9.07s\tremaining: 48.9s\n",
      "720:\tlearn: 3.1598702\ttotal: 9.09s\tremaining: 48.9s\n",
      "721:\tlearn: 3.1593565\ttotal: 9.1s\tremaining: 48.8s\n",
      "722:\tlearn: 3.1586610\ttotal: 9.11s\tremaining: 48.8s\n",
      "723:\tlearn: 3.1583136\ttotal: 9.12s\tremaining: 48.8s\n",
      "724:\tlearn: 3.1575847\ttotal: 9.13s\tremaining: 48.8s\n",
      "725:\tlearn: 3.1564870\ttotal: 9.15s\tremaining: 48.8s\n",
      "726:\tlearn: 3.1555485\ttotal: 9.16s\tremaining: 48.8s\n",
      "727:\tlearn: 3.1545074\ttotal: 9.17s\tremaining: 48.8s\n",
      "728:\tlearn: 3.1533680\ttotal: 9.18s\tremaining: 48.7s\n",
      "729:\tlearn: 3.1520557\ttotal: 9.2s\tremaining: 48.7s\n",
      "730:\tlearn: 3.1510287\ttotal: 9.21s\tremaining: 48.7s\n",
      "731:\tlearn: 3.1500767\ttotal: 9.22s\tremaining: 48.7s\n",
      "732:\tlearn: 3.1488861\ttotal: 9.23s\tremaining: 48.7s\n",
      "733:\tlearn: 3.1470170\ttotal: 9.24s\tremaining: 48.7s\n",
      "734:\tlearn: 3.1458363\ttotal: 9.26s\tremaining: 48.7s\n",
      "735:\tlearn: 3.1448075\ttotal: 9.27s\tremaining: 48.6s\n",
      "736:\tlearn: 3.1441521\ttotal: 9.28s\tremaining: 48.6s\n",
      "737:\tlearn: 3.1429106\ttotal: 9.29s\tremaining: 48.6s\n",
      "738:\tlearn: 3.1417970\ttotal: 9.3s\tremaining: 48.6s\n",
      "739:\tlearn: 3.1401547\ttotal: 9.32s\tremaining: 48.6s\n",
      "740:\tlearn: 3.1387709\ttotal: 9.33s\tremaining: 48.6s\n",
      "741:\tlearn: 3.1378078\ttotal: 9.36s\tremaining: 48.6s\n",
      "742:\tlearn: 3.1367434\ttotal: 9.37s\tremaining: 48.6s\n",
      "743:\tlearn: 3.1361611\ttotal: 9.39s\tremaining: 48.6s\n",
      "744:\tlearn: 3.1352657\ttotal: 9.4s\tremaining: 48.6s\n",
      "745:\tlearn: 3.1343125\ttotal: 9.41s\tremaining: 48.6s\n",
      "746:\tlearn: 3.1338211\ttotal: 9.42s\tremaining: 48.6s\n",
      "747:\tlearn: 3.1325267\ttotal: 9.44s\tremaining: 48.6s\n",
      "748:\tlearn: 3.1314810\ttotal: 9.45s\tremaining: 48.6s\n",
      "749:\tlearn: 3.1300923\ttotal: 9.46s\tremaining: 48.5s\n",
      "750:\tlearn: 3.1287306\ttotal: 9.47s\tremaining: 48.5s\n",
      "751:\tlearn: 3.1273158\ttotal: 9.49s\tremaining: 48.5s\n",
      "752:\tlearn: 3.1263625\ttotal: 9.51s\tremaining: 48.5s\n",
      "753:\tlearn: 3.1248938\ttotal: 9.52s\tremaining: 48.5s\n",
      "754:\tlearn: 3.1242831\ttotal: 9.53s\tremaining: 48.5s\n",
      "755:\tlearn: 3.1235719\ttotal: 9.55s\tremaining: 48.5s\n",
      "756:\tlearn: 3.1221635\ttotal: 9.56s\tremaining: 48.5s\n",
      "757:\tlearn: 3.1212356\ttotal: 9.57s\tremaining: 48.5s\n",
      "758:\tlearn: 3.1204152\ttotal: 9.58s\tremaining: 48.5s\n",
      "759:\tlearn: 3.1186896\ttotal: 9.59s\tremaining: 48.5s\n",
      "760:\tlearn: 3.1184161\ttotal: 9.61s\tremaining: 48.4s\n",
      "761:\tlearn: 3.1175496\ttotal: 9.62s\tremaining: 48.4s\n",
      "762:\tlearn: 3.1165675\ttotal: 9.63s\tremaining: 48.4s\n",
      "763:\tlearn: 3.1158086\ttotal: 9.64s\tremaining: 48.4s\n",
      "764:\tlearn: 3.1151946\ttotal: 9.65s\tremaining: 48.4s\n",
      "765:\tlearn: 3.1144483\ttotal: 9.66s\tremaining: 48.4s\n",
      "766:\tlearn: 3.1135044\ttotal: 9.68s\tremaining: 48.3s\n",
      "767:\tlearn: 3.1130867\ttotal: 9.69s\tremaining: 48.3s\n",
      "768:\tlearn: 3.1122610\ttotal: 9.7s\tremaining: 48.3s\n",
      "769:\tlearn: 3.1110047\ttotal: 9.71s\tremaining: 48.3s\n",
      "770:\tlearn: 3.1103554\ttotal: 9.73s\tremaining: 48.3s\n",
      "771:\tlearn: 3.1097763\ttotal: 9.74s\tremaining: 48.3s\n",
      "772:\tlearn: 3.1089964\ttotal: 9.75s\tremaining: 48.3s\n",
      "773:\tlearn: 3.1081765\ttotal: 9.76s\tremaining: 48.2s\n",
      "774:\tlearn: 3.1065819\ttotal: 9.78s\tremaining: 48.2s\n",
      "775:\tlearn: 3.1051215\ttotal: 9.79s\tremaining: 48.2s\n",
      "776:\tlearn: 3.1042377\ttotal: 9.8s\tremaining: 48.2s\n",
      "777:\tlearn: 3.1035045\ttotal: 9.81s\tremaining: 48.2s\n",
      "778:\tlearn: 3.1028825\ttotal: 9.83s\tremaining: 48.2s\n",
      "779:\tlearn: 3.1015800\ttotal: 9.84s\tremaining: 48.2s\n",
      "780:\tlearn: 3.1010078\ttotal: 9.85s\tremaining: 48.1s\n",
      "781:\tlearn: 3.0999781\ttotal: 9.86s\tremaining: 48.1s\n",
      "782:\tlearn: 3.0995153\ttotal: 9.88s\tremaining: 48.1s\n",
      "783:\tlearn: 3.0983800\ttotal: 9.89s\tremaining: 48.1s\n",
      "784:\tlearn: 3.0973797\ttotal: 9.9s\tremaining: 48.1s\n",
      "785:\tlearn: 3.0964449\ttotal: 9.91s\tremaining: 48.1s\n",
      "786:\tlearn: 3.0952495\ttotal: 9.92s\tremaining: 48.1s\n",
      "787:\tlearn: 3.0945639\ttotal: 9.94s\tremaining: 48s\n",
      "788:\tlearn: 3.0939038\ttotal: 9.95s\tremaining: 48s\n",
      "789:\tlearn: 3.0930310\ttotal: 9.96s\tremaining: 48s\n",
      "790:\tlearn: 3.0919450\ttotal: 9.97s\tremaining: 48s\n",
      "791:\tlearn: 3.0915553\ttotal: 9.99s\tremaining: 48s\n",
      "792:\tlearn: 3.0901370\ttotal: 10s\tremaining: 48s\n",
      "793:\tlearn: 3.0892477\ttotal: 10s\tremaining: 48s\n",
      "794:\tlearn: 3.0890652\ttotal: 10s\tremaining: 47.9s\n",
      "795:\tlearn: 3.0879382\ttotal: 10s\tremaining: 47.9s\n",
      "796:\tlearn: 3.0869324\ttotal: 10s\tremaining: 47.9s\n",
      "797:\tlearn: 3.0865657\ttotal: 10.1s\tremaining: 47.9s\n",
      "798:\tlearn: 3.0850684\ttotal: 10.1s\tremaining: 47.9s\n",
      "799:\tlearn: 3.0848074\ttotal: 10.1s\tremaining: 47.9s\n",
      "800:\tlearn: 3.0837019\ttotal: 10.1s\tremaining: 47.9s\n",
      "801:\tlearn: 3.0829663\ttotal: 10.1s\tremaining: 47.8s\n",
      "802:\tlearn: 3.0821029\ttotal: 10.1s\tremaining: 47.8s\n",
      "803:\tlearn: 3.0811050\ttotal: 10.1s\tremaining: 47.8s\n",
      "804:\tlearn: 3.0802081\ttotal: 10.1s\tremaining: 47.8s\n",
      "805:\tlearn: 3.0790269\ttotal: 10.2s\tremaining: 47.8s\n",
      "806:\tlearn: 3.0788481\ttotal: 10.2s\tremaining: 47.8s\n",
      "807:\tlearn: 3.0784891\ttotal: 10.2s\tremaining: 47.8s\n",
      "808:\tlearn: 3.0774847\ttotal: 10.2s\tremaining: 47.8s\n",
      "809:\tlearn: 3.0764524\ttotal: 10.2s\tremaining: 47.7s\n",
      "810:\tlearn: 3.0752898\ttotal: 10.2s\tremaining: 47.7s\n",
      "811:\tlearn: 3.0744224\ttotal: 10.2s\tremaining: 47.7s\n",
      "812:\tlearn: 3.0736199\ttotal: 10.2s\tremaining: 47.7s\n",
      "813:\tlearn: 3.0727241\ttotal: 10.3s\tremaining: 47.7s\n",
      "814:\tlearn: 3.0716751\ttotal: 10.3s\tremaining: 47.7s\n",
      "815:\tlearn: 3.0708153\ttotal: 10.3s\tremaining: 47.7s\n",
      "816:\tlearn: 3.0701481\ttotal: 10.3s\tremaining: 47.7s\n",
      "817:\tlearn: 3.0695580\ttotal: 10.3s\tremaining: 47.7s\n",
      "818:\tlearn: 3.0686575\ttotal: 10.3s\tremaining: 47.7s\n",
      "819:\tlearn: 3.0677755\ttotal: 10.3s\tremaining: 47.7s\n",
      "820:\tlearn: 3.0668974\ttotal: 10.4s\tremaining: 47.7s\n",
      "821:\tlearn: 3.0660084\ttotal: 10.4s\tremaining: 47.7s\n",
      "822:\tlearn: 3.0654115\ttotal: 10.4s\tremaining: 47.6s\n",
      "823:\tlearn: 3.0646063\ttotal: 10.4s\tremaining: 47.6s\n",
      "824:\tlearn: 3.0636509\ttotal: 10.4s\tremaining: 47.6s\n",
      "825:\tlearn: 3.0633874\ttotal: 10.4s\tremaining: 47.6s\n",
      "826:\tlearn: 3.0627683\ttotal: 10.4s\tremaining: 47.6s\n",
      "827:\tlearn: 3.0616853\ttotal: 10.4s\tremaining: 47.6s\n",
      "828:\tlearn: 3.0605853\ttotal: 10.5s\tremaining: 47.6s\n",
      "829:\tlearn: 3.0593074\ttotal: 10.5s\tremaining: 47.6s\n",
      "830:\tlearn: 3.0583278\ttotal: 10.5s\tremaining: 47.5s\n",
      "831:\tlearn: 3.0576265\ttotal: 10.5s\tremaining: 47.5s\n",
      "832:\tlearn: 3.0569881\ttotal: 10.5s\tremaining: 47.5s\n",
      "833:\tlearn: 3.0559741\ttotal: 10.5s\tremaining: 47.5s\n",
      "834:\tlearn: 3.0544772\ttotal: 10.5s\tremaining: 47.5s\n",
      "835:\tlearn: 3.0536258\ttotal: 10.5s\tremaining: 47.5s\n",
      "836:\tlearn: 3.0528289\ttotal: 10.6s\tremaining: 47.5s\n",
      "837:\tlearn: 3.0519547\ttotal: 10.6s\tremaining: 47.4s\n",
      "838:\tlearn: 3.0513328\ttotal: 10.6s\tremaining: 47.4s\n",
      "839:\tlearn: 3.0504060\ttotal: 10.6s\tremaining: 47.4s\n",
      "840:\tlearn: 3.0494902\ttotal: 10.6s\tremaining: 47.4s\n",
      "841:\tlearn: 3.0486972\ttotal: 10.6s\tremaining: 47.4s\n",
      "842:\tlearn: 3.0479580\ttotal: 10.6s\tremaining: 47.4s\n",
      "843:\tlearn: 3.0474775\ttotal: 10.7s\tremaining: 47.4s\n",
      "844:\tlearn: 3.0468770\ttotal: 10.7s\tremaining: 47.4s\n",
      "845:\tlearn: 3.0457290\ttotal: 10.7s\tremaining: 47.3s\n",
      "846:\tlearn: 3.0451203\ttotal: 10.7s\tremaining: 47.3s\n",
      "847:\tlearn: 3.0442321\ttotal: 10.7s\tremaining: 47.3s\n",
      "848:\tlearn: 3.0434812\ttotal: 10.7s\tremaining: 47.3s\n",
      "849:\tlearn: 3.0421163\ttotal: 10.7s\tremaining: 47.3s\n",
      "850:\tlearn: 3.0414024\ttotal: 10.7s\tremaining: 47.3s\n",
      "851:\tlearn: 3.0407761\ttotal: 10.7s\tremaining: 47.2s\n",
      "852:\tlearn: 3.0401358\ttotal: 10.8s\tremaining: 47.2s\n",
      "853:\tlearn: 3.0390123\ttotal: 10.8s\tremaining: 47.2s\n",
      "854:\tlearn: 3.0380834\ttotal: 10.8s\tremaining: 47.2s\n",
      "855:\tlearn: 3.0369694\ttotal: 10.8s\tremaining: 47.2s\n",
      "856:\tlearn: 3.0362396\ttotal: 10.8s\tremaining: 47.2s\n",
      "857:\tlearn: 3.0349354\ttotal: 10.8s\tremaining: 47.2s\n",
      "858:\tlearn: 3.0339227\ttotal: 10.8s\tremaining: 47.1s\n",
      "859:\tlearn: 3.0331904\ttotal: 10.8s\tremaining: 47.1s\n",
      "860:\tlearn: 3.0322540\ttotal: 10.9s\tremaining: 47.1s\n",
      "861:\tlearn: 3.0313570\ttotal: 10.9s\tremaining: 47.1s\n",
      "862:\tlearn: 3.0303765\ttotal: 10.9s\tremaining: 47.1s\n",
      "863:\tlearn: 3.0295380\ttotal: 10.9s\tremaining: 47.1s\n",
      "864:\tlearn: 3.0285872\ttotal: 10.9s\tremaining: 47s\n",
      "865:\tlearn: 3.0282274\ttotal: 10.9s\tremaining: 47s\n",
      "866:\tlearn: 3.0271831\ttotal: 10.9s\tremaining: 47s\n",
      "867:\tlearn: 3.0261457\ttotal: 10.9s\tremaining: 47s\n",
      "868:\tlearn: 3.0250488\ttotal: 10.9s\tremaining: 47s\n",
      "869:\tlearn: 3.0244855\ttotal: 11s\tremaining: 47s\n",
      "870:\tlearn: 3.0239237\ttotal: 11s\tremaining: 46.9s\n",
      "871:\tlearn: 3.0235671\ttotal: 11s\tremaining: 46.9s\n",
      "872:\tlearn: 3.0227081\ttotal: 11s\tremaining: 46.9s\n",
      "873:\tlearn: 3.0217326\ttotal: 11s\tremaining: 46.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "874:\tlearn: 3.0212508\ttotal: 11s\tremaining: 46.9s\n",
      "875:\tlearn: 3.0206581\ttotal: 11s\tremaining: 46.9s\n",
      "876:\tlearn: 3.0196372\ttotal: 11s\tremaining: 46.9s\n",
      "877:\tlearn: 3.0181401\ttotal: 11.1s\tremaining: 46.8s\n",
      "878:\tlearn: 3.0175182\ttotal: 11.1s\tremaining: 46.8s\n",
      "879:\tlearn: 3.0168333\ttotal: 11.1s\tremaining: 46.8s\n",
      "880:\tlearn: 3.0161723\ttotal: 11.1s\tremaining: 46.8s\n",
      "881:\tlearn: 3.0151249\ttotal: 11.1s\tremaining: 46.8s\n",
      "882:\tlearn: 3.0139676\ttotal: 11.1s\tremaining: 46.8s\n",
      "883:\tlearn: 3.0136758\ttotal: 11.1s\tremaining: 46.8s\n",
      "884:\tlearn: 3.0123719\ttotal: 11.1s\tremaining: 46.7s\n",
      "885:\tlearn: 3.0113450\ttotal: 11.2s\tremaining: 46.7s\n",
      "886:\tlearn: 3.0105098\ttotal: 11.2s\tremaining: 46.7s\n",
      "887:\tlearn: 3.0102689\ttotal: 11.2s\tremaining: 46.7s\n",
      "888:\tlearn: 3.0085363\ttotal: 11.2s\tremaining: 46.7s\n",
      "889:\tlearn: 3.0077507\ttotal: 11.2s\tremaining: 46.7s\n",
      "890:\tlearn: 3.0067047\ttotal: 11.2s\tremaining: 46.7s\n",
      "891:\tlearn: 3.0060762\ttotal: 11.2s\tremaining: 46.6s\n",
      "892:\tlearn: 3.0047523\ttotal: 11.2s\tremaining: 46.6s\n",
      "893:\tlearn: 3.0036522\ttotal: 11.3s\tremaining: 46.6s\n",
      "894:\tlearn: 3.0032501\ttotal: 11.3s\tremaining: 46.6s\n",
      "895:\tlearn: 3.0026562\ttotal: 11.3s\tremaining: 46.6s\n",
      "896:\tlearn: 3.0021776\ttotal: 11.3s\tremaining: 46.6s\n",
      "897:\tlearn: 3.0018164\ttotal: 11.3s\tremaining: 46.5s\n",
      "898:\tlearn: 2.9995454\ttotal: 11.3s\tremaining: 46.5s\n",
      "899:\tlearn: 2.9990361\ttotal: 11.3s\tremaining: 46.5s\n",
      "900:\tlearn: 2.9985111\ttotal: 11.3s\tremaining: 46.5s\n",
      "901:\tlearn: 2.9977085\ttotal: 11.3s\tremaining: 46.5s\n",
      "902:\tlearn: 2.9973789\ttotal: 11.4s\tremaining: 46.5s\n",
      "903:\tlearn: 2.9962622\ttotal: 11.4s\tremaining: 46.5s\n",
      "904:\tlearn: 2.9957520\ttotal: 11.4s\tremaining: 46.4s\n",
      "905:\tlearn: 2.9949469\ttotal: 11.4s\tremaining: 46.4s\n",
      "906:\tlearn: 2.9940172\ttotal: 11.4s\tremaining: 46.4s\n",
      "907:\tlearn: 2.9931321\ttotal: 11.4s\tremaining: 46.4s\n",
      "908:\tlearn: 2.9918973\ttotal: 11.4s\tremaining: 46.4s\n",
      "909:\tlearn: 2.9904674\ttotal: 11.4s\tremaining: 46.4s\n",
      "910:\tlearn: 2.9891276\ttotal: 11.5s\tremaining: 46.4s\n",
      "911:\tlearn: 2.9884325\ttotal: 11.5s\tremaining: 46.4s\n",
      "912:\tlearn: 2.9875530\ttotal: 11.5s\tremaining: 46.4s\n",
      "913:\tlearn: 2.9864968\ttotal: 11.5s\tremaining: 46.4s\n",
      "914:\tlearn: 2.9855637\ttotal: 11.5s\tremaining: 46.3s\n",
      "915:\tlearn: 2.9846713\ttotal: 11.5s\tremaining: 46.3s\n",
      "916:\tlearn: 2.9838174\ttotal: 11.5s\tremaining: 46.3s\n",
      "917:\tlearn: 2.9829083\ttotal: 11.6s\tremaining: 46.3s\n",
      "918:\tlearn: 2.9821063\ttotal: 11.6s\tremaining: 46.3s\n",
      "919:\tlearn: 2.9809010\ttotal: 11.6s\tremaining: 46.3s\n",
      "920:\tlearn: 2.9800910\ttotal: 11.6s\tremaining: 46.3s\n",
      "921:\tlearn: 2.9794982\ttotal: 11.6s\tremaining: 46.3s\n",
      "922:\tlearn: 2.9784868\ttotal: 11.6s\tremaining: 46.3s\n",
      "923:\tlearn: 2.9774072\ttotal: 11.6s\tremaining: 46.3s\n",
      "924:\tlearn: 2.9768147\ttotal: 11.7s\tremaining: 46.3s\n",
      "925:\tlearn: 2.9756916\ttotal: 11.7s\tremaining: 46.3s\n",
      "926:\tlearn: 2.9748443\ttotal: 11.7s\tremaining: 46.2s\n",
      "927:\tlearn: 2.9735415\ttotal: 11.7s\tremaining: 46.2s\n",
      "928:\tlearn: 2.9716306\ttotal: 11.7s\tremaining: 46.2s\n",
      "929:\tlearn: 2.9711402\ttotal: 11.7s\tremaining: 46.2s\n",
      "930:\tlearn: 2.9701692\ttotal: 11.7s\tremaining: 46.2s\n",
      "931:\tlearn: 2.9694575\ttotal: 11.7s\tremaining: 46.2s\n",
      "932:\tlearn: 2.9677660\ttotal: 11.7s\tremaining: 46.2s\n",
      "933:\tlearn: 2.9669529\ttotal: 11.8s\tremaining: 46.1s\n",
      "934:\tlearn: 2.9663584\ttotal: 11.8s\tremaining: 46.1s\n",
      "935:\tlearn: 2.9657594\ttotal: 11.8s\tremaining: 46.1s\n",
      "936:\tlearn: 2.9651725\ttotal: 11.8s\tremaining: 46.1s\n",
      "937:\tlearn: 2.9646031\ttotal: 11.8s\tremaining: 46.1s\n",
      "938:\tlearn: 2.9636610\ttotal: 11.8s\tremaining: 46.1s\n",
      "939:\tlearn: 2.9631932\ttotal: 11.8s\tremaining: 46s\n",
      "940:\tlearn: 2.9622901\ttotal: 11.8s\tremaining: 46s\n",
      "941:\tlearn: 2.9614861\ttotal: 11.9s\tremaining: 46s\n",
      "942:\tlearn: 2.9604395\ttotal: 11.9s\tremaining: 46s\n",
      "943:\tlearn: 2.9595807\ttotal: 11.9s\tremaining: 46s\n",
      "944:\tlearn: 2.9583216\ttotal: 11.9s\tremaining: 46s\n",
      "945:\tlearn: 2.9573229\ttotal: 11.9s\tremaining: 46s\n",
      "946:\tlearn: 2.9559933\ttotal: 11.9s\tremaining: 46s\n",
      "947:\tlearn: 2.9549804\ttotal: 11.9s\tremaining: 45.9s\n",
      "948:\tlearn: 2.9536499\ttotal: 11.9s\tremaining: 45.9s\n",
      "949:\tlearn: 2.9532244\ttotal: 12s\tremaining: 45.9s\n",
      "950:\tlearn: 2.9526746\ttotal: 12s\tremaining: 45.9s\n",
      "951:\tlearn: 2.9516562\ttotal: 12s\tremaining: 45.9s\n",
      "952:\tlearn: 2.9505694\ttotal: 12s\tremaining: 45.9s\n",
      "953:\tlearn: 2.9500437\ttotal: 12s\tremaining: 45.8s\n",
      "954:\tlearn: 2.9491434\ttotal: 12s\tremaining: 45.8s\n",
      "955:\tlearn: 2.9483868\ttotal: 12s\tremaining: 45.8s\n",
      "956:\tlearn: 2.9475811\ttotal: 12s\tremaining: 45.8s\n",
      "957:\tlearn: 2.9467661\ttotal: 12s\tremaining: 45.8s\n",
      "958:\tlearn: 2.9463660\ttotal: 12.1s\tremaining: 45.8s\n",
      "959:\tlearn: 2.9459427\ttotal: 12.1s\tremaining: 45.8s\n",
      "960:\tlearn: 2.9453138\ttotal: 12.1s\tremaining: 45.7s\n",
      "961:\tlearn: 2.9441627\ttotal: 12.1s\tremaining: 45.7s\n",
      "962:\tlearn: 2.9429830\ttotal: 12.1s\tremaining: 45.7s\n",
      "963:\tlearn: 2.9420299\ttotal: 12.1s\tremaining: 45.7s\n",
      "964:\tlearn: 2.9410345\ttotal: 12.1s\tremaining: 45.7s\n",
      "965:\tlearn: 2.9401495\ttotal: 12.1s\tremaining: 45.7s\n",
      "966:\tlearn: 2.9395502\ttotal: 12.2s\tremaining: 45.6s\n",
      "967:\tlearn: 2.9388723\ttotal: 12.2s\tremaining: 45.6s\n",
      "968:\tlearn: 2.9377992\ttotal: 12.2s\tremaining: 45.6s\n",
      "969:\tlearn: 2.9374166\ttotal: 12.2s\tremaining: 45.6s\n",
      "970:\tlearn: 2.9368134\ttotal: 12.2s\tremaining: 45.6s\n",
      "971:\tlearn: 2.9360088\ttotal: 12.2s\tremaining: 45.6s\n",
      "972:\tlearn: 2.9352505\ttotal: 12.2s\tremaining: 45.6s\n",
      "973:\tlearn: 2.9341099\ttotal: 12.2s\tremaining: 45.5s\n",
      "974:\tlearn: 2.9335075\ttotal: 12.3s\tremaining: 45.5s\n",
      "975:\tlearn: 2.9333337\ttotal: 12.3s\tremaining: 45.5s\n",
      "976:\tlearn: 2.9329739\ttotal: 12.3s\tremaining: 45.5s\n",
      "977:\tlearn: 2.9319520\ttotal: 12.3s\tremaining: 45.5s\n",
      "978:\tlearn: 2.9314993\ttotal: 12.3s\tremaining: 45.5s\n",
      "979:\tlearn: 2.9307985\ttotal: 12.3s\tremaining: 45.5s\n",
      "980:\tlearn: 2.9303327\ttotal: 12.3s\tremaining: 45.5s\n",
      "981:\tlearn: 2.9291511\ttotal: 12.3s\tremaining: 45.5s\n",
      "982:\tlearn: 2.9284128\ttotal: 12.4s\tremaining: 45.4s\n",
      "983:\tlearn: 2.9279679\ttotal: 12.4s\tremaining: 45.4s\n",
      "984:\tlearn: 2.9270481\ttotal: 12.4s\tremaining: 45.4s\n",
      "985:\tlearn: 2.9260595\ttotal: 12.4s\tremaining: 45.4s\n",
      "986:\tlearn: 2.9257378\ttotal: 12.4s\tremaining: 45.4s\n",
      "987:\tlearn: 2.9249086\ttotal: 12.4s\tremaining: 45.3s\n",
      "988:\tlearn: 2.9243449\ttotal: 12.4s\tremaining: 45.3s\n",
      "989:\tlearn: 2.9233336\ttotal: 12.4s\tremaining: 45.3s\n",
      "990:\tlearn: 2.9229272\ttotal: 12.4s\tremaining: 45.3s\n",
      "991:\tlearn: 2.9219296\ttotal: 12.5s\tremaining: 45.3s\n",
      "992:\tlearn: 2.9210880\ttotal: 12.5s\tremaining: 45.3s\n",
      "993:\tlearn: 2.9205557\ttotal: 12.5s\tremaining: 45.3s\n",
      "994:\tlearn: 2.9200952\ttotal: 12.5s\tremaining: 45.2s\n",
      "995:\tlearn: 2.9191054\ttotal: 12.5s\tremaining: 45.2s\n",
      "996:\tlearn: 2.9182385\ttotal: 12.5s\tremaining: 45.2s\n",
      "997:\tlearn: 2.9178796\ttotal: 12.5s\tremaining: 45.2s\n",
      "998:\tlearn: 2.9173513\ttotal: 12.5s\tremaining: 45.2s\n",
      "999:\tlearn: 2.9163484\ttotal: 12.6s\tremaining: 45.2s\n",
      "1000:\tlearn: 2.9152139\ttotal: 12.6s\tremaining: 45.2s\n",
      "1001:\tlearn: 2.9141547\ttotal: 12.6s\tremaining: 45.1s\n",
      "1002:\tlearn: 2.9135057\ttotal: 12.6s\tremaining: 45.1s\n",
      "1003:\tlearn: 2.9131004\ttotal: 12.6s\tremaining: 45.1s\n",
      "1004:\tlearn: 2.9123954\ttotal: 12.6s\tremaining: 45.1s\n",
      "1005:\tlearn: 2.9117567\ttotal: 12.6s\tremaining: 45.1s\n",
      "1006:\tlearn: 2.9113847\ttotal: 12.6s\tremaining: 45.1s\n",
      "1007:\tlearn: 2.9102590\ttotal: 12.7s\tremaining: 45.1s\n",
      "1008:\tlearn: 2.9097069\ttotal: 12.7s\tremaining: 45s\n",
      "1009:\tlearn: 2.9085951\ttotal: 12.7s\tremaining: 45s\n",
      "1010:\tlearn: 2.9080914\ttotal: 12.7s\tremaining: 45s\n",
      "1011:\tlearn: 2.9072996\ttotal: 12.7s\tremaining: 45s\n",
      "1012:\tlearn: 2.9068983\ttotal: 12.7s\tremaining: 45s\n",
      "1013:\tlearn: 2.9063879\ttotal: 12.7s\tremaining: 45s\n",
      "1014:\tlearn: 2.9058834\ttotal: 12.7s\tremaining: 45s\n",
      "1015:\tlearn: 2.9048010\ttotal: 12.8s\tremaining: 45s\n",
      "1016:\tlearn: 2.9043614\ttotal: 12.8s\tremaining: 44.9s\n",
      "1017:\tlearn: 2.9038488\ttotal: 12.8s\tremaining: 44.9s\n",
      "1018:\tlearn: 2.9035830\ttotal: 12.8s\tremaining: 44.9s\n",
      "1019:\tlearn: 2.9029784\ttotal: 12.8s\tremaining: 44.9s\n",
      "1020:\tlearn: 2.9019870\ttotal: 12.8s\tremaining: 44.9s\n",
      "1021:\tlearn: 2.9013820\ttotal: 12.8s\tremaining: 44.9s\n",
      "1022:\tlearn: 2.9006032\ttotal: 12.8s\tremaining: 44.8s\n",
      "1023:\tlearn: 2.8992870\ttotal: 12.8s\tremaining: 44.8s\n",
      "1024:\tlearn: 2.8978217\ttotal: 12.9s\tremaining: 44.8s\n",
      "1025:\tlearn: 2.8966987\ttotal: 12.9s\tremaining: 44.8s\n",
      "1026:\tlearn: 2.8960944\ttotal: 12.9s\tremaining: 44.8s\n",
      "1027:\tlearn: 2.8954869\ttotal: 12.9s\tremaining: 44.8s\n",
      "1028:\tlearn: 2.8947607\ttotal: 12.9s\tremaining: 44.8s\n",
      "1029:\tlearn: 2.8934545\ttotal: 12.9s\tremaining: 44.8s\n",
      "1030:\tlearn: 2.8927519\ttotal: 12.9s\tremaining: 44.7s\n",
      "1031:\tlearn: 2.8922141\ttotal: 12.9s\tremaining: 44.7s\n",
      "1032:\tlearn: 2.8918982\ttotal: 13s\tremaining: 44.7s\n",
      "1033:\tlearn: 2.8912457\ttotal: 13s\tremaining: 44.7s\n",
      "1034:\tlearn: 2.8907809\ttotal: 13s\tremaining: 44.7s\n",
      "1035:\tlearn: 2.8902660\ttotal: 13s\tremaining: 44.7s\n",
      "1036:\tlearn: 2.8898382\ttotal: 13s\tremaining: 44.7s\n",
      "1037:\tlearn: 2.8893356\ttotal: 13s\tremaining: 44.6s\n",
      "1038:\tlearn: 2.8885350\ttotal: 13s\tremaining: 44.6s\n",
      "1039:\tlearn: 2.8877150\ttotal: 13s\tremaining: 44.6s\n",
      "1040:\tlearn: 2.8868294\ttotal: 13.1s\tremaining: 44.6s\n",
      "1041:\tlearn: 2.8862745\ttotal: 13.1s\tremaining: 44.6s\n",
      "1042:\tlearn: 2.8859706\ttotal: 13.1s\tremaining: 44.6s\n",
      "1043:\tlearn: 2.8855265\ttotal: 13.1s\tremaining: 44.6s\n",
      "1044:\tlearn: 2.8847481\ttotal: 13.1s\tremaining: 44.5s\n",
      "1045:\tlearn: 2.8841091\ttotal: 13.1s\tremaining: 44.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046:\tlearn: 2.8832652\ttotal: 13.1s\tremaining: 44.5s\n",
      "1047:\tlearn: 2.8826207\ttotal: 13.1s\tremaining: 44.5s\n",
      "1048:\tlearn: 2.8822566\ttotal: 13.2s\tremaining: 44.5s\n",
      "1049:\tlearn: 2.8817812\ttotal: 13.2s\tremaining: 44.5s\n",
      "1050:\tlearn: 2.8809971\ttotal: 13.2s\tremaining: 44.5s\n",
      "1051:\tlearn: 2.8804941\ttotal: 13.2s\tremaining: 44.4s\n",
      "1052:\tlearn: 2.8804879\ttotal: 13.2s\tremaining: 44.4s\n",
      "1053:\tlearn: 2.8802819\ttotal: 13.2s\tremaining: 44.4s\n",
      "1054:\tlearn: 2.8790012\ttotal: 13.2s\tremaining: 44.4s\n",
      "1055:\tlearn: 2.8783925\ttotal: 13.2s\tremaining: 44.4s\n",
      "1056:\tlearn: 2.8773709\ttotal: 13.2s\tremaining: 44.4s\n",
      "1057:\tlearn: 2.8767474\ttotal: 13.3s\tremaining: 44.4s\n",
      "1058:\tlearn: 2.8756328\ttotal: 13.3s\tremaining: 44.3s\n",
      "1059:\tlearn: 2.8748465\ttotal: 13.3s\tremaining: 44.3s\n",
      "1060:\tlearn: 2.8740761\ttotal: 13.3s\tremaining: 44.3s\n",
      "1061:\tlearn: 2.8730792\ttotal: 13.3s\tremaining: 44.3s\n",
      "1062:\tlearn: 2.8723720\ttotal: 13.3s\tremaining: 44.3s\n",
      "1063:\tlearn: 2.8718866\ttotal: 13.3s\tremaining: 44.3s\n",
      "1064:\tlearn: 2.8714094\ttotal: 13.3s\tremaining: 44.3s\n",
      "1065:\tlearn: 2.8702074\ttotal: 13.4s\tremaining: 44.3s\n",
      "1066:\tlearn: 2.8693181\ttotal: 13.4s\tremaining: 44.2s\n",
      "1067:\tlearn: 2.8684002\ttotal: 13.4s\tremaining: 44.2s\n",
      "1068:\tlearn: 2.8670847\ttotal: 13.4s\tremaining: 44.2s\n",
      "1069:\tlearn: 2.8665867\ttotal: 13.4s\tremaining: 44.2s\n",
      "1070:\tlearn: 2.8658151\ttotal: 13.4s\tremaining: 44.2s\n",
      "1071:\tlearn: 2.8652343\ttotal: 13.4s\tremaining: 44.2s\n",
      "1072:\tlearn: 2.8644654\ttotal: 13.4s\tremaining: 44.2s\n",
      "1073:\tlearn: 2.8637707\ttotal: 13.5s\tremaining: 44.1s\n",
      "1074:\tlearn: 2.8625760\ttotal: 13.5s\tremaining: 44.1s\n",
      "1075:\tlearn: 2.8617996\ttotal: 13.5s\tremaining: 44.1s\n",
      "1076:\tlearn: 2.8606181\ttotal: 13.5s\tremaining: 44.1s\n",
      "1077:\tlearn: 2.8598064\ttotal: 13.5s\tremaining: 44.1s\n",
      "1078:\tlearn: 2.8590959\ttotal: 13.5s\tremaining: 44.1s\n",
      "1079:\tlearn: 2.8584787\ttotal: 13.5s\tremaining: 44.1s\n",
      "1080:\tlearn: 2.8576445\ttotal: 13.5s\tremaining: 44.1s\n",
      "1081:\tlearn: 2.8571626\ttotal: 13.6s\tremaining: 44s\n",
      "1082:\tlearn: 2.8566540\ttotal: 13.6s\tremaining: 44s\n",
      "1083:\tlearn: 2.8561323\ttotal: 13.6s\tremaining: 44s\n",
      "1084:\tlearn: 2.8553567\ttotal: 13.6s\tremaining: 44s\n",
      "1085:\tlearn: 2.8553539\ttotal: 13.6s\tremaining: 44s\n",
      "1086:\tlearn: 2.8542862\ttotal: 13.6s\tremaining: 44s\n",
      "1087:\tlearn: 2.8533680\ttotal: 13.6s\tremaining: 44s\n",
      "1088:\tlearn: 2.8528281\ttotal: 13.6s\tremaining: 43.9s\n",
      "1089:\tlearn: 2.8525012\ttotal: 13.6s\tremaining: 43.9s\n",
      "1090:\tlearn: 2.8513611\ttotal: 13.7s\tremaining: 43.9s\n",
      "1091:\tlearn: 2.8510195\ttotal: 13.7s\tremaining: 43.9s\n",
      "1092:\tlearn: 2.8505148\ttotal: 13.7s\tremaining: 43.9s\n",
      "1093:\tlearn: 2.8499193\ttotal: 13.7s\tremaining: 43.9s\n",
      "1094:\tlearn: 2.8496015\ttotal: 13.7s\tremaining: 43.8s\n",
      "1095:\tlearn: 2.8486011\ttotal: 13.7s\tremaining: 43.8s\n",
      "1096:\tlearn: 2.8477512\ttotal: 13.7s\tremaining: 43.8s\n",
      "1097:\tlearn: 2.8469485\ttotal: 13.7s\tremaining: 43.8s\n",
      "1098:\tlearn: 2.8464686\ttotal: 13.8s\tremaining: 43.8s\n",
      "1099:\tlearn: 2.8459542\ttotal: 13.8s\tremaining: 43.8s\n",
      "1100:\tlearn: 2.8452439\ttotal: 13.8s\tremaining: 43.8s\n",
      "1101:\tlearn: 2.8445636\ttotal: 13.8s\tremaining: 43.8s\n",
      "1102:\tlearn: 2.8436049\ttotal: 13.8s\tremaining: 43.7s\n",
      "1103:\tlearn: 2.8431901\ttotal: 13.8s\tremaining: 43.7s\n",
      "1104:\tlearn: 2.8428796\ttotal: 13.8s\tremaining: 43.7s\n",
      "1105:\tlearn: 2.8427794\ttotal: 13.8s\tremaining: 43.7s\n",
      "1106:\tlearn: 2.8422453\ttotal: 13.9s\tremaining: 43.7s\n",
      "1107:\tlearn: 2.8413703\ttotal: 13.9s\tremaining: 43.7s\n",
      "1108:\tlearn: 2.8403894\ttotal: 13.9s\tremaining: 43.7s\n",
      "1109:\tlearn: 2.8399569\ttotal: 13.9s\tremaining: 43.7s\n",
      "1110:\tlearn: 2.8391896\ttotal: 13.9s\tremaining: 43.6s\n",
      "1111:\tlearn: 2.8384709\ttotal: 13.9s\tremaining: 43.6s\n",
      "1112:\tlearn: 2.8379330\ttotal: 13.9s\tremaining: 43.6s\n",
      "1113:\tlearn: 2.8369771\ttotal: 13.9s\tremaining: 43.6s\n",
      "1114:\tlearn: 2.8363998\ttotal: 14s\tremaining: 43.6s\n",
      "1115:\tlearn: 2.8351971\ttotal: 14s\tremaining: 43.6s\n",
      "1116:\tlearn: 2.8348109\ttotal: 14s\tremaining: 43.6s\n",
      "1117:\tlearn: 2.8341102\ttotal: 14s\tremaining: 43.6s\n",
      "1118:\tlearn: 2.8334949\ttotal: 14s\tremaining: 43.5s\n",
      "1119:\tlearn: 2.8331129\ttotal: 14s\tremaining: 43.5s\n",
      "1120:\tlearn: 2.8322862\ttotal: 14s\tremaining: 43.5s\n",
      "1121:\tlearn: 2.8315850\ttotal: 14s\tremaining: 43.5s\n",
      "1122:\tlearn: 2.8311305\ttotal: 14.1s\tremaining: 43.5s\n",
      "1123:\tlearn: 2.8302150\ttotal: 14.1s\tremaining: 43.5s\n",
      "1124:\tlearn: 2.8295885\ttotal: 14.1s\tremaining: 43.5s\n",
      "1125:\tlearn: 2.8289558\ttotal: 14.1s\tremaining: 43.5s\n",
      "1126:\tlearn: 2.8282490\ttotal: 14.1s\tremaining: 43.4s\n",
      "1127:\tlearn: 2.8275663\ttotal: 14.1s\tremaining: 43.4s\n",
      "1128:\tlearn: 2.8267174\ttotal: 14.1s\tremaining: 43.4s\n",
      "1129:\tlearn: 2.8260843\ttotal: 14.1s\tremaining: 43.4s\n",
      "1130:\tlearn: 2.8255496\ttotal: 14.2s\tremaining: 43.4s\n",
      "1131:\tlearn: 2.8249705\ttotal: 14.2s\tremaining: 43.4s\n",
      "1132:\tlearn: 2.8239259\ttotal: 14.2s\tremaining: 43.4s\n",
      "1133:\tlearn: 2.8227634\ttotal: 14.2s\tremaining: 43.4s\n",
      "1134:\tlearn: 2.8216293\ttotal: 14.2s\tremaining: 43.3s\n",
      "1135:\tlearn: 2.8210409\ttotal: 14.2s\tremaining: 43.3s\n",
      "1136:\tlearn: 2.8201583\ttotal: 14.2s\tremaining: 43.3s\n",
      "1137:\tlearn: 2.8194671\ttotal: 14.2s\tremaining: 43.3s\n",
      "1138:\tlearn: 2.8186172\ttotal: 14.3s\tremaining: 43.3s\n",
      "1139:\tlearn: 2.8177369\ttotal: 14.3s\tremaining: 43.3s\n",
      "1140:\tlearn: 2.8167611\ttotal: 14.3s\tremaining: 43.3s\n",
      "1141:\tlearn: 2.8160204\ttotal: 14.3s\tremaining: 43.3s\n",
      "1142:\tlearn: 2.8155187\ttotal: 14.3s\tremaining: 43.2s\n",
      "1143:\tlearn: 2.8151072\ttotal: 14.3s\tremaining: 43.2s\n",
      "1144:\tlearn: 2.8144477\ttotal: 14.3s\tremaining: 43.2s\n",
      "1145:\tlearn: 2.8139955\ttotal: 14.3s\tremaining: 43.2s\n",
      "1146:\tlearn: 2.8136224\ttotal: 14.4s\tremaining: 43.2s\n",
      "1147:\tlearn: 2.8131450\ttotal: 14.4s\tremaining: 43.2s\n",
      "1148:\tlearn: 2.8124366\ttotal: 14.4s\tremaining: 43.2s\n",
      "1149:\tlearn: 2.8116852\ttotal: 14.4s\tremaining: 43.1s\n",
      "1150:\tlearn: 2.8108532\ttotal: 14.4s\tremaining: 43.1s\n",
      "1151:\tlearn: 2.8096525\ttotal: 14.4s\tremaining: 43.1s\n",
      "1152:\tlearn: 2.8091468\ttotal: 14.4s\tremaining: 43.1s\n",
      "1153:\tlearn: 2.8083984\ttotal: 14.4s\tremaining: 43.1s\n",
      "1154:\tlearn: 2.8083264\ttotal: 14.5s\tremaining: 43.1s\n",
      "1155:\tlearn: 2.8079793\ttotal: 14.5s\tremaining: 43.1s\n",
      "1156:\tlearn: 2.8072770\ttotal: 14.5s\tremaining: 43.1s\n",
      "1157:\tlearn: 2.8059687\ttotal: 14.5s\tremaining: 43s\n",
      "1158:\tlearn: 2.8052681\ttotal: 14.5s\tremaining: 43s\n",
      "1159:\tlearn: 2.8046173\ttotal: 14.5s\tremaining: 43s\n",
      "1160:\tlearn: 2.8043927\ttotal: 14.5s\tremaining: 43s\n",
      "1161:\tlearn: 2.8035830\ttotal: 14.5s\tremaining: 43s\n",
      "1162:\tlearn: 2.8025037\ttotal: 14.6s\tremaining: 43s\n",
      "1163:\tlearn: 2.8017267\ttotal: 14.6s\tremaining: 43s\n",
      "1164:\tlearn: 2.8016137\ttotal: 14.6s\tremaining: 42.9s\n",
      "1165:\tlearn: 2.8012153\ttotal: 14.6s\tremaining: 42.9s\n",
      "1166:\tlearn: 2.8000637\ttotal: 14.6s\tremaining: 42.9s\n",
      "1167:\tlearn: 2.7993137\ttotal: 14.6s\tremaining: 42.9s\n",
      "1168:\tlearn: 2.7986688\ttotal: 14.6s\tremaining: 42.9s\n",
      "1169:\tlearn: 2.7981380\ttotal: 14.6s\tremaining: 42.9s\n",
      "1170:\tlearn: 2.7974235\ttotal: 14.6s\tremaining: 42.9s\n",
      "1171:\tlearn: 2.7966456\ttotal: 14.7s\tremaining: 42.8s\n",
      "1172:\tlearn: 2.7960616\ttotal: 14.7s\tremaining: 42.8s\n",
      "1173:\tlearn: 2.7950986\ttotal: 14.7s\tremaining: 42.8s\n",
      "1174:\tlearn: 2.7938738\ttotal: 14.7s\tremaining: 42.8s\n",
      "1175:\tlearn: 2.7933479\ttotal: 14.7s\tremaining: 42.8s\n",
      "1176:\tlearn: 2.7932297\ttotal: 14.7s\tremaining: 42.8s\n",
      "1177:\tlearn: 2.7926338\ttotal: 14.7s\tremaining: 42.8s\n",
      "1178:\tlearn: 2.7923183\ttotal: 14.7s\tremaining: 42.7s\n",
      "1179:\tlearn: 2.7917884\ttotal: 14.8s\tremaining: 42.7s\n",
      "1180:\tlearn: 2.7911171\ttotal: 14.8s\tremaining: 42.7s\n",
      "1181:\tlearn: 2.7905456\ttotal: 14.8s\tremaining: 42.7s\n",
      "1182:\tlearn: 2.7897426\ttotal: 14.8s\tremaining: 42.7s\n",
      "1183:\tlearn: 2.7890649\ttotal: 14.8s\tremaining: 42.7s\n",
      "1184:\tlearn: 2.7881510\ttotal: 14.8s\tremaining: 42.7s\n",
      "1185:\tlearn: 2.7876702\ttotal: 14.8s\tremaining: 42.6s\n",
      "1186:\tlearn: 2.7868995\ttotal: 14.8s\tremaining: 42.6s\n",
      "1187:\tlearn: 2.7864152\ttotal: 14.8s\tremaining: 42.6s\n",
      "1188:\tlearn: 2.7856083\ttotal: 14.9s\tremaining: 42.6s\n",
      "1189:\tlearn: 2.7851251\ttotal: 14.9s\tremaining: 42.6s\n",
      "1190:\tlearn: 2.7848023\ttotal: 14.9s\tremaining: 42.6s\n",
      "1191:\tlearn: 2.7837784\ttotal: 14.9s\tremaining: 42.6s\n",
      "1192:\tlearn: 2.7827162\ttotal: 14.9s\tremaining: 42.6s\n",
      "1193:\tlearn: 2.7822543\ttotal: 14.9s\tremaining: 42.5s\n",
      "1194:\tlearn: 2.7817182\ttotal: 14.9s\tremaining: 42.5s\n",
      "1195:\tlearn: 2.7812508\ttotal: 14.9s\tremaining: 42.5s\n",
      "1196:\tlearn: 2.7805465\ttotal: 15s\tremaining: 42.5s\n",
      "1197:\tlearn: 2.7799934\ttotal: 15s\tremaining: 42.5s\n",
      "1198:\tlearn: 2.7792561\ttotal: 15s\tremaining: 42.5s\n",
      "1199:\tlearn: 2.7788207\ttotal: 15s\tremaining: 42.5s\n",
      "1200:\tlearn: 2.7781929\ttotal: 15s\tremaining: 42.4s\n",
      "1201:\tlearn: 2.7763899\ttotal: 15s\tremaining: 42.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202:\tlearn: 2.7757051\ttotal: 15s\tremaining: 42.4s\n",
      "1203:\tlearn: 2.7751392\ttotal: 15s\tremaining: 42.4s\n",
      "1204:\tlearn: 2.7740907\ttotal: 15.1s\tremaining: 42.4s\n",
      "1205:\tlearn: 2.7728352\ttotal: 15.1s\tremaining: 42.4s\n",
      "1206:\tlearn: 2.7722838\ttotal: 15.1s\tremaining: 42.4s\n",
      "1207:\tlearn: 2.7720624\ttotal: 15.1s\tremaining: 42.4s\n",
      "1208:\tlearn: 2.7716222\ttotal: 15.1s\tremaining: 42.3s\n",
      "1209:\tlearn: 2.7710677\ttotal: 15.1s\tremaining: 42.3s\n",
      "1210:\tlearn: 2.7706212\ttotal: 15.1s\tremaining: 42.3s\n",
      "1211:\tlearn: 2.7703129\ttotal: 15.1s\tremaining: 42.3s\n",
      "1212:\tlearn: 2.7698829\ttotal: 15.2s\tremaining: 42.3s\n",
      "1213:\tlearn: 2.7695067\ttotal: 15.2s\tremaining: 42.3s\n",
      "1214:\tlearn: 2.7689252\ttotal: 15.2s\tremaining: 42.3s\n",
      "1215:\tlearn: 2.7684765\ttotal: 15.2s\tremaining: 42.2s\n",
      "1216:\tlearn: 2.7679934\ttotal: 15.2s\tremaining: 42.2s\n",
      "1217:\tlearn: 2.7677423\ttotal: 15.2s\tremaining: 42.2s\n",
      "1218:\tlearn: 2.7672649\ttotal: 15.2s\tremaining: 42.2s\n",
      "1219:\tlearn: 2.7669640\ttotal: 15.2s\tremaining: 42.2s\n",
      "1220:\tlearn: 2.7662755\ttotal: 15.3s\tremaining: 42.2s\n",
      "1221:\tlearn: 2.7651657\ttotal: 15.3s\tremaining: 42.2s\n",
      "1222:\tlearn: 2.7646030\ttotal: 15.3s\tremaining: 42.2s\n",
      "1223:\tlearn: 2.7638179\ttotal: 15.3s\tremaining: 42.1s\n",
      "1224:\tlearn: 2.7634275\ttotal: 15.3s\tremaining: 42.1s\n",
      "1225:\tlearn: 2.7629051\ttotal: 15.3s\tremaining: 42.1s\n",
      "1226:\tlearn: 2.7621971\ttotal: 15.3s\tremaining: 42.1s\n",
      "1227:\tlearn: 2.7616217\ttotal: 15.3s\tremaining: 42.1s\n",
      "1228:\tlearn: 2.7606267\ttotal: 15.4s\tremaining: 42.1s\n",
      "1229:\tlearn: 2.7597787\ttotal: 15.4s\tremaining: 42.1s\n",
      "1230:\tlearn: 2.7590820\ttotal: 15.4s\tremaining: 42.1s\n",
      "1231:\tlearn: 2.7573593\ttotal: 15.4s\tremaining: 42s\n",
      "1232:\tlearn: 2.7567131\ttotal: 15.4s\tremaining: 42s\n",
      "1233:\tlearn: 2.7561167\ttotal: 15.4s\tremaining: 42s\n",
      "1234:\tlearn: 2.7549095\ttotal: 15.4s\tremaining: 42s\n",
      "1235:\tlearn: 2.7544271\ttotal: 15.4s\tremaining: 42s\n",
      "1236:\tlearn: 2.7534690\ttotal: 15.4s\tremaining: 42s\n",
      "1237:\tlearn: 2.7531571\ttotal: 15.5s\tremaining: 42s\n",
      "1238:\tlearn: 2.7525722\ttotal: 15.5s\tremaining: 42s\n",
      "1239:\tlearn: 2.7519516\ttotal: 15.5s\tremaining: 41.9s\n",
      "1240:\tlearn: 2.7512601\ttotal: 15.5s\tremaining: 41.9s\n",
      "1241:\tlearn: 2.7509828\ttotal: 15.5s\tremaining: 41.9s\n",
      "1242:\tlearn: 2.7505211\ttotal: 15.5s\tremaining: 41.9s\n",
      "1243:\tlearn: 2.7500318\ttotal: 15.5s\tremaining: 41.9s\n",
      "1244:\tlearn: 2.7488478\ttotal: 15.6s\tremaining: 41.9s\n",
      "1245:\tlearn: 2.7482394\ttotal: 15.6s\tremaining: 41.9s\n",
      "1246:\tlearn: 2.7478823\ttotal: 15.6s\tremaining: 41.9s\n",
      "1247:\tlearn: 2.7467156\ttotal: 15.6s\tremaining: 41.8s\n",
      "1248:\tlearn: 2.7460521\ttotal: 15.6s\tremaining: 41.8s\n",
      "1249:\tlearn: 2.7455650\ttotal: 15.6s\tremaining: 41.8s\n",
      "1250:\tlearn: 2.7450673\ttotal: 15.6s\tremaining: 41.8s\n",
      "1251:\tlearn: 2.7444886\ttotal: 15.6s\tremaining: 41.8s\n",
      "1252:\tlearn: 2.7438884\ttotal: 15.6s\tremaining: 41.8s\n",
      "1253:\tlearn: 2.7433354\ttotal: 15.7s\tremaining: 41.8s\n",
      "1254:\tlearn: 2.7430490\ttotal: 15.7s\tremaining: 41.7s\n",
      "1255:\tlearn: 2.7425892\ttotal: 15.7s\tremaining: 41.7s\n",
      "1256:\tlearn: 2.7414085\ttotal: 15.7s\tremaining: 41.7s\n",
      "1257:\tlearn: 2.7408856\ttotal: 15.7s\tremaining: 41.7s\n",
      "1258:\tlearn: 2.7399496\ttotal: 15.7s\tremaining: 41.7s\n",
      "1259:\tlearn: 2.7391431\ttotal: 15.7s\tremaining: 41.7s\n",
      "1260:\tlearn: 2.7384066\ttotal: 15.8s\tremaining: 41.7s\n",
      "1261:\tlearn: 2.7381446\ttotal: 15.8s\tremaining: 41.7s\n",
      "1262:\tlearn: 2.7374232\ttotal: 15.8s\tremaining: 41.7s\n",
      "1263:\tlearn: 2.7369583\ttotal: 15.8s\tremaining: 41.6s\n",
      "1264:\tlearn: 2.7363969\ttotal: 15.8s\tremaining: 41.6s\n",
      "1265:\tlearn: 2.7357724\ttotal: 15.8s\tremaining: 41.6s\n",
      "1266:\tlearn: 2.7355034\ttotal: 15.8s\tremaining: 41.6s\n",
      "1267:\tlearn: 2.7352199\ttotal: 15.8s\tremaining: 41.6s\n",
      "1268:\tlearn: 2.7343591\ttotal: 15.8s\tremaining: 41.6s\n",
      "1269:\tlearn: 2.7326674\ttotal: 15.9s\tremaining: 41.6s\n",
      "1270:\tlearn: 2.7320768\ttotal: 15.9s\tremaining: 41.5s\n",
      "1271:\tlearn: 2.7316012\ttotal: 15.9s\tremaining: 41.5s\n",
      "1272:\tlearn: 2.7309338\ttotal: 15.9s\tremaining: 41.5s\n",
      "1273:\tlearn: 2.7303084\ttotal: 15.9s\tremaining: 41.5s\n",
      "1274:\tlearn: 2.7294878\ttotal: 15.9s\tremaining: 41.5s\n",
      "1275:\tlearn: 2.7286412\ttotal: 15.9s\tremaining: 41.5s\n",
      "1276:\tlearn: 2.7282618\ttotal: 15.9s\tremaining: 41.5s\n",
      "1277:\tlearn: 2.7275475\ttotal: 16s\tremaining: 41.5s\n",
      "1278:\tlearn: 2.7268889\ttotal: 16s\tremaining: 41.4s\n",
      "1279:\tlearn: 2.7262887\ttotal: 16s\tremaining: 41.4s\n",
      "1280:\tlearn: 2.7257350\ttotal: 16s\tremaining: 41.4s\n",
      "1281:\tlearn: 2.7249479\ttotal: 16s\tremaining: 41.4s\n",
      "1282:\tlearn: 2.7241829\ttotal: 16s\tremaining: 41.4s\n",
      "1283:\tlearn: 2.7231871\ttotal: 16s\tremaining: 41.4s\n",
      "1284:\tlearn: 2.7222817\ttotal: 16s\tremaining: 41.4s\n",
      "1285:\tlearn: 2.7218638\ttotal: 16.1s\tremaining: 41.4s\n",
      "1286:\tlearn: 2.7212817\ttotal: 16.1s\tremaining: 41.3s\n",
      "1287:\tlearn: 2.7205425\ttotal: 16.1s\tremaining: 41.3s\n",
      "1288:\tlearn: 2.7199726\ttotal: 16.1s\tremaining: 41.3s\n",
      "1289:\tlearn: 2.7197390\ttotal: 16.1s\tremaining: 41.3s\n",
      "1290:\tlearn: 2.7192766\ttotal: 16.1s\tremaining: 41.3s\n",
      "1291:\tlearn: 2.7186794\ttotal: 16.1s\tremaining: 41.3s\n",
      "1292:\tlearn: 2.7181903\ttotal: 16.1s\tremaining: 41.3s\n",
      "1293:\tlearn: 2.7172030\ttotal: 16.2s\tremaining: 41.3s\n",
      "1294:\tlearn: 2.7168498\ttotal: 16.2s\tremaining: 41.3s\n",
      "1295:\tlearn: 2.7160231\ttotal: 16.2s\tremaining: 41.2s\n",
      "1296:\tlearn: 2.7154145\ttotal: 16.2s\tremaining: 41.2s\n",
      "1297:\tlearn: 2.7147302\ttotal: 16.2s\tremaining: 41.2s\n",
      "1298:\tlearn: 2.7143139\ttotal: 16.2s\tremaining: 41.2s\n",
      "1299:\tlearn: 2.7136632\ttotal: 16.2s\tremaining: 41.2s\n",
      "1300:\tlearn: 2.7126211\ttotal: 16.2s\tremaining: 41.2s\n",
      "1301:\tlearn: 2.7119538\ttotal: 16.3s\tremaining: 41.2s\n",
      "1302:\tlearn: 2.7110066\ttotal: 16.3s\tremaining: 41.2s\n",
      "1303:\tlearn: 2.7105052\ttotal: 16.3s\tremaining: 41.1s\n",
      "1304:\tlearn: 2.7098085\ttotal: 16.3s\tremaining: 41.1s\n",
      "1305:\tlearn: 2.7092927\ttotal: 16.3s\tremaining: 41.1s\n",
      "1306:\tlearn: 2.7090741\ttotal: 16.3s\tremaining: 41.1s\n",
      "1307:\tlearn: 2.7079114\ttotal: 16.3s\tremaining: 41.1s\n",
      "1308:\tlearn: 2.7075602\ttotal: 16.3s\tremaining: 41.1s\n",
      "1309:\tlearn: 2.7066771\ttotal: 16.4s\tremaining: 41.1s\n",
      "1310:\tlearn: 2.7062193\ttotal: 16.4s\tremaining: 41.1s\n",
      "1311:\tlearn: 2.7053937\ttotal: 16.4s\tremaining: 41s\n",
      "1312:\tlearn: 2.7051560\ttotal: 16.4s\tremaining: 41s\n",
      "1313:\tlearn: 2.7044379\ttotal: 16.4s\tremaining: 41s\n",
      "1314:\tlearn: 2.7041460\ttotal: 16.4s\tremaining: 41s\n",
      "1315:\tlearn: 2.7039217\ttotal: 16.4s\tremaining: 41s\n",
      "1316:\tlearn: 2.7031766\ttotal: 16.4s\tremaining: 41s\n",
      "1317:\tlearn: 2.7028757\ttotal: 16.5s\tremaining: 41s\n",
      "1318:\tlearn: 2.7023059\ttotal: 16.5s\tremaining: 40.9s\n",
      "1319:\tlearn: 2.7021165\ttotal: 16.5s\tremaining: 40.9s\n",
      "1320:\tlearn: 2.7021084\ttotal: 16.5s\tremaining: 40.9s\n",
      "1321:\tlearn: 2.7013962\ttotal: 16.5s\tremaining: 40.9s\n",
      "1322:\tlearn: 2.7010035\ttotal: 16.5s\tremaining: 40.9s\n",
      "1323:\tlearn: 2.7003059\ttotal: 16.5s\tremaining: 40.9s\n",
      "1324:\tlearn: 2.6999718\ttotal: 16.5s\tremaining: 40.9s\n",
      "1325:\tlearn: 2.6993125\ttotal: 16.6s\tremaining: 40.8s\n",
      "1326:\tlearn: 2.6988177\ttotal: 16.6s\tremaining: 40.8s\n",
      "1327:\tlearn: 2.6976969\ttotal: 16.6s\tremaining: 40.8s\n",
      "1328:\tlearn: 2.6971638\ttotal: 16.6s\tremaining: 40.8s\n",
      "1329:\tlearn: 2.6965939\ttotal: 16.6s\tremaining: 40.8s\n",
      "1330:\tlearn: 2.6960786\ttotal: 16.6s\tremaining: 40.8s\n",
      "1331:\tlearn: 2.6955374\ttotal: 16.6s\tremaining: 40.8s\n",
      "1332:\tlearn: 2.6949981\ttotal: 16.6s\tremaining: 40.8s\n",
      "1333:\tlearn: 2.6940791\ttotal: 16.7s\tremaining: 40.7s\n",
      "1334:\tlearn: 2.6933721\ttotal: 16.7s\tremaining: 40.7s\n",
      "1335:\tlearn: 2.6927215\ttotal: 16.7s\tremaining: 40.7s\n",
      "1336:\tlearn: 2.6921016\ttotal: 16.7s\tremaining: 40.7s\n",
      "1337:\tlearn: 2.6915525\ttotal: 16.7s\tremaining: 40.7s\n",
      "1338:\tlearn: 2.6910563\ttotal: 16.7s\tremaining: 40.7s\n",
      "1339:\tlearn: 2.6908096\ttotal: 16.7s\tremaining: 40.7s\n",
      "1340:\tlearn: 2.6901807\ttotal: 16.7s\tremaining: 40.6s\n",
      "1341:\tlearn: 2.6893178\ttotal: 16.8s\tremaining: 40.6s\n",
      "1342:\tlearn: 2.6887278\ttotal: 16.8s\tremaining: 40.6s\n",
      "1343:\tlearn: 2.6878362\ttotal: 16.8s\tremaining: 40.6s\n",
      "1344:\tlearn: 2.6871339\ttotal: 16.8s\tremaining: 40.6s\n",
      "1345:\tlearn: 2.6865760\ttotal: 16.8s\tremaining: 40.6s\n",
      "1346:\tlearn: 2.6861181\ttotal: 16.8s\tremaining: 40.6s\n",
      "1347:\tlearn: 2.6857723\ttotal: 16.8s\tremaining: 40.6s\n",
      "1348:\tlearn: 2.6850797\ttotal: 16.8s\tremaining: 40.6s\n",
      "1349:\tlearn: 2.6846563\ttotal: 16.9s\tremaining: 40.5s\n",
      "1350:\tlearn: 2.6841362\ttotal: 16.9s\tremaining: 40.5s\n",
      "1351:\tlearn: 2.6833514\ttotal: 16.9s\tremaining: 40.5s\n",
      "1352:\tlearn: 2.6827503\ttotal: 16.9s\tremaining: 40.5s\n",
      "1353:\tlearn: 2.6822593\ttotal: 16.9s\tremaining: 40.5s\n",
      "1354:\tlearn: 2.6816564\ttotal: 16.9s\tremaining: 40.5s\n",
      "1355:\tlearn: 2.6811816\ttotal: 16.9s\tremaining: 40.5s\n",
      "1356:\tlearn: 2.6807321\ttotal: 16.9s\tremaining: 40.4s\n",
      "1357:\tlearn: 2.6803971\ttotal: 16.9s\tremaining: 40.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1358:\tlearn: 2.6794237\ttotal: 17s\tremaining: 40.4s\n",
      "1359:\tlearn: 2.6786713\ttotal: 17s\tremaining: 40.4s\n",
      "1360:\tlearn: 2.6784335\ttotal: 17s\tremaining: 40.4s\n",
      "1361:\tlearn: 2.6778753\ttotal: 17s\tremaining: 40.4s\n",
      "1362:\tlearn: 2.6772897\ttotal: 17s\tremaining: 40.4s\n",
      "1363:\tlearn: 2.6764284\ttotal: 17s\tremaining: 40.4s\n",
      "1364:\tlearn: 2.6759179\ttotal: 17s\tremaining: 40.3s\n",
      "1365:\tlearn: 2.6753712\ttotal: 17s\tremaining: 40.3s\n",
      "1366:\tlearn: 2.6746707\ttotal: 17.1s\tremaining: 40.3s\n",
      "1367:\tlearn: 2.6739757\ttotal: 17.1s\tremaining: 40.3s\n",
      "1368:\tlearn: 2.6734224\ttotal: 17.1s\tremaining: 40.3s\n",
      "1369:\tlearn: 2.6729868\ttotal: 17.1s\tremaining: 40.3s\n",
      "1370:\tlearn: 2.6722229\ttotal: 17.1s\tremaining: 40.3s\n",
      "1371:\tlearn: 2.6716738\ttotal: 17.1s\tremaining: 40.3s\n",
      "1372:\tlearn: 2.6713779\ttotal: 17.1s\tremaining: 40.2s\n",
      "1373:\tlearn: 2.6709910\ttotal: 17.1s\tremaining: 40.2s\n",
      "1374:\tlearn: 2.6702236\ttotal: 17.2s\tremaining: 40.2s\n",
      "1375:\tlearn: 2.6695950\ttotal: 17.2s\tremaining: 40.2s\n",
      "1376:\tlearn: 2.6691912\ttotal: 17.2s\tremaining: 40.2s\n",
      "1377:\tlearn: 2.6686577\ttotal: 17.2s\tremaining: 40.2s\n",
      "1378:\tlearn: 2.6678889\ttotal: 17.2s\tremaining: 40.2s\n",
      "1379:\tlearn: 2.6674537\ttotal: 17.2s\tremaining: 40.2s\n",
      "1380:\tlearn: 2.6669993\ttotal: 17.2s\tremaining: 40.1s\n",
      "1381:\tlearn: 2.6664564\ttotal: 17.2s\tremaining: 40.1s\n",
      "1382:\tlearn: 2.6657978\ttotal: 17.3s\tremaining: 40.1s\n",
      "1383:\tlearn: 2.6653765\ttotal: 17.3s\tremaining: 40.1s\n",
      "1384:\tlearn: 2.6648714\ttotal: 17.3s\tremaining: 40.1s\n",
      "1385:\tlearn: 2.6638878\ttotal: 17.3s\tremaining: 40.1s\n",
      "1386:\tlearn: 2.6634417\ttotal: 17.3s\tremaining: 40.1s\n",
      "1387:\tlearn: 2.6630288\ttotal: 17.3s\tremaining: 40s\n",
      "1388:\tlearn: 2.6621475\ttotal: 17.3s\tremaining: 40s\n",
      "1389:\tlearn: 2.6611273\ttotal: 17.3s\tremaining: 40s\n",
      "1390:\tlearn: 2.6606362\ttotal: 17.3s\tremaining: 40s\n",
      "1391:\tlearn: 2.6598631\ttotal: 17.4s\tremaining: 40s\n",
      "1392:\tlearn: 2.6591912\ttotal: 17.4s\tremaining: 40s\n",
      "1393:\tlearn: 2.6588834\ttotal: 17.4s\tremaining: 40s\n",
      "1394:\tlearn: 2.6580063\ttotal: 17.4s\tremaining: 40s\n",
      "1395:\tlearn: 2.6573969\ttotal: 17.4s\tremaining: 39.9s\n",
      "1396:\tlearn: 2.6571967\ttotal: 17.4s\tremaining: 39.9s\n",
      "1397:\tlearn: 2.6568441\ttotal: 17.4s\tremaining: 39.9s\n",
      "1398:\tlearn: 2.6559082\ttotal: 17.4s\tremaining: 39.9s\n",
      "1399:\tlearn: 2.6552118\ttotal: 17.5s\tremaining: 39.9s\n",
      "1400:\tlearn: 2.6545487\ttotal: 17.5s\tremaining: 39.9s\n",
      "1401:\tlearn: 2.6539866\ttotal: 17.5s\tremaining: 39.9s\n",
      "1402:\tlearn: 2.6535006\ttotal: 17.5s\tremaining: 39.9s\n",
      "1403:\tlearn: 2.6532036\ttotal: 17.5s\tremaining: 39.8s\n",
      "1404:\tlearn: 2.6526366\ttotal: 17.5s\tremaining: 39.8s\n",
      "1405:\tlearn: 2.6521076\ttotal: 17.5s\tremaining: 39.8s\n",
      "1406:\tlearn: 2.6515886\ttotal: 17.5s\tremaining: 39.8s\n",
      "1407:\tlearn: 2.6511195\ttotal: 17.6s\tremaining: 39.8s\n",
      "1408:\tlearn: 2.6504624\ttotal: 17.6s\tremaining: 39.8s\n",
      "1409:\tlearn: 2.6495337\ttotal: 17.6s\tremaining: 39.8s\n",
      "1410:\tlearn: 2.6485879\ttotal: 17.6s\tremaining: 39.8s\n",
      "1411:\tlearn: 2.6479686\ttotal: 17.6s\tremaining: 39.7s\n",
      "1412:\tlearn: 2.6474127\ttotal: 17.6s\tremaining: 39.7s\n",
      "1413:\tlearn: 2.6468554\ttotal: 17.6s\tremaining: 39.7s\n",
      "1414:\tlearn: 2.6463894\ttotal: 17.6s\tremaining: 39.7s\n",
      "1415:\tlearn: 2.6458129\ttotal: 17.7s\tremaining: 39.7s\n",
      "1416:\tlearn: 2.6447412\ttotal: 17.7s\tremaining: 39.7s\n",
      "1417:\tlearn: 2.6439166\ttotal: 17.7s\tremaining: 39.7s\n",
      "1418:\tlearn: 2.6431139\ttotal: 17.7s\tremaining: 39.6s\n",
      "1419:\tlearn: 2.6427662\ttotal: 17.7s\tremaining: 39.6s\n",
      "1420:\tlearn: 2.6422816\ttotal: 17.7s\tremaining: 39.6s\n",
      "1421:\tlearn: 2.6410360\ttotal: 17.7s\tremaining: 39.6s\n",
      "1422:\tlearn: 2.6403902\ttotal: 17.7s\tremaining: 39.6s\n",
      "1423:\tlearn: 2.6400633\ttotal: 17.8s\tremaining: 39.6s\n",
      "1424:\tlearn: 2.6395400\ttotal: 17.8s\tremaining: 39.6s\n",
      "1425:\tlearn: 2.6391527\ttotal: 17.8s\tremaining: 39.5s\n",
      "1426:\tlearn: 2.6384876\ttotal: 17.8s\tremaining: 39.5s\n",
      "1427:\tlearn: 2.6379928\ttotal: 17.8s\tremaining: 39.5s\n",
      "1428:\tlearn: 2.6376448\ttotal: 17.8s\tremaining: 39.5s\n",
      "1429:\tlearn: 2.6368592\ttotal: 17.8s\tremaining: 39.5s\n",
      "1430:\tlearn: 2.6365516\ttotal: 17.8s\tremaining: 39.5s\n",
      "1431:\tlearn: 2.6361483\ttotal: 17.9s\tremaining: 39.5s\n",
      "1432:\tlearn: 2.6355764\ttotal: 17.9s\tremaining: 39.5s\n",
      "1433:\tlearn: 2.6347367\ttotal: 17.9s\tremaining: 39.5s\n",
      "1434:\tlearn: 2.6342366\ttotal: 17.9s\tremaining: 39.4s\n",
      "1435:\tlearn: 2.6341095\ttotal: 17.9s\tremaining: 39.4s\n",
      "1436:\tlearn: 2.6333041\ttotal: 17.9s\tremaining: 39.4s\n",
      "1437:\tlearn: 2.6326200\ttotal: 17.9s\tremaining: 39.4s\n",
      "1438:\tlearn: 2.6318737\ttotal: 17.9s\tremaining: 39.4s\n",
      "1439:\tlearn: 2.6314690\ttotal: 18s\tremaining: 39.4s\n",
      "1440:\tlearn: 2.6309506\ttotal: 18s\tremaining: 39.4s\n",
      "1441:\tlearn: 2.6302646\ttotal: 18s\tremaining: 39.3s\n",
      "1442:\tlearn: 2.6294146\ttotal: 18s\tremaining: 39.3s\n",
      "1443:\tlearn: 2.6291060\ttotal: 18s\tremaining: 39.3s\n",
      "1444:\tlearn: 2.6286072\ttotal: 18s\tremaining: 39.3s\n",
      "1445:\tlearn: 2.6282443\ttotal: 18s\tremaining: 39.3s\n",
      "1446:\tlearn: 2.6278106\ttotal: 18s\tremaining: 39.3s\n",
      "1447:\tlearn: 2.6269147\ttotal: 18.1s\tremaining: 39.3s\n",
      "1448:\tlearn: 2.6263729\ttotal: 18.1s\tremaining: 39.3s\n",
      "1449:\tlearn: 2.6261707\ttotal: 18.1s\tremaining: 39.2s\n",
      "1450:\tlearn: 2.6256149\ttotal: 18.1s\tremaining: 39.2s\n",
      "1451:\tlearn: 2.6248777\ttotal: 18.1s\tremaining: 39.2s\n",
      "1452:\tlearn: 2.6241462\ttotal: 18.1s\tremaining: 39.2s\n",
      "1453:\tlearn: 2.6233036\ttotal: 18.1s\tremaining: 39.2s\n",
      "1454:\tlearn: 2.6227291\ttotal: 18.1s\tremaining: 39.2s\n",
      "1455:\tlearn: 2.6220779\ttotal: 18.1s\tremaining: 39.2s\n",
      "1456:\tlearn: 2.6213607\ttotal: 18.2s\tremaining: 39.2s\n",
      "1457:\tlearn: 2.6206046\ttotal: 18.2s\tremaining: 39.1s\n",
      "1458:\tlearn: 2.6203372\ttotal: 18.2s\tremaining: 39.1s\n",
      "1459:\tlearn: 2.6196460\ttotal: 18.2s\tremaining: 39.1s\n",
      "1460:\tlearn: 2.6191222\ttotal: 18.2s\tremaining: 39.1s\n",
      "1461:\tlearn: 2.6186691\ttotal: 18.2s\tremaining: 39.1s\n",
      "1462:\tlearn: 2.6183057\ttotal: 18.2s\tremaining: 39.1s\n",
      "1463:\tlearn: 2.6176183\ttotal: 18.2s\tremaining: 39.1s\n",
      "1464:\tlearn: 2.6173300\ttotal: 18.3s\tremaining: 39.1s\n",
      "1465:\tlearn: 2.6166850\ttotal: 18.3s\tremaining: 39s\n",
      "1466:\tlearn: 2.6160498\ttotal: 18.3s\tremaining: 39s\n",
      "1467:\tlearn: 2.6156907\ttotal: 18.3s\tremaining: 39s\n",
      "1468:\tlearn: 2.6154269\ttotal: 18.3s\tremaining: 39s\n",
      "1469:\tlearn: 2.6149817\ttotal: 18.3s\tremaining: 39s\n",
      "1470:\tlearn: 2.6144481\ttotal: 18.3s\tremaining: 39s\n",
      "1471:\tlearn: 2.6138590\ttotal: 18.3s\tremaining: 39s\n",
      "1472:\tlearn: 2.6134002\ttotal: 18.4s\tremaining: 38.9s\n",
      "1473:\tlearn: 2.6130161\ttotal: 18.4s\tremaining: 38.9s\n",
      "1474:\tlearn: 2.6126771\ttotal: 18.4s\tremaining: 38.9s\n",
      "1475:\tlearn: 2.6122239\ttotal: 18.4s\tremaining: 38.9s\n",
      "1476:\tlearn: 2.6114582\ttotal: 18.4s\tremaining: 38.9s\n",
      "1477:\tlearn: 2.6109957\ttotal: 18.4s\tremaining: 38.9s\n",
      "1478:\tlearn: 2.6105842\ttotal: 18.4s\tremaining: 38.9s\n",
      "1479:\tlearn: 2.6100672\ttotal: 18.4s\tremaining: 38.9s\n",
      "1480:\tlearn: 2.6099217\ttotal: 18.5s\tremaining: 38.8s\n",
      "1481:\tlearn: 2.6091037\ttotal: 18.5s\tremaining: 38.8s\n",
      "1482:\tlearn: 2.6082709\ttotal: 18.5s\tremaining: 38.8s\n",
      "1483:\tlearn: 2.6076712\ttotal: 18.5s\tremaining: 38.8s\n",
      "1484:\tlearn: 2.6071712\ttotal: 18.5s\tremaining: 38.8s\n",
      "1485:\tlearn: 2.6067935\ttotal: 18.5s\tremaining: 38.8s\n",
      "1486:\tlearn: 2.6061315\ttotal: 18.5s\tremaining: 38.8s\n",
      "1487:\tlearn: 2.6046816\ttotal: 18.5s\tremaining: 38.8s\n",
      "1488:\tlearn: 2.6038687\ttotal: 18.6s\tremaining: 38.7s\n",
      "1489:\tlearn: 2.6031341\ttotal: 18.6s\tremaining: 38.7s\n",
      "1490:\tlearn: 2.6026617\ttotal: 18.6s\tremaining: 38.7s\n",
      "1491:\tlearn: 2.6021361\ttotal: 18.6s\tremaining: 38.7s\n",
      "1492:\tlearn: 2.6015791\ttotal: 18.6s\tremaining: 38.7s\n",
      "1493:\tlearn: 2.6011168\ttotal: 18.6s\tremaining: 38.7s\n",
      "1494:\tlearn: 2.6008559\ttotal: 18.6s\tremaining: 38.7s\n",
      "1495:\tlearn: 2.6000663\ttotal: 18.6s\tremaining: 38.7s\n",
      "1496:\tlearn: 2.5993230\ttotal: 18.7s\tremaining: 38.6s\n",
      "1497:\tlearn: 2.5990987\ttotal: 18.7s\tremaining: 38.6s\n",
      "1498:\tlearn: 2.5981676\ttotal: 18.7s\tremaining: 38.6s\n",
      "1499:\tlearn: 2.5972288\ttotal: 18.7s\tremaining: 38.6s\n",
      "1500:\tlearn: 2.5969999\ttotal: 18.7s\tremaining: 38.6s\n",
      "1501:\tlearn: 2.5966651\ttotal: 18.7s\tremaining: 38.6s\n",
      "1502:\tlearn: 2.5963397\ttotal: 18.7s\tremaining: 38.6s\n",
      "1503:\tlearn: 2.5960151\ttotal: 18.7s\tremaining: 38.5s\n",
      "1504:\tlearn: 2.5955497\ttotal: 18.8s\tremaining: 38.5s\n",
      "1505:\tlearn: 2.5945043\ttotal: 18.8s\tremaining: 38.5s\n",
      "1506:\tlearn: 2.5942145\ttotal: 18.8s\tremaining: 38.5s\n",
      "1507:\tlearn: 2.5935154\ttotal: 18.8s\tremaining: 38.5s\n",
      "1508:\tlearn: 2.5930523\ttotal: 18.8s\tremaining: 38.5s\n",
      "1509:\tlearn: 2.5924792\ttotal: 18.8s\tremaining: 38.5s\n",
      "1510:\tlearn: 2.5920324\ttotal: 18.8s\tremaining: 38.5s\n",
      "1511:\tlearn: 2.5919237\ttotal: 18.8s\tremaining: 38.4s\n",
      "1512:\tlearn: 2.5914392\ttotal: 18.8s\tremaining: 38.4s\n",
      "1513:\tlearn: 2.5907649\ttotal: 18.9s\tremaining: 38.4s\n",
      "1514:\tlearn: 2.5900447\ttotal: 18.9s\tremaining: 38.4s\n",
      "1515:\tlearn: 2.5893270\ttotal: 18.9s\tremaining: 38.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1516:\tlearn: 2.5886936\ttotal: 18.9s\tremaining: 38.4s\n",
      "1517:\tlearn: 2.5877446\ttotal: 18.9s\tremaining: 38.4s\n",
      "1518:\tlearn: 2.5873724\ttotal: 18.9s\tremaining: 38.4s\n",
      "1519:\tlearn: 2.5869051\ttotal: 18.9s\tremaining: 38.3s\n",
      "1520:\tlearn: 2.5864947\ttotal: 18.9s\tremaining: 38.3s\n",
      "1521:\tlearn: 2.5859491\ttotal: 19s\tremaining: 38.3s\n",
      "1522:\tlearn: 2.5855816\ttotal: 19s\tremaining: 38.3s\n",
      "1523:\tlearn: 2.5850211\ttotal: 19s\tremaining: 38.3s\n",
      "1524:\tlearn: 2.5843496\ttotal: 19s\tremaining: 38.3s\n",
      "1525:\tlearn: 2.5838916\ttotal: 19s\tremaining: 38.3s\n",
      "1526:\tlearn: 2.5833683\ttotal: 19s\tremaining: 38.3s\n",
      "1527:\tlearn: 2.5830390\ttotal: 19s\tremaining: 38.2s\n",
      "1528:\tlearn: 2.5825302\ttotal: 19s\tremaining: 38.2s\n",
      "1529:\tlearn: 2.5821104\ttotal: 19.1s\tremaining: 38.2s\n",
      "1530:\tlearn: 2.5814030\ttotal: 19.1s\tremaining: 38.2s\n",
      "1531:\tlearn: 2.5809345\ttotal: 19.1s\tremaining: 38.2s\n",
      "1532:\tlearn: 2.5804784\ttotal: 19.1s\tremaining: 38.2s\n",
      "1533:\tlearn: 2.5801898\ttotal: 19.1s\tremaining: 38.2s\n",
      "1534:\tlearn: 2.5794463\ttotal: 19.1s\tremaining: 38.2s\n",
      "1535:\tlearn: 2.5783944\ttotal: 19.1s\tremaining: 38.1s\n",
      "1536:\tlearn: 2.5781636\ttotal: 19.1s\tremaining: 38.1s\n",
      "1537:\tlearn: 2.5778118\ttotal: 19.2s\tremaining: 38.1s\n",
      "1538:\tlearn: 2.5774755\ttotal: 19.2s\tremaining: 38.1s\n",
      "1539:\tlearn: 2.5771440\ttotal: 19.2s\tremaining: 38.1s\n",
      "1540:\tlearn: 2.5768114\ttotal: 19.2s\tremaining: 38.1s\n",
      "1541:\tlearn: 2.5761167\ttotal: 19.2s\tremaining: 38.1s\n",
      "1542:\tlearn: 2.5756149\ttotal: 19.2s\tremaining: 38s\n",
      "1543:\tlearn: 2.5751775\ttotal: 19.2s\tremaining: 38s\n",
      "1544:\tlearn: 2.5746165\ttotal: 19.2s\tremaining: 38s\n",
      "1545:\tlearn: 2.5742231\ttotal: 19.3s\tremaining: 38s\n",
      "1546:\tlearn: 2.5737079\ttotal: 19.3s\tremaining: 38s\n",
      "1547:\tlearn: 2.5734680\ttotal: 19.3s\tremaining: 38s\n",
      "1548:\tlearn: 2.5730832\ttotal: 19.3s\tremaining: 38s\n",
      "1549:\tlearn: 2.5726718\ttotal: 19.3s\tremaining: 38s\n",
      "1550:\tlearn: 2.5720027\ttotal: 19.3s\tremaining: 37.9s\n",
      "1551:\tlearn: 2.5716606\ttotal: 19.3s\tremaining: 37.9s\n",
      "1552:\tlearn: 2.5710654\ttotal: 19.3s\tremaining: 37.9s\n",
      "1553:\tlearn: 2.5703587\ttotal: 19.4s\tremaining: 37.9s\n",
      "1554:\tlearn: 2.5700238\ttotal: 19.4s\tremaining: 37.9s\n",
      "1555:\tlearn: 2.5693001\ttotal: 19.4s\tremaining: 37.9s\n",
      "1556:\tlearn: 2.5687619\ttotal: 19.4s\tremaining: 37.9s\n",
      "1557:\tlearn: 2.5681346\ttotal: 19.4s\tremaining: 37.9s\n",
      "1558:\tlearn: 2.5673641\ttotal: 19.4s\tremaining: 37.8s\n",
      "1559:\tlearn: 2.5667578\ttotal: 19.4s\tremaining: 37.8s\n",
      "1560:\tlearn: 2.5664356\ttotal: 19.4s\tremaining: 37.8s\n",
      "1561:\tlearn: 2.5659874\ttotal: 19.5s\tremaining: 37.8s\n",
      "1562:\tlearn: 2.5652922\ttotal: 19.5s\tremaining: 37.8s\n",
      "1563:\tlearn: 2.5648512\ttotal: 19.5s\tremaining: 37.8s\n",
      "1564:\tlearn: 2.5641311\ttotal: 19.5s\tremaining: 37.8s\n",
      "1565:\tlearn: 2.5637069\ttotal: 19.5s\tremaining: 37.8s\n",
      "1566:\tlearn: 2.5632165\ttotal: 19.5s\tremaining: 37.7s\n",
      "1567:\tlearn: 2.5628285\ttotal: 19.5s\tremaining: 37.7s\n",
      "1568:\tlearn: 2.5621566\ttotal: 19.5s\tremaining: 37.7s\n",
      "1569:\tlearn: 2.5610371\ttotal: 19.5s\tremaining: 37.7s\n",
      "1570:\tlearn: 2.5604686\ttotal: 19.6s\tremaining: 37.7s\n",
      "1571:\tlearn: 2.5598255\ttotal: 19.6s\tremaining: 37.7s\n",
      "1572:\tlearn: 2.5594886\ttotal: 19.6s\tremaining: 37.7s\n",
      "1573:\tlearn: 2.5589411\ttotal: 19.6s\tremaining: 37.7s\n",
      "1574:\tlearn: 2.5587539\ttotal: 19.6s\tremaining: 37.6s\n",
      "1575:\tlearn: 2.5583161\ttotal: 19.6s\tremaining: 37.6s\n",
      "1576:\tlearn: 2.5572170\ttotal: 19.6s\tremaining: 37.6s\n",
      "1577:\tlearn: 2.5565256\ttotal: 19.6s\tremaining: 37.6s\n",
      "1578:\tlearn: 2.5559377\ttotal: 19.7s\tremaining: 37.6s\n",
      "1579:\tlearn: 2.5554052\ttotal: 19.7s\tremaining: 37.6s\n",
      "1580:\tlearn: 2.5548902\ttotal: 19.7s\tremaining: 37.6s\n",
      "1581:\tlearn: 2.5540932\ttotal: 19.7s\tremaining: 37.5s\n",
      "1582:\tlearn: 2.5534771\ttotal: 19.7s\tremaining: 37.5s\n",
      "1583:\tlearn: 2.5529888\ttotal: 19.7s\tremaining: 37.5s\n",
      "1584:\tlearn: 2.5526771\ttotal: 19.7s\tremaining: 37.5s\n",
      "1585:\tlearn: 2.5521964\ttotal: 19.7s\tremaining: 37.5s\n",
      "1586:\tlearn: 2.5519043\ttotal: 19.8s\tremaining: 37.5s\n",
      "1587:\tlearn: 2.5514611\ttotal: 19.8s\tremaining: 37.5s\n",
      "1588:\tlearn: 2.5511454\ttotal: 19.8s\tremaining: 37.5s\n",
      "1589:\tlearn: 2.5507429\ttotal: 19.8s\tremaining: 37.4s\n",
      "1590:\tlearn: 2.5500639\ttotal: 19.8s\tremaining: 37.4s\n",
      "1591:\tlearn: 2.5498479\ttotal: 19.8s\tremaining: 37.4s\n",
      "1592:\tlearn: 2.5492870\ttotal: 19.8s\tremaining: 37.4s\n",
      "1593:\tlearn: 2.5489969\ttotal: 19.8s\tremaining: 37.4s\n",
      "1594:\tlearn: 2.5482795\ttotal: 19.9s\tremaining: 37.4s\n",
      "1595:\tlearn: 2.5475061\ttotal: 19.9s\tremaining: 37.4s\n",
      "1596:\tlearn: 2.5470324\ttotal: 19.9s\tremaining: 37.4s\n",
      "1597:\tlearn: 2.5462950\ttotal: 19.9s\tremaining: 37.3s\n",
      "1598:\tlearn: 2.5459570\ttotal: 19.9s\tremaining: 37.3s\n",
      "1599:\tlearn: 2.5457601\ttotal: 19.9s\tremaining: 37.3s\n",
      "1600:\tlearn: 2.5450669\ttotal: 19.9s\tremaining: 37.3s\n",
      "1601:\tlearn: 2.5447213\ttotal: 19.9s\tremaining: 37.3s\n",
      "1602:\tlearn: 2.5438160\ttotal: 20s\tremaining: 37.3s\n",
      "1603:\tlearn: 2.5433251\ttotal: 20s\tremaining: 37.3s\n",
      "1604:\tlearn: 2.5425032\ttotal: 20s\tremaining: 37.3s\n",
      "1605:\tlearn: 2.5420759\ttotal: 20s\tremaining: 37.2s\n",
      "1606:\tlearn: 2.5413132\ttotal: 20s\tremaining: 37.2s\n",
      "1607:\tlearn: 2.5404340\ttotal: 20s\tremaining: 37.2s\n",
      "1608:\tlearn: 2.5396514\ttotal: 20s\tremaining: 37.2s\n",
      "1609:\tlearn: 2.5393522\ttotal: 20s\tremaining: 37.2s\n",
      "1610:\tlearn: 2.5389181\ttotal: 20.1s\tremaining: 37.2s\n",
      "1611:\tlearn: 2.5382832\ttotal: 20.1s\tremaining: 37.2s\n",
      "1612:\tlearn: 2.5381047\ttotal: 20.1s\tremaining: 37.2s\n",
      "1613:\tlearn: 2.5375504\ttotal: 20.1s\tremaining: 37.1s\n",
      "1614:\tlearn: 2.5373344\ttotal: 20.1s\tremaining: 37.1s\n",
      "1615:\tlearn: 2.5370240\ttotal: 20.1s\tremaining: 37.1s\n",
      "1616:\tlearn: 2.5364671\ttotal: 20.1s\tremaining: 37.1s\n",
      "1617:\tlearn: 2.5357171\ttotal: 20.1s\tremaining: 37.1s\n",
      "1618:\tlearn: 2.5350344\ttotal: 20.1s\tremaining: 37.1s\n",
      "1619:\tlearn: 2.5346515\ttotal: 20.2s\tremaining: 37.1s\n",
      "1620:\tlearn: 2.5342347\ttotal: 20.2s\tremaining: 37s\n",
      "1621:\tlearn: 2.5337967\ttotal: 20.2s\tremaining: 37s\n",
      "1622:\tlearn: 2.5335880\ttotal: 20.2s\tremaining: 37s\n",
      "1623:\tlearn: 2.5332176\ttotal: 20.2s\tremaining: 37s\n",
      "1624:\tlearn: 2.5322738\ttotal: 20.2s\tremaining: 37s\n",
      "1625:\tlearn: 2.5312764\ttotal: 20.2s\tremaining: 37s\n",
      "1626:\tlearn: 2.5310298\ttotal: 20.2s\tremaining: 37s\n",
      "1627:\tlearn: 2.5305123\ttotal: 20.3s\tremaining: 37s\n",
      "1628:\tlearn: 2.5299417\ttotal: 20.3s\tremaining: 36.9s\n",
      "1629:\tlearn: 2.5295785\ttotal: 20.3s\tremaining: 36.9s\n",
      "1630:\tlearn: 2.5286155\ttotal: 20.3s\tremaining: 36.9s\n",
      "1631:\tlearn: 2.5283517\ttotal: 20.3s\tremaining: 36.9s\n",
      "1632:\tlearn: 2.5279988\ttotal: 20.3s\tremaining: 36.9s\n",
      "1633:\tlearn: 2.5276165\ttotal: 20.3s\tremaining: 36.9s\n",
      "1634:\tlearn: 2.5271890\ttotal: 20.3s\tremaining: 36.9s\n",
      "1635:\tlearn: 2.5267129\ttotal: 20.4s\tremaining: 36.9s\n",
      "1636:\tlearn: 2.5262075\ttotal: 20.4s\tremaining: 36.8s\n",
      "1637:\tlearn: 2.5257670\ttotal: 20.4s\tremaining: 36.8s\n",
      "1638:\tlearn: 2.5249176\ttotal: 20.4s\tremaining: 36.8s\n",
      "1639:\tlearn: 2.5246684\ttotal: 20.4s\tremaining: 36.8s\n",
      "1640:\tlearn: 2.5243782\ttotal: 20.4s\tremaining: 36.8s\n",
      "1641:\tlearn: 2.5241718\ttotal: 20.4s\tremaining: 36.8s\n",
      "1642:\tlearn: 2.5237412\ttotal: 20.4s\tremaining: 36.8s\n",
      "1643:\tlearn: 2.5233342\ttotal: 20.5s\tremaining: 36.8s\n",
      "1644:\tlearn: 2.5229428\ttotal: 20.5s\tremaining: 36.8s\n",
      "1645:\tlearn: 2.5225848\ttotal: 20.5s\tremaining: 36.8s\n",
      "1646:\tlearn: 2.5219825\ttotal: 20.5s\tremaining: 36.7s\n",
      "1647:\tlearn: 2.5216282\ttotal: 20.5s\tremaining: 36.7s\n",
      "1648:\tlearn: 2.5211904\ttotal: 20.5s\tremaining: 36.7s\n",
      "1649:\tlearn: 2.5206143\ttotal: 20.5s\tremaining: 36.7s\n",
      "1650:\tlearn: 2.5201983\ttotal: 20.6s\tremaining: 36.7s\n",
      "1651:\tlearn: 2.5197449\ttotal: 20.6s\tremaining: 36.7s\n",
      "1652:\tlearn: 2.5185328\ttotal: 20.6s\tremaining: 36.7s\n",
      "1653:\tlearn: 2.5177902\ttotal: 20.6s\tremaining: 36.7s\n",
      "1654:\tlearn: 2.5174001\ttotal: 20.6s\tremaining: 36.6s\n",
      "1655:\tlearn: 2.5171750\ttotal: 20.6s\tremaining: 36.6s\n",
      "1656:\tlearn: 2.5166640\ttotal: 20.6s\tremaining: 36.6s\n",
      "1657:\tlearn: 2.5159623\ttotal: 20.6s\tremaining: 36.6s\n",
      "1658:\tlearn: 2.5154052\ttotal: 20.7s\tremaining: 36.6s\n",
      "1659:\tlearn: 2.5152349\ttotal: 20.7s\tremaining: 36.6s\n",
      "1660:\tlearn: 2.5144772\ttotal: 20.7s\tremaining: 36.6s\n",
      "1661:\tlearn: 2.5136852\ttotal: 20.7s\tremaining: 36.6s\n",
      "1662:\tlearn: 2.5133774\ttotal: 20.7s\tremaining: 36.5s\n",
      "1663:\tlearn: 2.5131475\ttotal: 20.7s\tremaining: 36.5s\n",
      "1664:\tlearn: 2.5127437\ttotal: 20.7s\tremaining: 36.5s\n",
      "1665:\tlearn: 2.5123892\ttotal: 20.7s\tremaining: 36.5s\n",
      "1666:\tlearn: 2.5119006\ttotal: 20.8s\tremaining: 36.5s\n",
      "1667:\tlearn: 2.5114380\ttotal: 20.8s\tremaining: 36.5s\n",
      "1668:\tlearn: 2.5110182\ttotal: 20.8s\tremaining: 36.5s\n",
      "1669:\tlearn: 2.5107891\ttotal: 20.8s\tremaining: 36.4s\n",
      "1670:\tlearn: 2.5102387\ttotal: 20.8s\tremaining: 36.4s\n",
      "1671:\tlearn: 2.5098700\ttotal: 20.8s\tremaining: 36.4s\n",
      "1672:\tlearn: 2.5094160\ttotal: 20.8s\tremaining: 36.4s\n",
      "1673:\tlearn: 2.5085948\ttotal: 20.8s\tremaining: 36.4s\n",
      "1674:\tlearn: 2.5076860\ttotal: 20.9s\tremaining: 36.4s\n",
      "1675:\tlearn: 2.5070504\ttotal: 20.9s\tremaining: 36.4s\n",
      "1676:\tlearn: 2.5065797\ttotal: 20.9s\tremaining: 36.4s\n",
      "1677:\tlearn: 2.5061866\ttotal: 20.9s\tremaining: 36.3s\n",
      "1678:\tlearn: 2.5055580\ttotal: 20.9s\tremaining: 36.3s\n",
      "1679:\tlearn: 2.5051097\ttotal: 20.9s\tremaining: 36.3s\n",
      "1680:\tlearn: 2.5046987\ttotal: 20.9s\tremaining: 36.3s\n",
      "1681:\tlearn: 2.5041865\ttotal: 20.9s\tremaining: 36.3s\n",
      "1682:\tlearn: 2.5040008\ttotal: 20.9s\tremaining: 36.3s\n",
      "1683:\tlearn: 2.5028615\ttotal: 21s\tremaining: 36.3s\n",
      "1684:\tlearn: 2.5025486\ttotal: 21s\tremaining: 36.3s\n",
      "1685:\tlearn: 2.5020015\ttotal: 21s\tremaining: 36.2s\n",
      "1686:\tlearn: 2.5018430\ttotal: 21s\tremaining: 36.2s\n",
      "1687:\tlearn: 2.5015293\ttotal: 21s\tremaining: 36.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688:\tlearn: 2.5011410\ttotal: 21s\tremaining: 36.2s\n",
      "1689:\tlearn: 2.5008959\ttotal: 21s\tremaining: 36.2s\n",
      "1690:\tlearn: 2.5004762\ttotal: 21s\tremaining: 36.2s\n",
      "1691:\tlearn: 2.5000817\ttotal: 21.1s\tremaining: 36.2s\n",
      "1692:\tlearn: 2.4994007\ttotal: 21.1s\tremaining: 36.2s\n",
      "1693:\tlearn: 2.4989061\ttotal: 21.1s\tremaining: 36.1s\n",
      "1694:\tlearn: 2.4985438\ttotal: 21.1s\tremaining: 36.1s\n",
      "1695:\tlearn: 2.4982691\ttotal: 21.1s\tremaining: 36.1s\n",
      "1696:\tlearn: 2.4979825\ttotal: 21.1s\tremaining: 36.1s\n",
      "1697:\tlearn: 2.4976559\ttotal: 21.1s\tremaining: 36.1s\n",
      "1698:\tlearn: 2.4971320\ttotal: 21.1s\tremaining: 36.1s\n",
      "1699:\tlearn: 2.4962203\ttotal: 21.2s\tremaining: 36.1s\n",
      "1700:\tlearn: 2.4958098\ttotal: 21.2s\tremaining: 36s\n",
      "1701:\tlearn: 2.4953655\ttotal: 21.2s\tremaining: 36s\n",
      "1702:\tlearn: 2.4950152\ttotal: 21.2s\tremaining: 36s\n",
      "1703:\tlearn: 2.4945822\ttotal: 21.2s\tremaining: 36s\n",
      "1704:\tlearn: 2.4940329\ttotal: 21.2s\tremaining: 36s\n",
      "1705:\tlearn: 2.4934413\ttotal: 21.2s\tremaining: 36s\n",
      "1706:\tlearn: 2.4933345\ttotal: 21.2s\tremaining: 36s\n",
      "1707:\tlearn: 2.4926884\ttotal: 21.3s\tremaining: 36s\n",
      "1708:\tlearn: 2.4923205\ttotal: 21.3s\tremaining: 35.9s\n",
      "1709:\tlearn: 2.4917061\ttotal: 21.3s\tremaining: 35.9s\n",
      "1710:\tlearn: 2.4914010\ttotal: 21.3s\tremaining: 35.9s\n",
      "1711:\tlearn: 2.4910904\ttotal: 21.3s\tremaining: 35.9s\n",
      "1712:\tlearn: 2.4900929\ttotal: 21.3s\tremaining: 35.9s\n",
      "1713:\tlearn: 2.4896124\ttotal: 21.3s\tremaining: 35.9s\n",
      "1714:\tlearn: 2.4890944\ttotal: 21.3s\tremaining: 35.9s\n",
      "1715:\tlearn: 2.4884419\ttotal: 21.4s\tremaining: 35.9s\n",
      "1716:\tlearn: 2.4879846\ttotal: 21.4s\tremaining: 35.8s\n",
      "1717:\tlearn: 2.4866208\ttotal: 21.4s\tremaining: 35.8s\n",
      "1718:\tlearn: 2.4862085\ttotal: 21.4s\tremaining: 35.8s\n",
      "1719:\tlearn: 2.4858875\ttotal: 21.4s\tremaining: 35.8s\n",
      "1720:\tlearn: 2.4852143\ttotal: 21.4s\tremaining: 35.8s\n",
      "1721:\tlearn: 2.4848559\ttotal: 21.4s\tremaining: 35.8s\n",
      "1722:\tlearn: 2.4844451\ttotal: 21.4s\tremaining: 35.8s\n",
      "1723:\tlearn: 2.4841935\ttotal: 21.4s\tremaining: 35.8s\n",
      "1724:\tlearn: 2.4835264\ttotal: 21.5s\tremaining: 35.7s\n",
      "1725:\tlearn: 2.4830355\ttotal: 21.5s\tremaining: 35.7s\n",
      "1726:\tlearn: 2.4827382\ttotal: 21.5s\tremaining: 35.7s\n",
      "1727:\tlearn: 2.4824256\ttotal: 21.5s\tremaining: 35.7s\n",
      "1728:\tlearn: 2.4820662\ttotal: 21.5s\tremaining: 35.7s\n",
      "1729:\tlearn: 2.4817756\ttotal: 21.5s\tremaining: 35.7s\n",
      "1730:\tlearn: 2.4812315\ttotal: 21.5s\tremaining: 35.7s\n",
      "1731:\tlearn: 2.4806089\ttotal: 21.5s\tremaining: 35.6s\n",
      "1732:\tlearn: 2.4801991\ttotal: 21.6s\tremaining: 35.6s\n",
      "1733:\tlearn: 2.4794594\ttotal: 21.6s\tremaining: 35.6s\n",
      "1734:\tlearn: 2.4790877\ttotal: 21.6s\tremaining: 35.6s\n",
      "1735:\tlearn: 2.4784767\ttotal: 21.6s\tremaining: 35.6s\n",
      "1736:\tlearn: 2.4780483\ttotal: 21.6s\tremaining: 35.6s\n",
      "1737:\tlearn: 2.4777387\ttotal: 21.6s\tremaining: 35.6s\n",
      "1738:\tlearn: 2.4773950\ttotal: 21.6s\tremaining: 35.6s\n",
      "1739:\tlearn: 2.4769318\ttotal: 21.6s\tremaining: 35.5s\n",
      "1740:\tlearn: 2.4764936\ttotal: 21.6s\tremaining: 35.5s\n",
      "1741:\tlearn: 2.4761558\ttotal: 21.7s\tremaining: 35.5s\n",
      "1742:\tlearn: 2.4757215\ttotal: 21.7s\tremaining: 35.5s\n",
      "1743:\tlearn: 2.4750824\ttotal: 21.7s\tremaining: 35.5s\n",
      "1744:\tlearn: 2.4742806\ttotal: 21.7s\tremaining: 35.5s\n",
      "1745:\tlearn: 2.4737850\ttotal: 21.7s\tremaining: 35.5s\n",
      "1746:\tlearn: 2.4734842\ttotal: 21.7s\tremaining: 35.5s\n",
      "1747:\tlearn: 2.4730117\ttotal: 21.7s\tremaining: 35.4s\n",
      "1748:\tlearn: 2.4726068\ttotal: 21.8s\tremaining: 35.4s\n",
      "1749:\tlearn: 2.4720147\ttotal: 21.8s\tremaining: 35.4s\n",
      "1750:\tlearn: 2.4714207\ttotal: 21.8s\tremaining: 35.4s\n",
      "1751:\tlearn: 2.4710499\ttotal: 21.8s\tremaining: 35.4s\n",
      "1752:\tlearn: 2.4707629\ttotal: 21.8s\tremaining: 35.4s\n",
      "1753:\tlearn: 2.4704518\ttotal: 21.8s\tremaining: 35.4s\n",
      "1754:\tlearn: 2.4691353\ttotal: 21.8s\tremaining: 35.3s\n",
      "1755:\tlearn: 2.4688183\ttotal: 21.8s\tremaining: 35.3s\n",
      "1756:\tlearn: 2.4681410\ttotal: 21.8s\tremaining: 35.3s\n",
      "1757:\tlearn: 2.4670774\ttotal: 21.9s\tremaining: 35.3s\n",
      "1758:\tlearn: 2.4667526\ttotal: 21.9s\tremaining: 35.3s\n",
      "1759:\tlearn: 2.4661868\ttotal: 21.9s\tremaining: 35.3s\n",
      "1760:\tlearn: 2.4654311\ttotal: 21.9s\tremaining: 35.3s\n",
      "1761:\tlearn: 2.4649252\ttotal: 21.9s\tremaining: 35.3s\n",
      "1762:\tlearn: 2.4645089\ttotal: 21.9s\tremaining: 35.3s\n",
      "1763:\tlearn: 2.4636309\ttotal: 21.9s\tremaining: 35.2s\n",
      "1764:\tlearn: 2.4633317\ttotal: 21.9s\tremaining: 35.2s\n",
      "1765:\tlearn: 2.4628184\ttotal: 22s\tremaining: 35.2s\n",
      "1766:\tlearn: 2.4626773\ttotal: 22s\tremaining: 35.2s\n",
      "1767:\tlearn: 2.4621668\ttotal: 22s\tremaining: 35.2s\n",
      "1768:\tlearn: 2.4616872\ttotal: 22s\tremaining: 35.2s\n",
      "1769:\tlearn: 2.4613689\ttotal: 22s\tremaining: 35.2s\n",
      "1770:\tlearn: 2.4606028\ttotal: 22s\tremaining: 35.1s\n",
      "1771:\tlearn: 2.4601195\ttotal: 22s\tremaining: 35.1s\n",
      "1772:\tlearn: 2.4599807\ttotal: 22s\tremaining: 35.1s\n",
      "1773:\tlearn: 2.4595004\ttotal: 22.1s\tremaining: 35.1s\n",
      "1774:\tlearn: 2.4589978\ttotal: 22.1s\tremaining: 35.1s\n",
      "1775:\tlearn: 2.4585786\ttotal: 22.1s\tremaining: 35.1s\n",
      "1776:\tlearn: 2.4580208\ttotal: 22.1s\tremaining: 35.1s\n",
      "1777:\tlearn: 2.4573531\ttotal: 22.1s\tremaining: 35.1s\n",
      "1778:\tlearn: 2.4566300\ttotal: 22.1s\tremaining: 35.1s\n",
      "1779:\tlearn: 2.4561441\ttotal: 22.1s\tremaining: 35s\n",
      "1780:\tlearn: 2.4556679\ttotal: 22.1s\tremaining: 35s\n",
      "1781:\tlearn: 2.4552722\ttotal: 22.2s\tremaining: 35s\n",
      "1782:\tlearn: 2.4547436\ttotal: 22.2s\tremaining: 35s\n",
      "1783:\tlearn: 2.4543240\ttotal: 22.2s\tremaining: 35s\n",
      "1784:\tlearn: 2.4539236\ttotal: 22.2s\tremaining: 35s\n",
      "1785:\tlearn: 2.4531740\ttotal: 22.2s\tremaining: 35s\n",
      "1786:\tlearn: 2.4521276\ttotal: 22.2s\tremaining: 34.9s\n",
      "1787:\tlearn: 2.4518289\ttotal: 22.2s\tremaining: 34.9s\n",
      "1788:\tlearn: 2.4514139\ttotal: 22.2s\tremaining: 34.9s\n",
      "1789:\tlearn: 2.4505830\ttotal: 22.3s\tremaining: 34.9s\n",
      "1790:\tlearn: 2.4499555\ttotal: 22.3s\tremaining: 34.9s\n",
      "1791:\tlearn: 2.4496335\ttotal: 22.3s\tremaining: 34.9s\n",
      "1792:\tlearn: 2.4491837\ttotal: 22.3s\tremaining: 34.9s\n",
      "1793:\tlearn: 2.4483569\ttotal: 22.3s\tremaining: 34.9s\n",
      "1794:\tlearn: 2.4481371\ttotal: 22.3s\tremaining: 34.8s\n",
      "1795:\tlearn: 2.4479599\ttotal: 22.3s\tremaining: 34.8s\n",
      "1796:\tlearn: 2.4472599\ttotal: 22.3s\tremaining: 34.8s\n",
      "1797:\tlearn: 2.4472214\ttotal: 22.3s\tremaining: 34.8s\n",
      "1798:\tlearn: 2.4468367\ttotal: 22.4s\tremaining: 34.8s\n",
      "1799:\tlearn: 2.4464718\ttotal: 22.4s\tremaining: 34.8s\n",
      "1800:\tlearn: 2.4462152\ttotal: 22.4s\tremaining: 34.8s\n",
      "1801:\tlearn: 2.4458221\ttotal: 22.4s\tremaining: 34.8s\n",
      "1802:\tlearn: 2.4453280\ttotal: 22.4s\tremaining: 34.7s\n",
      "1803:\tlearn: 2.4445626\ttotal: 22.4s\tremaining: 34.7s\n",
      "1804:\tlearn: 2.4440425\ttotal: 22.4s\tremaining: 34.7s\n",
      "1805:\tlearn: 2.4438114\ttotal: 22.5s\tremaining: 34.7s\n",
      "1806:\tlearn: 2.4430383\ttotal: 22.5s\tremaining: 34.7s\n",
      "1807:\tlearn: 2.4427512\ttotal: 22.5s\tremaining: 34.7s\n",
      "1808:\tlearn: 2.4424858\ttotal: 22.5s\tremaining: 34.7s\n",
      "1809:\tlearn: 2.4418673\ttotal: 22.5s\tremaining: 34.7s\n",
      "1810:\tlearn: 2.4415415\ttotal: 22.5s\tremaining: 34.7s\n",
      "1811:\tlearn: 2.4408536\ttotal: 22.5s\tremaining: 34.7s\n",
      "1812:\tlearn: 2.4402094\ttotal: 22.6s\tremaining: 34.6s\n",
      "1813:\tlearn: 2.4398392\ttotal: 22.6s\tremaining: 34.6s\n",
      "1814:\tlearn: 2.4393898\ttotal: 22.6s\tremaining: 34.6s\n",
      "1815:\tlearn: 2.4390732\ttotal: 22.6s\tremaining: 34.6s\n",
      "1816:\tlearn: 2.4389055\ttotal: 22.6s\tremaining: 34.6s\n",
      "1817:\tlearn: 2.4379066\ttotal: 22.6s\tremaining: 34.6s\n",
      "1818:\tlearn: 2.4370973\ttotal: 22.6s\tremaining: 34.6s\n",
      "1819:\tlearn: 2.4368505\ttotal: 22.7s\tremaining: 34.6s\n",
      "1820:\tlearn: 2.4365545\ttotal: 22.7s\tremaining: 34.6s\n",
      "1821:\tlearn: 2.4361541\ttotal: 22.7s\tremaining: 34.6s\n",
      "1822:\tlearn: 2.4353410\ttotal: 22.7s\tremaining: 34.5s\n",
      "1823:\tlearn: 2.4349459\ttotal: 22.7s\tremaining: 34.5s\n",
      "1824:\tlearn: 2.4347237\ttotal: 22.7s\tremaining: 34.5s\n",
      "1825:\tlearn: 2.4343569\ttotal: 22.7s\tremaining: 34.5s\n",
      "1826:\tlearn: 2.4339246\ttotal: 22.8s\tremaining: 34.5s\n",
      "1827:\tlearn: 2.4332890\ttotal: 22.8s\tremaining: 34.5s\n",
      "1828:\tlearn: 2.4329182\ttotal: 22.8s\tremaining: 34.5s\n",
      "1829:\tlearn: 2.4326077\ttotal: 22.8s\tremaining: 34.5s\n",
      "1830:\tlearn: 2.4318384\ttotal: 22.8s\tremaining: 34.5s\n",
      "1831:\tlearn: 2.4312433\ttotal: 22.8s\tremaining: 34.5s\n",
      "1832:\tlearn: 2.4309644\ttotal: 22.8s\tremaining: 34.4s\n",
      "1833:\tlearn: 2.4305615\ttotal: 22.9s\tremaining: 34.4s\n",
      "1834:\tlearn: 2.4299548\ttotal: 22.9s\tremaining: 34.4s\n",
      "1835:\tlearn: 2.4294203\ttotal: 22.9s\tremaining: 34.4s\n",
      "1836:\tlearn: 2.4288496\ttotal: 22.9s\tremaining: 34.4s\n",
      "1837:\tlearn: 2.4284268\ttotal: 22.9s\tremaining: 34.4s\n",
      "1838:\tlearn: 2.4280210\ttotal: 22.9s\tremaining: 34.4s\n",
      "1839:\tlearn: 2.4276035\ttotal: 22.9s\tremaining: 34.4s\n",
      "1840:\tlearn: 2.4272043\ttotal: 22.9s\tremaining: 34.4s\n",
      "1841:\tlearn: 2.4266715\ttotal: 23s\tremaining: 34.4s\n",
      "1842:\tlearn: 2.4258921\ttotal: 23s\tremaining: 34.3s\n",
      "1843:\tlearn: 2.4253895\ttotal: 23s\tremaining: 34.3s\n",
      "1844:\tlearn: 2.4247771\ttotal: 23s\tremaining: 34.3s\n",
      "1845:\tlearn: 2.4244424\ttotal: 23s\tremaining: 34.3s\n",
      "1846:\tlearn: 2.4238287\ttotal: 23s\tremaining: 34.3s\n",
      "1847:\tlearn: 2.4233959\ttotal: 23s\tremaining: 34.3s\n",
      "1848:\tlearn: 2.4229181\ttotal: 23.1s\tremaining: 34.3s\n",
      "1849:\tlearn: 2.4224807\ttotal: 23.1s\tremaining: 34.3s\n",
      "1850:\tlearn: 2.4222687\ttotal: 23.1s\tremaining: 34.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1851:\tlearn: 2.4220886\ttotal: 23.1s\tremaining: 34.3s\n",
      "1852:\tlearn: 2.4218399\ttotal: 23.1s\tremaining: 34.2s\n",
      "1853:\tlearn: 2.4214827\ttotal: 23.1s\tremaining: 34.2s\n",
      "1854:\tlearn: 2.4212266\ttotal: 23.1s\tremaining: 34.2s\n",
      "1855:\tlearn: 2.4208943\ttotal: 23.2s\tremaining: 34.2s\n",
      "1856:\tlearn: 2.4204187\ttotal: 23.2s\tremaining: 34.2s\n",
      "1857:\tlearn: 2.4200782\ttotal: 23.2s\tremaining: 34.2s\n",
      "1858:\tlearn: 2.4197717\ttotal: 23.2s\tremaining: 34.2s\n",
      "1859:\tlearn: 2.4191225\ttotal: 23.2s\tremaining: 34.2s\n",
      "1860:\tlearn: 2.4183816\ttotal: 23.2s\tremaining: 34.1s\n",
      "1861:\tlearn: 2.4179302\ttotal: 23.2s\tremaining: 34.1s\n",
      "1862:\tlearn: 2.4176226\ttotal: 23.2s\tremaining: 34.1s\n",
      "1863:\tlearn: 2.4172751\ttotal: 23.3s\tremaining: 34.1s\n",
      "1864:\tlearn: 2.4167741\ttotal: 23.3s\tremaining: 34.1s\n",
      "1865:\tlearn: 2.4167568\ttotal: 23.3s\tremaining: 34.1s\n",
      "1866:\tlearn: 2.4162637\ttotal: 23.3s\tremaining: 34.1s\n",
      "1867:\tlearn: 2.4155543\ttotal: 23.3s\tremaining: 34.1s\n",
      "1868:\tlearn: 2.4152728\ttotal: 23.3s\tremaining: 34s\n",
      "1869:\tlearn: 2.4147723\ttotal: 23.3s\tremaining: 34s\n",
      "1870:\tlearn: 2.4141494\ttotal: 23.3s\tremaining: 34s\n",
      "1871:\tlearn: 2.4137764\ttotal: 23.4s\tremaining: 34s\n",
      "1872:\tlearn: 2.4134716\ttotal: 23.4s\tremaining: 34s\n",
      "1873:\tlearn: 2.4127244\ttotal: 23.4s\tremaining: 34s\n",
      "1874:\tlearn: 2.4123028\ttotal: 23.4s\tremaining: 34s\n",
      "1875:\tlearn: 2.4120050\ttotal: 23.4s\tremaining: 34s\n",
      "1876:\tlearn: 2.4115167\ttotal: 23.4s\tremaining: 33.9s\n",
      "1877:\tlearn: 2.4111232\ttotal: 23.4s\tremaining: 33.9s\n",
      "1878:\tlearn: 2.4105682\ttotal: 23.4s\tremaining: 33.9s\n",
      "1879:\tlearn: 2.4101121\ttotal: 23.5s\tremaining: 33.9s\n",
      "1880:\tlearn: 2.4095371\ttotal: 23.5s\tremaining: 33.9s\n",
      "1881:\tlearn: 2.4091535\ttotal: 23.5s\tremaining: 33.9s\n",
      "1882:\tlearn: 2.4084892\ttotal: 23.5s\tremaining: 33.9s\n",
      "1883:\tlearn: 2.4081739\ttotal: 23.5s\tremaining: 33.9s\n",
      "1884:\tlearn: 2.4079779\ttotal: 23.5s\tremaining: 33.8s\n",
      "1885:\tlearn: 2.4074284\ttotal: 23.5s\tremaining: 33.8s\n",
      "1886:\tlearn: 2.4069353\ttotal: 23.5s\tremaining: 33.8s\n",
      "1887:\tlearn: 2.4062079\ttotal: 23.6s\tremaining: 33.8s\n",
      "1888:\tlearn: 2.4059258\ttotal: 23.6s\tremaining: 33.8s\n",
      "1889:\tlearn: 2.4055399\ttotal: 23.6s\tremaining: 33.8s\n",
      "1890:\tlearn: 2.4052644\ttotal: 23.6s\tremaining: 33.8s\n",
      "1891:\tlearn: 2.4050795\ttotal: 23.6s\tremaining: 33.8s\n",
      "1892:\tlearn: 2.4044244\ttotal: 23.6s\tremaining: 33.7s\n",
      "1893:\tlearn: 2.4039783\ttotal: 23.6s\tremaining: 33.7s\n",
      "1894:\tlearn: 2.4035552\ttotal: 23.6s\tremaining: 33.7s\n",
      "1895:\tlearn: 2.4032720\ttotal: 23.6s\tremaining: 33.7s\n",
      "1896:\tlearn: 2.4024362\ttotal: 23.7s\tremaining: 33.7s\n",
      "1897:\tlearn: 2.4017590\ttotal: 23.7s\tremaining: 33.7s\n",
      "1898:\tlearn: 2.4011753\ttotal: 23.7s\tremaining: 33.7s\n",
      "1899:\tlearn: 2.4007268\ttotal: 23.7s\tremaining: 33.6s\n",
      "1900:\tlearn: 2.3998536\ttotal: 23.7s\tremaining: 33.6s\n",
      "1901:\tlearn: 2.3995787\ttotal: 23.7s\tremaining: 33.6s\n",
      "1902:\tlearn: 2.3990684\ttotal: 23.7s\tremaining: 33.6s\n",
      "1903:\tlearn: 2.3984941\ttotal: 23.7s\tremaining: 33.6s\n",
      "1904:\tlearn: 2.3982810\ttotal: 23.8s\tremaining: 33.6s\n",
      "1905:\tlearn: 2.3976817\ttotal: 23.8s\tremaining: 33.6s\n",
      "1906:\tlearn: 2.3969974\ttotal: 23.8s\tremaining: 33.6s\n",
      "1907:\tlearn: 2.3966250\ttotal: 23.8s\tremaining: 33.5s\n",
      "1908:\tlearn: 2.3961489\ttotal: 23.8s\tremaining: 33.5s\n",
      "1909:\tlearn: 2.3957967\ttotal: 23.8s\tremaining: 33.5s\n",
      "1910:\tlearn: 2.3951731\ttotal: 23.8s\tremaining: 33.5s\n",
      "1911:\tlearn: 2.3949832\ttotal: 23.8s\tremaining: 33.5s\n",
      "1912:\tlearn: 2.3943653\ttotal: 23.9s\tremaining: 33.5s\n",
      "1913:\tlearn: 2.3938784\ttotal: 23.9s\tremaining: 33.5s\n",
      "1914:\tlearn: 2.3933019\ttotal: 23.9s\tremaining: 33.5s\n",
      "1915:\tlearn: 2.3929390\ttotal: 23.9s\tremaining: 33.4s\n",
      "1916:\tlearn: 2.3924624\ttotal: 23.9s\tremaining: 33.4s\n",
      "1917:\tlearn: 2.3921340\ttotal: 23.9s\tremaining: 33.4s\n",
      "1918:\tlearn: 2.3916007\ttotal: 23.9s\tremaining: 33.4s\n",
      "1919:\tlearn: 2.3909956\ttotal: 23.9s\tremaining: 33.4s\n",
      "1920:\tlearn: 2.3905711\ttotal: 24s\tremaining: 33.4s\n",
      "1921:\tlearn: 2.3897217\ttotal: 24s\tremaining: 33.4s\n",
      "1922:\tlearn: 2.3888610\ttotal: 24s\tremaining: 33.4s\n",
      "1923:\tlearn: 2.3885055\ttotal: 24s\tremaining: 33.4s\n",
      "1924:\tlearn: 2.3878927\ttotal: 24s\tremaining: 33.3s\n",
      "1925:\tlearn: 2.3874950\ttotal: 24s\tremaining: 33.3s\n",
      "1926:\tlearn: 2.3869615\ttotal: 24s\tremaining: 33.3s\n",
      "1927:\tlearn: 2.3869492\ttotal: 24s\tremaining: 33.3s\n",
      "1928:\tlearn: 2.3862238\ttotal: 24.1s\tremaining: 33.3s\n",
      "1929:\tlearn: 2.3858479\ttotal: 24.1s\tremaining: 33.3s\n",
      "1930:\tlearn: 2.3851708\ttotal: 24.1s\tremaining: 33.3s\n",
      "1931:\tlearn: 2.3848834\ttotal: 24.1s\tremaining: 33.2s\n",
      "1932:\tlearn: 2.3841963\ttotal: 24.1s\tremaining: 33.2s\n",
      "1933:\tlearn: 2.3832676\ttotal: 24.1s\tremaining: 33.2s\n",
      "1934:\tlearn: 2.3828209\ttotal: 24.1s\tremaining: 33.2s\n",
      "1935:\tlearn: 2.3824218\ttotal: 24.1s\tremaining: 33.2s\n",
      "1936:\tlearn: 2.3821564\ttotal: 24.2s\tremaining: 33.2s\n",
      "1937:\tlearn: 2.3814296\ttotal: 24.2s\tremaining: 33.2s\n",
      "1938:\tlearn: 2.3810213\ttotal: 24.2s\tremaining: 33.2s\n",
      "1939:\tlearn: 2.3808352\ttotal: 24.2s\tremaining: 33.1s\n",
      "1940:\tlearn: 2.3805188\ttotal: 24.2s\tremaining: 33.1s\n",
      "1941:\tlearn: 2.3801491\ttotal: 24.2s\tremaining: 33.1s\n",
      "1942:\tlearn: 2.3801183\ttotal: 24.2s\tremaining: 33.1s\n",
      "1943:\tlearn: 2.3796038\ttotal: 24.2s\tremaining: 33.1s\n",
      "1944:\tlearn: 2.3794120\ttotal: 24.3s\tremaining: 33.1s\n",
      "1945:\tlearn: 2.3790603\ttotal: 24.3s\tremaining: 33.1s\n",
      "1946:\tlearn: 2.3784907\ttotal: 24.3s\tremaining: 33.1s\n",
      "1947:\tlearn: 2.3783122\ttotal: 24.3s\tremaining: 33s\n",
      "1948:\tlearn: 2.3778484\ttotal: 24.3s\tremaining: 33s\n",
      "1949:\tlearn: 2.3775518\ttotal: 24.3s\tremaining: 33s\n",
      "1950:\tlearn: 2.3774856\ttotal: 24.3s\tremaining: 33s\n",
      "1951:\tlearn: 2.3770054\ttotal: 24.3s\tremaining: 33s\n",
      "1952:\tlearn: 2.3767544\ttotal: 24.3s\tremaining: 33s\n",
      "1953:\tlearn: 2.3765450\ttotal: 24.4s\tremaining: 33s\n",
      "1954:\tlearn: 2.3760752\ttotal: 24.4s\tremaining: 32.9s\n",
      "1955:\tlearn: 2.3754501\ttotal: 24.4s\tremaining: 32.9s\n",
      "1956:\tlearn: 2.3749704\ttotal: 24.4s\tremaining: 32.9s\n",
      "1957:\tlearn: 2.3743280\ttotal: 24.4s\tremaining: 32.9s\n",
      "1958:\tlearn: 2.3738483\ttotal: 24.4s\tremaining: 32.9s\n",
      "1959:\tlearn: 2.3732050\ttotal: 24.4s\tremaining: 32.9s\n",
      "1960:\tlearn: 2.3725270\ttotal: 24.4s\tremaining: 32.9s\n",
      "1961:\tlearn: 2.3723658\ttotal: 24.5s\tremaining: 32.9s\n",
      "1962:\tlearn: 2.3717114\ttotal: 24.5s\tremaining: 32.8s\n",
      "1963:\tlearn: 2.3713911\ttotal: 24.5s\tremaining: 32.8s\n",
      "1964:\tlearn: 2.3708201\ttotal: 24.5s\tremaining: 32.8s\n",
      "1965:\tlearn: 2.3703576\ttotal: 24.5s\tremaining: 32.8s\n",
      "1966:\tlearn: 2.3701071\ttotal: 24.5s\tremaining: 32.8s\n",
      "1967:\tlearn: 2.3696108\ttotal: 24.5s\tremaining: 32.8s\n",
      "1968:\tlearn: 2.3691956\ttotal: 24.5s\tremaining: 32.8s\n",
      "1969:\tlearn: 2.3690285\ttotal: 24.5s\tremaining: 32.7s\n",
      "1970:\tlearn: 2.3685636\ttotal: 24.6s\tremaining: 32.7s\n",
      "1971:\tlearn: 2.3682690\ttotal: 24.6s\tremaining: 32.7s\n",
      "1972:\tlearn: 2.3678086\ttotal: 24.6s\tremaining: 32.7s\n",
      "1973:\tlearn: 2.3673250\ttotal: 24.6s\tremaining: 32.7s\n",
      "1974:\tlearn: 2.3673014\ttotal: 24.6s\tremaining: 32.7s\n",
      "1975:\tlearn: 2.3669769\ttotal: 24.6s\tremaining: 32.7s\n",
      "1976:\tlearn: 2.3663995\ttotal: 24.6s\tremaining: 32.7s\n",
      "1977:\tlearn: 2.3654904\ttotal: 24.6s\tremaining: 32.6s\n",
      "1978:\tlearn: 2.3645790\ttotal: 24.7s\tremaining: 32.6s\n",
      "1979:\tlearn: 2.3642664\ttotal: 24.7s\tremaining: 32.6s\n",
      "1980:\tlearn: 2.3637200\ttotal: 24.7s\tremaining: 32.6s\n",
      "1981:\tlearn: 2.3630175\ttotal: 24.7s\tremaining: 32.6s\n",
      "1982:\tlearn: 2.3623753\ttotal: 24.7s\tremaining: 32.6s\n",
      "1983:\tlearn: 2.3619047\ttotal: 24.7s\tremaining: 32.6s\n",
      "1984:\tlearn: 2.3616634\ttotal: 24.7s\tremaining: 32.6s\n",
      "1985:\tlearn: 2.3611012\ttotal: 24.7s\tremaining: 32.5s\n",
      "1986:\tlearn: 2.3604785\ttotal: 24.8s\tremaining: 32.5s\n",
      "1987:\tlearn: 2.3599401\ttotal: 24.8s\tremaining: 32.5s\n",
      "1988:\tlearn: 2.3595681\ttotal: 24.8s\tremaining: 32.5s\n",
      "1989:\tlearn: 2.3591304\ttotal: 24.8s\tremaining: 32.5s\n",
      "1990:\tlearn: 2.3585495\ttotal: 24.8s\tremaining: 32.5s\n",
      "1991:\tlearn: 2.3582770\ttotal: 24.8s\tremaining: 32.5s\n",
      "1992:\tlearn: 2.3576166\ttotal: 24.8s\tremaining: 32.5s\n",
      "1993:\tlearn: 2.3571847\ttotal: 24.8s\tremaining: 32.4s\n",
      "1994:\tlearn: 2.3565897\ttotal: 24.9s\tremaining: 32.4s\n",
      "1995:\tlearn: 2.3561980\ttotal: 24.9s\tremaining: 32.4s\n",
      "1996:\tlearn: 2.3556699\ttotal: 24.9s\tremaining: 32.4s\n",
      "1997:\tlearn: 2.3552829\ttotal: 24.9s\tremaining: 32.4s\n",
      "1998:\tlearn: 2.3546535\ttotal: 24.9s\tremaining: 32.4s\n",
      "1999:\tlearn: 2.3539663\ttotal: 24.9s\tremaining: 32.4s\n",
      "2000:\tlearn: 2.3536327\ttotal: 24.9s\tremaining: 32.4s\n",
      "2001:\tlearn: 2.3530480\ttotal: 24.9s\tremaining: 32.3s\n",
      "2002:\tlearn: 2.3522727\ttotal: 25s\tremaining: 32.3s\n",
      "2003:\tlearn: 2.3518178\ttotal: 25s\tremaining: 32.3s\n",
      "2004:\tlearn: 2.3510711\ttotal: 25s\tremaining: 32.3s\n",
      "2005:\tlearn: 2.3508361\ttotal: 25s\tremaining: 32.3s\n",
      "2006:\tlearn: 2.3504196\ttotal: 25s\tremaining: 32.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007:\tlearn: 2.3502366\ttotal: 25s\tremaining: 32.3s\n",
      "2008:\tlearn: 2.3497637\ttotal: 25s\tremaining: 32.3s\n",
      "2009:\tlearn: 2.3495015\ttotal: 25s\tremaining: 32.2s\n",
      "2010:\tlearn: 2.3491420\ttotal: 25.1s\tremaining: 32.2s\n",
      "2011:\tlearn: 2.3485313\ttotal: 25.1s\tremaining: 32.2s\n",
      "2012:\tlearn: 2.3479260\ttotal: 25.1s\tremaining: 32.2s\n",
      "2013:\tlearn: 2.3469895\ttotal: 25.1s\tremaining: 32.2s\n",
      "2014:\tlearn: 2.3464255\ttotal: 25.1s\tremaining: 32.2s\n",
      "2015:\tlearn: 2.3455620\ttotal: 25.1s\tremaining: 32.2s\n",
      "2016:\tlearn: 2.3449272\ttotal: 25.1s\tremaining: 32.2s\n",
      "2017:\tlearn: 2.3447180\ttotal: 25.1s\tremaining: 32.2s\n",
      "2018:\tlearn: 2.3440354\ttotal: 25.2s\tremaining: 32.1s\n",
      "2019:\tlearn: 2.3433090\ttotal: 25.2s\tremaining: 32.1s\n",
      "2020:\tlearn: 2.3429090\ttotal: 25.2s\tremaining: 32.1s\n",
      "2021:\tlearn: 2.3426097\ttotal: 25.2s\tremaining: 32.1s\n",
      "2022:\tlearn: 2.3422671\ttotal: 25.2s\tremaining: 32.1s\n",
      "2023:\tlearn: 2.3418387\ttotal: 25.2s\tremaining: 32.1s\n",
      "2024:\tlearn: 2.3416151\ttotal: 25.2s\tremaining: 32.1s\n",
      "2025:\tlearn: 2.3411539\ttotal: 25.2s\tremaining: 32s\n",
      "2026:\tlearn: 2.3408607\ttotal: 25.3s\tremaining: 32s\n",
      "2027:\tlearn: 2.3404149\ttotal: 25.3s\tremaining: 32s\n",
      "2028:\tlearn: 2.3400743\ttotal: 25.3s\tremaining: 32s\n",
      "2029:\tlearn: 2.3394209\ttotal: 25.3s\tremaining: 32s\n",
      "2030:\tlearn: 2.3392993\ttotal: 25.3s\tremaining: 32s\n",
      "2031:\tlearn: 2.3390000\ttotal: 25.3s\tremaining: 32s\n",
      "2032:\tlearn: 2.3385602\ttotal: 25.3s\tremaining: 32s\n",
      "2033:\tlearn: 2.3382315\ttotal: 25.3s\tremaining: 31.9s\n",
      "2034:\tlearn: 2.3373427\ttotal: 25.4s\tremaining: 31.9s\n",
      "2035:\tlearn: 2.3371860\ttotal: 25.4s\tremaining: 31.9s\n",
      "2036:\tlearn: 2.3367490\ttotal: 25.4s\tremaining: 31.9s\n",
      "2037:\tlearn: 2.3364307\ttotal: 25.4s\tremaining: 31.9s\n",
      "2038:\tlearn: 2.3360758\ttotal: 25.4s\tremaining: 31.9s\n",
      "2039:\tlearn: 2.3358395\ttotal: 25.4s\tremaining: 31.9s\n",
      "2040:\tlearn: 2.3352645\ttotal: 25.4s\tremaining: 31.9s\n",
      "2041:\tlearn: 2.3345829\ttotal: 25.4s\tremaining: 31.8s\n",
      "2042:\tlearn: 2.3340906\ttotal: 25.5s\tremaining: 31.8s\n",
      "2043:\tlearn: 2.3334643\ttotal: 25.5s\tremaining: 31.8s\n",
      "2044:\tlearn: 2.3330559\ttotal: 25.5s\tremaining: 31.8s\n",
      "2045:\tlearn: 2.3326963\ttotal: 25.5s\tremaining: 31.8s\n",
      "2046:\tlearn: 2.3324541\ttotal: 25.5s\tremaining: 31.8s\n",
      "2047:\tlearn: 2.3319442\ttotal: 25.5s\tremaining: 31.8s\n",
      "2048:\tlearn: 2.3316409\ttotal: 25.5s\tremaining: 31.8s\n",
      "2049:\tlearn: 2.3313304\ttotal: 25.5s\tremaining: 31.7s\n",
      "2050:\tlearn: 2.3309602\ttotal: 25.6s\tremaining: 31.7s\n",
      "2051:\tlearn: 2.3304767\ttotal: 25.6s\tremaining: 31.7s\n",
      "2052:\tlearn: 2.3301331\ttotal: 25.6s\tremaining: 31.7s\n",
      "2053:\tlearn: 2.3296191\ttotal: 25.6s\tremaining: 31.7s\n",
      "2054:\tlearn: 2.3293915\ttotal: 25.6s\tremaining: 31.7s\n",
      "2055:\tlearn: 2.3291184\ttotal: 25.6s\tremaining: 31.7s\n",
      "2056:\tlearn: 2.3286217\ttotal: 25.6s\tremaining: 31.7s\n",
      "2057:\tlearn: 2.3283939\ttotal: 25.6s\tremaining: 31.6s\n",
      "2058:\tlearn: 2.3281765\ttotal: 25.6s\tremaining: 31.6s\n",
      "2059:\tlearn: 2.3277095\ttotal: 25.7s\tremaining: 31.6s\n",
      "2060:\tlearn: 2.3274521\ttotal: 25.7s\tremaining: 31.6s\n",
      "2061:\tlearn: 2.3268753\ttotal: 25.7s\tremaining: 31.6s\n",
      "2062:\tlearn: 2.3266844\ttotal: 25.7s\tremaining: 31.6s\n",
      "2063:\tlearn: 2.3265592\ttotal: 25.7s\tremaining: 31.6s\n",
      "2064:\tlearn: 2.3261920\ttotal: 25.7s\tremaining: 31.6s\n",
      "2065:\tlearn: 2.3257477\ttotal: 25.7s\tremaining: 31.5s\n",
      "2066:\tlearn: 2.3254277\ttotal: 25.7s\tremaining: 31.5s\n",
      "2067:\tlearn: 2.3252507\ttotal: 25.8s\tremaining: 31.5s\n",
      "2068:\tlearn: 2.3250660\ttotal: 25.8s\tremaining: 31.5s\n",
      "2069:\tlearn: 2.3248938\ttotal: 25.8s\tremaining: 31.5s\n",
      "2070:\tlearn: 2.3243587\ttotal: 25.8s\tremaining: 31.5s\n",
      "2071:\tlearn: 2.3240004\ttotal: 25.8s\tremaining: 31.5s\n",
      "2072:\tlearn: 2.3235675\ttotal: 25.8s\tremaining: 31.4s\n",
      "2073:\tlearn: 2.3229714\ttotal: 25.8s\tremaining: 31.4s\n",
      "2074:\tlearn: 2.3225056\ttotal: 25.8s\tremaining: 31.4s\n",
      "2075:\tlearn: 2.3220291\ttotal: 25.9s\tremaining: 31.4s\n",
      "2076:\tlearn: 2.3212774\ttotal: 25.9s\tremaining: 31.4s\n",
      "2077:\tlearn: 2.3210420\ttotal: 25.9s\tremaining: 31.4s\n",
      "2078:\tlearn: 2.3204237\ttotal: 25.9s\tremaining: 31.4s\n",
      "2079:\tlearn: 2.3198336\ttotal: 25.9s\tremaining: 31.4s\n",
      "2080:\tlearn: 2.3196036\ttotal: 25.9s\tremaining: 31.3s\n",
      "2081:\tlearn: 2.3191208\ttotal: 25.9s\tremaining: 31.3s\n",
      "2082:\tlearn: 2.3186171\ttotal: 25.9s\tremaining: 31.3s\n",
      "2083:\tlearn: 2.3180072\ttotal: 26s\tremaining: 31.3s\n",
      "2084:\tlearn: 2.3176098\ttotal: 26s\tremaining: 31.3s\n",
      "2085:\tlearn: 2.3171835\ttotal: 26s\tremaining: 31.3s\n",
      "2086:\tlearn: 2.3168241\ttotal: 26s\tremaining: 31.3s\n",
      "2087:\tlearn: 2.3161157\ttotal: 26s\tremaining: 31.3s\n",
      "2088:\tlearn: 2.3157281\ttotal: 26s\tremaining: 31.2s\n",
      "2089:\tlearn: 2.3153483\ttotal: 26s\tremaining: 31.2s\n",
      "2090:\tlearn: 2.3150438\ttotal: 26s\tremaining: 31.2s\n",
      "2091:\tlearn: 2.3143960\ttotal: 26.1s\tremaining: 31.2s\n",
      "2092:\tlearn: 2.3138028\ttotal: 26.1s\tremaining: 31.2s\n",
      "2093:\tlearn: 2.3134567\ttotal: 26.1s\tremaining: 31.2s\n",
      "2094:\tlearn: 2.3127885\ttotal: 26.1s\tremaining: 31.2s\n",
      "2095:\tlearn: 2.3123160\ttotal: 26.1s\tremaining: 31.2s\n",
      "2096:\tlearn: 2.3122398\ttotal: 26.1s\tremaining: 31.1s\n",
      "2097:\tlearn: 2.3118872\ttotal: 26.1s\tremaining: 31.1s\n",
      "2098:\tlearn: 2.3113942\ttotal: 26.1s\tremaining: 31.1s\n",
      "2099:\tlearn: 2.3108474\ttotal: 26.2s\tremaining: 31.1s\n",
      "2100:\tlearn: 2.3103532\ttotal: 26.2s\tremaining: 31.1s\n",
      "2101:\tlearn: 2.3099496\ttotal: 26.2s\tremaining: 31.1s\n",
      "2102:\tlearn: 2.3096249\ttotal: 26.2s\tremaining: 31.1s\n",
      "2103:\tlearn: 2.3093960\ttotal: 26.2s\tremaining: 31.1s\n",
      "2104:\tlearn: 2.3088771\ttotal: 26.2s\tremaining: 31s\n",
      "2105:\tlearn: 2.3085755\ttotal: 26.2s\tremaining: 31s\n",
      "2106:\tlearn: 2.3081874\ttotal: 26.2s\tremaining: 31s\n",
      "2107:\tlearn: 2.3076556\ttotal: 26.3s\tremaining: 31s\n",
      "2108:\tlearn: 2.3073802\ttotal: 26.3s\tremaining: 31s\n",
      "2109:\tlearn: 2.3068754\ttotal: 26.3s\tremaining: 31s\n",
      "2110:\tlearn: 2.3066405\ttotal: 26.3s\tremaining: 31s\n",
      "2111:\tlearn: 2.3060688\ttotal: 26.3s\tremaining: 31s\n",
      "2112:\tlearn: 2.3056197\ttotal: 26.3s\tremaining: 30.9s\n",
      "2113:\tlearn: 2.3052134\ttotal: 26.3s\tremaining: 30.9s\n",
      "2114:\tlearn: 2.3049300\ttotal: 26.3s\tremaining: 30.9s\n",
      "2115:\tlearn: 2.3042311\ttotal: 26.3s\tremaining: 30.9s\n",
      "2116:\tlearn: 2.3037367\ttotal: 26.4s\tremaining: 30.9s\n",
      "2117:\tlearn: 2.3028419\ttotal: 26.4s\tremaining: 30.9s\n",
      "2118:\tlearn: 2.3022203\ttotal: 26.4s\tremaining: 30.9s\n",
      "2119:\tlearn: 2.3019117\ttotal: 26.4s\tremaining: 30.9s\n",
      "2120:\tlearn: 2.3017733\ttotal: 26.4s\tremaining: 30.8s\n",
      "2121:\tlearn: 2.3015564\ttotal: 26.4s\tremaining: 30.8s\n",
      "2122:\tlearn: 2.3011120\ttotal: 26.4s\tremaining: 30.8s\n",
      "2123:\tlearn: 2.3007234\ttotal: 26.4s\tremaining: 30.8s\n",
      "2124:\tlearn: 2.3004453\ttotal: 26.5s\tremaining: 30.8s\n",
      "2125:\tlearn: 2.3001452\ttotal: 26.5s\tremaining: 30.8s\n",
      "2126:\tlearn: 2.2996538\ttotal: 26.5s\tremaining: 30.8s\n",
      "2127:\tlearn: 2.2991658\ttotal: 26.5s\tremaining: 30.7s\n",
      "2128:\tlearn: 2.2986942\ttotal: 26.5s\tremaining: 30.7s\n",
      "2129:\tlearn: 2.2980331\ttotal: 26.5s\tremaining: 30.7s\n",
      "2130:\tlearn: 2.2975947\ttotal: 26.5s\tremaining: 30.7s\n",
      "2131:\tlearn: 2.2971079\ttotal: 26.5s\tremaining: 30.7s\n",
      "2132:\tlearn: 2.2966957\ttotal: 26.6s\tremaining: 30.7s\n",
      "2133:\tlearn: 2.2964538\ttotal: 26.6s\tremaining: 30.7s\n",
      "2134:\tlearn: 2.2959177\ttotal: 26.6s\tremaining: 30.7s\n",
      "2135:\tlearn: 2.2955293\ttotal: 26.6s\tremaining: 30.6s\n",
      "2136:\tlearn: 2.2952452\ttotal: 26.6s\tremaining: 30.6s\n",
      "2137:\tlearn: 2.2948719\ttotal: 26.6s\tremaining: 30.6s\n",
      "2138:\tlearn: 2.2944600\ttotal: 26.6s\tremaining: 30.6s\n",
      "2139:\tlearn: 2.2941369\ttotal: 26.6s\tremaining: 30.6s\n",
      "2140:\tlearn: 2.2937331\ttotal: 26.6s\tremaining: 30.6s\n",
      "2141:\tlearn: 2.2935331\ttotal: 26.7s\tremaining: 30.6s\n",
      "2142:\tlearn: 2.2934074\ttotal: 26.7s\tremaining: 30.6s\n",
      "2143:\tlearn: 2.2930710\ttotal: 26.7s\tremaining: 30.5s\n",
      "2144:\tlearn: 2.2924270\ttotal: 26.7s\tremaining: 30.5s\n",
      "2145:\tlearn: 2.2920988\ttotal: 26.7s\tremaining: 30.5s\n",
      "2146:\tlearn: 2.2914833\ttotal: 26.7s\tremaining: 30.5s\n",
      "2147:\tlearn: 2.2912940\ttotal: 26.7s\tremaining: 30.5s\n",
      "2148:\tlearn: 2.2906248\ttotal: 26.7s\tremaining: 30.5s\n",
      "2149:\tlearn: 2.2901158\ttotal: 26.8s\tremaining: 30.5s\n",
      "2150:\tlearn: 2.2893796\ttotal: 26.8s\tremaining: 30.5s\n",
      "2151:\tlearn: 2.2890636\ttotal: 26.8s\tremaining: 30.4s\n",
      "2152:\tlearn: 2.2884669\ttotal: 26.8s\tremaining: 30.4s\n",
      "2153:\tlearn: 2.2882674\ttotal: 26.8s\tremaining: 30.4s\n",
      "2154:\tlearn: 2.2879685\ttotal: 26.8s\tremaining: 30.4s\n",
      "2155:\tlearn: 2.2874076\ttotal: 26.8s\tremaining: 30.4s\n",
      "2156:\tlearn: 2.2871385\ttotal: 26.8s\tremaining: 30.4s\n",
      "2157:\tlearn: 2.2868686\ttotal: 26.9s\tremaining: 30.4s\n",
      "2158:\tlearn: 2.2862815\ttotal: 26.9s\tremaining: 30.4s\n",
      "2159:\tlearn: 2.2857457\ttotal: 26.9s\tremaining: 30.3s\n",
      "2160:\tlearn: 2.2853140\ttotal: 26.9s\tremaining: 30.3s\n",
      "2161:\tlearn: 2.2845531\ttotal: 26.9s\tremaining: 30.3s\n",
      "2162:\tlearn: 2.2839146\ttotal: 26.9s\tremaining: 30.3s\n",
      "2163:\tlearn: 2.2838617\ttotal: 26.9s\tremaining: 30.3s\n",
      "2164:\tlearn: 2.2835685\ttotal: 26.9s\tremaining: 30.3s\n",
      "2165:\tlearn: 2.2832894\ttotal: 27s\tremaining: 30.3s\n",
      "2166:\tlearn: 2.2828847\ttotal: 27s\tremaining: 30.3s\n",
      "2167:\tlearn: 2.2823856\ttotal: 27s\tremaining: 30.2s\n",
      "2168:\tlearn: 2.2819617\ttotal: 27s\tremaining: 30.2s\n",
      "2169:\tlearn: 2.2816714\ttotal: 27s\tremaining: 30.2s\n",
      "2170:\tlearn: 2.2814252\ttotal: 27s\tremaining: 30.2s\n",
      "2171:\tlearn: 2.2808007\ttotal: 27s\tremaining: 30.2s\n",
      "2172:\tlearn: 2.2804965\ttotal: 27s\tremaining: 30.2s\n",
      "2173:\tlearn: 2.2800838\ttotal: 27.1s\tremaining: 30.2s\n",
      "2174:\tlearn: 2.2793685\ttotal: 27.1s\tremaining: 30.2s\n",
      "2175:\tlearn: 2.2789841\ttotal: 27.1s\tremaining: 30.1s\n",
      "2176:\tlearn: 2.2787296\ttotal: 27.1s\tremaining: 30.1s\n",
      "2177:\tlearn: 2.2780598\ttotal: 27.1s\tremaining: 30.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2178:\tlearn: 2.2776699\ttotal: 27.1s\tremaining: 30.1s\n",
      "2179:\tlearn: 2.2772964\ttotal: 27.1s\tremaining: 30.1s\n",
      "2180:\tlearn: 2.2768501\ttotal: 27.1s\tremaining: 30.1s\n",
      "2181:\tlearn: 2.2762580\ttotal: 27.2s\tremaining: 30.1s\n",
      "2182:\tlearn: 2.2760641\ttotal: 27.2s\tremaining: 30.1s\n",
      "2183:\tlearn: 2.2753852\ttotal: 27.2s\tremaining: 30s\n",
      "2184:\tlearn: 2.2750235\ttotal: 27.2s\tremaining: 30s\n",
      "2185:\tlearn: 2.2748877\ttotal: 27.2s\tremaining: 30s\n",
      "2186:\tlearn: 2.2744122\ttotal: 27.2s\tremaining: 30s\n",
      "2187:\tlearn: 2.2740067\ttotal: 27.2s\tremaining: 30s\n",
      "2188:\tlearn: 2.2737628\ttotal: 27.2s\tremaining: 30s\n",
      "2189:\tlearn: 2.2733865\ttotal: 27.3s\tremaining: 30s\n",
      "2190:\tlearn: 2.2728291\ttotal: 27.3s\tremaining: 30s\n",
      "2191:\tlearn: 2.2725404\ttotal: 27.3s\tremaining: 29.9s\n",
      "2192:\tlearn: 2.2722588\ttotal: 27.3s\tremaining: 29.9s\n",
      "2193:\tlearn: 2.2720244\ttotal: 27.3s\tremaining: 29.9s\n",
      "2194:\tlearn: 2.2716358\ttotal: 27.3s\tremaining: 29.9s\n",
      "2195:\tlearn: 2.2712158\ttotal: 27.3s\tremaining: 29.9s\n",
      "2196:\tlearn: 2.2707479\ttotal: 27.3s\tremaining: 29.9s\n",
      "2197:\tlearn: 2.2703798\ttotal: 27.4s\tremaining: 29.9s\n",
      "2198:\tlearn: 2.2700475\ttotal: 27.4s\tremaining: 29.9s\n",
      "2199:\tlearn: 2.2699228\ttotal: 27.4s\tremaining: 29.8s\n",
      "2200:\tlearn: 2.2695000\ttotal: 27.4s\tremaining: 29.8s\n",
      "2201:\tlearn: 2.2690536\ttotal: 27.4s\tremaining: 29.8s\n",
      "2202:\tlearn: 2.2686402\ttotal: 27.4s\tremaining: 29.8s\n",
      "2203:\tlearn: 2.2683105\ttotal: 27.4s\tremaining: 29.8s\n",
      "2204:\tlearn: 2.2680960\ttotal: 27.4s\tremaining: 29.8s\n",
      "2205:\tlearn: 2.2677999\ttotal: 27.5s\tremaining: 29.8s\n",
      "2206:\tlearn: 2.2675505\ttotal: 27.5s\tremaining: 29.8s\n",
      "2207:\tlearn: 2.2671563\ttotal: 27.5s\tremaining: 29.7s\n",
      "2208:\tlearn: 2.2667764\ttotal: 27.5s\tremaining: 29.7s\n",
      "2209:\tlearn: 2.2664768\ttotal: 27.5s\tremaining: 29.7s\n",
      "2210:\tlearn: 2.2658552\ttotal: 27.5s\tremaining: 29.7s\n",
      "2211:\tlearn: 2.2654773\ttotal: 27.5s\tremaining: 29.7s\n",
      "2212:\tlearn: 2.2651109\ttotal: 27.5s\tremaining: 29.7s\n",
      "2213:\tlearn: 2.2643933\ttotal: 27.6s\tremaining: 29.7s\n",
      "2214:\tlearn: 2.2639974\ttotal: 27.6s\tremaining: 29.7s\n",
      "2215:\tlearn: 2.2635393\ttotal: 27.6s\tremaining: 29.6s\n",
      "2216:\tlearn: 2.2631982\ttotal: 27.6s\tremaining: 29.6s\n",
      "2217:\tlearn: 2.2628873\ttotal: 27.6s\tremaining: 29.6s\n",
      "2218:\tlearn: 2.2625565\ttotal: 27.6s\tremaining: 29.6s\n",
      "2219:\tlearn: 2.2621722\ttotal: 27.6s\tremaining: 29.6s\n",
      "2220:\tlearn: 2.2616288\ttotal: 27.6s\tremaining: 29.6s\n",
      "2221:\tlearn: 2.2613991\ttotal: 27.6s\tremaining: 29.6s\n",
      "2222:\tlearn: 2.2607984\ttotal: 27.7s\tremaining: 29.6s\n",
      "2223:\tlearn: 2.2601544\ttotal: 27.7s\tremaining: 29.5s\n",
      "2224:\tlearn: 2.2597376\ttotal: 27.7s\tremaining: 29.5s\n",
      "2225:\tlearn: 2.2594890\ttotal: 27.7s\tremaining: 29.5s\n",
      "2226:\tlearn: 2.2591027\ttotal: 27.7s\tremaining: 29.5s\n",
      "2227:\tlearn: 2.2586073\ttotal: 27.7s\tremaining: 29.5s\n",
      "2228:\tlearn: 2.2580923\ttotal: 27.7s\tremaining: 29.5s\n",
      "2229:\tlearn: 2.2577541\ttotal: 27.7s\tremaining: 29.5s\n",
      "2230:\tlearn: 2.2574875\ttotal: 27.8s\tremaining: 29.5s\n",
      "2231:\tlearn: 2.2573541\ttotal: 27.8s\tremaining: 29.5s\n",
      "2232:\tlearn: 2.2569325\ttotal: 27.8s\tremaining: 29.5s\n",
      "2233:\tlearn: 2.2562958\ttotal: 27.8s\tremaining: 29.4s\n",
      "2234:\tlearn: 2.2561243\ttotal: 27.8s\tremaining: 29.4s\n",
      "2235:\tlearn: 2.2558434\ttotal: 27.8s\tremaining: 29.4s\n",
      "2236:\tlearn: 2.2552027\ttotal: 27.9s\tremaining: 29.4s\n",
      "2237:\tlearn: 2.2547629\ttotal: 27.9s\tremaining: 29.4s\n",
      "2238:\tlearn: 2.2544403\ttotal: 27.9s\tremaining: 29.4s\n",
      "2239:\tlearn: 2.2541874\ttotal: 27.9s\tremaining: 29.4s\n",
      "2240:\tlearn: 2.2536980\ttotal: 27.9s\tremaining: 29.4s\n",
      "2241:\tlearn: 2.2531852\ttotal: 27.9s\tremaining: 29.3s\n",
      "2242:\tlearn: 2.2524341\ttotal: 27.9s\tremaining: 29.3s\n",
      "2243:\tlearn: 2.2520845\ttotal: 27.9s\tremaining: 29.3s\n",
      "2244:\tlearn: 2.2516100\ttotal: 28s\tremaining: 29.3s\n",
      "2245:\tlearn: 2.2511687\ttotal: 28s\tremaining: 29.3s\n",
      "2246:\tlearn: 2.2509200\ttotal: 28s\tremaining: 29.3s\n",
      "2247:\tlearn: 2.2506394\ttotal: 28s\tremaining: 29.3s\n",
      "2248:\tlearn: 2.2502725\ttotal: 28s\tremaining: 29.2s\n",
      "2249:\tlearn: 2.2500464\ttotal: 28s\tremaining: 29.2s\n",
      "2250:\tlearn: 2.2494989\ttotal: 28s\tremaining: 29.2s\n",
      "2251:\tlearn: 2.2487034\ttotal: 28s\tremaining: 29.2s\n",
      "2252:\tlearn: 2.2480690\ttotal: 28.1s\tremaining: 29.2s\n",
      "2253:\tlearn: 2.2477552\ttotal: 28.1s\tremaining: 29.2s\n",
      "2254:\tlearn: 2.2473092\ttotal: 28.1s\tremaining: 29.2s\n",
      "2255:\tlearn: 2.2471565\ttotal: 28.1s\tremaining: 29.2s\n",
      "2256:\tlearn: 2.2469104\ttotal: 28.1s\tremaining: 29.1s\n",
      "2257:\tlearn: 2.2465747\ttotal: 28.1s\tremaining: 29.1s\n",
      "2258:\tlearn: 2.2462013\ttotal: 28.1s\tremaining: 29.1s\n",
      "2259:\tlearn: 2.2459681\ttotal: 28.1s\tremaining: 29.1s\n",
      "2260:\tlearn: 2.2451259\ttotal: 28.1s\tremaining: 29.1s\n",
      "2261:\tlearn: 2.2446803\ttotal: 28.2s\tremaining: 29.1s\n",
      "2262:\tlearn: 2.2444546\ttotal: 28.2s\tremaining: 29.1s\n",
      "2263:\tlearn: 2.2440792\ttotal: 28.2s\tremaining: 29.1s\n",
      "2264:\tlearn: 2.2433566\ttotal: 28.2s\tremaining: 29s\n",
      "2265:\tlearn: 2.2430946\ttotal: 28.2s\tremaining: 29s\n",
      "2266:\tlearn: 2.2428304\ttotal: 28.2s\tremaining: 29s\n",
      "2267:\tlearn: 2.2426137\ttotal: 28.2s\tremaining: 29s\n",
      "2268:\tlearn: 2.2421957\ttotal: 28.2s\tremaining: 29s\n",
      "2269:\tlearn: 2.2417334\ttotal: 28.3s\tremaining: 29s\n",
      "2270:\tlearn: 2.2412180\ttotal: 28.3s\tremaining: 29s\n",
      "2271:\tlearn: 2.2409384\ttotal: 28.3s\tremaining: 29s\n",
      "2272:\tlearn: 2.2403739\ttotal: 28.3s\tremaining: 28.9s\n",
      "2273:\tlearn: 2.2400207\ttotal: 28.3s\tremaining: 28.9s\n",
      "2274:\tlearn: 2.2397580\ttotal: 28.3s\tremaining: 28.9s\n",
      "2275:\tlearn: 2.2394098\ttotal: 28.3s\tremaining: 28.9s\n",
      "2276:\tlearn: 2.2391113\ttotal: 28.3s\tremaining: 28.9s\n",
      "2277:\tlearn: 2.2382219\ttotal: 28.4s\tremaining: 28.9s\n",
      "2278:\tlearn: 2.2380089\ttotal: 28.4s\tremaining: 28.9s\n",
      "2279:\tlearn: 2.2377365\ttotal: 28.4s\tremaining: 28.9s\n",
      "2280:\tlearn: 2.2371759\ttotal: 28.4s\tremaining: 28.8s\n",
      "2281:\tlearn: 2.2368179\ttotal: 28.4s\tremaining: 28.8s\n",
      "2282:\tlearn: 2.2365179\ttotal: 28.4s\tremaining: 28.8s\n",
      "2283:\tlearn: 2.2362115\ttotal: 28.4s\tremaining: 28.8s\n",
      "2284:\tlearn: 2.2354734\ttotal: 28.4s\tremaining: 28.8s\n",
      "2285:\tlearn: 2.2351913\ttotal: 28.5s\tremaining: 28.8s\n",
      "2286:\tlearn: 2.2349886\ttotal: 28.5s\tremaining: 28.8s\n",
      "2287:\tlearn: 2.2347089\ttotal: 28.5s\tremaining: 28.8s\n",
      "2288:\tlearn: 2.2341104\ttotal: 28.5s\tremaining: 28.7s\n",
      "2289:\tlearn: 2.2333901\ttotal: 28.5s\tremaining: 28.7s\n",
      "2290:\tlearn: 2.2331843\ttotal: 28.5s\tremaining: 28.7s\n",
      "2291:\tlearn: 2.2325819\ttotal: 28.5s\tremaining: 28.7s\n",
      "2292:\tlearn: 2.2324709\ttotal: 28.5s\tremaining: 28.7s\n",
      "2293:\tlearn: 2.2321754\ttotal: 28.5s\tremaining: 28.7s\n",
      "2294:\tlearn: 2.2315891\ttotal: 28.6s\tremaining: 28.7s\n",
      "2295:\tlearn: 2.2309981\ttotal: 28.6s\tremaining: 28.6s\n",
      "2296:\tlearn: 2.2307927\ttotal: 28.6s\tremaining: 28.6s\n",
      "2297:\tlearn: 2.2305373\ttotal: 28.6s\tremaining: 28.6s\n",
      "2298:\tlearn: 2.2300356\ttotal: 28.6s\tremaining: 28.6s\n",
      "2299:\tlearn: 2.2297543\ttotal: 28.6s\tremaining: 28.6s\n",
      "2300:\tlearn: 2.2293168\ttotal: 28.6s\tremaining: 28.6s\n",
      "2301:\tlearn: 2.2290990\ttotal: 28.6s\tremaining: 28.6s\n",
      "2302:\tlearn: 2.2282368\ttotal: 28.7s\tremaining: 28.6s\n",
      "2303:\tlearn: 2.2279687\ttotal: 28.7s\tremaining: 28.5s\n",
      "2304:\tlearn: 2.2275439\ttotal: 28.7s\tremaining: 28.5s\n",
      "2305:\tlearn: 2.2274100\ttotal: 28.7s\tremaining: 28.5s\n",
      "2306:\tlearn: 2.2268219\ttotal: 28.7s\tremaining: 28.5s\n",
      "2307:\tlearn: 2.2265442\ttotal: 28.7s\tremaining: 28.5s\n",
      "2308:\tlearn: 2.2263090\ttotal: 28.7s\tremaining: 28.5s\n",
      "2309:\tlearn: 2.2259269\ttotal: 28.7s\tremaining: 28.5s\n",
      "2310:\tlearn: 2.2257379\ttotal: 28.8s\tremaining: 28.5s\n",
      "2311:\tlearn: 2.2255116\ttotal: 28.8s\tremaining: 28.4s\n",
      "2312:\tlearn: 2.2253489\ttotal: 28.8s\tremaining: 28.4s\n",
      "2313:\tlearn: 2.2253341\ttotal: 28.8s\tremaining: 28.4s\n",
      "2314:\tlearn: 2.2249744\ttotal: 28.8s\tremaining: 28.4s\n",
      "2315:\tlearn: 2.2247152\ttotal: 28.8s\tremaining: 28.4s\n",
      "2316:\tlearn: 2.2244137\ttotal: 28.8s\tremaining: 28.4s\n",
      "2317:\tlearn: 2.2239698\ttotal: 28.8s\tremaining: 28.4s\n",
      "2318:\tlearn: 2.2236204\ttotal: 28.8s\tremaining: 28.3s\n",
      "2319:\tlearn: 2.2229605\ttotal: 28.9s\tremaining: 28.3s\n",
      "2320:\tlearn: 2.2226788\ttotal: 28.9s\tremaining: 28.3s\n",
      "2321:\tlearn: 2.2224106\ttotal: 28.9s\tremaining: 28.3s\n",
      "2322:\tlearn: 2.2220409\ttotal: 28.9s\tremaining: 28.3s\n",
      "2323:\tlearn: 2.2214172\ttotal: 28.9s\tremaining: 28.3s\n",
      "2324:\tlearn: 2.2212693\ttotal: 28.9s\tremaining: 28.3s\n",
      "2325:\tlearn: 2.2210530\ttotal: 28.9s\tremaining: 28.3s\n",
      "2326:\tlearn: 2.2206231\ttotal: 28.9s\tremaining: 28.3s\n",
      "2327:\tlearn: 2.2200334\ttotal: 29s\tremaining: 28.2s\n",
      "2328:\tlearn: 2.2198313\ttotal: 29s\tremaining: 28.2s\n",
      "2329:\tlearn: 2.2196906\ttotal: 29s\tremaining: 28.2s\n",
      "2330:\tlearn: 2.2193928\ttotal: 29s\tremaining: 28.2s\n",
      "2331:\tlearn: 2.2189947\ttotal: 29s\tremaining: 28.2s\n",
      "2332:\tlearn: 2.2185319\ttotal: 29s\tremaining: 28.2s\n",
      "2333:\tlearn: 2.2179672\ttotal: 29s\tremaining: 28.2s\n",
      "2334:\tlearn: 2.2177519\ttotal: 29s\tremaining: 28.1s\n",
      "2335:\tlearn: 2.2173441\ttotal: 29.1s\tremaining: 28.1s\n",
      "2336:\tlearn: 2.2173300\ttotal: 29.1s\tremaining: 28.1s\n",
      "2337:\tlearn: 2.2169050\ttotal: 29.1s\tremaining: 28.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2338:\tlearn: 2.2167121\ttotal: 29.1s\tremaining: 28.1s\n",
      "2339:\tlearn: 2.2163742\ttotal: 29.1s\tremaining: 28.1s\n",
      "2340:\tlearn: 2.2161933\ttotal: 29.1s\tremaining: 28.1s\n",
      "2341:\tlearn: 2.2154111\ttotal: 29.1s\tremaining: 28.1s\n",
      "2342:\tlearn: 2.2147919\ttotal: 29.1s\tremaining: 28s\n",
      "2343:\tlearn: 2.2141959\ttotal: 29.2s\tremaining: 28s\n",
      "2344:\tlearn: 2.2139643\ttotal: 29.2s\tremaining: 28s\n",
      "2345:\tlearn: 2.2136242\ttotal: 29.2s\tremaining: 28s\n",
      "2346:\tlearn: 2.2132007\ttotal: 29.2s\tremaining: 28s\n",
      "2347:\tlearn: 2.2128328\ttotal: 29.2s\tremaining: 28s\n",
      "2348:\tlearn: 2.2123580\ttotal: 29.2s\tremaining: 28s\n",
      "2349:\tlearn: 2.2121599\ttotal: 29.2s\tremaining: 28s\n",
      "2350:\tlearn: 2.2116385\ttotal: 29.2s\tremaining: 27.9s\n",
      "2351:\tlearn: 2.2112270\ttotal: 29.3s\tremaining: 27.9s\n",
      "2352:\tlearn: 2.2109002\ttotal: 29.3s\tremaining: 27.9s\n",
      "2353:\tlearn: 2.2104496\ttotal: 29.3s\tremaining: 27.9s\n",
      "2354:\tlearn: 2.2101866\ttotal: 29.3s\tremaining: 27.9s\n",
      "2355:\tlearn: 2.2098219\ttotal: 29.3s\tremaining: 27.9s\n",
      "2356:\tlearn: 2.2095121\ttotal: 29.3s\tremaining: 27.9s\n",
      "2357:\tlearn: 2.2091564\ttotal: 29.3s\tremaining: 27.9s\n",
      "2358:\tlearn: 2.2085944\ttotal: 29.3s\tremaining: 27.8s\n",
      "2359:\tlearn: 2.2082905\ttotal: 29.4s\tremaining: 27.8s\n",
      "2360:\tlearn: 2.2078741\ttotal: 29.4s\tremaining: 27.8s\n",
      "2361:\tlearn: 2.2076303\ttotal: 29.4s\tremaining: 27.8s\n",
      "2362:\tlearn: 2.2072518\ttotal: 29.4s\tremaining: 27.8s\n",
      "2363:\tlearn: 2.2068634\ttotal: 29.4s\tremaining: 27.8s\n",
      "2364:\tlearn: 2.2061971\ttotal: 29.4s\tremaining: 27.8s\n",
      "2365:\tlearn: 2.2061141\ttotal: 29.4s\tremaining: 27.8s\n",
      "2366:\tlearn: 2.2057986\ttotal: 29.4s\tremaining: 27.7s\n",
      "2367:\tlearn: 2.2056192\ttotal: 29.4s\tremaining: 27.7s\n",
      "2368:\tlearn: 2.2053615\ttotal: 29.5s\tremaining: 27.7s\n",
      "2369:\tlearn: 2.2051822\ttotal: 29.5s\tremaining: 27.7s\n",
      "2370:\tlearn: 2.2047331\ttotal: 29.5s\tremaining: 27.7s\n",
      "2371:\tlearn: 2.2044643\ttotal: 29.5s\tremaining: 27.7s\n",
      "2372:\tlearn: 2.2042669\ttotal: 29.5s\tremaining: 27.7s\n",
      "2373:\tlearn: 2.2040105\ttotal: 29.5s\tremaining: 27.7s\n",
      "2374:\tlearn: 2.2038181\ttotal: 29.5s\tremaining: 27.6s\n",
      "2375:\tlearn: 2.2035529\ttotal: 29.5s\tremaining: 27.6s\n",
      "2376:\tlearn: 2.2032214\ttotal: 29.6s\tremaining: 27.6s\n",
      "2377:\tlearn: 2.2028092\ttotal: 29.6s\tremaining: 27.6s\n",
      "2378:\tlearn: 2.2024580\ttotal: 29.6s\tremaining: 27.6s\n",
      "2379:\tlearn: 2.2022473\ttotal: 29.6s\tremaining: 27.6s\n",
      "2380:\tlearn: 2.2017475\ttotal: 29.6s\tremaining: 27.6s\n",
      "2381:\tlearn: 2.2014935\ttotal: 29.6s\tremaining: 27.6s\n",
      "2382:\tlearn: 2.2009686\ttotal: 29.6s\tremaining: 27.5s\n",
      "2383:\tlearn: 2.2008103\ttotal: 29.6s\tremaining: 27.5s\n",
      "2384:\tlearn: 2.2004820\ttotal: 29.7s\tremaining: 27.5s\n",
      "2385:\tlearn: 2.1996347\ttotal: 29.7s\tremaining: 27.5s\n",
      "2386:\tlearn: 2.1995154\ttotal: 29.7s\tremaining: 27.5s\n",
      "2387:\tlearn: 2.1991502\ttotal: 29.7s\tremaining: 27.5s\n",
      "2388:\tlearn: 2.1986018\ttotal: 29.7s\tremaining: 27.5s\n",
      "2389:\tlearn: 2.1981178\ttotal: 29.7s\tremaining: 27.4s\n",
      "2390:\tlearn: 2.1977993\ttotal: 29.7s\tremaining: 27.4s\n",
      "2391:\tlearn: 2.1973259\ttotal: 29.7s\tremaining: 27.4s\n",
      "2392:\tlearn: 2.1973051\ttotal: 29.8s\tremaining: 27.4s\n",
      "2393:\tlearn: 2.1971860\ttotal: 29.8s\tremaining: 27.4s\n",
      "2394:\tlearn: 2.1969542\ttotal: 29.8s\tremaining: 27.4s\n",
      "2395:\tlearn: 2.1967442\ttotal: 29.8s\tremaining: 27.4s\n",
      "2396:\tlearn: 2.1963780\ttotal: 29.8s\tremaining: 27.4s\n",
      "2397:\tlearn: 2.1959403\ttotal: 29.8s\tremaining: 27.4s\n",
      "2398:\tlearn: 2.1955411\ttotal: 29.8s\tremaining: 27.3s\n",
      "2399:\tlearn: 2.1950388\ttotal: 29.8s\tremaining: 27.3s\n",
      "2400:\tlearn: 2.1947614\ttotal: 29.8s\tremaining: 27.3s\n",
      "2401:\tlearn: 2.1946147\ttotal: 29.9s\tremaining: 27.3s\n",
      "2402:\tlearn: 2.1940493\ttotal: 29.9s\tremaining: 27.3s\n",
      "2403:\tlearn: 2.1938554\ttotal: 29.9s\tremaining: 27.3s\n",
      "2404:\tlearn: 2.1935177\ttotal: 29.9s\tremaining: 27.3s\n",
      "2405:\tlearn: 2.1930120\ttotal: 29.9s\tremaining: 27.2s\n",
      "2406:\tlearn: 2.1928739\ttotal: 29.9s\tremaining: 27.2s\n",
      "2407:\tlearn: 2.1923011\ttotal: 29.9s\tremaining: 27.2s\n",
      "2408:\tlearn: 2.1920308\ttotal: 29.9s\tremaining: 27.2s\n",
      "2409:\tlearn: 2.1917042\ttotal: 30s\tremaining: 27.2s\n",
      "2410:\tlearn: 2.1915342\ttotal: 30s\tremaining: 27.2s\n",
      "2411:\tlearn: 2.1913033\ttotal: 30s\tremaining: 27.2s\n",
      "2412:\tlearn: 2.1906982\ttotal: 30s\tremaining: 27.2s\n",
      "2413:\tlearn: 2.1903692\ttotal: 30s\tremaining: 27.1s\n",
      "2414:\tlearn: 2.1903558\ttotal: 30s\tremaining: 27.1s\n",
      "2415:\tlearn: 2.1900593\ttotal: 30s\tremaining: 27.1s\n",
      "2416:\tlearn: 2.1898116\ttotal: 30s\tremaining: 27.1s\n",
      "2417:\tlearn: 2.1893535\ttotal: 30s\tremaining: 27.1s\n",
      "2418:\tlearn: 2.1888413\ttotal: 30.1s\tremaining: 27.1s\n",
      "2419:\tlearn: 2.1884937\ttotal: 30.1s\tremaining: 27.1s\n",
      "2420:\tlearn: 2.1880353\ttotal: 30.1s\tremaining: 27.1s\n",
      "2421:\tlearn: 2.1877761\ttotal: 30.1s\tremaining: 27s\n",
      "2422:\tlearn: 2.1875208\ttotal: 30.1s\tremaining: 27s\n",
      "2423:\tlearn: 2.1871127\ttotal: 30.1s\tremaining: 27s\n",
      "2424:\tlearn: 2.1866753\ttotal: 30.1s\tremaining: 27s\n",
      "2425:\tlearn: 2.1862501\ttotal: 30.1s\tremaining: 27s\n",
      "2426:\tlearn: 2.1859504\ttotal: 30.2s\tremaining: 27s\n",
      "2427:\tlearn: 2.1854589\ttotal: 30.2s\tremaining: 27s\n",
      "2428:\tlearn: 2.1850110\ttotal: 30.2s\tremaining: 27s\n",
      "2429:\tlearn: 2.1847168\ttotal: 30.2s\tremaining: 26.9s\n",
      "2430:\tlearn: 2.1845072\ttotal: 30.2s\tremaining: 26.9s\n",
      "2431:\tlearn: 2.1842478\ttotal: 30.2s\tremaining: 26.9s\n",
      "2432:\tlearn: 2.1839102\ttotal: 30.2s\tremaining: 26.9s\n",
      "2433:\tlearn: 2.1834773\ttotal: 30.2s\tremaining: 26.9s\n",
      "2434:\tlearn: 2.1830904\ttotal: 30.3s\tremaining: 26.9s\n",
      "2435:\tlearn: 2.1827118\ttotal: 30.3s\tremaining: 26.9s\n",
      "2436:\tlearn: 2.1819728\ttotal: 30.3s\tremaining: 26.9s\n",
      "2437:\tlearn: 2.1814345\ttotal: 30.3s\tremaining: 26.8s\n",
      "2438:\tlearn: 2.1809605\ttotal: 30.3s\tremaining: 26.8s\n",
      "2439:\tlearn: 2.1808003\ttotal: 30.3s\tremaining: 26.8s\n",
      "2440:\tlearn: 2.1804039\ttotal: 30.3s\tremaining: 26.8s\n",
      "2441:\tlearn: 2.1801359\ttotal: 30.3s\tremaining: 26.8s\n",
      "2442:\tlearn: 2.1794933\ttotal: 30.4s\tremaining: 26.8s\n",
      "2443:\tlearn: 2.1791143\ttotal: 30.4s\tremaining: 26.8s\n",
      "2444:\tlearn: 2.1788031\ttotal: 30.4s\tremaining: 26.8s\n",
      "2445:\tlearn: 2.1784789\ttotal: 30.4s\tremaining: 26.7s\n",
      "2446:\tlearn: 2.1779660\ttotal: 30.4s\tremaining: 26.7s\n",
      "2447:\tlearn: 2.1774764\ttotal: 30.4s\tremaining: 26.7s\n",
      "2448:\tlearn: 2.1773089\ttotal: 30.4s\tremaining: 26.7s\n",
      "2449:\tlearn: 2.1770635\ttotal: 30.4s\tremaining: 26.7s\n",
      "2450:\tlearn: 2.1765477\ttotal: 30.5s\tremaining: 26.7s\n",
      "2451:\tlearn: 2.1761240\ttotal: 30.5s\tremaining: 26.7s\n",
      "2452:\tlearn: 2.1757686\ttotal: 30.5s\tremaining: 26.6s\n",
      "2453:\tlearn: 2.1754062\ttotal: 30.5s\tremaining: 26.6s\n",
      "2454:\tlearn: 2.1747652\ttotal: 30.5s\tremaining: 26.6s\n",
      "2455:\tlearn: 2.1744611\ttotal: 30.5s\tremaining: 26.6s\n",
      "2456:\tlearn: 2.1737801\ttotal: 30.5s\tremaining: 26.6s\n",
      "2457:\tlearn: 2.1733658\ttotal: 30.5s\tremaining: 26.6s\n",
      "2458:\tlearn: 2.1730285\ttotal: 30.6s\tremaining: 26.6s\n",
      "2459:\tlearn: 2.1725618\ttotal: 30.6s\tremaining: 26.6s\n",
      "2460:\tlearn: 2.1720966\ttotal: 30.6s\tremaining: 26.6s\n",
      "2461:\tlearn: 2.1716092\ttotal: 30.6s\tremaining: 26.5s\n",
      "2462:\tlearn: 2.1712885\ttotal: 30.6s\tremaining: 26.5s\n",
      "2463:\tlearn: 2.1709110\ttotal: 30.6s\tremaining: 26.5s\n",
      "2464:\tlearn: 2.1706129\ttotal: 30.6s\tremaining: 26.5s\n",
      "2465:\tlearn: 2.1701348\ttotal: 30.6s\tremaining: 26.5s\n",
      "2466:\tlearn: 2.1699275\ttotal: 30.6s\tremaining: 26.5s\n",
      "2467:\tlearn: 2.1691348\ttotal: 30.7s\tremaining: 26.5s\n",
      "2468:\tlearn: 2.1684136\ttotal: 30.7s\tremaining: 26.5s\n",
      "2469:\tlearn: 2.1680020\ttotal: 30.7s\tremaining: 26.4s\n",
      "2470:\tlearn: 2.1677616\ttotal: 30.7s\tremaining: 26.4s\n",
      "2471:\tlearn: 2.1673663\ttotal: 30.7s\tremaining: 26.4s\n",
      "2472:\tlearn: 2.1671474\ttotal: 30.7s\tremaining: 26.4s\n",
      "2473:\tlearn: 2.1667213\ttotal: 30.7s\tremaining: 26.4s\n",
      "2474:\tlearn: 2.1660226\ttotal: 30.7s\tremaining: 26.4s\n",
      "2475:\tlearn: 2.1657296\ttotal: 30.8s\tremaining: 26.4s\n",
      "2476:\tlearn: 2.1654788\ttotal: 30.8s\tremaining: 26.3s\n",
      "2477:\tlearn: 2.1652806\ttotal: 30.8s\tremaining: 26.3s\n",
      "2478:\tlearn: 2.1651589\ttotal: 30.8s\tremaining: 26.3s\n",
      "2479:\tlearn: 2.1649831\ttotal: 30.8s\tremaining: 26.3s\n",
      "2480:\tlearn: 2.1646234\ttotal: 30.8s\tremaining: 26.3s\n",
      "2481:\tlearn: 2.1646214\ttotal: 30.8s\tremaining: 26.3s\n",
      "2482:\tlearn: 2.1642935\ttotal: 30.8s\tremaining: 26.3s\n",
      "2483:\tlearn: 2.1641075\ttotal: 30.9s\tremaining: 26.3s\n",
      "2484:\tlearn: 2.1638249\ttotal: 30.9s\tremaining: 26.2s\n",
      "2485:\tlearn: 2.1635258\ttotal: 30.9s\tremaining: 26.2s\n",
      "2486:\tlearn: 2.1628977\ttotal: 30.9s\tremaining: 26.2s\n",
      "2487:\tlearn: 2.1626149\ttotal: 30.9s\tremaining: 26.2s\n",
      "2488:\tlearn: 2.1623914\ttotal: 30.9s\tremaining: 26.2s\n",
      "2489:\tlearn: 2.1621532\ttotal: 30.9s\tremaining: 26.2s\n",
      "2490:\tlearn: 2.1619314\ttotal: 30.9s\tremaining: 26.2s\n",
      "2491:\tlearn: 2.1614710\ttotal: 30.9s\tremaining: 26.2s\n",
      "2492:\tlearn: 2.1610640\ttotal: 31s\tremaining: 26.1s\n",
      "2493:\tlearn: 2.1608044\ttotal: 31s\tremaining: 26.1s\n",
      "2494:\tlearn: 2.1604440\ttotal: 31s\tremaining: 26.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2495:\tlearn: 2.1598345\ttotal: 31s\tremaining: 26.1s\n",
      "2496:\tlearn: 2.1595190\ttotal: 31s\tremaining: 26.1s\n",
      "2497:\tlearn: 2.1591472\ttotal: 31s\tremaining: 26.1s\n",
      "2498:\tlearn: 2.1585346\ttotal: 31s\tremaining: 26.1s\n",
      "2499:\tlearn: 2.1581962\ttotal: 31.1s\tremaining: 26.1s\n",
      "2500:\tlearn: 2.1575540\ttotal: 31.1s\tremaining: 26s\n",
      "2501:\tlearn: 2.1573329\ttotal: 31.1s\tremaining: 26s\n",
      "2502:\tlearn: 2.1571417\ttotal: 31.1s\tremaining: 26s\n",
      "2503:\tlearn: 2.1566413\ttotal: 31.1s\tremaining: 26s\n",
      "2504:\tlearn: 2.1562879\ttotal: 31.1s\tremaining: 26s\n",
      "2505:\tlearn: 2.1559526\ttotal: 31.1s\tremaining: 26s\n",
      "2506:\tlearn: 2.1555269\ttotal: 31.1s\tremaining: 26s\n",
      "2507:\tlearn: 2.1550889\ttotal: 31.2s\tremaining: 26s\n",
      "2508:\tlearn: 2.1545644\ttotal: 31.2s\tremaining: 25.9s\n",
      "2509:\tlearn: 2.1543458\ttotal: 31.2s\tremaining: 25.9s\n",
      "2510:\tlearn: 2.1539159\ttotal: 31.2s\tremaining: 25.9s\n",
      "2511:\tlearn: 2.1536437\ttotal: 31.2s\tremaining: 25.9s\n",
      "2512:\tlearn: 2.1532187\ttotal: 31.2s\tremaining: 25.9s\n",
      "2513:\tlearn: 2.1529376\ttotal: 31.2s\tremaining: 25.9s\n",
      "2514:\tlearn: 2.1522584\ttotal: 31.2s\tremaining: 25.9s\n",
      "2515:\tlearn: 2.1518881\ttotal: 31.3s\tremaining: 25.9s\n",
      "2516:\tlearn: 2.1516877\ttotal: 31.3s\tremaining: 25.9s\n",
      "2517:\tlearn: 2.1514075\ttotal: 31.3s\tremaining: 25.8s\n",
      "2518:\tlearn: 2.1510393\ttotal: 31.3s\tremaining: 25.8s\n",
      "2519:\tlearn: 2.1507924\ttotal: 31.3s\tremaining: 25.8s\n",
      "2520:\tlearn: 2.1505762\ttotal: 31.3s\tremaining: 25.8s\n",
      "2521:\tlearn: 2.1503169\ttotal: 31.3s\tremaining: 25.8s\n",
      "2522:\tlearn: 2.1497487\ttotal: 31.3s\tremaining: 25.8s\n",
      "2523:\tlearn: 2.1495569\ttotal: 31.4s\tremaining: 25.8s\n",
      "2524:\tlearn: 2.1491963\ttotal: 31.4s\tremaining: 25.7s\n",
      "2525:\tlearn: 2.1488525\ttotal: 31.4s\tremaining: 25.7s\n",
      "2526:\tlearn: 2.1485589\ttotal: 31.4s\tremaining: 25.7s\n",
      "2527:\tlearn: 2.1483548\ttotal: 31.4s\tremaining: 25.7s\n",
      "2528:\tlearn: 2.1480127\ttotal: 31.4s\tremaining: 25.7s\n",
      "2529:\tlearn: 2.1477171\ttotal: 31.4s\tremaining: 25.7s\n",
      "2530:\tlearn: 2.1471250\ttotal: 31.4s\tremaining: 25.7s\n",
      "2531:\tlearn: 2.1467840\ttotal: 31.5s\tremaining: 25.7s\n",
      "2532:\tlearn: 2.1465999\ttotal: 31.5s\tremaining: 25.6s\n",
      "2533:\tlearn: 2.1460148\ttotal: 31.5s\tremaining: 25.6s\n",
      "2534:\tlearn: 2.1457746\ttotal: 31.5s\tremaining: 25.6s\n",
      "2535:\tlearn: 2.1451719\ttotal: 31.5s\tremaining: 25.6s\n",
      "2536:\tlearn: 2.1448079\ttotal: 31.5s\tremaining: 25.6s\n",
      "2537:\tlearn: 2.1442665\ttotal: 31.5s\tremaining: 25.6s\n",
      "2538:\tlearn: 2.1439416\ttotal: 31.5s\tremaining: 25.6s\n",
      "2539:\tlearn: 2.1437089\ttotal: 31.5s\tremaining: 25.6s\n",
      "2540:\tlearn: 2.1431124\ttotal: 31.6s\tremaining: 25.6s\n",
      "2541:\tlearn: 2.1426284\ttotal: 31.6s\tremaining: 25.5s\n",
      "2542:\tlearn: 2.1421996\ttotal: 31.6s\tremaining: 25.5s\n",
      "2543:\tlearn: 2.1417238\ttotal: 31.6s\tremaining: 25.5s\n",
      "2544:\tlearn: 2.1415597\ttotal: 31.6s\tremaining: 25.5s\n",
      "2545:\tlearn: 2.1410757\ttotal: 31.6s\tremaining: 25.5s\n",
      "2546:\tlearn: 2.1407136\ttotal: 31.6s\tremaining: 25.5s\n",
      "2547:\tlearn: 2.1400576\ttotal: 31.6s\tremaining: 25.5s\n",
      "2548:\tlearn: 2.1393943\ttotal: 31.7s\tremaining: 25.5s\n",
      "2549:\tlearn: 2.1389953\ttotal: 31.7s\tremaining: 25.4s\n",
      "2550:\tlearn: 2.1383227\ttotal: 31.7s\tremaining: 25.4s\n",
      "2551:\tlearn: 2.1379255\ttotal: 31.7s\tremaining: 25.4s\n",
      "2552:\tlearn: 2.1378149\ttotal: 31.7s\tremaining: 25.4s\n",
      "2553:\tlearn: 2.1373512\ttotal: 31.7s\tremaining: 25.4s\n",
      "2554:\tlearn: 2.1370839\ttotal: 31.7s\tremaining: 25.4s\n",
      "2555:\tlearn: 2.1366060\ttotal: 31.7s\tremaining: 25.4s\n",
      "2556:\tlearn: 2.1361162\ttotal: 31.8s\tremaining: 25.4s\n",
      "2557:\tlearn: 2.1357056\ttotal: 31.8s\tremaining: 25.3s\n",
      "2558:\tlearn: 2.1353722\ttotal: 31.8s\tremaining: 25.3s\n",
      "2559:\tlearn: 2.1345845\ttotal: 31.8s\tremaining: 25.3s\n",
      "2560:\tlearn: 2.1340320\ttotal: 31.8s\tremaining: 25.3s\n",
      "2561:\tlearn: 2.1337992\ttotal: 31.8s\tremaining: 25.3s\n",
      "2562:\tlearn: 2.1334573\ttotal: 31.8s\tremaining: 25.3s\n",
      "2563:\tlearn: 2.1332653\ttotal: 31.8s\tremaining: 25.3s\n",
      "2564:\tlearn: 2.1330879\ttotal: 31.9s\tremaining: 25.3s\n",
      "2565:\tlearn: 2.1328408\ttotal: 31.9s\tremaining: 25.2s\n",
      "2566:\tlearn: 2.1326718\ttotal: 31.9s\tremaining: 25.2s\n",
      "2567:\tlearn: 2.1323915\ttotal: 31.9s\tremaining: 25.2s\n",
      "2568:\tlearn: 2.1321155\ttotal: 31.9s\tremaining: 25.2s\n",
      "2569:\tlearn: 2.1316924\ttotal: 31.9s\tremaining: 25.2s\n",
      "2570:\tlearn: 2.1311145\ttotal: 31.9s\tremaining: 25.2s\n",
      "2571:\tlearn: 2.1306706\ttotal: 31.9s\tremaining: 25.2s\n",
      "2572:\tlearn: 2.1304070\ttotal: 32s\tremaining: 25.2s\n",
      "2573:\tlearn: 2.1300076\ttotal: 32s\tremaining: 25.1s\n",
      "2574:\tlearn: 2.1297821\ttotal: 32s\tremaining: 25.1s\n",
      "2575:\tlearn: 2.1294808\ttotal: 32s\tremaining: 25.1s\n",
      "2576:\tlearn: 2.1292154\ttotal: 32s\tremaining: 25.1s\n",
      "2577:\tlearn: 2.1288111\ttotal: 32s\tremaining: 25.1s\n",
      "2578:\tlearn: 2.1282409\ttotal: 32s\tremaining: 25.1s\n",
      "2579:\tlearn: 2.1280487\ttotal: 32s\tremaining: 25.1s\n",
      "2580:\tlearn: 2.1277030\ttotal: 32.1s\tremaining: 25.1s\n",
      "2581:\tlearn: 2.1274165\ttotal: 32.1s\tremaining: 25s\n",
      "2582:\tlearn: 2.1271778\ttotal: 32.1s\tremaining: 25s\n",
      "2583:\tlearn: 2.1269924\ttotal: 32.1s\tremaining: 25s\n",
      "2584:\tlearn: 2.1267376\ttotal: 32.1s\tremaining: 25s\n",
      "2585:\tlearn: 2.1262540\ttotal: 32.1s\tremaining: 25s\n",
      "2586:\tlearn: 2.1258805\ttotal: 32.1s\tremaining: 25s\n",
      "2587:\tlearn: 2.1255036\ttotal: 32.1s\tremaining: 25s\n",
      "2588:\tlearn: 2.1251410\ttotal: 32.2s\tremaining: 25s\n",
      "2589:\tlearn: 2.1249433\ttotal: 32.2s\tremaining: 24.9s\n",
      "2590:\tlearn: 2.1244696\ttotal: 32.2s\tremaining: 24.9s\n",
      "2591:\tlearn: 2.1241213\ttotal: 32.2s\tremaining: 24.9s\n",
      "2592:\tlearn: 2.1239053\ttotal: 32.2s\tremaining: 24.9s\n",
      "2593:\tlearn: 2.1231812\ttotal: 32.2s\tremaining: 24.9s\n",
      "2594:\tlearn: 2.1229413\ttotal: 32.2s\tremaining: 24.9s\n",
      "2595:\tlearn: 2.1224055\ttotal: 32.2s\tremaining: 24.9s\n",
      "2596:\tlearn: 2.1218594\ttotal: 32.3s\tremaining: 24.9s\n",
      "2597:\tlearn: 2.1216582\ttotal: 32.3s\tremaining: 24.8s\n",
      "2598:\tlearn: 2.1210270\ttotal: 32.3s\tremaining: 24.8s\n",
      "2599:\tlearn: 2.1205275\ttotal: 32.3s\tremaining: 24.8s\n",
      "2600:\tlearn: 2.1203203\ttotal: 32.3s\tremaining: 24.8s\n",
      "2601:\tlearn: 2.1198647\ttotal: 32.3s\tremaining: 24.8s\n",
      "2602:\tlearn: 2.1193874\ttotal: 32.3s\tremaining: 24.8s\n",
      "2603:\tlearn: 2.1191364\ttotal: 32.3s\tremaining: 24.8s\n",
      "2604:\tlearn: 2.1188195\ttotal: 32.4s\tremaining: 24.8s\n",
      "2605:\tlearn: 2.1185106\ttotal: 32.4s\tremaining: 24.7s\n",
      "2606:\tlearn: 2.1180215\ttotal: 32.4s\tremaining: 24.7s\n",
      "2607:\tlearn: 2.1174571\ttotal: 32.4s\tremaining: 24.7s\n",
      "2608:\tlearn: 2.1172009\ttotal: 32.4s\tremaining: 24.7s\n",
      "2609:\tlearn: 2.1167790\ttotal: 32.4s\tremaining: 24.7s\n",
      "2610:\tlearn: 2.1162227\ttotal: 32.4s\tremaining: 24.7s\n",
      "2611:\tlearn: 2.1160361\ttotal: 32.4s\tremaining: 24.7s\n",
      "2612:\tlearn: 2.1155201\ttotal: 32.5s\tremaining: 24.7s\n",
      "2613:\tlearn: 2.1150911\ttotal: 32.5s\tremaining: 24.6s\n",
      "2614:\tlearn: 2.1145501\ttotal: 32.5s\tremaining: 24.6s\n",
      "2615:\tlearn: 2.1143277\ttotal: 32.5s\tremaining: 24.6s\n",
      "2616:\tlearn: 2.1136886\ttotal: 32.5s\tremaining: 24.6s\n",
      "2617:\tlearn: 2.1131167\ttotal: 32.5s\tremaining: 24.6s\n",
      "2618:\tlearn: 2.1127120\ttotal: 32.5s\tremaining: 24.6s\n",
      "2619:\tlearn: 2.1124232\ttotal: 32.5s\tremaining: 24.6s\n",
      "2620:\tlearn: 2.1123141\ttotal: 32.6s\tremaining: 24.6s\n",
      "2621:\tlearn: 2.1120922\ttotal: 32.6s\tremaining: 24.5s\n",
      "2622:\tlearn: 2.1117486\ttotal: 32.6s\tremaining: 24.5s\n",
      "2623:\tlearn: 2.1112417\ttotal: 32.6s\tremaining: 24.5s\n",
      "2624:\tlearn: 2.1109970\ttotal: 32.6s\tremaining: 24.5s\n",
      "2625:\tlearn: 2.1108245\ttotal: 32.6s\tremaining: 24.5s\n",
      "2626:\tlearn: 2.1102632\ttotal: 32.6s\tremaining: 24.5s\n",
      "2627:\tlearn: 2.1100890\ttotal: 32.6s\tremaining: 24.5s\n",
      "2628:\tlearn: 2.1096594\ttotal: 32.6s\tremaining: 24.5s\n",
      "2629:\tlearn: 2.1093616\ttotal: 32.7s\tremaining: 24.4s\n",
      "2630:\tlearn: 2.1093577\ttotal: 32.7s\tremaining: 24.4s\n",
      "2631:\tlearn: 2.1091032\ttotal: 32.7s\tremaining: 24.4s\n",
      "2632:\tlearn: 2.1088723\ttotal: 32.7s\tremaining: 24.4s\n",
      "2633:\tlearn: 2.1085555\ttotal: 32.7s\tremaining: 24.4s\n",
      "2634:\tlearn: 2.1082236\ttotal: 32.7s\tremaining: 24.4s\n",
      "2635:\tlearn: 2.1079508\ttotal: 32.7s\tremaining: 24.4s\n",
      "2636:\tlearn: 2.1075891\ttotal: 32.7s\tremaining: 24.4s\n",
      "2637:\tlearn: 2.1072811\ttotal: 32.8s\tremaining: 24.3s\n",
      "2638:\tlearn: 2.1069985\ttotal: 32.8s\tremaining: 24.3s\n",
      "2639:\tlearn: 2.1066447\ttotal: 32.8s\tremaining: 24.3s\n",
      "2640:\tlearn: 2.1063137\ttotal: 32.8s\tremaining: 24.3s\n",
      "2641:\tlearn: 2.1060987\ttotal: 32.8s\tremaining: 24.3s\n",
      "2642:\tlearn: 2.1058126\ttotal: 32.8s\tremaining: 24.3s\n",
      "2643:\tlearn: 2.1053536\ttotal: 32.8s\tremaining: 24.3s\n",
      "2644:\tlearn: 2.1052190\ttotal: 32.8s\tremaining: 24.3s\n",
      "2645:\tlearn: 2.1048233\ttotal: 32.9s\tremaining: 24.2s\n",
      "2646:\tlearn: 2.1044114\ttotal: 32.9s\tremaining: 24.2s\n",
      "2647:\tlearn: 2.1041367\ttotal: 32.9s\tremaining: 24.2s\n",
      "2648:\tlearn: 2.1038546\ttotal: 32.9s\tremaining: 24.2s\n",
      "2649:\tlearn: 2.1033943\ttotal: 32.9s\tremaining: 24.2s\n",
      "2650:\tlearn: 2.1031291\ttotal: 32.9s\tremaining: 24.2s\n",
      "2651:\tlearn: 2.1031280\ttotal: 32.9s\tremaining: 24.2s\n",
      "2652:\tlearn: 2.1030559\ttotal: 32.9s\tremaining: 24.2s\n",
      "2653:\tlearn: 2.1028016\ttotal: 33s\tremaining: 24.1s\n",
      "2654:\tlearn: 2.1027159\ttotal: 33s\tremaining: 24.1s\n",
      "2655:\tlearn: 2.1024161\ttotal: 33s\tremaining: 24.1s\n",
      "2656:\tlearn: 2.1021135\ttotal: 33s\tremaining: 24.1s\n",
      "2657:\tlearn: 2.1019073\ttotal: 33s\tremaining: 24.1s\n",
      "2658:\tlearn: 2.1012289\ttotal: 33s\tremaining: 24.1s\n",
      "2659:\tlearn: 2.1010369\ttotal: 33s\tremaining: 24.1s\n",
      "2660:\tlearn: 2.1008680\ttotal: 33s\tremaining: 24s\n",
      "2661:\tlearn: 2.1006099\ttotal: 33s\tremaining: 24s\n",
      "2662:\tlearn: 2.1002338\ttotal: 33.1s\tremaining: 24s\n",
      "2663:\tlearn: 2.0998192\ttotal: 33.1s\tremaining: 24s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2664:\tlearn: 2.0998169\ttotal: 33.1s\tremaining: 24s\n",
      "2665:\tlearn: 2.0993137\ttotal: 33.1s\tremaining: 24s\n",
      "2666:\tlearn: 2.0989867\ttotal: 33.1s\tremaining: 24s\n",
      "2667:\tlearn: 2.0986318\ttotal: 33.1s\tremaining: 24s\n",
      "2668:\tlearn: 2.0982537\ttotal: 33.1s\tremaining: 23.9s\n",
      "2669:\tlearn: 2.0978679\ttotal: 33.1s\tremaining: 23.9s\n",
      "2670:\tlearn: 2.0977843\ttotal: 33.2s\tremaining: 23.9s\n",
      "2671:\tlearn: 2.0975425\ttotal: 33.2s\tremaining: 23.9s\n",
      "2672:\tlearn: 2.0972797\ttotal: 33.2s\tremaining: 23.9s\n",
      "2673:\tlearn: 2.0968579\ttotal: 33.2s\tremaining: 23.9s\n",
      "2674:\tlearn: 2.0964944\ttotal: 33.2s\tremaining: 23.9s\n",
      "2675:\tlearn: 2.0962796\ttotal: 33.2s\tremaining: 23.9s\n",
      "2676:\tlearn: 2.0958377\ttotal: 33.2s\tremaining: 23.8s\n",
      "2677:\tlearn: 2.0955467\ttotal: 33.2s\tremaining: 23.8s\n",
      "2678:\tlearn: 2.0949688\ttotal: 33.3s\tremaining: 23.8s\n",
      "2679:\tlearn: 2.0945629\ttotal: 33.3s\tremaining: 23.8s\n",
      "2680:\tlearn: 2.0943999\ttotal: 33.3s\tremaining: 23.8s\n",
      "2681:\tlearn: 2.0939018\ttotal: 33.3s\tremaining: 23.8s\n",
      "2682:\tlearn: 2.0937854\ttotal: 33.3s\tremaining: 23.8s\n",
      "2683:\tlearn: 2.0936027\ttotal: 33.3s\tremaining: 23.8s\n",
      "2684:\tlearn: 2.0931548\ttotal: 33.3s\tremaining: 23.7s\n",
      "2685:\tlearn: 2.0927852\ttotal: 33.3s\tremaining: 23.7s\n",
      "2686:\tlearn: 2.0924507\ttotal: 33.4s\tremaining: 23.7s\n",
      "2687:\tlearn: 2.0920999\ttotal: 33.4s\tremaining: 23.7s\n",
      "2688:\tlearn: 2.0918333\ttotal: 33.4s\tremaining: 23.7s\n",
      "2689:\tlearn: 2.0914473\ttotal: 33.4s\tremaining: 23.7s\n",
      "2690:\tlearn: 2.0910897\ttotal: 33.4s\tremaining: 23.7s\n",
      "2691:\tlearn: 2.0906545\ttotal: 33.4s\tremaining: 23.7s\n",
      "2692:\tlearn: 2.0904311\ttotal: 33.4s\tremaining: 23.6s\n",
      "2693:\tlearn: 2.0898451\ttotal: 33.4s\tremaining: 23.6s\n",
      "2694:\tlearn: 2.0894829\ttotal: 33.5s\tremaining: 23.6s\n",
      "2695:\tlearn: 2.0892935\ttotal: 33.5s\tremaining: 23.6s\n",
      "2696:\tlearn: 2.0890589\ttotal: 33.5s\tremaining: 23.6s\n",
      "2697:\tlearn: 2.0888013\ttotal: 33.5s\tremaining: 23.6s\n",
      "2698:\tlearn: 2.0884647\ttotal: 33.5s\tremaining: 23.6s\n",
      "2699:\tlearn: 2.0881466\ttotal: 33.5s\tremaining: 23.6s\n",
      "2700:\tlearn: 2.0876260\ttotal: 33.5s\tremaining: 23.6s\n",
      "2701:\tlearn: 2.0871880\ttotal: 33.5s\tremaining: 23.5s\n",
      "2702:\tlearn: 2.0868520\ttotal: 33.6s\tremaining: 23.5s\n",
      "2703:\tlearn: 2.0864116\ttotal: 33.6s\tremaining: 23.5s\n",
      "2704:\tlearn: 2.0860823\ttotal: 33.6s\tremaining: 23.5s\n",
      "2705:\tlearn: 2.0856325\ttotal: 33.6s\tremaining: 23.5s\n",
      "2706:\tlearn: 2.0850176\ttotal: 33.6s\tremaining: 23.5s\n",
      "2707:\tlearn: 2.0846576\ttotal: 33.6s\tremaining: 23.5s\n",
      "2708:\tlearn: 2.0844170\ttotal: 33.6s\tremaining: 23.5s\n",
      "2709:\tlearn: 2.0841914\ttotal: 33.6s\tremaining: 23.4s\n",
      "2710:\tlearn: 2.0837665\ttotal: 33.7s\tremaining: 23.4s\n",
      "2711:\tlearn: 2.0833341\ttotal: 33.7s\tremaining: 23.4s\n",
      "2712:\tlearn: 2.0827200\ttotal: 33.7s\tremaining: 23.4s\n",
      "2713:\tlearn: 2.0824335\ttotal: 33.7s\tremaining: 23.4s\n",
      "2714:\tlearn: 2.0819860\ttotal: 33.7s\tremaining: 23.4s\n",
      "2715:\tlearn: 2.0817672\ttotal: 33.7s\tremaining: 23.4s\n",
      "2716:\tlearn: 2.0814569\ttotal: 33.7s\tremaining: 23.4s\n",
      "2717:\tlearn: 2.0811923\ttotal: 33.7s\tremaining: 23.3s\n",
      "2718:\tlearn: 2.0806428\ttotal: 33.8s\tremaining: 23.3s\n",
      "2719:\tlearn: 2.0803562\ttotal: 33.8s\tremaining: 23.3s\n",
      "2720:\tlearn: 2.0801592\ttotal: 33.8s\tremaining: 23.3s\n",
      "2721:\tlearn: 2.0799331\ttotal: 33.8s\tremaining: 23.3s\n",
      "2722:\tlearn: 2.0798035\ttotal: 33.8s\tremaining: 23.3s\n",
      "2723:\tlearn: 2.0795153\ttotal: 33.8s\tremaining: 23.3s\n",
      "2724:\tlearn: 2.0793863\ttotal: 33.8s\tremaining: 23.3s\n",
      "2725:\tlearn: 2.0788923\ttotal: 33.8s\tremaining: 23.2s\n",
      "2726:\tlearn: 2.0784358\ttotal: 33.9s\tremaining: 23.2s\n",
      "2727:\tlearn: 2.0781191\ttotal: 33.9s\tremaining: 23.2s\n",
      "2728:\tlearn: 2.0778332\ttotal: 33.9s\tremaining: 23.2s\n",
      "2729:\tlearn: 2.0777038\ttotal: 33.9s\tremaining: 23.2s\n",
      "2730:\tlearn: 2.0774997\ttotal: 33.9s\tremaining: 23.2s\n",
      "2731:\tlearn: 2.0771706\ttotal: 33.9s\tremaining: 23.2s\n",
      "2732:\tlearn: 2.0767782\ttotal: 33.9s\tremaining: 23.2s\n",
      "2733:\tlearn: 2.0764196\ttotal: 33.9s\tremaining: 23.1s\n",
      "2734:\tlearn: 2.0759826\ttotal: 34s\tremaining: 23.1s\n",
      "2735:\tlearn: 2.0756456\ttotal: 34s\tremaining: 23.1s\n",
      "2736:\tlearn: 2.0754231\ttotal: 34s\tremaining: 23.1s\n",
      "2737:\tlearn: 2.0751691\ttotal: 34s\tremaining: 23.1s\n",
      "2738:\tlearn: 2.0748837\ttotal: 34s\tremaining: 23.1s\n",
      "2739:\tlearn: 2.0743712\ttotal: 34s\tremaining: 23.1s\n",
      "2740:\tlearn: 2.0741846\ttotal: 34s\tremaining: 23.1s\n",
      "2741:\tlearn: 2.0739226\ttotal: 34s\tremaining: 23s\n",
      "2742:\tlearn: 2.0734700\ttotal: 34.1s\tremaining: 23s\n",
      "2743:\tlearn: 2.0730637\ttotal: 34.1s\tremaining: 23s\n",
      "2744:\tlearn: 2.0727368\ttotal: 34.1s\tremaining: 23s\n",
      "2745:\tlearn: 2.0725869\ttotal: 34.1s\tremaining: 23s\n",
      "2746:\tlearn: 2.0722123\ttotal: 34.1s\tremaining: 23s\n",
      "2747:\tlearn: 2.0717713\ttotal: 34.1s\tremaining: 23s\n",
      "2748:\tlearn: 2.0713484\ttotal: 34.1s\tremaining: 23s\n",
      "2749:\tlearn: 2.0710453\ttotal: 34.1s\tremaining: 22.9s\n",
      "2750:\tlearn: 2.0708197\ttotal: 34.2s\tremaining: 22.9s\n",
      "2751:\tlearn: 2.0705164\ttotal: 34.2s\tremaining: 22.9s\n",
      "2752:\tlearn: 2.0703138\ttotal: 34.2s\tremaining: 22.9s\n",
      "2753:\tlearn: 2.0699162\ttotal: 34.2s\tremaining: 22.9s\n",
      "2754:\tlearn: 2.0694592\ttotal: 34.2s\tremaining: 22.9s\n",
      "2755:\tlearn: 2.0691807\ttotal: 34.2s\tremaining: 22.9s\n",
      "2756:\tlearn: 2.0688942\ttotal: 34.2s\tremaining: 22.9s\n",
      "2757:\tlearn: 2.0685256\ttotal: 34.2s\tremaining: 22.8s\n",
      "2758:\tlearn: 2.0680299\ttotal: 34.3s\tremaining: 22.8s\n",
      "2759:\tlearn: 2.0678807\ttotal: 34.3s\tremaining: 22.8s\n",
      "2760:\tlearn: 2.0674774\ttotal: 34.3s\tremaining: 22.8s\n",
      "2761:\tlearn: 2.0671505\ttotal: 34.3s\tremaining: 22.8s\n",
      "2762:\tlearn: 2.0669837\ttotal: 34.3s\tremaining: 22.8s\n",
      "2763:\tlearn: 2.0666074\ttotal: 34.3s\tremaining: 22.8s\n",
      "2764:\tlearn: 2.0662017\ttotal: 34.3s\tremaining: 22.8s\n",
      "2765:\tlearn: 2.0658448\ttotal: 34.3s\tremaining: 22.7s\n",
      "2766:\tlearn: 2.0655827\ttotal: 34.4s\tremaining: 22.7s\n",
      "2767:\tlearn: 2.0653930\ttotal: 34.4s\tremaining: 22.7s\n",
      "2768:\tlearn: 2.0652470\ttotal: 34.4s\tremaining: 22.7s\n",
      "2769:\tlearn: 2.0649628\ttotal: 34.4s\tremaining: 22.7s\n",
      "2770:\tlearn: 2.0645024\ttotal: 34.4s\tremaining: 22.7s\n",
      "2771:\tlearn: 2.0641038\ttotal: 34.4s\tremaining: 22.7s\n",
      "2772:\tlearn: 2.0637859\ttotal: 34.4s\tremaining: 22.7s\n",
      "2773:\tlearn: 2.0634491\ttotal: 34.4s\tremaining: 22.6s\n",
      "2774:\tlearn: 2.0631425\ttotal: 34.5s\tremaining: 22.6s\n",
      "2775:\tlearn: 2.0628590\ttotal: 34.5s\tremaining: 22.6s\n",
      "2776:\tlearn: 2.0625152\ttotal: 34.5s\tremaining: 22.6s\n",
      "2777:\tlearn: 2.0622631\ttotal: 34.5s\tremaining: 22.6s\n",
      "2778:\tlearn: 2.0617812\ttotal: 34.5s\tremaining: 22.6s\n",
      "2779:\tlearn: 2.0611870\ttotal: 34.5s\tremaining: 22.6s\n",
      "2780:\tlearn: 2.0606615\ttotal: 34.5s\tremaining: 22.6s\n",
      "2781:\tlearn: 2.0605616\ttotal: 34.5s\tremaining: 22.5s\n",
      "2782:\tlearn: 2.0602037\ttotal: 34.5s\tremaining: 22.5s\n",
      "2783:\tlearn: 2.0598516\ttotal: 34.6s\tremaining: 22.5s\n",
      "2784:\tlearn: 2.0595786\ttotal: 34.6s\tremaining: 22.5s\n",
      "2785:\tlearn: 2.0593757\ttotal: 34.6s\tremaining: 22.5s\n",
      "2786:\tlearn: 2.0591475\ttotal: 34.6s\tremaining: 22.5s\n",
      "2787:\tlearn: 2.0588819\ttotal: 34.6s\tremaining: 22.5s\n",
      "2788:\tlearn: 2.0585411\ttotal: 34.6s\tremaining: 22.5s\n",
      "2789:\tlearn: 2.0583759\ttotal: 34.6s\tremaining: 22.4s\n",
      "2790:\tlearn: 2.0582454\ttotal: 34.6s\tremaining: 22.4s\n",
      "2791:\tlearn: 2.0578879\ttotal: 34.7s\tremaining: 22.4s\n",
      "2792:\tlearn: 2.0573902\ttotal: 34.7s\tremaining: 22.4s\n",
      "2793:\tlearn: 2.0566485\ttotal: 34.7s\tremaining: 22.4s\n",
      "2794:\tlearn: 2.0561744\ttotal: 34.7s\tremaining: 22.4s\n",
      "2795:\tlearn: 2.0559594\ttotal: 34.7s\tremaining: 22.4s\n",
      "2796:\tlearn: 2.0556705\ttotal: 34.7s\tremaining: 22.4s\n",
      "2797:\tlearn: 2.0554276\ttotal: 34.7s\tremaining: 22.3s\n",
      "2798:\tlearn: 2.0551408\ttotal: 34.7s\tremaining: 22.3s\n",
      "2799:\tlearn: 2.0547802\ttotal: 34.8s\tremaining: 22.3s\n",
      "2800:\tlearn: 2.0544152\ttotal: 34.8s\tremaining: 22.3s\n",
      "2801:\tlearn: 2.0540822\ttotal: 34.8s\tremaining: 22.3s\n",
      "2802:\tlearn: 2.0537072\ttotal: 34.8s\tremaining: 22.3s\n",
      "2803:\tlearn: 2.0531900\ttotal: 34.8s\tremaining: 22.3s\n",
      "2804:\tlearn: 2.0527634\ttotal: 34.8s\tremaining: 22.3s\n",
      "2805:\tlearn: 2.0523783\ttotal: 34.8s\tremaining: 22.2s\n",
      "2806:\tlearn: 2.0521733\ttotal: 34.8s\tremaining: 22.2s\n",
      "2807:\tlearn: 2.0519656\ttotal: 34.9s\tremaining: 22.2s\n",
      "2808:\tlearn: 2.0517314\ttotal: 34.9s\tremaining: 22.2s\n",
      "2809:\tlearn: 2.0513669\ttotal: 34.9s\tremaining: 22.2s\n",
      "2810:\tlearn: 2.0512219\ttotal: 34.9s\tremaining: 22.2s\n",
      "2811:\tlearn: 2.0505885\ttotal: 34.9s\tremaining: 22.2s\n",
      "2812:\tlearn: 2.0502267\ttotal: 34.9s\tremaining: 22.2s\n",
      "2813:\tlearn: 2.0499209\ttotal: 34.9s\tremaining: 22.1s\n",
      "2814:\tlearn: 2.0493647\ttotal: 34.9s\tremaining: 22.1s\n",
      "2815:\tlearn: 2.0491535\ttotal: 35s\tremaining: 22.1s\n",
      "2816:\tlearn: 2.0488381\ttotal: 35s\tremaining: 22.1s\n",
      "2817:\tlearn: 2.0485996\ttotal: 35s\tremaining: 22.1s\n",
      "2818:\tlearn: 2.0483278\ttotal: 35s\tremaining: 22.1s\n",
      "2819:\tlearn: 2.0480670\ttotal: 35s\tremaining: 22.1s\n",
      "2820:\tlearn: 2.0479646\ttotal: 35s\tremaining: 22.1s\n",
      "2821:\tlearn: 2.0477264\ttotal: 35s\tremaining: 22s\n",
      "2822:\tlearn: 2.0474139\ttotal: 35s\tremaining: 22s\n",
      "2823:\tlearn: 2.0469585\ttotal: 35.1s\tremaining: 22s\n",
      "2824:\tlearn: 2.0468350\ttotal: 35.1s\tremaining: 22s\n",
      "2825:\tlearn: 2.0464707\ttotal: 35.1s\tremaining: 22s\n",
      "2826:\tlearn: 2.0462174\ttotal: 35.1s\tremaining: 22s\n",
      "2827:\tlearn: 2.0460757\ttotal: 35.1s\tremaining: 22s\n",
      "2828:\tlearn: 2.0457160\ttotal: 35.1s\tremaining: 22s\n",
      "2829:\tlearn: 2.0453350\ttotal: 35.1s\tremaining: 21.9s\n",
      "2830:\tlearn: 2.0450106\ttotal: 35.1s\tremaining: 21.9s\n",
      "2831:\tlearn: 2.0449715\ttotal: 35.1s\tremaining: 21.9s\n",
      "2832:\tlearn: 2.0444479\ttotal: 35.2s\tremaining: 21.9s\n",
      "2833:\tlearn: 2.0442918\ttotal: 35.2s\tremaining: 21.9s\n",
      "2834:\tlearn: 2.0439168\ttotal: 35.2s\tremaining: 21.9s\n",
      "2835:\tlearn: 2.0435547\ttotal: 35.2s\tremaining: 21.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2836:\tlearn: 2.0432888\ttotal: 35.2s\tremaining: 21.9s\n",
      "2837:\tlearn: 2.0428496\ttotal: 35.2s\tremaining: 21.8s\n",
      "2838:\tlearn: 2.0423501\ttotal: 35.2s\tremaining: 21.8s\n",
      "2839:\tlearn: 2.0420987\ttotal: 35.2s\tremaining: 21.8s\n",
      "2840:\tlearn: 2.0415571\ttotal: 35.3s\tremaining: 21.8s\n",
      "2841:\tlearn: 2.0413144\ttotal: 35.3s\tremaining: 21.8s\n",
      "2842:\tlearn: 2.0408151\ttotal: 35.3s\tremaining: 21.8s\n",
      "2843:\tlearn: 2.0405430\ttotal: 35.3s\tremaining: 21.8s\n",
      "2844:\tlearn: 2.0404234\ttotal: 35.3s\tremaining: 21.8s\n",
      "2845:\tlearn: 2.0402940\ttotal: 35.3s\tremaining: 21.7s\n",
      "2846:\tlearn: 2.0399061\ttotal: 35.3s\tremaining: 21.7s\n",
      "2847:\tlearn: 2.0396451\ttotal: 35.3s\tremaining: 21.7s\n",
      "2848:\tlearn: 2.0393463\ttotal: 35.4s\tremaining: 21.7s\n",
      "2849:\tlearn: 2.0390746\ttotal: 35.4s\tremaining: 21.7s\n",
      "2850:\tlearn: 2.0385438\ttotal: 35.4s\tremaining: 21.7s\n",
      "2851:\tlearn: 2.0382503\ttotal: 35.4s\tremaining: 21.7s\n",
      "2852:\tlearn: 2.0380946\ttotal: 35.4s\tremaining: 21.7s\n",
      "2853:\tlearn: 2.0376142\ttotal: 35.4s\tremaining: 21.6s\n",
      "2854:\tlearn: 2.0373358\ttotal: 35.4s\tremaining: 21.6s\n",
      "2855:\tlearn: 2.0370373\ttotal: 35.4s\tremaining: 21.6s\n",
      "2856:\tlearn: 2.0367915\ttotal: 35.5s\tremaining: 21.6s\n",
      "2857:\tlearn: 2.0360525\ttotal: 35.5s\tremaining: 21.6s\n",
      "2858:\tlearn: 2.0358437\ttotal: 35.5s\tremaining: 21.6s\n",
      "2859:\tlearn: 2.0357705\ttotal: 35.5s\tremaining: 21.6s\n",
      "2860:\tlearn: 2.0354732\ttotal: 35.5s\tremaining: 21.6s\n",
      "2861:\tlearn: 2.0350415\ttotal: 35.5s\tremaining: 21.5s\n",
      "2862:\tlearn: 2.0345730\ttotal: 35.5s\tremaining: 21.5s\n",
      "2863:\tlearn: 2.0343250\ttotal: 35.5s\tremaining: 21.5s\n",
      "2864:\tlearn: 2.0338589\ttotal: 35.5s\tremaining: 21.5s\n",
      "2865:\tlearn: 2.0335860\ttotal: 35.6s\tremaining: 21.5s\n",
      "2866:\tlearn: 2.0332930\ttotal: 35.6s\tremaining: 21.5s\n",
      "2867:\tlearn: 2.0328415\ttotal: 35.6s\tremaining: 21.5s\n",
      "2868:\tlearn: 2.0325146\ttotal: 35.6s\tremaining: 21.5s\n",
      "2869:\tlearn: 2.0321925\ttotal: 35.6s\tremaining: 21.4s\n",
      "2870:\tlearn: 2.0316510\ttotal: 35.6s\tremaining: 21.4s\n",
      "2871:\tlearn: 2.0311167\ttotal: 35.6s\tremaining: 21.4s\n",
      "2872:\tlearn: 2.0306380\ttotal: 35.6s\tremaining: 21.4s\n",
      "2873:\tlearn: 2.0304394\ttotal: 35.7s\tremaining: 21.4s\n",
      "2874:\tlearn: 2.0300234\ttotal: 35.7s\tremaining: 21.4s\n",
      "2875:\tlearn: 2.0297566\ttotal: 35.7s\tremaining: 21.4s\n",
      "2876:\tlearn: 2.0295383\ttotal: 35.7s\tremaining: 21.4s\n",
      "2877:\tlearn: 2.0290815\ttotal: 35.7s\tremaining: 21.3s\n",
      "2878:\tlearn: 2.0286722\ttotal: 35.7s\tremaining: 21.3s\n",
      "2879:\tlearn: 2.0283121\ttotal: 35.7s\tremaining: 21.3s\n",
      "2880:\tlearn: 2.0279500\ttotal: 35.7s\tremaining: 21.3s\n",
      "2881:\tlearn: 2.0276974\ttotal: 35.8s\tremaining: 21.3s\n",
      "2882:\tlearn: 2.0273314\ttotal: 35.8s\tremaining: 21.3s\n",
      "2883:\tlearn: 2.0269232\ttotal: 35.8s\tremaining: 21.3s\n",
      "2884:\tlearn: 2.0264527\ttotal: 35.8s\tremaining: 21.3s\n",
      "2885:\tlearn: 2.0262497\ttotal: 35.8s\tremaining: 21.2s\n",
      "2886:\tlearn: 2.0259834\ttotal: 35.8s\tremaining: 21.2s\n",
      "2887:\tlearn: 2.0256778\ttotal: 35.8s\tremaining: 21.2s\n",
      "2888:\tlearn: 2.0255891\ttotal: 35.8s\tremaining: 21.2s\n",
      "2889:\tlearn: 2.0251357\ttotal: 35.9s\tremaining: 21.2s\n",
      "2890:\tlearn: 2.0249834\ttotal: 35.9s\tremaining: 21.2s\n",
      "2891:\tlearn: 2.0246586\ttotal: 35.9s\tremaining: 21.2s\n",
      "2892:\tlearn: 2.0241643\ttotal: 35.9s\tremaining: 21.2s\n",
      "2893:\tlearn: 2.0237317\ttotal: 35.9s\tremaining: 21.1s\n",
      "2894:\tlearn: 2.0234898\ttotal: 35.9s\tremaining: 21.1s\n",
      "2895:\tlearn: 2.0233243\ttotal: 35.9s\tremaining: 21.1s\n",
      "2896:\tlearn: 2.0231336\ttotal: 35.9s\tremaining: 21.1s\n",
      "2897:\tlearn: 2.0226526\ttotal: 36s\tremaining: 21.1s\n",
      "2898:\tlearn: 2.0224080\ttotal: 36s\tremaining: 21.1s\n",
      "2899:\tlearn: 2.0222509\ttotal: 36s\tremaining: 21.1s\n",
      "2900:\tlearn: 2.0218244\ttotal: 36s\tremaining: 21.1s\n",
      "2901:\tlearn: 2.0213749\ttotal: 36s\tremaining: 21s\n",
      "2902:\tlearn: 2.0211844\ttotal: 36s\tremaining: 21s\n",
      "2903:\tlearn: 2.0211551\ttotal: 36s\tremaining: 21s\n",
      "2904:\tlearn: 2.0205691\ttotal: 36s\tremaining: 21s\n",
      "2905:\tlearn: 2.0202302\ttotal: 36s\tremaining: 21s\n",
      "2906:\tlearn: 2.0201555\ttotal: 36.1s\tremaining: 21s\n",
      "2907:\tlearn: 2.0197437\ttotal: 36.1s\tremaining: 21s\n",
      "2908:\tlearn: 2.0195753\ttotal: 36.1s\tremaining: 21s\n",
      "2909:\tlearn: 2.0193227\ttotal: 36.1s\tremaining: 20.9s\n",
      "2910:\tlearn: 2.0190167\ttotal: 36.1s\tremaining: 20.9s\n",
      "2911:\tlearn: 2.0189162\ttotal: 36.1s\tremaining: 20.9s\n",
      "2912:\tlearn: 2.0187230\ttotal: 36.1s\tremaining: 20.9s\n",
      "2913:\tlearn: 2.0185266\ttotal: 36.1s\tremaining: 20.9s\n",
      "2914:\tlearn: 2.0181503\ttotal: 36.2s\tremaining: 20.9s\n",
      "2915:\tlearn: 2.0178195\ttotal: 36.2s\tremaining: 20.9s\n",
      "2916:\tlearn: 2.0177284\ttotal: 36.2s\tremaining: 20.8s\n",
      "2917:\tlearn: 2.0175387\ttotal: 36.2s\tremaining: 20.8s\n",
      "2918:\tlearn: 2.0173416\ttotal: 36.2s\tremaining: 20.8s\n",
      "2919:\tlearn: 2.0167277\ttotal: 36.2s\tremaining: 20.8s\n",
      "2920:\tlearn: 2.0163254\ttotal: 36.2s\tremaining: 20.8s\n",
      "2921:\tlearn: 2.0160201\ttotal: 36.2s\tremaining: 20.8s\n",
      "2922:\tlearn: 2.0157790\ttotal: 36.3s\tremaining: 20.8s\n",
      "2923:\tlearn: 2.0153603\ttotal: 36.3s\tremaining: 20.8s\n",
      "2924:\tlearn: 2.0150459\ttotal: 36.3s\tremaining: 20.7s\n",
      "2925:\tlearn: 2.0147734\ttotal: 36.3s\tremaining: 20.7s\n",
      "2926:\tlearn: 2.0147419\ttotal: 36.3s\tremaining: 20.7s\n",
      "2927:\tlearn: 2.0145586\ttotal: 36.3s\tremaining: 20.7s\n",
      "2928:\tlearn: 2.0143886\ttotal: 36.3s\tremaining: 20.7s\n",
      "2929:\tlearn: 2.0141725\ttotal: 36.3s\tremaining: 20.7s\n",
      "2930:\tlearn: 2.0137852\ttotal: 36.3s\tremaining: 20.7s\n",
      "2931:\tlearn: 2.0132043\ttotal: 36.4s\tremaining: 20.7s\n",
      "2932:\tlearn: 2.0129536\ttotal: 36.4s\tremaining: 20.6s\n",
      "2933:\tlearn: 2.0127795\ttotal: 36.4s\tremaining: 20.6s\n",
      "2934:\tlearn: 2.0124586\ttotal: 36.4s\tremaining: 20.6s\n",
      "2935:\tlearn: 2.0121678\ttotal: 36.4s\tremaining: 20.6s\n",
      "2936:\tlearn: 2.0119333\ttotal: 36.4s\tremaining: 20.6s\n",
      "2937:\tlearn: 2.0115768\ttotal: 36.4s\tremaining: 20.6s\n",
      "2938:\tlearn: 2.0111003\ttotal: 36.5s\tremaining: 20.6s\n",
      "2939:\tlearn: 2.0107117\ttotal: 36.5s\tremaining: 20.6s\n",
      "2940:\tlearn: 2.0104074\ttotal: 36.5s\tremaining: 20.6s\n",
      "2941:\tlearn: 2.0100908\ttotal: 36.5s\tremaining: 20.5s\n",
      "2942:\tlearn: 2.0097392\ttotal: 36.5s\tremaining: 20.5s\n",
      "2943:\tlearn: 2.0092357\ttotal: 36.5s\tremaining: 20.5s\n",
      "2944:\tlearn: 2.0087704\ttotal: 36.5s\tremaining: 20.5s\n",
      "2945:\tlearn: 2.0085128\ttotal: 36.5s\tremaining: 20.5s\n",
      "2946:\tlearn: 2.0079180\ttotal: 36.6s\tremaining: 20.5s\n",
      "2947:\tlearn: 2.0074891\ttotal: 36.6s\tremaining: 20.5s\n",
      "2948:\tlearn: 2.0069828\ttotal: 36.6s\tremaining: 20.5s\n",
      "2949:\tlearn: 2.0066277\ttotal: 36.6s\tremaining: 20.4s\n",
      "2950:\tlearn: 2.0063806\ttotal: 36.6s\tremaining: 20.4s\n",
      "2951:\tlearn: 2.0058310\ttotal: 36.6s\tremaining: 20.4s\n",
      "2952:\tlearn: 2.0054862\ttotal: 36.6s\tremaining: 20.4s\n",
      "2953:\tlearn: 2.0053516\ttotal: 36.6s\tremaining: 20.4s\n",
      "2954:\tlearn: 2.0049807\ttotal: 36.7s\tremaining: 20.4s\n",
      "2955:\tlearn: 2.0046932\ttotal: 36.7s\tremaining: 20.4s\n",
      "2956:\tlearn: 2.0045008\ttotal: 36.7s\tremaining: 20.4s\n",
      "2957:\tlearn: 2.0041793\ttotal: 36.7s\tremaining: 20.3s\n",
      "2958:\tlearn: 2.0038946\ttotal: 36.7s\tremaining: 20.3s\n",
      "2959:\tlearn: 2.0036059\ttotal: 36.7s\tremaining: 20.3s\n",
      "2960:\tlearn: 2.0033472\ttotal: 36.7s\tremaining: 20.3s\n",
      "2961:\tlearn: 2.0032879\ttotal: 36.8s\tremaining: 20.3s\n",
      "2962:\tlearn: 2.0031429\ttotal: 36.8s\tremaining: 20.3s\n",
      "2963:\tlearn: 2.0025521\ttotal: 36.8s\tremaining: 20.3s\n",
      "2964:\tlearn: 2.0024209\ttotal: 36.8s\tremaining: 20.3s\n",
      "2965:\tlearn: 2.0022936\ttotal: 36.8s\tremaining: 20.3s\n",
      "2966:\tlearn: 2.0018212\ttotal: 36.8s\tremaining: 20.2s\n",
      "2967:\tlearn: 2.0015445\ttotal: 36.8s\tremaining: 20.2s\n",
      "2968:\tlearn: 2.0013522\ttotal: 36.9s\tremaining: 20.2s\n",
      "2969:\tlearn: 2.0006550\ttotal: 36.9s\tremaining: 20.2s\n",
      "2970:\tlearn: 2.0004083\ttotal: 36.9s\tremaining: 20.2s\n",
      "2971:\tlearn: 2.0001144\ttotal: 36.9s\tremaining: 20.2s\n",
      "2972:\tlearn: 1.9998369\ttotal: 36.9s\tremaining: 20.2s\n",
      "2973:\tlearn: 1.9994701\ttotal: 36.9s\tremaining: 20.2s\n",
      "2974:\tlearn: 1.9990225\ttotal: 36.9s\tremaining: 20.1s\n",
      "2975:\tlearn: 1.9987566\ttotal: 36.9s\tremaining: 20.1s\n",
      "2976:\tlearn: 1.9985344\ttotal: 37s\tremaining: 20.1s\n",
      "2977:\tlearn: 1.9982594\ttotal: 37s\tremaining: 20.1s\n",
      "2978:\tlearn: 1.9978160\ttotal: 37s\tremaining: 20.1s\n",
      "2979:\tlearn: 1.9974771\ttotal: 37s\tremaining: 20.1s\n",
      "2980:\tlearn: 1.9970231\ttotal: 37s\tremaining: 20.1s\n",
      "2981:\tlearn: 1.9967986\ttotal: 37s\tremaining: 20.1s\n",
      "2982:\tlearn: 1.9964764\ttotal: 37s\tremaining: 20s\n",
      "2983:\tlearn: 1.9962899\ttotal: 37s\tremaining: 20s\n",
      "2984:\tlearn: 1.9960270\ttotal: 37s\tremaining: 20s\n",
      "2985:\tlearn: 1.9959011\ttotal: 37.1s\tremaining: 20s\n",
      "2986:\tlearn: 1.9957572\ttotal: 37.1s\tremaining: 20s\n",
      "2987:\tlearn: 1.9953855\ttotal: 37.1s\tremaining: 20s\n",
      "2988:\tlearn: 1.9951762\ttotal: 37.1s\tremaining: 20s\n",
      "2989:\tlearn: 1.9948261\ttotal: 37.1s\tremaining: 20s\n",
      "2990:\tlearn: 1.9941106\ttotal: 37.1s\tremaining: 19.9s\n",
      "2991:\tlearn: 1.9939939\ttotal: 37.1s\tremaining: 19.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2992:\tlearn: 1.9937773\ttotal: 37.1s\tremaining: 19.9s\n",
      "2993:\tlearn: 1.9934824\ttotal: 37.2s\tremaining: 19.9s\n",
      "2994:\tlearn: 1.9930086\ttotal: 37.2s\tremaining: 19.9s\n",
      "2995:\tlearn: 1.9928630\ttotal: 37.2s\tremaining: 19.9s\n",
      "2996:\tlearn: 1.9926258\ttotal: 37.2s\tremaining: 19.9s\n",
      "2997:\tlearn: 1.9924324\ttotal: 37.2s\tremaining: 19.9s\n",
      "2998:\tlearn: 1.9922025\ttotal: 37.2s\tremaining: 19.8s\n",
      "2999:\tlearn: 1.9917582\ttotal: 37.2s\tremaining: 19.8s\n",
      "3000:\tlearn: 1.9913553\ttotal: 37.2s\tremaining: 19.8s\n",
      "3001:\tlearn: 1.9912191\ttotal: 37.3s\tremaining: 19.8s\n",
      "3002:\tlearn: 1.9910111\ttotal: 37.3s\tremaining: 19.8s\n",
      "3003:\tlearn: 1.9905340\ttotal: 37.3s\tremaining: 19.8s\n",
      "3004:\tlearn: 1.9901750\ttotal: 37.3s\tremaining: 19.8s\n",
      "3005:\tlearn: 1.9899279\ttotal: 37.3s\tremaining: 19.8s\n",
      "3006:\tlearn: 1.9896628\ttotal: 37.3s\tremaining: 19.7s\n",
      "3007:\tlearn: 1.9894881\ttotal: 37.3s\tremaining: 19.7s\n",
      "3008:\tlearn: 1.9893713\ttotal: 37.3s\tremaining: 19.7s\n",
      "3009:\tlearn: 1.9891292\ttotal: 37.4s\tremaining: 19.7s\n",
      "3010:\tlearn: 1.9888591\ttotal: 37.4s\tremaining: 19.7s\n",
      "3011:\tlearn: 1.9885213\ttotal: 37.4s\tremaining: 19.7s\n",
      "3012:\tlearn: 1.9882398\ttotal: 37.4s\tremaining: 19.7s\n",
      "3013:\tlearn: 1.9881991\ttotal: 37.4s\tremaining: 19.7s\n",
      "3014:\tlearn: 1.9880692\ttotal: 37.4s\tremaining: 19.6s\n",
      "3015:\tlearn: 1.9877336\ttotal: 37.4s\tremaining: 19.6s\n",
      "3016:\tlearn: 1.9874077\ttotal: 37.4s\tremaining: 19.6s\n",
      "3017:\tlearn: 1.9869415\ttotal: 37.5s\tremaining: 19.6s\n",
      "3018:\tlearn: 1.9866090\ttotal: 37.5s\tremaining: 19.6s\n",
      "3019:\tlearn: 1.9864412\ttotal: 37.5s\tremaining: 19.6s\n",
      "3020:\tlearn: 1.9862008\ttotal: 37.5s\tremaining: 19.6s\n",
      "3021:\tlearn: 1.9859945\ttotal: 37.5s\tremaining: 19.6s\n",
      "3022:\tlearn: 1.9856842\ttotal: 37.5s\tremaining: 19.5s\n",
      "3023:\tlearn: 1.9853014\ttotal: 37.5s\tremaining: 19.5s\n",
      "3024:\tlearn: 1.9850392\ttotal: 37.5s\tremaining: 19.5s\n",
      "3025:\tlearn: 1.9848400\ttotal: 37.5s\tremaining: 19.5s\n",
      "3026:\tlearn: 1.9844819\ttotal: 37.6s\tremaining: 19.5s\n",
      "3027:\tlearn: 1.9842800\ttotal: 37.6s\tremaining: 19.5s\n",
      "3028:\tlearn: 1.9841758\ttotal: 37.6s\tremaining: 19.5s\n",
      "3029:\tlearn: 1.9837936\ttotal: 37.6s\tremaining: 19.5s\n",
      "3030:\tlearn: 1.9834807\ttotal: 37.6s\tremaining: 19.4s\n",
      "3031:\tlearn: 1.9833322\ttotal: 37.6s\tremaining: 19.4s\n",
      "3032:\tlearn: 1.9831512\ttotal: 37.6s\tremaining: 19.4s\n",
      "3033:\tlearn: 1.9830146\ttotal: 37.6s\tremaining: 19.4s\n",
      "3034:\tlearn: 1.9827378\ttotal: 37.7s\tremaining: 19.4s\n",
      "3035:\tlearn: 1.9825355\ttotal: 37.7s\tremaining: 19.4s\n",
      "3036:\tlearn: 1.9822990\ttotal: 37.7s\tremaining: 19.4s\n",
      "3037:\tlearn: 1.9821975\ttotal: 37.7s\tremaining: 19.4s\n",
      "3038:\tlearn: 1.9818737\ttotal: 37.7s\tremaining: 19.3s\n",
      "3039:\tlearn: 1.9815354\ttotal: 37.7s\tremaining: 19.3s\n",
      "3040:\tlearn: 1.9812335\ttotal: 37.7s\tremaining: 19.3s\n",
      "3041:\tlearn: 1.9811168\ttotal: 37.7s\tremaining: 19.3s\n",
      "3042:\tlearn: 1.9808390\ttotal: 37.7s\tremaining: 19.3s\n",
      "3043:\tlearn: 1.9806401\ttotal: 37.8s\tremaining: 19.3s\n",
      "3044:\tlearn: 1.9802223\ttotal: 37.8s\tremaining: 19.3s\n",
      "3045:\tlearn: 1.9799126\ttotal: 37.8s\tremaining: 19.3s\n",
      "3046:\tlearn: 1.9796779\ttotal: 37.8s\tremaining: 19.2s\n",
      "3047:\tlearn: 1.9794294\ttotal: 37.8s\tremaining: 19.2s\n",
      "3048:\tlearn: 1.9792325\ttotal: 37.8s\tremaining: 19.2s\n",
      "3049:\tlearn: 1.9790547\ttotal: 37.8s\tremaining: 19.2s\n",
      "3050:\tlearn: 1.9786173\ttotal: 37.8s\tremaining: 19.2s\n",
      "3051:\tlearn: 1.9782756\ttotal: 37.9s\tremaining: 19.2s\n",
      "3052:\tlearn: 1.9778272\ttotal: 37.9s\tremaining: 19.2s\n",
      "3053:\tlearn: 1.9776138\ttotal: 37.9s\tremaining: 19.2s\n",
      "3054:\tlearn: 1.9772143\ttotal: 37.9s\tremaining: 19.1s\n",
      "3055:\tlearn: 1.9769970\ttotal: 37.9s\tremaining: 19.1s\n",
      "3056:\tlearn: 1.9768078\ttotal: 37.9s\tremaining: 19.1s\n",
      "3057:\tlearn: 1.9767036\ttotal: 37.9s\tremaining: 19.1s\n",
      "3058:\tlearn: 1.9764881\ttotal: 37.9s\tremaining: 19.1s\n",
      "3059:\tlearn: 1.9760826\ttotal: 38s\tremaining: 19.1s\n",
      "3060:\tlearn: 1.9756561\ttotal: 38s\tremaining: 19.1s\n",
      "3061:\tlearn: 1.9750648\ttotal: 38s\tremaining: 19.1s\n",
      "3062:\tlearn: 1.9744822\ttotal: 38s\tremaining: 19s\n",
      "3063:\tlearn: 1.9738902\ttotal: 38s\tremaining: 19s\n",
      "3064:\tlearn: 1.9736252\ttotal: 38s\tremaining: 19s\n",
      "3065:\tlearn: 1.9731752\ttotal: 38s\tremaining: 19s\n",
      "3066:\tlearn: 1.9728991\ttotal: 38s\tremaining: 19s\n",
      "3067:\tlearn: 1.9727817\ttotal: 38.1s\tremaining: 19s\n",
      "3068:\tlearn: 1.9726111\ttotal: 38.1s\tremaining: 19s\n",
      "3069:\tlearn: 1.9723739\ttotal: 38.1s\tremaining: 19s\n",
      "3070:\tlearn: 1.9719972\ttotal: 38.1s\tremaining: 18.9s\n",
      "3071:\tlearn: 1.9717144\ttotal: 38.1s\tremaining: 18.9s\n",
      "3072:\tlearn: 1.9712808\ttotal: 38.1s\tremaining: 18.9s\n",
      "3073:\tlearn: 1.9709836\ttotal: 38.1s\tremaining: 18.9s\n",
      "3074:\tlearn: 1.9707263\ttotal: 38.1s\tremaining: 18.9s\n",
      "3075:\tlearn: 1.9704275\ttotal: 38.2s\tremaining: 18.9s\n",
      "3076:\tlearn: 1.9701058\ttotal: 38.2s\tremaining: 18.9s\n",
      "3077:\tlearn: 1.9698852\ttotal: 38.2s\tremaining: 18.9s\n",
      "3078:\tlearn: 1.9696435\ttotal: 38.2s\tremaining: 18.8s\n",
      "3079:\tlearn: 1.9691303\ttotal: 38.2s\tremaining: 18.8s\n",
      "3080:\tlearn: 1.9687942\ttotal: 38.2s\tremaining: 18.8s\n",
      "3081:\tlearn: 1.9684629\ttotal: 38.2s\tremaining: 18.8s\n",
      "3082:\tlearn: 1.9681928\ttotal: 38.2s\tremaining: 18.8s\n",
      "3083:\tlearn: 1.9677624\ttotal: 38.3s\tremaining: 18.8s\n",
      "3084:\tlearn: 1.9672998\ttotal: 38.3s\tremaining: 18.8s\n",
      "3085:\tlearn: 1.9671236\ttotal: 38.3s\tremaining: 18.8s\n",
      "3086:\tlearn: 1.9664621\ttotal: 38.3s\tremaining: 18.7s\n",
      "3087:\tlearn: 1.9662975\ttotal: 38.3s\tremaining: 18.7s\n",
      "3088:\tlearn: 1.9660156\ttotal: 38.3s\tremaining: 18.7s\n",
      "3089:\tlearn: 1.9655443\ttotal: 38.3s\tremaining: 18.7s\n",
      "3090:\tlearn: 1.9651494\ttotal: 38.3s\tremaining: 18.7s\n",
      "3091:\tlearn: 1.9648301\ttotal: 38.4s\tremaining: 18.7s\n",
      "3092:\tlearn: 1.9644929\ttotal: 38.4s\tremaining: 18.7s\n",
      "3093:\tlearn: 1.9642219\ttotal: 38.4s\tremaining: 18.7s\n",
      "3094:\tlearn: 1.9639932\ttotal: 38.4s\tremaining: 18.6s\n",
      "3095:\tlearn: 1.9638448\ttotal: 38.4s\tremaining: 18.6s\n",
      "3096:\tlearn: 1.9633757\ttotal: 38.4s\tremaining: 18.6s\n",
      "3097:\tlearn: 1.9629998\ttotal: 38.4s\tremaining: 18.6s\n",
      "3098:\tlearn: 1.9624863\ttotal: 38.4s\tremaining: 18.6s\n",
      "3099:\tlearn: 1.9620800\ttotal: 38.5s\tremaining: 18.6s\n",
      "3100:\tlearn: 1.9616810\ttotal: 38.5s\tremaining: 18.6s\n",
      "3101:\tlearn: 1.9611434\ttotal: 38.5s\tremaining: 18.6s\n",
      "3102:\tlearn: 1.9607709\ttotal: 38.5s\tremaining: 18.5s\n",
      "3103:\tlearn: 1.9604143\ttotal: 38.5s\tremaining: 18.5s\n",
      "3104:\tlearn: 1.9601965\ttotal: 38.5s\tremaining: 18.5s\n",
      "3105:\tlearn: 1.9597565\ttotal: 38.5s\tremaining: 18.5s\n",
      "3106:\tlearn: 1.9595832\ttotal: 38.5s\tremaining: 18.5s\n",
      "3107:\tlearn: 1.9592098\ttotal: 38.5s\tremaining: 18.5s\n",
      "3108:\tlearn: 1.9589347\ttotal: 38.6s\tremaining: 18.5s\n",
      "3109:\tlearn: 1.9586907\ttotal: 38.6s\tremaining: 18.5s\n",
      "3110:\tlearn: 1.9583026\ttotal: 38.6s\tremaining: 18.4s\n",
      "3111:\tlearn: 1.9575237\ttotal: 38.6s\tremaining: 18.4s\n",
      "3112:\tlearn: 1.9573253\ttotal: 38.6s\tremaining: 18.4s\n",
      "3113:\tlearn: 1.9571782\ttotal: 38.6s\tremaining: 18.4s\n",
      "3114:\tlearn: 1.9569276\ttotal: 38.6s\tremaining: 18.4s\n",
      "3115:\tlearn: 1.9567150\ttotal: 38.6s\tremaining: 18.4s\n",
      "3116:\tlearn: 1.9565900\ttotal: 38.7s\tremaining: 18.4s\n",
      "3117:\tlearn: 1.9563872\ttotal: 38.7s\tremaining: 18.4s\n",
      "3118:\tlearn: 1.9562353\ttotal: 38.7s\tremaining: 18.3s\n",
      "3119:\tlearn: 1.9559284\ttotal: 38.7s\tremaining: 18.3s\n",
      "3120:\tlearn: 1.9556383\ttotal: 38.7s\tremaining: 18.3s\n",
      "3121:\tlearn: 1.9553875\ttotal: 38.7s\tremaining: 18.3s\n",
      "3122:\tlearn: 1.9552745\ttotal: 38.7s\tremaining: 18.3s\n",
      "3123:\tlearn: 1.9552515\ttotal: 38.7s\tremaining: 18.3s\n",
      "3124:\tlearn: 1.9550564\ttotal: 38.8s\tremaining: 18.3s\n",
      "3125:\tlearn: 1.9546098\ttotal: 38.8s\tremaining: 18.3s\n",
      "3126:\tlearn: 1.9543800\ttotal: 38.8s\tremaining: 18.2s\n",
      "3127:\tlearn: 1.9538456\ttotal: 38.8s\tremaining: 18.2s\n",
      "3128:\tlearn: 1.9535929\ttotal: 38.8s\tremaining: 18.2s\n",
      "3129:\tlearn: 1.9532087\ttotal: 38.8s\tremaining: 18.2s\n",
      "3130:\tlearn: 1.9528993\ttotal: 38.8s\tremaining: 18.2s\n",
      "3131:\tlearn: 1.9524117\ttotal: 38.8s\tremaining: 18.2s\n",
      "3132:\tlearn: 1.9520347\ttotal: 38.9s\tremaining: 18.2s\n",
      "3133:\tlearn: 1.9518283\ttotal: 38.9s\tremaining: 18.2s\n",
      "3134:\tlearn: 1.9515960\ttotal: 38.9s\tremaining: 18.1s\n",
      "3135:\tlearn: 1.9512252\ttotal: 38.9s\tremaining: 18.1s\n",
      "3136:\tlearn: 1.9509413\ttotal: 38.9s\tremaining: 18.1s\n",
      "3137:\tlearn: 1.9508508\ttotal: 38.9s\tremaining: 18.1s\n",
      "3138:\tlearn: 1.9503828\ttotal: 38.9s\tremaining: 18.1s\n",
      "3139:\tlearn: 1.9502451\ttotal: 38.9s\tremaining: 18.1s\n",
      "3140:\tlearn: 1.9500225\ttotal: 39s\tremaining: 18.1s\n",
      "3141:\tlearn: 1.9499680\ttotal: 39s\tremaining: 18.1s\n",
      "3142:\tlearn: 1.9497691\ttotal: 39s\tremaining: 18s\n",
      "3143:\tlearn: 1.9496186\ttotal: 39s\tremaining: 18s\n",
      "3144:\tlearn: 1.9495815\ttotal: 39s\tremaining: 18s\n",
      "3145:\tlearn: 1.9492687\ttotal: 39s\tremaining: 18s\n",
      "3146:\tlearn: 1.9489504\ttotal: 39s\tremaining: 18s\n",
      "3147:\tlearn: 1.9487074\ttotal: 39s\tremaining: 18s\n",
      "3148:\tlearn: 1.9485760\ttotal: 39.1s\tremaining: 18s\n",
      "3149:\tlearn: 1.9482425\ttotal: 39.1s\tremaining: 18s\n",
      "3150:\tlearn: 1.9480069\ttotal: 39.1s\tremaining: 17.9s\n",
      "3151:\tlearn: 1.9477527\ttotal: 39.1s\tremaining: 17.9s\n",
      "3152:\tlearn: 1.9474928\ttotal: 39.1s\tremaining: 17.9s\n",
      "3153:\tlearn: 1.9470262\ttotal: 39.1s\tremaining: 17.9s\n",
      "3154:\tlearn: 1.9469068\ttotal: 39.1s\tremaining: 17.9s\n",
      "3155:\tlearn: 1.9464744\ttotal: 39.1s\tremaining: 17.9s\n",
      "3156:\tlearn: 1.9463286\ttotal: 39.2s\tremaining: 17.9s\n",
      "3157:\tlearn: 1.9459510\ttotal: 39.2s\tremaining: 17.9s\n",
      "3158:\tlearn: 1.9456583\ttotal: 39.2s\tremaining: 17.8s\n",
      "3159:\tlearn: 1.9453556\ttotal: 39.2s\tremaining: 17.8s\n",
      "3160:\tlearn: 1.9451307\ttotal: 39.2s\tremaining: 17.8s\n",
      "3161:\tlearn: 1.9449484\ttotal: 39.2s\tremaining: 17.8s\n",
      "3162:\tlearn: 1.9446606\ttotal: 39.2s\tremaining: 17.8s\n",
      "3163:\tlearn: 1.9444063\ttotal: 39.2s\tremaining: 17.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3164:\tlearn: 1.9439289\ttotal: 39.3s\tremaining: 17.8s\n",
      "3165:\tlearn: 1.9435695\ttotal: 39.3s\tremaining: 17.8s\n",
      "3166:\tlearn: 1.9433116\ttotal: 39.3s\tremaining: 17.7s\n",
      "3167:\tlearn: 1.9430225\ttotal: 39.3s\tremaining: 17.7s\n",
      "3168:\tlearn: 1.9428936\ttotal: 39.3s\tremaining: 17.7s\n",
      "3169:\tlearn: 1.9427130\ttotal: 39.3s\tremaining: 17.7s\n",
      "3170:\tlearn: 1.9423490\ttotal: 39.3s\tremaining: 17.7s\n",
      "3171:\tlearn: 1.9421425\ttotal: 39.3s\tremaining: 17.7s\n",
      "3172:\tlearn: 1.9418912\ttotal: 39.4s\tremaining: 17.7s\n",
      "3173:\tlearn: 1.9415192\ttotal: 39.4s\tremaining: 17.7s\n",
      "3174:\tlearn: 1.9414088\ttotal: 39.4s\tremaining: 17.6s\n",
      "3175:\tlearn: 1.9412655\ttotal: 39.4s\tremaining: 17.6s\n",
      "3176:\tlearn: 1.9409597\ttotal: 39.4s\tremaining: 17.6s\n",
      "3177:\tlearn: 1.9406273\ttotal: 39.4s\tremaining: 17.6s\n",
      "3178:\tlearn: 1.9403534\ttotal: 39.4s\tremaining: 17.6s\n",
      "3179:\tlearn: 1.9399429\ttotal: 39.4s\tremaining: 17.6s\n",
      "3180:\tlearn: 1.9396052\ttotal: 39.5s\tremaining: 17.6s\n",
      "3181:\tlearn: 1.9393310\ttotal: 39.5s\tremaining: 17.6s\n",
      "3182:\tlearn: 1.9390135\ttotal: 39.5s\tremaining: 17.5s\n",
      "3183:\tlearn: 1.9388307\ttotal: 39.5s\tremaining: 17.5s\n",
      "3184:\tlearn: 1.9386006\ttotal: 39.5s\tremaining: 17.5s\n",
      "3185:\tlearn: 1.9383713\ttotal: 39.5s\tremaining: 17.5s\n",
      "3186:\tlearn: 1.9378075\ttotal: 39.5s\tremaining: 17.5s\n",
      "3187:\tlearn: 1.9373548\ttotal: 39.5s\tremaining: 17.5s\n",
      "3188:\tlearn: 1.9371273\ttotal: 39.5s\tremaining: 17.5s\n",
      "3189:\tlearn: 1.9369213\ttotal: 39.6s\tremaining: 17.5s\n",
      "3190:\tlearn: 1.9367050\ttotal: 39.6s\tremaining: 17.4s\n",
      "3191:\tlearn: 1.9364673\ttotal: 39.6s\tremaining: 17.4s\n",
      "3192:\tlearn: 1.9363194\ttotal: 39.6s\tremaining: 17.4s\n",
      "3193:\tlearn: 1.9359135\ttotal: 39.6s\tremaining: 17.4s\n",
      "3194:\tlearn: 1.9354290\ttotal: 39.6s\tremaining: 17.4s\n",
      "3195:\tlearn: 1.9350295\ttotal: 39.6s\tremaining: 17.4s\n",
      "3196:\tlearn: 1.9348634\ttotal: 39.6s\tremaining: 17.4s\n",
      "3197:\tlearn: 1.9345715\ttotal: 39.7s\tremaining: 17.4s\n",
      "3198:\tlearn: 1.9342252\ttotal: 39.7s\tremaining: 17.3s\n",
      "3199:\tlearn: 1.9341492\ttotal: 39.7s\tremaining: 17.3s\n",
      "3200:\tlearn: 1.9336823\ttotal: 39.7s\tremaining: 17.3s\n",
      "3201:\tlearn: 1.9334276\ttotal: 39.7s\tremaining: 17.3s\n",
      "3202:\tlearn: 1.9330730\ttotal: 39.7s\tremaining: 17.3s\n",
      "3203:\tlearn: 1.9328624\ttotal: 39.7s\tremaining: 17.3s\n",
      "3204:\tlearn: 1.9324231\ttotal: 39.7s\tremaining: 17.3s\n",
      "3205:\tlearn: 1.9321645\ttotal: 39.8s\tremaining: 17.3s\n",
      "3206:\tlearn: 1.9317681\ttotal: 39.8s\tremaining: 17.3s\n",
      "3207:\tlearn: 1.9315387\ttotal: 39.8s\tremaining: 17.2s\n",
      "3208:\tlearn: 1.9313011\ttotal: 39.8s\tremaining: 17.2s\n",
      "3209:\tlearn: 1.9311179\ttotal: 39.8s\tremaining: 17.2s\n",
      "3210:\tlearn: 1.9306848\ttotal: 39.8s\tremaining: 17.2s\n",
      "3211:\tlearn: 1.9304130\ttotal: 39.8s\tremaining: 17.2s\n",
      "3212:\tlearn: 1.9301587\ttotal: 39.8s\tremaining: 17.2s\n",
      "3213:\tlearn: 1.9298867\ttotal: 39.9s\tremaining: 17.2s\n",
      "3214:\tlearn: 1.9295868\ttotal: 39.9s\tremaining: 17.1s\n",
      "3215:\tlearn: 1.9293143\ttotal: 39.9s\tremaining: 17.1s\n",
      "3216:\tlearn: 1.9291438\ttotal: 39.9s\tremaining: 17.1s\n",
      "3217:\tlearn: 1.9287532\ttotal: 39.9s\tremaining: 17.1s\n",
      "3218:\tlearn: 1.9285762\ttotal: 39.9s\tremaining: 17.1s\n",
      "3219:\tlearn: 1.9283511\ttotal: 39.9s\tremaining: 17.1s\n",
      "3220:\tlearn: 1.9282540\ttotal: 39.9s\tremaining: 17.1s\n",
      "3221:\tlearn: 1.9279179\ttotal: 40s\tremaining: 17.1s\n",
      "3222:\tlearn: 1.9277698\ttotal: 40s\tremaining: 17.1s\n",
      "3223:\tlearn: 1.9275770\ttotal: 40s\tremaining: 17s\n",
      "3224:\tlearn: 1.9273456\ttotal: 40s\tremaining: 17s\n",
      "3225:\tlearn: 1.9271081\ttotal: 40s\tremaining: 17s\n",
      "3226:\tlearn: 1.9267706\ttotal: 40s\tremaining: 17s\n",
      "3227:\tlearn: 1.9265036\ttotal: 40s\tremaining: 17s\n",
      "3228:\tlearn: 1.9262958\ttotal: 40s\tremaining: 17s\n",
      "3229:\tlearn: 1.9260770\ttotal: 40.1s\tremaining: 17s\n",
      "3230:\tlearn: 1.9258043\ttotal: 40.1s\tremaining: 16.9s\n",
      "3231:\tlearn: 1.9254194\ttotal: 40.1s\tremaining: 16.9s\n",
      "3232:\tlearn: 1.9252230\ttotal: 40.1s\tremaining: 16.9s\n",
      "3233:\tlearn: 1.9250086\ttotal: 40.1s\tremaining: 16.9s\n",
      "3234:\tlearn: 1.9245903\ttotal: 40.1s\tremaining: 16.9s\n",
      "3235:\tlearn: 1.9243622\ttotal: 40.1s\tremaining: 16.9s\n",
      "3236:\tlearn: 1.9240606\ttotal: 40.1s\tremaining: 16.9s\n",
      "3237:\tlearn: 1.9238465\ttotal: 40.1s\tremaining: 16.9s\n",
      "3238:\tlearn: 1.9233691\ttotal: 40.2s\tremaining: 16.9s\n",
      "3239:\tlearn: 1.9229340\ttotal: 40.2s\tremaining: 16.8s\n",
      "3240:\tlearn: 1.9227734\ttotal: 40.2s\tremaining: 16.8s\n",
      "3241:\tlearn: 1.9224908\ttotal: 40.2s\tremaining: 16.8s\n",
      "3242:\tlearn: 1.9220797\ttotal: 40.2s\tremaining: 16.8s\n",
      "3243:\tlearn: 1.9219048\ttotal: 40.2s\tremaining: 16.8s\n",
      "3244:\tlearn: 1.9215642\ttotal: 40.2s\tremaining: 16.8s\n",
      "3245:\tlearn: 1.9210586\ttotal: 40.2s\tremaining: 16.8s\n",
      "3246:\tlearn: 1.9206806\ttotal: 40.3s\tremaining: 16.8s\n",
      "3247:\tlearn: 1.9203116\ttotal: 40.3s\tremaining: 16.7s\n",
      "3248:\tlearn: 1.9199571\ttotal: 40.3s\tremaining: 16.7s\n",
      "3249:\tlearn: 1.9198399\ttotal: 40.3s\tremaining: 16.7s\n",
      "3250:\tlearn: 1.9195088\ttotal: 40.3s\tremaining: 16.7s\n",
      "3251:\tlearn: 1.9192265\ttotal: 40.3s\tremaining: 16.7s\n",
      "3252:\tlearn: 1.9189632\ttotal: 40.3s\tremaining: 16.7s\n",
      "3253:\tlearn: 1.9184500\ttotal: 40.4s\tremaining: 16.7s\n",
      "3254:\tlearn: 1.9182233\ttotal: 40.4s\tremaining: 16.7s\n",
      "3255:\tlearn: 1.9180428\ttotal: 40.4s\tremaining: 16.6s\n",
      "3256:\tlearn: 1.9176345\ttotal: 40.4s\tremaining: 16.6s\n",
      "3257:\tlearn: 1.9174206\ttotal: 40.4s\tremaining: 16.6s\n",
      "3258:\tlearn: 1.9173184\ttotal: 40.4s\tremaining: 16.6s\n",
      "3259:\tlearn: 1.9168160\ttotal: 40.4s\tremaining: 16.6s\n",
      "3260:\tlearn: 1.9166142\ttotal: 40.4s\tremaining: 16.6s\n",
      "3261:\tlearn: 1.9164031\ttotal: 40.4s\tremaining: 16.6s\n",
      "3262:\tlearn: 1.9160401\ttotal: 40.5s\tremaining: 16.6s\n",
      "3263:\tlearn: 1.9156892\ttotal: 40.5s\tremaining: 16.5s\n",
      "3264:\tlearn: 1.9153785\ttotal: 40.5s\tremaining: 16.5s\n",
      "3265:\tlearn: 1.9147877\ttotal: 40.5s\tremaining: 16.5s\n",
      "3266:\tlearn: 1.9145195\ttotal: 40.5s\tremaining: 16.5s\n",
      "3267:\tlearn: 1.9143343\ttotal: 40.5s\tremaining: 16.5s\n",
      "3268:\tlearn: 1.9141651\ttotal: 40.5s\tremaining: 16.5s\n",
      "3269:\tlearn: 1.9138727\ttotal: 40.5s\tremaining: 16.5s\n",
      "3270:\tlearn: 1.9136499\ttotal: 40.6s\tremaining: 16.5s\n",
      "3271:\tlearn: 1.9133969\ttotal: 40.6s\tremaining: 16.4s\n",
      "3272:\tlearn: 1.9131208\ttotal: 40.6s\tremaining: 16.4s\n",
      "3273:\tlearn: 1.9129265\ttotal: 40.6s\tremaining: 16.4s\n",
      "3274:\tlearn: 1.9127912\ttotal: 40.6s\tremaining: 16.4s\n",
      "3275:\tlearn: 1.9124394\ttotal: 40.6s\tremaining: 16.4s\n",
      "3276:\tlearn: 1.9120765\ttotal: 40.6s\tremaining: 16.4s\n",
      "3277:\tlearn: 1.9118182\ttotal: 40.6s\tremaining: 16.4s\n",
      "3278:\tlearn: 1.9116527\ttotal: 40.7s\tremaining: 16.4s\n",
      "3279:\tlearn: 1.9113100\ttotal: 40.7s\tremaining: 16.3s\n",
      "3280:\tlearn: 1.9110061\ttotal: 40.7s\tremaining: 16.3s\n",
      "3281:\tlearn: 1.9107745\ttotal: 40.7s\tremaining: 16.3s\n",
      "3282:\tlearn: 1.9105266\ttotal: 40.7s\tremaining: 16.3s\n",
      "3283:\tlearn: 1.9102642\ttotal: 40.7s\tremaining: 16.3s\n",
      "3284:\tlearn: 1.9099355\ttotal: 40.7s\tremaining: 16.3s\n",
      "3285:\tlearn: 1.9095222\ttotal: 40.7s\tremaining: 16.3s\n",
      "3286:\tlearn: 1.9093595\ttotal: 40.8s\tremaining: 16.3s\n",
      "3287:\tlearn: 1.9089063\ttotal: 40.8s\tremaining: 16.2s\n",
      "3288:\tlearn: 1.9087283\ttotal: 40.8s\tremaining: 16.2s\n",
      "3289:\tlearn: 1.9085592\ttotal: 40.8s\tremaining: 16.2s\n",
      "3290:\tlearn: 1.9085586\ttotal: 40.8s\tremaining: 16.2s\n",
      "3291:\tlearn: 1.9082869\ttotal: 40.8s\tremaining: 16.2s\n",
      "3292:\tlearn: 1.9081469\ttotal: 40.8s\tremaining: 16.2s\n",
      "3293:\tlearn: 1.9079111\ttotal: 40.8s\tremaining: 16.2s\n",
      "3294:\tlearn: 1.9077422\ttotal: 40.9s\tremaining: 16.2s\n",
      "3295:\tlearn: 1.9073179\ttotal: 40.9s\tremaining: 16.1s\n",
      "3296:\tlearn: 1.9069891\ttotal: 40.9s\tremaining: 16.1s\n",
      "3297:\tlearn: 1.9066942\ttotal: 40.9s\tremaining: 16.1s\n",
      "3298:\tlearn: 1.9062341\ttotal: 40.9s\tremaining: 16.1s\n",
      "3299:\tlearn: 1.9060113\ttotal: 40.9s\tremaining: 16.1s\n",
      "3300:\tlearn: 1.9056908\ttotal: 40.9s\tremaining: 16.1s\n",
      "3301:\tlearn: 1.9053632\ttotal: 40.9s\tremaining: 16.1s\n",
      "3302:\tlearn: 1.9050080\ttotal: 41s\tremaining: 16.1s\n",
      "3303:\tlearn: 1.9046419\ttotal: 41s\tremaining: 16s\n",
      "3304:\tlearn: 1.9045676\ttotal: 41s\tremaining: 16s\n",
      "3305:\tlearn: 1.9045214\ttotal: 41s\tremaining: 16s\n",
      "3306:\tlearn: 1.9044035\ttotal: 41s\tremaining: 16s\n",
      "3307:\tlearn: 1.9041462\ttotal: 41s\tremaining: 16s\n",
      "3308:\tlearn: 1.9039878\ttotal: 41s\tremaining: 16s\n",
      "3309:\tlearn: 1.9036887\ttotal: 41s\tremaining: 16s\n",
      "3310:\tlearn: 1.9035764\ttotal: 41.1s\tremaining: 16s\n",
      "3311:\tlearn: 1.9032556\ttotal: 41.1s\tremaining: 15.9s\n",
      "3312:\tlearn: 1.9031577\ttotal: 41.1s\tremaining: 15.9s\n",
      "3313:\tlearn: 1.9028241\ttotal: 41.1s\tremaining: 15.9s\n",
      "3314:\tlearn: 1.9026931\ttotal: 41.1s\tremaining: 15.9s\n",
      "3315:\tlearn: 1.9024745\ttotal: 41.1s\tremaining: 15.9s\n",
      "3316:\tlearn: 1.9021110\ttotal: 41.1s\tremaining: 15.9s\n",
      "3317:\tlearn: 1.9020411\ttotal: 41.1s\tremaining: 15.9s\n",
      "3318:\tlearn: 1.9015762\ttotal: 41.1s\tremaining: 15.9s\n",
      "3319:\tlearn: 1.9014725\ttotal: 41.2s\tremaining: 15.8s\n",
      "3320:\tlearn: 1.9012462\ttotal: 41.2s\tremaining: 15.8s\n",
      "3321:\tlearn: 1.9009971\ttotal: 41.2s\tremaining: 15.8s\n",
      "3322:\tlearn: 1.9007343\ttotal: 41.2s\tremaining: 15.8s\n",
      "3323:\tlearn: 1.9004110\ttotal: 41.2s\tremaining: 15.8s\n",
      "3324:\tlearn: 1.9001964\ttotal: 41.2s\tremaining: 15.8s\n",
      "3325:\tlearn: 1.9000242\ttotal: 41.2s\tremaining: 15.8s\n",
      "3326:\tlearn: 1.8997231\ttotal: 41.3s\tremaining: 15.8s\n",
      "3327:\tlearn: 1.8995530\ttotal: 41.3s\tremaining: 15.7s\n",
      "3328:\tlearn: 1.8990488\ttotal: 41.3s\tremaining: 15.7s\n",
      "3329:\tlearn: 1.8988929\ttotal: 41.3s\tremaining: 15.7s\n",
      "3330:\tlearn: 1.8986955\ttotal: 41.3s\tremaining: 15.7s\n",
      "3331:\tlearn: 1.8986229\ttotal: 41.3s\tremaining: 15.7s\n",
      "3332:\tlearn: 1.8984632\ttotal: 41.3s\tremaining: 15.7s\n",
      "3333:\tlearn: 1.8982627\ttotal: 41.3s\tremaining: 15.7s\n",
      "3334:\tlearn: 1.8979136\ttotal: 41.3s\tremaining: 15.7s\n",
      "3335:\tlearn: 1.8973249\ttotal: 41.4s\tremaining: 15.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3336:\tlearn: 1.8969823\ttotal: 41.4s\tremaining: 15.6s\n",
      "3337:\tlearn: 1.8969328\ttotal: 41.4s\tremaining: 15.6s\n",
      "3338:\tlearn: 1.8966112\ttotal: 41.4s\tremaining: 15.6s\n",
      "3339:\tlearn: 1.8963611\ttotal: 41.4s\tremaining: 15.6s\n",
      "3340:\tlearn: 1.8961345\ttotal: 41.4s\tremaining: 15.6s\n",
      "3341:\tlearn: 1.8959815\ttotal: 41.4s\tremaining: 15.6s\n",
      "3342:\tlearn: 1.8956862\ttotal: 41.4s\tremaining: 15.6s\n",
      "3343:\tlearn: 1.8955665\ttotal: 41.5s\tremaining: 15.5s\n",
      "3344:\tlearn: 1.8954048\ttotal: 41.5s\tremaining: 15.5s\n",
      "3345:\tlearn: 1.8952556\ttotal: 41.5s\tremaining: 15.5s\n",
      "3346:\tlearn: 1.8949069\ttotal: 41.5s\tremaining: 15.5s\n",
      "3347:\tlearn: 1.8945829\ttotal: 41.5s\tremaining: 15.5s\n",
      "3348:\tlearn: 1.8944699\ttotal: 41.5s\tremaining: 15.5s\n",
      "3349:\tlearn: 1.8941995\ttotal: 41.5s\tremaining: 15.5s\n",
      "3350:\tlearn: 1.8938146\ttotal: 41.5s\tremaining: 15.5s\n",
      "3351:\tlearn: 1.8934123\ttotal: 41.5s\tremaining: 15.4s\n",
      "3352:\tlearn: 1.8929126\ttotal: 41.6s\tremaining: 15.4s\n",
      "3353:\tlearn: 1.8926794\ttotal: 41.6s\tremaining: 15.4s\n",
      "3354:\tlearn: 1.8924533\ttotal: 41.6s\tremaining: 15.4s\n",
      "3355:\tlearn: 1.8920501\ttotal: 41.6s\tremaining: 15.4s\n",
      "3356:\tlearn: 1.8919746\ttotal: 41.6s\tremaining: 15.4s\n",
      "3357:\tlearn: 1.8916648\ttotal: 41.6s\tremaining: 15.4s\n",
      "3358:\tlearn: 1.8914236\ttotal: 41.6s\tremaining: 15.4s\n",
      "3359:\tlearn: 1.8912619\ttotal: 41.6s\tremaining: 15.3s\n",
      "3360:\tlearn: 1.8910378\ttotal: 41.7s\tremaining: 15.3s\n",
      "3361:\tlearn: 1.8906578\ttotal: 41.7s\tremaining: 15.3s\n",
      "3362:\tlearn: 1.8904646\ttotal: 41.7s\tremaining: 15.3s\n",
      "3363:\tlearn: 1.8903258\ttotal: 41.7s\tremaining: 15.3s\n",
      "3364:\tlearn: 1.8899859\ttotal: 41.7s\tremaining: 15.3s\n",
      "3365:\tlearn: 1.8898077\ttotal: 41.7s\tremaining: 15.3s\n",
      "3366:\tlearn: 1.8893831\ttotal: 41.7s\tremaining: 15.3s\n",
      "3367:\tlearn: 1.8893025\ttotal: 41.7s\tremaining: 15.2s\n",
      "3368:\tlearn: 1.8890263\ttotal: 41.8s\tremaining: 15.2s\n",
      "3369:\tlearn: 1.8886972\ttotal: 41.8s\tremaining: 15.2s\n",
      "3370:\tlearn: 1.8883476\ttotal: 41.8s\tremaining: 15.2s\n",
      "3371:\tlearn: 1.8880004\ttotal: 41.8s\tremaining: 15.2s\n",
      "3372:\tlearn: 1.8877403\ttotal: 41.8s\tremaining: 15.2s\n",
      "3373:\tlearn: 1.8874885\ttotal: 41.8s\tremaining: 15.2s\n",
      "3374:\tlearn: 1.8873073\ttotal: 41.8s\tremaining: 15.2s\n",
      "3375:\tlearn: 1.8870629\ttotal: 41.8s\tremaining: 15.1s\n",
      "3376:\tlearn: 1.8865929\ttotal: 41.9s\tremaining: 15.1s\n",
      "3377:\tlearn: 1.8863636\ttotal: 41.9s\tremaining: 15.1s\n",
      "3378:\tlearn: 1.8859721\ttotal: 41.9s\tremaining: 15.1s\n",
      "3379:\tlearn: 1.8856116\ttotal: 41.9s\tremaining: 15.1s\n",
      "3380:\tlearn: 1.8853415\ttotal: 41.9s\tremaining: 15.1s\n",
      "3381:\tlearn: 1.8850658\ttotal: 41.9s\tremaining: 15.1s\n",
      "3382:\tlearn: 1.8846364\ttotal: 41.9s\tremaining: 15.1s\n",
      "3383:\tlearn: 1.8844807\ttotal: 41.9s\tremaining: 15s\n",
      "3384:\tlearn: 1.8842158\ttotal: 42s\tremaining: 15s\n",
      "3385:\tlearn: 1.8838454\ttotal: 42s\tremaining: 15s\n",
      "3386:\tlearn: 1.8837214\ttotal: 42s\tremaining: 15s\n",
      "3387:\tlearn: 1.8832893\ttotal: 42s\tremaining: 15s\n",
      "3388:\tlearn: 1.8829958\ttotal: 42s\tremaining: 15s\n",
      "3389:\tlearn: 1.8826504\ttotal: 42s\tremaining: 15s\n",
      "3390:\tlearn: 1.8824015\ttotal: 42s\tremaining: 15s\n",
      "3391:\tlearn: 1.8820658\ttotal: 42s\tremaining: 14.9s\n",
      "3392:\tlearn: 1.8818601\ttotal: 42.1s\tremaining: 14.9s\n",
      "3393:\tlearn: 1.8818046\ttotal: 42.1s\tremaining: 14.9s\n",
      "3394:\tlearn: 1.8813765\ttotal: 42.1s\tremaining: 14.9s\n",
      "3395:\tlearn: 1.8810119\ttotal: 42.1s\tremaining: 14.9s\n",
      "3396:\tlearn: 1.8807886\ttotal: 42.1s\tremaining: 14.9s\n",
      "3397:\tlearn: 1.8804933\ttotal: 42.1s\tremaining: 14.9s\n",
      "3398:\tlearn: 1.8803936\ttotal: 42.1s\tremaining: 14.9s\n",
      "3399:\tlearn: 1.8801929\ttotal: 42.1s\tremaining: 14.8s\n",
      "3400:\tlearn: 1.8797481\ttotal: 42.1s\tremaining: 14.8s\n",
      "3401:\tlearn: 1.8795049\ttotal: 42.2s\tremaining: 14.8s\n",
      "3402:\tlearn: 1.8792646\ttotal: 42.2s\tremaining: 14.8s\n",
      "3403:\tlearn: 1.8791980\ttotal: 42.2s\tremaining: 14.8s\n",
      "3404:\tlearn: 1.8789770\ttotal: 42.2s\tremaining: 14.8s\n",
      "3405:\tlearn: 1.8785165\ttotal: 42.2s\tremaining: 14.8s\n",
      "3406:\tlearn: 1.8781961\ttotal: 42.2s\tremaining: 14.8s\n",
      "3407:\tlearn: 1.8777985\ttotal: 42.2s\tremaining: 14.7s\n",
      "3408:\tlearn: 1.8775631\ttotal: 42.2s\tremaining: 14.7s\n",
      "3409:\tlearn: 1.8772833\ttotal: 42.3s\tremaining: 14.7s\n",
      "3410:\tlearn: 1.8770858\ttotal: 42.3s\tremaining: 14.7s\n",
      "3411:\tlearn: 1.8766726\ttotal: 42.3s\tremaining: 14.7s\n",
      "3412:\tlearn: 1.8763640\ttotal: 42.3s\tremaining: 14.7s\n",
      "3413:\tlearn: 1.8762639\ttotal: 42.3s\tremaining: 14.7s\n",
      "3414:\tlearn: 1.8759989\ttotal: 42.3s\tremaining: 14.7s\n",
      "3415:\tlearn: 1.8758781\ttotal: 42.3s\tremaining: 14.6s\n",
      "3416:\tlearn: 1.8754629\ttotal: 42.3s\tremaining: 14.6s\n",
      "3417:\tlearn: 1.8750066\ttotal: 42.4s\tremaining: 14.6s\n",
      "3418:\tlearn: 1.8746680\ttotal: 42.4s\tremaining: 14.6s\n",
      "3419:\tlearn: 1.8745131\ttotal: 42.4s\tremaining: 14.6s\n",
      "3420:\tlearn: 1.8743091\ttotal: 42.4s\tremaining: 14.6s\n",
      "3421:\tlearn: 1.8740591\ttotal: 42.4s\tremaining: 14.6s\n",
      "3422:\tlearn: 1.8738917\ttotal: 42.4s\tremaining: 14.6s\n",
      "3423:\tlearn: 1.8736781\ttotal: 42.4s\tremaining: 14.5s\n",
      "3424:\tlearn: 1.8734556\ttotal: 42.4s\tremaining: 14.5s\n",
      "3425:\tlearn: 1.8734271\ttotal: 42.4s\tremaining: 14.5s\n",
      "3426:\tlearn: 1.8732055\ttotal: 42.5s\tremaining: 14.5s\n",
      "3427:\tlearn: 1.8728847\ttotal: 42.5s\tremaining: 14.5s\n",
      "3428:\tlearn: 1.8724471\ttotal: 42.5s\tremaining: 14.5s\n",
      "3429:\tlearn: 1.8720206\ttotal: 42.5s\tremaining: 14.5s\n",
      "3430:\tlearn: 1.8718745\ttotal: 42.5s\tremaining: 14.5s\n",
      "3431:\tlearn: 1.8715307\ttotal: 42.5s\tremaining: 14.4s\n",
      "3432:\tlearn: 1.8712226\ttotal: 42.5s\tremaining: 14.4s\n",
      "3433:\tlearn: 1.8710610\ttotal: 42.5s\tremaining: 14.4s\n",
      "3434:\tlearn: 1.8707992\ttotal: 42.6s\tremaining: 14.4s\n",
      "3435:\tlearn: 1.8706784\ttotal: 42.6s\tremaining: 14.4s\n",
      "3436:\tlearn: 1.8705283\ttotal: 42.6s\tremaining: 14.4s\n",
      "3437:\tlearn: 1.8702667\ttotal: 42.6s\tremaining: 14.4s\n",
      "3438:\tlearn: 1.8698897\ttotal: 42.6s\tremaining: 14.4s\n",
      "3439:\tlearn: 1.8695731\ttotal: 42.6s\tremaining: 14.3s\n",
      "3440:\tlearn: 1.8693184\ttotal: 42.6s\tremaining: 14.3s\n",
      "3441:\tlearn: 1.8690448\ttotal: 42.6s\tremaining: 14.3s\n",
      "3442:\tlearn: 1.8688002\ttotal: 42.7s\tremaining: 14.3s\n",
      "3443:\tlearn: 1.8684459\ttotal: 42.7s\tremaining: 14.3s\n",
      "3444:\tlearn: 1.8679357\ttotal: 42.7s\tremaining: 14.3s\n",
      "3445:\tlearn: 1.8677234\ttotal: 42.7s\tremaining: 14.3s\n",
      "3446:\tlearn: 1.8671410\ttotal: 42.7s\tremaining: 14.3s\n",
      "3447:\tlearn: 1.8667894\ttotal: 42.7s\tremaining: 14.2s\n",
      "3448:\tlearn: 1.8665095\ttotal: 42.7s\tremaining: 14.2s\n",
      "3449:\tlearn: 1.8663711\ttotal: 42.7s\tremaining: 14.2s\n",
      "3450:\tlearn: 1.8662316\ttotal: 42.8s\tremaining: 14.2s\n",
      "3451:\tlearn: 1.8658915\ttotal: 42.8s\tremaining: 14.2s\n",
      "3452:\tlearn: 1.8656196\ttotal: 42.8s\tremaining: 14.2s\n",
      "3453:\tlearn: 1.8652457\ttotal: 42.8s\tremaining: 14.2s\n",
      "3454:\tlearn: 1.8651459\ttotal: 42.8s\tremaining: 14.2s\n",
      "3455:\tlearn: 1.8648812\ttotal: 42.8s\tremaining: 14.1s\n",
      "3456:\tlearn: 1.8643635\ttotal: 42.8s\tremaining: 14.1s\n",
      "3457:\tlearn: 1.8642541\ttotal: 42.8s\tremaining: 14.1s\n",
      "3458:\tlearn: 1.8637952\ttotal: 42.9s\tremaining: 14.1s\n",
      "3459:\tlearn: 1.8635358\ttotal: 42.9s\tremaining: 14.1s\n",
      "3460:\tlearn: 1.8631839\ttotal: 42.9s\tremaining: 14.1s\n",
      "3461:\tlearn: 1.8627497\ttotal: 42.9s\tremaining: 14.1s\n",
      "3462:\tlearn: 1.8621357\ttotal: 42.9s\tremaining: 14.1s\n",
      "3463:\tlearn: 1.8620720\ttotal: 42.9s\tremaining: 14s\n",
      "3464:\tlearn: 1.8619314\ttotal: 42.9s\tremaining: 14s\n",
      "3465:\tlearn: 1.8616441\ttotal: 42.9s\tremaining: 14s\n",
      "3466:\tlearn: 1.8612817\ttotal: 43s\tremaining: 14s\n",
      "3467:\tlearn: 1.8610176\ttotal: 43s\tremaining: 14s\n",
      "3468:\tlearn: 1.8605565\ttotal: 43s\tremaining: 14s\n",
      "3469:\tlearn: 1.8602198\ttotal: 43s\tremaining: 14s\n",
      "3470:\tlearn: 1.8600589\ttotal: 43s\tremaining: 14s\n",
      "3471:\tlearn: 1.8596872\ttotal: 43s\tremaining: 13.9s\n",
      "3472:\tlearn: 1.8594449\ttotal: 43s\tremaining: 13.9s\n",
      "3473:\tlearn: 1.8592013\ttotal: 43s\tremaining: 13.9s\n",
      "3474:\tlearn: 1.8589221\ttotal: 43s\tremaining: 13.9s\n",
      "3475:\tlearn: 1.8584905\ttotal: 43.1s\tremaining: 13.9s\n",
      "3476:\tlearn: 1.8583384\ttotal: 43.1s\tremaining: 13.9s\n",
      "3477:\tlearn: 1.8580379\ttotal: 43.1s\tremaining: 13.9s\n",
      "3478:\tlearn: 1.8578791\ttotal: 43.1s\tremaining: 13.9s\n",
      "3479:\tlearn: 1.8576080\ttotal: 43.1s\tremaining: 13.8s\n",
      "3480:\tlearn: 1.8570225\ttotal: 43.1s\tremaining: 13.8s\n",
      "3481:\tlearn: 1.8566847\ttotal: 43.1s\tremaining: 13.8s\n",
      "3482:\tlearn: 1.8564817\ttotal: 43.1s\tremaining: 13.8s\n",
      "3483:\tlearn: 1.8564416\ttotal: 43.2s\tremaining: 13.8s\n",
      "3484:\tlearn: 1.8562108\ttotal: 43.2s\tremaining: 13.8s\n",
      "3485:\tlearn: 1.8559237\ttotal: 43.2s\tremaining: 13.8s\n",
      "3486:\tlearn: 1.8557086\ttotal: 43.2s\tremaining: 13.8s\n",
      "3487:\tlearn: 1.8553375\ttotal: 43.2s\tremaining: 13.7s\n",
      "3488:\tlearn: 1.8551852\ttotal: 43.2s\tremaining: 13.7s\n",
      "3489:\tlearn: 1.8551044\ttotal: 43.2s\tremaining: 13.7s\n",
      "3490:\tlearn: 1.8549134\ttotal: 43.2s\tremaining: 13.7s\n",
      "3491:\tlearn: 1.8548472\ttotal: 43.3s\tremaining: 13.7s\n",
      "3492:\tlearn: 1.8544603\ttotal: 43.3s\tremaining: 13.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3493:\tlearn: 1.8541115\ttotal: 43.3s\tremaining: 13.7s\n",
      "3494:\tlearn: 1.8537828\ttotal: 43.3s\tremaining: 13.7s\n",
      "3495:\tlearn: 1.8535402\ttotal: 43.3s\tremaining: 13.6s\n",
      "3496:\tlearn: 1.8533504\ttotal: 43.3s\tremaining: 13.6s\n",
      "3497:\tlearn: 1.8533035\ttotal: 43.3s\tremaining: 13.6s\n",
      "3498:\tlearn: 1.8531456\ttotal: 43.3s\tremaining: 13.6s\n",
      "3499:\tlearn: 1.8528239\ttotal: 43.4s\tremaining: 13.6s\n",
      "3500:\tlearn: 1.8525449\ttotal: 43.4s\tremaining: 13.6s\n",
      "3501:\tlearn: 1.8519643\ttotal: 43.4s\tremaining: 13.6s\n",
      "3502:\tlearn: 1.8518115\ttotal: 43.4s\tremaining: 13.6s\n",
      "3503:\tlearn: 1.8514487\ttotal: 43.4s\tremaining: 13.6s\n",
      "3504:\tlearn: 1.8511605\ttotal: 43.4s\tremaining: 13.5s\n",
      "3505:\tlearn: 1.8510026\ttotal: 43.4s\tremaining: 13.5s\n",
      "3506:\tlearn: 1.8507156\ttotal: 43.4s\tremaining: 13.5s\n",
      "3507:\tlearn: 1.8503957\ttotal: 43.4s\tremaining: 13.5s\n",
      "3508:\tlearn: 1.8500641\ttotal: 43.5s\tremaining: 13.5s\n",
      "3509:\tlearn: 1.8499043\ttotal: 43.5s\tremaining: 13.5s\n",
      "3510:\tlearn: 1.8497056\ttotal: 43.5s\tremaining: 13.5s\n",
      "3511:\tlearn: 1.8493509\ttotal: 43.5s\tremaining: 13.5s\n",
      "3512:\tlearn: 1.8491646\ttotal: 43.5s\tremaining: 13.4s\n",
      "3513:\tlearn: 1.8487701\ttotal: 43.5s\tremaining: 13.4s\n",
      "3514:\tlearn: 1.8486993\ttotal: 43.5s\tremaining: 13.4s\n",
      "3515:\tlearn: 1.8484384\ttotal: 43.5s\tremaining: 13.4s\n",
      "3516:\tlearn: 1.8481228\ttotal: 43.6s\tremaining: 13.4s\n",
      "3517:\tlearn: 1.8479151\ttotal: 43.6s\tremaining: 13.4s\n",
      "3518:\tlearn: 1.8475716\ttotal: 43.6s\tremaining: 13.4s\n",
      "3519:\tlearn: 1.8473761\ttotal: 43.6s\tremaining: 13.4s\n",
      "3520:\tlearn: 1.8472357\ttotal: 43.6s\tremaining: 13.3s\n",
      "3521:\tlearn: 1.8470033\ttotal: 43.6s\tremaining: 13.3s\n",
      "3522:\tlearn: 1.8464420\ttotal: 43.6s\tremaining: 13.3s\n",
      "3523:\tlearn: 1.8460538\ttotal: 43.6s\tremaining: 13.3s\n",
      "3524:\tlearn: 1.8456357\ttotal: 43.7s\tremaining: 13.3s\n",
      "3525:\tlearn: 1.8454754\ttotal: 43.7s\tremaining: 13.3s\n",
      "3526:\tlearn: 1.8452261\ttotal: 43.7s\tremaining: 13.3s\n",
      "3527:\tlearn: 1.8448639\ttotal: 43.7s\tremaining: 13.3s\n",
      "3528:\tlearn: 1.8445710\ttotal: 43.7s\tremaining: 13.2s\n",
      "3529:\tlearn: 1.8441837\ttotal: 43.7s\tremaining: 13.2s\n",
      "3530:\tlearn: 1.8439206\ttotal: 43.7s\tremaining: 13.2s\n",
      "3531:\tlearn: 1.8435230\ttotal: 43.8s\tremaining: 13.2s\n",
      "3532:\tlearn: 1.8432833\ttotal: 43.8s\tremaining: 13.2s\n",
      "3533:\tlearn: 1.8428707\ttotal: 43.8s\tremaining: 13.2s\n",
      "3534:\tlearn: 1.8425273\ttotal: 43.8s\tremaining: 13.2s\n",
      "3535:\tlearn: 1.8423316\ttotal: 43.8s\tremaining: 13.2s\n",
      "3536:\tlearn: 1.8420747\ttotal: 43.8s\tremaining: 13.1s\n",
      "3537:\tlearn: 1.8416757\ttotal: 43.8s\tremaining: 13.1s\n",
      "3538:\tlearn: 1.8414532\ttotal: 43.8s\tremaining: 13.1s\n",
      "3539:\tlearn: 1.8410360\ttotal: 43.8s\tremaining: 13.1s\n",
      "3540:\tlearn: 1.8408869\ttotal: 43.9s\tremaining: 13.1s\n",
      "3541:\tlearn: 1.8406075\ttotal: 43.9s\tremaining: 13.1s\n",
      "3542:\tlearn: 1.8402984\ttotal: 43.9s\tremaining: 13.1s\n",
      "3543:\tlearn: 1.8401581\ttotal: 43.9s\tremaining: 13.1s\n",
      "3544:\tlearn: 1.8397381\ttotal: 43.9s\tremaining: 13s\n",
      "3545:\tlearn: 1.8394942\ttotal: 43.9s\tremaining: 13s\n",
      "3546:\tlearn: 1.8390802\ttotal: 43.9s\tremaining: 13s\n",
      "3547:\tlearn: 1.8388527\ttotal: 43.9s\tremaining: 13s\n",
      "3548:\tlearn: 1.8385732\ttotal: 44s\tremaining: 13s\n",
      "3549:\tlearn: 1.8381818\ttotal: 44s\tremaining: 13s\n",
      "3550:\tlearn: 1.8379698\ttotal: 44s\tremaining: 13s\n",
      "3551:\tlearn: 1.8377835\ttotal: 44s\tremaining: 13s\n",
      "3552:\tlearn: 1.8375403\ttotal: 44s\tremaining: 12.9s\n",
      "3553:\tlearn: 1.8373766\ttotal: 44s\tremaining: 12.9s\n",
      "3554:\tlearn: 1.8370871\ttotal: 44s\tremaining: 12.9s\n",
      "3555:\tlearn: 1.8369172\ttotal: 44s\tremaining: 12.9s\n",
      "3556:\tlearn: 1.8364742\ttotal: 44.1s\tremaining: 12.9s\n",
      "3557:\tlearn: 1.8362042\ttotal: 44.1s\tremaining: 12.9s\n",
      "3558:\tlearn: 1.8359789\ttotal: 44.1s\tremaining: 12.9s\n",
      "3559:\tlearn: 1.8356466\ttotal: 44.1s\tremaining: 12.9s\n",
      "3560:\tlearn: 1.8353557\ttotal: 44.1s\tremaining: 12.8s\n",
      "3561:\tlearn: 1.8352676\ttotal: 44.1s\tremaining: 12.8s\n",
      "3562:\tlearn: 1.8350107\ttotal: 44.1s\tremaining: 12.8s\n",
      "3563:\tlearn: 1.8349132\ttotal: 44.1s\tremaining: 12.8s\n",
      "3564:\tlearn: 1.8346978\ttotal: 44.2s\tremaining: 12.8s\n",
      "3565:\tlearn: 1.8345056\ttotal: 44.2s\tremaining: 12.8s\n",
      "3566:\tlearn: 1.8342976\ttotal: 44.2s\tremaining: 12.8s\n",
      "3567:\tlearn: 1.8342136\ttotal: 44.2s\tremaining: 12.8s\n",
      "3568:\tlearn: 1.8339375\ttotal: 44.2s\tremaining: 12.7s\n",
      "3569:\tlearn: 1.8338311\ttotal: 44.2s\tremaining: 12.7s\n",
      "3570:\tlearn: 1.8335557\ttotal: 44.2s\tremaining: 12.7s\n",
      "3571:\tlearn: 1.8334153\ttotal: 44.2s\tremaining: 12.7s\n",
      "3572:\tlearn: 1.8331153\ttotal: 44.3s\tremaining: 12.7s\n",
      "3573:\tlearn: 1.8329467\ttotal: 44.3s\tremaining: 12.7s\n",
      "3574:\tlearn: 1.8325315\ttotal: 44.3s\tremaining: 12.7s\n",
      "3575:\tlearn: 1.8324930\ttotal: 44.3s\tremaining: 12.7s\n",
      "3576:\tlearn: 1.8321900\ttotal: 44.3s\tremaining: 12.6s\n",
      "3577:\tlearn: 1.8318213\ttotal: 44.3s\tremaining: 12.6s\n",
      "3578:\tlearn: 1.8315010\ttotal: 44.3s\tremaining: 12.6s\n",
      "3579:\tlearn: 1.8311521\ttotal: 44.3s\tremaining: 12.6s\n",
      "3580:\tlearn: 1.8307792\ttotal: 44.4s\tremaining: 12.6s\n",
      "3581:\tlearn: 1.8303506\ttotal: 44.4s\tremaining: 12.6s\n",
      "3582:\tlearn: 1.8301218\ttotal: 44.4s\tremaining: 12.6s\n",
      "3583:\tlearn: 1.8297212\ttotal: 44.4s\tremaining: 12.6s\n",
      "3584:\tlearn: 1.8293061\ttotal: 44.4s\tremaining: 12.5s\n",
      "3585:\tlearn: 1.8290545\ttotal: 44.4s\tremaining: 12.5s\n",
      "3586:\tlearn: 1.8287699\ttotal: 44.4s\tremaining: 12.5s\n",
      "3587:\tlearn: 1.8285042\ttotal: 44.4s\tremaining: 12.5s\n",
      "3588:\tlearn: 1.8283678\ttotal: 44.5s\tremaining: 12.5s\n",
      "3589:\tlearn: 1.8282422\ttotal: 44.5s\tremaining: 12.5s\n",
      "3590:\tlearn: 1.8278193\ttotal: 44.5s\tremaining: 12.5s\n",
      "3591:\tlearn: 1.8275408\ttotal: 44.5s\tremaining: 12.5s\n",
      "3592:\tlearn: 1.8274012\ttotal: 44.5s\tremaining: 12.4s\n",
      "3593:\tlearn: 1.8270010\ttotal: 44.5s\tremaining: 12.4s\n",
      "3594:\tlearn: 1.8268013\ttotal: 44.5s\tremaining: 12.4s\n",
      "3595:\tlearn: 1.8263927\ttotal: 44.5s\tremaining: 12.4s\n",
      "3596:\tlearn: 1.8260478\ttotal: 44.5s\tremaining: 12.4s\n",
      "3597:\tlearn: 1.8257386\ttotal: 44.6s\tremaining: 12.4s\n",
      "3598:\tlearn: 1.8254851\ttotal: 44.6s\tremaining: 12.4s\n",
      "3599:\tlearn: 1.8252777\ttotal: 44.6s\tremaining: 12.4s\n",
      "3600:\tlearn: 1.8250053\ttotal: 44.6s\tremaining: 12.3s\n",
      "3601:\tlearn: 1.8247582\ttotal: 44.6s\tremaining: 12.3s\n",
      "3602:\tlearn: 1.8245116\ttotal: 44.6s\tremaining: 12.3s\n",
      "3603:\tlearn: 1.8241784\ttotal: 44.6s\tremaining: 12.3s\n",
      "3604:\tlearn: 1.8240185\ttotal: 44.6s\tremaining: 12.3s\n",
      "3605:\tlearn: 1.8238572\ttotal: 44.7s\tremaining: 12.3s\n",
      "3606:\tlearn: 1.8237076\ttotal: 44.7s\tremaining: 12.3s\n",
      "3607:\tlearn: 1.8231949\ttotal: 44.7s\tremaining: 12.3s\n",
      "3608:\tlearn: 1.8228906\ttotal: 44.7s\tremaining: 12.2s\n",
      "3609:\tlearn: 1.8226171\ttotal: 44.7s\tremaining: 12.2s\n",
      "3610:\tlearn: 1.8222552\ttotal: 44.7s\tremaining: 12.2s\n",
      "3611:\tlearn: 1.8221525\ttotal: 44.7s\tremaining: 12.2s\n",
      "3612:\tlearn: 1.8216489\ttotal: 44.7s\tremaining: 12.2s\n",
      "3613:\tlearn: 1.8214342\ttotal: 44.8s\tremaining: 12.2s\n",
      "3614:\tlearn: 1.8212793\ttotal: 44.8s\tremaining: 12.2s\n",
      "3615:\tlearn: 1.8208474\ttotal: 44.8s\tremaining: 12.2s\n",
      "3616:\tlearn: 1.8203915\ttotal: 44.8s\tremaining: 12.1s\n",
      "3617:\tlearn: 1.8201720\ttotal: 44.8s\tremaining: 12.1s\n",
      "3618:\tlearn: 1.8199510\ttotal: 44.8s\tremaining: 12.1s\n",
      "3619:\tlearn: 1.8196911\ttotal: 44.8s\tremaining: 12.1s\n",
      "3620:\tlearn: 1.8193256\ttotal: 44.8s\tremaining: 12.1s\n",
      "3621:\tlearn: 1.8189785\ttotal: 44.9s\tremaining: 12.1s\n",
      "3622:\tlearn: 1.8187134\ttotal: 44.9s\tremaining: 12.1s\n",
      "3623:\tlearn: 1.8186031\ttotal: 44.9s\tremaining: 12.1s\n",
      "3624:\tlearn: 1.8182389\ttotal: 44.9s\tremaining: 12s\n",
      "3625:\tlearn: 1.8179818\ttotal: 44.9s\tremaining: 12s\n",
      "3626:\tlearn: 1.8176478\ttotal: 44.9s\tremaining: 12s\n",
      "3627:\tlearn: 1.8175099\ttotal: 44.9s\tremaining: 12s\n",
      "3628:\tlearn: 1.8173295\ttotal: 44.9s\tremaining: 12s\n",
      "3629:\tlearn: 1.8171399\ttotal: 45s\tremaining: 12s\n",
      "3630:\tlearn: 1.8170002\ttotal: 45s\tremaining: 12s\n",
      "3631:\tlearn: 1.8167465\ttotal: 45s\tremaining: 12s\n",
      "3632:\tlearn: 1.8165451\ttotal: 45s\tremaining: 11.9s\n",
      "3633:\tlearn: 1.8164717\ttotal: 45s\tremaining: 11.9s\n",
      "3634:\tlearn: 1.8163907\ttotal: 45s\tremaining: 11.9s\n",
      "3635:\tlearn: 1.8161866\ttotal: 45s\tremaining: 11.9s\n",
      "3636:\tlearn: 1.8160061\ttotal: 45s\tremaining: 11.9s\n",
      "3637:\tlearn: 1.8157345\ttotal: 45s\tremaining: 11.9s\n",
      "3638:\tlearn: 1.8155206\ttotal: 45.1s\tremaining: 11.9s\n",
      "3639:\tlearn: 1.8153826\ttotal: 45.1s\tremaining: 11.9s\n",
      "3640:\tlearn: 1.8149552\ttotal: 45.1s\tremaining: 11.8s\n",
      "3641:\tlearn: 1.8147493\ttotal: 45.1s\tremaining: 11.8s\n",
      "3642:\tlearn: 1.8143838\ttotal: 45.1s\tremaining: 11.8s\n",
      "3643:\tlearn: 1.8142228\ttotal: 45.1s\tremaining: 11.8s\n",
      "3644:\tlearn: 1.8138475\ttotal: 45.1s\tremaining: 11.8s\n",
      "3645:\tlearn: 1.8137632\ttotal: 45.1s\tremaining: 11.8s\n",
      "3646:\tlearn: 1.8134702\ttotal: 45.2s\tremaining: 11.8s\n",
      "3647:\tlearn: 1.8131877\ttotal: 45.2s\tremaining: 11.8s\n",
      "3648:\tlearn: 1.8129002\ttotal: 45.2s\tremaining: 11.8s\n",
      "3649:\tlearn: 1.8127191\ttotal: 45.2s\tremaining: 11.7s\n",
      "3650:\tlearn: 1.8125531\ttotal: 45.2s\tremaining: 11.7s\n",
      "3651:\tlearn: 1.8124512\ttotal: 45.2s\tremaining: 11.7s\n",
      "3652:\tlearn: 1.8123076\ttotal: 45.2s\tremaining: 11.7s\n",
      "3653:\tlearn: 1.8119099\ttotal: 45.2s\tremaining: 11.7s\n",
      "3654:\tlearn: 1.8115870\ttotal: 45.3s\tremaining: 11.7s\n",
      "3655:\tlearn: 1.8112674\ttotal: 45.3s\tremaining: 11.7s\n",
      "3656:\tlearn: 1.8110120\ttotal: 45.3s\tremaining: 11.7s\n",
      "3657:\tlearn: 1.8106601\ttotal: 45.3s\tremaining: 11.6s\n",
      "3658:\tlearn: 1.8102992\ttotal: 45.3s\tremaining: 11.6s\n",
      "3659:\tlearn: 1.8098964\ttotal: 45.3s\tremaining: 11.6s\n",
      "3660:\tlearn: 1.8097427\ttotal: 45.3s\tremaining: 11.6s\n",
      "3661:\tlearn: 1.8095563\ttotal: 45.3s\tremaining: 11.6s\n",
      "3662:\tlearn: 1.8093963\ttotal: 45.4s\tremaining: 11.6s\n",
      "3663:\tlearn: 1.8091659\ttotal: 45.4s\tremaining: 11.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3664:\tlearn: 1.8089007\ttotal: 45.4s\tremaining: 11.6s\n",
      "3665:\tlearn: 1.8083070\ttotal: 45.4s\tremaining: 11.5s\n",
      "3666:\tlearn: 1.8079688\ttotal: 45.4s\tremaining: 11.5s\n",
      "3667:\tlearn: 1.8076931\ttotal: 45.4s\tremaining: 11.5s\n",
      "3668:\tlearn: 1.8074114\ttotal: 45.4s\tremaining: 11.5s\n",
      "3669:\tlearn: 1.8072984\ttotal: 45.4s\tremaining: 11.5s\n",
      "3670:\tlearn: 1.8069810\ttotal: 45.5s\tremaining: 11.5s\n",
      "3671:\tlearn: 1.8068792\ttotal: 45.5s\tremaining: 11.5s\n",
      "3672:\tlearn: 1.8066630\ttotal: 45.5s\tremaining: 11.5s\n",
      "3673:\tlearn: 1.8064492\ttotal: 45.5s\tremaining: 11.4s\n",
      "3674:\tlearn: 1.8063078\ttotal: 45.5s\tremaining: 11.4s\n",
      "3675:\tlearn: 1.8061521\ttotal: 45.5s\tremaining: 11.4s\n",
      "3676:\tlearn: 1.8059401\ttotal: 45.5s\tremaining: 11.4s\n",
      "3677:\tlearn: 1.8057102\ttotal: 45.5s\tremaining: 11.4s\n",
      "3678:\tlearn: 1.8053491\ttotal: 45.6s\tremaining: 11.4s\n",
      "3679:\tlearn: 1.8052012\ttotal: 45.6s\tremaining: 11.4s\n",
      "3680:\tlearn: 1.8051030\ttotal: 45.6s\tremaining: 11.4s\n",
      "3681:\tlearn: 1.8047780\ttotal: 45.6s\tremaining: 11.3s\n",
      "3682:\tlearn: 1.8045875\ttotal: 45.6s\tremaining: 11.3s\n",
      "3683:\tlearn: 1.8044848\ttotal: 45.6s\tremaining: 11.3s\n",
      "3684:\tlearn: 1.8040269\ttotal: 45.6s\tremaining: 11.3s\n",
      "3685:\tlearn: 1.8037869\ttotal: 45.6s\tremaining: 11.3s\n",
      "3686:\tlearn: 1.8034318\ttotal: 45.7s\tremaining: 11.3s\n",
      "3687:\tlearn: 1.8031177\ttotal: 45.7s\tremaining: 11.3s\n",
      "3688:\tlearn: 1.8029629\ttotal: 45.7s\tremaining: 11.3s\n",
      "3689:\tlearn: 1.8026759\ttotal: 45.7s\tremaining: 11.2s\n",
      "3690:\tlearn: 1.8024395\ttotal: 45.7s\tremaining: 11.2s\n",
      "3691:\tlearn: 1.8022422\ttotal: 45.7s\tremaining: 11.2s\n",
      "3692:\tlearn: 1.8020665\ttotal: 45.7s\tremaining: 11.2s\n",
      "3693:\tlearn: 1.8018428\ttotal: 45.7s\tremaining: 11.2s\n",
      "3694:\tlearn: 1.8015796\ttotal: 45.7s\tremaining: 11.2s\n",
      "3695:\tlearn: 1.8014825\ttotal: 45.8s\tremaining: 11.2s\n",
      "3696:\tlearn: 1.8011855\ttotal: 45.8s\tremaining: 11.2s\n",
      "3697:\tlearn: 1.8009130\ttotal: 45.8s\tremaining: 11.1s\n",
      "3698:\tlearn: 1.8006838\ttotal: 45.8s\tremaining: 11.1s\n",
      "3699:\tlearn: 1.8005366\ttotal: 45.8s\tremaining: 11.1s\n",
      "3700:\tlearn: 1.8002382\ttotal: 45.8s\tremaining: 11.1s\n",
      "3701:\tlearn: 1.8000244\ttotal: 45.8s\tremaining: 11.1s\n",
      "3702:\tlearn: 1.7998145\ttotal: 45.8s\tremaining: 11.1s\n",
      "3703:\tlearn: 1.7996562\ttotal: 45.9s\tremaining: 11.1s\n",
      "3704:\tlearn: 1.7993570\ttotal: 45.9s\tremaining: 11.1s\n",
      "3705:\tlearn: 1.7990039\ttotal: 45.9s\tremaining: 11s\n",
      "3706:\tlearn: 1.7988557\ttotal: 45.9s\tremaining: 11s\n",
      "3707:\tlearn: 1.7986022\ttotal: 45.9s\tremaining: 11s\n",
      "3708:\tlearn: 1.7981810\ttotal: 45.9s\tremaining: 11s\n",
      "3709:\tlearn: 1.7980609\ttotal: 45.9s\tremaining: 11s\n",
      "3710:\tlearn: 1.7978776\ttotal: 46s\tremaining: 11s\n",
      "3711:\tlearn: 1.7977662\ttotal: 46s\tremaining: 11s\n",
      "3712:\tlearn: 1.7974732\ttotal: 46s\tremaining: 11s\n",
      "3713:\tlearn: 1.7970476\ttotal: 46s\tremaining: 10.9s\n",
      "3714:\tlearn: 1.7967047\ttotal: 46s\tremaining: 10.9s\n",
      "3715:\tlearn: 1.7964953\ttotal: 46s\tremaining: 10.9s\n",
      "3716:\tlearn: 1.7962549\ttotal: 46s\tremaining: 10.9s\n",
      "3717:\tlearn: 1.7959495\ttotal: 46s\tremaining: 10.9s\n",
      "3718:\tlearn: 1.7957621\ttotal: 46.1s\tremaining: 10.9s\n",
      "3719:\tlearn: 1.7954919\ttotal: 46.1s\tremaining: 10.9s\n",
      "3720:\tlearn: 1.7951566\ttotal: 46.1s\tremaining: 10.9s\n",
      "3721:\tlearn: 1.7951136\ttotal: 46.1s\tremaining: 10.8s\n",
      "3722:\tlearn: 1.7949311\ttotal: 46.1s\tremaining: 10.8s\n",
      "3723:\tlearn: 1.7947901\ttotal: 46.1s\tremaining: 10.8s\n",
      "3724:\tlearn: 1.7945421\ttotal: 46.1s\tremaining: 10.8s\n",
      "3725:\tlearn: 1.7943652\ttotal: 46.1s\tremaining: 10.8s\n",
      "3726:\tlearn: 1.7940858\ttotal: 46.2s\tremaining: 10.8s\n",
      "3727:\tlearn: 1.7937854\ttotal: 46.2s\tremaining: 10.8s\n",
      "3728:\tlearn: 1.7935359\ttotal: 46.2s\tremaining: 10.8s\n",
      "3729:\tlearn: 1.7934202\ttotal: 46.2s\tremaining: 10.7s\n",
      "3730:\tlearn: 1.7931701\ttotal: 46.2s\tremaining: 10.7s\n",
      "3731:\tlearn: 1.7929282\ttotal: 46.2s\tremaining: 10.7s\n",
      "3732:\tlearn: 1.7928105\ttotal: 46.2s\tremaining: 10.7s\n",
      "3733:\tlearn: 1.7923770\ttotal: 46.2s\tremaining: 10.7s\n",
      "3734:\tlearn: 1.7921427\ttotal: 46.3s\tremaining: 10.7s\n",
      "3735:\tlearn: 1.7919980\ttotal: 46.3s\tremaining: 10.7s\n",
      "3736:\tlearn: 1.7918763\ttotal: 46.3s\tremaining: 10.7s\n",
      "3737:\tlearn: 1.7916085\ttotal: 46.3s\tremaining: 10.7s\n",
      "3738:\tlearn: 1.7913666\ttotal: 46.3s\tremaining: 10.6s\n",
      "3739:\tlearn: 1.7910832\ttotal: 46.3s\tremaining: 10.6s\n",
      "3740:\tlearn: 1.7908262\ttotal: 46.3s\tremaining: 10.6s\n",
      "3741:\tlearn: 1.7906182\ttotal: 46.3s\tremaining: 10.6s\n",
      "3742:\tlearn: 1.7903702\ttotal: 46.4s\tremaining: 10.6s\n",
      "3743:\tlearn: 1.7900913\ttotal: 46.4s\tremaining: 10.6s\n",
      "3744:\tlearn: 1.7897919\ttotal: 46.4s\tremaining: 10.6s\n",
      "3745:\tlearn: 1.7895558\ttotal: 46.4s\tremaining: 10.6s\n",
      "3746:\tlearn: 1.7894598\ttotal: 46.4s\tremaining: 10.5s\n",
      "3747:\tlearn: 1.7893290\ttotal: 46.4s\tremaining: 10.5s\n",
      "3748:\tlearn: 1.7890761\ttotal: 46.4s\tremaining: 10.5s\n",
      "3749:\tlearn: 1.7887244\ttotal: 46.4s\tremaining: 10.5s\n",
      "3750:\tlearn: 1.7884337\ttotal: 46.5s\tremaining: 10.5s\n",
      "3751:\tlearn: 1.7880702\ttotal: 46.5s\tremaining: 10.5s\n",
      "3752:\tlearn: 1.7878295\ttotal: 46.5s\tremaining: 10.5s\n",
      "3753:\tlearn: 1.7877516\ttotal: 46.5s\tremaining: 10.5s\n",
      "3754:\tlearn: 1.7876311\ttotal: 46.5s\tremaining: 10.4s\n",
      "3755:\tlearn: 1.7872475\ttotal: 46.5s\tremaining: 10.4s\n",
      "3756:\tlearn: 1.7869823\ttotal: 46.5s\tremaining: 10.4s\n",
      "3757:\tlearn: 1.7866032\ttotal: 46.5s\tremaining: 10.4s\n",
      "3758:\tlearn: 1.7863146\ttotal: 46.6s\tremaining: 10.4s\n",
      "3759:\tlearn: 1.7861621\ttotal: 46.6s\tremaining: 10.4s\n",
      "3760:\tlearn: 1.7857961\ttotal: 46.6s\tremaining: 10.4s\n",
      "3761:\tlearn: 1.7855838\ttotal: 46.6s\tremaining: 10.4s\n",
      "3762:\tlearn: 1.7852466\ttotal: 46.6s\tremaining: 10.3s\n",
      "3763:\tlearn: 1.7850089\ttotal: 46.6s\tremaining: 10.3s\n",
      "3764:\tlearn: 1.7847672\ttotal: 46.6s\tremaining: 10.3s\n",
      "3765:\tlearn: 1.7843858\ttotal: 46.6s\tremaining: 10.3s\n",
      "3766:\tlearn: 1.7841320\ttotal: 46.7s\tremaining: 10.3s\n",
      "3767:\tlearn: 1.7838502\ttotal: 46.7s\tremaining: 10.3s\n",
      "3768:\tlearn: 1.7835936\ttotal: 46.7s\tremaining: 10.3s\n",
      "3769:\tlearn: 1.7833266\ttotal: 46.7s\tremaining: 10.3s\n",
      "3770:\tlearn: 1.7827586\ttotal: 46.7s\tremaining: 10.2s\n",
      "3771:\tlearn: 1.7826427\ttotal: 46.7s\tremaining: 10.2s\n",
      "3772:\tlearn: 1.7826417\ttotal: 46.7s\tremaining: 10.2s\n",
      "3773:\tlearn: 1.7826407\ttotal: 46.7s\tremaining: 10.2s\n",
      "3774:\tlearn: 1.7824962\ttotal: 46.8s\tremaining: 10.2s\n",
      "3775:\tlearn: 1.7823180\ttotal: 46.8s\tremaining: 10.2s\n",
      "3776:\tlearn: 1.7821613\ttotal: 46.8s\tremaining: 10.2s\n",
      "3777:\tlearn: 1.7818705\ttotal: 46.8s\tremaining: 10.2s\n",
      "3778:\tlearn: 1.7817607\ttotal: 46.8s\tremaining: 10.1s\n",
      "3779:\tlearn: 1.7815152\ttotal: 46.8s\tremaining: 10.1s\n",
      "3780:\tlearn: 1.7813515\ttotal: 46.8s\tremaining: 10.1s\n",
      "3781:\tlearn: 1.7810070\ttotal: 46.8s\tremaining: 10.1s\n",
      "3782:\tlearn: 1.7807344\ttotal: 46.9s\tremaining: 10.1s\n",
      "3783:\tlearn: 1.7804856\ttotal: 46.9s\tremaining: 10.1s\n",
      "3784:\tlearn: 1.7802135\ttotal: 46.9s\tremaining: 10.1s\n",
      "3785:\tlearn: 1.7800475\ttotal: 46.9s\tremaining: 10.1s\n",
      "3786:\tlearn: 1.7800264\ttotal: 46.9s\tremaining: 10s\n",
      "3787:\tlearn: 1.7798397\ttotal: 46.9s\tremaining: 10s\n",
      "3788:\tlearn: 1.7796534\ttotal: 46.9s\tremaining: 10s\n",
      "3789:\tlearn: 1.7794223\ttotal: 46.9s\tremaining: 10s\n",
      "3790:\tlearn: 1.7790863\ttotal: 47s\tremaining: 9.99s\n",
      "3791:\tlearn: 1.7788001\ttotal: 47s\tremaining: 9.98s\n",
      "3792:\tlearn: 1.7786951\ttotal: 47s\tremaining: 9.97s\n",
      "3793:\tlearn: 1.7785713\ttotal: 47s\tremaining: 9.96s\n",
      "3794:\tlearn: 1.7784550\ttotal: 47s\tremaining: 9.94s\n",
      "3795:\tlearn: 1.7782420\ttotal: 47s\tremaining: 9.93s\n",
      "3796:\tlearn: 1.7781391\ttotal: 47s\tremaining: 9.92s\n",
      "3797:\tlearn: 1.7780608\ttotal: 47s\tremaining: 9.91s\n",
      "3798:\tlearn: 1.7779711\ttotal: 47s\tremaining: 9.89s\n",
      "3799:\tlearn: 1.7777549\ttotal: 47.1s\tremaining: 9.88s\n",
      "3800:\tlearn: 1.7775005\ttotal: 47.1s\tremaining: 9.87s\n",
      "3801:\tlearn: 1.7772395\ttotal: 47.1s\tremaining: 9.86s\n",
      "3802:\tlearn: 1.7771934\ttotal: 47.1s\tremaining: 9.85s\n",
      "3803:\tlearn: 1.7769805\ttotal: 47.1s\tremaining: 9.83s\n",
      "3804:\tlearn: 1.7767465\ttotal: 47.1s\tremaining: 9.82s\n",
      "3805:\tlearn: 1.7764657\ttotal: 47.1s\tremaining: 9.81s\n",
      "3806:\tlearn: 1.7760423\ttotal: 47.1s\tremaining: 9.79s\n",
      "3807:\tlearn: 1.7759048\ttotal: 47.2s\tremaining: 9.78s\n",
      "3808:\tlearn: 1.7754163\ttotal: 47.2s\tremaining: 9.77s\n",
      "3809:\tlearn: 1.7753421\ttotal: 47.2s\tremaining: 9.76s\n",
      "3810:\tlearn: 1.7751466\ttotal: 47.2s\tremaining: 9.74s\n",
      "3811:\tlearn: 1.7748865\ttotal: 47.2s\tremaining: 9.73s\n",
      "3812:\tlearn: 1.7746293\ttotal: 47.2s\tremaining: 9.72s\n",
      "3813:\tlearn: 1.7744010\ttotal: 47.2s\tremaining: 9.71s\n",
      "3814:\tlearn: 1.7743727\ttotal: 47.2s\tremaining: 9.7s\n",
      "3815:\tlearn: 1.7742238\ttotal: 47.3s\tremaining: 9.68s\n",
      "3816:\tlearn: 1.7740973\ttotal: 47.3s\tremaining: 9.67s\n",
      "3817:\tlearn: 1.7736871\ttotal: 47.3s\tremaining: 9.66s\n",
      "3818:\tlearn: 1.7733325\ttotal: 47.3s\tremaining: 9.64s\n",
      "3819:\tlearn: 1.7730944\ttotal: 47.3s\tremaining: 9.63s\n",
      "3820:\tlearn: 1.7729877\ttotal: 47.3s\tremaining: 9.62s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3821:\tlearn: 1.7727463\ttotal: 47.3s\tremaining: 9.61s\n",
      "3822:\tlearn: 1.7724950\ttotal: 47.3s\tremaining: 9.6s\n",
      "3823:\tlearn: 1.7722062\ttotal: 47.3s\tremaining: 9.58s\n",
      "3824:\tlearn: 1.7719626\ttotal: 47.4s\tremaining: 9.57s\n",
      "3825:\tlearn: 1.7718880\ttotal: 47.4s\tremaining: 9.56s\n",
      "3826:\tlearn: 1.7718876\ttotal: 47.4s\tremaining: 9.55s\n",
      "3827:\tlearn: 1.7716374\ttotal: 47.4s\tremaining: 9.53s\n",
      "3828:\tlearn: 1.7715479\ttotal: 47.4s\tremaining: 9.52s\n",
      "3829:\tlearn: 1.7713892\ttotal: 47.4s\tremaining: 9.51s\n",
      "3830:\tlearn: 1.7709666\ttotal: 47.4s\tremaining: 9.5s\n",
      "3831:\tlearn: 1.7708840\ttotal: 47.4s\tremaining: 9.48s\n",
      "3832:\tlearn: 1.7707037\ttotal: 47.5s\tremaining: 9.47s\n",
      "3833:\tlearn: 1.7703777\ttotal: 47.5s\tremaining: 9.46s\n",
      "3834:\tlearn: 1.7702501\ttotal: 47.5s\tremaining: 9.45s\n",
      "3835:\tlearn: 1.7701231\ttotal: 47.5s\tremaining: 9.43s\n",
      "3836:\tlearn: 1.7696428\ttotal: 47.5s\tremaining: 9.42s\n",
      "3837:\tlearn: 1.7694777\ttotal: 47.5s\tremaining: 9.41s\n",
      "3838:\tlearn: 1.7694155\ttotal: 47.5s\tremaining: 9.4s\n",
      "3839:\tlearn: 1.7688206\ttotal: 47.5s\tremaining: 9.38s\n",
      "3840:\tlearn: 1.7687777\ttotal: 47.6s\tremaining: 9.37s\n",
      "3841:\tlearn: 1.7685993\ttotal: 47.6s\tremaining: 9.36s\n",
      "3842:\tlearn: 1.7683284\ttotal: 47.6s\tremaining: 9.35s\n",
      "3843:\tlearn: 1.7681178\ttotal: 47.6s\tremaining: 9.33s\n",
      "3844:\tlearn: 1.7678835\ttotal: 47.6s\tremaining: 9.32s\n",
      "3845:\tlearn: 1.7676566\ttotal: 47.6s\tremaining: 9.31s\n",
      "3846:\tlearn: 1.7674608\ttotal: 47.6s\tremaining: 9.3s\n",
      "3847:\tlearn: 1.7670956\ttotal: 47.6s\tremaining: 9.28s\n",
      "3848:\tlearn: 1.7667591\ttotal: 47.6s\tremaining: 9.27s\n",
      "3849:\tlearn: 1.7666315\ttotal: 47.7s\tremaining: 9.26s\n",
      "3850:\tlearn: 1.7663850\ttotal: 47.7s\tremaining: 9.25s\n",
      "3851:\tlearn: 1.7662248\ttotal: 47.7s\tremaining: 9.23s\n",
      "3852:\tlearn: 1.7660597\ttotal: 47.7s\tremaining: 9.22s\n",
      "3853:\tlearn: 1.7655537\ttotal: 47.7s\tremaining: 9.21s\n",
      "3854:\tlearn: 1.7654690\ttotal: 47.7s\tremaining: 9.2s\n",
      "3855:\tlearn: 1.7652114\ttotal: 47.7s\tremaining: 9.19s\n",
      "3856:\tlearn: 1.7650396\ttotal: 47.7s\tremaining: 9.17s\n",
      "3857:\tlearn: 1.7649286\ttotal: 47.8s\tremaining: 9.16s\n",
      "3858:\tlearn: 1.7648148\ttotal: 47.8s\tremaining: 9.15s\n",
      "3859:\tlearn: 1.7645979\ttotal: 47.8s\tremaining: 9.13s\n",
      "3860:\tlearn: 1.7642513\ttotal: 47.8s\tremaining: 9.12s\n",
      "3861:\tlearn: 1.7640151\ttotal: 47.8s\tremaining: 9.11s\n",
      "3862:\tlearn: 1.7636457\ttotal: 47.8s\tremaining: 9.1s\n",
      "3863:\tlearn: 1.7632585\ttotal: 47.8s\tremaining: 9.09s\n",
      "3864:\tlearn: 1.7628301\ttotal: 47.8s\tremaining: 9.07s\n",
      "3865:\tlearn: 1.7626454\ttotal: 47.9s\tremaining: 9.06s\n",
      "3866:\tlearn: 1.7624634\ttotal: 47.9s\tremaining: 9.05s\n",
      "3867:\tlearn: 1.7620442\ttotal: 47.9s\tremaining: 9.04s\n",
      "3868:\tlearn: 1.7618026\ttotal: 47.9s\tremaining: 9.02s\n",
      "3869:\tlearn: 1.7615221\ttotal: 47.9s\tremaining: 9.01s\n",
      "3870:\tlearn: 1.7612498\ttotal: 47.9s\tremaining: 9s\n",
      "3871:\tlearn: 1.7611211\ttotal: 47.9s\tremaining: 8.99s\n",
      "3872:\tlearn: 1.7608555\ttotal: 47.9s\tremaining: 8.97s\n",
      "3873:\tlearn: 1.7606783\ttotal: 48s\tremaining: 8.96s\n",
      "3874:\tlearn: 1.7606417\ttotal: 48s\tremaining: 8.95s\n",
      "3875:\tlearn: 1.7603603\ttotal: 48s\tremaining: 8.94s\n",
      "3876:\tlearn: 1.7601524\ttotal: 48s\tremaining: 8.92s\n",
      "3877:\tlearn: 1.7599755\ttotal: 48s\tremaining: 8.91s\n",
      "3878:\tlearn: 1.7598428\ttotal: 48s\tremaining: 8.9s\n",
      "3879:\tlearn: 1.7596337\ttotal: 48s\tremaining: 8.89s\n",
      "3880:\tlearn: 1.7593878\ttotal: 48s\tremaining: 8.87s\n",
      "3881:\tlearn: 1.7589609\ttotal: 48s\tremaining: 8.86s\n",
      "3882:\tlearn: 1.7589294\ttotal: 48.1s\tremaining: 8.85s\n",
      "3883:\tlearn: 1.7588430\ttotal: 48.1s\tremaining: 8.84s\n",
      "3884:\tlearn: 1.7585113\ttotal: 48.1s\tremaining: 8.82s\n",
      "3885:\tlearn: 1.7582610\ttotal: 48.1s\tremaining: 8.81s\n",
      "3886:\tlearn: 1.7581357\ttotal: 48.1s\tremaining: 8.8s\n",
      "3887:\tlearn: 1.7579558\ttotal: 48.1s\tremaining: 8.79s\n",
      "3888:\tlearn: 1.7577503\ttotal: 48.1s\tremaining: 8.77s\n",
      "3889:\tlearn: 1.7576667\ttotal: 48.1s\tremaining: 8.76s\n",
      "3890:\tlearn: 1.7574494\ttotal: 48.2s\tremaining: 8.75s\n",
      "3891:\tlearn: 1.7573345\ttotal: 48.2s\tremaining: 8.74s\n",
      "3892:\tlearn: 1.7571019\ttotal: 48.2s\tremaining: 8.72s\n",
      "3893:\tlearn: 1.7570099\ttotal: 48.2s\tremaining: 8.71s\n",
      "3894:\tlearn: 1.7569569\ttotal: 48.2s\tremaining: 8.7s\n",
      "3895:\tlearn: 1.7567215\ttotal: 48.2s\tremaining: 8.69s\n",
      "3896:\tlearn: 1.7564450\ttotal: 48.2s\tremaining: 8.68s\n",
      "3897:\tlearn: 1.7562221\ttotal: 48.2s\tremaining: 8.66s\n",
      "3898:\tlearn: 1.7561086\ttotal: 48.3s\tremaining: 8.65s\n",
      "3899:\tlearn: 1.7558306\ttotal: 48.3s\tremaining: 8.64s\n",
      "3900:\tlearn: 1.7557007\ttotal: 48.3s\tremaining: 8.63s\n",
      "3901:\tlearn: 1.7555692\ttotal: 48.3s\tremaining: 8.61s\n",
      "3902:\tlearn: 1.7554422\ttotal: 48.3s\tremaining: 8.6s\n",
      "3903:\tlearn: 1.7552391\ttotal: 48.3s\tremaining: 8.59s\n",
      "3904:\tlearn: 1.7550152\ttotal: 48.3s\tremaining: 8.57s\n",
      "3905:\tlearn: 1.7547573\ttotal: 48.3s\tremaining: 8.56s\n",
      "3906:\tlearn: 1.7544352\ttotal: 48.3s\tremaining: 8.55s\n",
      "3907:\tlearn: 1.7542208\ttotal: 48.4s\tremaining: 8.54s\n",
      "3908:\tlearn: 1.7541592\ttotal: 48.4s\tremaining: 8.53s\n",
      "3909:\tlearn: 1.7538457\ttotal: 48.4s\tremaining: 8.51s\n",
      "3910:\tlearn: 1.7534801\ttotal: 48.4s\tremaining: 8.5s\n",
      "3911:\tlearn: 1.7531134\ttotal: 48.4s\tremaining: 8.49s\n",
      "3912:\tlearn: 1.7529547\ttotal: 48.4s\tremaining: 8.48s\n",
      "3913:\tlearn: 1.7526059\ttotal: 48.4s\tremaining: 8.46s\n",
      "3914:\tlearn: 1.7522804\ttotal: 48.4s\tremaining: 8.45s\n",
      "3915:\tlearn: 1.7519861\ttotal: 48.5s\tremaining: 8.44s\n",
      "3916:\tlearn: 1.7516279\ttotal: 48.5s\tremaining: 8.43s\n",
      "3917:\tlearn: 1.7514404\ttotal: 48.5s\tremaining: 8.41s\n",
      "3918:\tlearn: 1.7511510\ttotal: 48.5s\tremaining: 8.4s\n",
      "3919:\tlearn: 1.7507861\ttotal: 48.5s\tremaining: 8.39s\n",
      "3920:\tlearn: 1.7506556\ttotal: 48.5s\tremaining: 8.38s\n",
      "3921:\tlearn: 1.7503013\ttotal: 48.5s\tremaining: 8.37s\n",
      "3922:\tlearn: 1.7499252\ttotal: 48.5s\tremaining: 8.35s\n",
      "3923:\tlearn: 1.7497405\ttotal: 48.6s\tremaining: 8.34s\n",
      "3924:\tlearn: 1.7494281\ttotal: 48.6s\tremaining: 8.33s\n",
      "3925:\tlearn: 1.7493899\ttotal: 48.6s\tremaining: 8.31s\n",
      "3926:\tlearn: 1.7491335\ttotal: 48.6s\tremaining: 8.3s\n",
      "3927:\tlearn: 1.7490031\ttotal: 48.6s\tremaining: 8.29s\n",
      "3928:\tlearn: 1.7487170\ttotal: 48.6s\tremaining: 8.28s\n",
      "3929:\tlearn: 1.7485180\ttotal: 48.6s\tremaining: 8.27s\n",
      "3930:\tlearn: 1.7481625\ttotal: 48.6s\tremaining: 8.25s\n",
      "3931:\tlearn: 1.7480733\ttotal: 48.7s\tremaining: 8.24s\n",
      "3932:\tlearn: 1.7478561\ttotal: 48.7s\tremaining: 8.23s\n",
      "3933:\tlearn: 1.7476049\ttotal: 48.7s\tremaining: 8.22s\n",
      "3934:\tlearn: 1.7472494\ttotal: 48.7s\tremaining: 8.2s\n",
      "3935:\tlearn: 1.7470207\ttotal: 48.7s\tremaining: 8.19s\n",
      "3936:\tlearn: 1.7469514\ttotal: 48.7s\tremaining: 8.18s\n",
      "3937:\tlearn: 1.7468367\ttotal: 48.7s\tremaining: 8.17s\n",
      "3938:\tlearn: 1.7465516\ttotal: 48.7s\tremaining: 8.15s\n",
      "3939:\tlearn: 1.7463007\ttotal: 48.8s\tremaining: 8.14s\n",
      "3940:\tlearn: 1.7460765\ttotal: 48.8s\tremaining: 8.13s\n",
      "3941:\tlearn: 1.7459632\ttotal: 48.8s\tremaining: 8.12s\n",
      "3942:\tlearn: 1.7455260\ttotal: 48.8s\tremaining: 8.1s\n",
      "3943:\tlearn: 1.7454096\ttotal: 48.8s\tremaining: 8.09s\n",
      "3944:\tlearn: 1.7452449\ttotal: 48.8s\tremaining: 8.08s\n",
      "3945:\tlearn: 1.7447459\ttotal: 48.8s\tremaining: 8.07s\n",
      "3946:\tlearn: 1.7444576\ttotal: 48.8s\tremaining: 8.05s\n",
      "3947:\tlearn: 1.7441684\ttotal: 48.9s\tremaining: 8.04s\n",
      "3948:\tlearn: 1.7440693\ttotal: 48.9s\tremaining: 8.03s\n",
      "3949:\tlearn: 1.7439592\ttotal: 48.9s\tremaining: 8.02s\n",
      "3950:\tlearn: 1.7437957\ttotal: 48.9s\tremaining: 8.01s\n",
      "3951:\tlearn: 1.7432889\ttotal: 48.9s\tremaining: 7.99s\n",
      "3952:\tlearn: 1.7430942\ttotal: 48.9s\tremaining: 7.98s\n",
      "3953:\tlearn: 1.7429222\ttotal: 48.9s\tremaining: 7.97s\n",
      "3954:\tlearn: 1.7428860\ttotal: 48.9s\tremaining: 7.96s\n",
      "3955:\tlearn: 1.7427877\ttotal: 48.9s\tremaining: 7.94s\n",
      "3956:\tlearn: 1.7423141\ttotal: 49s\tremaining: 7.93s\n",
      "3957:\tlearn: 1.7421735\ttotal: 49s\tremaining: 7.92s\n",
      "3958:\tlearn: 1.7417128\ttotal: 49s\tremaining: 7.91s\n",
      "3959:\tlearn: 1.7415091\ttotal: 49s\tremaining: 7.89s\n",
      "3960:\tlearn: 1.7413057\ttotal: 49s\tremaining: 7.88s\n",
      "3961:\tlearn: 1.7410548\ttotal: 49s\tremaining: 7.87s\n",
      "3962:\tlearn: 1.7406280\ttotal: 49s\tremaining: 7.86s\n",
      "3963:\tlearn: 1.7404346\ttotal: 49s\tremaining: 7.84s\n",
      "3964:\tlearn: 1.7403378\ttotal: 49.1s\tremaining: 7.83s\n",
      "3965:\tlearn: 1.7401247\ttotal: 49.1s\tremaining: 7.82s\n",
      "3966:\tlearn: 1.7399781\ttotal: 49.1s\tremaining: 7.81s\n",
      "3967:\tlearn: 1.7398520\ttotal: 49.1s\tremaining: 7.79s\n",
      "3968:\tlearn: 1.7396984\ttotal: 49.1s\tremaining: 7.78s\n",
      "3969:\tlearn: 1.7396103\ttotal: 49.1s\tremaining: 7.77s\n",
      "3970:\tlearn: 1.7392406\ttotal: 49.1s\tremaining: 7.76s\n",
      "3971:\tlearn: 1.7388524\ttotal: 49.1s\tremaining: 7.75s\n",
      "3972:\tlearn: 1.7385025\ttotal: 49.2s\tremaining: 7.73s\n",
      "3973:\tlearn: 1.7382643\ttotal: 49.2s\tremaining: 7.72s\n",
      "3974:\tlearn: 1.7379114\ttotal: 49.2s\tremaining: 7.71s\n",
      "3975:\tlearn: 1.7376146\ttotal: 49.2s\tremaining: 7.7s\n",
      "3976:\tlearn: 1.7373269\ttotal: 49.2s\tremaining: 7.68s\n",
      "3977:\tlearn: 1.7369437\ttotal: 49.2s\tremaining: 7.67s\n",
      "3978:\tlearn: 1.7365404\ttotal: 49.2s\tremaining: 7.66s\n",
      "3979:\tlearn: 1.7363052\ttotal: 49.2s\tremaining: 7.65s\n",
      "3980:\tlearn: 1.7359936\ttotal: 49.3s\tremaining: 7.63s\n",
      "3981:\tlearn: 1.7357949\ttotal: 49.3s\tremaining: 7.62s\n",
      "3982:\tlearn: 1.7355122\ttotal: 49.3s\tremaining: 7.61s\n",
      "3983:\tlearn: 1.7354000\ttotal: 49.3s\tremaining: 7.6s\n",
      "3984:\tlearn: 1.7351477\ttotal: 49.3s\tremaining: 7.58s\n",
      "3985:\tlearn: 1.7347551\ttotal: 49.3s\tremaining: 7.57s\n",
      "3986:\tlearn: 1.7343783\ttotal: 49.3s\tremaining: 7.56s\n",
      "3987:\tlearn: 1.7342061\ttotal: 49.3s\tremaining: 7.55s\n",
      "3988:\tlearn: 1.7340147\ttotal: 49.4s\tremaining: 7.54s\n",
      "3989:\tlearn: 1.7338835\ttotal: 49.4s\tremaining: 7.52s\n",
      "3990:\tlearn: 1.7336202\ttotal: 49.4s\tremaining: 7.51s\n",
      "3991:\tlearn: 1.7333128\ttotal: 49.4s\tremaining: 7.5s\n",
      "3992:\tlearn: 1.7330172\ttotal: 49.4s\tremaining: 7.49s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3993:\tlearn: 1.7327030\ttotal: 49.4s\tremaining: 7.47s\n",
      "3994:\tlearn: 1.7326008\ttotal: 49.4s\tremaining: 7.46s\n",
      "3995:\tlearn: 1.7323616\ttotal: 49.4s\tremaining: 7.45s\n",
      "3996:\tlearn: 1.7321903\ttotal: 49.5s\tremaining: 7.43s\n",
      "3997:\tlearn: 1.7319915\ttotal: 49.5s\tremaining: 7.42s\n",
      "3998:\tlearn: 1.7318695\ttotal: 49.5s\tremaining: 7.41s\n",
      "3999:\tlearn: 1.7317240\ttotal: 49.5s\tremaining: 7.4s\n",
      "4000:\tlearn: 1.7312972\ttotal: 49.5s\tremaining: 7.39s\n",
      "4001:\tlearn: 1.7310546\ttotal: 49.5s\tremaining: 7.37s\n",
      "4002:\tlearn: 1.7308647\ttotal: 49.5s\tremaining: 7.36s\n",
      "4003:\tlearn: 1.7307473\ttotal: 49.5s\tremaining: 7.35s\n",
      "4004:\tlearn: 1.7305618\ttotal: 49.5s\tremaining: 7.34s\n",
      "4005:\tlearn: 1.7304931\ttotal: 49.6s\tremaining: 7.32s\n",
      "4006:\tlearn: 1.7302970\ttotal: 49.6s\tremaining: 7.31s\n",
      "4007:\tlearn: 1.7300479\ttotal: 49.6s\tremaining: 7.3s\n",
      "4008:\tlearn: 1.7299931\ttotal: 49.6s\tremaining: 7.29s\n",
      "4009:\tlearn: 1.7296034\ttotal: 49.6s\tremaining: 7.27s\n",
      "4010:\tlearn: 1.7295223\ttotal: 49.6s\tremaining: 7.26s\n",
      "4011:\tlearn: 1.7292429\ttotal: 49.6s\tremaining: 7.25s\n",
      "4012:\tlearn: 1.7291398\ttotal: 49.6s\tremaining: 7.24s\n",
      "4013:\tlearn: 1.7287898\ttotal: 49.7s\tremaining: 7.23s\n",
      "4014:\tlearn: 1.7283537\ttotal: 49.7s\tremaining: 7.21s\n",
      "4015:\tlearn: 1.7279584\ttotal: 49.7s\tremaining: 7.2s\n",
      "4016:\tlearn: 1.7277923\ttotal: 49.7s\tremaining: 7.19s\n",
      "4017:\tlearn: 1.7276882\ttotal: 49.7s\tremaining: 7.18s\n",
      "4018:\tlearn: 1.7273985\ttotal: 49.7s\tremaining: 7.16s\n",
      "4019:\tlearn: 1.7271374\ttotal: 49.7s\tremaining: 7.15s\n",
      "4020:\tlearn: 1.7269159\ttotal: 49.8s\tremaining: 7.14s\n",
      "4021:\tlearn: 1.7266526\ttotal: 49.8s\tremaining: 7.13s\n",
      "4022:\tlearn: 1.7263955\ttotal: 49.8s\tremaining: 7.11s\n",
      "4023:\tlearn: 1.7260797\ttotal: 49.8s\tremaining: 7.1s\n",
      "4024:\tlearn: 1.7260008\ttotal: 49.8s\tremaining: 7.09s\n",
      "4025:\tlearn: 1.7257760\ttotal: 49.8s\tremaining: 7.08s\n",
      "4026:\tlearn: 1.7254882\ttotal: 49.8s\tremaining: 7.06s\n",
      "4027:\tlearn: 1.7253174\ttotal: 49.8s\tremaining: 7.05s\n",
      "4028:\tlearn: 1.7251491\ttotal: 49.8s\tremaining: 7.04s\n",
      "4029:\tlearn: 1.7245926\ttotal: 49.9s\tremaining: 7.03s\n",
      "4030:\tlearn: 1.7242073\ttotal: 49.9s\tremaining: 7.01s\n",
      "4031:\tlearn: 1.7239694\ttotal: 49.9s\tremaining: 7s\n",
      "4032:\tlearn: 1.7237355\ttotal: 49.9s\tremaining: 6.99s\n",
      "4033:\tlearn: 1.7234251\ttotal: 49.9s\tremaining: 6.98s\n",
      "4034:\tlearn: 1.7232239\ttotal: 49.9s\tremaining: 6.96s\n",
      "4035:\tlearn: 1.7230610\ttotal: 49.9s\tremaining: 6.95s\n",
      "4036:\tlearn: 1.7228100\ttotal: 49.9s\tremaining: 6.94s\n",
      "4037:\tlearn: 1.7226008\ttotal: 50s\tremaining: 6.93s\n",
      "4038:\tlearn: 1.7225454\ttotal: 50s\tremaining: 6.92s\n",
      "4039:\tlearn: 1.7221280\ttotal: 50s\tremaining: 6.9s\n",
      "4040:\tlearn: 1.7219174\ttotal: 50s\tremaining: 6.89s\n",
      "4041:\tlearn: 1.7216580\ttotal: 50s\tremaining: 6.88s\n",
      "4042:\tlearn: 1.7214703\ttotal: 50s\tremaining: 6.87s\n",
      "4043:\tlearn: 1.7208853\ttotal: 50s\tremaining: 6.86s\n",
      "4044:\tlearn: 1.7208038\ttotal: 50.1s\tremaining: 6.84s\n",
      "4045:\tlearn: 1.7206988\ttotal: 50.1s\tremaining: 6.83s\n",
      "4046:\tlearn: 1.7205938\ttotal: 50.1s\tremaining: 6.82s\n",
      "4047:\tlearn: 1.7203886\ttotal: 50.1s\tremaining: 6.81s\n",
      "4048:\tlearn: 1.7201244\ttotal: 50.1s\tremaining: 6.79s\n",
      "4049:\tlearn: 1.7197997\ttotal: 50.1s\tremaining: 6.78s\n",
      "4050:\tlearn: 1.7194590\ttotal: 50.1s\tremaining: 6.77s\n",
      "4051:\tlearn: 1.7192818\ttotal: 50.1s\tremaining: 6.76s\n",
      "4052:\tlearn: 1.7192206\ttotal: 50.2s\tremaining: 6.74s\n",
      "4053:\tlearn: 1.7189210\ttotal: 50.2s\tremaining: 6.73s\n",
      "4054:\tlearn: 1.7187814\ttotal: 50.2s\tremaining: 6.72s\n",
      "4055:\tlearn: 1.7184935\ttotal: 50.2s\tremaining: 6.71s\n",
      "4056:\tlearn: 1.7182532\ttotal: 50.2s\tremaining: 6.69s\n",
      "4057:\tlearn: 1.7179690\ttotal: 50.2s\tremaining: 6.68s\n",
      "4058:\tlearn: 1.7178625\ttotal: 50.2s\tremaining: 6.67s\n",
      "4059:\tlearn: 1.7176343\ttotal: 50.2s\tremaining: 6.66s\n",
      "4060:\tlearn: 1.7173137\ttotal: 50.3s\tremaining: 6.64s\n",
      "4061:\tlearn: 1.7170707\ttotal: 50.3s\tremaining: 6.63s\n",
      "4062:\tlearn: 1.7169405\ttotal: 50.3s\tremaining: 6.62s\n",
      "4063:\tlearn: 1.7166209\ttotal: 50.3s\tremaining: 6.61s\n",
      "4064:\tlearn: 1.7164988\ttotal: 50.3s\tremaining: 6.6s\n",
      "4065:\tlearn: 1.7162019\ttotal: 50.3s\tremaining: 6.58s\n",
      "4066:\tlearn: 1.7160253\ttotal: 50.3s\tremaining: 6.57s\n",
      "4067:\tlearn: 1.7156853\ttotal: 50.3s\tremaining: 6.56s\n",
      "4068:\tlearn: 1.7156683\ttotal: 50.4s\tremaining: 6.55s\n",
      "4069:\tlearn: 1.7154773\ttotal: 50.4s\tremaining: 6.53s\n",
      "4070:\tlearn: 1.7153606\ttotal: 50.4s\tremaining: 6.52s\n",
      "4071:\tlearn: 1.7151539\ttotal: 50.4s\tremaining: 6.51s\n",
      "4072:\tlearn: 1.7148764\ttotal: 50.4s\tremaining: 6.5s\n",
      "4073:\tlearn: 1.7144784\ttotal: 50.4s\tremaining: 6.48s\n",
      "4074:\tlearn: 1.7142576\ttotal: 50.4s\tremaining: 6.47s\n",
      "4075:\tlearn: 1.7141822\ttotal: 50.4s\tremaining: 6.46s\n",
      "4076:\tlearn: 1.7139838\ttotal: 50.4s\tremaining: 6.45s\n",
      "4077:\tlearn: 1.7138010\ttotal: 50.5s\tremaining: 6.43s\n",
      "4078:\tlearn: 1.7135755\ttotal: 50.5s\tremaining: 6.42s\n",
      "4079:\tlearn: 1.7134579\ttotal: 50.5s\tremaining: 6.41s\n",
      "4080:\tlearn: 1.7133538\ttotal: 50.5s\tremaining: 6.4s\n",
      "4081:\tlearn: 1.7132054\ttotal: 50.5s\tremaining: 6.38s\n",
      "4082:\tlearn: 1.7130543\ttotal: 50.5s\tremaining: 6.37s\n",
      "4083:\tlearn: 1.7127491\ttotal: 50.5s\tremaining: 6.36s\n",
      "4084:\tlearn: 1.7125159\ttotal: 50.5s\tremaining: 6.35s\n",
      "4085:\tlearn: 1.7122531\ttotal: 50.6s\tremaining: 6.33s\n",
      "4086:\tlearn: 1.7118805\ttotal: 50.6s\tremaining: 6.32s\n",
      "4087:\tlearn: 1.7117236\ttotal: 50.6s\tremaining: 6.31s\n",
      "4088:\tlearn: 1.7113932\ttotal: 50.6s\tremaining: 6.3s\n",
      "4089:\tlearn: 1.7111004\ttotal: 50.6s\tremaining: 6.29s\n",
      "4090:\tlearn: 1.7109192\ttotal: 50.6s\tremaining: 6.27s\n",
      "4091:\tlearn: 1.7107297\ttotal: 50.6s\tremaining: 6.26s\n",
      "4092:\tlearn: 1.7105347\ttotal: 50.6s\tremaining: 6.25s\n",
      "4093:\tlearn: 1.7103337\ttotal: 50.6s\tremaining: 6.24s\n",
      "4094:\tlearn: 1.7101088\ttotal: 50.7s\tremaining: 6.22s\n",
      "4095:\tlearn: 1.7100097\ttotal: 50.7s\tremaining: 6.21s\n",
      "4096:\tlearn: 1.7098495\ttotal: 50.7s\tremaining: 6.2s\n",
      "4097:\tlearn: 1.7095040\ttotal: 50.7s\tremaining: 6.18s\n",
      "4098:\tlearn: 1.7092362\ttotal: 50.7s\tremaining: 6.17s\n",
      "4099:\tlearn: 1.7090577\ttotal: 50.7s\tremaining: 6.16s\n",
      "4100:\tlearn: 1.7088198\ttotal: 50.7s\tremaining: 6.15s\n",
      "4101:\tlearn: 1.7085411\ttotal: 50.7s\tremaining: 6.14s\n",
      "4102:\tlearn: 1.7083809\ttotal: 50.8s\tremaining: 6.12s\n",
      "4103:\tlearn: 1.7080266\ttotal: 50.8s\tremaining: 6.11s\n",
      "4104:\tlearn: 1.7078918\ttotal: 50.8s\tremaining: 6.1s\n",
      "4105:\tlearn: 1.7076044\ttotal: 50.8s\tremaining: 6.09s\n",
      "4106:\tlearn: 1.7073112\ttotal: 50.8s\tremaining: 6.07s\n",
      "4107:\tlearn: 1.7068031\ttotal: 50.8s\tremaining: 6.06s\n",
      "4108:\tlearn: 1.7064426\ttotal: 50.8s\tremaining: 6.05s\n",
      "4109:\tlearn: 1.7061946\ttotal: 50.8s\tremaining: 6.04s\n",
      "4110:\tlearn: 1.7059872\ttotal: 50.9s\tremaining: 6.03s\n",
      "4111:\tlearn: 1.7058183\ttotal: 50.9s\tremaining: 6.01s\n",
      "4112:\tlearn: 1.7056312\ttotal: 50.9s\tremaining: 6s\n",
      "4113:\tlearn: 1.7054818\ttotal: 50.9s\tremaining: 5.99s\n",
      "4114:\tlearn: 1.7053199\ttotal: 50.9s\tremaining: 5.97s\n",
      "4115:\tlearn: 1.7050254\ttotal: 50.9s\tremaining: 5.96s\n",
      "4116:\tlearn: 1.7048286\ttotal: 50.9s\tremaining: 5.95s\n",
      "4117:\tlearn: 1.7045536\ttotal: 51s\tremaining: 5.94s\n",
      "4118:\tlearn: 1.7044562\ttotal: 51s\tremaining: 5.93s\n",
      "4119:\tlearn: 1.7041494\ttotal: 51s\tremaining: 5.91s\n",
      "4120:\tlearn: 1.7040629\ttotal: 51s\tremaining: 5.9s\n",
      "4121:\tlearn: 1.7038783\ttotal: 51s\tremaining: 5.89s\n",
      "4122:\tlearn: 1.7036124\ttotal: 51s\tremaining: 5.88s\n",
      "4123:\tlearn: 1.7032631\ttotal: 51s\tremaining: 5.86s\n",
      "4124:\tlearn: 1.7030311\ttotal: 51s\tremaining: 5.85s\n",
      "4125:\tlearn: 1.7029039\ttotal: 51s\tremaining: 5.84s\n",
      "4126:\tlearn: 1.7028807\ttotal: 51.1s\tremaining: 5.83s\n",
      "4127:\tlearn: 1.7026664\ttotal: 51.1s\tremaining: 5.81s\n",
      "4128:\tlearn: 1.7024111\ttotal: 51.1s\tremaining: 5.8s\n",
      "4129:\tlearn: 1.7020803\ttotal: 51.1s\tremaining: 5.79s\n",
      "4130:\tlearn: 1.7019228\ttotal: 51.1s\tremaining: 5.78s\n",
      "4131:\tlearn: 1.7016921\ttotal: 51.1s\tremaining: 5.76s\n",
      "4132:\tlearn: 1.7013300\ttotal: 51.1s\tremaining: 5.75s\n",
      "4133:\tlearn: 1.7010328\ttotal: 51.1s\tremaining: 5.74s\n",
      "4134:\tlearn: 1.7007039\ttotal: 51.2s\tremaining: 5.73s\n",
      "4135:\tlearn: 1.7005031\ttotal: 51.2s\tremaining: 5.72s\n",
      "4136:\tlearn: 1.7004659\ttotal: 51.2s\tremaining: 5.7s\n",
      "4137:\tlearn: 1.7001470\ttotal: 51.2s\tremaining: 5.69s\n",
      "4138:\tlearn: 1.6999004\ttotal: 51.2s\tremaining: 5.68s\n",
      "4139:\tlearn: 1.6997018\ttotal: 51.2s\tremaining: 5.67s\n",
      "4140:\tlearn: 1.6996409\ttotal: 51.2s\tremaining: 5.65s\n",
      "4141:\tlearn: 1.6990628\ttotal: 51.2s\tremaining: 5.64s\n",
      "4142:\tlearn: 1.6986261\ttotal: 51.3s\tremaining: 5.63s\n",
      "4143:\tlearn: 1.6984073\ttotal: 51.3s\tremaining: 5.62s\n",
      "4144:\tlearn: 1.6982438\ttotal: 51.3s\tremaining: 5.6s\n",
      "4145:\tlearn: 1.6981098\ttotal: 51.3s\tremaining: 5.59s\n",
      "4146:\tlearn: 1.6978705\ttotal: 51.3s\tremaining: 5.58s\n",
      "4147:\tlearn: 1.6976744\ttotal: 51.3s\tremaining: 5.57s\n",
      "4148:\tlearn: 1.6974097\ttotal: 51.3s\tremaining: 5.55s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4149:\tlearn: 1.6971421\ttotal: 51.3s\tremaining: 5.54s\n",
      "4150:\tlearn: 1.6966494\ttotal: 51.4s\tremaining: 5.53s\n",
      "4151:\tlearn: 1.6964719\ttotal: 51.4s\tremaining: 5.52s\n",
      "4152:\tlearn: 1.6963205\ttotal: 51.4s\tremaining: 5.5s\n",
      "4153:\tlearn: 1.6961147\ttotal: 51.4s\tremaining: 5.49s\n",
      "4154:\tlearn: 1.6959574\ttotal: 51.4s\tremaining: 5.48s\n",
      "4155:\tlearn: 1.6958749\ttotal: 51.4s\tremaining: 5.47s\n",
      "4156:\tlearn: 1.6956098\ttotal: 51.4s\tremaining: 5.46s\n",
      "4157:\tlearn: 1.6954471\ttotal: 51.4s\tremaining: 5.44s\n",
      "4158:\tlearn: 1.6952767\ttotal: 51.5s\tremaining: 5.43s\n",
      "4159:\tlearn: 1.6950797\ttotal: 51.5s\tremaining: 5.42s\n",
      "4160:\tlearn: 1.6947589\ttotal: 51.5s\tremaining: 5.41s\n",
      "4161:\tlearn: 1.6947278\ttotal: 51.5s\tremaining: 5.39s\n",
      "4162:\tlearn: 1.6943336\ttotal: 51.5s\tremaining: 5.38s\n",
      "4163:\tlearn: 1.6940917\ttotal: 51.5s\tremaining: 5.37s\n",
      "4164:\tlearn: 1.6937414\ttotal: 51.5s\tremaining: 5.36s\n",
      "4165:\tlearn: 1.6935272\ttotal: 51.5s\tremaining: 5.34s\n",
      "4166:\tlearn: 1.6933610\ttotal: 51.6s\tremaining: 5.33s\n",
      "4167:\tlearn: 1.6932479\ttotal: 51.6s\tremaining: 5.32s\n",
      "4168:\tlearn: 1.6930316\ttotal: 51.6s\tremaining: 5.31s\n",
      "4169:\tlearn: 1.6927840\ttotal: 51.6s\tremaining: 5.29s\n",
      "4170:\tlearn: 1.6925212\ttotal: 51.6s\tremaining: 5.28s\n",
      "4171:\tlearn: 1.6922443\ttotal: 51.6s\tremaining: 5.27s\n",
      "4172:\tlearn: 1.6920581\ttotal: 51.6s\tremaining: 5.26s\n",
      "4173:\tlearn: 1.6919339\ttotal: 51.6s\tremaining: 5.25s\n",
      "4174:\tlearn: 1.6917818\ttotal: 51.7s\tremaining: 5.23s\n",
      "4175:\tlearn: 1.6913887\ttotal: 51.7s\tremaining: 5.22s\n",
      "4176:\tlearn: 1.6911374\ttotal: 51.7s\tremaining: 5.21s\n",
      "4177:\tlearn: 1.6908687\ttotal: 51.7s\tremaining: 5.2s\n",
      "4178:\tlearn: 1.6907448\ttotal: 51.7s\tremaining: 5.18s\n",
      "4179:\tlearn: 1.6905182\ttotal: 51.7s\tremaining: 5.17s\n",
      "4180:\tlearn: 1.6904187\ttotal: 51.7s\tremaining: 5.16s\n",
      "4181:\tlearn: 1.6899383\ttotal: 51.7s\tremaining: 5.15s\n",
      "4182:\tlearn: 1.6896541\ttotal: 51.7s\tremaining: 5.13s\n",
      "4183:\tlearn: 1.6894270\ttotal: 51.8s\tremaining: 5.12s\n",
      "4184:\tlearn: 1.6891968\ttotal: 51.8s\tremaining: 5.11s\n",
      "4185:\tlearn: 1.6888427\ttotal: 51.8s\tremaining: 5.1s\n",
      "4186:\tlearn: 1.6886295\ttotal: 51.8s\tremaining: 5.08s\n",
      "4187:\tlearn: 1.6883969\ttotal: 51.8s\tremaining: 5.07s\n",
      "4188:\tlearn: 1.6880151\ttotal: 51.8s\tremaining: 5.06s\n",
      "4189:\tlearn: 1.6880146\ttotal: 51.8s\tremaining: 5.05s\n",
      "4190:\tlearn: 1.6880141\ttotal: 51.8s\tremaining: 5.03s\n",
      "4191:\tlearn: 1.6877084\ttotal: 51.9s\tremaining: 5.02s\n",
      "4192:\tlearn: 1.6871185\ttotal: 51.9s\tremaining: 5.01s\n",
      "4193:\tlearn: 1.6869669\ttotal: 51.9s\tremaining: 5s\n",
      "4194:\tlearn: 1.6867185\ttotal: 51.9s\tremaining: 4.99s\n",
      "4195:\tlearn: 1.6866144\ttotal: 51.9s\tremaining: 4.97s\n",
      "4196:\tlearn: 1.6864260\ttotal: 51.9s\tremaining: 4.96s\n",
      "4197:\tlearn: 1.6862747\ttotal: 51.9s\tremaining: 4.95s\n",
      "4198:\tlearn: 1.6859095\ttotal: 51.9s\tremaining: 4.93s\n",
      "4199:\tlearn: 1.6856701\ttotal: 52s\tremaining: 4.92s\n",
      "4200:\tlearn: 1.6855998\ttotal: 52s\tremaining: 4.91s\n",
      "4201:\tlearn: 1.6852481\ttotal: 52s\tremaining: 4.9s\n",
      "4202:\tlearn: 1.6851300\ttotal: 52s\tremaining: 4.89s\n",
      "4203:\tlearn: 1.6848485\ttotal: 52s\tremaining: 4.87s\n",
      "4204:\tlearn: 1.6847114\ttotal: 52s\tremaining: 4.86s\n",
      "4205:\tlearn: 1.6844258\ttotal: 52s\tremaining: 4.85s\n",
      "4206:\tlearn: 1.6843371\ttotal: 52s\tremaining: 4.84s\n",
      "4207:\tlearn: 1.6842781\ttotal: 52s\tremaining: 4.82s\n",
      "4208:\tlearn: 1.6842720\ttotal: 52.1s\tremaining: 4.81s\n",
      "4209:\tlearn: 1.6840563\ttotal: 52.1s\tremaining: 4.8s\n",
      "4210:\tlearn: 1.6838241\ttotal: 52.1s\tremaining: 4.79s\n",
      "4211:\tlearn: 1.6837668\ttotal: 52.1s\tremaining: 4.77s\n",
      "4212:\tlearn: 1.6836054\ttotal: 52.1s\tremaining: 4.76s\n",
      "4213:\tlearn: 1.6833132\ttotal: 52.1s\tremaining: 4.75s\n",
      "4214:\tlearn: 1.6831364\ttotal: 52.1s\tremaining: 4.74s\n",
      "4215:\tlearn: 1.6827224\ttotal: 52.1s\tremaining: 4.72s\n",
      "4216:\tlearn: 1.6825698\ttotal: 52.2s\tremaining: 4.71s\n",
      "4217:\tlearn: 1.6822627\ttotal: 52.2s\tremaining: 4.7s\n",
      "4218:\tlearn: 1.6819886\ttotal: 52.2s\tremaining: 4.69s\n",
      "4219:\tlearn: 1.6818950\ttotal: 52.2s\tremaining: 4.67s\n",
      "4220:\tlearn: 1.6818092\ttotal: 52.2s\tremaining: 4.66s\n",
      "4221:\tlearn: 1.6816325\ttotal: 52.2s\tremaining: 4.65s\n",
      "4222:\tlearn: 1.6814631\ttotal: 52.2s\tremaining: 4.64s\n",
      "4223:\tlearn: 1.6812077\ttotal: 52.2s\tremaining: 4.63s\n",
      "4224:\tlearn: 1.6809152\ttotal: 52.3s\tremaining: 4.61s\n",
      "4225:\tlearn: 1.6807343\ttotal: 52.3s\tremaining: 4.6s\n",
      "4226:\tlearn: 1.6805063\ttotal: 52.3s\tremaining: 4.59s\n",
      "4227:\tlearn: 1.6802119\ttotal: 52.3s\tremaining: 4.58s\n",
      "4228:\tlearn: 1.6801183\ttotal: 52.3s\tremaining: 4.56s\n",
      "4229:\tlearn: 1.6799748\ttotal: 52.3s\tremaining: 4.55s\n",
      "4230:\tlearn: 1.6798251\ttotal: 52.3s\tremaining: 4.54s\n",
      "4231:\tlearn: 1.6793775\ttotal: 52.3s\tremaining: 4.53s\n",
      "4232:\tlearn: 1.6791428\ttotal: 52.4s\tremaining: 4.51s\n",
      "4233:\tlearn: 1.6789221\ttotal: 52.4s\tremaining: 4.5s\n",
      "4234:\tlearn: 1.6785792\ttotal: 52.4s\tremaining: 4.49s\n",
      "4235:\tlearn: 1.6783560\ttotal: 52.4s\tremaining: 4.48s\n",
      "4236:\tlearn: 1.6780909\ttotal: 52.4s\tremaining: 4.46s\n",
      "4237:\tlearn: 1.6778146\ttotal: 52.4s\tremaining: 4.45s\n",
      "4238:\tlearn: 1.6776496\ttotal: 52.4s\tremaining: 4.44s\n",
      "4239:\tlearn: 1.6774519\ttotal: 52.4s\tremaining: 4.43s\n",
      "4240:\tlearn: 1.6771637\ttotal: 52.5s\tremaining: 4.42s\n",
      "4241:\tlearn: 1.6767879\ttotal: 52.5s\tremaining: 4.4s\n",
      "4242:\tlearn: 1.6765072\ttotal: 52.5s\tremaining: 4.39s\n",
      "4243:\tlearn: 1.6764326\ttotal: 52.5s\tremaining: 4.38s\n",
      "4244:\tlearn: 1.6762430\ttotal: 52.5s\tremaining: 4.37s\n",
      "4245:\tlearn: 1.6760416\ttotal: 52.5s\tremaining: 4.35s\n",
      "4246:\tlearn: 1.6758388\ttotal: 52.5s\tremaining: 4.34s\n",
      "4247:\tlearn: 1.6756659\ttotal: 52.5s\tremaining: 4.33s\n",
      "4248:\tlearn: 1.6755128\ttotal: 52.6s\tremaining: 4.32s\n",
      "4249:\tlearn: 1.6754005\ttotal: 52.6s\tremaining: 4.3s\n",
      "4250:\tlearn: 1.6750999\ttotal: 52.6s\tremaining: 4.29s\n",
      "4251:\tlearn: 1.6748189\ttotal: 52.6s\tremaining: 4.28s\n",
      "4252:\tlearn: 1.6747280\ttotal: 52.6s\tremaining: 4.27s\n",
      "4253:\tlearn: 1.6745897\ttotal: 52.6s\tremaining: 4.25s\n",
      "4254:\tlearn: 1.6743970\ttotal: 52.6s\tremaining: 4.24s\n",
      "4255:\tlearn: 1.6742584\ttotal: 52.6s\tremaining: 4.23s\n",
      "4256:\tlearn: 1.6741794\ttotal: 52.6s\tremaining: 4.22s\n",
      "4257:\tlearn: 1.6739003\ttotal: 52.7s\tremaining: 4.21s\n",
      "4258:\tlearn: 1.6738459\ttotal: 52.7s\tremaining: 4.19s\n",
      "4259:\tlearn: 1.6737059\ttotal: 52.7s\tremaining: 4.18s\n",
      "4260:\tlearn: 1.6735846\ttotal: 52.7s\tremaining: 4.17s\n",
      "4261:\tlearn: 1.6734304\ttotal: 52.7s\tremaining: 4.16s\n",
      "4262:\tlearn: 1.6731857\ttotal: 52.7s\tremaining: 4.14s\n",
      "4263:\tlearn: 1.6730192\ttotal: 52.7s\tremaining: 4.13s\n",
      "4264:\tlearn: 1.6728511\ttotal: 52.7s\tremaining: 4.12s\n",
      "4265:\tlearn: 1.6727406\ttotal: 52.8s\tremaining: 4.11s\n",
      "4266:\tlearn: 1.6724985\ttotal: 52.8s\tremaining: 4.09s\n",
      "4267:\tlearn: 1.6721092\ttotal: 52.8s\tremaining: 4.08s\n",
      "4268:\tlearn: 1.6719779\ttotal: 52.8s\tremaining: 4.07s\n",
      "4269:\tlearn: 1.6717608\ttotal: 52.8s\tremaining: 4.06s\n",
      "4270:\tlearn: 1.6716238\ttotal: 52.8s\tremaining: 4.04s\n",
      "4271:\tlearn: 1.6713997\ttotal: 52.8s\tremaining: 4.03s\n",
      "4272:\tlearn: 1.6712479\ttotal: 52.8s\tremaining: 4.02s\n",
      "4273:\tlearn: 1.6711205\ttotal: 52.9s\tremaining: 4.01s\n",
      "4274:\tlearn: 1.6708826\ttotal: 52.9s\tremaining: 3.99s\n",
      "4275:\tlearn: 1.6704549\ttotal: 52.9s\tremaining: 3.98s\n",
      "4276:\tlearn: 1.6702807\ttotal: 52.9s\tremaining: 3.97s\n",
      "4277:\tlearn: 1.6700720\ttotal: 52.9s\tremaining: 3.96s\n",
      "4278:\tlearn: 1.6698744\ttotal: 52.9s\tremaining: 3.94s\n",
      "4279:\tlearn: 1.6697151\ttotal: 52.9s\tremaining: 3.93s\n",
      "4280:\tlearn: 1.6694706\ttotal: 52.9s\tremaining: 3.92s\n",
      "4281:\tlearn: 1.6692666\ttotal: 53s\tremaining: 3.91s\n",
      "4282:\tlearn: 1.6691191\ttotal: 53s\tremaining: 3.9s\n",
      "4283:\tlearn: 1.6690091\ttotal: 53s\tremaining: 3.88s\n",
      "4284:\tlearn: 1.6688065\ttotal: 53s\tremaining: 3.87s\n",
      "4285:\tlearn: 1.6686073\ttotal: 53s\tremaining: 3.86s\n",
      "4286:\tlearn: 1.6684323\ttotal: 53s\tremaining: 3.85s\n",
      "4287:\tlearn: 1.6681189\ttotal: 53s\tremaining: 3.83s\n",
      "4288:\tlearn: 1.6679887\ttotal: 53s\tremaining: 3.82s\n",
      "4289:\tlearn: 1.6677321\ttotal: 53.1s\tremaining: 3.81s\n",
      "4290:\tlearn: 1.6676071\ttotal: 53.1s\tremaining: 3.8s\n",
      "4291:\tlearn: 1.6675551\ttotal: 53.1s\tremaining: 3.78s\n",
      "4292:\tlearn: 1.6673728\ttotal: 53.1s\tremaining: 3.77s\n",
      "4293:\tlearn: 1.6672903\ttotal: 53.1s\tremaining: 3.76s\n",
      "4294:\tlearn: 1.6671044\ttotal: 53.1s\tremaining: 3.75s\n",
      "4295:\tlearn: 1.6669740\ttotal: 53.1s\tremaining: 3.73s\n",
      "4296:\tlearn: 1.6667150\ttotal: 53.1s\tremaining: 3.72s\n",
      "4297:\tlearn: 1.6664152\ttotal: 53.1s\tremaining: 3.71s\n",
      "4298:\tlearn: 1.6663450\ttotal: 53.2s\tremaining: 3.7s\n",
      "4299:\tlearn: 1.6661846\ttotal: 53.2s\tremaining: 3.68s\n",
      "4300:\tlearn: 1.6660698\ttotal: 53.2s\tremaining: 3.67s\n",
      "4301:\tlearn: 1.6660077\ttotal: 53.2s\tremaining: 3.66s\n",
      "4302:\tlearn: 1.6657503\ttotal: 53.2s\tremaining: 3.65s\n",
      "4303:\tlearn: 1.6655525\ttotal: 53.2s\tremaining: 3.63s\n",
      "4304:\tlearn: 1.6652625\ttotal: 53.2s\tremaining: 3.62s\n",
      "4305:\tlearn: 1.6651601\ttotal: 53.2s\tremaining: 3.61s\n",
      "4306:\tlearn: 1.6649313\ttotal: 53.3s\tremaining: 3.6s\n",
      "4307:\tlearn: 1.6645837\ttotal: 53.3s\tremaining: 3.58s\n",
      "4308:\tlearn: 1.6644373\ttotal: 53.3s\tremaining: 3.57s\n",
      "4309:\tlearn: 1.6642537\ttotal: 53.3s\tremaining: 3.56s\n",
      "4310:\tlearn: 1.6640351\ttotal: 53.3s\tremaining: 3.55s\n",
      "4311:\tlearn: 1.6638953\ttotal: 53.3s\tremaining: 3.54s\n",
      "4312:\tlearn: 1.6637285\ttotal: 53.3s\tremaining: 3.52s\n",
      "4313:\tlearn: 1.6636001\ttotal: 53.3s\tremaining: 3.51s\n",
      "4314:\tlearn: 1.6634941\ttotal: 53.4s\tremaining: 3.5s\n",
      "4315:\tlearn: 1.6633621\ttotal: 53.4s\tremaining: 3.49s\n",
      "4316:\tlearn: 1.6632016\ttotal: 53.4s\tremaining: 3.47s\n",
      "4317:\tlearn: 1.6631146\ttotal: 53.4s\tremaining: 3.46s\n",
      "4318:\tlearn: 1.6630398\ttotal: 53.4s\tremaining: 3.45s\n",
      "4319:\tlearn: 1.6628751\ttotal: 53.4s\tremaining: 3.44s\n",
      "4320:\tlearn: 1.6626819\ttotal: 53.4s\tremaining: 3.42s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4321:\tlearn: 1.6625248\ttotal: 53.4s\tremaining: 3.41s\n",
      "4322:\tlearn: 1.6623994\ttotal: 53.5s\tremaining: 3.4s\n",
      "4323:\tlearn: 1.6622605\ttotal: 53.5s\tremaining: 3.39s\n",
      "4324:\tlearn: 1.6620626\ttotal: 53.5s\tremaining: 3.38s\n",
      "4325:\tlearn: 1.6618823\ttotal: 53.5s\tremaining: 3.36s\n",
      "4326:\tlearn: 1.6616963\ttotal: 53.5s\tremaining: 3.35s\n",
      "4327:\tlearn: 1.6613115\ttotal: 53.5s\tremaining: 3.34s\n",
      "4328:\tlearn: 1.6611544\ttotal: 53.5s\tremaining: 3.33s\n",
      "4329:\tlearn: 1.6610886\ttotal: 53.5s\tremaining: 3.31s\n",
      "4330:\tlearn: 1.6607165\ttotal: 53.5s\tremaining: 3.3s\n",
      "4331:\tlearn: 1.6603731\ttotal: 53.6s\tremaining: 3.29s\n",
      "4332:\tlearn: 1.6602051\ttotal: 53.6s\tremaining: 3.28s\n",
      "4333:\tlearn: 1.6599964\ttotal: 53.6s\tremaining: 3.26s\n",
      "4334:\tlearn: 1.6597585\ttotal: 53.6s\tremaining: 3.25s\n",
      "4335:\tlearn: 1.6594450\ttotal: 53.6s\tremaining: 3.24s\n",
      "4336:\tlearn: 1.6593780\ttotal: 53.6s\tremaining: 3.23s\n",
      "4337:\tlearn: 1.6591465\ttotal: 53.6s\tremaining: 3.21s\n",
      "4338:\tlearn: 1.6589908\ttotal: 53.6s\tremaining: 3.2s\n",
      "4339:\tlearn: 1.6587416\ttotal: 53.7s\tremaining: 3.19s\n",
      "4340:\tlearn: 1.6586085\ttotal: 53.7s\tremaining: 3.18s\n",
      "4341:\tlearn: 1.6584030\ttotal: 53.7s\tremaining: 3.17s\n",
      "4342:\tlearn: 1.6582068\ttotal: 53.7s\tremaining: 3.15s\n",
      "4343:\tlearn: 1.6580178\ttotal: 53.7s\tremaining: 3.14s\n",
      "4344:\tlearn: 1.6578180\ttotal: 53.7s\tremaining: 3.13s\n",
      "4345:\tlearn: 1.6575628\ttotal: 53.7s\tremaining: 3.12s\n",
      "4346:\tlearn: 1.6571392\ttotal: 53.7s\tremaining: 3.1s\n",
      "4347:\tlearn: 1.6569681\ttotal: 53.8s\tremaining: 3.09s\n",
      "4348:\tlearn: 1.6566553\ttotal: 53.8s\tremaining: 3.08s\n",
      "4349:\tlearn: 1.6564368\ttotal: 53.8s\tremaining: 3.07s\n",
      "4350:\tlearn: 1.6561474\ttotal: 53.8s\tremaining: 3.05s\n",
      "4351:\tlearn: 1.6559945\ttotal: 53.8s\tremaining: 3.04s\n",
      "4352:\tlearn: 1.6557595\ttotal: 53.8s\tremaining: 3.03s\n",
      "4353:\tlearn: 1.6554567\ttotal: 53.8s\tremaining: 3.02s\n",
      "4354:\tlearn: 1.6552673\ttotal: 53.8s\tremaining: 3s\n",
      "4355:\tlearn: 1.6551218\ttotal: 53.9s\tremaining: 2.99s\n",
      "4356:\tlearn: 1.6550061\ttotal: 53.9s\tremaining: 2.98s\n",
      "4357:\tlearn: 1.6548399\ttotal: 53.9s\tremaining: 2.97s\n",
      "4358:\tlearn: 1.6546472\ttotal: 53.9s\tremaining: 2.95s\n",
      "4359:\tlearn: 1.6545352\ttotal: 53.9s\tremaining: 2.94s\n",
      "4360:\tlearn: 1.6544504\ttotal: 53.9s\tremaining: 2.93s\n",
      "4361:\tlearn: 1.6540831\ttotal: 53.9s\tremaining: 2.92s\n",
      "4362:\tlearn: 1.6537649\ttotal: 53.9s\tremaining: 2.9s\n",
      "4363:\tlearn: 1.6535650\ttotal: 54s\tremaining: 2.89s\n",
      "4364:\tlearn: 1.6533896\ttotal: 54s\tremaining: 2.88s\n",
      "4365:\tlearn: 1.6532879\ttotal: 54s\tremaining: 2.87s\n",
      "4366:\tlearn: 1.6528850\ttotal: 54s\tremaining: 2.85s\n",
      "4367:\tlearn: 1.6528216\ttotal: 54s\tremaining: 2.84s\n",
      "4368:\tlearn: 1.6525696\ttotal: 54s\tremaining: 2.83s\n",
      "4369:\tlearn: 1.6519635\ttotal: 54s\tremaining: 2.82s\n",
      "4370:\tlearn: 1.6519204\ttotal: 54s\tremaining: 2.81s\n",
      "4371:\tlearn: 1.6515913\ttotal: 54s\tremaining: 2.79s\n",
      "4372:\tlearn: 1.6513971\ttotal: 54.1s\tremaining: 2.78s\n",
      "4373:\tlearn: 1.6512940\ttotal: 54.1s\tremaining: 2.77s\n",
      "4374:\tlearn: 1.6511393\ttotal: 54.1s\tremaining: 2.76s\n",
      "4375:\tlearn: 1.6509459\ttotal: 54.1s\tremaining: 2.74s\n",
      "4376:\tlearn: 1.6508683\ttotal: 54.1s\tremaining: 2.73s\n",
      "4377:\tlearn: 1.6507898\ttotal: 54.1s\tremaining: 2.72s\n",
      "4378:\tlearn: 1.6504423\ttotal: 54.1s\tremaining: 2.71s\n",
      "4379:\tlearn: 1.6502768\ttotal: 54.2s\tremaining: 2.69s\n",
      "4380:\tlearn: 1.6501391\ttotal: 54.2s\tremaining: 2.68s\n",
      "4381:\tlearn: 1.6498995\ttotal: 54.2s\tremaining: 2.67s\n",
      "4382:\tlearn: 1.6496420\ttotal: 54.2s\tremaining: 2.66s\n",
      "4383:\tlearn: 1.6494964\ttotal: 54.2s\tremaining: 2.65s\n",
      "4384:\tlearn: 1.6492125\ttotal: 54.2s\tremaining: 2.63s\n",
      "4385:\tlearn: 1.6490549\ttotal: 54.2s\tremaining: 2.62s\n",
      "4386:\tlearn: 1.6489101\ttotal: 54.2s\tremaining: 2.61s\n",
      "4387:\tlearn: 1.6488209\ttotal: 54.3s\tremaining: 2.6s\n",
      "4388:\tlearn: 1.6487678\ttotal: 54.3s\tremaining: 2.58s\n",
      "4389:\tlearn: 1.6485073\ttotal: 54.3s\tremaining: 2.57s\n",
      "4390:\tlearn: 1.6484269\ttotal: 54.3s\tremaining: 2.56s\n",
      "4391:\tlearn: 1.6480926\ttotal: 54.3s\tremaining: 2.55s\n",
      "4392:\tlearn: 1.6478907\ttotal: 54.3s\tremaining: 2.53s\n",
      "4393:\tlearn: 1.6476817\ttotal: 54.3s\tremaining: 2.52s\n",
      "4394:\tlearn: 1.6474311\ttotal: 54.3s\tremaining: 2.51s\n",
      "4395:\tlearn: 1.6472282\ttotal: 54.3s\tremaining: 2.5s\n",
      "4396:\tlearn: 1.6471115\ttotal: 54.4s\tremaining: 2.48s\n",
      "4397:\tlearn: 1.6469800\ttotal: 54.4s\tremaining: 2.47s\n",
      "4398:\tlearn: 1.6466591\ttotal: 54.4s\tremaining: 2.46s\n",
      "4399:\tlearn: 1.6463481\ttotal: 54.4s\tremaining: 2.45s\n",
      "4400:\tlearn: 1.6461495\ttotal: 54.4s\tremaining: 2.44s\n",
      "4401:\tlearn: 1.6459491\ttotal: 54.4s\tremaining: 2.42s\n",
      "4402:\tlearn: 1.6457871\ttotal: 54.4s\tremaining: 2.41s\n",
      "4403:\tlearn: 1.6456273\ttotal: 54.4s\tremaining: 2.4s\n",
      "4404:\tlearn: 1.6455267\ttotal: 54.5s\tremaining: 2.39s\n",
      "4405:\tlearn: 1.6453749\ttotal: 54.5s\tremaining: 2.37s\n",
      "4406:\tlearn: 1.6450744\ttotal: 54.5s\tremaining: 2.36s\n",
      "4407:\tlearn: 1.6448555\ttotal: 54.5s\tremaining: 2.35s\n",
      "4408:\tlearn: 1.6448200\ttotal: 54.5s\tremaining: 2.34s\n",
      "4409:\tlearn: 1.6445993\ttotal: 54.5s\tremaining: 2.32s\n",
      "4410:\tlearn: 1.6443301\ttotal: 54.5s\tremaining: 2.31s\n",
      "4411:\tlearn: 1.6441773\ttotal: 54.5s\tremaining: 2.3s\n",
      "4412:\tlearn: 1.6438405\ttotal: 54.6s\tremaining: 2.29s\n",
      "4413:\tlearn: 1.6435649\ttotal: 54.6s\tremaining: 2.27s\n",
      "4414:\tlearn: 1.6432928\ttotal: 54.6s\tremaining: 2.26s\n",
      "4415:\tlearn: 1.6430717\ttotal: 54.6s\tremaining: 2.25s\n",
      "4416:\tlearn: 1.6429330\ttotal: 54.6s\tremaining: 2.24s\n",
      "4417:\tlearn: 1.6427125\ttotal: 54.6s\tremaining: 2.23s\n",
      "4418:\tlearn: 1.6424236\ttotal: 54.6s\tremaining: 2.21s\n",
      "4419:\tlearn: 1.6422246\ttotal: 54.6s\tremaining: 2.2s\n",
      "4420:\tlearn: 1.6418786\ttotal: 54.7s\tremaining: 2.19s\n",
      "4421:\tlearn: 1.6417586\ttotal: 54.7s\tremaining: 2.17s\n",
      "4422:\tlearn: 1.6416948\ttotal: 54.7s\tremaining: 2.16s\n",
      "4423:\tlearn: 1.6416376\ttotal: 54.7s\tremaining: 2.15s\n",
      "4424:\tlearn: 1.6412336\ttotal: 54.7s\tremaining: 2.14s\n",
      "4425:\tlearn: 1.6410410\ttotal: 54.7s\tremaining: 2.13s\n",
      "4426:\tlearn: 1.6408010\ttotal: 54.7s\tremaining: 2.11s\n",
      "4427:\tlearn: 1.6405517\ttotal: 54.7s\tremaining: 2.1s\n",
      "4428:\tlearn: 1.6402780\ttotal: 54.8s\tremaining: 2.09s\n",
      "4429:\tlearn: 1.6399438\ttotal: 54.8s\tremaining: 2.08s\n",
      "4430:\tlearn: 1.6396736\ttotal: 54.8s\tremaining: 2.06s\n",
      "4431:\tlearn: 1.6392381\ttotal: 54.8s\tremaining: 2.05s\n",
      "4432:\tlearn: 1.6388524\ttotal: 54.8s\tremaining: 2.04s\n",
      "4433:\tlearn: 1.6387030\ttotal: 54.8s\tremaining: 2.03s\n",
      "4434:\tlearn: 1.6384526\ttotal: 54.8s\tremaining: 2.02s\n",
      "4435:\tlearn: 1.6382861\ttotal: 54.8s\tremaining: 2s\n",
      "4436:\tlearn: 1.6381472\ttotal: 54.9s\tremaining: 1.99s\n",
      "4437:\tlearn: 1.6379341\ttotal: 54.9s\tremaining: 1.98s\n",
      "4438:\tlearn: 1.6377527\ttotal: 54.9s\tremaining: 1.97s\n",
      "4439:\tlearn: 1.6376031\ttotal: 54.9s\tremaining: 1.95s\n",
      "4440:\tlearn: 1.6373675\ttotal: 54.9s\tremaining: 1.94s\n",
      "4441:\tlearn: 1.6372857\ttotal: 54.9s\tremaining: 1.93s\n",
      "4442:\tlearn: 1.6370558\ttotal: 54.9s\tremaining: 1.92s\n",
      "4443:\tlearn: 1.6368958\ttotal: 54.9s\tremaining: 1.9s\n",
      "4444:\tlearn: 1.6365464\ttotal: 55s\tremaining: 1.89s\n",
      "4445:\tlearn: 1.6364024\ttotal: 55s\tremaining: 1.88s\n",
      "4446:\tlearn: 1.6360404\ttotal: 55s\tremaining: 1.87s\n",
      "4447:\tlearn: 1.6357129\ttotal: 55s\tremaining: 1.85s\n",
      "4448:\tlearn: 1.6354134\ttotal: 55s\tremaining: 1.84s\n",
      "4449:\tlearn: 1.6352239\ttotal: 55s\tremaining: 1.83s\n",
      "4450:\tlearn: 1.6350094\ttotal: 55s\tremaining: 1.82s\n",
      "4451:\tlearn: 1.6347552\ttotal: 55s\tremaining: 1.8s\n",
      "4452:\tlearn: 1.6344547\ttotal: 55.1s\tremaining: 1.79s\n",
      "4453:\tlearn: 1.6342753\ttotal: 55.1s\tremaining: 1.78s\n",
      "4454:\tlearn: 1.6341676\ttotal: 55.1s\tremaining: 1.77s\n",
      "4455:\tlearn: 1.6336422\ttotal: 55.1s\tremaining: 1.75s\n",
      "4456:\tlearn: 1.6333661\ttotal: 55.1s\tremaining: 1.74s\n",
      "4457:\tlearn: 1.6332067\ttotal: 55.1s\tremaining: 1.73s\n",
      "4458:\tlearn: 1.6331062\ttotal: 55.1s\tremaining: 1.72s\n",
      "4459:\tlearn: 1.6327811\ttotal: 55.1s\tremaining: 1.71s\n",
      "4460:\tlearn: 1.6321289\ttotal: 55.2s\tremaining: 1.69s\n",
      "4461:\tlearn: 1.6319080\ttotal: 55.2s\tremaining: 1.68s\n",
      "4462:\tlearn: 1.6316491\ttotal: 55.2s\tremaining: 1.67s\n",
      "4463:\tlearn: 1.6315531\ttotal: 55.2s\tremaining: 1.66s\n",
      "4464:\tlearn: 1.6314461\ttotal: 55.2s\tremaining: 1.64s\n",
      "4465:\tlearn: 1.6312956\ttotal: 55.2s\tremaining: 1.63s\n",
      "4466:\tlearn: 1.6311111\ttotal: 55.2s\tremaining: 1.62s\n",
      "4467:\tlearn: 1.6309203\ttotal: 55.2s\tremaining: 1.61s\n",
      "4468:\tlearn: 1.6307632\ttotal: 55.2s\tremaining: 1.59s\n",
      "4469:\tlearn: 1.6306822\ttotal: 55.3s\tremaining: 1.58s\n",
      "4470:\tlearn: 1.6305429\ttotal: 55.3s\tremaining: 1.57s\n",
      "4471:\tlearn: 1.6303212\ttotal: 55.3s\tremaining: 1.56s\n",
      "4472:\tlearn: 1.6301222\ttotal: 55.3s\tremaining: 1.54s\n",
      "4473:\tlearn: 1.6299159\ttotal: 55.3s\tremaining: 1.53s\n",
      "4474:\tlearn: 1.6297046\ttotal: 55.3s\tremaining: 1.52s\n",
      "4475:\tlearn: 1.6294569\ttotal: 55.3s\tremaining: 1.51s\n",
      "4476:\tlearn: 1.6292212\ttotal: 55.3s\tremaining: 1.5s\n",
      "4477:\tlearn: 1.6291071\ttotal: 55.4s\tremaining: 1.48s\n",
      "4478:\tlearn: 1.6289161\ttotal: 55.4s\tremaining: 1.47s\n",
      "4479:\tlearn: 1.6285709\ttotal: 55.4s\tremaining: 1.46s\n",
      "4480:\tlearn: 1.6283942\ttotal: 55.4s\tremaining: 1.45s\n",
      "4481:\tlearn: 1.6281928\ttotal: 55.4s\tremaining: 1.43s\n",
      "4482:\tlearn: 1.6279673\ttotal: 55.4s\tremaining: 1.42s\n",
      "4483:\tlearn: 1.6275410\ttotal: 55.4s\tremaining: 1.41s\n",
      "4484:\tlearn: 1.6273300\ttotal: 55.4s\tremaining: 1.4s\n",
      "4485:\tlearn: 1.6271495\ttotal: 55.5s\tremaining: 1.38s\n",
      "4486:\tlearn: 1.6270537\ttotal: 55.5s\tremaining: 1.37s\n",
      "4487:\tlearn: 1.6268561\ttotal: 55.5s\tremaining: 1.36s\n",
      "4488:\tlearn: 1.6267244\ttotal: 55.5s\tremaining: 1.35s\n",
      "4489:\tlearn: 1.6264535\ttotal: 55.5s\tremaining: 1.33s\n",
      "4490:\tlearn: 1.6260502\ttotal: 55.5s\tremaining: 1.32s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4491:\tlearn: 1.6258728\ttotal: 55.5s\tremaining: 1.31s\n",
      "4492:\tlearn: 1.6256638\ttotal: 55.5s\tremaining: 1.3s\n",
      "4493:\tlearn: 1.6254525\ttotal: 55.6s\tremaining: 1.28s\n",
      "4494:\tlearn: 1.6253385\ttotal: 55.6s\tremaining: 1.27s\n",
      "4495:\tlearn: 1.6250625\ttotal: 55.6s\tremaining: 1.26s\n",
      "4496:\tlearn: 1.6248442\ttotal: 55.6s\tremaining: 1.25s\n",
      "4497:\tlearn: 1.6246178\ttotal: 55.6s\tremaining: 1.24s\n",
      "4498:\tlearn: 1.6244220\ttotal: 55.6s\tremaining: 1.22s\n",
      "4499:\tlearn: 1.6244008\ttotal: 55.6s\tremaining: 1.21s\n",
      "4500:\tlearn: 1.6241170\ttotal: 55.6s\tremaining: 1.2s\n",
      "4501:\tlearn: 1.6237988\ttotal: 55.7s\tremaining: 1.19s\n",
      "4502:\tlearn: 1.6237214\ttotal: 55.7s\tremaining: 1.17s\n",
      "4503:\tlearn: 1.6235486\ttotal: 55.7s\tremaining: 1.16s\n",
      "4504:\tlearn: 1.6233264\ttotal: 55.7s\tremaining: 1.15s\n",
      "4505:\tlearn: 1.6231366\ttotal: 55.7s\tremaining: 1.14s\n",
      "4506:\tlearn: 1.6229456\ttotal: 55.7s\tremaining: 1.12s\n",
      "4507:\tlearn: 1.6226623\ttotal: 55.7s\tremaining: 1.11s\n",
      "4508:\tlearn: 1.6223633\ttotal: 55.7s\tremaining: 1.1s\n",
      "4509:\tlearn: 1.6221895\ttotal: 55.8s\tremaining: 1.09s\n",
      "4510:\tlearn: 1.6220781\ttotal: 55.8s\tremaining: 1.07s\n",
      "4511:\tlearn: 1.6219261\ttotal: 55.8s\tremaining: 1.06s\n",
      "4512:\tlearn: 1.6218644\ttotal: 55.8s\tremaining: 1.05s\n",
      "4513:\tlearn: 1.6216953\ttotal: 55.8s\tremaining: 1.04s\n",
      "4514:\tlearn: 1.6214910\ttotal: 55.8s\tremaining: 1.03s\n",
      "4515:\tlearn: 1.6212398\ttotal: 55.8s\tremaining: 1.01s\n",
      "4516:\tlearn: 1.6209481\ttotal: 55.8s\tremaining: 1s\n",
      "4517:\tlearn: 1.6208696\ttotal: 55.8s\tremaining: 989ms\n",
      "4518:\tlearn: 1.6205036\ttotal: 55.9s\tremaining: 977ms\n",
      "4519:\tlearn: 1.6204130\ttotal: 55.9s\tremaining: 964ms\n",
      "4520:\tlearn: 1.6200683\ttotal: 55.9s\tremaining: 952ms\n",
      "4521:\tlearn: 1.6199429\ttotal: 55.9s\tremaining: 939ms\n",
      "4522:\tlearn: 1.6197098\ttotal: 55.9s\tremaining: 927ms\n",
      "4523:\tlearn: 1.6194642\ttotal: 55.9s\tremaining: 915ms\n",
      "4524:\tlearn: 1.6194415\ttotal: 55.9s\tremaining: 902ms\n",
      "4525:\tlearn: 1.6192806\ttotal: 55.9s\tremaining: 890ms\n",
      "4526:\tlearn: 1.6190461\ttotal: 56s\tremaining: 878ms\n",
      "4527:\tlearn: 1.6186353\ttotal: 56s\tremaining: 865ms\n",
      "4528:\tlearn: 1.6184331\ttotal: 56s\tremaining: 853ms\n",
      "4529:\tlearn: 1.6182651\ttotal: 56s\tremaining: 841ms\n",
      "4530:\tlearn: 1.6180496\ttotal: 56s\tremaining: 828ms\n",
      "4531:\tlearn: 1.6178017\ttotal: 56s\tremaining: 816ms\n",
      "4532:\tlearn: 1.6176242\ttotal: 56s\tremaining: 804ms\n",
      "4533:\tlearn: 1.6173326\ttotal: 56.1s\tremaining: 791ms\n",
      "4534:\tlearn: 1.6170105\ttotal: 56.1s\tremaining: 779ms\n",
      "4535:\tlearn: 1.6166926\ttotal: 56.1s\tremaining: 766ms\n",
      "4536:\tlearn: 1.6161899\ttotal: 56.1s\tremaining: 754ms\n",
      "4537:\tlearn: 1.6158293\ttotal: 56.1s\tremaining: 742ms\n",
      "4538:\tlearn: 1.6157403\ttotal: 56.1s\tremaining: 729ms\n",
      "4539:\tlearn: 1.6156325\ttotal: 56.1s\tremaining: 717ms\n",
      "4540:\tlearn: 1.6153706\ttotal: 56.1s\tremaining: 705ms\n",
      "4541:\tlearn: 1.6150728\ttotal: 56.2s\tremaining: 692ms\n",
      "4542:\tlearn: 1.6148727\ttotal: 56.2s\tremaining: 680ms\n",
      "4543:\tlearn: 1.6145978\ttotal: 56.2s\tremaining: 668ms\n",
      "4544:\tlearn: 1.6143334\ttotal: 56.2s\tremaining: 655ms\n",
      "4545:\tlearn: 1.6140548\ttotal: 56.2s\tremaining: 643ms\n",
      "4546:\tlearn: 1.6138394\ttotal: 56.2s\tremaining: 631ms\n",
      "4547:\tlearn: 1.6136051\ttotal: 56.2s\tremaining: 618ms\n",
      "4548:\tlearn: 1.6133630\ttotal: 56.3s\tremaining: 606ms\n",
      "4549:\tlearn: 1.6132813\ttotal: 56.3s\tremaining: 594ms\n",
      "4550:\tlearn: 1.6130506\ttotal: 56.3s\tremaining: 581ms\n",
      "4551:\tlearn: 1.6126954\ttotal: 56.3s\tremaining: 569ms\n",
      "4552:\tlearn: 1.6124677\ttotal: 56.3s\tremaining: 557ms\n",
      "4553:\tlearn: 1.6123437\ttotal: 56.3s\tremaining: 544ms\n",
      "4554:\tlearn: 1.6120619\ttotal: 56.3s\tremaining: 532ms\n",
      "4555:\tlearn: 1.6118864\ttotal: 56.3s\tremaining: 519ms\n",
      "4556:\tlearn: 1.6116226\ttotal: 56.4s\tremaining: 507ms\n",
      "4557:\tlearn: 1.6116050\ttotal: 56.4s\tremaining: 495ms\n",
      "4558:\tlearn: 1.6114530\ttotal: 56.4s\tremaining: 482ms\n",
      "4559:\tlearn: 1.6110495\ttotal: 56.4s\tremaining: 470ms\n",
      "4560:\tlearn: 1.6109272\ttotal: 56.4s\tremaining: 458ms\n",
      "4561:\tlearn: 1.6105941\ttotal: 56.4s\tremaining: 445ms\n",
      "4562:\tlearn: 1.6104236\ttotal: 56.4s\tremaining: 433ms\n",
      "4563:\tlearn: 1.6101965\ttotal: 56.4s\tremaining: 420ms\n",
      "4564:\tlearn: 1.6100873\ttotal: 56.5s\tremaining: 408ms\n",
      "4565:\tlearn: 1.6098073\ttotal: 56.5s\tremaining: 396ms\n",
      "4566:\tlearn: 1.6094743\ttotal: 56.5s\tremaining: 383ms\n",
      "4567:\tlearn: 1.6092543\ttotal: 56.5s\tremaining: 371ms\n",
      "4568:\tlearn: 1.6089946\ttotal: 56.5s\tremaining: 359ms\n",
      "4569:\tlearn: 1.6087598\ttotal: 56.5s\tremaining: 346ms\n",
      "4570:\tlearn: 1.6087120\ttotal: 56.5s\tremaining: 334ms\n",
      "4571:\tlearn: 1.6085738\ttotal: 56.5s\tremaining: 321ms\n",
      "4572:\tlearn: 1.6085063\ttotal: 56.5s\tremaining: 309ms\n",
      "4573:\tlearn: 1.6084296\ttotal: 56.6s\tremaining: 297ms\n",
      "4574:\tlearn: 1.6080042\ttotal: 56.6s\tremaining: 284ms\n",
      "4575:\tlearn: 1.6079805\ttotal: 56.6s\tremaining: 272ms\n",
      "4576:\tlearn: 1.6076457\ttotal: 56.6s\tremaining: 260ms\n",
      "4577:\tlearn: 1.6073897\ttotal: 56.6s\tremaining: 247ms\n",
      "4578:\tlearn: 1.6073342\ttotal: 56.6s\tremaining: 235ms\n",
      "4579:\tlearn: 1.6071351\ttotal: 56.6s\tremaining: 223ms\n",
      "4580:\tlearn: 1.6070209\ttotal: 56.6s\tremaining: 210ms\n",
      "4581:\tlearn: 1.6069200\ttotal: 56.7s\tremaining: 198ms\n",
      "4582:\tlearn: 1.6067991\ttotal: 56.7s\tremaining: 185ms\n",
      "4583:\tlearn: 1.6065235\ttotal: 56.7s\tremaining: 173ms\n",
      "4584:\tlearn: 1.6062579\ttotal: 56.7s\tremaining: 161ms\n",
      "4585:\tlearn: 1.6060282\ttotal: 56.7s\tremaining: 148ms\n",
      "4586:\tlearn: 1.6058433\ttotal: 56.7s\tremaining: 136ms\n",
      "4587:\tlearn: 1.6056701\ttotal: 56.7s\tremaining: 124ms\n",
      "4588:\tlearn: 1.6055542\ttotal: 56.7s\tremaining: 111ms\n",
      "4589:\tlearn: 1.6054554\ttotal: 56.8s\tremaining: 98.9ms\n",
      "4590:\tlearn: 1.6051771\ttotal: 56.8s\tremaining: 86.6ms\n",
      "4591:\tlearn: 1.6050671\ttotal: 56.8s\tremaining: 74.2ms\n",
      "4592:\tlearn: 1.6048133\ttotal: 56.8s\tremaining: 61.8ms\n",
      "4593:\tlearn: 1.6045676\ttotal: 56.8s\tremaining: 49.5ms\n",
      "4594:\tlearn: 1.6044790\ttotal: 56.8s\tremaining: 37.1ms\n",
      "4595:\tlearn: 1.6042468\ttotal: 56.8s\tremaining: 24.7ms\n",
      "4596:\tlearn: 1.6040881\ttotal: 56.8s\tremaining: 12.4ms\n",
      "4597:\tlearn: 1.6038559\ttotal: 56.9s\tremaining: 0us\n",
      "0:\tlearn: 14.5264146\ttotal: 12.8ms\tremaining: 58.6s\n",
      "1:\tlearn: 13.1275920\ttotal: 23.2ms\tremaining: 53.4s\n",
      "2:\tlearn: 11.9114124\ttotal: 34ms\tremaining: 52.1s\n",
      "3:\tlearn: 10.8345539\ttotal: 44.6ms\tremaining: 51.2s\n",
      "4:\tlearn: 9.8847220\ttotal: 55.1ms\tremaining: 50.6s\n",
      "5:\tlearn: 9.0690954\ttotal: 65.6ms\tremaining: 50.2s\n",
      "6:\tlearn: 8.3747100\ttotal: 76.4ms\tremaining: 50.1s\n",
      "7:\tlearn: 7.7717541\ttotal: 87ms\tremaining: 49.9s\n",
      "8:\tlearn: 7.2489693\ttotal: 97.7ms\tremaining: 49.8s\n",
      "9:\tlearn: 6.8069015\ttotal: 108ms\tremaining: 49.8s\n",
      "10:\tlearn: 6.4195820\ttotal: 120ms\tremaining: 49.9s\n",
      "11:\tlearn: 6.1067546\ttotal: 131ms\tremaining: 50s\n",
      "12:\tlearn: 5.8395784\ttotal: 142ms\tremaining: 50.1s\n",
      "13:\tlearn: 5.6139166\ttotal: 153ms\tremaining: 50.1s\n",
      "14:\tlearn: 5.4181096\ttotal: 165ms\tremaining: 50.3s\n",
      "15:\tlearn: 5.2604495\ttotal: 176ms\tremaining: 50.4s\n",
      "16:\tlearn: 5.1322001\ttotal: 186ms\tremaining: 50.2s\n",
      "17:\tlearn: 5.0164948\ttotal: 198ms\tremaining: 50.3s\n",
      "18:\tlearn: 4.9215152\ttotal: 209ms\tremaining: 50.4s\n",
      "19:\tlearn: 4.8435468\ttotal: 221ms\tremaining: 50.5s\n",
      "20:\tlearn: 4.7759546\ttotal: 233ms\tremaining: 50.7s\n",
      "21:\tlearn: 4.7167385\ttotal: 246ms\tremaining: 51.1s\n",
      "22:\tlearn: 4.6663293\ttotal: 257ms\tremaining: 51.2s\n",
      "23:\tlearn: 4.6204181\ttotal: 269ms\tremaining: 51.2s\n",
      "24:\tlearn: 4.5814712\ttotal: 280ms\tremaining: 51.3s\n",
      "25:\tlearn: 4.5500677\ttotal: 292ms\tremaining: 51.3s\n",
      "26:\tlearn: 4.5209178\ttotal: 303ms\tremaining: 51.2s\n",
      "27:\tlearn: 4.4975948\ttotal: 314ms\tremaining: 51.2s\n",
      "28:\tlearn: 4.4803304\ttotal: 324ms\tremaining: 51s\n",
      "29:\tlearn: 4.4641196\ttotal: 334ms\tremaining: 50.8s\n",
      "30:\tlearn: 4.4465456\ttotal: 345ms\tremaining: 50.8s\n",
      "31:\tlearn: 4.4280673\ttotal: 356ms\tremaining: 50.8s\n",
      "32:\tlearn: 4.4138765\ttotal: 368ms\tremaining: 50.9s\n",
      "33:\tlearn: 4.4008151\ttotal: 379ms\tremaining: 50.8s\n",
      "34:\tlearn: 4.3877475\ttotal: 390ms\tremaining: 50.8s\n",
      "35:\tlearn: 4.3771241\ttotal: 400ms\tremaining: 50.7s\n",
      "36:\tlearn: 4.3666505\ttotal: 410ms\tremaining: 50.6s\n",
      "37:\tlearn: 4.3577857\ttotal: 421ms\tremaining: 50.5s\n",
      "38:\tlearn: 4.3507233\ttotal: 433ms\tremaining: 50.6s\n",
      "39:\tlearn: 4.3373542\ttotal: 446ms\tremaining: 50.9s\n",
      "40:\tlearn: 4.3294255\ttotal: 457ms\tremaining: 50.8s\n",
      "41:\tlearn: 4.3241387\ttotal: 467ms\tremaining: 50.7s\n",
      "42:\tlearn: 4.3174855\ttotal: 478ms\tremaining: 50.6s\n",
      "43:\tlearn: 4.3109113\ttotal: 488ms\tremaining: 50.6s\n",
      "44:\tlearn: 4.3035284\ttotal: 499ms\tremaining: 50.5s\n",
      "45:\tlearn: 4.2970007\ttotal: 510ms\tremaining: 50.4s\n",
      "46:\tlearn: 4.2902692\ttotal: 521ms\tremaining: 50.4s\n",
      "47:\tlearn: 4.2829954\ttotal: 532ms\tremaining: 50.4s\n",
      "48:\tlearn: 4.2779966\ttotal: 542ms\tremaining: 50.3s\n",
      "49:\tlearn: 4.2711636\ttotal: 553ms\tremaining: 50.3s\n",
      "50:\tlearn: 4.2654531\ttotal: 564ms\tremaining: 50.3s\n",
      "51:\tlearn: 4.2570441\ttotal: 575ms\tremaining: 50.3s\n",
      "52:\tlearn: 4.2515930\ttotal: 585ms\tremaining: 50.2s\n",
      "53:\tlearn: 4.2454995\ttotal: 596ms\tremaining: 50.2s\n",
      "54:\tlearn: 4.2416363\ttotal: 607ms\tremaining: 50.2s\n",
      "55:\tlearn: 4.2354923\ttotal: 618ms\tremaining: 50.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56:\tlearn: 4.2258668\ttotal: 629ms\tremaining: 50.1s\n",
      "57:\tlearn: 4.2216555\ttotal: 640ms\tremaining: 50.1s\n",
      "58:\tlearn: 4.2180714\ttotal: 651ms\tremaining: 50.1s\n",
      "59:\tlearn: 4.2152706\ttotal: 662ms\tremaining: 50s\n",
      "60:\tlearn: 4.2114788\ttotal: 673ms\tremaining: 50s\n",
      "61:\tlearn: 4.2069542\ttotal: 684ms\tremaining: 50s\n",
      "62:\tlearn: 4.1998372\ttotal: 694ms\tremaining: 50s\n",
      "63:\tlearn: 4.1965148\ttotal: 705ms\tremaining: 49.9s\n",
      "64:\tlearn: 4.1913160\ttotal: 715ms\tremaining: 49.9s\n",
      "65:\tlearn: 4.1880364\ttotal: 726ms\tremaining: 49.8s\n",
      "66:\tlearn: 4.1834910\ttotal: 737ms\tremaining: 49.8s\n",
      "67:\tlearn: 4.1808600\ttotal: 747ms\tremaining: 49.8s\n",
      "68:\tlearn: 4.1764915\ttotal: 758ms\tremaining: 49.8s\n",
      "69:\tlearn: 4.1744317\ttotal: 768ms\tremaining: 49.7s\n",
      "70:\tlearn: 4.1691973\ttotal: 778ms\tremaining: 49.6s\n",
      "71:\tlearn: 4.1661110\ttotal: 788ms\tremaining: 49.6s\n",
      "72:\tlearn: 4.1632169\ttotal: 799ms\tremaining: 49.5s\n",
      "73:\tlearn: 4.1607794\ttotal: 809ms\tremaining: 49.5s\n",
      "74:\tlearn: 4.1577782\ttotal: 819ms\tremaining: 49.4s\n",
      "75:\tlearn: 4.1543241\ttotal: 831ms\tremaining: 49.4s\n",
      "76:\tlearn: 4.1525720\ttotal: 841ms\tremaining: 49.4s\n",
      "77:\tlearn: 4.1466058\ttotal: 853ms\tremaining: 49.4s\n",
      "78:\tlearn: 4.1397539\ttotal: 865ms\tremaining: 49.5s\n",
      "79:\tlearn: 4.1351802\ttotal: 876ms\tremaining: 49.5s\n",
      "80:\tlearn: 4.1321116\ttotal: 887ms\tremaining: 49.5s\n",
      "81:\tlearn: 4.1283586\ttotal: 899ms\tremaining: 49.5s\n",
      "82:\tlearn: 4.1246568\ttotal: 911ms\tremaining: 49.5s\n",
      "83:\tlearn: 4.1201887\ttotal: 922ms\tremaining: 49.5s\n",
      "84:\tlearn: 4.1167360\ttotal: 932ms\tremaining: 49.5s\n",
      "85:\tlearn: 4.1149026\ttotal: 942ms\tremaining: 49.4s\n",
      "86:\tlearn: 4.1109566\ttotal: 954ms\tremaining: 49.5s\n",
      "87:\tlearn: 4.1075659\ttotal: 964ms\tremaining: 49.4s\n",
      "88:\tlearn: 4.1038277\ttotal: 975ms\tremaining: 49.4s\n",
      "89:\tlearn: 4.1016856\ttotal: 985ms\tremaining: 49.3s\n",
      "90:\tlearn: 4.0988545\ttotal: 996ms\tremaining: 49.3s\n",
      "91:\tlearn: 4.0974379\ttotal: 1s\tremaining: 49.2s\n",
      "92:\tlearn: 4.0943657\ttotal: 1.02s\tremaining: 49.2s\n",
      "93:\tlearn: 4.0900234\ttotal: 1.03s\tremaining: 49.2s\n",
      "94:\tlearn: 4.0874264\ttotal: 1.04s\tremaining: 49.2s\n",
      "95:\tlearn: 4.0843082\ttotal: 1.05s\tremaining: 49.2s\n",
      "96:\tlearn: 4.0815030\ttotal: 1.06s\tremaining: 49.3s\n",
      "97:\tlearn: 4.0780791\ttotal: 1.07s\tremaining: 49.2s\n",
      "98:\tlearn: 4.0760779\ttotal: 1.08s\tremaining: 49.2s\n",
      "99:\tlearn: 4.0730921\ttotal: 1.09s\tremaining: 49.3s\n",
      "100:\tlearn: 4.0694049\ttotal: 1.1s\tremaining: 49.2s\n",
      "101:\tlearn: 4.0671827\ttotal: 1.12s\tremaining: 49.2s\n",
      "102:\tlearn: 4.0615902\ttotal: 1.13s\tremaining: 49.2s\n",
      "103:\tlearn: 4.0579704\ttotal: 1.14s\tremaining: 49.2s\n",
      "104:\tlearn: 4.0539391\ttotal: 1.15s\tremaining: 49.2s\n",
      "105:\tlearn: 4.0504298\ttotal: 1.16s\tremaining: 49.1s\n",
      "106:\tlearn: 4.0473763\ttotal: 1.17s\tremaining: 49.1s\n",
      "107:\tlearn: 4.0435131\ttotal: 1.18s\tremaining: 49.1s\n",
      "108:\tlearn: 4.0399980\ttotal: 1.19s\tremaining: 49.1s\n",
      "109:\tlearn: 4.0359513\ttotal: 1.2s\tremaining: 49.1s\n",
      "110:\tlearn: 4.0323696\ttotal: 1.21s\tremaining: 49s\n",
      "111:\tlearn: 4.0299792\ttotal: 1.22s\tremaining: 49.1s\n",
      "112:\tlearn: 4.0266866\ttotal: 1.24s\tremaining: 49.1s\n",
      "113:\tlearn: 4.0247552\ttotal: 1.25s\tremaining: 49s\n",
      "114:\tlearn: 4.0215398\ttotal: 1.26s\tremaining: 49s\n",
      "115:\tlearn: 4.0174050\ttotal: 1.27s\tremaining: 49.1s\n",
      "116:\tlearn: 4.0137748\ttotal: 1.28s\tremaining: 49.1s\n",
      "117:\tlearn: 4.0118959\ttotal: 1.29s\tremaining: 49.1s\n",
      "118:\tlearn: 4.0090445\ttotal: 1.3s\tremaining: 49.1s\n",
      "119:\tlearn: 4.0067151\ttotal: 1.32s\tremaining: 49.1s\n",
      "120:\tlearn: 4.0021000\ttotal: 1.33s\tremaining: 49.1s\n",
      "121:\tlearn: 3.9985712\ttotal: 1.34s\tremaining: 49.1s\n",
      "122:\tlearn: 3.9957894\ttotal: 1.35s\tremaining: 49s\n",
      "123:\tlearn: 3.9930506\ttotal: 1.36s\tremaining: 49s\n",
      "124:\tlearn: 3.9886020\ttotal: 1.37s\tremaining: 49s\n",
      "125:\tlearn: 3.9871089\ttotal: 1.38s\tremaining: 48.9s\n",
      "126:\tlearn: 3.9829056\ttotal: 1.39s\tremaining: 48.9s\n",
      "127:\tlearn: 3.9803187\ttotal: 1.4s\tremaining: 48.9s\n",
      "128:\tlearn: 3.9772194\ttotal: 1.41s\tremaining: 48.9s\n",
      "129:\tlearn: 3.9745501\ttotal: 1.42s\tremaining: 48.9s\n",
      "130:\tlearn: 3.9717323\ttotal: 1.43s\tremaining: 48.9s\n",
      "131:\tlearn: 3.9687671\ttotal: 1.44s\tremaining: 48.9s\n",
      "132:\tlearn: 3.9669401\ttotal: 1.45s\tremaining: 48.8s\n",
      "133:\tlearn: 3.9641616\ttotal: 1.47s\tremaining: 48.8s\n",
      "134:\tlearn: 3.9612993\ttotal: 1.48s\tremaining: 48.8s\n",
      "135:\tlearn: 3.9583455\ttotal: 1.49s\tremaining: 48.8s\n",
      "136:\tlearn: 3.9564749\ttotal: 1.5s\tremaining: 48.8s\n",
      "137:\tlearn: 3.9531370\ttotal: 1.51s\tremaining: 48.9s\n",
      "138:\tlearn: 3.9494111\ttotal: 1.52s\tremaining: 48.9s\n",
      "139:\tlearn: 3.9468713\ttotal: 1.53s\tremaining: 48.9s\n",
      "140:\tlearn: 3.9441816\ttotal: 1.54s\tremaining: 48.8s\n",
      "141:\tlearn: 3.9415143\ttotal: 1.55s\tremaining: 48.8s\n",
      "142:\tlearn: 3.9382817\ttotal: 1.57s\tremaining: 48.8s\n",
      "143:\tlearn: 3.9365215\ttotal: 1.58s\tremaining: 48.8s\n",
      "144:\tlearn: 3.9341495\ttotal: 1.59s\tremaining: 48.8s\n",
      "145:\tlearn: 3.9312553\ttotal: 1.6s\tremaining: 48.7s\n",
      "146:\tlearn: 3.9279300\ttotal: 1.61s\tremaining: 48.7s\n",
      "147:\tlearn: 3.9248905\ttotal: 1.62s\tremaining: 48.7s\n",
      "148:\tlearn: 3.9223086\ttotal: 1.63s\tremaining: 48.7s\n",
      "149:\tlearn: 3.9203786\ttotal: 1.64s\tremaining: 48.7s\n",
      "150:\tlearn: 3.9159545\ttotal: 1.65s\tremaining: 48.6s\n",
      "151:\tlearn: 3.9141985\ttotal: 1.66s\tremaining: 48.6s\n",
      "152:\tlearn: 3.9114668\ttotal: 1.67s\tremaining: 48.6s\n",
      "153:\tlearn: 3.9088668\ttotal: 1.68s\tremaining: 48.6s\n",
      "154:\tlearn: 3.9072036\ttotal: 1.7s\tremaining: 48.6s\n",
      "155:\tlearn: 3.9052008\ttotal: 1.71s\tremaining: 48.7s\n",
      "156:\tlearn: 3.9021088\ttotal: 1.72s\tremaining: 48.6s\n",
      "157:\tlearn: 3.8987039\ttotal: 1.73s\tremaining: 48.6s\n",
      "158:\tlearn: 3.8957912\ttotal: 1.74s\tremaining: 48.6s\n",
      "159:\tlearn: 3.8932852\ttotal: 1.75s\tremaining: 48.6s\n",
      "160:\tlearn: 3.8905436\ttotal: 1.76s\tremaining: 48.6s\n",
      "161:\tlearn: 3.8882734\ttotal: 1.77s\tremaining: 48.6s\n",
      "162:\tlearn: 3.8851810\ttotal: 1.78s\tremaining: 48.6s\n",
      "163:\tlearn: 3.8814169\ttotal: 1.79s\tremaining: 48.6s\n",
      "164:\tlearn: 3.8784644\ttotal: 1.81s\tremaining: 48.5s\n",
      "165:\tlearn: 3.8754968\ttotal: 1.82s\tremaining: 48.5s\n",
      "166:\tlearn: 3.8724695\ttotal: 1.83s\tremaining: 48.5s\n",
      "167:\tlearn: 3.8698801\ttotal: 1.84s\tremaining: 48.5s\n",
      "168:\tlearn: 3.8673499\ttotal: 1.85s\tremaining: 48.5s\n",
      "169:\tlearn: 3.8647787\ttotal: 1.86s\tremaining: 48.5s\n",
      "170:\tlearn: 3.8623709\ttotal: 1.87s\tremaining: 48.5s\n",
      "171:\tlearn: 3.8604417\ttotal: 1.88s\tremaining: 48.5s\n",
      "172:\tlearn: 3.8581256\ttotal: 1.89s\tremaining: 48.5s\n",
      "173:\tlearn: 3.8561467\ttotal: 1.91s\tremaining: 48.5s\n",
      "174:\tlearn: 3.8525940\ttotal: 1.92s\tremaining: 48.5s\n",
      "175:\tlearn: 3.8509010\ttotal: 1.93s\tremaining: 48.5s\n",
      "176:\tlearn: 3.8484426\ttotal: 1.94s\tremaining: 48.5s\n",
      "177:\tlearn: 3.8462014\ttotal: 1.95s\tremaining: 48.5s\n",
      "178:\tlearn: 3.8441944\ttotal: 1.96s\tremaining: 48.4s\n",
      "179:\tlearn: 3.8419234\ttotal: 1.97s\tremaining: 48.4s\n",
      "180:\tlearn: 3.8403832\ttotal: 1.99s\tremaining: 48.4s\n",
      "181:\tlearn: 3.8388050\ttotal: 2s\tremaining: 48.4s\n",
      "182:\tlearn: 3.8356430\ttotal: 2.01s\tremaining: 48.4s\n",
      "183:\tlearn: 3.8330045\ttotal: 2.02s\tremaining: 48.5s\n",
      "184:\tlearn: 3.8314247\ttotal: 2.03s\tremaining: 48.5s\n",
      "185:\tlearn: 3.8283167\ttotal: 2.05s\tremaining: 48.5s\n",
      "186:\tlearn: 3.8259100\ttotal: 2.06s\tremaining: 48.6s\n",
      "187:\tlearn: 3.8248711\ttotal: 2.07s\tremaining: 48.6s\n",
      "188:\tlearn: 3.8236051\ttotal: 2.08s\tremaining: 48.6s\n",
      "189:\tlearn: 3.8211299\ttotal: 2.1s\tremaining: 48.7s\n",
      "190:\tlearn: 3.8188285\ttotal: 2.11s\tremaining: 48.7s\n",
      "191:\tlearn: 3.8156430\ttotal: 2.12s\tremaining: 48.7s\n",
      "192:\tlearn: 3.8142333\ttotal: 2.13s\tremaining: 48.7s\n",
      "193:\tlearn: 3.8130175\ttotal: 2.15s\tremaining: 48.7s\n",
      "194:\tlearn: 3.8108241\ttotal: 2.16s\tremaining: 48.7s\n",
      "195:\tlearn: 3.8088872\ttotal: 2.17s\tremaining: 48.7s\n",
      "196:\tlearn: 3.8059210\ttotal: 2.18s\tremaining: 48.7s\n",
      "197:\tlearn: 3.8027406\ttotal: 2.19s\tremaining: 48.6s\n",
      "198:\tlearn: 3.8004347\ttotal: 2.2s\tremaining: 48.6s\n",
      "199:\tlearn: 3.7982714\ttotal: 2.21s\tremaining: 48.6s\n",
      "200:\tlearn: 3.7946477\ttotal: 2.22s\tremaining: 48.6s\n",
      "201:\tlearn: 3.7927526\ttotal: 2.23s\tremaining: 48.6s\n",
      "202:\tlearn: 3.7901950\ttotal: 2.24s\tremaining: 48.6s\n",
      "203:\tlearn: 3.7890795\ttotal: 2.25s\tremaining: 48.6s\n",
      "204:\tlearn: 3.7864691\ttotal: 2.27s\tremaining: 48.6s\n",
      "205:\tlearn: 3.7841880\ttotal: 2.28s\tremaining: 48.5s\n",
      "206:\tlearn: 3.7823055\ttotal: 2.29s\tremaining: 48.5s\n",
      "207:\tlearn: 3.7807056\ttotal: 2.3s\tremaining: 48.5s\n",
      "208:\tlearn: 3.7793194\ttotal: 2.31s\tremaining: 48.4s\n",
      "209:\tlearn: 3.7777310\ttotal: 2.32s\tremaining: 48.4s\n",
      "210:\tlearn: 3.7761933\ttotal: 2.33s\tremaining: 48.4s\n",
      "211:\tlearn: 3.7741339\ttotal: 2.34s\tremaining: 48.3s\n",
      "212:\tlearn: 3.7716317\ttotal: 2.35s\tremaining: 48.3s\n",
      "213:\tlearn: 3.7681401\ttotal: 2.36s\tremaining: 48.3s\n",
      "214:\tlearn: 3.7653830\ttotal: 2.37s\tremaining: 48.3s\n",
      "215:\tlearn: 3.7620961\ttotal: 2.38s\tremaining: 48.3s\n",
      "216:\tlearn: 3.7598146\ttotal: 2.39s\tremaining: 48.3s\n",
      "217:\tlearn: 3.7580244\ttotal: 2.4s\tremaining: 48.3s\n",
      "218:\tlearn: 3.7553696\ttotal: 2.41s\tremaining: 48.3s\n",
      "219:\tlearn: 3.7546489\ttotal: 2.42s\tremaining: 48.2s\n",
      "220:\tlearn: 3.7521767\ttotal: 2.43s\tremaining: 48.2s\n",
      "221:\tlearn: 3.7489125\ttotal: 2.44s\tremaining: 48.2s\n",
      "222:\tlearn: 3.7466772\ttotal: 2.45s\tremaining: 48.2s\n",
      "223:\tlearn: 3.7437933\ttotal: 2.46s\tremaining: 48.1s\n",
      "224:\tlearn: 3.7422948\ttotal: 2.48s\tremaining: 48.1s\n",
      "225:\tlearn: 3.7411472\ttotal: 2.48s\tremaining: 48.1s\n",
      "226:\tlearn: 3.7396481\ttotal: 2.5s\tremaining: 48.1s\n",
      "227:\tlearn: 3.7378900\ttotal: 2.51s\tremaining: 48s\n",
      "228:\tlearn: 3.7363820\ttotal: 2.52s\tremaining: 48s\n",
      "229:\tlearn: 3.7337722\ttotal: 2.53s\tremaining: 48s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230:\tlearn: 3.7324858\ttotal: 2.54s\tremaining: 48s\n",
      "231:\tlearn: 3.7313727\ttotal: 2.55s\tremaining: 48s\n",
      "232:\tlearn: 3.7297611\ttotal: 2.56s\tremaining: 48s\n",
      "233:\tlearn: 3.7277935\ttotal: 2.57s\tremaining: 47.9s\n",
      "234:\tlearn: 3.7254041\ttotal: 2.58s\tremaining: 47.9s\n",
      "235:\tlearn: 3.7241433\ttotal: 2.59s\tremaining: 47.9s\n",
      "236:\tlearn: 3.7223111\ttotal: 2.6s\tremaining: 47.9s\n",
      "237:\tlearn: 3.7199254\ttotal: 2.61s\tremaining: 47.8s\n",
      "238:\tlearn: 3.7185650\ttotal: 2.62s\tremaining: 47.8s\n",
      "239:\tlearn: 3.7165084\ttotal: 2.63s\tremaining: 47.8s\n",
      "240:\tlearn: 3.7146713\ttotal: 2.64s\tremaining: 47.8s\n",
      "241:\tlearn: 3.7123578\ttotal: 2.65s\tremaining: 47.8s\n",
      "242:\tlearn: 3.7105385\ttotal: 2.66s\tremaining: 47.8s\n",
      "243:\tlearn: 3.7092677\ttotal: 2.67s\tremaining: 47.7s\n",
      "244:\tlearn: 3.7064356\ttotal: 2.69s\tremaining: 47.7s\n",
      "245:\tlearn: 3.7043224\ttotal: 2.69s\tremaining: 47.7s\n",
      "246:\tlearn: 3.7024324\ttotal: 2.71s\tremaining: 47.7s\n",
      "247:\tlearn: 3.7011164\ttotal: 2.72s\tremaining: 47.7s\n",
      "248:\tlearn: 3.6985750\ttotal: 2.73s\tremaining: 47.6s\n",
      "249:\tlearn: 3.6971369\ttotal: 2.74s\tremaining: 47.6s\n",
      "250:\tlearn: 3.6953106\ttotal: 2.75s\tremaining: 47.6s\n",
      "251:\tlearn: 3.6939153\ttotal: 2.76s\tremaining: 47.6s\n",
      "252:\tlearn: 3.6909947\ttotal: 2.77s\tremaining: 47.6s\n",
      "253:\tlearn: 3.6888417\ttotal: 2.78s\tremaining: 47.6s\n",
      "254:\tlearn: 3.6867971\ttotal: 2.79s\tremaining: 47.6s\n",
      "255:\tlearn: 3.6848236\ttotal: 2.8s\tremaining: 47.6s\n",
      "256:\tlearn: 3.6827148\ttotal: 2.81s\tremaining: 47.6s\n",
      "257:\tlearn: 3.6807693\ttotal: 2.83s\tremaining: 47.5s\n",
      "258:\tlearn: 3.6793054\ttotal: 2.83s\tremaining: 47.5s\n",
      "259:\tlearn: 3.6768953\ttotal: 2.85s\tremaining: 47.5s\n",
      "260:\tlearn: 3.6755593\ttotal: 2.86s\tremaining: 47.5s\n",
      "261:\tlearn: 3.6739239\ttotal: 2.87s\tremaining: 47.4s\n",
      "262:\tlearn: 3.6725020\ttotal: 2.88s\tremaining: 47.4s\n",
      "263:\tlearn: 3.6713423\ttotal: 2.89s\tremaining: 47.4s\n",
      "264:\tlearn: 3.6697330\ttotal: 2.9s\tremaining: 47.4s\n",
      "265:\tlearn: 3.6689931\ttotal: 2.91s\tremaining: 47.4s\n",
      "266:\tlearn: 3.6673895\ttotal: 2.92s\tremaining: 47.3s\n",
      "267:\tlearn: 3.6654215\ttotal: 2.93s\tremaining: 47.3s\n",
      "268:\tlearn: 3.6635839\ttotal: 2.94s\tremaining: 47.3s\n",
      "269:\tlearn: 3.6617450\ttotal: 2.95s\tremaining: 47.3s\n",
      "270:\tlearn: 3.6609495\ttotal: 2.96s\tremaining: 47.3s\n",
      "271:\tlearn: 3.6570547\ttotal: 2.98s\tremaining: 47.3s\n",
      "272:\tlearn: 3.6556114\ttotal: 2.99s\tremaining: 47.3s\n",
      "273:\tlearn: 3.6544614\ttotal: 3s\tremaining: 47.3s\n",
      "274:\tlearn: 3.6523121\ttotal: 3.01s\tremaining: 47.3s\n",
      "275:\tlearn: 3.6510090\ttotal: 3.02s\tremaining: 47.3s\n",
      "276:\tlearn: 3.6497260\ttotal: 3.03s\tremaining: 47.3s\n",
      "277:\tlearn: 3.6472323\ttotal: 3.04s\tremaining: 47.3s\n",
      "278:\tlearn: 3.6446934\ttotal: 3.05s\tremaining: 47.3s\n",
      "279:\tlearn: 3.6428652\ttotal: 3.06s\tremaining: 47.3s\n",
      "280:\tlearn: 3.6413163\ttotal: 3.07s\tremaining: 47.2s\n",
      "281:\tlearn: 3.6390195\ttotal: 3.08s\tremaining: 47.2s\n",
      "282:\tlearn: 3.6370670\ttotal: 3.1s\tremaining: 47.2s\n",
      "283:\tlearn: 3.6358762\ttotal: 3.11s\tremaining: 47.2s\n",
      "284:\tlearn: 3.6329940\ttotal: 3.12s\tremaining: 47.2s\n",
      "285:\tlearn: 3.6317161\ttotal: 3.13s\tremaining: 47.2s\n",
      "286:\tlearn: 3.6299477\ttotal: 3.14s\tremaining: 47.2s\n",
      "287:\tlearn: 3.6278477\ttotal: 3.15s\tremaining: 47.2s\n",
      "288:\tlearn: 3.6253669\ttotal: 3.16s\tremaining: 47.2s\n",
      "289:\tlearn: 3.6235961\ttotal: 3.17s\tremaining: 47.1s\n",
      "290:\tlearn: 3.6226099\ttotal: 3.18s\tremaining: 47.1s\n",
      "291:\tlearn: 3.6212858\ttotal: 3.2s\tremaining: 47.1s\n",
      "292:\tlearn: 3.6197643\ttotal: 3.21s\tremaining: 47.2s\n",
      "293:\tlearn: 3.6180061\ttotal: 3.22s\tremaining: 47.2s\n",
      "294:\tlearn: 3.6167249\ttotal: 3.23s\tremaining: 47.2s\n",
      "295:\tlearn: 3.6148579\ttotal: 3.25s\tremaining: 47.2s\n",
      "296:\tlearn: 3.6134891\ttotal: 3.26s\tremaining: 47.2s\n",
      "297:\tlearn: 3.6116396\ttotal: 3.27s\tremaining: 47.2s\n",
      "298:\tlearn: 3.6099368\ttotal: 3.28s\tremaining: 47.2s\n",
      "299:\tlearn: 3.6080908\ttotal: 3.29s\tremaining: 47.2s\n",
      "300:\tlearn: 3.6061724\ttotal: 3.31s\tremaining: 47.2s\n",
      "301:\tlearn: 3.6043842\ttotal: 3.32s\tremaining: 47.2s\n",
      "302:\tlearn: 3.6021432\ttotal: 3.33s\tremaining: 47.2s\n",
      "303:\tlearn: 3.6007993\ttotal: 3.34s\tremaining: 47.2s\n",
      "304:\tlearn: 3.5982966\ttotal: 3.35s\tremaining: 47.2s\n",
      "305:\tlearn: 3.5966973\ttotal: 3.37s\tremaining: 47.2s\n",
      "306:\tlearn: 3.5956975\ttotal: 3.38s\tremaining: 47.2s\n",
      "307:\tlearn: 3.5936397\ttotal: 3.39s\tremaining: 47.2s\n",
      "308:\tlearn: 3.5911299\ttotal: 3.4s\tremaining: 47.2s\n",
      "309:\tlearn: 3.5889547\ttotal: 3.41s\tremaining: 47.2s\n",
      "310:\tlearn: 3.5876183\ttotal: 3.42s\tremaining: 47.2s\n",
      "311:\tlearn: 3.5847626\ttotal: 3.44s\tremaining: 47.2s\n",
      "312:\tlearn: 3.5832189\ttotal: 3.45s\tremaining: 47.2s\n",
      "313:\tlearn: 3.5802217\ttotal: 3.46s\tremaining: 47.2s\n",
      "314:\tlearn: 3.5781338\ttotal: 3.47s\tremaining: 47.2s\n",
      "315:\tlearn: 3.5753174\ttotal: 3.48s\tremaining: 47.1s\n",
      "316:\tlearn: 3.5742123\ttotal: 3.49s\tremaining: 47.1s\n",
      "317:\tlearn: 3.5729230\ttotal: 3.5s\tremaining: 47.1s\n",
      "318:\tlearn: 3.5706585\ttotal: 3.51s\tremaining: 47.1s\n",
      "319:\tlearn: 3.5690439\ttotal: 3.52s\tremaining: 47.1s\n",
      "320:\tlearn: 3.5679354\ttotal: 3.53s\tremaining: 47s\n",
      "321:\tlearn: 3.5658793\ttotal: 3.54s\tremaining: 47s\n",
      "322:\tlearn: 3.5653266\ttotal: 3.55s\tremaining: 47s\n",
      "323:\tlearn: 3.5635898\ttotal: 3.56s\tremaining: 47s\n",
      "324:\tlearn: 3.5613208\ttotal: 3.58s\tremaining: 47s\n",
      "325:\tlearn: 3.5595544\ttotal: 3.59s\tremaining: 47s\n",
      "326:\tlearn: 3.5579186\ttotal: 3.6s\tremaining: 47s\n",
      "327:\tlearn: 3.5567756\ttotal: 3.61s\tremaining: 47s\n",
      "328:\tlearn: 3.5561009\ttotal: 3.62s\tremaining: 47s\n",
      "329:\tlearn: 3.5549785\ttotal: 3.63s\tremaining: 47s\n",
      "330:\tlearn: 3.5538719\ttotal: 3.64s\tremaining: 47s\n",
      "331:\tlearn: 3.5517442\ttotal: 3.65s\tremaining: 46.9s\n",
      "332:\tlearn: 3.5507926\ttotal: 3.66s\tremaining: 46.9s\n",
      "333:\tlearn: 3.5499442\ttotal: 3.67s\tremaining: 46.9s\n",
      "334:\tlearn: 3.5487834\ttotal: 3.69s\tremaining: 46.9s\n",
      "335:\tlearn: 3.5482381\ttotal: 3.69s\tremaining: 46.9s\n",
      "336:\tlearn: 3.5472135\ttotal: 3.7s\tremaining: 46.8s\n",
      "337:\tlearn: 3.5458171\ttotal: 3.71s\tremaining: 46.8s\n",
      "338:\tlearn: 3.5452490\ttotal: 3.73s\tremaining: 46.8s\n",
      "339:\tlearn: 3.5429873\ttotal: 3.74s\tremaining: 46.8s\n",
      "340:\tlearn: 3.5408249\ttotal: 3.75s\tremaining: 46.8s\n",
      "341:\tlearn: 3.5392866\ttotal: 3.76s\tremaining: 46.8s\n",
      "342:\tlearn: 3.5370051\ttotal: 3.77s\tremaining: 46.7s\n",
      "343:\tlearn: 3.5357125\ttotal: 3.78s\tremaining: 46.7s\n",
      "344:\tlearn: 3.5344351\ttotal: 3.79s\tremaining: 46.7s\n",
      "345:\tlearn: 3.5328498\ttotal: 3.8s\tremaining: 46.7s\n",
      "346:\tlearn: 3.5315460\ttotal: 3.81s\tremaining: 46.7s\n",
      "347:\tlearn: 3.5309458\ttotal: 3.82s\tremaining: 46.7s\n",
      "348:\tlearn: 3.5295459\ttotal: 3.83s\tremaining: 46.7s\n",
      "349:\tlearn: 3.5278064\ttotal: 3.84s\tremaining: 46.6s\n",
      "350:\tlearn: 3.5262664\ttotal: 3.85s\tremaining: 46.6s\n",
      "351:\tlearn: 3.5252973\ttotal: 3.86s\tremaining: 46.6s\n",
      "352:\tlearn: 3.5243663\ttotal: 3.87s\tremaining: 46.6s\n",
      "353:\tlearn: 3.5233627\ttotal: 3.88s\tremaining: 46.5s\n",
      "354:\tlearn: 3.5224173\ttotal: 3.89s\tremaining: 46.5s\n",
      "355:\tlearn: 3.5198826\ttotal: 3.9s\tremaining: 46.5s\n",
      "356:\tlearn: 3.5184511\ttotal: 3.91s\tremaining: 46.5s\n",
      "357:\tlearn: 3.5169605\ttotal: 3.92s\tremaining: 46.5s\n",
      "358:\tlearn: 3.5163505\ttotal: 3.93s\tremaining: 46.4s\n",
      "359:\tlearn: 3.5152641\ttotal: 3.94s\tremaining: 46.4s\n",
      "360:\tlearn: 3.5131288\ttotal: 3.95s\tremaining: 46.4s\n",
      "361:\tlearn: 3.5123981\ttotal: 3.96s\tremaining: 46.4s\n",
      "362:\tlearn: 3.5116138\ttotal: 3.98s\tremaining: 46.4s\n",
      "363:\tlearn: 3.5097121\ttotal: 3.98s\tremaining: 46.4s\n",
      "364:\tlearn: 3.5078991\ttotal: 4s\tremaining: 46.3s\n",
      "365:\tlearn: 3.5059781\ttotal: 4.01s\tremaining: 46.3s\n",
      "366:\tlearn: 3.5048441\ttotal: 4.02s\tremaining: 46.3s\n",
      "367:\tlearn: 3.5036357\ttotal: 4.03s\tremaining: 46.3s\n",
      "368:\tlearn: 3.5026779\ttotal: 4.04s\tremaining: 46.3s\n",
      "369:\tlearn: 3.5012548\ttotal: 4.05s\tremaining: 46.3s\n",
      "370:\tlearn: 3.5005737\ttotal: 4.06s\tremaining: 46.2s\n",
      "371:\tlearn: 3.4978006\ttotal: 4.07s\tremaining: 46.2s\n",
      "372:\tlearn: 3.4957315\ttotal: 4.08s\tremaining: 46.2s\n",
      "373:\tlearn: 3.4942335\ttotal: 4.09s\tremaining: 46.2s\n",
      "374:\tlearn: 3.4936931\ttotal: 4.1s\tremaining: 46.2s\n",
      "375:\tlearn: 3.4920735\ttotal: 4.11s\tremaining: 46.2s\n",
      "376:\tlearn: 3.4900360\ttotal: 4.12s\tremaining: 46.1s\n",
      "377:\tlearn: 3.4887014\ttotal: 4.13s\tremaining: 46.1s\n",
      "378:\tlearn: 3.4870715\ttotal: 4.14s\tremaining: 46.1s\n",
      "379:\tlearn: 3.4854616\ttotal: 4.15s\tremaining: 46.1s\n",
      "380:\tlearn: 3.4838937\ttotal: 4.16s\tremaining: 46.1s\n",
      "381:\tlearn: 3.4828981\ttotal: 4.17s\tremaining: 46s\n",
      "382:\tlearn: 3.4820431\ttotal: 4.18s\tremaining: 46s\n",
      "383:\tlearn: 3.4807410\ttotal: 4.19s\tremaining: 46s\n",
      "384:\tlearn: 3.4789721\ttotal: 4.2s\tremaining: 46s\n",
      "385:\tlearn: 3.4773115\ttotal: 4.22s\tremaining: 46s\n",
      "386:\tlearn: 3.4757579\ttotal: 4.23s\tremaining: 46s\n",
      "387:\tlearn: 3.4740195\ttotal: 4.24s\tremaining: 46s\n",
      "388:\tlearn: 3.4729214\ttotal: 4.25s\tremaining: 46s\n",
      "389:\tlearn: 3.4718519\ttotal: 4.26s\tremaining: 46s\n",
      "390:\tlearn: 3.4711681\ttotal: 4.27s\tremaining: 46s\n",
      "391:\tlearn: 3.4692601\ttotal: 4.28s\tremaining: 46s\n",
      "392:\tlearn: 3.4674811\ttotal: 4.29s\tremaining: 45.9s\n",
      "393:\tlearn: 3.4661351\ttotal: 4.3s\tremaining: 45.9s\n",
      "394:\tlearn: 3.4654953\ttotal: 4.31s\tremaining: 45.9s\n",
      "395:\tlearn: 3.4634746\ttotal: 4.32s\tremaining: 45.9s\n",
      "396:\tlearn: 3.4623822\ttotal: 4.33s\tremaining: 45.9s\n",
      "397:\tlearn: 3.4606616\ttotal: 4.35s\tremaining: 45.9s\n",
      "398:\tlearn: 3.4592538\ttotal: 4.36s\tremaining: 45.8s\n",
      "399:\tlearn: 3.4573939\ttotal: 4.37s\tremaining: 45.8s\n",
      "400:\tlearn: 3.4552126\ttotal: 4.38s\tremaining: 45.8s\n",
      "401:\tlearn: 3.4538001\ttotal: 4.39s\tremaining: 45.8s\n",
      "402:\tlearn: 3.4529970\ttotal: 4.4s\tremaining: 45.8s\n",
      "403:\tlearn: 3.4520845\ttotal: 4.41s\tremaining: 45.8s\n",
      "404:\tlearn: 3.4513311\ttotal: 4.42s\tremaining: 45.8s\n",
      "405:\tlearn: 3.4493738\ttotal: 4.43s\tremaining: 45.8s\n",
      "406:\tlearn: 3.4489029\ttotal: 4.44s\tremaining: 45.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407:\tlearn: 3.4471421\ttotal: 4.45s\tremaining: 45.7s\n",
      "408:\tlearn: 3.4447785\ttotal: 4.47s\tremaining: 45.7s\n",
      "409:\tlearn: 3.4428962\ttotal: 4.48s\tremaining: 45.7s\n",
      "410:\tlearn: 3.4416783\ttotal: 4.49s\tremaining: 45.7s\n",
      "411:\tlearn: 3.4398066\ttotal: 4.5s\tremaining: 45.7s\n",
      "412:\tlearn: 3.4386488\ttotal: 4.51s\tremaining: 45.7s\n",
      "413:\tlearn: 3.4375500\ttotal: 4.52s\tremaining: 45.7s\n",
      "414:\tlearn: 3.4357385\ttotal: 4.53s\tremaining: 45.7s\n",
      "415:\tlearn: 3.4341040\ttotal: 4.54s\tremaining: 45.7s\n",
      "416:\tlearn: 3.4323751\ttotal: 4.55s\tremaining: 45.6s\n",
      "417:\tlearn: 3.4311167\ttotal: 4.56s\tremaining: 45.6s\n",
      "418:\tlearn: 3.4298158\ttotal: 4.58s\tremaining: 45.6s\n",
      "419:\tlearn: 3.4285207\ttotal: 4.59s\tremaining: 45.6s\n",
      "420:\tlearn: 3.4249671\ttotal: 4.6s\tremaining: 45.6s\n",
      "421:\tlearn: 3.4234487\ttotal: 4.61s\tremaining: 45.6s\n",
      "422:\tlearn: 3.4213320\ttotal: 4.62s\tremaining: 45.6s\n",
      "423:\tlearn: 3.4198149\ttotal: 4.63s\tremaining: 45.6s\n",
      "424:\tlearn: 3.4183304\ttotal: 4.64s\tremaining: 45.5s\n",
      "425:\tlearn: 3.4168010\ttotal: 4.65s\tremaining: 45.5s\n",
      "426:\tlearn: 3.4155102\ttotal: 4.66s\tremaining: 45.5s\n",
      "427:\tlearn: 3.4134319\ttotal: 4.67s\tremaining: 45.5s\n",
      "428:\tlearn: 3.4116235\ttotal: 4.68s\tremaining: 45.5s\n",
      "429:\tlearn: 3.4105944\ttotal: 4.7s\tremaining: 45.5s\n",
      "430:\tlearn: 3.4097933\ttotal: 4.71s\tremaining: 45.5s\n",
      "431:\tlearn: 3.4087867\ttotal: 4.72s\tremaining: 45.5s\n",
      "432:\tlearn: 3.4074806\ttotal: 4.73s\tremaining: 45.5s\n",
      "433:\tlearn: 3.4064628\ttotal: 4.74s\tremaining: 45.5s\n",
      "434:\tlearn: 3.4049544\ttotal: 4.75s\tremaining: 45.4s\n",
      "435:\tlearn: 3.4043039\ttotal: 4.76s\tremaining: 45.4s\n",
      "436:\tlearn: 3.4020303\ttotal: 4.77s\tremaining: 45.4s\n",
      "437:\tlearn: 3.4006030\ttotal: 4.78s\tremaining: 45.4s\n",
      "438:\tlearn: 3.3998179\ttotal: 4.79s\tremaining: 45.4s\n",
      "439:\tlearn: 3.3979678\ttotal: 4.8s\tremaining: 45.4s\n",
      "440:\tlearn: 3.3975150\ttotal: 4.81s\tremaining: 45.4s\n",
      "441:\tlearn: 3.3964252\ttotal: 4.82s\tremaining: 45.4s\n",
      "442:\tlearn: 3.3955098\ttotal: 4.83s\tremaining: 45.4s\n",
      "443:\tlearn: 3.3935852\ttotal: 4.85s\tremaining: 45.3s\n",
      "444:\tlearn: 3.3923985\ttotal: 4.86s\tremaining: 45.3s\n",
      "445:\tlearn: 3.3907058\ttotal: 4.87s\tremaining: 45.3s\n",
      "446:\tlearn: 3.3894486\ttotal: 4.88s\tremaining: 45.3s\n",
      "447:\tlearn: 3.3876896\ttotal: 4.89s\tremaining: 45.3s\n",
      "448:\tlearn: 3.3859920\ttotal: 4.91s\tremaining: 45.3s\n",
      "449:\tlearn: 3.3850268\ttotal: 4.92s\tremaining: 45.3s\n",
      "450:\tlearn: 3.3837754\ttotal: 4.93s\tremaining: 45.3s\n",
      "451:\tlearn: 3.3811829\ttotal: 4.94s\tremaining: 45.3s\n",
      "452:\tlearn: 3.3788887\ttotal: 4.95s\tremaining: 45.3s\n",
      "453:\tlearn: 3.3781744\ttotal: 4.96s\tremaining: 45.3s\n",
      "454:\tlearn: 3.3768269\ttotal: 4.97s\tremaining: 45.3s\n",
      "455:\tlearn: 3.3757826\ttotal: 4.98s\tremaining: 45.3s\n",
      "456:\tlearn: 3.3743174\ttotal: 4.99s\tremaining: 45.2s\n",
      "457:\tlearn: 3.3726886\ttotal: 5s\tremaining: 45.2s\n",
      "458:\tlearn: 3.3688631\ttotal: 5.01s\tremaining: 45.2s\n",
      "459:\tlearn: 3.3675897\ttotal: 5.03s\tremaining: 45.2s\n",
      "460:\tlearn: 3.3660632\ttotal: 5.04s\tremaining: 45.2s\n",
      "461:\tlearn: 3.3646792\ttotal: 5.05s\tremaining: 45.2s\n",
      "462:\tlearn: 3.3634215\ttotal: 5.06s\tremaining: 45.2s\n",
      "463:\tlearn: 3.3622127\ttotal: 5.07s\tremaining: 45.2s\n",
      "464:\tlearn: 3.3608937\ttotal: 5.08s\tremaining: 45.1s\n",
      "465:\tlearn: 3.3598856\ttotal: 5.09s\tremaining: 45.1s\n",
      "466:\tlearn: 3.3590934\ttotal: 5.1s\tremaining: 45.1s\n",
      "467:\tlearn: 3.3581504\ttotal: 5.11s\tremaining: 45.1s\n",
      "468:\tlearn: 3.3566491\ttotal: 5.12s\tremaining: 45.1s\n",
      "469:\tlearn: 3.3555052\ttotal: 5.13s\tremaining: 45.1s\n",
      "470:\tlearn: 3.3537799\ttotal: 5.15s\tremaining: 45.1s\n",
      "471:\tlearn: 3.3516962\ttotal: 5.16s\tremaining: 45.1s\n",
      "472:\tlearn: 3.3507186\ttotal: 5.17s\tremaining: 45.1s\n",
      "473:\tlearn: 3.3484928\ttotal: 5.18s\tremaining: 45.1s\n",
      "474:\tlearn: 3.3479546\ttotal: 5.19s\tremaining: 45.1s\n",
      "475:\tlearn: 3.3454299\ttotal: 5.2s\tremaining: 45s\n",
      "476:\tlearn: 3.3437560\ttotal: 5.21s\tremaining: 45s\n",
      "477:\tlearn: 3.3424879\ttotal: 5.22s\tremaining: 45s\n",
      "478:\tlearn: 3.3420619\ttotal: 5.23s\tremaining: 45s\n",
      "479:\tlearn: 3.3403229\ttotal: 5.24s\tremaining: 45s\n",
      "480:\tlearn: 3.3384430\ttotal: 5.25s\tremaining: 45s\n",
      "481:\tlearn: 3.3361841\ttotal: 5.27s\tremaining: 45s\n",
      "482:\tlearn: 3.3352121\ttotal: 5.28s\tremaining: 45s\n",
      "483:\tlearn: 3.3341884\ttotal: 5.29s\tremaining: 44.9s\n",
      "484:\tlearn: 3.3325939\ttotal: 5.3s\tremaining: 44.9s\n",
      "485:\tlearn: 3.3310915\ttotal: 5.31s\tremaining: 44.9s\n",
      "486:\tlearn: 3.3294732\ttotal: 5.32s\tremaining: 44.9s\n",
      "487:\tlearn: 3.3290326\ttotal: 5.33s\tremaining: 44.9s\n",
      "488:\tlearn: 3.3277306\ttotal: 5.34s\tremaining: 44.9s\n",
      "489:\tlearn: 3.3265001\ttotal: 5.35s\tremaining: 44.9s\n",
      "490:\tlearn: 3.3254912\ttotal: 5.36s\tremaining: 44.9s\n",
      "491:\tlearn: 3.3247307\ttotal: 5.37s\tremaining: 44.8s\n",
      "492:\tlearn: 3.3233788\ttotal: 5.38s\tremaining: 44.8s\n",
      "493:\tlearn: 3.3218980\ttotal: 5.39s\tremaining: 44.8s\n",
      "494:\tlearn: 3.3207969\ttotal: 5.41s\tremaining: 44.8s\n",
      "495:\tlearn: 3.3199282\ttotal: 5.42s\tremaining: 44.8s\n",
      "496:\tlearn: 3.3186132\ttotal: 5.43s\tremaining: 44.8s\n",
      "497:\tlearn: 3.3171109\ttotal: 5.44s\tremaining: 44.8s\n",
      "498:\tlearn: 3.3152853\ttotal: 5.45s\tremaining: 44.8s\n",
      "499:\tlearn: 3.3133000\ttotal: 5.46s\tremaining: 44.7s\n",
      "500:\tlearn: 3.3118761\ttotal: 5.47s\tremaining: 44.7s\n",
      "501:\tlearn: 3.3106858\ttotal: 5.48s\tremaining: 44.7s\n",
      "502:\tlearn: 3.3096613\ttotal: 5.49s\tremaining: 44.7s\n",
      "503:\tlearn: 3.3087478\ttotal: 5.5s\tremaining: 44.7s\n",
      "504:\tlearn: 3.3073844\ttotal: 5.51s\tremaining: 44.7s\n",
      "505:\tlearn: 3.3064676\ttotal: 5.52s\tremaining: 44.7s\n",
      "506:\tlearn: 3.3055403\ttotal: 5.54s\tremaining: 44.7s\n",
      "507:\tlearn: 3.3041482\ttotal: 5.55s\tremaining: 44.7s\n",
      "508:\tlearn: 3.3031755\ttotal: 5.56s\tremaining: 44.7s\n",
      "509:\tlearn: 3.3021160\ttotal: 5.57s\tremaining: 44.7s\n",
      "510:\tlearn: 3.3011029\ttotal: 5.58s\tremaining: 44.7s\n",
      "511:\tlearn: 3.3010005\ttotal: 5.59s\tremaining: 44.6s\n",
      "512:\tlearn: 3.3000902\ttotal: 5.6s\tremaining: 44.6s\n",
      "513:\tlearn: 3.2994189\ttotal: 5.61s\tremaining: 44.6s\n",
      "514:\tlearn: 3.2987147\ttotal: 5.63s\tremaining: 44.6s\n",
      "515:\tlearn: 3.2974301\ttotal: 5.64s\tremaining: 44.6s\n",
      "516:\tlearn: 3.2959793\ttotal: 5.65s\tremaining: 44.6s\n",
      "517:\tlearn: 3.2948898\ttotal: 5.66s\tremaining: 44.6s\n",
      "518:\tlearn: 3.2941449\ttotal: 5.67s\tremaining: 44.5s\n",
      "519:\tlearn: 3.2931438\ttotal: 5.68s\tremaining: 44.5s\n",
      "520:\tlearn: 3.2916166\ttotal: 5.69s\tremaining: 44.5s\n",
      "521:\tlearn: 3.2903126\ttotal: 5.7s\tremaining: 44.5s\n",
      "522:\tlearn: 3.2890459\ttotal: 5.71s\tremaining: 44.5s\n",
      "523:\tlearn: 3.2873029\ttotal: 5.72s\tremaining: 44.5s\n",
      "524:\tlearn: 3.2860805\ttotal: 5.73s\tremaining: 44.5s\n",
      "525:\tlearn: 3.2843475\ttotal: 5.74s\tremaining: 44.5s\n",
      "526:\tlearn: 3.2828836\ttotal: 5.76s\tremaining: 44.5s\n",
      "527:\tlearn: 3.2812798\ttotal: 5.77s\tremaining: 44.5s\n",
      "528:\tlearn: 3.2799267\ttotal: 5.78s\tremaining: 44.4s\n",
      "529:\tlearn: 3.2795610\ttotal: 5.79s\tremaining: 44.4s\n",
      "530:\tlearn: 3.2770850\ttotal: 5.8s\tremaining: 44.4s\n",
      "531:\tlearn: 3.2757692\ttotal: 5.81s\tremaining: 44.4s\n",
      "532:\tlearn: 3.2740856\ttotal: 5.82s\tremaining: 44.4s\n",
      "533:\tlearn: 3.2723075\ttotal: 5.83s\tremaining: 44.4s\n",
      "534:\tlearn: 3.2711928\ttotal: 5.84s\tremaining: 44.4s\n",
      "535:\tlearn: 3.2697025\ttotal: 5.86s\tremaining: 44.4s\n",
      "536:\tlearn: 3.2681411\ttotal: 5.87s\tremaining: 44.4s\n",
      "537:\tlearn: 3.2677030\ttotal: 5.88s\tremaining: 44.4s\n",
      "538:\tlearn: 3.2665895\ttotal: 5.89s\tremaining: 44.4s\n",
      "539:\tlearn: 3.2653295\ttotal: 5.9s\tremaining: 44.3s\n",
      "540:\tlearn: 3.2640300\ttotal: 5.91s\tremaining: 44.3s\n",
      "541:\tlearn: 3.2629870\ttotal: 5.92s\tremaining: 44.3s\n",
      "542:\tlearn: 3.2610957\ttotal: 5.93s\tremaining: 44.3s\n",
      "543:\tlearn: 3.2595975\ttotal: 5.94s\tremaining: 44.3s\n",
      "544:\tlearn: 3.2582722\ttotal: 5.96s\tremaining: 44.3s\n",
      "545:\tlearn: 3.2578764\ttotal: 5.97s\tremaining: 44.3s\n",
      "546:\tlearn: 3.2569709\ttotal: 5.98s\tremaining: 44.3s\n",
      "547:\tlearn: 3.2562988\ttotal: 5.99s\tremaining: 44.3s\n",
      "548:\tlearn: 3.2556055\ttotal: 6s\tremaining: 44.3s\n",
      "549:\tlearn: 3.2542826\ttotal: 6.01s\tremaining: 44.2s\n",
      "550:\tlearn: 3.2536379\ttotal: 6.02s\tremaining: 44.2s\n",
      "551:\tlearn: 3.2529946\ttotal: 6.03s\tremaining: 44.2s\n",
      "552:\tlearn: 3.2523656\ttotal: 6.04s\tremaining: 44.2s\n",
      "553:\tlearn: 3.2515442\ttotal: 6.05s\tremaining: 44.2s\n",
      "554:\tlearn: 3.2493992\ttotal: 6.06s\tremaining: 44.2s\n",
      "555:\tlearn: 3.2482496\ttotal: 6.07s\tremaining: 44.2s\n",
      "556:\tlearn: 3.2468631\ttotal: 6.08s\tremaining: 44.2s\n",
      "557:\tlearn: 3.2461465\ttotal: 6.09s\tremaining: 44.1s\n",
      "558:\tlearn: 3.2455131\ttotal: 6.11s\tremaining: 44.1s\n",
      "559:\tlearn: 3.2446900\ttotal: 6.12s\tremaining: 44.1s\n",
      "560:\tlearn: 3.2427627\ttotal: 6.13s\tremaining: 44.1s\n",
      "561:\tlearn: 3.2419742\ttotal: 6.14s\tremaining: 44.1s\n",
      "562:\tlearn: 3.2407725\ttotal: 6.15s\tremaining: 44.1s\n",
      "563:\tlearn: 3.2391962\ttotal: 6.16s\tremaining: 44.1s\n",
      "564:\tlearn: 3.2385170\ttotal: 6.17s\tremaining: 44s\n",
      "565:\tlearn: 3.2383199\ttotal: 6.18s\tremaining: 44s\n",
      "566:\tlearn: 3.2374200\ttotal: 6.19s\tremaining: 44s\n",
      "567:\tlearn: 3.2357928\ttotal: 6.2s\tremaining: 44s\n",
      "568:\tlearn: 3.2347041\ttotal: 6.21s\tremaining: 44s\n",
      "569:\tlearn: 3.2332473\ttotal: 6.22s\tremaining: 44s\n",
      "570:\tlearn: 3.2317259\ttotal: 6.23s\tremaining: 44s\n",
      "571:\tlearn: 3.2301728\ttotal: 6.25s\tremaining: 44s\n",
      "572:\tlearn: 3.2288510\ttotal: 6.26s\tremaining: 44s\n",
      "573:\tlearn: 3.2275015\ttotal: 6.27s\tremaining: 43.9s\n",
      "574:\tlearn: 3.2264829\ttotal: 6.28s\tremaining: 43.9s\n",
      "575:\tlearn: 3.2253067\ttotal: 6.29s\tremaining: 43.9s\n",
      "576:\tlearn: 3.2240621\ttotal: 6.3s\tremaining: 43.9s\n",
      "577:\tlearn: 3.2226905\ttotal: 6.31s\tremaining: 43.9s\n",
      "578:\tlearn: 3.2207535\ttotal: 6.32s\tremaining: 43.9s\n",
      "579:\tlearn: 3.2197673\ttotal: 6.33s\tremaining: 43.9s\n",
      "580:\tlearn: 3.2189335\ttotal: 6.34s\tremaining: 43.9s\n",
      "581:\tlearn: 3.2182202\ttotal: 6.35s\tremaining: 43.8s\n",
      "582:\tlearn: 3.2169121\ttotal: 6.36s\tremaining: 43.8s\n",
      "583:\tlearn: 3.2161129\ttotal: 6.37s\tremaining: 43.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584:\tlearn: 3.2152154\ttotal: 6.38s\tremaining: 43.8s\n",
      "585:\tlearn: 3.2143232\ttotal: 6.4s\tremaining: 43.8s\n",
      "586:\tlearn: 3.2131445\ttotal: 6.41s\tremaining: 43.8s\n",
      "587:\tlearn: 3.2117755\ttotal: 6.42s\tremaining: 43.8s\n",
      "588:\tlearn: 3.2109206\ttotal: 6.43s\tremaining: 43.8s\n",
      "589:\tlearn: 3.2094238\ttotal: 6.44s\tremaining: 43.8s\n",
      "590:\tlearn: 3.2070517\ttotal: 6.45s\tremaining: 43.8s\n",
      "591:\tlearn: 3.2061357\ttotal: 6.46s\tremaining: 43.7s\n",
      "592:\tlearn: 3.2055841\ttotal: 6.47s\tremaining: 43.7s\n",
      "593:\tlearn: 3.2045911\ttotal: 6.49s\tremaining: 43.7s\n",
      "594:\tlearn: 3.2037047\ttotal: 6.5s\tremaining: 43.7s\n",
      "595:\tlearn: 3.2026524\ttotal: 6.51s\tremaining: 43.7s\n",
      "596:\tlearn: 3.2014375\ttotal: 6.52s\tremaining: 43.7s\n",
      "597:\tlearn: 3.2001022\ttotal: 6.53s\tremaining: 43.7s\n",
      "598:\tlearn: 3.1991114\ttotal: 6.54s\tremaining: 43.7s\n",
      "599:\tlearn: 3.1979396\ttotal: 6.55s\tremaining: 43.6s\n",
      "600:\tlearn: 3.1969475\ttotal: 6.56s\tremaining: 43.6s\n",
      "601:\tlearn: 3.1962690\ttotal: 6.57s\tremaining: 43.6s\n",
      "602:\tlearn: 3.1948697\ttotal: 6.58s\tremaining: 43.6s\n",
      "603:\tlearn: 3.1935807\ttotal: 6.59s\tremaining: 43.6s\n",
      "604:\tlearn: 3.1910872\ttotal: 6.6s\tremaining: 43.6s\n",
      "605:\tlearn: 3.1892509\ttotal: 6.62s\tremaining: 43.6s\n",
      "606:\tlearn: 3.1880921\ttotal: 6.63s\tremaining: 43.6s\n",
      "607:\tlearn: 3.1866963\ttotal: 6.64s\tremaining: 43.6s\n",
      "608:\tlearn: 3.1854848\ttotal: 6.65s\tremaining: 43.6s\n",
      "609:\tlearn: 3.1842883\ttotal: 6.66s\tremaining: 43.5s\n",
      "610:\tlearn: 3.1831639\ttotal: 6.67s\tremaining: 43.5s\n",
      "611:\tlearn: 3.1815072\ttotal: 6.68s\tremaining: 43.5s\n",
      "612:\tlearn: 3.1797747\ttotal: 6.69s\tremaining: 43.5s\n",
      "613:\tlearn: 3.1786029\ttotal: 6.71s\tremaining: 43.5s\n",
      "614:\tlearn: 3.1773205\ttotal: 6.72s\tremaining: 43.5s\n",
      "615:\tlearn: 3.1770207\ttotal: 6.73s\tremaining: 43.5s\n",
      "616:\tlearn: 3.1754351\ttotal: 6.74s\tremaining: 43.5s\n",
      "617:\tlearn: 3.1741901\ttotal: 6.75s\tremaining: 43.5s\n",
      "618:\tlearn: 3.1732492\ttotal: 6.76s\tremaining: 43.5s\n",
      "619:\tlearn: 3.1717209\ttotal: 6.77s\tremaining: 43.4s\n",
      "620:\tlearn: 3.1712119\ttotal: 6.78s\tremaining: 43.4s\n",
      "621:\tlearn: 3.1702595\ttotal: 6.79s\tremaining: 43.4s\n",
      "622:\tlearn: 3.1690452\ttotal: 6.8s\tremaining: 43.4s\n",
      "623:\tlearn: 3.1682175\ttotal: 6.82s\tremaining: 43.4s\n",
      "624:\tlearn: 3.1676133\ttotal: 6.83s\tremaining: 43.4s\n",
      "625:\tlearn: 3.1667705\ttotal: 6.84s\tremaining: 43.4s\n",
      "626:\tlearn: 3.1656493\ttotal: 6.85s\tremaining: 43.4s\n",
      "627:\tlearn: 3.1649936\ttotal: 6.86s\tremaining: 43.4s\n",
      "628:\tlearn: 3.1639104\ttotal: 6.87s\tremaining: 43.3s\n",
      "629:\tlearn: 3.1625521\ttotal: 6.88s\tremaining: 43.3s\n",
      "630:\tlearn: 3.1612187\ttotal: 6.89s\tremaining: 43.3s\n",
      "631:\tlearn: 3.1596508\ttotal: 6.9s\tremaining: 43.3s\n",
      "632:\tlearn: 3.1583195\ttotal: 6.91s\tremaining: 43.3s\n",
      "633:\tlearn: 3.1576131\ttotal: 6.92s\tremaining: 43.3s\n",
      "634:\tlearn: 3.1570484\ttotal: 6.93s\tremaining: 43.3s\n",
      "635:\tlearn: 3.1555170\ttotal: 6.95s\tremaining: 43.3s\n",
      "636:\tlearn: 3.1538855\ttotal: 6.96s\tremaining: 43.3s\n",
      "637:\tlearn: 3.1523128\ttotal: 6.97s\tremaining: 43.2s\n",
      "638:\tlearn: 3.1508389\ttotal: 6.98s\tremaining: 43.2s\n",
      "639:\tlearn: 3.1495634\ttotal: 6.99s\tremaining: 43.2s\n",
      "640:\tlearn: 3.1483535\ttotal: 7s\tremaining: 43.2s\n",
      "641:\tlearn: 3.1478028\ttotal: 7.01s\tremaining: 43.2s\n",
      "642:\tlearn: 3.1471833\ttotal: 7.02s\tremaining: 43.2s\n",
      "643:\tlearn: 3.1455165\ttotal: 7.03s\tremaining: 43.2s\n",
      "644:\tlearn: 3.1447081\ttotal: 7.04s\tremaining: 43.2s\n",
      "645:\tlearn: 3.1438406\ttotal: 7.05s\tremaining: 43.2s\n",
      "646:\tlearn: 3.1422802\ttotal: 7.07s\tremaining: 43.1s\n",
      "647:\tlearn: 3.1414666\ttotal: 7.08s\tremaining: 43.1s\n",
      "648:\tlearn: 3.1407704\ttotal: 7.09s\tremaining: 43.1s\n",
      "649:\tlearn: 3.1390830\ttotal: 7.1s\tremaining: 43.1s\n",
      "650:\tlearn: 3.1377953\ttotal: 7.11s\tremaining: 43.1s\n",
      "651:\tlearn: 3.1369241\ttotal: 7.12s\tremaining: 43.1s\n",
      "652:\tlearn: 3.1360039\ttotal: 7.13s\tremaining: 43.1s\n",
      "653:\tlearn: 3.1357793\ttotal: 7.14s\tremaining: 43.1s\n",
      "654:\tlearn: 3.1345117\ttotal: 7.15s\tremaining: 43.1s\n",
      "655:\tlearn: 3.1339330\ttotal: 7.16s\tremaining: 43s\n",
      "656:\tlearn: 3.1325869\ttotal: 7.17s\tremaining: 43s\n",
      "657:\tlearn: 3.1316110\ttotal: 7.18s\tremaining: 43s\n",
      "658:\tlearn: 3.1302258\ttotal: 7.19s\tremaining: 43s\n",
      "659:\tlearn: 3.1292738\ttotal: 7.21s\tremaining: 43s\n",
      "660:\tlearn: 3.1281539\ttotal: 7.22s\tremaining: 43s\n",
      "661:\tlearn: 3.1268196\ttotal: 7.23s\tremaining: 43s\n",
      "662:\tlearn: 3.1257185\ttotal: 7.24s\tremaining: 43s\n",
      "663:\tlearn: 3.1246254\ttotal: 7.25s\tremaining: 43s\n",
      "664:\tlearn: 3.1245446\ttotal: 7.26s\tremaining: 42.9s\n",
      "665:\tlearn: 3.1228775\ttotal: 7.27s\tremaining: 42.9s\n",
      "666:\tlearn: 3.1220204\ttotal: 7.28s\tremaining: 42.9s\n",
      "667:\tlearn: 3.1211229\ttotal: 7.29s\tremaining: 42.9s\n",
      "668:\tlearn: 3.1200916\ttotal: 7.3s\tremaining: 42.9s\n",
      "669:\tlearn: 3.1194602\ttotal: 7.32s\tremaining: 42.9s\n",
      "670:\tlearn: 3.1186421\ttotal: 7.33s\tremaining: 42.9s\n",
      "671:\tlearn: 3.1180307\ttotal: 7.34s\tremaining: 42.9s\n",
      "672:\tlearn: 3.1169939\ttotal: 7.35s\tremaining: 42.9s\n",
      "673:\tlearn: 3.1155911\ttotal: 7.36s\tremaining: 42.8s\n",
      "674:\tlearn: 3.1150038\ttotal: 7.37s\tremaining: 42.8s\n",
      "675:\tlearn: 3.1131624\ttotal: 7.38s\tremaining: 42.8s\n",
      "676:\tlearn: 3.1122251\ttotal: 7.39s\tremaining: 42.8s\n",
      "677:\tlearn: 3.1110364\ttotal: 7.4s\tremaining: 42.8s\n",
      "678:\tlearn: 3.1091930\ttotal: 7.41s\tremaining: 42.8s\n",
      "679:\tlearn: 3.1083111\ttotal: 7.42s\tremaining: 42.8s\n",
      "680:\tlearn: 3.1081944\ttotal: 7.43s\tremaining: 42.8s\n",
      "681:\tlearn: 3.1069855\ttotal: 7.45s\tremaining: 42.8s\n",
      "682:\tlearn: 3.1056288\ttotal: 7.46s\tremaining: 42.7s\n",
      "683:\tlearn: 3.1051950\ttotal: 7.47s\tremaining: 42.7s\n",
      "684:\tlearn: 3.1038900\ttotal: 7.48s\tremaining: 42.7s\n",
      "685:\tlearn: 3.1033284\ttotal: 7.49s\tremaining: 42.7s\n",
      "686:\tlearn: 3.1026089\ttotal: 7.5s\tremaining: 42.7s\n",
      "687:\tlearn: 3.1016827\ttotal: 7.51s\tremaining: 42.7s\n",
      "688:\tlearn: 3.1002714\ttotal: 7.52s\tremaining: 42.7s\n",
      "689:\tlearn: 3.0989794\ttotal: 7.53s\tremaining: 42.7s\n",
      "690:\tlearn: 3.0980596\ttotal: 7.54s\tremaining: 42.7s\n",
      "691:\tlearn: 3.0964119\ttotal: 7.55s\tremaining: 42.6s\n",
      "692:\tlearn: 3.0951819\ttotal: 7.57s\tremaining: 42.6s\n",
      "693:\tlearn: 3.0939507\ttotal: 7.58s\tremaining: 42.6s\n",
      "694:\tlearn: 3.0928575\ttotal: 7.59s\tremaining: 42.6s\n",
      "695:\tlearn: 3.0920498\ttotal: 7.6s\tremaining: 42.6s\n",
      "696:\tlearn: 3.0911189\ttotal: 7.61s\tremaining: 42.6s\n",
      "697:\tlearn: 3.0905937\ttotal: 7.62s\tremaining: 42.6s\n",
      "698:\tlearn: 3.0899924\ttotal: 7.63s\tremaining: 42.6s\n",
      "699:\tlearn: 3.0890180\ttotal: 7.64s\tremaining: 42.6s\n",
      "700:\tlearn: 3.0883760\ttotal: 7.65s\tremaining: 42.5s\n",
      "701:\tlearn: 3.0868834\ttotal: 7.66s\tremaining: 42.5s\n",
      "702:\tlearn: 3.0862999\ttotal: 7.67s\tremaining: 42.5s\n",
      "703:\tlearn: 3.0858266\ttotal: 7.68s\tremaining: 42.5s\n",
      "704:\tlearn: 3.0857053\ttotal: 7.69s\tremaining: 42.5s\n",
      "705:\tlearn: 3.0846994\ttotal: 7.71s\tremaining: 42.5s\n",
      "706:\tlearn: 3.0838368\ttotal: 7.71s\tremaining: 42.5s\n",
      "707:\tlearn: 3.0825676\ttotal: 7.73s\tremaining: 42.5s\n",
      "708:\tlearn: 3.0818938\ttotal: 7.74s\tremaining: 42.4s\n",
      "709:\tlearn: 3.0806919\ttotal: 7.75s\tremaining: 42.4s\n",
      "710:\tlearn: 3.0800064\ttotal: 7.76s\tremaining: 42.4s\n",
      "711:\tlearn: 3.0791603\ttotal: 7.77s\tremaining: 42.4s\n",
      "712:\tlearn: 3.0783405\ttotal: 7.78s\tremaining: 42.4s\n",
      "713:\tlearn: 3.0757568\ttotal: 7.79s\tremaining: 42.4s\n",
      "714:\tlearn: 3.0749327\ttotal: 7.8s\tremaining: 42.4s\n",
      "715:\tlearn: 3.0740293\ttotal: 7.81s\tremaining: 42.3s\n",
      "716:\tlearn: 3.0731752\ttotal: 7.82s\tremaining: 42.3s\n",
      "717:\tlearn: 3.0722656\ttotal: 7.83s\tremaining: 42.3s\n",
      "718:\tlearn: 3.0710673\ttotal: 7.84s\tremaining: 42.3s\n",
      "719:\tlearn: 3.0698554\ttotal: 7.85s\tremaining: 42.3s\n",
      "720:\tlearn: 3.0690159\ttotal: 7.86s\tremaining: 42.3s\n",
      "721:\tlearn: 3.0682820\ttotal: 7.87s\tremaining: 42.3s\n",
      "722:\tlearn: 3.0675372\ttotal: 7.88s\tremaining: 42.3s\n",
      "723:\tlearn: 3.0666906\ttotal: 7.9s\tremaining: 42.3s\n",
      "724:\tlearn: 3.0655517\ttotal: 7.91s\tremaining: 42.2s\n",
      "725:\tlearn: 3.0636477\ttotal: 7.92s\tremaining: 42.2s\n",
      "726:\tlearn: 3.0636433\ttotal: 7.93s\tremaining: 42.2s\n",
      "727:\tlearn: 3.0628362\ttotal: 7.94s\tremaining: 42.2s\n",
      "728:\tlearn: 3.0611346\ttotal: 7.95s\tremaining: 42.2s\n",
      "729:\tlearn: 3.0595724\ttotal: 7.96s\tremaining: 42.2s\n",
      "730:\tlearn: 3.0586061\ttotal: 7.97s\tremaining: 42.2s\n",
      "731:\tlearn: 3.0579516\ttotal: 7.98s\tremaining: 42.2s\n",
      "732:\tlearn: 3.0567752\ttotal: 8s\tremaining: 42.2s\n",
      "733:\tlearn: 3.0556579\ttotal: 8.01s\tremaining: 42.2s\n",
      "734:\tlearn: 3.0544624\ttotal: 8.02s\tremaining: 42.2s\n",
      "735:\tlearn: 3.0540707\ttotal: 8.03s\tremaining: 42.1s\n",
      "736:\tlearn: 3.0530305\ttotal: 8.04s\tremaining: 42.1s\n",
      "737:\tlearn: 3.0517875\ttotal: 8.05s\tremaining: 42.1s\n",
      "738:\tlearn: 3.0513669\ttotal: 8.06s\tremaining: 42.1s\n",
      "739:\tlearn: 3.0493756\ttotal: 8.07s\tremaining: 42.1s\n",
      "740:\tlearn: 3.0485268\ttotal: 8.09s\tremaining: 42.1s\n",
      "741:\tlearn: 3.0470374\ttotal: 8.1s\tremaining: 42.1s\n",
      "742:\tlearn: 3.0460557\ttotal: 8.11s\tremaining: 42.1s\n",
      "743:\tlearn: 3.0453850\ttotal: 8.12s\tremaining: 42.1s\n",
      "744:\tlearn: 3.0442415\ttotal: 8.13s\tremaining: 42.1s\n",
      "745:\tlearn: 3.0431855\ttotal: 8.14s\tremaining: 42.1s\n",
      "746:\tlearn: 3.0417989\ttotal: 8.15s\tremaining: 42s\n",
      "747:\tlearn: 3.0406140\ttotal: 8.17s\tremaining: 42s\n",
      "748:\tlearn: 3.0400651\ttotal: 8.18s\tremaining: 42s\n",
      "749:\tlearn: 3.0389402\ttotal: 8.19s\tremaining: 42s\n",
      "750:\tlearn: 3.0373562\ttotal: 8.2s\tremaining: 42s\n",
      "751:\tlearn: 3.0364372\ttotal: 8.21s\tremaining: 42s\n",
      "752:\tlearn: 3.0356767\ttotal: 8.22s\tremaining: 42s\n",
      "753:\tlearn: 3.0345211\ttotal: 8.23s\tremaining: 42s\n",
      "754:\tlearn: 3.0339863\ttotal: 8.24s\tremaining: 42s\n",
      "755:\tlearn: 3.0335306\ttotal: 8.25s\tremaining: 41.9s\n",
      "756:\tlearn: 3.0333790\ttotal: 8.26s\tremaining: 41.9s\n",
      "757:\tlearn: 3.0326331\ttotal: 8.27s\tremaining: 41.9s\n",
      "758:\tlearn: 3.0315302\ttotal: 8.29s\tremaining: 41.9s\n",
      "759:\tlearn: 3.0302894\ttotal: 8.3s\tremaining: 41.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760:\tlearn: 3.0290075\ttotal: 8.31s\tremaining: 41.9s\n",
      "761:\tlearn: 3.0276728\ttotal: 8.32s\tremaining: 41.9s\n",
      "762:\tlearn: 3.0266708\ttotal: 8.33s\tremaining: 41.9s\n",
      "763:\tlearn: 3.0255397\ttotal: 8.35s\tremaining: 41.9s\n",
      "764:\tlearn: 3.0250545\ttotal: 8.36s\tremaining: 41.9s\n",
      "765:\tlearn: 3.0240801\ttotal: 8.37s\tremaining: 41.9s\n",
      "766:\tlearn: 3.0231184\ttotal: 8.38s\tremaining: 41.8s\n",
      "767:\tlearn: 3.0214703\ttotal: 8.39s\tremaining: 41.8s\n",
      "768:\tlearn: 3.0209492\ttotal: 8.4s\tremaining: 41.8s\n",
      "769:\tlearn: 3.0194333\ttotal: 8.41s\tremaining: 41.8s\n",
      "770:\tlearn: 3.0186294\ttotal: 8.42s\tremaining: 41.8s\n",
      "771:\tlearn: 3.0177000\ttotal: 8.43s\tremaining: 41.8s\n",
      "772:\tlearn: 3.0170284\ttotal: 8.44s\tremaining: 41.8s\n",
      "773:\tlearn: 3.0162226\ttotal: 8.45s\tremaining: 41.8s\n",
      "774:\tlearn: 3.0154469\ttotal: 8.46s\tremaining: 41.7s\n",
      "775:\tlearn: 3.0137712\ttotal: 8.47s\tremaining: 41.7s\n",
      "776:\tlearn: 3.0131358\ttotal: 8.48s\tremaining: 41.7s\n",
      "777:\tlearn: 3.0123508\ttotal: 8.49s\tremaining: 41.7s\n",
      "778:\tlearn: 3.0115818\ttotal: 8.5s\tremaining: 41.7s\n",
      "779:\tlearn: 3.0106267\ttotal: 8.52s\tremaining: 41.7s\n",
      "780:\tlearn: 3.0097915\ttotal: 8.53s\tremaining: 41.7s\n",
      "781:\tlearn: 3.0084711\ttotal: 8.54s\tremaining: 41.7s\n",
      "782:\tlearn: 3.0077460\ttotal: 8.55s\tremaining: 41.7s\n",
      "783:\tlearn: 3.0066762\ttotal: 8.56s\tremaining: 41.6s\n",
      "784:\tlearn: 3.0054681\ttotal: 8.57s\tremaining: 41.6s\n",
      "785:\tlearn: 3.0046378\ttotal: 8.58s\tremaining: 41.6s\n",
      "786:\tlearn: 3.0046234\ttotal: 8.59s\tremaining: 41.6s\n",
      "787:\tlearn: 3.0038591\ttotal: 8.6s\tremaining: 41.6s\n",
      "788:\tlearn: 3.0033275\ttotal: 8.61s\tremaining: 41.6s\n",
      "789:\tlearn: 3.0026539\ttotal: 8.63s\tremaining: 41.6s\n",
      "790:\tlearn: 3.0018036\ttotal: 8.64s\tremaining: 41.6s\n",
      "791:\tlearn: 3.0007700\ttotal: 8.65s\tremaining: 41.6s\n",
      "792:\tlearn: 2.9996937\ttotal: 8.66s\tremaining: 41.5s\n",
      "793:\tlearn: 2.9987896\ttotal: 8.67s\tremaining: 41.5s\n",
      "794:\tlearn: 2.9981981\ttotal: 8.68s\tremaining: 41.5s\n",
      "795:\tlearn: 2.9976783\ttotal: 8.69s\tremaining: 41.5s\n",
      "796:\tlearn: 2.9967491\ttotal: 8.7s\tremaining: 41.5s\n",
      "797:\tlearn: 2.9966514\ttotal: 8.71s\tremaining: 41.5s\n",
      "798:\tlearn: 2.9962857\ttotal: 8.72s\tremaining: 41.5s\n",
      "799:\tlearn: 2.9957097\ttotal: 8.73s\tremaining: 41.4s\n",
      "800:\tlearn: 2.9947550\ttotal: 8.74s\tremaining: 41.4s\n",
      "801:\tlearn: 2.9937529\ttotal: 8.75s\tremaining: 41.4s\n",
      "802:\tlearn: 2.9931045\ttotal: 8.76s\tremaining: 41.4s\n",
      "803:\tlearn: 2.9916839\ttotal: 8.77s\tremaining: 41.4s\n",
      "804:\tlearn: 2.9906939\ttotal: 8.79s\tremaining: 41.4s\n",
      "805:\tlearn: 2.9899696\ttotal: 8.8s\tremaining: 41.4s\n",
      "806:\tlearn: 2.9888961\ttotal: 8.81s\tremaining: 41.4s\n",
      "807:\tlearn: 2.9882008\ttotal: 8.82s\tremaining: 41.4s\n",
      "808:\tlearn: 2.9870764\ttotal: 8.83s\tremaining: 41.4s\n",
      "809:\tlearn: 2.9861791\ttotal: 8.84s\tremaining: 41.3s\n",
      "810:\tlearn: 2.9848776\ttotal: 8.85s\tremaining: 41.3s\n",
      "811:\tlearn: 2.9838758\ttotal: 8.86s\tremaining: 41.3s\n",
      "812:\tlearn: 2.9828258\ttotal: 8.87s\tremaining: 41.3s\n",
      "813:\tlearn: 2.9813714\ttotal: 8.89s\tremaining: 41.3s\n",
      "814:\tlearn: 2.9810491\ttotal: 8.9s\tremaining: 41.3s\n",
      "815:\tlearn: 2.9800823\ttotal: 8.91s\tremaining: 41.3s\n",
      "816:\tlearn: 2.9789108\ttotal: 8.92s\tremaining: 41.3s\n",
      "817:\tlearn: 2.9782216\ttotal: 8.93s\tremaining: 41.3s\n",
      "818:\tlearn: 2.9780417\ttotal: 8.94s\tremaining: 41.3s\n",
      "819:\tlearn: 2.9771367\ttotal: 8.95s\tremaining: 41.3s\n",
      "820:\tlearn: 2.9756104\ttotal: 8.97s\tremaining: 41.2s\n",
      "821:\tlearn: 2.9748338\ttotal: 8.98s\tremaining: 41.2s\n",
      "822:\tlearn: 2.9745390\ttotal: 8.99s\tremaining: 41.2s\n",
      "823:\tlearn: 2.9741264\ttotal: 9s\tremaining: 41.2s\n",
      "824:\tlearn: 2.9731639\ttotal: 9.01s\tremaining: 41.2s\n",
      "825:\tlearn: 2.9714996\ttotal: 9.02s\tremaining: 41.2s\n",
      "826:\tlearn: 2.9708068\ttotal: 9.04s\tremaining: 41.2s\n",
      "827:\tlearn: 2.9701584\ttotal: 9.05s\tremaining: 41.2s\n",
      "828:\tlearn: 2.9692349\ttotal: 9.06s\tremaining: 41.2s\n",
      "829:\tlearn: 2.9683011\ttotal: 9.07s\tremaining: 41.2s\n",
      "830:\tlearn: 2.9677737\ttotal: 9.09s\tremaining: 41.2s\n",
      "831:\tlearn: 2.9666223\ttotal: 9.1s\tremaining: 41.2s\n",
      "832:\tlearn: 2.9658880\ttotal: 9.11s\tremaining: 41.2s\n",
      "833:\tlearn: 2.9651656\ttotal: 9.12s\tremaining: 41.2s\n",
      "834:\tlearn: 2.9646524\ttotal: 9.13s\tremaining: 41.2s\n",
      "835:\tlearn: 2.9637530\ttotal: 9.15s\tremaining: 41.2s\n",
      "836:\tlearn: 2.9630103\ttotal: 9.16s\tremaining: 41.2s\n",
      "837:\tlearn: 2.9616954\ttotal: 9.17s\tremaining: 41.1s\n",
      "838:\tlearn: 2.9607009\ttotal: 9.18s\tremaining: 41.1s\n",
      "839:\tlearn: 2.9593254\ttotal: 9.2s\tremaining: 41.1s\n",
      "840:\tlearn: 2.9576836\ttotal: 9.21s\tremaining: 41.1s\n",
      "841:\tlearn: 2.9568662\ttotal: 9.22s\tremaining: 41.1s\n",
      "842:\tlearn: 2.9562905\ttotal: 9.23s\tremaining: 41.1s\n",
      "843:\tlearn: 2.9555265\ttotal: 9.24s\tremaining: 41.1s\n",
      "844:\tlearn: 2.9538094\ttotal: 9.25s\tremaining: 41.1s\n",
      "845:\tlearn: 2.9525670\ttotal: 9.26s\tremaining: 41.1s\n",
      "846:\tlearn: 2.9514851\ttotal: 9.27s\tremaining: 41.1s\n",
      "847:\tlearn: 2.9512126\ttotal: 9.28s\tremaining: 41.1s\n",
      "848:\tlearn: 2.9506409\ttotal: 9.29s\tremaining: 41s\n",
      "849:\tlearn: 2.9497752\ttotal: 9.3s\tremaining: 41s\n",
      "850:\tlearn: 2.9490298\ttotal: 9.31s\tremaining: 41s\n",
      "851:\tlearn: 2.9481709\ttotal: 9.32s\tremaining: 41s\n",
      "852:\tlearn: 2.9471113\ttotal: 9.34s\tremaining: 41s\n",
      "853:\tlearn: 2.9462660\ttotal: 9.35s\tremaining: 41s\n",
      "854:\tlearn: 2.9449407\ttotal: 9.36s\tremaining: 41s\n",
      "855:\tlearn: 2.9439448\ttotal: 9.37s\tremaining: 41s\n",
      "856:\tlearn: 2.9422643\ttotal: 9.38s\tremaining: 41s\n",
      "857:\tlearn: 2.9415073\ttotal: 9.39s\tremaining: 41s\n",
      "858:\tlearn: 2.9403988\ttotal: 9.41s\tremaining: 40.9s\n",
      "859:\tlearn: 2.9400810\ttotal: 9.42s\tremaining: 40.9s\n",
      "860:\tlearn: 2.9395617\ttotal: 9.43s\tremaining: 40.9s\n",
      "861:\tlearn: 2.9389527\ttotal: 9.44s\tremaining: 40.9s\n",
      "862:\tlearn: 2.9384018\ttotal: 9.45s\tremaining: 40.9s\n",
      "863:\tlearn: 2.9374034\ttotal: 9.46s\tremaining: 40.9s\n",
      "864:\tlearn: 2.9367492\ttotal: 9.47s\tremaining: 40.9s\n",
      "865:\tlearn: 2.9354607\ttotal: 9.48s\tremaining: 40.8s\n",
      "866:\tlearn: 2.9340406\ttotal: 9.49s\tremaining: 40.8s\n",
      "867:\tlearn: 2.9330200\ttotal: 9.5s\tremaining: 40.8s\n",
      "868:\tlearn: 2.9317359\ttotal: 9.51s\tremaining: 40.8s\n",
      "869:\tlearn: 2.9311723\ttotal: 9.52s\tremaining: 40.8s\n",
      "870:\tlearn: 2.9306288\ttotal: 9.53s\tremaining: 40.8s\n",
      "871:\tlearn: 2.9294285\ttotal: 9.54s\tremaining: 40.8s\n",
      "872:\tlearn: 2.9283778\ttotal: 9.56s\tremaining: 40.8s\n",
      "873:\tlearn: 2.9277745\ttotal: 9.57s\tremaining: 40.8s\n",
      "874:\tlearn: 2.9263039\ttotal: 9.58s\tremaining: 40.8s\n",
      "875:\tlearn: 2.9251712\ttotal: 9.59s\tremaining: 40.8s\n",
      "876:\tlearn: 2.9243485\ttotal: 9.61s\tremaining: 40.8s\n",
      "877:\tlearn: 2.9232215\ttotal: 9.62s\tremaining: 40.7s\n",
      "878:\tlearn: 2.9227148\ttotal: 9.63s\tremaining: 40.7s\n",
      "879:\tlearn: 2.9218233\ttotal: 9.64s\tremaining: 40.7s\n",
      "880:\tlearn: 2.9212411\ttotal: 9.65s\tremaining: 40.7s\n",
      "881:\tlearn: 2.9210463\ttotal: 9.66s\tremaining: 40.7s\n",
      "882:\tlearn: 2.9206387\ttotal: 9.67s\tremaining: 40.7s\n",
      "883:\tlearn: 2.9201830\ttotal: 9.68s\tremaining: 40.7s\n",
      "884:\tlearn: 2.9193760\ttotal: 9.69s\tremaining: 40.6s\n",
      "885:\tlearn: 2.9186413\ttotal: 9.7s\tremaining: 40.6s\n",
      "886:\tlearn: 2.9173111\ttotal: 9.71s\tremaining: 40.6s\n",
      "887:\tlearn: 2.9162451\ttotal: 9.72s\tremaining: 40.6s\n",
      "888:\tlearn: 2.9149216\ttotal: 9.73s\tremaining: 40.6s\n",
      "889:\tlearn: 2.9140400\ttotal: 9.74s\tremaining: 40.6s\n",
      "890:\tlearn: 2.9127965\ttotal: 9.75s\tremaining: 40.6s\n",
      "891:\tlearn: 2.9115208\ttotal: 9.77s\tremaining: 40.6s\n",
      "892:\tlearn: 2.9106405\ttotal: 9.78s\tremaining: 40.6s\n",
      "893:\tlearn: 2.9100174\ttotal: 9.79s\tremaining: 40.6s\n",
      "894:\tlearn: 2.9092116\ttotal: 9.8s\tremaining: 40.6s\n",
      "895:\tlearn: 2.9081771\ttotal: 9.81s\tremaining: 40.5s\n",
      "896:\tlearn: 2.9075114\ttotal: 9.82s\tremaining: 40.5s\n",
      "897:\tlearn: 2.9067893\ttotal: 9.83s\tremaining: 40.5s\n",
      "898:\tlearn: 2.9059922\ttotal: 9.84s\tremaining: 40.5s\n",
      "899:\tlearn: 2.9051396\ttotal: 9.86s\tremaining: 40.5s\n",
      "900:\tlearn: 2.9042220\ttotal: 9.87s\tremaining: 40.5s\n",
      "901:\tlearn: 2.9024270\ttotal: 9.88s\tremaining: 40.5s\n",
      "902:\tlearn: 2.9017336\ttotal: 9.89s\tremaining: 40.5s\n",
      "903:\tlearn: 2.9006348\ttotal: 9.9s\tremaining: 40.4s\n",
      "904:\tlearn: 2.8995255\ttotal: 9.91s\tremaining: 40.4s\n",
      "905:\tlearn: 2.8982602\ttotal: 9.92s\tremaining: 40.4s\n",
      "906:\tlearn: 2.8973305\ttotal: 9.93s\tremaining: 40.4s\n",
      "907:\tlearn: 2.8963472\ttotal: 9.94s\tremaining: 40.4s\n",
      "908:\tlearn: 2.8950652\ttotal: 9.95s\tremaining: 40.4s\n",
      "909:\tlearn: 2.8945520\ttotal: 9.96s\tremaining: 40.4s\n",
      "910:\tlearn: 2.8939133\ttotal: 9.97s\tremaining: 40.4s\n",
      "911:\tlearn: 2.8931585\ttotal: 9.99s\tremaining: 40.4s\n",
      "912:\tlearn: 2.8922515\ttotal: 10s\tremaining: 40.4s\n",
      "913:\tlearn: 2.8905442\ttotal: 10s\tremaining: 40.4s\n",
      "914:\tlearn: 2.8894061\ttotal: 10s\tremaining: 40.3s\n",
      "915:\tlearn: 2.8883825\ttotal: 10s\tremaining: 40.3s\n",
      "916:\tlearn: 2.8878049\ttotal: 10s\tremaining: 40.3s\n",
      "917:\tlearn: 2.8870285\ttotal: 10.1s\tremaining: 40.3s\n",
      "918:\tlearn: 2.8861328\ttotal: 10.1s\tremaining: 40.3s\n",
      "919:\tlearn: 2.8860700\ttotal: 10.1s\tremaining: 40.3s\n",
      "920:\tlearn: 2.8852997\ttotal: 10.1s\tremaining: 40.3s\n",
      "921:\tlearn: 2.8840737\ttotal: 10.1s\tremaining: 40.3s\n",
      "922:\tlearn: 2.8832285\ttotal: 10.1s\tremaining: 40.2s\n",
      "923:\tlearn: 2.8830772\ttotal: 10.1s\tremaining: 40.2s\n",
      "924:\tlearn: 2.8826013\ttotal: 10.1s\tremaining: 40.2s\n",
      "925:\tlearn: 2.8823912\ttotal: 10.1s\tremaining: 40.2s\n",
      "926:\tlearn: 2.8813025\ttotal: 10.1s\tremaining: 40.2s\n",
      "927:\tlearn: 2.8808996\ttotal: 10.2s\tremaining: 40.2s\n",
      "928:\tlearn: 2.8800299\ttotal: 10.2s\tremaining: 40.2s\n",
      "929:\tlearn: 2.8789641\ttotal: 10.2s\tremaining: 40.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "930:\tlearn: 2.8781110\ttotal: 10.2s\tremaining: 40.1s\n",
      "931:\tlearn: 2.8771219\ttotal: 10.2s\tremaining: 40.1s\n",
      "932:\tlearn: 2.8758712\ttotal: 10.2s\tremaining: 40.1s\n",
      "933:\tlearn: 2.8755060\ttotal: 10.2s\tremaining: 40.1s\n",
      "934:\tlearn: 2.8746696\ttotal: 10.2s\tremaining: 40.1s\n",
      "935:\tlearn: 2.8740874\ttotal: 10.2s\tremaining: 40.1s\n",
      "936:\tlearn: 2.8731151\ttotal: 10.3s\tremaining: 40.1s\n",
      "937:\tlearn: 2.8721931\ttotal: 10.3s\tremaining: 40.1s\n",
      "938:\tlearn: 2.8712325\ttotal: 10.3s\tremaining: 40.1s\n",
      "939:\tlearn: 2.8699110\ttotal: 10.3s\tremaining: 40s\n",
      "940:\tlearn: 2.8689109\ttotal: 10.3s\tremaining: 40s\n",
      "941:\tlearn: 2.8679044\ttotal: 10.3s\tremaining: 40s\n",
      "942:\tlearn: 2.8674267\ttotal: 10.3s\tremaining: 40s\n",
      "943:\tlearn: 2.8670819\ttotal: 10.3s\tremaining: 40s\n",
      "944:\tlearn: 2.8666465\ttotal: 10.3s\tremaining: 40s\n",
      "945:\tlearn: 2.8660912\ttotal: 10.4s\tremaining: 40s\n",
      "946:\tlearn: 2.8652109\ttotal: 10.4s\tremaining: 40s\n",
      "947:\tlearn: 2.8644048\ttotal: 10.4s\tremaining: 40s\n",
      "948:\tlearn: 2.8633561\ttotal: 10.4s\tremaining: 39.9s\n",
      "949:\tlearn: 2.8629444\ttotal: 10.4s\tremaining: 39.9s\n",
      "950:\tlearn: 2.8621515\ttotal: 10.4s\tremaining: 39.9s\n",
      "951:\tlearn: 2.8618705\ttotal: 10.4s\tremaining: 39.9s\n",
      "952:\tlearn: 2.8610516\ttotal: 10.4s\tremaining: 39.9s\n",
      "953:\tlearn: 2.8603471\ttotal: 10.4s\tremaining: 39.9s\n",
      "954:\tlearn: 2.8597700\ttotal: 10.5s\tremaining: 39.9s\n",
      "955:\tlearn: 2.8589471\ttotal: 10.5s\tremaining: 39.9s\n",
      "956:\tlearn: 2.8585221\ttotal: 10.5s\tremaining: 39.9s\n",
      "957:\tlearn: 2.8578072\ttotal: 10.5s\tremaining: 39.8s\n",
      "958:\tlearn: 2.8566816\ttotal: 10.5s\tremaining: 39.8s\n",
      "959:\tlearn: 2.8559320\ttotal: 10.5s\tremaining: 39.8s\n",
      "960:\tlearn: 2.8556531\ttotal: 10.5s\tremaining: 39.8s\n",
      "961:\tlearn: 2.8545931\ttotal: 10.5s\tremaining: 39.8s\n",
      "962:\tlearn: 2.8538424\ttotal: 10.5s\tremaining: 39.8s\n",
      "963:\tlearn: 2.8528383\ttotal: 10.6s\tremaining: 39.8s\n",
      "964:\tlearn: 2.8519702\ttotal: 10.6s\tremaining: 39.8s\n",
      "965:\tlearn: 2.8512352\ttotal: 10.6s\tremaining: 39.8s\n",
      "966:\tlearn: 2.8505863\ttotal: 10.6s\tremaining: 39.7s\n",
      "967:\tlearn: 2.8497282\ttotal: 10.6s\tremaining: 39.7s\n",
      "968:\tlearn: 2.8491237\ttotal: 10.6s\tremaining: 39.7s\n",
      "969:\tlearn: 2.8486456\ttotal: 10.6s\tremaining: 39.7s\n",
      "970:\tlearn: 2.8477752\ttotal: 10.6s\tremaining: 39.7s\n",
      "971:\tlearn: 2.8470788\ttotal: 10.6s\tremaining: 39.7s\n",
      "972:\tlearn: 2.8453520\ttotal: 10.7s\tremaining: 39.7s\n",
      "973:\tlearn: 2.8444530\ttotal: 10.7s\tremaining: 39.7s\n",
      "974:\tlearn: 2.8435029\ttotal: 10.7s\tremaining: 39.7s\n",
      "975:\tlearn: 2.8422336\ttotal: 10.7s\tremaining: 39.6s\n",
      "976:\tlearn: 2.8410971\ttotal: 10.7s\tremaining: 39.6s\n",
      "977:\tlearn: 2.8402842\ttotal: 10.7s\tremaining: 39.6s\n",
      "978:\tlearn: 2.8396589\ttotal: 10.7s\tremaining: 39.6s\n",
      "979:\tlearn: 2.8389570\ttotal: 10.7s\tremaining: 39.6s\n",
      "980:\tlearn: 2.8379161\ttotal: 10.7s\tremaining: 39.6s\n",
      "981:\tlearn: 2.8374442\ttotal: 10.7s\tremaining: 39.6s\n",
      "982:\tlearn: 2.8364306\ttotal: 10.8s\tremaining: 39.6s\n",
      "983:\tlearn: 2.8359049\ttotal: 10.8s\tremaining: 39.6s\n",
      "984:\tlearn: 2.8349483\ttotal: 10.8s\tremaining: 39.6s\n",
      "985:\tlearn: 2.8345842\ttotal: 10.8s\tremaining: 39.5s\n",
      "986:\tlearn: 2.8338189\ttotal: 10.8s\tremaining: 39.5s\n",
      "987:\tlearn: 2.8334375\ttotal: 10.8s\tremaining: 39.5s\n",
      "988:\tlearn: 2.8324814\ttotal: 10.8s\tremaining: 39.5s\n",
      "989:\tlearn: 2.8318382\ttotal: 10.8s\tremaining: 39.5s\n",
      "990:\tlearn: 2.8312307\ttotal: 10.9s\tremaining: 39.5s\n",
      "991:\tlearn: 2.8308601\ttotal: 10.9s\tremaining: 39.5s\n",
      "992:\tlearn: 2.8305124\ttotal: 10.9s\tremaining: 39.5s\n",
      "993:\tlearn: 2.8298075\ttotal: 10.9s\tremaining: 39.5s\n",
      "994:\tlearn: 2.8291325\ttotal: 10.9s\tremaining: 39.5s\n",
      "995:\tlearn: 2.8284196\ttotal: 10.9s\tremaining: 39.4s\n",
      "996:\tlearn: 2.8275055\ttotal: 10.9s\tremaining: 39.4s\n",
      "997:\tlearn: 2.8262684\ttotal: 10.9s\tremaining: 39.4s\n",
      "998:\tlearn: 2.8258100\ttotal: 10.9s\tremaining: 39.4s\n",
      "999:\tlearn: 2.8249169\ttotal: 10.9s\tremaining: 39.4s\n",
      "1000:\tlearn: 2.8242217\ttotal: 11s\tremaining: 39.4s\n",
      "1001:\tlearn: 2.8230637\ttotal: 11s\tremaining: 39.4s\n",
      "1002:\tlearn: 2.8223670\ttotal: 11s\tremaining: 39.4s\n",
      "1003:\tlearn: 2.8216032\ttotal: 11s\tremaining: 39.3s\n",
      "1004:\tlearn: 2.8207828\ttotal: 11s\tremaining: 39.3s\n",
      "1005:\tlearn: 2.8201256\ttotal: 11s\tremaining: 39.3s\n",
      "1006:\tlearn: 2.8192249\ttotal: 11s\tremaining: 39.3s\n",
      "1007:\tlearn: 2.8186688\ttotal: 11s\tremaining: 39.3s\n",
      "1008:\tlearn: 2.8178669\ttotal: 11s\tremaining: 39.3s\n",
      "1009:\tlearn: 2.8174787\ttotal: 11.1s\tremaining: 39.3s\n",
      "1010:\tlearn: 2.8169099\ttotal: 11.1s\tremaining: 39.3s\n",
      "1011:\tlearn: 2.8164614\ttotal: 11.1s\tremaining: 39.3s\n",
      "1012:\tlearn: 2.8158009\ttotal: 11.1s\tremaining: 39.2s\n",
      "1013:\tlearn: 2.8147258\ttotal: 11.1s\tremaining: 39.2s\n",
      "1014:\tlearn: 2.8138087\ttotal: 11.1s\tremaining: 39.2s\n",
      "1015:\tlearn: 2.8130428\ttotal: 11.1s\tremaining: 39.2s\n",
      "1016:\tlearn: 2.8125080\ttotal: 11.1s\tremaining: 39.2s\n",
      "1017:\tlearn: 2.8115947\ttotal: 11.1s\tremaining: 39.2s\n",
      "1018:\tlearn: 2.8108095\ttotal: 11.2s\tremaining: 39.2s\n",
      "1019:\tlearn: 2.8100334\ttotal: 11.2s\tremaining: 39.2s\n",
      "1020:\tlearn: 2.8094420\ttotal: 11.2s\tremaining: 39.1s\n",
      "1021:\tlearn: 2.8090549\ttotal: 11.2s\tremaining: 39.1s\n",
      "1022:\tlearn: 2.8079072\ttotal: 11.2s\tremaining: 39.1s\n",
      "1023:\tlearn: 2.8071528\ttotal: 11.2s\tremaining: 39.1s\n",
      "1024:\tlearn: 2.8066261\ttotal: 11.2s\tremaining: 39.1s\n",
      "1025:\tlearn: 2.8052620\ttotal: 11.2s\tremaining: 39.1s\n",
      "1026:\tlearn: 2.8043987\ttotal: 11.2s\tremaining: 39.1s\n",
      "1027:\tlearn: 2.8034750\ttotal: 11.3s\tremaining: 39.1s\n",
      "1028:\tlearn: 2.8026274\ttotal: 11.3s\tremaining: 39.1s\n",
      "1029:\tlearn: 2.8020171\ttotal: 11.3s\tremaining: 39.1s\n",
      "1030:\tlearn: 2.8016657\ttotal: 11.3s\tremaining: 39s\n",
      "1031:\tlearn: 2.8013226\ttotal: 11.3s\tremaining: 39s\n",
      "1032:\tlearn: 2.8007987\ttotal: 11.3s\tremaining: 39s\n",
      "1033:\tlearn: 2.7997392\ttotal: 11.3s\tremaining: 39s\n",
      "1034:\tlearn: 2.7991557\ttotal: 11.3s\tremaining: 39s\n",
      "1035:\tlearn: 2.7987420\ttotal: 11.3s\tremaining: 39s\n",
      "1036:\tlearn: 2.7972364\ttotal: 11.3s\tremaining: 39s\n",
      "1037:\tlearn: 2.7966965\ttotal: 11.4s\tremaining: 39s\n",
      "1038:\tlearn: 2.7958340\ttotal: 11.4s\tremaining: 39s\n",
      "1039:\tlearn: 2.7951987\ttotal: 11.4s\tremaining: 38.9s\n",
      "1040:\tlearn: 2.7943079\ttotal: 11.4s\tremaining: 38.9s\n",
      "1041:\tlearn: 2.7937530\ttotal: 11.4s\tremaining: 38.9s\n",
      "1042:\tlearn: 2.7928517\ttotal: 11.4s\tremaining: 38.9s\n",
      "1043:\tlearn: 2.7921081\ttotal: 11.4s\tremaining: 38.9s\n",
      "1044:\tlearn: 2.7915597\ttotal: 11.4s\tremaining: 38.9s\n",
      "1045:\tlearn: 2.7907080\ttotal: 11.4s\tremaining: 38.9s\n",
      "1046:\tlearn: 2.7897682\ttotal: 11.5s\tremaining: 38.9s\n",
      "1047:\tlearn: 2.7884381\ttotal: 11.5s\tremaining: 38.9s\n",
      "1048:\tlearn: 2.7876679\ttotal: 11.5s\tremaining: 38.9s\n",
      "1049:\tlearn: 2.7866385\ttotal: 11.5s\tremaining: 38.9s\n",
      "1050:\tlearn: 2.7859859\ttotal: 11.5s\tremaining: 38.9s\n",
      "1051:\tlearn: 2.7849140\ttotal: 11.5s\tremaining: 38.9s\n",
      "1052:\tlearn: 2.7841023\ttotal: 11.5s\tremaining: 38.8s\n",
      "1053:\tlearn: 2.7832894\ttotal: 11.6s\tremaining: 38.8s\n",
      "1054:\tlearn: 2.7829241\ttotal: 11.6s\tremaining: 38.8s\n",
      "1055:\tlearn: 2.7820440\ttotal: 11.6s\tremaining: 38.8s\n",
      "1056:\tlearn: 2.7814545\ttotal: 11.6s\tremaining: 38.8s\n",
      "1057:\tlearn: 2.7809560\ttotal: 11.6s\tremaining: 38.8s\n",
      "1058:\tlearn: 2.7800120\ttotal: 11.6s\tremaining: 38.8s\n",
      "1059:\tlearn: 2.7793715\ttotal: 11.6s\tremaining: 38.8s\n",
      "1060:\tlearn: 2.7787119\ttotal: 11.6s\tremaining: 38.8s\n",
      "1061:\tlearn: 2.7784741\ttotal: 11.6s\tremaining: 38.7s\n",
      "1062:\tlearn: 2.7774432\ttotal: 11.6s\tremaining: 38.7s\n",
      "1063:\tlearn: 2.7766708\ttotal: 11.7s\tremaining: 38.7s\n",
      "1064:\tlearn: 2.7762042\ttotal: 11.7s\tremaining: 38.7s\n",
      "1065:\tlearn: 2.7755604\ttotal: 11.7s\tremaining: 38.7s\n",
      "1066:\tlearn: 2.7749668\ttotal: 11.7s\tremaining: 38.7s\n",
      "1067:\tlearn: 2.7738504\ttotal: 11.7s\tremaining: 38.7s\n",
      "1068:\tlearn: 2.7728130\ttotal: 11.7s\tremaining: 38.7s\n",
      "1069:\tlearn: 2.7726798\ttotal: 11.7s\tremaining: 38.7s\n",
      "1070:\tlearn: 2.7718107\ttotal: 11.7s\tremaining: 38.6s\n",
      "1071:\tlearn: 2.7711493\ttotal: 11.7s\tremaining: 38.6s\n",
      "1072:\tlearn: 2.7699740\ttotal: 11.8s\tremaining: 38.6s\n",
      "1073:\tlearn: 2.7695653\ttotal: 11.8s\tremaining: 38.6s\n",
      "1074:\tlearn: 2.7686941\ttotal: 11.8s\tremaining: 38.6s\n",
      "1075:\tlearn: 2.7678320\ttotal: 11.8s\tremaining: 38.6s\n",
      "1076:\tlearn: 2.7671625\ttotal: 11.8s\tremaining: 38.6s\n",
      "1077:\tlearn: 2.7666019\ttotal: 11.8s\tremaining: 38.6s\n",
      "1078:\tlearn: 2.7654616\ttotal: 11.8s\tremaining: 38.6s\n",
      "1079:\tlearn: 2.7648346\ttotal: 11.8s\tremaining: 38.5s\n",
      "1080:\tlearn: 2.7639097\ttotal: 11.8s\tremaining: 38.5s\n",
      "1081:\tlearn: 2.7634356\ttotal: 11.9s\tremaining: 38.5s\n",
      "1082:\tlearn: 2.7626601\ttotal: 11.9s\tremaining: 38.5s\n",
      "1083:\tlearn: 2.7617670\ttotal: 11.9s\tremaining: 38.5s\n",
      "1084:\tlearn: 2.7611115\ttotal: 11.9s\tremaining: 38.5s\n",
      "1085:\tlearn: 2.7607519\ttotal: 11.9s\tremaining: 38.5s\n",
      "1086:\tlearn: 2.7599690\ttotal: 11.9s\tremaining: 38.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1087:\tlearn: 2.7595551\ttotal: 11.9s\tremaining: 38.4s\n",
      "1088:\tlearn: 2.7587966\ttotal: 11.9s\tremaining: 38.4s\n",
      "1089:\tlearn: 2.7583225\ttotal: 11.9s\tremaining: 38.4s\n",
      "1090:\tlearn: 2.7572517\ttotal: 12s\tremaining: 38.4s\n",
      "1091:\tlearn: 2.7563607\ttotal: 12s\tremaining: 38.4s\n",
      "1092:\tlearn: 2.7553160\ttotal: 12s\tremaining: 38.4s\n",
      "1093:\tlearn: 2.7541208\ttotal: 12s\tremaining: 38.4s\n",
      "1094:\tlearn: 2.7527535\ttotal: 12s\tremaining: 38.4s\n",
      "1095:\tlearn: 2.7521891\ttotal: 12s\tremaining: 38.4s\n",
      "1096:\tlearn: 2.7515520\ttotal: 12s\tremaining: 38.4s\n",
      "1097:\tlearn: 2.7509169\ttotal: 12s\tremaining: 38.3s\n",
      "1098:\tlearn: 2.7502578\ttotal: 12s\tremaining: 38.3s\n",
      "1099:\tlearn: 2.7501119\ttotal: 12s\tremaining: 38.3s\n",
      "1100:\tlearn: 2.7494804\ttotal: 12.1s\tremaining: 38.3s\n",
      "1101:\tlearn: 2.7487282\ttotal: 12.1s\tremaining: 38.3s\n",
      "1102:\tlearn: 2.7477167\ttotal: 12.1s\tremaining: 38.3s\n",
      "1103:\tlearn: 2.7466919\ttotal: 12.1s\tremaining: 38.3s\n",
      "1104:\tlearn: 2.7458389\ttotal: 12.1s\tremaining: 38.2s\n",
      "1105:\tlearn: 2.7450896\ttotal: 12.1s\tremaining: 38.2s\n",
      "1106:\tlearn: 2.7444384\ttotal: 12.1s\tremaining: 38.2s\n",
      "1107:\tlearn: 2.7439582\ttotal: 12.1s\tremaining: 38.2s\n",
      "1108:\tlearn: 2.7432925\ttotal: 12.1s\tremaining: 38.2s\n",
      "1109:\tlearn: 2.7422593\ttotal: 12.2s\tremaining: 38.2s\n",
      "1110:\tlearn: 2.7413821\ttotal: 12.2s\tremaining: 38.2s\n",
      "1111:\tlearn: 2.7410297\ttotal: 12.2s\tremaining: 38.2s\n",
      "1112:\tlearn: 2.7407670\ttotal: 12.2s\tremaining: 38.2s\n",
      "1113:\tlearn: 2.7398666\ttotal: 12.2s\tremaining: 38.2s\n",
      "1114:\tlearn: 2.7393367\ttotal: 12.2s\tremaining: 38.2s\n",
      "1115:\tlearn: 2.7387214\ttotal: 12.2s\tremaining: 38.2s\n",
      "1116:\tlearn: 2.7379954\ttotal: 12.2s\tremaining: 38.1s\n",
      "1117:\tlearn: 2.7373188\ttotal: 12.3s\tremaining: 38.1s\n",
      "1118:\tlearn: 2.7364223\ttotal: 12.3s\tremaining: 38.1s\n",
      "1119:\tlearn: 2.7360653\ttotal: 12.3s\tremaining: 38.1s\n",
      "1120:\tlearn: 2.7355760\ttotal: 12.3s\tremaining: 38.1s\n",
      "1121:\tlearn: 2.7348918\ttotal: 12.3s\tremaining: 38.1s\n",
      "1122:\tlearn: 2.7339446\ttotal: 12.3s\tremaining: 38.1s\n",
      "1123:\tlearn: 2.7337139\ttotal: 12.3s\tremaining: 38.1s\n",
      "1124:\tlearn: 2.7328168\ttotal: 12.3s\tremaining: 38.1s\n",
      "1125:\tlearn: 2.7323786\ttotal: 12.4s\tremaining: 38.1s\n",
      "1126:\tlearn: 2.7318627\ttotal: 12.4s\tremaining: 38.1s\n",
      "1127:\tlearn: 2.7314532\ttotal: 12.4s\tremaining: 38.1s\n",
      "1128:\tlearn: 2.7307235\ttotal: 12.4s\tremaining: 38.1s\n",
      "1129:\tlearn: 2.7297307\ttotal: 12.4s\tremaining: 38s\n",
      "1130:\tlearn: 2.7292173\ttotal: 12.4s\tremaining: 38s\n",
      "1131:\tlearn: 2.7287446\ttotal: 12.4s\tremaining: 38s\n",
      "1132:\tlearn: 2.7282794\ttotal: 12.4s\tremaining: 38s\n",
      "1133:\tlearn: 2.7278304\ttotal: 12.4s\tremaining: 38s\n",
      "1134:\tlearn: 2.7271700\ttotal: 12.4s\tremaining: 38s\n",
      "1135:\tlearn: 2.7265234\ttotal: 12.5s\tremaining: 38s\n",
      "1136:\tlearn: 2.7261166\ttotal: 12.5s\tremaining: 38s\n",
      "1137:\tlearn: 2.7246269\ttotal: 12.5s\tremaining: 38s\n",
      "1138:\tlearn: 2.7239468\ttotal: 12.5s\tremaining: 37.9s\n",
      "1139:\tlearn: 2.7229676\ttotal: 12.5s\tremaining: 37.9s\n",
      "1140:\tlearn: 2.7222521\ttotal: 12.5s\tremaining: 37.9s\n",
      "1141:\tlearn: 2.7218258\ttotal: 12.5s\tremaining: 37.9s\n",
      "1142:\tlearn: 2.7210233\ttotal: 12.5s\tremaining: 37.9s\n",
      "1143:\tlearn: 2.7196668\ttotal: 12.5s\tremaining: 37.9s\n",
      "1144:\tlearn: 2.7188946\ttotal: 12.6s\tremaining: 37.9s\n",
      "1145:\tlearn: 2.7182694\ttotal: 12.6s\tremaining: 37.9s\n",
      "1146:\tlearn: 2.7174429\ttotal: 12.6s\tremaining: 37.9s\n",
      "1147:\tlearn: 2.7172741\ttotal: 12.6s\tremaining: 37.8s\n",
      "1148:\tlearn: 2.7164685\ttotal: 12.6s\tremaining: 37.8s\n",
      "1149:\tlearn: 2.7157108\ttotal: 12.6s\tremaining: 37.8s\n",
      "1150:\tlearn: 2.7150519\ttotal: 12.6s\tremaining: 37.8s\n",
      "1151:\tlearn: 2.7144906\ttotal: 12.6s\tremaining: 37.8s\n",
      "1152:\tlearn: 2.7137395\ttotal: 12.6s\tremaining: 37.8s\n",
      "1153:\tlearn: 2.7127659\ttotal: 12.7s\tremaining: 37.8s\n",
      "1154:\tlearn: 2.7120418\ttotal: 12.7s\tremaining: 37.8s\n",
      "1155:\tlearn: 2.7113637\ttotal: 12.7s\tremaining: 37.8s\n",
      "1156:\tlearn: 2.7101652\ttotal: 12.7s\tremaining: 37.7s\n",
      "1157:\tlearn: 2.7097278\ttotal: 12.7s\tremaining: 37.7s\n",
      "1158:\tlearn: 2.7089160\ttotal: 12.7s\tremaining: 37.7s\n",
      "1159:\tlearn: 2.7084029\ttotal: 12.7s\tremaining: 37.7s\n",
      "1160:\tlearn: 2.7077672\ttotal: 12.7s\tremaining: 37.7s\n",
      "1161:\tlearn: 2.7069447\ttotal: 12.7s\tremaining: 37.7s\n",
      "1162:\tlearn: 2.7064034\ttotal: 12.8s\tremaining: 37.7s\n",
      "1163:\tlearn: 2.7060642\ttotal: 12.8s\tremaining: 37.7s\n",
      "1164:\tlearn: 2.7054418\ttotal: 12.8s\tremaining: 37.6s\n",
      "1165:\tlearn: 2.7040868\ttotal: 12.8s\tremaining: 37.6s\n",
      "1166:\tlearn: 2.7033007\ttotal: 12.8s\tremaining: 37.6s\n",
      "1167:\tlearn: 2.7026041\ttotal: 12.8s\tremaining: 37.6s\n",
      "1168:\tlearn: 2.7015937\ttotal: 12.8s\tremaining: 37.6s\n",
      "1169:\tlearn: 2.7009724\ttotal: 12.8s\tremaining: 37.6s\n",
      "1170:\tlearn: 2.7003993\ttotal: 12.8s\tremaining: 37.6s\n",
      "1171:\tlearn: 2.6996056\ttotal: 12.8s\tremaining: 37.6s\n",
      "1172:\tlearn: 2.6988641\ttotal: 12.9s\tremaining: 37.6s\n",
      "1173:\tlearn: 2.6974369\ttotal: 12.9s\tremaining: 37.5s\n",
      "1174:\tlearn: 2.6966476\ttotal: 12.9s\tremaining: 37.5s\n",
      "1175:\tlearn: 2.6963173\ttotal: 12.9s\tremaining: 37.5s\n",
      "1176:\tlearn: 2.6957877\ttotal: 12.9s\tremaining: 37.5s\n",
      "1177:\tlearn: 2.6951017\ttotal: 12.9s\tremaining: 37.5s\n",
      "1178:\tlearn: 2.6945117\ttotal: 12.9s\tremaining: 37.5s\n",
      "1179:\tlearn: 2.6938487\ttotal: 12.9s\tremaining: 37.5s\n",
      "1180:\tlearn: 2.6931865\ttotal: 12.9s\tremaining: 37.4s\n",
      "1181:\tlearn: 2.6922083\ttotal: 13s\tremaining: 37.4s\n",
      "1182:\tlearn: 2.6913000\ttotal: 13s\tremaining: 37.4s\n",
      "1183:\tlearn: 2.6908281\ttotal: 13s\tremaining: 37.4s\n",
      "1184:\tlearn: 2.6898951\ttotal: 13s\tremaining: 37.4s\n",
      "1185:\tlearn: 2.6890355\ttotal: 13s\tremaining: 37.4s\n",
      "1186:\tlearn: 2.6879199\ttotal: 13s\tremaining: 37.4s\n",
      "1187:\tlearn: 2.6875068\ttotal: 13s\tremaining: 37.4s\n",
      "1188:\tlearn: 2.6866128\ttotal: 13s\tremaining: 37.4s\n",
      "1189:\tlearn: 2.6862598\ttotal: 13s\tremaining: 37.4s\n",
      "1190:\tlearn: 2.6855972\ttotal: 13.1s\tremaining: 37.3s\n",
      "1191:\tlearn: 2.6848904\ttotal: 13.1s\tremaining: 37.3s\n",
      "1192:\tlearn: 2.6844690\ttotal: 13.1s\tremaining: 37.3s\n",
      "1193:\tlearn: 2.6838170\ttotal: 13.1s\tremaining: 37.3s\n",
      "1194:\tlearn: 2.6834635\ttotal: 13.1s\tremaining: 37.3s\n",
      "1195:\tlearn: 2.6830167\ttotal: 13.1s\tremaining: 37.3s\n",
      "1196:\tlearn: 2.6823002\ttotal: 13.1s\tremaining: 37.3s\n",
      "1197:\tlearn: 2.6816567\ttotal: 13.1s\tremaining: 37.3s\n",
      "1198:\tlearn: 2.6808935\ttotal: 13.1s\tremaining: 37.2s\n",
      "1199:\tlearn: 2.6803902\ttotal: 13.1s\tremaining: 37.2s\n",
      "1200:\tlearn: 2.6798334\ttotal: 13.2s\tremaining: 37.2s\n",
      "1201:\tlearn: 2.6790861\ttotal: 13.2s\tremaining: 37.2s\n",
      "1202:\tlearn: 2.6781524\ttotal: 13.2s\tremaining: 37.2s\n",
      "1203:\tlearn: 2.6778583\ttotal: 13.2s\tremaining: 37.2s\n",
      "1204:\tlearn: 2.6774176\ttotal: 13.2s\tremaining: 37.2s\n",
      "1205:\tlearn: 2.6770634\ttotal: 13.2s\tremaining: 37.2s\n",
      "1206:\tlearn: 2.6766365\ttotal: 13.2s\tremaining: 37.1s\n",
      "1207:\tlearn: 2.6761109\ttotal: 13.2s\tremaining: 37.1s\n",
      "1208:\tlearn: 2.6756896\ttotal: 13.2s\tremaining: 37.1s\n",
      "1209:\tlearn: 2.6751210\ttotal: 13.3s\tremaining: 37.1s\n",
      "1210:\tlearn: 2.6742936\ttotal: 13.3s\tremaining: 37.1s\n",
      "1211:\tlearn: 2.6733389\ttotal: 13.3s\tremaining: 37.1s\n",
      "1212:\tlearn: 2.6726308\ttotal: 13.3s\tremaining: 37.1s\n",
      "1213:\tlearn: 2.6715872\ttotal: 13.3s\tremaining: 37.1s\n",
      "1214:\tlearn: 2.6708893\ttotal: 13.3s\tremaining: 37.1s\n",
      "1215:\tlearn: 2.6704298\ttotal: 13.3s\tremaining: 37s\n",
      "1216:\tlearn: 2.6699748\ttotal: 13.3s\tremaining: 37s\n",
      "1217:\tlearn: 2.6693704\ttotal: 13.3s\tremaining: 37s\n",
      "1218:\tlearn: 2.6688722\ttotal: 13.3s\tremaining: 37s\n",
      "1219:\tlearn: 2.6683949\ttotal: 13.4s\tremaining: 37s\n",
      "1220:\tlearn: 2.6680104\ttotal: 13.4s\tremaining: 37s\n",
      "1221:\tlearn: 2.6671732\ttotal: 13.4s\tremaining: 37s\n",
      "1222:\tlearn: 2.6664061\ttotal: 13.4s\tremaining: 37s\n",
      "1223:\tlearn: 2.6657848\ttotal: 13.4s\tremaining: 37s\n",
      "1224:\tlearn: 2.6652909\ttotal: 13.4s\tremaining: 37s\n",
      "1225:\tlearn: 2.6648805\ttotal: 13.4s\tremaining: 37s\n",
      "1226:\tlearn: 2.6648383\ttotal: 13.4s\tremaining: 36.9s\n",
      "1227:\tlearn: 2.6645366\ttotal: 13.5s\tremaining: 36.9s\n",
      "1228:\tlearn: 2.6641399\ttotal: 13.5s\tremaining: 36.9s\n",
      "1229:\tlearn: 2.6633798\ttotal: 13.5s\tremaining: 36.9s\n",
      "1230:\tlearn: 2.6628663\ttotal: 13.5s\tremaining: 36.9s\n",
      "1231:\tlearn: 2.6622257\ttotal: 13.5s\tremaining: 36.9s\n",
      "1232:\tlearn: 2.6615035\ttotal: 13.5s\tremaining: 36.9s\n",
      "1233:\tlearn: 2.6604645\ttotal: 13.5s\tremaining: 36.9s\n",
      "1234:\tlearn: 2.6594664\ttotal: 13.5s\tremaining: 36.9s\n",
      "1235:\tlearn: 2.6585594\ttotal: 13.5s\tremaining: 36.9s\n",
      "1236:\tlearn: 2.6578063\ttotal: 13.6s\tremaining: 36.8s\n",
      "1237:\tlearn: 2.6571493\ttotal: 13.6s\tremaining: 36.8s\n",
      "1238:\tlearn: 2.6568263\ttotal: 13.6s\tremaining: 36.8s\n",
      "1239:\tlearn: 2.6564097\ttotal: 13.6s\tremaining: 36.8s\n",
      "1240:\tlearn: 2.6557770\ttotal: 13.6s\tremaining: 36.8s\n",
      "1241:\tlearn: 2.6551551\ttotal: 13.6s\tremaining: 36.8s\n",
      "1242:\tlearn: 2.6546309\ttotal: 13.6s\tremaining: 36.8s\n",
      "1243:\tlearn: 2.6535270\ttotal: 13.6s\tremaining: 36.8s\n",
      "1244:\tlearn: 2.6527759\ttotal: 13.7s\tremaining: 36.8s\n",
      "1245:\tlearn: 2.6523800\ttotal: 13.7s\tremaining: 36.8s\n",
      "1246:\tlearn: 2.6515028\ttotal: 13.7s\tremaining: 36.8s\n",
      "1247:\tlearn: 2.6510009\ttotal: 13.7s\tremaining: 36.7s\n",
      "1248:\tlearn: 2.6500913\ttotal: 13.7s\tremaining: 36.7s\n",
      "1249:\tlearn: 2.6494290\ttotal: 13.7s\tremaining: 36.7s\n",
      "1250:\tlearn: 2.6487756\ttotal: 13.7s\tremaining: 36.7s\n",
      "1251:\tlearn: 2.6477933\ttotal: 13.7s\tremaining: 36.7s\n",
      "1252:\tlearn: 2.6477565\ttotal: 13.7s\tremaining: 36.7s\n",
      "1253:\tlearn: 2.6474327\ttotal: 13.8s\tremaining: 36.7s\n",
      "1254:\tlearn: 2.6465485\ttotal: 13.8s\tremaining: 36.7s\n",
      "1255:\tlearn: 2.6454375\ttotal: 13.8s\tremaining: 36.6s\n",
      "1256:\tlearn: 2.6449344\ttotal: 13.8s\tremaining: 36.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1257:\tlearn: 2.6442557\ttotal: 13.8s\tremaining: 36.6s\n",
      "1258:\tlearn: 2.6436493\ttotal: 13.8s\tremaining: 36.6s\n",
      "1259:\tlearn: 2.6431936\ttotal: 13.8s\tremaining: 36.6s\n",
      "1260:\tlearn: 2.6423868\ttotal: 13.8s\tremaining: 36.6s\n",
      "1261:\tlearn: 2.6419274\ttotal: 13.8s\tremaining: 36.6s\n",
      "1262:\tlearn: 2.6412667\ttotal: 13.8s\tremaining: 36.6s\n",
      "1263:\tlearn: 2.6406989\ttotal: 13.9s\tremaining: 36.6s\n",
      "1264:\tlearn: 2.6399167\ttotal: 13.9s\tremaining: 36.5s\n",
      "1265:\tlearn: 2.6389336\ttotal: 13.9s\tremaining: 36.5s\n",
      "1266:\tlearn: 2.6389026\ttotal: 13.9s\tremaining: 36.5s\n",
      "1267:\tlearn: 2.6385232\ttotal: 13.9s\tremaining: 36.5s\n",
      "1268:\tlearn: 2.6379726\ttotal: 13.9s\tremaining: 36.5s\n",
      "1269:\tlearn: 2.6368961\ttotal: 13.9s\tremaining: 36.5s\n",
      "1270:\tlearn: 2.6360435\ttotal: 13.9s\tremaining: 36.5s\n",
      "1271:\tlearn: 2.6356990\ttotal: 13.9s\tremaining: 36.5s\n",
      "1272:\tlearn: 2.6351227\ttotal: 13.9s\tremaining: 36.4s\n",
      "1273:\tlearn: 2.6347029\ttotal: 14s\tremaining: 36.4s\n",
      "1274:\tlearn: 2.6343237\ttotal: 14s\tremaining: 36.4s\n",
      "1275:\tlearn: 2.6336424\ttotal: 14s\tremaining: 36.4s\n",
      "1276:\tlearn: 2.6333620\ttotal: 14s\tremaining: 36.4s\n",
      "1277:\tlearn: 2.6326018\ttotal: 14s\tremaining: 36.4s\n",
      "1278:\tlearn: 2.6321791\ttotal: 14s\tremaining: 36.4s\n",
      "1279:\tlearn: 2.6315055\ttotal: 14s\tremaining: 36.4s\n",
      "1280:\tlearn: 2.6311694\ttotal: 14s\tremaining: 36.3s\n",
      "1281:\tlearn: 2.6306547\ttotal: 14s\tremaining: 36.3s\n",
      "1282:\tlearn: 2.6299408\ttotal: 14.1s\tremaining: 36.3s\n",
      "1283:\tlearn: 2.6294139\ttotal: 14.1s\tremaining: 36.3s\n",
      "1284:\tlearn: 2.6285069\ttotal: 14.1s\tremaining: 36.3s\n",
      "1285:\tlearn: 2.6281152\ttotal: 14.1s\tremaining: 36.3s\n",
      "1286:\tlearn: 2.6274204\ttotal: 14.1s\tremaining: 36.3s\n",
      "1287:\tlearn: 2.6268231\ttotal: 14.1s\tremaining: 36.3s\n",
      "1288:\tlearn: 2.6261684\ttotal: 14.1s\tremaining: 36.2s\n",
      "1289:\tlearn: 2.6258445\ttotal: 14.1s\tremaining: 36.2s\n",
      "1290:\tlearn: 2.6250682\ttotal: 14.1s\tremaining: 36.2s\n",
      "1291:\tlearn: 2.6244405\ttotal: 14.2s\tremaining: 36.2s\n",
      "1292:\tlearn: 2.6239129\ttotal: 14.2s\tremaining: 36.2s\n",
      "1293:\tlearn: 2.6237990\ttotal: 14.2s\tremaining: 36.2s\n",
      "1294:\tlearn: 2.6232479\ttotal: 14.2s\tremaining: 36.2s\n",
      "1295:\tlearn: 2.6230302\ttotal: 14.2s\tremaining: 36.2s\n",
      "1296:\tlearn: 2.6226311\ttotal: 14.2s\tremaining: 36.1s\n",
      "1297:\tlearn: 2.6219539\ttotal: 14.2s\tremaining: 36.1s\n",
      "1298:\tlearn: 2.6211678\ttotal: 14.2s\tremaining: 36.1s\n",
      "1299:\tlearn: 2.6201207\ttotal: 14.2s\tremaining: 36.1s\n",
      "1300:\tlearn: 2.6201170\ttotal: 14.2s\tremaining: 36.1s\n",
      "1301:\tlearn: 2.6197121\ttotal: 14.3s\tremaining: 36.1s\n",
      "1302:\tlearn: 2.6190702\ttotal: 14.3s\tremaining: 36.1s\n",
      "1303:\tlearn: 2.6181990\ttotal: 14.3s\tremaining: 36.1s\n",
      "1304:\tlearn: 2.6173353\ttotal: 14.3s\tremaining: 36.1s\n",
      "1305:\tlearn: 2.6162649\ttotal: 14.3s\tremaining: 36s\n",
      "1306:\tlearn: 2.6153907\ttotal: 14.3s\tremaining: 36s\n",
      "1307:\tlearn: 2.6147083\ttotal: 14.3s\tremaining: 36s\n",
      "1308:\tlearn: 2.6142531\ttotal: 14.3s\tremaining: 36s\n",
      "1309:\tlearn: 2.6138409\ttotal: 14.3s\tremaining: 36s\n",
      "1310:\tlearn: 2.6134937\ttotal: 14.4s\tremaining: 36s\n",
      "1311:\tlearn: 2.6130486\ttotal: 14.4s\tremaining: 36s\n",
      "1312:\tlearn: 2.6119467\ttotal: 14.4s\tremaining: 36s\n",
      "1313:\tlearn: 2.6112471\ttotal: 14.4s\tremaining: 36s\n",
      "1314:\tlearn: 2.6103869\ttotal: 14.4s\tremaining: 35.9s\n",
      "1315:\tlearn: 2.6095160\ttotal: 14.4s\tremaining: 35.9s\n",
      "1316:\tlearn: 2.6090228\ttotal: 14.4s\tremaining: 35.9s\n",
      "1317:\tlearn: 2.6086392\ttotal: 14.4s\tremaining: 35.9s\n",
      "1318:\tlearn: 2.6082749\ttotal: 14.4s\tremaining: 35.9s\n",
      "1319:\tlearn: 2.6079665\ttotal: 14.4s\tremaining: 35.9s\n",
      "1320:\tlearn: 2.6074153\ttotal: 14.5s\tremaining: 35.9s\n",
      "1321:\tlearn: 2.6063799\ttotal: 14.5s\tremaining: 35.9s\n",
      "1322:\tlearn: 2.6054739\ttotal: 14.5s\tremaining: 35.9s\n",
      "1323:\tlearn: 2.6047951\ttotal: 14.5s\tremaining: 35.8s\n",
      "1324:\tlearn: 2.6043244\ttotal: 14.5s\tremaining: 35.8s\n",
      "1325:\tlearn: 2.6037696\ttotal: 14.5s\tremaining: 35.8s\n",
      "1326:\tlearn: 2.6030587\ttotal: 14.5s\tremaining: 35.8s\n",
      "1327:\tlearn: 2.6021512\ttotal: 14.5s\tremaining: 35.8s\n",
      "1328:\tlearn: 2.6013197\ttotal: 14.5s\tremaining: 35.8s\n",
      "1329:\tlearn: 2.6008404\ttotal: 14.6s\tremaining: 35.8s\n",
      "1330:\tlearn: 2.6004346\ttotal: 14.6s\tremaining: 35.8s\n",
      "1331:\tlearn: 2.5994539\ttotal: 14.6s\tremaining: 35.8s\n",
      "1332:\tlearn: 2.5987454\ttotal: 14.6s\tremaining: 35.7s\n",
      "1333:\tlearn: 2.5979247\ttotal: 14.6s\tremaining: 35.7s\n",
      "1334:\tlearn: 2.5972966\ttotal: 14.6s\tremaining: 35.7s\n",
      "1335:\tlearn: 2.5970536\ttotal: 14.6s\tremaining: 35.7s\n",
      "1336:\tlearn: 2.5962004\ttotal: 14.6s\tremaining: 35.7s\n",
      "1337:\tlearn: 2.5955928\ttotal: 14.7s\tremaining: 35.7s\n",
      "1338:\tlearn: 2.5950078\ttotal: 14.7s\tremaining: 35.7s\n",
      "1339:\tlearn: 2.5941582\ttotal: 14.7s\tremaining: 35.7s\n",
      "1340:\tlearn: 2.5934265\ttotal: 14.7s\tremaining: 35.7s\n",
      "1341:\tlearn: 2.5933860\ttotal: 14.7s\tremaining: 35.6s\n",
      "1342:\tlearn: 2.5924543\ttotal: 14.7s\tremaining: 35.6s\n",
      "1343:\tlearn: 2.5915799\ttotal: 14.7s\tremaining: 35.6s\n",
      "1344:\tlearn: 2.5908176\ttotal: 14.7s\tremaining: 35.6s\n",
      "1345:\tlearn: 2.5900895\ttotal: 14.7s\tremaining: 35.6s\n",
      "1346:\tlearn: 2.5895787\ttotal: 14.7s\tremaining: 35.6s\n",
      "1347:\tlearn: 2.5892446\ttotal: 14.8s\tremaining: 35.6s\n",
      "1348:\tlearn: 2.5886724\ttotal: 14.8s\tremaining: 35.6s\n",
      "1349:\tlearn: 2.5880738\ttotal: 14.8s\tremaining: 35.6s\n",
      "1350:\tlearn: 2.5874653\ttotal: 14.8s\tremaining: 35.5s\n",
      "1351:\tlearn: 2.5869760\ttotal: 14.8s\tremaining: 35.5s\n",
      "1352:\tlearn: 2.5859611\ttotal: 14.8s\tremaining: 35.5s\n",
      "1353:\tlearn: 2.5851950\ttotal: 14.8s\tremaining: 35.5s\n",
      "1354:\tlearn: 2.5848475\ttotal: 14.8s\tremaining: 35.5s\n",
      "1355:\tlearn: 2.5841604\ttotal: 14.8s\tremaining: 35.5s\n",
      "1356:\tlearn: 2.5837035\ttotal: 14.9s\tremaining: 35.5s\n",
      "1357:\tlearn: 2.5832334\ttotal: 14.9s\tremaining: 35.5s\n",
      "1358:\tlearn: 2.5827528\ttotal: 14.9s\tremaining: 35.5s\n",
      "1359:\tlearn: 2.5820779\ttotal: 14.9s\tremaining: 35.5s\n",
      "1360:\tlearn: 2.5814771\ttotal: 14.9s\tremaining: 35.4s\n",
      "1361:\tlearn: 2.5808608\ttotal: 14.9s\tremaining: 35.4s\n",
      "1362:\tlearn: 2.5804959\ttotal: 14.9s\tremaining: 35.4s\n",
      "1363:\tlearn: 2.5799287\ttotal: 14.9s\tremaining: 35.4s\n",
      "1364:\tlearn: 2.5794908\ttotal: 14.9s\tremaining: 35.4s\n",
      "1365:\tlearn: 2.5789799\ttotal: 15s\tremaining: 35.4s\n",
      "1366:\tlearn: 2.5784723\ttotal: 15s\tremaining: 35.4s\n",
      "1367:\tlearn: 2.5774529\ttotal: 15s\tremaining: 35.4s\n",
      "1368:\tlearn: 2.5764191\ttotal: 15s\tremaining: 35.4s\n",
      "1369:\tlearn: 2.5759072\ttotal: 15s\tremaining: 35.3s\n",
      "1370:\tlearn: 2.5754098\ttotal: 15s\tremaining: 35.3s\n",
      "1371:\tlearn: 2.5747568\ttotal: 15s\tremaining: 35.3s\n",
      "1372:\tlearn: 2.5739600\ttotal: 15s\tremaining: 35.3s\n",
      "1373:\tlearn: 2.5730265\ttotal: 15s\tremaining: 35.3s\n",
      "1374:\tlearn: 2.5725326\ttotal: 15.1s\tremaining: 35.3s\n",
      "1375:\tlearn: 2.5720663\ttotal: 15.1s\tremaining: 35.3s\n",
      "1376:\tlearn: 2.5715358\ttotal: 15.1s\tremaining: 35.3s\n",
      "1377:\tlearn: 2.5709412\ttotal: 15.1s\tremaining: 35.3s\n",
      "1378:\tlearn: 2.5700118\ttotal: 15.1s\tremaining: 35.2s\n",
      "1379:\tlearn: 2.5692089\ttotal: 15.1s\tremaining: 35.2s\n",
      "1380:\tlearn: 2.5686661\ttotal: 15.1s\tremaining: 35.2s\n",
      "1381:\tlearn: 2.5680209\ttotal: 15.1s\tremaining: 35.2s\n",
      "1382:\tlearn: 2.5675412\ttotal: 15.1s\tremaining: 35.2s\n",
      "1383:\tlearn: 2.5665834\ttotal: 15.2s\tremaining: 35.2s\n",
      "1384:\tlearn: 2.5659338\ttotal: 15.2s\tremaining: 35.2s\n",
      "1385:\tlearn: 2.5649585\ttotal: 15.2s\tremaining: 35.2s\n",
      "1386:\tlearn: 2.5644316\ttotal: 15.2s\tremaining: 35.2s\n",
      "1387:\tlearn: 2.5637423\ttotal: 15.2s\tremaining: 35.1s\n",
      "1388:\tlearn: 2.5631362\ttotal: 15.2s\tremaining: 35.1s\n",
      "1389:\tlearn: 2.5627426\ttotal: 15.2s\tremaining: 35.1s\n",
      "1390:\tlearn: 2.5622096\ttotal: 15.2s\tremaining: 35.1s\n",
      "1391:\tlearn: 2.5618751\ttotal: 15.2s\tremaining: 35.1s\n",
      "1392:\tlearn: 2.5614342\ttotal: 15.2s\tremaining: 35.1s\n",
      "1393:\tlearn: 2.5607134\ttotal: 15.3s\tremaining: 35.1s\n",
      "1394:\tlearn: 2.5601718\ttotal: 15.3s\tremaining: 35.1s\n",
      "1395:\tlearn: 2.5591877\ttotal: 15.3s\tremaining: 35.1s\n",
      "1396:\tlearn: 2.5588709\ttotal: 15.3s\tremaining: 35s\n",
      "1397:\tlearn: 2.5582249\ttotal: 15.3s\tremaining: 35s\n",
      "1398:\tlearn: 2.5579635\ttotal: 15.3s\tremaining: 35s\n",
      "1399:\tlearn: 2.5571096\ttotal: 15.3s\tremaining: 35s\n",
      "1400:\tlearn: 2.5563111\ttotal: 15.3s\tremaining: 35s\n",
      "1401:\tlearn: 2.5558384\ttotal: 15.3s\tremaining: 35s\n",
      "1402:\tlearn: 2.5554514\ttotal: 15.4s\tremaining: 35s\n",
      "1403:\tlearn: 2.5546603\ttotal: 15.4s\tremaining: 35s\n",
      "1404:\tlearn: 2.5543594\ttotal: 15.4s\tremaining: 35s\n",
      "1405:\tlearn: 2.5539585\ttotal: 15.4s\tremaining: 34.9s\n",
      "1406:\tlearn: 2.5536998\ttotal: 15.4s\tremaining: 34.9s\n",
      "1407:\tlearn: 2.5529701\ttotal: 15.4s\tremaining: 34.9s\n",
      "1408:\tlearn: 2.5524140\ttotal: 15.4s\tremaining: 34.9s\n",
      "1409:\tlearn: 2.5514326\ttotal: 15.4s\tremaining: 34.9s\n",
      "1410:\tlearn: 2.5511922\ttotal: 15.4s\tremaining: 34.9s\n",
      "1411:\tlearn: 2.5506765\ttotal: 15.5s\tremaining: 34.9s\n",
      "1412:\tlearn: 2.5502312\ttotal: 15.5s\tremaining: 34.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1413:\tlearn: 2.5497503\ttotal: 15.5s\tremaining: 34.8s\n",
      "1414:\tlearn: 2.5493262\ttotal: 15.5s\tremaining: 34.8s\n",
      "1415:\tlearn: 2.5487940\ttotal: 15.5s\tremaining: 34.8s\n",
      "1416:\tlearn: 2.5484807\ttotal: 15.5s\tremaining: 34.8s\n",
      "1417:\tlearn: 2.5478933\ttotal: 15.5s\tremaining: 34.8s\n",
      "1418:\tlearn: 2.5475669\ttotal: 15.5s\tremaining: 34.8s\n",
      "1419:\tlearn: 2.5467746\ttotal: 15.5s\tremaining: 34.8s\n",
      "1420:\tlearn: 2.5461504\ttotal: 15.6s\tremaining: 34.8s\n",
      "1421:\tlearn: 2.5456591\ttotal: 15.6s\tremaining: 34.8s\n",
      "1422:\tlearn: 2.5453944\ttotal: 15.6s\tremaining: 34.7s\n",
      "1423:\tlearn: 2.5449182\ttotal: 15.6s\tremaining: 34.7s\n",
      "1424:\tlearn: 2.5446622\ttotal: 15.6s\tremaining: 34.7s\n",
      "1425:\tlearn: 2.5441775\ttotal: 15.6s\tremaining: 34.7s\n",
      "1426:\tlearn: 2.5436360\ttotal: 15.6s\tremaining: 34.7s\n",
      "1427:\tlearn: 2.5436044\ttotal: 15.6s\tremaining: 34.7s\n",
      "1428:\tlearn: 2.5431199\ttotal: 15.6s\tremaining: 34.7s\n",
      "1429:\tlearn: 2.5424820\ttotal: 15.6s\tremaining: 34.7s\n",
      "1430:\tlearn: 2.5420349\ttotal: 15.7s\tremaining: 34.6s\n",
      "1431:\tlearn: 2.5418111\ttotal: 15.7s\tremaining: 34.6s\n",
      "1432:\tlearn: 2.5413451\ttotal: 15.7s\tremaining: 34.6s\n",
      "1433:\tlearn: 2.5410416\ttotal: 15.7s\tremaining: 34.6s\n",
      "1434:\tlearn: 2.5407817\ttotal: 15.7s\tremaining: 34.6s\n",
      "1435:\tlearn: 2.5398360\ttotal: 15.7s\tremaining: 34.6s\n",
      "1436:\tlearn: 2.5393911\ttotal: 15.7s\tremaining: 34.6s\n",
      "1437:\tlearn: 2.5389533\ttotal: 15.7s\tremaining: 34.6s\n",
      "1438:\tlearn: 2.5383850\ttotal: 15.7s\tremaining: 34.6s\n",
      "1439:\tlearn: 2.5381051\ttotal: 15.8s\tremaining: 34.5s\n",
      "1440:\tlearn: 2.5373900\ttotal: 15.8s\tremaining: 34.5s\n",
      "1441:\tlearn: 2.5366694\ttotal: 15.8s\tremaining: 34.5s\n",
      "1442:\tlearn: 2.5361509\ttotal: 15.8s\tremaining: 34.5s\n",
      "1443:\tlearn: 2.5353530\ttotal: 15.8s\tremaining: 34.5s\n",
      "1444:\tlearn: 2.5347605\ttotal: 15.8s\tremaining: 34.5s\n",
      "1445:\tlearn: 2.5339914\ttotal: 15.8s\tremaining: 34.5s\n",
      "1446:\tlearn: 2.5333862\ttotal: 15.8s\tremaining: 34.5s\n",
      "1447:\tlearn: 2.5327893\ttotal: 15.8s\tremaining: 34.5s\n",
      "1448:\tlearn: 2.5321952\ttotal: 15.8s\tremaining: 34.4s\n",
      "1449:\tlearn: 2.5319920\ttotal: 15.9s\tremaining: 34.4s\n",
      "1450:\tlearn: 2.5313534\ttotal: 15.9s\tremaining: 34.4s\n",
      "1451:\tlearn: 2.5305598\ttotal: 15.9s\tremaining: 34.4s\n",
      "1452:\tlearn: 2.5299462\ttotal: 15.9s\tremaining: 34.4s\n",
      "1453:\tlearn: 2.5294659\ttotal: 15.9s\tremaining: 34.4s\n",
      "1454:\tlearn: 2.5289650\ttotal: 15.9s\tremaining: 34.4s\n",
      "1455:\tlearn: 2.5283391\ttotal: 15.9s\tremaining: 34.4s\n",
      "1456:\tlearn: 2.5278663\ttotal: 15.9s\tremaining: 34.4s\n",
      "1457:\tlearn: 2.5272018\ttotal: 15.9s\tremaining: 34.3s\n",
      "1458:\tlearn: 2.5264753\ttotal: 16s\tremaining: 34.3s\n",
      "1459:\tlearn: 2.5261831\ttotal: 16s\tremaining: 34.3s\n",
      "1460:\tlearn: 2.5256495\ttotal: 16s\tremaining: 34.3s\n",
      "1461:\tlearn: 2.5250471\ttotal: 16s\tremaining: 34.3s\n",
      "1462:\tlearn: 2.5246849\ttotal: 16s\tremaining: 34.3s\n",
      "1463:\tlearn: 2.5243658\ttotal: 16s\tremaining: 34.3s\n",
      "1464:\tlearn: 2.5233435\ttotal: 16s\tremaining: 34.3s\n",
      "1465:\tlearn: 2.5227876\ttotal: 16s\tremaining: 34.3s\n",
      "1466:\tlearn: 2.5221196\ttotal: 16s\tremaining: 34.2s\n",
      "1467:\tlearn: 2.5212447\ttotal: 16.1s\tremaining: 34.2s\n",
      "1468:\tlearn: 2.5209030\ttotal: 16.1s\tremaining: 34.2s\n",
      "1469:\tlearn: 2.5202866\ttotal: 16.1s\tremaining: 34.2s\n",
      "1470:\tlearn: 2.5198871\ttotal: 16.1s\tremaining: 34.2s\n",
      "1471:\tlearn: 2.5192442\ttotal: 16.1s\tremaining: 34.2s\n",
      "1472:\tlearn: 2.5187387\ttotal: 16.1s\tremaining: 34.2s\n",
      "1473:\tlearn: 2.5181166\ttotal: 16.1s\tremaining: 34.2s\n",
      "1474:\tlearn: 2.5177012\ttotal: 16.1s\tremaining: 34.2s\n",
      "1475:\tlearn: 2.5171407\ttotal: 16.1s\tremaining: 34.1s\n",
      "1476:\tlearn: 2.5165125\ttotal: 16.2s\tremaining: 34.1s\n",
      "1477:\tlearn: 2.5158598\ttotal: 16.2s\tremaining: 34.1s\n",
      "1478:\tlearn: 2.5156799\ttotal: 16.2s\tremaining: 34.1s\n",
      "1479:\tlearn: 2.5153758\ttotal: 16.2s\tremaining: 34.1s\n",
      "1480:\tlearn: 2.5145593\ttotal: 16.2s\tremaining: 34.1s\n",
      "1481:\tlearn: 2.5140271\ttotal: 16.2s\tremaining: 34.1s\n",
      "1482:\tlearn: 2.5139952\ttotal: 16.2s\tremaining: 34.1s\n",
      "1483:\tlearn: 2.5133587\ttotal: 16.2s\tremaining: 34s\n",
      "1484:\tlearn: 2.5125324\ttotal: 16.2s\tremaining: 34s\n",
      "1485:\tlearn: 2.5122180\ttotal: 16.2s\tremaining: 34s\n",
      "1486:\tlearn: 2.5116272\ttotal: 16.3s\tremaining: 34s\n",
      "1487:\tlearn: 2.5113545\ttotal: 16.3s\tremaining: 34s\n",
      "1488:\tlearn: 2.5104293\ttotal: 16.3s\tremaining: 34s\n",
      "1489:\tlearn: 2.5100635\ttotal: 16.3s\tremaining: 34s\n",
      "1490:\tlearn: 2.5097673\ttotal: 16.3s\tremaining: 34s\n",
      "1491:\tlearn: 2.5094883\ttotal: 16.3s\tremaining: 34s\n",
      "1492:\tlearn: 2.5088054\ttotal: 16.3s\tremaining: 34s\n",
      "1493:\tlearn: 2.5084161\ttotal: 16.3s\tremaining: 33.9s\n",
      "1494:\tlearn: 2.5077585\ttotal: 16.3s\tremaining: 33.9s\n",
      "1495:\tlearn: 2.5071924\ttotal: 16.4s\tremaining: 33.9s\n",
      "1496:\tlearn: 2.5069194\ttotal: 16.4s\tremaining: 33.9s\n",
      "1497:\tlearn: 2.5057137\ttotal: 16.4s\tremaining: 33.9s\n",
      "1498:\tlearn: 2.5050148\ttotal: 16.4s\tremaining: 33.9s\n",
      "1499:\tlearn: 2.5034278\ttotal: 16.4s\tremaining: 33.9s\n",
      "1500:\tlearn: 2.5028773\ttotal: 16.4s\tremaining: 33.9s\n",
      "1501:\tlearn: 2.5024014\ttotal: 16.4s\tremaining: 33.9s\n",
      "1502:\tlearn: 2.5016750\ttotal: 16.4s\tremaining: 33.8s\n",
      "1503:\tlearn: 2.5015726\ttotal: 16.4s\tremaining: 33.8s\n",
      "1504:\tlearn: 2.5010952\ttotal: 16.5s\tremaining: 33.8s\n",
      "1505:\tlearn: 2.5005902\ttotal: 16.5s\tremaining: 33.8s\n",
      "1506:\tlearn: 2.5002737\ttotal: 16.5s\tremaining: 33.8s\n",
      "1507:\tlearn: 2.5002083\ttotal: 16.5s\tremaining: 33.8s\n",
      "1508:\tlearn: 2.4993324\ttotal: 16.5s\tremaining: 33.8s\n",
      "1509:\tlearn: 2.4991269\ttotal: 16.5s\tremaining: 33.8s\n",
      "1510:\tlearn: 2.4985970\ttotal: 16.5s\tremaining: 33.7s\n",
      "1511:\tlearn: 2.4979606\ttotal: 16.5s\tremaining: 33.7s\n",
      "1512:\tlearn: 2.4974293\ttotal: 16.5s\tremaining: 33.7s\n",
      "1513:\tlearn: 2.4969866\ttotal: 16.6s\tremaining: 33.7s\n",
      "1514:\tlearn: 2.4963424\ttotal: 16.6s\tremaining: 33.7s\n",
      "1515:\tlearn: 2.4956939\ttotal: 16.6s\tremaining: 33.7s\n",
      "1516:\tlearn: 2.4949455\ttotal: 16.6s\tremaining: 33.7s\n",
      "1517:\tlearn: 2.4943953\ttotal: 16.6s\tremaining: 33.7s\n",
      "1518:\tlearn: 2.4938800\ttotal: 16.6s\tremaining: 33.7s\n",
      "1519:\tlearn: 2.4934009\ttotal: 16.6s\tremaining: 33.7s\n",
      "1520:\tlearn: 2.4928596\ttotal: 16.6s\tremaining: 33.6s\n",
      "1521:\tlearn: 2.4922504\ttotal: 16.6s\tremaining: 33.6s\n",
      "1522:\tlearn: 2.4917751\ttotal: 16.7s\tremaining: 33.6s\n",
      "1523:\tlearn: 2.4913163\ttotal: 16.7s\tremaining: 33.6s\n",
      "1524:\tlearn: 2.4905931\ttotal: 16.7s\tremaining: 33.6s\n",
      "1525:\tlearn: 2.4899810\ttotal: 16.7s\tremaining: 33.6s\n",
      "1526:\tlearn: 2.4893654\ttotal: 16.7s\tremaining: 33.6s\n",
      "1527:\tlearn: 2.4883721\ttotal: 16.7s\tremaining: 33.6s\n",
      "1528:\tlearn: 2.4879152\ttotal: 16.7s\tremaining: 33.6s\n",
      "1529:\tlearn: 2.4875351\ttotal: 16.7s\tremaining: 33.5s\n",
      "1530:\tlearn: 2.4867334\ttotal: 16.7s\tremaining: 33.5s\n",
      "1531:\tlearn: 2.4863971\ttotal: 16.8s\tremaining: 33.5s\n",
      "1532:\tlearn: 2.4855728\ttotal: 16.8s\tremaining: 33.5s\n",
      "1533:\tlearn: 2.4851411\ttotal: 16.8s\tremaining: 33.5s\n",
      "1534:\tlearn: 2.4844698\ttotal: 16.8s\tremaining: 33.5s\n",
      "1535:\tlearn: 2.4837721\ttotal: 16.8s\tremaining: 33.5s\n",
      "1536:\tlearn: 2.4832626\ttotal: 16.8s\tremaining: 33.5s\n",
      "1537:\tlearn: 2.4828786\ttotal: 16.8s\tremaining: 33.5s\n",
      "1538:\tlearn: 2.4824748\ttotal: 16.8s\tremaining: 33.5s\n",
      "1539:\tlearn: 2.4819288\ttotal: 16.8s\tremaining: 33.4s\n",
      "1540:\tlearn: 2.4814495\ttotal: 16.9s\tremaining: 33.4s\n",
      "1541:\tlearn: 2.4808000\ttotal: 16.9s\tremaining: 33.4s\n",
      "1542:\tlearn: 2.4801355\ttotal: 16.9s\tremaining: 33.4s\n",
      "1543:\tlearn: 2.4794106\ttotal: 16.9s\tremaining: 33.4s\n",
      "1544:\tlearn: 2.4788908\ttotal: 16.9s\tremaining: 33.4s\n",
      "1545:\tlearn: 2.4783024\ttotal: 16.9s\tremaining: 33.4s\n",
      "1546:\tlearn: 2.4777036\ttotal: 16.9s\tremaining: 33.4s\n",
      "1547:\tlearn: 2.4773762\ttotal: 16.9s\tremaining: 33.4s\n",
      "1548:\tlearn: 2.4770009\ttotal: 16.9s\tremaining: 33.4s\n",
      "1549:\tlearn: 2.4765792\ttotal: 17s\tremaining: 33.3s\n",
      "1550:\tlearn: 2.4759316\ttotal: 17s\tremaining: 33.3s\n",
      "1551:\tlearn: 2.4756442\ttotal: 17s\tremaining: 33.3s\n",
      "1552:\tlearn: 2.4749655\ttotal: 17s\tremaining: 33.3s\n",
      "1553:\tlearn: 2.4747923\ttotal: 17s\tremaining: 33.3s\n",
      "1554:\tlearn: 2.4740877\ttotal: 17s\tremaining: 33.3s\n",
      "1555:\tlearn: 2.4737705\ttotal: 17s\tremaining: 33.3s\n",
      "1556:\tlearn: 2.4734345\ttotal: 17s\tremaining: 33.3s\n",
      "1557:\tlearn: 2.4730435\ttotal: 17s\tremaining: 33.3s\n",
      "1558:\tlearn: 2.4726787\ttotal: 17.1s\tremaining: 33.2s\n",
      "1559:\tlearn: 2.4724499\ttotal: 17.1s\tremaining: 33.2s\n",
      "1560:\tlearn: 2.4718972\ttotal: 17.1s\tremaining: 33.2s\n",
      "1561:\tlearn: 2.4714798\ttotal: 17.1s\tremaining: 33.2s\n",
      "1562:\tlearn: 2.4709896\ttotal: 17.1s\tremaining: 33.2s\n",
      "1563:\tlearn: 2.4706678\ttotal: 17.1s\tremaining: 33.2s\n",
      "1564:\tlearn: 2.4700228\ttotal: 17.1s\tremaining: 33.2s\n",
      "1565:\tlearn: 2.4692830\ttotal: 17.1s\tremaining: 33.2s\n",
      "1566:\tlearn: 2.4689800\ttotal: 17.1s\tremaining: 33.1s\n",
      "1567:\tlearn: 2.4683380\ttotal: 17.1s\tremaining: 33.1s\n",
      "1568:\tlearn: 2.4678675\ttotal: 17.2s\tremaining: 33.1s\n",
      "1569:\tlearn: 2.4668722\ttotal: 17.2s\tremaining: 33.1s\n",
      "1570:\tlearn: 2.4664403\ttotal: 17.2s\tremaining: 33.1s\n",
      "1571:\tlearn: 2.4657500\ttotal: 17.2s\tremaining: 33.1s\n",
      "1572:\tlearn: 2.4654478\ttotal: 17.2s\tremaining: 33.1s\n",
      "1573:\tlearn: 2.4648506\ttotal: 17.2s\tremaining: 33.1s\n",
      "1574:\tlearn: 2.4641617\ttotal: 17.2s\tremaining: 33.1s\n",
      "1575:\tlearn: 2.4634912\ttotal: 17.2s\tremaining: 33s\n",
      "1576:\tlearn: 2.4629971\ttotal: 17.2s\tremaining: 33s\n",
      "1577:\tlearn: 2.4627982\ttotal: 17.3s\tremaining: 33s\n",
      "1578:\tlearn: 2.4622295\ttotal: 17.3s\tremaining: 33s\n",
      "1579:\tlearn: 2.4616913\ttotal: 17.3s\tremaining: 33s\n",
      "1580:\tlearn: 2.4611933\ttotal: 17.3s\tremaining: 33s\n",
      "1581:\tlearn: 2.4605825\ttotal: 17.3s\tremaining: 33s\n",
      "1582:\tlearn: 2.4603981\ttotal: 17.3s\tremaining: 33s\n",
      "1583:\tlearn: 2.4598157\ttotal: 17.3s\tremaining: 33s\n",
      "1584:\tlearn: 2.4593717\ttotal: 17.3s\tremaining: 33s\n",
      "1585:\tlearn: 2.4588081\ttotal: 17.3s\tremaining: 32.9s\n",
      "1586:\tlearn: 2.4585236\ttotal: 17.4s\tremaining: 32.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1587:\tlearn: 2.4578168\ttotal: 17.4s\tremaining: 32.9s\n",
      "1588:\tlearn: 2.4568258\ttotal: 17.4s\tremaining: 32.9s\n",
      "1589:\tlearn: 2.4563573\ttotal: 17.4s\tremaining: 32.9s\n",
      "1590:\tlearn: 2.4560676\ttotal: 17.4s\tremaining: 32.9s\n",
      "1591:\tlearn: 2.4555553\ttotal: 17.4s\tremaining: 32.9s\n",
      "1592:\tlearn: 2.4549809\ttotal: 17.4s\tremaining: 32.9s\n",
      "1593:\tlearn: 2.4542460\ttotal: 17.4s\tremaining: 32.9s\n",
      "1594:\tlearn: 2.4538888\ttotal: 17.4s\tremaining: 32.8s\n",
      "1595:\tlearn: 2.4532381\ttotal: 17.5s\tremaining: 32.8s\n",
      "1596:\tlearn: 2.4522961\ttotal: 17.5s\tremaining: 32.8s\n",
      "1597:\tlearn: 2.4519232\ttotal: 17.5s\tremaining: 32.8s\n",
      "1598:\tlearn: 2.4512437\ttotal: 17.5s\tremaining: 32.8s\n",
      "1599:\tlearn: 2.4509426\ttotal: 17.5s\tremaining: 32.8s\n",
      "1600:\tlearn: 2.4502863\ttotal: 17.5s\tremaining: 32.8s\n",
      "1601:\tlearn: 2.4495550\ttotal: 17.5s\tremaining: 32.8s\n",
      "1602:\tlearn: 2.4487876\ttotal: 17.5s\tremaining: 32.8s\n",
      "1603:\tlearn: 2.4484914\ttotal: 17.5s\tremaining: 32.7s\n",
      "1604:\tlearn: 2.4478776\ttotal: 17.6s\tremaining: 32.7s\n",
      "1605:\tlearn: 2.4471505\ttotal: 17.6s\tremaining: 32.7s\n",
      "1606:\tlearn: 2.4464124\ttotal: 17.6s\tremaining: 32.7s\n",
      "1607:\tlearn: 2.4461721\ttotal: 17.6s\tremaining: 32.7s\n",
      "1608:\tlearn: 2.4458076\ttotal: 17.6s\tremaining: 32.7s\n",
      "1609:\tlearn: 2.4453943\ttotal: 17.6s\tremaining: 32.7s\n",
      "1610:\tlearn: 2.4450950\ttotal: 17.6s\tremaining: 32.7s\n",
      "1611:\tlearn: 2.4445748\ttotal: 17.6s\tremaining: 32.7s\n",
      "1612:\tlearn: 2.4438828\ttotal: 17.6s\tremaining: 32.7s\n",
      "1613:\tlearn: 2.4430519\ttotal: 17.7s\tremaining: 32.6s\n",
      "1614:\tlearn: 2.4424889\ttotal: 17.7s\tremaining: 32.6s\n",
      "1615:\tlearn: 2.4419824\ttotal: 17.7s\tremaining: 32.6s\n",
      "1616:\tlearn: 2.4413525\ttotal: 17.7s\tremaining: 32.6s\n",
      "1617:\tlearn: 2.4409029\ttotal: 17.7s\tremaining: 32.6s\n",
      "1618:\tlearn: 2.4403826\ttotal: 17.7s\tremaining: 32.6s\n",
      "1619:\tlearn: 2.4400600\ttotal: 17.7s\tremaining: 32.6s\n",
      "1620:\tlearn: 2.4389830\ttotal: 17.7s\tremaining: 32.6s\n",
      "1621:\tlearn: 2.4383792\ttotal: 17.7s\tremaining: 32.6s\n",
      "1622:\tlearn: 2.4377737\ttotal: 17.8s\tremaining: 32.5s\n",
      "1623:\tlearn: 2.4373631\ttotal: 17.8s\tremaining: 32.5s\n",
      "1624:\tlearn: 2.4368933\ttotal: 17.8s\tremaining: 32.5s\n",
      "1625:\tlearn: 2.4363660\ttotal: 17.8s\tremaining: 32.5s\n",
      "1626:\tlearn: 2.4357685\ttotal: 17.8s\tremaining: 32.5s\n",
      "1627:\tlearn: 2.4351782\ttotal: 17.8s\tremaining: 32.5s\n",
      "1628:\tlearn: 2.4345143\ttotal: 17.8s\tremaining: 32.5s\n",
      "1629:\tlearn: 2.4339935\ttotal: 17.8s\tremaining: 32.5s\n",
      "1630:\tlearn: 2.4334998\ttotal: 17.8s\tremaining: 32.5s\n",
      "1631:\tlearn: 2.4329857\ttotal: 17.9s\tremaining: 32.4s\n",
      "1632:\tlearn: 2.4321849\ttotal: 17.9s\tremaining: 32.4s\n",
      "1633:\tlearn: 2.4315240\ttotal: 17.9s\tremaining: 32.4s\n",
      "1634:\tlearn: 2.4308115\ttotal: 17.9s\tremaining: 32.4s\n",
      "1635:\tlearn: 2.4301974\ttotal: 17.9s\tremaining: 32.4s\n",
      "1636:\tlearn: 2.4296637\ttotal: 17.9s\tremaining: 32.4s\n",
      "1637:\tlearn: 2.4285448\ttotal: 17.9s\tremaining: 32.4s\n",
      "1638:\tlearn: 2.4282797\ttotal: 17.9s\tremaining: 32.4s\n",
      "1639:\tlearn: 2.4279138\ttotal: 17.9s\tremaining: 32.4s\n",
      "1640:\tlearn: 2.4274012\ttotal: 18s\tremaining: 32.3s\n",
      "1641:\tlearn: 2.4271204\ttotal: 18s\tremaining: 32.3s\n",
      "1642:\tlearn: 2.4266827\ttotal: 18s\tremaining: 32.3s\n",
      "1643:\tlearn: 2.4259797\ttotal: 18s\tremaining: 32.3s\n",
      "1644:\tlearn: 2.4255328\ttotal: 18s\tremaining: 32.3s\n",
      "1645:\tlearn: 2.4250111\ttotal: 18s\tremaining: 32.3s\n",
      "1646:\tlearn: 2.4240737\ttotal: 18s\tremaining: 32.3s\n",
      "1647:\tlearn: 2.4234576\ttotal: 18s\tremaining: 32.3s\n",
      "1648:\tlearn: 2.4230227\ttotal: 18s\tremaining: 32.3s\n",
      "1649:\tlearn: 2.4226786\ttotal: 18s\tremaining: 32.2s\n",
      "1650:\tlearn: 2.4220360\ttotal: 18.1s\tremaining: 32.2s\n",
      "1651:\tlearn: 2.4216196\ttotal: 18.1s\tremaining: 32.2s\n",
      "1652:\tlearn: 2.4211750\ttotal: 18.1s\tremaining: 32.2s\n",
      "1653:\tlearn: 2.4208311\ttotal: 18.1s\tremaining: 32.2s\n",
      "1654:\tlearn: 2.4203738\ttotal: 18.1s\tremaining: 32.2s\n",
      "1655:\tlearn: 2.4200047\ttotal: 18.1s\tremaining: 32.2s\n",
      "1656:\tlearn: 2.4194950\ttotal: 18.1s\tremaining: 32.2s\n",
      "1657:\tlearn: 2.4190659\ttotal: 18.1s\tremaining: 32.2s\n",
      "1658:\tlearn: 2.4185128\ttotal: 18.1s\tremaining: 32.1s\n",
      "1659:\tlearn: 2.4180412\ttotal: 18.2s\tremaining: 32.1s\n",
      "1660:\tlearn: 2.4174313\ttotal: 18.2s\tremaining: 32.1s\n",
      "1661:\tlearn: 2.4166253\ttotal: 18.2s\tremaining: 32.1s\n",
      "1662:\tlearn: 2.4159006\ttotal: 18.2s\tremaining: 32.1s\n",
      "1663:\tlearn: 2.4154075\ttotal: 18.2s\tremaining: 32.1s\n",
      "1664:\tlearn: 2.4150834\ttotal: 18.2s\tremaining: 32.1s\n",
      "1665:\tlearn: 2.4146383\ttotal: 18.2s\tremaining: 32.1s\n",
      "1666:\tlearn: 2.4139790\ttotal: 18.2s\tremaining: 32.1s\n",
      "1667:\tlearn: 2.4134547\ttotal: 18.2s\tremaining: 32.1s\n",
      "1668:\tlearn: 2.4128083\ttotal: 18.3s\tremaining: 32s\n",
      "1669:\tlearn: 2.4121602\ttotal: 18.3s\tremaining: 32s\n",
      "1670:\tlearn: 2.4117367\ttotal: 18.3s\tremaining: 32s\n",
      "1671:\tlearn: 2.4113479\ttotal: 18.3s\tremaining: 32s\n",
      "1672:\tlearn: 2.4111786\ttotal: 18.3s\tremaining: 32s\n",
      "1673:\tlearn: 2.4108653\ttotal: 18.3s\tremaining: 32s\n",
      "1674:\tlearn: 2.4104827\ttotal: 18.3s\tremaining: 32s\n",
      "1675:\tlearn: 2.4098147\ttotal: 18.3s\tremaining: 32s\n",
      "1676:\tlearn: 2.4091439\ttotal: 18.3s\tremaining: 32s\n",
      "1677:\tlearn: 2.4086341\ttotal: 18.4s\tremaining: 31.9s\n",
      "1678:\tlearn: 2.4079955\ttotal: 18.4s\tremaining: 31.9s\n",
      "1679:\tlearn: 2.4071799\ttotal: 18.4s\tremaining: 31.9s\n",
      "1680:\tlearn: 2.4066752\ttotal: 18.4s\tremaining: 31.9s\n",
      "1681:\tlearn: 2.4060783\ttotal: 18.4s\tremaining: 31.9s\n",
      "1682:\tlearn: 2.4056262\ttotal: 18.4s\tremaining: 31.9s\n",
      "1683:\tlearn: 2.4051062\ttotal: 18.4s\tremaining: 31.9s\n",
      "1684:\tlearn: 2.4045755\ttotal: 18.4s\tremaining: 31.9s\n",
      "1685:\tlearn: 2.4038652\ttotal: 18.4s\tremaining: 31.9s\n",
      "1686:\tlearn: 2.4031948\ttotal: 18.5s\tremaining: 31.9s\n",
      "1687:\tlearn: 2.4026848\ttotal: 18.5s\tremaining: 31.8s\n",
      "1688:\tlearn: 2.4022567\ttotal: 18.5s\tremaining: 31.8s\n",
      "1689:\tlearn: 2.4015587\ttotal: 18.5s\tremaining: 31.8s\n",
      "1690:\tlearn: 2.4013602\ttotal: 18.5s\tremaining: 31.8s\n",
      "1691:\tlearn: 2.4009287\ttotal: 18.5s\tremaining: 31.8s\n",
      "1692:\tlearn: 2.4003664\ttotal: 18.5s\tremaining: 31.8s\n",
      "1693:\tlearn: 2.4000844\ttotal: 18.5s\tremaining: 31.8s\n",
      "1694:\tlearn: 2.3995395\ttotal: 18.5s\tremaining: 31.8s\n",
      "1695:\tlearn: 2.3989484\ttotal: 18.6s\tremaining: 31.8s\n",
      "1696:\tlearn: 2.3987266\ttotal: 18.6s\tremaining: 31.7s\n",
      "1697:\tlearn: 2.3987206\ttotal: 18.6s\tremaining: 31.7s\n",
      "1698:\tlearn: 2.3982034\ttotal: 18.6s\tremaining: 31.7s\n",
      "1699:\tlearn: 2.3975663\ttotal: 18.6s\tremaining: 31.7s\n",
      "1700:\tlearn: 2.3970926\ttotal: 18.6s\tremaining: 31.7s\n",
      "1701:\tlearn: 2.3965530\ttotal: 18.6s\tremaining: 31.7s\n",
      "1702:\tlearn: 2.3956511\ttotal: 18.6s\tremaining: 31.7s\n",
      "1703:\tlearn: 2.3946421\ttotal: 18.6s\tremaining: 31.7s\n",
      "1704:\tlearn: 2.3943294\ttotal: 18.7s\tremaining: 31.7s\n",
      "1705:\tlearn: 2.3942739\ttotal: 18.7s\tremaining: 31.6s\n",
      "1706:\tlearn: 2.3936640\ttotal: 18.7s\tremaining: 31.6s\n",
      "1707:\tlearn: 2.3933943\ttotal: 18.7s\tremaining: 31.6s\n",
      "1708:\tlearn: 2.3928594\ttotal: 18.7s\tremaining: 31.6s\n",
      "1709:\tlearn: 2.3924072\ttotal: 18.7s\tremaining: 31.6s\n",
      "1710:\tlearn: 2.3918720\ttotal: 18.7s\tremaining: 31.6s\n",
      "1711:\tlearn: 2.3913302\ttotal: 18.7s\tremaining: 31.6s\n",
      "1712:\tlearn: 2.3910663\ttotal: 18.7s\tremaining: 31.6s\n",
      "1713:\tlearn: 2.3905967\ttotal: 18.8s\tremaining: 31.5s\n",
      "1714:\tlearn: 2.3903723\ttotal: 18.8s\tremaining: 31.5s\n",
      "1715:\tlearn: 2.3896539\ttotal: 18.8s\tremaining: 31.5s\n",
      "1716:\tlearn: 2.3887768\ttotal: 18.8s\tremaining: 31.5s\n",
      "1717:\tlearn: 2.3885903\ttotal: 18.8s\tremaining: 31.5s\n",
      "1718:\tlearn: 2.3881462\ttotal: 18.8s\tremaining: 31.5s\n",
      "1719:\tlearn: 2.3870819\ttotal: 18.8s\tremaining: 31.5s\n",
      "1720:\tlearn: 2.3865661\ttotal: 18.8s\tremaining: 31.5s\n",
      "1721:\tlearn: 2.3858980\ttotal: 18.8s\tremaining: 31.5s\n",
      "1722:\tlearn: 2.3853985\ttotal: 18.8s\tremaining: 31.4s\n",
      "1723:\tlearn: 2.3846395\ttotal: 18.9s\tremaining: 31.4s\n",
      "1724:\tlearn: 2.3844055\ttotal: 18.9s\tremaining: 31.4s\n",
      "1725:\tlearn: 2.3837315\ttotal: 18.9s\tremaining: 31.4s\n",
      "1726:\tlearn: 2.3828879\ttotal: 18.9s\tremaining: 31.4s\n",
      "1727:\tlearn: 2.3822325\ttotal: 18.9s\tremaining: 31.4s\n",
      "1728:\tlearn: 2.3816973\ttotal: 18.9s\tremaining: 31.4s\n",
      "1729:\tlearn: 2.3811231\ttotal: 18.9s\tremaining: 31.4s\n",
      "1730:\tlearn: 2.3802980\ttotal: 18.9s\tremaining: 31.4s\n",
      "1731:\tlearn: 2.3799467\ttotal: 18.9s\tremaining: 31.4s\n",
      "1732:\tlearn: 2.3794939\ttotal: 19s\tremaining: 31.3s\n",
      "1733:\tlearn: 2.3785492\ttotal: 19s\tremaining: 31.3s\n",
      "1734:\tlearn: 2.3779070\ttotal: 19s\tremaining: 31.3s\n",
      "1735:\tlearn: 2.3775772\ttotal: 19s\tremaining: 31.3s\n",
      "1736:\tlearn: 2.3771577\ttotal: 19s\tremaining: 31.3s\n",
      "1737:\tlearn: 2.3766849\ttotal: 19s\tremaining: 31.3s\n",
      "1738:\tlearn: 2.3766613\ttotal: 19s\tremaining: 31.3s\n",
      "1739:\tlearn: 2.3763883\ttotal: 19s\tremaining: 31.3s\n",
      "1740:\tlearn: 2.3759897\ttotal: 19s\tremaining: 31.2s\n",
      "1741:\tlearn: 2.3754115\ttotal: 19s\tremaining: 31.2s\n",
      "1742:\tlearn: 2.3751160\ttotal: 19.1s\tremaining: 31.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1743:\tlearn: 2.3746248\ttotal: 19.1s\tremaining: 31.2s\n",
      "1744:\tlearn: 2.3742353\ttotal: 19.1s\tremaining: 31.2s\n",
      "1745:\tlearn: 2.3737382\ttotal: 19.1s\tremaining: 31.2s\n",
      "1746:\tlearn: 2.3734027\ttotal: 19.1s\tremaining: 31.2s\n",
      "1747:\tlearn: 2.3727203\ttotal: 19.1s\tremaining: 31.2s\n",
      "1748:\tlearn: 2.3717217\ttotal: 19.1s\tremaining: 31.2s\n",
      "1749:\tlearn: 2.3712978\ttotal: 19.1s\tremaining: 31.1s\n",
      "1750:\tlearn: 2.3706493\ttotal: 19.1s\tremaining: 31.1s\n",
      "1751:\tlearn: 2.3703217\ttotal: 19.2s\tremaining: 31.1s\n",
      "1752:\tlearn: 2.3697183\ttotal: 19.2s\tremaining: 31.1s\n",
      "1753:\tlearn: 2.3692056\ttotal: 19.2s\tremaining: 31.1s\n",
      "1754:\tlearn: 2.3686973\ttotal: 19.2s\tremaining: 31.1s\n",
      "1755:\tlearn: 2.3684189\ttotal: 19.2s\tremaining: 31.1s\n",
      "1756:\tlearn: 2.3676245\ttotal: 19.2s\tremaining: 31.1s\n",
      "1757:\tlearn: 2.3672272\ttotal: 19.2s\tremaining: 31.1s\n",
      "1758:\tlearn: 2.3666752\ttotal: 19.2s\tremaining: 31s\n",
      "1759:\tlearn: 2.3661022\ttotal: 19.2s\tremaining: 31s\n",
      "1760:\tlearn: 2.3655417\ttotal: 19.3s\tremaining: 31s\n",
      "1761:\tlearn: 2.3651173\ttotal: 19.3s\tremaining: 31s\n",
      "1762:\tlearn: 2.3647374\ttotal: 19.3s\tremaining: 31s\n",
      "1763:\tlearn: 2.3642654\ttotal: 19.3s\tremaining: 31s\n",
      "1764:\tlearn: 2.3638502\ttotal: 19.3s\tremaining: 31s\n",
      "1765:\tlearn: 2.3633279\ttotal: 19.3s\tremaining: 31s\n",
      "1766:\tlearn: 2.3629484\ttotal: 19.3s\tremaining: 31s\n",
      "1767:\tlearn: 2.3627570\ttotal: 19.3s\tremaining: 30.9s\n",
      "1768:\tlearn: 2.3623192\ttotal: 19.3s\tremaining: 30.9s\n",
      "1769:\tlearn: 2.3616773\ttotal: 19.4s\tremaining: 30.9s\n",
      "1770:\tlearn: 2.3610512\ttotal: 19.4s\tremaining: 30.9s\n",
      "1771:\tlearn: 2.3606154\ttotal: 19.4s\tremaining: 30.9s\n",
      "1772:\tlearn: 2.3602950\ttotal: 19.4s\tremaining: 30.9s\n",
      "1773:\tlearn: 2.3599349\ttotal: 19.4s\tremaining: 30.9s\n",
      "1774:\tlearn: 2.3594896\ttotal: 19.4s\tremaining: 30.9s\n",
      "1775:\tlearn: 2.3588967\ttotal: 19.4s\tremaining: 30.9s\n",
      "1776:\tlearn: 2.3584673\ttotal: 19.4s\tremaining: 30.8s\n",
      "1777:\tlearn: 2.3577436\ttotal: 19.4s\tremaining: 30.8s\n",
      "1778:\tlearn: 2.3573824\ttotal: 19.5s\tremaining: 30.8s\n",
      "1779:\tlearn: 2.3570984\ttotal: 19.5s\tremaining: 30.8s\n",
      "1780:\tlearn: 2.3567239\ttotal: 19.5s\tremaining: 30.8s\n",
      "1781:\tlearn: 2.3560227\ttotal: 19.5s\tremaining: 30.8s\n",
      "1782:\tlearn: 2.3556201\ttotal: 19.5s\tremaining: 30.8s\n",
      "1783:\tlearn: 2.3547872\ttotal: 19.5s\tremaining: 30.8s\n",
      "1784:\tlearn: 2.3544930\ttotal: 19.5s\tremaining: 30.8s\n",
      "1785:\tlearn: 2.3541383\ttotal: 19.5s\tremaining: 30.7s\n",
      "1786:\tlearn: 2.3537536\ttotal: 19.5s\tremaining: 30.7s\n",
      "1787:\tlearn: 2.3534589\ttotal: 19.6s\tremaining: 30.7s\n",
      "1788:\tlearn: 2.3528285\ttotal: 19.6s\tremaining: 30.7s\n",
      "1789:\tlearn: 2.3526222\ttotal: 19.6s\tremaining: 30.7s\n",
      "1790:\tlearn: 2.3523541\ttotal: 19.6s\tremaining: 30.7s\n",
      "1791:\tlearn: 2.3517984\ttotal: 19.6s\tremaining: 30.7s\n",
      "1792:\tlearn: 2.3515131\ttotal: 19.6s\tremaining: 30.7s\n",
      "1793:\tlearn: 2.3511315\ttotal: 19.6s\tremaining: 30.7s\n",
      "1794:\tlearn: 2.3509698\ttotal: 19.6s\tremaining: 30.6s\n",
      "1795:\tlearn: 2.3503941\ttotal: 19.6s\tremaining: 30.6s\n",
      "1796:\tlearn: 2.3498417\ttotal: 19.6s\tremaining: 30.6s\n",
      "1797:\tlearn: 2.3488529\ttotal: 19.7s\tremaining: 30.6s\n",
      "1798:\tlearn: 2.3486665\ttotal: 19.7s\tremaining: 30.6s\n",
      "1799:\tlearn: 2.3486381\ttotal: 19.7s\tremaining: 30.6s\n",
      "1800:\tlearn: 2.3481847\ttotal: 19.7s\tremaining: 30.6s\n",
      "1801:\tlearn: 2.3477955\ttotal: 19.7s\tremaining: 30.6s\n",
      "1802:\tlearn: 2.3472707\ttotal: 19.7s\tremaining: 30.6s\n",
      "1803:\tlearn: 2.3467077\ttotal: 19.7s\tremaining: 30.5s\n",
      "1804:\tlearn: 2.3462333\ttotal: 19.7s\tremaining: 30.5s\n",
      "1805:\tlearn: 2.3457882\ttotal: 19.7s\tremaining: 30.5s\n",
      "1806:\tlearn: 2.3455259\ttotal: 19.8s\tremaining: 30.5s\n",
      "1807:\tlearn: 2.3452507\ttotal: 19.8s\tremaining: 30.5s\n",
      "1808:\tlearn: 2.3448023\ttotal: 19.8s\tremaining: 30.5s\n",
      "1809:\tlearn: 2.3444175\ttotal: 19.8s\tremaining: 30.5s\n",
      "1810:\tlearn: 2.3440795\ttotal: 19.8s\tremaining: 30.5s\n",
      "1811:\tlearn: 2.3436361\ttotal: 19.8s\tremaining: 30.5s\n",
      "1812:\tlearn: 2.3428884\ttotal: 19.8s\tremaining: 30.4s\n",
      "1813:\tlearn: 2.3424705\ttotal: 19.8s\tremaining: 30.4s\n",
      "1814:\tlearn: 2.3422084\ttotal: 19.8s\tremaining: 30.4s\n",
      "1815:\tlearn: 2.3417477\ttotal: 19.9s\tremaining: 30.4s\n",
      "1816:\tlearn: 2.3413121\ttotal: 19.9s\tremaining: 30.4s\n",
      "1817:\tlearn: 2.3409238\ttotal: 19.9s\tremaining: 30.4s\n",
      "1818:\tlearn: 2.3406567\ttotal: 19.9s\tremaining: 30.4s\n",
      "1819:\tlearn: 2.3402440\ttotal: 19.9s\tremaining: 30.4s\n",
      "1820:\tlearn: 2.3399579\ttotal: 19.9s\tremaining: 30.4s\n",
      "1821:\tlearn: 2.3394979\ttotal: 19.9s\tremaining: 30.3s\n",
      "1822:\tlearn: 2.3392193\ttotal: 19.9s\tremaining: 30.3s\n",
      "1823:\tlearn: 2.3387985\ttotal: 19.9s\tremaining: 30.3s\n",
      "1824:\tlearn: 2.3382134\ttotal: 19.9s\tremaining: 30.3s\n",
      "1825:\tlearn: 2.3376030\ttotal: 20s\tremaining: 30.3s\n",
      "1826:\tlearn: 2.3371837\ttotal: 20s\tremaining: 30.3s\n",
      "1827:\tlearn: 2.3364600\ttotal: 20s\tremaining: 30.3s\n",
      "1828:\tlearn: 2.3360492\ttotal: 20s\tremaining: 30.3s\n",
      "1829:\tlearn: 2.3356877\ttotal: 20s\tremaining: 30.3s\n",
      "1830:\tlearn: 2.3353460\ttotal: 20s\tremaining: 30.2s\n",
      "1831:\tlearn: 2.3342953\ttotal: 20s\tremaining: 30.2s\n",
      "1832:\tlearn: 2.3339490\ttotal: 20s\tremaining: 30.2s\n",
      "1833:\tlearn: 2.3336532\ttotal: 20s\tremaining: 30.2s\n",
      "1834:\tlearn: 2.3331333\ttotal: 20.1s\tremaining: 30.2s\n",
      "1835:\tlearn: 2.3326660\ttotal: 20.1s\tremaining: 30.2s\n",
      "1836:\tlearn: 2.3320979\ttotal: 20.1s\tremaining: 30.2s\n",
      "1837:\tlearn: 2.3317807\ttotal: 20.1s\tremaining: 30.2s\n",
      "1838:\tlearn: 2.3311810\ttotal: 20.1s\tremaining: 30.2s\n",
      "1839:\tlearn: 2.3309178\ttotal: 20.1s\tremaining: 30.1s\n",
      "1840:\tlearn: 2.3304435\ttotal: 20.1s\tremaining: 30.1s\n",
      "1841:\tlearn: 2.3300208\ttotal: 20.1s\tremaining: 30.1s\n",
      "1842:\tlearn: 2.3296642\ttotal: 20.1s\tremaining: 30.1s\n",
      "1843:\tlearn: 2.3293758\ttotal: 20.1s\tremaining: 30.1s\n",
      "1844:\tlearn: 2.3289155\ttotal: 20.2s\tremaining: 30.1s\n",
      "1845:\tlearn: 2.3286381\ttotal: 20.2s\tremaining: 30.1s\n",
      "1846:\tlearn: 2.3285417\ttotal: 20.2s\tremaining: 30.1s\n",
      "1847:\tlearn: 2.3282583\ttotal: 20.2s\tremaining: 30s\n",
      "1848:\tlearn: 2.3279557\ttotal: 20.2s\tremaining: 30s\n",
      "1849:\tlearn: 2.3275904\ttotal: 20.2s\tremaining: 30s\n",
      "1850:\tlearn: 2.3268414\ttotal: 20.2s\tremaining: 30s\n",
      "1851:\tlearn: 2.3263572\ttotal: 20.2s\tremaining: 30s\n",
      "1852:\tlearn: 2.3260481\ttotal: 20.2s\tremaining: 30s\n",
      "1853:\tlearn: 2.3253832\ttotal: 20.3s\tremaining: 30s\n",
      "1854:\tlearn: 2.3249845\ttotal: 20.3s\tremaining: 30s\n",
      "1855:\tlearn: 2.3246212\ttotal: 20.3s\tremaining: 30s\n",
      "1856:\tlearn: 2.3243806\ttotal: 20.3s\tremaining: 29.9s\n",
      "1857:\tlearn: 2.3237236\ttotal: 20.3s\tremaining: 29.9s\n",
      "1858:\tlearn: 2.3234125\ttotal: 20.3s\tremaining: 29.9s\n",
      "1859:\tlearn: 2.3230335\ttotal: 20.3s\tremaining: 29.9s\n",
      "1860:\tlearn: 2.3222754\ttotal: 20.3s\tremaining: 29.9s\n",
      "1861:\tlearn: 2.3219148\ttotal: 20.3s\tremaining: 29.9s\n",
      "1862:\tlearn: 2.3215500\ttotal: 20.4s\tremaining: 29.9s\n",
      "1863:\tlearn: 2.3213320\ttotal: 20.4s\tremaining: 29.9s\n",
      "1864:\tlearn: 2.3206801\ttotal: 20.4s\tremaining: 29.9s\n",
      "1865:\tlearn: 2.3200869\ttotal: 20.4s\tremaining: 29.8s\n",
      "1866:\tlearn: 2.3196944\ttotal: 20.4s\tremaining: 29.8s\n",
      "1867:\tlearn: 2.3191286\ttotal: 20.4s\tremaining: 29.8s\n",
      "1868:\tlearn: 2.3188402\ttotal: 20.4s\tremaining: 29.8s\n",
      "1869:\tlearn: 2.3185697\ttotal: 20.4s\tremaining: 29.8s\n",
      "1870:\tlearn: 2.3182407\ttotal: 20.4s\tremaining: 29.8s\n",
      "1871:\tlearn: 2.3179439\ttotal: 20.4s\tremaining: 29.8s\n",
      "1872:\tlearn: 2.3176496\ttotal: 20.5s\tremaining: 29.8s\n",
      "1873:\tlearn: 2.3171756\ttotal: 20.5s\tremaining: 29.8s\n",
      "1874:\tlearn: 2.3164275\ttotal: 20.5s\tremaining: 29.7s\n",
      "1875:\tlearn: 2.3157574\ttotal: 20.5s\tremaining: 29.7s\n",
      "1876:\tlearn: 2.3151045\ttotal: 20.5s\tremaining: 29.7s\n",
      "1877:\tlearn: 2.3149315\ttotal: 20.5s\tremaining: 29.7s\n",
      "1878:\tlearn: 2.3144458\ttotal: 20.5s\tremaining: 29.7s\n",
      "1879:\tlearn: 2.3139749\ttotal: 20.5s\tremaining: 29.7s\n",
      "1880:\tlearn: 2.3136079\ttotal: 20.5s\tremaining: 29.7s\n",
      "1881:\tlearn: 2.3128323\ttotal: 20.6s\tremaining: 29.7s\n",
      "1882:\tlearn: 2.3122601\ttotal: 20.6s\tremaining: 29.7s\n",
      "1883:\tlearn: 2.3119214\ttotal: 20.6s\tremaining: 29.6s\n",
      "1884:\tlearn: 2.3110664\ttotal: 20.6s\tremaining: 29.6s\n",
      "1885:\tlearn: 2.3108484\ttotal: 20.6s\tremaining: 29.6s\n",
      "1886:\tlearn: 2.3105500\ttotal: 20.6s\tremaining: 29.6s\n",
      "1887:\tlearn: 2.3100815\ttotal: 20.6s\tremaining: 29.6s\n",
      "1888:\tlearn: 2.3097762\ttotal: 20.6s\tremaining: 29.6s\n",
      "1889:\tlearn: 2.3093956\ttotal: 20.6s\tremaining: 29.6s\n",
      "1890:\tlearn: 2.3089069\ttotal: 20.7s\tremaining: 29.6s\n",
      "1891:\tlearn: 2.3083566\ttotal: 20.7s\tremaining: 29.6s\n",
      "1892:\tlearn: 2.3079150\ttotal: 20.7s\tremaining: 29.5s\n",
      "1893:\tlearn: 2.3076658\ttotal: 20.7s\tremaining: 29.5s\n",
      "1894:\tlearn: 2.3069856\ttotal: 20.7s\tremaining: 29.5s\n",
      "1895:\tlearn: 2.3066189\ttotal: 20.7s\tremaining: 29.5s\n",
      "1896:\tlearn: 2.3062639\ttotal: 20.7s\tremaining: 29.5s\n",
      "1897:\tlearn: 2.3057467\ttotal: 20.7s\tremaining: 29.5s\n",
      "1898:\tlearn: 2.3054942\ttotal: 20.7s\tremaining: 29.5s\n",
      "1899:\tlearn: 2.3049247\ttotal: 20.8s\tremaining: 29.5s\n",
      "1900:\tlearn: 2.3043590\ttotal: 20.8s\tremaining: 29.5s\n",
      "1901:\tlearn: 2.3033304\ttotal: 20.8s\tremaining: 29.5s\n",
      "1902:\tlearn: 2.3028344\ttotal: 20.8s\tremaining: 29.4s\n",
      "1903:\tlearn: 2.3024623\ttotal: 20.8s\tremaining: 29.4s\n",
      "1904:\tlearn: 2.3022681\ttotal: 20.8s\tremaining: 29.4s\n",
      "1905:\tlearn: 2.3018556\ttotal: 20.8s\tremaining: 29.4s\n",
      "1906:\tlearn: 2.3015092\ttotal: 20.8s\tremaining: 29.4s\n",
      "1907:\tlearn: 2.3010283\ttotal: 20.8s\tremaining: 29.4s\n",
      "1908:\tlearn: 2.3005241\ttotal: 20.9s\tremaining: 29.4s\n",
      "1909:\tlearn: 2.3000091\ttotal: 20.9s\tremaining: 29.4s\n",
      "1910:\tlearn: 2.2995874\ttotal: 20.9s\tremaining: 29.4s\n",
      "1911:\tlearn: 2.2992067\ttotal: 20.9s\tremaining: 29.3s\n",
      "1912:\tlearn: 2.2985205\ttotal: 20.9s\tremaining: 29.3s\n",
      "1913:\tlearn: 2.2982649\ttotal: 20.9s\tremaining: 29.3s\n",
      "1914:\tlearn: 2.2978165\ttotal: 20.9s\tremaining: 29.3s\n",
      "1915:\tlearn: 2.2974299\ttotal: 20.9s\tremaining: 29.3s\n",
      "1916:\tlearn: 2.2969325\ttotal: 20.9s\tremaining: 29.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1917:\tlearn: 2.2963686\ttotal: 21s\tremaining: 29.3s\n",
      "1918:\tlearn: 2.2956519\ttotal: 21s\tremaining: 29.3s\n",
      "1919:\tlearn: 2.2950225\ttotal: 21s\tremaining: 29.3s\n",
      "1920:\tlearn: 2.2945832\ttotal: 21s\tremaining: 29.3s\n",
      "1921:\tlearn: 2.2944194\ttotal: 21s\tremaining: 29.2s\n",
      "1922:\tlearn: 2.2937360\ttotal: 21s\tremaining: 29.2s\n",
      "1923:\tlearn: 2.2932726\ttotal: 21s\tremaining: 29.2s\n",
      "1924:\tlearn: 2.2926605\ttotal: 21s\tremaining: 29.2s\n",
      "1925:\tlearn: 2.2919368\ttotal: 21s\tremaining: 29.2s\n",
      "1926:\tlearn: 2.2915991\ttotal: 21.1s\tremaining: 29.2s\n",
      "1927:\tlearn: 2.2915675\ttotal: 21.1s\tremaining: 29.2s\n",
      "1928:\tlearn: 2.2913476\ttotal: 21.1s\tremaining: 29.2s\n",
      "1929:\tlearn: 2.2907894\ttotal: 21.1s\tremaining: 29.1s\n",
      "1930:\tlearn: 2.2904055\ttotal: 21.1s\tremaining: 29.1s\n",
      "1931:\tlearn: 2.2896559\ttotal: 21.1s\tremaining: 29.1s\n",
      "1932:\tlearn: 2.2892804\ttotal: 21.1s\tremaining: 29.1s\n",
      "1933:\tlearn: 2.2885249\ttotal: 21.1s\tremaining: 29.1s\n",
      "1934:\tlearn: 2.2885043\ttotal: 21.1s\tremaining: 29.1s\n",
      "1935:\tlearn: 2.2882979\ttotal: 21.1s\tremaining: 29.1s\n",
      "1936:\tlearn: 2.2882875\ttotal: 21.2s\tremaining: 29.1s\n",
      "1937:\tlearn: 2.2879273\ttotal: 21.2s\tremaining: 29.1s\n",
      "1938:\tlearn: 2.2873079\ttotal: 21.2s\tremaining: 29s\n",
      "1939:\tlearn: 2.2867245\ttotal: 21.2s\tremaining: 29s\n",
      "1940:\tlearn: 2.2862449\ttotal: 21.2s\tremaining: 29s\n",
      "1941:\tlearn: 2.2858903\ttotal: 21.2s\tremaining: 29s\n",
      "1942:\tlearn: 2.2853571\ttotal: 21.2s\tremaining: 29s\n",
      "1943:\tlearn: 2.2844124\ttotal: 21.2s\tremaining: 29s\n",
      "1944:\tlearn: 2.2838318\ttotal: 21.2s\tremaining: 29s\n",
      "1945:\tlearn: 2.2831169\ttotal: 21.3s\tremaining: 29s\n",
      "1946:\tlearn: 2.2827149\ttotal: 21.3s\tremaining: 29s\n",
      "1947:\tlearn: 2.2822274\ttotal: 21.3s\tremaining: 28.9s\n",
      "1948:\tlearn: 2.2817956\ttotal: 21.3s\tremaining: 28.9s\n",
      "1949:\tlearn: 2.2815725\ttotal: 21.3s\tremaining: 28.9s\n",
      "1950:\tlearn: 2.2811804\ttotal: 21.3s\tremaining: 28.9s\n",
      "1951:\tlearn: 2.2806996\ttotal: 21.3s\tremaining: 28.9s\n",
      "1952:\tlearn: 2.2803734\ttotal: 21.3s\tremaining: 28.9s\n",
      "1953:\tlearn: 2.2799387\ttotal: 21.3s\tremaining: 28.9s\n",
      "1954:\tlearn: 2.2792077\ttotal: 21.4s\tremaining: 28.9s\n",
      "1955:\tlearn: 2.2787840\ttotal: 21.4s\tremaining: 28.9s\n",
      "1956:\tlearn: 2.2784473\ttotal: 21.4s\tremaining: 28.8s\n",
      "1957:\tlearn: 2.2780133\ttotal: 21.4s\tremaining: 28.8s\n",
      "1958:\tlearn: 2.2776608\ttotal: 21.4s\tremaining: 28.8s\n",
      "1959:\tlearn: 2.2772548\ttotal: 21.4s\tremaining: 28.8s\n",
      "1960:\tlearn: 2.2766563\ttotal: 21.4s\tremaining: 28.8s\n",
      "1961:\tlearn: 2.2763727\ttotal: 21.4s\tremaining: 28.8s\n",
      "1962:\tlearn: 2.2760593\ttotal: 21.4s\tremaining: 28.8s\n",
      "1963:\tlearn: 2.2755654\ttotal: 21.5s\tremaining: 28.8s\n",
      "1964:\tlearn: 2.2746770\ttotal: 21.5s\tremaining: 28.8s\n",
      "1965:\tlearn: 2.2742327\ttotal: 21.5s\tremaining: 28.8s\n",
      "1966:\tlearn: 2.2739038\ttotal: 21.5s\tremaining: 28.7s\n",
      "1967:\tlearn: 2.2732661\ttotal: 21.5s\tremaining: 28.7s\n",
      "1968:\tlearn: 2.2730192\ttotal: 21.5s\tremaining: 28.7s\n",
      "1969:\tlearn: 2.2725075\ttotal: 21.5s\tremaining: 28.7s\n",
      "1970:\tlearn: 2.2719557\ttotal: 21.5s\tremaining: 28.7s\n",
      "1971:\tlearn: 2.2717588\ttotal: 21.5s\tremaining: 28.7s\n",
      "1972:\tlearn: 2.2712235\ttotal: 21.5s\tremaining: 28.7s\n",
      "1973:\tlearn: 2.2705996\ttotal: 21.6s\tremaining: 28.7s\n",
      "1974:\tlearn: 2.2700648\ttotal: 21.6s\tremaining: 28.6s\n",
      "1975:\tlearn: 2.2695831\ttotal: 21.6s\tremaining: 28.6s\n",
      "1976:\tlearn: 2.2691187\ttotal: 21.6s\tremaining: 28.6s\n",
      "1977:\tlearn: 2.2685790\ttotal: 21.6s\tremaining: 28.6s\n",
      "1978:\tlearn: 2.2683496\ttotal: 21.6s\tremaining: 28.6s\n",
      "1979:\tlearn: 2.2676693\ttotal: 21.6s\tremaining: 28.6s\n",
      "1980:\tlearn: 2.2673228\ttotal: 21.6s\tremaining: 28.6s\n",
      "1981:\tlearn: 2.2671481\ttotal: 21.6s\tremaining: 28.6s\n",
      "1982:\tlearn: 2.2668154\ttotal: 21.7s\tremaining: 28.6s\n",
      "1983:\tlearn: 2.2660662\ttotal: 21.7s\tremaining: 28.6s\n",
      "1984:\tlearn: 2.2655965\ttotal: 21.7s\tremaining: 28.5s\n",
      "1985:\tlearn: 2.2652187\ttotal: 21.7s\tremaining: 28.5s\n",
      "1986:\tlearn: 2.2649483\ttotal: 21.7s\tremaining: 28.5s\n",
      "1987:\tlearn: 2.2645229\ttotal: 21.7s\tremaining: 28.5s\n",
      "1988:\tlearn: 2.2639418\ttotal: 21.7s\tremaining: 28.5s\n",
      "1989:\tlearn: 2.2635933\ttotal: 21.7s\tremaining: 28.5s\n",
      "1990:\tlearn: 2.2631058\ttotal: 21.7s\tremaining: 28.5s\n",
      "1991:\tlearn: 2.2622142\ttotal: 21.8s\tremaining: 28.5s\n",
      "1992:\tlearn: 2.2617580\ttotal: 21.8s\tremaining: 28.4s\n",
      "1993:\tlearn: 2.2614295\ttotal: 21.8s\tremaining: 28.4s\n",
      "1994:\tlearn: 2.2609290\ttotal: 21.8s\tremaining: 28.4s\n",
      "1995:\tlearn: 2.2605921\ttotal: 21.8s\tremaining: 28.4s\n",
      "1996:\tlearn: 2.2601240\ttotal: 21.8s\tremaining: 28.4s\n",
      "1997:\tlearn: 2.2597414\ttotal: 21.8s\tremaining: 28.4s\n",
      "1998:\tlearn: 2.2593841\ttotal: 21.8s\tremaining: 28.4s\n",
      "1999:\tlearn: 2.2590228\ttotal: 21.8s\tremaining: 28.4s\n",
      "2000:\tlearn: 2.2583871\ttotal: 21.9s\tremaining: 28.4s\n",
      "2001:\tlearn: 2.2578626\ttotal: 21.9s\tremaining: 28.4s\n",
      "2002:\tlearn: 2.2575887\ttotal: 21.9s\tremaining: 28.3s\n",
      "2003:\tlearn: 2.2570639\ttotal: 21.9s\tremaining: 28.3s\n",
      "2004:\tlearn: 2.2564306\ttotal: 21.9s\tremaining: 28.3s\n",
      "2005:\tlearn: 2.2560263\ttotal: 21.9s\tremaining: 28.3s\n",
      "2006:\tlearn: 2.2555428\ttotal: 21.9s\tremaining: 28.3s\n",
      "2007:\tlearn: 2.2548786\ttotal: 21.9s\tremaining: 28.3s\n",
      "2008:\tlearn: 2.2545682\ttotal: 21.9s\tremaining: 28.3s\n",
      "2009:\tlearn: 2.2543861\ttotal: 21.9s\tremaining: 28.3s\n",
      "2010:\tlearn: 2.2538727\ttotal: 22s\tremaining: 28.3s\n",
      "2011:\tlearn: 2.2535276\ttotal: 22s\tremaining: 28.2s\n",
      "2012:\tlearn: 2.2532224\ttotal: 22s\tremaining: 28.2s\n",
      "2013:\tlearn: 2.2523770\ttotal: 22s\tremaining: 28.2s\n",
      "2014:\tlearn: 2.2518888\ttotal: 22s\tremaining: 28.2s\n",
      "2015:\tlearn: 2.2514332\ttotal: 22s\tremaining: 28.2s\n",
      "2016:\tlearn: 2.2509828\ttotal: 22s\tremaining: 28.2s\n",
      "2017:\tlearn: 2.2503152\ttotal: 22s\tremaining: 28.2s\n",
      "2018:\tlearn: 2.2499674\ttotal: 22s\tremaining: 28.2s\n",
      "2019:\tlearn: 2.2495357\ttotal: 22.1s\tremaining: 28.2s\n",
      "2020:\tlearn: 2.2490461\ttotal: 22.1s\tremaining: 28.1s\n",
      "2021:\tlearn: 2.2485246\ttotal: 22.1s\tremaining: 28.1s\n",
      "2022:\tlearn: 2.2481927\ttotal: 22.1s\tremaining: 28.1s\n",
      "2023:\tlearn: 2.2477727\ttotal: 22.1s\tremaining: 28.1s\n",
      "2024:\tlearn: 2.2475646\ttotal: 22.1s\tremaining: 28.1s\n",
      "2025:\tlearn: 2.2472297\ttotal: 22.1s\tremaining: 28.1s\n",
      "2026:\tlearn: 2.2465330\ttotal: 22.1s\tremaining: 28.1s\n",
      "2027:\tlearn: 2.2460906\ttotal: 22.1s\tremaining: 28.1s\n",
      "2028:\tlearn: 2.2457858\ttotal: 22.2s\tremaining: 28.1s\n",
      "2029:\tlearn: 2.2453794\ttotal: 22.2s\tremaining: 28s\n",
      "2030:\tlearn: 2.2451788\ttotal: 22.2s\tremaining: 28s\n",
      "2031:\tlearn: 2.2444859\ttotal: 22.2s\tremaining: 28s\n",
      "2032:\tlearn: 2.2436192\ttotal: 22.2s\tremaining: 28s\n",
      "2033:\tlearn: 2.2432200\ttotal: 22.2s\tremaining: 28s\n",
      "2034:\tlearn: 2.2428779\ttotal: 22.2s\tremaining: 28s\n",
      "2035:\tlearn: 2.2421723\ttotal: 22.2s\tremaining: 28s\n",
      "2036:\tlearn: 2.2417153\ttotal: 22.2s\tremaining: 28s\n",
      "2037:\tlearn: 2.2412012\ttotal: 22.3s\tremaining: 27.9s\n",
      "2038:\tlearn: 2.2406051\ttotal: 22.3s\tremaining: 27.9s\n",
      "2039:\tlearn: 2.2401129\ttotal: 22.3s\tremaining: 27.9s\n",
      "2040:\tlearn: 2.2396879\ttotal: 22.3s\tremaining: 27.9s\n",
      "2041:\tlearn: 2.2392846\ttotal: 22.3s\tremaining: 27.9s\n",
      "2042:\tlearn: 2.2386260\ttotal: 22.3s\tremaining: 27.9s\n",
      "2043:\tlearn: 2.2382204\ttotal: 22.3s\tremaining: 27.9s\n",
      "2044:\tlearn: 2.2379046\ttotal: 22.3s\tremaining: 27.9s\n",
      "2045:\tlearn: 2.2373320\ttotal: 22.3s\tremaining: 27.9s\n",
      "2046:\tlearn: 2.2365313\ttotal: 22.4s\tremaining: 27.9s\n",
      "2047:\tlearn: 2.2358207\ttotal: 22.4s\tremaining: 27.8s\n",
      "2048:\tlearn: 2.2352710\ttotal: 22.4s\tremaining: 27.8s\n",
      "2049:\tlearn: 2.2350348\ttotal: 22.4s\tremaining: 27.8s\n",
      "2050:\tlearn: 2.2345777\ttotal: 22.4s\tremaining: 27.8s\n",
      "2051:\tlearn: 2.2342972\ttotal: 22.4s\tremaining: 27.8s\n",
      "2052:\tlearn: 2.2341149\ttotal: 22.4s\tremaining: 27.8s\n",
      "2053:\tlearn: 2.2335576\ttotal: 22.4s\tremaining: 27.8s\n",
      "2054:\tlearn: 2.2330930\ttotal: 22.4s\tremaining: 27.8s\n",
      "2055:\tlearn: 2.2326692\ttotal: 22.5s\tremaining: 27.8s\n",
      "2056:\tlearn: 2.2320944\ttotal: 22.5s\tremaining: 27.8s\n",
      "2057:\tlearn: 2.2316720\ttotal: 22.5s\tremaining: 27.8s\n",
      "2058:\tlearn: 2.2310824\ttotal: 22.5s\tremaining: 27.7s\n",
      "2059:\tlearn: 2.2304556\ttotal: 22.5s\tremaining: 27.7s\n",
      "2060:\tlearn: 2.2301260\ttotal: 22.5s\tremaining: 27.7s\n",
      "2061:\tlearn: 2.2296517\ttotal: 22.5s\tremaining: 27.7s\n",
      "2062:\tlearn: 2.2292119\ttotal: 22.5s\tremaining: 27.7s\n",
      "2063:\tlearn: 2.2288410\ttotal: 22.6s\tremaining: 27.7s\n",
      "2064:\tlearn: 2.2281441\ttotal: 22.6s\tremaining: 27.7s\n",
      "2065:\tlearn: 2.2279813\ttotal: 22.6s\tremaining: 27.7s\n",
      "2066:\tlearn: 2.2277417\ttotal: 22.6s\tremaining: 27.7s\n",
      "2067:\tlearn: 2.2276816\ttotal: 22.6s\tremaining: 27.6s\n",
      "2068:\tlearn: 2.2272750\ttotal: 22.6s\tremaining: 27.6s\n",
      "2069:\tlearn: 2.2266021\ttotal: 22.6s\tremaining: 27.6s\n",
      "2070:\tlearn: 2.2262011\ttotal: 22.6s\tremaining: 27.6s\n",
      "2071:\tlearn: 2.2256788\ttotal: 22.6s\tremaining: 27.6s\n",
      "2072:\tlearn: 2.2252882\ttotal: 22.6s\tremaining: 27.6s\n",
      "2073:\tlearn: 2.2250775\ttotal: 22.7s\tremaining: 27.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2074:\tlearn: 2.2245289\ttotal: 22.7s\tremaining: 27.6s\n",
      "2075:\tlearn: 2.2238701\ttotal: 22.7s\tremaining: 27.6s\n",
      "2076:\tlearn: 2.2233270\ttotal: 22.7s\tremaining: 27.5s\n",
      "2077:\tlearn: 2.2231729\ttotal: 22.7s\tremaining: 27.5s\n",
      "2078:\tlearn: 2.2226875\ttotal: 22.7s\tremaining: 27.5s\n",
      "2079:\tlearn: 2.2219574\ttotal: 22.7s\tremaining: 27.5s\n",
      "2080:\tlearn: 2.2216323\ttotal: 22.7s\tremaining: 27.5s\n",
      "2081:\tlearn: 2.2213261\ttotal: 22.7s\tremaining: 27.5s\n",
      "2082:\tlearn: 2.2207980\ttotal: 22.8s\tremaining: 27.5s\n",
      "2083:\tlearn: 2.2201564\ttotal: 22.8s\tremaining: 27.5s\n",
      "2084:\tlearn: 2.2197380\ttotal: 22.8s\tremaining: 27.4s\n",
      "2085:\tlearn: 2.2192101\ttotal: 22.8s\tremaining: 27.4s\n",
      "2086:\tlearn: 2.2190141\ttotal: 22.8s\tremaining: 27.4s\n",
      "2087:\tlearn: 2.2181167\ttotal: 22.8s\tremaining: 27.4s\n",
      "2088:\tlearn: 2.2177463\ttotal: 22.8s\tremaining: 27.4s\n",
      "2089:\tlearn: 2.2174826\ttotal: 22.8s\tremaining: 27.4s\n",
      "2090:\tlearn: 2.2171096\ttotal: 22.8s\tremaining: 27.4s\n",
      "2091:\tlearn: 2.2165920\ttotal: 22.9s\tremaining: 27.4s\n",
      "2092:\tlearn: 2.2161692\ttotal: 22.9s\tremaining: 27.4s\n",
      "2093:\tlearn: 2.2158028\ttotal: 22.9s\tremaining: 27.4s\n",
      "2094:\tlearn: 2.2153923\ttotal: 22.9s\tremaining: 27.3s\n",
      "2095:\tlearn: 2.2151543\ttotal: 22.9s\tremaining: 27.3s\n",
      "2096:\tlearn: 2.2142228\ttotal: 22.9s\tremaining: 27.3s\n",
      "2097:\tlearn: 2.2139019\ttotal: 22.9s\tremaining: 27.3s\n",
      "2098:\tlearn: 2.2135205\ttotal: 22.9s\tremaining: 27.3s\n",
      "2099:\tlearn: 2.2128906\ttotal: 22.9s\tremaining: 27.3s\n",
      "2100:\tlearn: 2.2124877\ttotal: 23s\tremaining: 27.3s\n",
      "2101:\tlearn: 2.2119997\ttotal: 23s\tremaining: 27.3s\n",
      "2102:\tlearn: 2.2117713\ttotal: 23s\tremaining: 27.3s\n",
      "2103:\tlearn: 2.2113962\ttotal: 23s\tremaining: 27.2s\n",
      "2104:\tlearn: 2.2109427\ttotal: 23s\tremaining: 27.2s\n",
      "2105:\tlearn: 2.2104597\ttotal: 23s\tremaining: 27.2s\n",
      "2106:\tlearn: 2.2101720\ttotal: 23s\tremaining: 27.2s\n",
      "2107:\tlearn: 2.2097496\ttotal: 23s\tremaining: 27.2s\n",
      "2108:\tlearn: 2.2094965\ttotal: 23s\tremaining: 27.2s\n",
      "2109:\tlearn: 2.2088691\ttotal: 23s\tremaining: 27.2s\n",
      "2110:\tlearn: 2.2086615\ttotal: 23.1s\tremaining: 27.2s\n",
      "2111:\tlearn: 2.2083473\ttotal: 23.1s\tremaining: 27.2s\n",
      "2112:\tlearn: 2.2078832\ttotal: 23.1s\tremaining: 27.1s\n",
      "2113:\tlearn: 2.2073907\ttotal: 23.1s\tremaining: 27.1s\n",
      "2114:\tlearn: 2.2070511\ttotal: 23.1s\tremaining: 27.1s\n",
      "2115:\tlearn: 2.2065644\ttotal: 23.1s\tremaining: 27.1s\n",
      "2116:\tlearn: 2.2061577\ttotal: 23.1s\tremaining: 27.1s\n",
      "2117:\tlearn: 2.2057318\ttotal: 23.1s\tremaining: 27.1s\n",
      "2118:\tlearn: 2.2053107\ttotal: 23.1s\tremaining: 27.1s\n",
      "2119:\tlearn: 2.2046086\ttotal: 23.2s\tremaining: 27.1s\n",
      "2120:\tlearn: 2.2042994\ttotal: 23.2s\tremaining: 27.1s\n",
      "2121:\tlearn: 2.2038139\ttotal: 23.2s\tremaining: 27s\n",
      "2122:\tlearn: 2.2036257\ttotal: 23.2s\tremaining: 27s\n",
      "2123:\tlearn: 2.2032582\ttotal: 23.2s\tremaining: 27s\n",
      "2124:\tlearn: 2.2028605\ttotal: 23.2s\tremaining: 27s\n",
      "2125:\tlearn: 2.2021878\ttotal: 23.2s\tremaining: 27s\n",
      "2126:\tlearn: 2.2015615\ttotal: 23.2s\tremaining: 27s\n",
      "2127:\tlearn: 2.2009845\ttotal: 23.2s\tremaining: 27s\n",
      "2128:\tlearn: 2.2005489\ttotal: 23.3s\tremaining: 27s\n",
      "2129:\tlearn: 2.2002486\ttotal: 23.3s\tremaining: 27s\n",
      "2130:\tlearn: 2.1997160\ttotal: 23.3s\tremaining: 26.9s\n",
      "2131:\tlearn: 2.1990320\ttotal: 23.3s\tremaining: 26.9s\n",
      "2132:\tlearn: 2.1983811\ttotal: 23.3s\tremaining: 26.9s\n",
      "2133:\tlearn: 2.1978323\ttotal: 23.3s\tremaining: 26.9s\n",
      "2134:\tlearn: 2.1975190\ttotal: 23.3s\tremaining: 26.9s\n",
      "2135:\tlearn: 2.1968723\ttotal: 23.3s\tremaining: 26.9s\n",
      "2136:\tlearn: 2.1966309\ttotal: 23.3s\tremaining: 26.9s\n",
      "2137:\tlearn: 2.1963783\ttotal: 23.4s\tremaining: 26.9s\n",
      "2138:\tlearn: 2.1959362\ttotal: 23.4s\tremaining: 26.9s\n",
      "2139:\tlearn: 2.1955031\ttotal: 23.4s\tremaining: 26.9s\n",
      "2140:\tlearn: 2.1954982\ttotal: 23.4s\tremaining: 26.8s\n",
      "2141:\tlearn: 2.1950420\ttotal: 23.4s\tremaining: 26.8s\n",
      "2142:\tlearn: 2.1945004\ttotal: 23.4s\tremaining: 26.8s\n",
      "2143:\tlearn: 2.1942646\ttotal: 23.4s\tremaining: 26.8s\n",
      "2144:\tlearn: 2.1938511\ttotal: 23.4s\tremaining: 26.8s\n",
      "2145:\tlearn: 2.1933144\ttotal: 23.4s\tremaining: 26.8s\n",
      "2146:\tlearn: 2.1931125\ttotal: 23.5s\tremaining: 26.8s\n",
      "2147:\tlearn: 2.1926568\ttotal: 23.5s\tremaining: 26.8s\n",
      "2148:\tlearn: 2.1922672\ttotal: 23.5s\tremaining: 26.8s\n",
      "2149:\tlearn: 2.1919488\ttotal: 23.5s\tremaining: 26.7s\n",
      "2150:\tlearn: 2.1916416\ttotal: 23.5s\tremaining: 26.7s\n",
      "2151:\tlearn: 2.1911250\ttotal: 23.5s\tremaining: 26.7s\n",
      "2152:\tlearn: 2.1908321\ttotal: 23.5s\tremaining: 26.7s\n",
      "2153:\tlearn: 2.1903027\ttotal: 23.5s\tremaining: 26.7s\n",
      "2154:\tlearn: 2.1899351\ttotal: 23.5s\tremaining: 26.7s\n",
      "2155:\tlearn: 2.1895536\ttotal: 23.6s\tremaining: 26.7s\n",
      "2156:\tlearn: 2.1890927\ttotal: 23.6s\tremaining: 26.7s\n",
      "2157:\tlearn: 2.1887440\ttotal: 23.6s\tremaining: 26.7s\n",
      "2158:\tlearn: 2.1884621\ttotal: 23.6s\tremaining: 26.6s\n",
      "2159:\tlearn: 2.1880106\ttotal: 23.6s\tremaining: 26.6s\n",
      "2160:\tlearn: 2.1874550\ttotal: 23.6s\tremaining: 26.6s\n",
      "2161:\tlearn: 2.1872459\ttotal: 23.6s\tremaining: 26.6s\n",
      "2162:\tlearn: 2.1870806\ttotal: 23.6s\tremaining: 26.6s\n",
      "2163:\tlearn: 2.1868615\ttotal: 23.6s\tremaining: 26.6s\n",
      "2164:\tlearn: 2.1864845\ttotal: 23.6s\tremaining: 26.6s\n",
      "2165:\tlearn: 2.1859421\ttotal: 23.7s\tremaining: 26.6s\n",
      "2166:\tlearn: 2.1857174\ttotal: 23.7s\tremaining: 26.5s\n",
      "2167:\tlearn: 2.1853515\ttotal: 23.7s\tremaining: 26.5s\n",
      "2168:\tlearn: 2.1849084\ttotal: 23.7s\tremaining: 26.5s\n",
      "2169:\tlearn: 2.1844204\ttotal: 23.7s\tremaining: 26.5s\n",
      "2170:\tlearn: 2.1842946\ttotal: 23.7s\tremaining: 26.5s\n",
      "2171:\tlearn: 2.1839201\ttotal: 23.7s\tremaining: 26.5s\n",
      "2172:\tlearn: 2.1835734\ttotal: 23.7s\tremaining: 26.5s\n",
      "2173:\tlearn: 2.1831817\ttotal: 23.7s\tremaining: 26.5s\n",
      "2174:\tlearn: 2.1827397\ttotal: 23.8s\tremaining: 26.5s\n",
      "2175:\tlearn: 2.1824301\ttotal: 23.8s\tremaining: 26.5s\n",
      "2176:\tlearn: 2.1817546\ttotal: 23.8s\tremaining: 26.4s\n",
      "2177:\tlearn: 2.1811506\ttotal: 23.8s\tremaining: 26.4s\n",
      "2178:\tlearn: 2.1810080\ttotal: 23.8s\tremaining: 26.4s\n",
      "2179:\tlearn: 2.1807670\ttotal: 23.8s\tremaining: 26.4s\n",
      "2180:\tlearn: 2.1803222\ttotal: 23.8s\tremaining: 26.4s\n",
      "2181:\tlearn: 2.1796172\ttotal: 23.8s\tremaining: 26.4s\n",
      "2182:\tlearn: 2.1793386\ttotal: 23.8s\tremaining: 26.4s\n",
      "2183:\tlearn: 2.1789680\ttotal: 23.9s\tremaining: 26.4s\n",
      "2184:\tlearn: 2.1786244\ttotal: 23.9s\tremaining: 26.4s\n",
      "2185:\tlearn: 2.1781213\ttotal: 23.9s\tremaining: 26.3s\n",
      "2186:\tlearn: 2.1776898\ttotal: 23.9s\tremaining: 26.3s\n",
      "2187:\tlearn: 2.1774447\ttotal: 23.9s\tremaining: 26.3s\n",
      "2188:\tlearn: 2.1772872\ttotal: 23.9s\tremaining: 26.3s\n",
      "2189:\tlearn: 2.1767907\ttotal: 23.9s\tremaining: 26.3s\n",
      "2190:\tlearn: 2.1767876\ttotal: 23.9s\tremaining: 26.3s\n",
      "2191:\tlearn: 2.1765497\ttotal: 23.9s\tremaining: 26.3s\n",
      "2192:\tlearn: 2.1764801\ttotal: 23.9s\tremaining: 26.3s\n",
      "2193:\tlearn: 2.1760268\ttotal: 24s\tremaining: 26.3s\n",
      "2194:\tlearn: 2.1754799\ttotal: 24s\tremaining: 26.2s\n",
      "2195:\tlearn: 2.1750337\ttotal: 24s\tremaining: 26.2s\n",
      "2196:\tlearn: 2.1746934\ttotal: 24s\tremaining: 26.2s\n",
      "2197:\tlearn: 2.1743568\ttotal: 24s\tremaining: 26.2s\n",
      "2198:\tlearn: 2.1739303\ttotal: 24s\tremaining: 26.2s\n",
      "2199:\tlearn: 2.1736050\ttotal: 24s\tremaining: 26.2s\n",
      "2200:\tlearn: 2.1731853\ttotal: 24s\tremaining: 26.2s\n",
      "2201:\tlearn: 2.1728700\ttotal: 24s\tremaining: 26.2s\n",
      "2202:\tlearn: 2.1724516\ttotal: 24.1s\tremaining: 26.2s\n",
      "2203:\tlearn: 2.1719017\ttotal: 24.1s\tremaining: 26.1s\n",
      "2204:\tlearn: 2.1713775\ttotal: 24.1s\tremaining: 26.1s\n",
      "2205:\tlearn: 2.1709622\ttotal: 24.1s\tremaining: 26.1s\n",
      "2206:\tlearn: 2.1708375\ttotal: 24.1s\tremaining: 26.1s\n",
      "2207:\tlearn: 2.1705214\ttotal: 24.1s\tremaining: 26.1s\n",
      "2208:\tlearn: 2.1700163\ttotal: 24.1s\tremaining: 26.1s\n",
      "2209:\tlearn: 2.1698515\ttotal: 24.1s\tremaining: 26.1s\n",
      "2210:\tlearn: 2.1695166\ttotal: 24.1s\tremaining: 26.1s\n",
      "2211:\tlearn: 2.1691679\ttotal: 24.2s\tremaining: 26.1s\n",
      "2212:\tlearn: 2.1688431\ttotal: 24.2s\tremaining: 26s\n",
      "2213:\tlearn: 2.1683974\ttotal: 24.2s\tremaining: 26s\n",
      "2214:\tlearn: 2.1682095\ttotal: 24.2s\tremaining: 26s\n",
      "2215:\tlearn: 2.1679144\ttotal: 24.2s\tremaining: 26s\n",
      "2216:\tlearn: 2.1676915\ttotal: 24.2s\tremaining: 26s\n",
      "2217:\tlearn: 2.1671203\ttotal: 24.2s\tremaining: 26s\n",
      "2218:\tlearn: 2.1668052\ttotal: 24.2s\tremaining: 26s\n",
      "2219:\tlearn: 2.1664510\ttotal: 24.2s\tremaining: 26s\n",
      "2220:\tlearn: 2.1657770\ttotal: 24.2s\tremaining: 26s\n",
      "2221:\tlearn: 2.1656679\ttotal: 24.3s\tremaining: 25.9s\n",
      "2222:\tlearn: 2.1654125\ttotal: 24.3s\tremaining: 25.9s\n",
      "2223:\tlearn: 2.1649960\ttotal: 24.3s\tremaining: 25.9s\n",
      "2224:\tlearn: 2.1644558\ttotal: 24.3s\tremaining: 25.9s\n",
      "2225:\tlearn: 2.1639350\ttotal: 24.3s\tremaining: 25.9s\n",
      "2226:\tlearn: 2.1635819\ttotal: 24.3s\tremaining: 25.9s\n",
      "2227:\tlearn: 2.1630749\ttotal: 24.3s\tremaining: 25.9s\n",
      "2228:\tlearn: 2.1625519\ttotal: 24.3s\tremaining: 25.9s\n",
      "2229:\tlearn: 2.1623016\ttotal: 24.3s\tremaining: 25.9s\n",
      "2230:\tlearn: 2.1616323\ttotal: 24.4s\tremaining: 25.8s\n",
      "2231:\tlearn: 2.1614631\ttotal: 24.4s\tremaining: 25.8s\n",
      "2232:\tlearn: 2.1608259\ttotal: 24.4s\tremaining: 25.8s\n",
      "2233:\tlearn: 2.1601979\ttotal: 24.4s\tremaining: 25.8s\n",
      "2234:\tlearn: 2.1596536\ttotal: 24.4s\tremaining: 25.8s\n",
      "2235:\tlearn: 2.1591920\ttotal: 24.4s\tremaining: 25.8s\n",
      "2236:\tlearn: 2.1588553\ttotal: 24.4s\tremaining: 25.8s\n",
      "2237:\tlearn: 2.1586132\ttotal: 24.4s\tremaining: 25.8s\n",
      "2238:\tlearn: 2.1582553\ttotal: 24.4s\tremaining: 25.8s\n",
      "2239:\tlearn: 2.1579256\ttotal: 24.5s\tremaining: 25.7s\n",
      "2240:\tlearn: 2.1576642\ttotal: 24.5s\tremaining: 25.7s\n",
      "2241:\tlearn: 2.1574796\ttotal: 24.5s\tremaining: 25.7s\n",
      "2242:\tlearn: 2.1570410\ttotal: 24.5s\tremaining: 25.7s\n",
      "2243:\tlearn: 2.1568174\ttotal: 24.5s\tremaining: 25.7s\n",
      "2244:\tlearn: 2.1563563\ttotal: 24.5s\tremaining: 25.7s\n",
      "2245:\tlearn: 2.1558226\ttotal: 24.5s\tremaining: 25.7s\n",
      "2246:\tlearn: 2.1555108\ttotal: 24.5s\tremaining: 25.7s\n",
      "2247:\tlearn: 2.1551184\ttotal: 24.5s\tremaining: 25.7s\n",
      "2248:\tlearn: 2.1545644\ttotal: 24.6s\tremaining: 25.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2249:\tlearn: 2.1541294\ttotal: 24.6s\tremaining: 25.6s\n",
      "2250:\tlearn: 2.1537081\ttotal: 24.6s\tremaining: 25.6s\n",
      "2251:\tlearn: 2.1533899\ttotal: 24.6s\tremaining: 25.6s\n",
      "2252:\tlearn: 2.1529173\ttotal: 24.6s\tremaining: 25.6s\n",
      "2253:\tlearn: 2.1526815\ttotal: 24.6s\tremaining: 25.6s\n",
      "2254:\tlearn: 2.1522757\ttotal: 24.6s\tremaining: 25.6s\n",
      "2255:\tlearn: 2.1520220\ttotal: 24.6s\tremaining: 25.6s\n",
      "2256:\tlearn: 2.1518422\ttotal: 24.6s\tremaining: 25.6s\n",
      "2257:\tlearn: 2.1516264\ttotal: 24.7s\tremaining: 25.5s\n",
      "2258:\tlearn: 2.1511709\ttotal: 24.7s\tremaining: 25.5s\n",
      "2259:\tlearn: 2.1507406\ttotal: 24.7s\tremaining: 25.5s\n",
      "2260:\tlearn: 2.1502846\ttotal: 24.7s\tremaining: 25.5s\n",
      "2261:\tlearn: 2.1500409\ttotal: 24.7s\tremaining: 25.5s\n",
      "2262:\tlearn: 2.1497008\ttotal: 24.7s\tremaining: 25.5s\n",
      "2263:\tlearn: 2.1492066\ttotal: 24.7s\tremaining: 25.5s\n",
      "2264:\tlearn: 2.1486701\ttotal: 24.7s\tremaining: 25.5s\n",
      "2265:\tlearn: 2.1483449\ttotal: 24.7s\tremaining: 25.5s\n",
      "2266:\tlearn: 2.1479220\ttotal: 24.7s\tremaining: 25.4s\n",
      "2267:\tlearn: 2.1471953\ttotal: 24.8s\tremaining: 25.4s\n",
      "2268:\tlearn: 2.1466947\ttotal: 24.8s\tremaining: 25.4s\n",
      "2269:\tlearn: 2.1463897\ttotal: 24.8s\tremaining: 25.4s\n",
      "2270:\tlearn: 2.1460940\ttotal: 24.8s\tremaining: 25.4s\n",
      "2271:\tlearn: 2.1458830\ttotal: 24.8s\tremaining: 25.4s\n",
      "2272:\tlearn: 2.1452537\ttotal: 24.8s\tremaining: 25.4s\n",
      "2273:\tlearn: 2.1449720\ttotal: 24.8s\tremaining: 25.4s\n",
      "2274:\tlearn: 2.1447439\ttotal: 24.8s\tremaining: 25.4s\n",
      "2275:\tlearn: 2.1443867\ttotal: 24.8s\tremaining: 25.4s\n",
      "2276:\tlearn: 2.1440646\ttotal: 24.9s\tremaining: 25.3s\n",
      "2277:\tlearn: 2.1438371\ttotal: 24.9s\tremaining: 25.3s\n",
      "2278:\tlearn: 2.1435068\ttotal: 24.9s\tremaining: 25.3s\n",
      "2279:\tlearn: 2.1431682\ttotal: 24.9s\tremaining: 25.3s\n",
      "2280:\tlearn: 2.1426692\ttotal: 24.9s\tremaining: 25.3s\n",
      "2281:\tlearn: 2.1421415\ttotal: 24.9s\tremaining: 25.3s\n",
      "2282:\tlearn: 2.1418897\ttotal: 24.9s\tremaining: 25.3s\n",
      "2283:\tlearn: 2.1416492\ttotal: 24.9s\tremaining: 25.3s\n",
      "2284:\tlearn: 2.1413339\ttotal: 24.9s\tremaining: 25.3s\n",
      "2285:\tlearn: 2.1409733\ttotal: 25s\tremaining: 25.2s\n",
      "2286:\tlearn: 2.1406247\ttotal: 25s\tremaining: 25.2s\n",
      "2287:\tlearn: 2.1401751\ttotal: 25s\tremaining: 25.2s\n",
      "2288:\tlearn: 2.1397603\ttotal: 25s\tremaining: 25.2s\n",
      "2289:\tlearn: 2.1389032\ttotal: 25s\tremaining: 25.2s\n",
      "2290:\tlearn: 2.1382006\ttotal: 25s\tremaining: 25.2s\n",
      "2291:\tlearn: 2.1379106\ttotal: 25s\tremaining: 25.2s\n",
      "2292:\tlearn: 2.1375926\ttotal: 25s\tremaining: 25.2s\n",
      "2293:\tlearn: 2.1369021\ttotal: 25s\tremaining: 25.2s\n",
      "2294:\tlearn: 2.1365218\ttotal: 25.1s\tremaining: 25.1s\n",
      "2295:\tlearn: 2.1360319\ttotal: 25.1s\tremaining: 25.1s\n",
      "2296:\tlearn: 2.1357675\ttotal: 25.1s\tremaining: 25.1s\n",
      "2297:\tlearn: 2.1350824\ttotal: 25.1s\tremaining: 25.1s\n",
      "2298:\tlearn: 2.1348339\ttotal: 25.1s\tremaining: 25.1s\n",
      "2299:\tlearn: 2.1344043\ttotal: 25.1s\tremaining: 25.1s\n",
      "2300:\tlearn: 2.1340456\ttotal: 25.1s\tremaining: 25.1s\n",
      "2301:\tlearn: 2.1337357\ttotal: 25.1s\tremaining: 25.1s\n",
      "2302:\tlearn: 2.1334772\ttotal: 25.1s\tremaining: 25.1s\n",
      "2303:\tlearn: 2.1332552\ttotal: 25.2s\tremaining: 25s\n",
      "2304:\tlearn: 2.1326968\ttotal: 25.2s\tremaining: 25s\n",
      "2305:\tlearn: 2.1319598\ttotal: 25.2s\tremaining: 25s\n",
      "2306:\tlearn: 2.1314077\ttotal: 25.2s\tremaining: 25s\n",
      "2307:\tlearn: 2.1310184\ttotal: 25.2s\tremaining: 25s\n",
      "2308:\tlearn: 2.1306702\ttotal: 25.2s\tremaining: 25s\n",
      "2309:\tlearn: 2.1303665\ttotal: 25.2s\tremaining: 25s\n",
      "2310:\tlearn: 2.1300823\ttotal: 25.2s\tremaining: 25s\n",
      "2311:\tlearn: 2.1297950\ttotal: 25.2s\tremaining: 25s\n",
      "2312:\tlearn: 2.1293620\ttotal: 25.3s\tremaining: 24.9s\n",
      "2313:\tlearn: 2.1289589\ttotal: 25.3s\tremaining: 24.9s\n",
      "2314:\tlearn: 2.1284949\ttotal: 25.3s\tremaining: 24.9s\n",
      "2315:\tlearn: 2.1278747\ttotal: 25.3s\tremaining: 24.9s\n",
      "2316:\tlearn: 2.1276404\ttotal: 25.3s\tremaining: 24.9s\n",
      "2317:\tlearn: 2.1273668\ttotal: 25.3s\tremaining: 24.9s\n",
      "2318:\tlearn: 2.1265436\ttotal: 25.3s\tremaining: 24.9s\n",
      "2319:\tlearn: 2.1262697\ttotal: 25.3s\tremaining: 24.9s\n",
      "2320:\tlearn: 2.1257720\ttotal: 25.3s\tremaining: 24.9s\n",
      "2321:\tlearn: 2.1254326\ttotal: 25.4s\tremaining: 24.9s\n",
      "2322:\tlearn: 2.1249984\ttotal: 25.4s\tremaining: 24.8s\n",
      "2323:\tlearn: 2.1247541\ttotal: 25.4s\tremaining: 24.8s\n",
      "2324:\tlearn: 2.1244712\ttotal: 25.4s\tremaining: 24.8s\n",
      "2325:\tlearn: 2.1236998\ttotal: 25.4s\tremaining: 24.8s\n",
      "2326:\tlearn: 2.1231483\ttotal: 25.4s\tremaining: 24.8s\n",
      "2327:\tlearn: 2.1225332\ttotal: 25.4s\tremaining: 24.8s\n",
      "2328:\tlearn: 2.1223732\ttotal: 25.4s\tremaining: 24.8s\n",
      "2329:\tlearn: 2.1217361\ttotal: 25.4s\tremaining: 24.8s\n",
      "2330:\tlearn: 2.1215866\ttotal: 25.5s\tremaining: 24.8s\n",
      "2331:\tlearn: 2.1209397\ttotal: 25.5s\tremaining: 24.8s\n",
      "2332:\tlearn: 2.1202969\ttotal: 25.5s\tremaining: 24.7s\n",
      "2333:\tlearn: 2.1198324\ttotal: 25.5s\tremaining: 24.7s\n",
      "2334:\tlearn: 2.1196122\ttotal: 25.5s\tremaining: 24.7s\n",
      "2335:\tlearn: 2.1194786\ttotal: 25.5s\tremaining: 24.7s\n",
      "2336:\tlearn: 2.1190495\ttotal: 25.5s\tremaining: 24.7s\n",
      "2337:\tlearn: 2.1187813\ttotal: 25.5s\tremaining: 24.7s\n",
      "2338:\tlearn: 2.1182603\ttotal: 25.5s\tremaining: 24.7s\n",
      "2339:\tlearn: 2.1178007\ttotal: 25.6s\tremaining: 24.7s\n",
      "2340:\tlearn: 2.1171499\ttotal: 25.6s\tremaining: 24.7s\n",
      "2341:\tlearn: 2.1167638\ttotal: 25.6s\tremaining: 24.6s\n",
      "2342:\tlearn: 2.1165654\ttotal: 25.6s\tremaining: 24.6s\n",
      "2343:\tlearn: 2.1161893\ttotal: 25.6s\tremaining: 24.6s\n",
      "2344:\tlearn: 2.1159490\ttotal: 25.6s\tremaining: 24.6s\n",
      "2345:\tlearn: 2.1155540\ttotal: 25.6s\tremaining: 24.6s\n",
      "2346:\tlearn: 2.1151042\ttotal: 25.6s\tremaining: 24.6s\n",
      "2347:\tlearn: 2.1147026\ttotal: 25.7s\tremaining: 24.6s\n",
      "2348:\tlearn: 2.1143964\ttotal: 25.7s\tremaining: 24.6s\n",
      "2349:\tlearn: 2.1142211\ttotal: 25.7s\tremaining: 24.6s\n",
      "2350:\tlearn: 2.1138172\ttotal: 25.7s\tremaining: 24.5s\n",
      "2351:\tlearn: 2.1136316\ttotal: 25.7s\tremaining: 24.5s\n",
      "2352:\tlearn: 2.1129347\ttotal: 25.7s\tremaining: 24.5s\n",
      "2353:\tlearn: 2.1122617\ttotal: 25.7s\tremaining: 24.5s\n",
      "2354:\tlearn: 2.1119571\ttotal: 25.7s\tremaining: 24.5s\n",
      "2355:\tlearn: 2.1115465\ttotal: 25.7s\tremaining: 24.5s\n",
      "2356:\tlearn: 2.1111313\ttotal: 25.8s\tremaining: 24.5s\n",
      "2357:\tlearn: 2.1109226\ttotal: 25.8s\tremaining: 24.5s\n",
      "2358:\tlearn: 2.1105665\ttotal: 25.8s\tremaining: 24.5s\n",
      "2359:\tlearn: 2.1100972\ttotal: 25.8s\tremaining: 24.5s\n",
      "2360:\tlearn: 2.1098289\ttotal: 25.8s\tremaining: 24.4s\n",
      "2361:\tlearn: 2.1095340\ttotal: 25.8s\tremaining: 24.4s\n",
      "2362:\tlearn: 2.1091250\ttotal: 25.8s\tremaining: 24.4s\n",
      "2363:\tlearn: 2.1088062\ttotal: 25.8s\tremaining: 24.4s\n",
      "2364:\tlearn: 2.1083915\ttotal: 25.8s\tremaining: 24.4s\n",
      "2365:\tlearn: 2.1081274\ttotal: 25.9s\tremaining: 24.4s\n",
      "2366:\tlearn: 2.1076751\ttotal: 25.9s\tremaining: 24.4s\n",
      "2367:\tlearn: 2.1071086\ttotal: 25.9s\tremaining: 24.4s\n",
      "2368:\tlearn: 2.1065983\ttotal: 25.9s\tremaining: 24.4s\n",
      "2369:\tlearn: 2.1064025\ttotal: 25.9s\tremaining: 24.3s\n",
      "2370:\tlearn: 2.1060789\ttotal: 25.9s\tremaining: 24.3s\n",
      "2371:\tlearn: 2.1055820\ttotal: 25.9s\tremaining: 24.3s\n",
      "2372:\tlearn: 2.1048006\ttotal: 25.9s\tremaining: 24.3s\n",
      "2373:\tlearn: 2.1042044\ttotal: 25.9s\tremaining: 24.3s\n",
      "2374:\tlearn: 2.1039311\ttotal: 25.9s\tremaining: 24.3s\n",
      "2375:\tlearn: 2.1034262\ttotal: 26s\tremaining: 24.3s\n",
      "2376:\tlearn: 2.1029284\ttotal: 26s\tremaining: 24.3s\n",
      "2377:\tlearn: 2.1026248\ttotal: 26s\tremaining: 24.3s\n",
      "2378:\tlearn: 2.1022319\ttotal: 26s\tremaining: 24.2s\n",
      "2379:\tlearn: 2.1021628\ttotal: 26s\tremaining: 24.2s\n",
      "2380:\tlearn: 2.1019707\ttotal: 26s\tremaining: 24.2s\n",
      "2381:\tlearn: 2.1017505\ttotal: 26s\tremaining: 24.2s\n",
      "2382:\tlearn: 2.1014728\ttotal: 26.1s\tremaining: 24.2s\n",
      "2383:\tlearn: 2.1011144\ttotal: 26.1s\tremaining: 24.2s\n",
      "2384:\tlearn: 2.1009888\ttotal: 26.1s\tremaining: 24.2s\n",
      "2385:\tlearn: 2.1006603\ttotal: 26.1s\tremaining: 24.2s\n",
      "2386:\tlearn: 2.1001560\ttotal: 26.1s\tremaining: 24.2s\n",
      "2387:\tlearn: 2.1000388\ttotal: 26.1s\tremaining: 24.2s\n",
      "2388:\tlearn: 2.0997339\ttotal: 26.1s\tremaining: 24.2s\n",
      "2389:\tlearn: 2.0994501\ttotal: 26.1s\tremaining: 24.1s\n",
      "2390:\tlearn: 2.0989196\ttotal: 26.1s\tremaining: 24.1s\n",
      "2391:\tlearn: 2.0986995\ttotal: 26.2s\tremaining: 24.1s\n",
      "2392:\tlearn: 2.0982400\ttotal: 26.2s\tremaining: 24.1s\n",
      "2393:\tlearn: 2.0979004\ttotal: 26.2s\tremaining: 24.1s\n",
      "2394:\tlearn: 2.0975608\ttotal: 26.2s\tremaining: 24.1s\n",
      "2395:\tlearn: 2.0967678\ttotal: 26.2s\tremaining: 24.1s\n",
      "2396:\tlearn: 2.0961636\ttotal: 26.2s\tremaining: 24.1s\n",
      "2397:\tlearn: 2.0958163\ttotal: 26.2s\tremaining: 24.1s\n",
      "2398:\tlearn: 2.0951570\ttotal: 26.2s\tremaining: 24.1s\n",
      "2399:\tlearn: 2.0949794\ttotal: 26.3s\tremaining: 24s\n",
      "2400:\tlearn: 2.0944662\ttotal: 26.3s\tremaining: 24s\n",
      "2401:\tlearn: 2.0940817\ttotal: 26.3s\tremaining: 24s\n",
      "2402:\tlearn: 2.0935327\ttotal: 26.3s\tremaining: 24s\n",
      "2403:\tlearn: 2.0930401\ttotal: 26.3s\tremaining: 24s\n",
      "2404:\tlearn: 2.0926259\ttotal: 26.3s\tremaining: 24s\n",
      "2405:\tlearn: 2.0924309\ttotal: 26.3s\tremaining: 24s\n",
      "2406:\tlearn: 2.0918885\ttotal: 26.3s\tremaining: 24s\n",
      "2407:\tlearn: 2.0917100\ttotal: 26.4s\tremaining: 24s\n",
      "2408:\tlearn: 2.0912102\ttotal: 26.4s\tremaining: 24s\n",
      "2409:\tlearn: 2.0908505\ttotal: 26.4s\tremaining: 23.9s\n",
      "2410:\tlearn: 2.0903916\ttotal: 26.4s\tremaining: 23.9s\n",
      "2411:\tlearn: 2.0902170\ttotal: 26.4s\tremaining: 23.9s\n",
      "2412:\tlearn: 2.0899927\ttotal: 26.4s\tremaining: 23.9s\n",
      "2413:\tlearn: 2.0894440\ttotal: 26.4s\tremaining: 23.9s\n",
      "2414:\tlearn: 2.0889305\ttotal: 26.4s\tremaining: 23.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2415:\tlearn: 2.0886379\ttotal: 26.4s\tremaining: 23.9s\n",
      "2416:\tlearn: 2.0882772\ttotal: 26.5s\tremaining: 23.9s\n",
      "2417:\tlearn: 2.0878892\ttotal: 26.5s\tremaining: 23.9s\n",
      "2418:\tlearn: 2.0876222\ttotal: 26.5s\tremaining: 23.9s\n",
      "2419:\tlearn: 2.0873021\ttotal: 26.5s\tremaining: 23.8s\n",
      "2420:\tlearn: 2.0872710\ttotal: 26.5s\tremaining: 23.8s\n",
      "2421:\tlearn: 2.0870897\ttotal: 26.5s\tremaining: 23.8s\n",
      "2422:\tlearn: 2.0867020\ttotal: 26.5s\tremaining: 23.8s\n",
      "2423:\tlearn: 2.0863974\ttotal: 26.5s\tremaining: 23.8s\n",
      "2424:\tlearn: 2.0860792\ttotal: 26.5s\tremaining: 23.8s\n",
      "2425:\tlearn: 2.0858067\ttotal: 26.6s\tremaining: 23.8s\n",
      "2426:\tlearn: 2.0855475\ttotal: 26.6s\tremaining: 23.8s\n",
      "2427:\tlearn: 2.0848162\ttotal: 26.6s\tremaining: 23.8s\n",
      "2428:\tlearn: 2.0843099\ttotal: 26.6s\tremaining: 23.7s\n",
      "2429:\tlearn: 2.0838013\ttotal: 26.6s\tremaining: 23.7s\n",
      "2430:\tlearn: 2.0833455\ttotal: 26.6s\tremaining: 23.7s\n",
      "2431:\tlearn: 2.0828828\ttotal: 26.6s\tremaining: 23.7s\n",
      "2432:\tlearn: 2.0825817\ttotal: 26.6s\tremaining: 23.7s\n",
      "2433:\tlearn: 2.0824908\ttotal: 26.6s\tremaining: 23.7s\n",
      "2434:\tlearn: 2.0820965\ttotal: 26.7s\tremaining: 23.7s\n",
      "2435:\tlearn: 2.0816982\ttotal: 26.7s\tremaining: 23.7s\n",
      "2436:\tlearn: 2.0813125\ttotal: 26.7s\tremaining: 23.7s\n",
      "2437:\tlearn: 2.0813099\ttotal: 26.7s\tremaining: 23.6s\n",
      "2438:\tlearn: 2.0806974\ttotal: 26.7s\tremaining: 23.6s\n",
      "2439:\tlearn: 2.0803318\ttotal: 26.7s\tremaining: 23.6s\n",
      "2440:\tlearn: 2.0800155\ttotal: 26.7s\tremaining: 23.6s\n",
      "2441:\tlearn: 2.0797553\ttotal: 26.7s\tremaining: 23.6s\n",
      "2442:\tlearn: 2.0794987\ttotal: 26.7s\tremaining: 23.6s\n",
      "2443:\tlearn: 2.0793627\ttotal: 26.8s\tremaining: 23.6s\n",
      "2444:\tlearn: 2.0790716\ttotal: 26.8s\tremaining: 23.6s\n",
      "2445:\tlearn: 2.0786723\ttotal: 26.8s\tremaining: 23.6s\n",
      "2446:\tlearn: 2.0782972\ttotal: 26.8s\tremaining: 23.5s\n",
      "2447:\tlearn: 2.0777669\ttotal: 26.8s\tremaining: 23.5s\n",
      "2448:\tlearn: 2.0773315\ttotal: 26.8s\tremaining: 23.5s\n",
      "2449:\tlearn: 2.0769428\ttotal: 26.8s\tremaining: 23.5s\n",
      "2450:\tlearn: 2.0764582\ttotal: 26.8s\tremaining: 23.5s\n",
      "2451:\tlearn: 2.0761788\ttotal: 26.8s\tremaining: 23.5s\n",
      "2452:\tlearn: 2.0757627\ttotal: 26.8s\tremaining: 23.5s\n",
      "2453:\tlearn: 2.0755934\ttotal: 26.9s\tremaining: 23.5s\n",
      "2454:\tlearn: 2.0752054\ttotal: 26.9s\tremaining: 23.5s\n",
      "2455:\tlearn: 2.0750640\ttotal: 26.9s\tremaining: 23.4s\n",
      "2456:\tlearn: 2.0745024\ttotal: 26.9s\tremaining: 23.4s\n",
      "2457:\tlearn: 2.0741070\ttotal: 26.9s\tremaining: 23.4s\n",
      "2458:\tlearn: 2.0736734\ttotal: 26.9s\tremaining: 23.4s\n",
      "2459:\tlearn: 2.0736697\ttotal: 26.9s\tremaining: 23.4s\n",
      "2460:\tlearn: 2.0734975\ttotal: 26.9s\tremaining: 23.4s\n",
      "2461:\tlearn: 2.0732842\ttotal: 26.9s\tremaining: 23.4s\n",
      "2462:\tlearn: 2.0729436\ttotal: 27s\tremaining: 23.4s\n",
      "2463:\tlearn: 2.0726501\ttotal: 27s\tremaining: 23.4s\n",
      "2464:\tlearn: 2.0722465\ttotal: 27s\tremaining: 23.3s\n",
      "2465:\tlearn: 2.0717672\ttotal: 27s\tremaining: 23.3s\n",
      "2466:\tlearn: 2.0715918\ttotal: 27s\tremaining: 23.3s\n",
      "2467:\tlearn: 2.0713900\ttotal: 27s\tremaining: 23.3s\n",
      "2468:\tlearn: 2.0710745\ttotal: 27s\tremaining: 23.3s\n",
      "2469:\tlearn: 2.0706835\ttotal: 27s\tremaining: 23.3s\n",
      "2470:\tlearn: 2.0703054\ttotal: 27s\tremaining: 23.3s\n",
      "2471:\tlearn: 2.0697648\ttotal: 27.1s\tremaining: 23.3s\n",
      "2472:\tlearn: 2.0693800\ttotal: 27.1s\tremaining: 23.3s\n",
      "2473:\tlearn: 2.0689980\ttotal: 27.1s\tremaining: 23.2s\n",
      "2474:\tlearn: 2.0686225\ttotal: 27.1s\tremaining: 23.2s\n",
      "2475:\tlearn: 2.0681580\ttotal: 27.1s\tremaining: 23.2s\n",
      "2476:\tlearn: 2.0677673\ttotal: 27.1s\tremaining: 23.2s\n",
      "2477:\tlearn: 2.0675297\ttotal: 27.1s\tremaining: 23.2s\n",
      "2478:\tlearn: 2.0672482\ttotal: 27.1s\tremaining: 23.2s\n",
      "2479:\tlearn: 2.0666661\ttotal: 27.1s\tremaining: 23.2s\n",
      "2480:\tlearn: 2.0660568\ttotal: 27.2s\tremaining: 23.2s\n",
      "2481:\tlearn: 2.0657095\ttotal: 27.2s\tremaining: 23.2s\n",
      "2482:\tlearn: 2.0653635\ttotal: 27.2s\tremaining: 23.1s\n",
      "2483:\tlearn: 2.0651683\ttotal: 27.2s\tremaining: 23.1s\n",
      "2484:\tlearn: 2.0649804\ttotal: 27.2s\tremaining: 23.1s\n",
      "2485:\tlearn: 2.0646598\ttotal: 27.2s\tremaining: 23.1s\n",
      "2486:\tlearn: 2.0643216\ttotal: 27.2s\tremaining: 23.1s\n",
      "2487:\tlearn: 2.0640829\ttotal: 27.2s\tremaining: 23.1s\n",
      "2488:\tlearn: 2.0636000\ttotal: 27.2s\tremaining: 23.1s\n",
      "2489:\tlearn: 2.0630602\ttotal: 27.2s\tremaining: 23.1s\n",
      "2490:\tlearn: 2.0625963\ttotal: 27.3s\tremaining: 23.1s\n",
      "2491:\tlearn: 2.0623782\ttotal: 27.3s\tremaining: 23s\n",
      "2492:\tlearn: 2.0620845\ttotal: 27.3s\tremaining: 23s\n",
      "2493:\tlearn: 2.0617926\ttotal: 27.3s\tremaining: 23s\n",
      "2494:\tlearn: 2.0614005\ttotal: 27.3s\tremaining: 23s\n",
      "2495:\tlearn: 2.0610742\ttotal: 27.3s\tremaining: 23s\n",
      "2496:\tlearn: 2.0606890\ttotal: 27.3s\tremaining: 23s\n",
      "2497:\tlearn: 2.0600375\ttotal: 27.3s\tremaining: 23s\n",
      "2498:\tlearn: 2.0597543\ttotal: 27.4s\tremaining: 23s\n",
      "2499:\tlearn: 2.0593145\ttotal: 27.4s\tremaining: 23s\n",
      "2500:\tlearn: 2.0589922\ttotal: 27.4s\tremaining: 23s\n",
      "2501:\tlearn: 2.0583532\ttotal: 27.4s\tremaining: 22.9s\n",
      "2502:\tlearn: 2.0581921\ttotal: 27.4s\tremaining: 22.9s\n",
      "2503:\tlearn: 2.0580049\ttotal: 27.4s\tremaining: 22.9s\n",
      "2504:\tlearn: 2.0575571\ttotal: 27.4s\tremaining: 22.9s\n",
      "2505:\tlearn: 2.0571549\ttotal: 27.4s\tremaining: 22.9s\n",
      "2506:\tlearn: 2.0567360\ttotal: 27.4s\tremaining: 22.9s\n",
      "2507:\tlearn: 2.0560288\ttotal: 27.4s\tremaining: 22.9s\n",
      "2508:\tlearn: 2.0557401\ttotal: 27.5s\tremaining: 22.9s\n",
      "2509:\tlearn: 2.0554618\ttotal: 27.5s\tremaining: 22.8s\n",
      "2510:\tlearn: 2.0552097\ttotal: 27.5s\tremaining: 22.8s\n",
      "2511:\tlearn: 2.0547558\ttotal: 27.5s\tremaining: 22.8s\n",
      "2512:\tlearn: 2.0543627\ttotal: 27.5s\tremaining: 22.8s\n",
      "2513:\tlearn: 2.0538261\ttotal: 27.5s\tremaining: 22.8s\n",
      "2514:\tlearn: 2.0532840\ttotal: 27.5s\tremaining: 22.8s\n",
      "2515:\tlearn: 2.0526394\ttotal: 27.5s\tremaining: 22.8s\n",
      "2516:\tlearn: 2.0524318\ttotal: 27.5s\tremaining: 22.8s\n",
      "2517:\tlearn: 2.0519363\ttotal: 27.6s\tremaining: 22.8s\n",
      "2518:\tlearn: 2.0517531\ttotal: 27.6s\tremaining: 22.8s\n",
      "2519:\tlearn: 2.0514251\ttotal: 27.6s\tremaining: 22.7s\n",
      "2520:\tlearn: 2.0511132\ttotal: 27.6s\tremaining: 22.7s\n",
      "2521:\tlearn: 2.0508537\ttotal: 27.6s\tremaining: 22.7s\n",
      "2522:\tlearn: 2.0505762\ttotal: 27.6s\tremaining: 22.7s\n",
      "2523:\tlearn: 2.0500406\ttotal: 27.6s\tremaining: 22.7s\n",
      "2524:\tlearn: 2.0496916\ttotal: 27.6s\tremaining: 22.7s\n",
      "2525:\tlearn: 2.0494913\ttotal: 27.6s\tremaining: 22.7s\n",
      "2526:\tlearn: 2.0492365\ttotal: 27.7s\tremaining: 22.7s\n",
      "2527:\tlearn: 2.0489554\ttotal: 27.7s\tremaining: 22.7s\n",
      "2528:\tlearn: 2.0485231\ttotal: 27.7s\tremaining: 22.6s\n",
      "2529:\tlearn: 2.0481978\ttotal: 27.7s\tremaining: 22.6s\n",
      "2530:\tlearn: 2.0477290\ttotal: 27.7s\tremaining: 22.6s\n",
      "2531:\tlearn: 2.0473520\ttotal: 27.7s\tremaining: 22.6s\n",
      "2532:\tlearn: 2.0472745\ttotal: 27.7s\tremaining: 22.6s\n",
      "2533:\tlearn: 2.0467574\ttotal: 27.7s\tremaining: 22.6s\n",
      "2534:\tlearn: 2.0464328\ttotal: 27.7s\tremaining: 22.6s\n",
      "2535:\tlearn: 2.0457114\ttotal: 27.8s\tremaining: 22.6s\n",
      "2536:\tlearn: 2.0453800\ttotal: 27.8s\tremaining: 22.6s\n",
      "2537:\tlearn: 2.0451635\ttotal: 27.8s\tremaining: 22.5s\n",
      "2538:\tlearn: 2.0448401\ttotal: 27.8s\tremaining: 22.5s\n",
      "2539:\tlearn: 2.0443847\ttotal: 27.8s\tremaining: 22.5s\n",
      "2540:\tlearn: 2.0439389\ttotal: 27.8s\tremaining: 22.5s\n",
      "2541:\tlearn: 2.0436898\ttotal: 27.8s\tremaining: 22.5s\n",
      "2542:\tlearn: 2.0434237\ttotal: 27.8s\tremaining: 22.5s\n",
      "2543:\tlearn: 2.0431650\ttotal: 27.8s\tremaining: 22.5s\n",
      "2544:\tlearn: 2.0428974\ttotal: 27.9s\tremaining: 22.5s\n",
      "2545:\tlearn: 2.0423862\ttotal: 27.9s\tremaining: 22.5s\n",
      "2546:\tlearn: 2.0421963\ttotal: 27.9s\tremaining: 22.4s\n",
      "2547:\tlearn: 2.0418694\ttotal: 27.9s\tremaining: 22.4s\n",
      "2548:\tlearn: 2.0415002\ttotal: 27.9s\tremaining: 22.4s\n",
      "2549:\tlearn: 2.0413454\ttotal: 27.9s\tremaining: 22.4s\n",
      "2550:\tlearn: 2.0408617\ttotal: 27.9s\tremaining: 22.4s\n",
      "2551:\tlearn: 2.0402647\ttotal: 27.9s\tremaining: 22.4s\n",
      "2552:\tlearn: 2.0398935\ttotal: 27.9s\tremaining: 22.4s\n",
      "2553:\tlearn: 2.0396830\ttotal: 27.9s\tremaining: 22.4s\n",
      "2554:\tlearn: 2.0395449\ttotal: 28s\tremaining: 22.4s\n",
      "2555:\tlearn: 2.0390540\ttotal: 28s\tremaining: 22.3s\n",
      "2556:\tlearn: 2.0387786\ttotal: 28s\tremaining: 22.3s\n",
      "2557:\tlearn: 2.0384200\ttotal: 28s\tremaining: 22.3s\n",
      "2558:\tlearn: 2.0380005\ttotal: 28s\tremaining: 22.3s\n",
      "2559:\tlearn: 2.0375025\ttotal: 28s\tremaining: 22.3s\n",
      "2560:\tlearn: 2.0372852\ttotal: 28s\tremaining: 22.3s\n",
      "2561:\tlearn: 2.0368778\ttotal: 28s\tremaining: 22.3s\n",
      "2562:\tlearn: 2.0365966\ttotal: 28s\tremaining: 22.3s\n",
      "2563:\tlearn: 2.0361463\ttotal: 28.1s\tremaining: 22.3s\n",
      "2564:\tlearn: 2.0357614\ttotal: 28.1s\tremaining: 22.2s\n",
      "2565:\tlearn: 2.0357599\ttotal: 28.1s\tremaining: 22.2s\n",
      "2566:\tlearn: 2.0355553\ttotal: 28.1s\tremaining: 22.2s\n",
      "2567:\tlearn: 2.0348565\ttotal: 28.1s\tremaining: 22.2s\n",
      "2568:\tlearn: 2.0343661\ttotal: 28.1s\tremaining: 22.2s\n",
      "2569:\tlearn: 2.0339727\ttotal: 28.1s\tremaining: 22.2s\n",
      "2570:\tlearn: 2.0335870\ttotal: 28.1s\tremaining: 22.2s\n",
      "2571:\tlearn: 2.0331934\ttotal: 28.1s\tremaining: 22.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572:\tlearn: 2.0327684\ttotal: 28.2s\tremaining: 22.2s\n",
      "2573:\tlearn: 2.0325424\ttotal: 28.2s\tremaining: 22.1s\n",
      "2574:\tlearn: 2.0322492\ttotal: 28.2s\tremaining: 22.1s\n",
      "2575:\tlearn: 2.0321222\ttotal: 28.2s\tremaining: 22.1s\n",
      "2576:\tlearn: 2.0316759\ttotal: 28.2s\tremaining: 22.1s\n",
      "2577:\tlearn: 2.0314372\ttotal: 28.2s\tremaining: 22.1s\n",
      "2578:\tlearn: 2.0314057\ttotal: 28.2s\tremaining: 22.1s\n",
      "2579:\tlearn: 2.0310693\ttotal: 28.2s\tremaining: 22.1s\n",
      "2580:\tlearn: 2.0308866\ttotal: 28.2s\tremaining: 22.1s\n",
      "2581:\tlearn: 2.0305432\ttotal: 28.2s\tremaining: 22.1s\n",
      "2582:\tlearn: 2.0302009\ttotal: 28.3s\tremaining: 22s\n",
      "2583:\tlearn: 2.0298761\ttotal: 28.3s\tremaining: 22s\n",
      "2584:\tlearn: 2.0294116\ttotal: 28.3s\tremaining: 22s\n",
      "2585:\tlearn: 2.0290228\ttotal: 28.3s\tremaining: 22s\n",
      "2586:\tlearn: 2.0288974\ttotal: 28.3s\tremaining: 22s\n",
      "2587:\tlearn: 2.0282446\ttotal: 28.3s\tremaining: 22s\n",
      "2588:\tlearn: 2.0277556\ttotal: 28.3s\tremaining: 22s\n",
      "2589:\tlearn: 2.0269873\ttotal: 28.3s\tremaining: 22s\n",
      "2590:\tlearn: 2.0266292\ttotal: 28.3s\tremaining: 22s\n",
      "2591:\tlearn: 2.0263513\ttotal: 28.4s\tremaining: 21.9s\n",
      "2592:\tlearn: 2.0259427\ttotal: 28.4s\tremaining: 21.9s\n",
      "2593:\tlearn: 2.0257088\ttotal: 28.4s\tremaining: 21.9s\n",
      "2594:\tlearn: 2.0254564\ttotal: 28.4s\tremaining: 21.9s\n",
      "2595:\tlearn: 2.0253032\ttotal: 28.4s\tremaining: 21.9s\n",
      "2596:\tlearn: 2.0250098\ttotal: 28.4s\tremaining: 21.9s\n",
      "2597:\tlearn: 2.0246912\ttotal: 28.4s\tremaining: 21.9s\n",
      "2598:\tlearn: 2.0244627\ttotal: 28.4s\tremaining: 21.9s\n",
      "2599:\tlearn: 2.0243730\ttotal: 28.4s\tremaining: 21.9s\n",
      "2600:\tlearn: 2.0240505\ttotal: 28.5s\tremaining: 21.8s\n",
      "2601:\tlearn: 2.0237565\ttotal: 28.5s\tremaining: 21.8s\n",
      "2602:\tlearn: 2.0234547\ttotal: 28.5s\tremaining: 21.8s\n",
      "2603:\tlearn: 2.0232426\ttotal: 28.5s\tremaining: 21.8s\n",
      "2604:\tlearn: 2.0229042\ttotal: 28.5s\tremaining: 21.8s\n",
      "2605:\tlearn: 2.0227108\ttotal: 28.5s\tremaining: 21.8s\n",
      "2606:\tlearn: 2.0224436\ttotal: 28.5s\tremaining: 21.8s\n",
      "2607:\tlearn: 2.0221570\ttotal: 28.5s\tremaining: 21.8s\n",
      "2608:\tlearn: 2.0220269\ttotal: 28.5s\tremaining: 21.8s\n",
      "2609:\tlearn: 2.0215646\ttotal: 28.6s\tremaining: 21.7s\n",
      "2610:\tlearn: 2.0212617\ttotal: 28.6s\tremaining: 21.7s\n",
      "2611:\tlearn: 2.0207160\ttotal: 28.6s\tremaining: 21.7s\n",
      "2612:\tlearn: 2.0202873\ttotal: 28.6s\tremaining: 21.7s\n",
      "2613:\tlearn: 2.0200232\ttotal: 28.6s\tremaining: 21.7s\n",
      "2614:\tlearn: 2.0197406\ttotal: 28.6s\tremaining: 21.7s\n",
      "2615:\tlearn: 2.0193311\ttotal: 28.6s\tremaining: 21.7s\n",
      "2616:\tlearn: 2.0191022\ttotal: 28.6s\tremaining: 21.7s\n",
      "2617:\tlearn: 2.0187490\ttotal: 28.6s\tremaining: 21.7s\n",
      "2618:\tlearn: 2.0182785\ttotal: 28.7s\tremaining: 21.7s\n",
      "2619:\tlearn: 2.0179693\ttotal: 28.7s\tremaining: 21.6s\n",
      "2620:\tlearn: 2.0178173\ttotal: 28.7s\tremaining: 21.6s\n",
      "2621:\tlearn: 2.0175106\ttotal: 28.7s\tremaining: 21.6s\n",
      "2622:\tlearn: 2.0172314\ttotal: 28.7s\tremaining: 21.6s\n",
      "2623:\tlearn: 2.0164498\ttotal: 28.7s\tremaining: 21.6s\n",
      "2624:\tlearn: 2.0160770\ttotal: 28.7s\tremaining: 21.6s\n",
      "2625:\tlearn: 2.0157362\ttotal: 28.7s\tremaining: 21.6s\n",
      "2626:\tlearn: 2.0152663\ttotal: 28.7s\tremaining: 21.6s\n",
      "2627:\tlearn: 2.0151699\ttotal: 28.8s\tremaining: 21.6s\n",
      "2628:\tlearn: 2.0150327\ttotal: 28.8s\tremaining: 21.5s\n",
      "2629:\tlearn: 2.0146096\ttotal: 28.8s\tremaining: 21.5s\n",
      "2630:\tlearn: 2.0143336\ttotal: 28.8s\tremaining: 21.5s\n",
      "2631:\tlearn: 2.0141570\ttotal: 28.8s\tremaining: 21.5s\n",
      "2632:\tlearn: 2.0138656\ttotal: 28.8s\tremaining: 21.5s\n",
      "2633:\tlearn: 2.0135801\ttotal: 28.8s\tremaining: 21.5s\n",
      "2634:\tlearn: 2.0133953\ttotal: 28.8s\tremaining: 21.5s\n",
      "2635:\tlearn: 2.0128438\ttotal: 28.8s\tremaining: 21.5s\n",
      "2636:\tlearn: 2.0125176\ttotal: 28.9s\tremaining: 21.5s\n",
      "2637:\tlearn: 2.0121900\ttotal: 28.9s\tremaining: 21.4s\n",
      "2638:\tlearn: 2.0119285\ttotal: 28.9s\tremaining: 21.4s\n",
      "2639:\tlearn: 2.0117080\ttotal: 28.9s\tremaining: 21.4s\n",
      "2640:\tlearn: 2.0114758\ttotal: 28.9s\tremaining: 21.4s\n",
      "2641:\tlearn: 2.0112373\ttotal: 28.9s\tremaining: 21.4s\n",
      "2642:\tlearn: 2.0108897\ttotal: 28.9s\tremaining: 21.4s\n",
      "2643:\tlearn: 2.0107569\ttotal: 28.9s\tremaining: 21.4s\n",
      "2644:\tlearn: 2.0105395\ttotal: 28.9s\tremaining: 21.4s\n",
      "2645:\tlearn: 2.0102521\ttotal: 28.9s\tremaining: 21.4s\n",
      "2646:\tlearn: 2.0099073\ttotal: 29s\tremaining: 21.3s\n",
      "2647:\tlearn: 2.0095228\ttotal: 29s\tremaining: 21.3s\n",
      "2648:\tlearn: 2.0090675\ttotal: 29s\tremaining: 21.3s\n",
      "2649:\tlearn: 2.0086834\ttotal: 29s\tremaining: 21.3s\n",
      "2650:\tlearn: 2.0084165\ttotal: 29s\tremaining: 21.3s\n",
      "2651:\tlearn: 2.0080793\ttotal: 29s\tremaining: 21.3s\n",
      "2652:\tlearn: 2.0076672\ttotal: 29s\tremaining: 21.3s\n",
      "2653:\tlearn: 2.0072593\ttotal: 29s\tremaining: 21.3s\n",
      "2654:\tlearn: 2.0070873\ttotal: 29.1s\tremaining: 21.3s\n",
      "2655:\tlearn: 2.0067628\ttotal: 29.1s\tremaining: 21.3s\n",
      "2656:\tlearn: 2.0064003\ttotal: 29.1s\tremaining: 21.2s\n",
      "2657:\tlearn: 2.0059661\ttotal: 29.1s\tremaining: 21.2s\n",
      "2658:\tlearn: 2.0055994\ttotal: 29.1s\tremaining: 21.2s\n",
      "2659:\tlearn: 2.0053761\ttotal: 29.1s\tremaining: 21.2s\n",
      "2660:\tlearn: 2.0051137\ttotal: 29.1s\tremaining: 21.2s\n",
      "2661:\tlearn: 2.0046521\ttotal: 29.1s\tremaining: 21.2s\n",
      "2662:\tlearn: 2.0042520\ttotal: 29.1s\tremaining: 21.2s\n",
      "2663:\tlearn: 2.0039746\ttotal: 29.1s\tremaining: 21.2s\n",
      "2664:\tlearn: 2.0037434\ttotal: 29.2s\tremaining: 21.2s\n",
      "2665:\tlearn: 2.0031958\ttotal: 29.2s\tremaining: 21.1s\n",
      "2666:\tlearn: 2.0029782\ttotal: 29.2s\tremaining: 21.1s\n",
      "2667:\tlearn: 2.0026150\ttotal: 29.2s\tremaining: 21.1s\n",
      "2668:\tlearn: 2.0022771\ttotal: 29.2s\tremaining: 21.1s\n",
      "2669:\tlearn: 2.0020054\ttotal: 29.2s\tremaining: 21.1s\n",
      "2670:\tlearn: 2.0017784\ttotal: 29.2s\tremaining: 21.1s\n",
      "2671:\tlearn: 2.0013850\ttotal: 29.2s\tremaining: 21.1s\n",
      "2672:\tlearn: 2.0007917\ttotal: 29.3s\tremaining: 21.1s\n",
      "2673:\tlearn: 2.0006383\ttotal: 29.3s\tremaining: 21.1s\n",
      "2674:\tlearn: 2.0003097\ttotal: 29.3s\tremaining: 21s\n",
      "2675:\tlearn: 1.9999887\ttotal: 29.3s\tremaining: 21s\n",
      "2676:\tlearn: 1.9997225\ttotal: 29.3s\tremaining: 21s\n",
      "2677:\tlearn: 1.9993821\ttotal: 29.3s\tremaining: 21s\n",
      "2678:\tlearn: 1.9991505\ttotal: 29.3s\tremaining: 21s\n",
      "2679:\tlearn: 1.9986889\ttotal: 29.3s\tremaining: 21s\n",
      "2680:\tlearn: 1.9984546\ttotal: 29.3s\tremaining: 21s\n",
      "2681:\tlearn: 1.9979586\ttotal: 29.3s\tremaining: 21s\n",
      "2682:\tlearn: 1.9976656\ttotal: 29.4s\tremaining: 21s\n",
      "2683:\tlearn: 1.9972799\ttotal: 29.4s\tremaining: 20.9s\n",
      "2684:\tlearn: 1.9970477\ttotal: 29.4s\tremaining: 20.9s\n",
      "2685:\tlearn: 1.9966941\ttotal: 29.4s\tremaining: 20.9s\n",
      "2686:\tlearn: 1.9962873\ttotal: 29.4s\tremaining: 20.9s\n",
      "2687:\tlearn: 1.9961770\ttotal: 29.4s\tremaining: 20.9s\n",
      "2688:\tlearn: 1.9958643\ttotal: 29.4s\tremaining: 20.9s\n",
      "2689:\tlearn: 1.9956276\ttotal: 29.4s\tremaining: 20.9s\n",
      "2690:\tlearn: 1.9953836\ttotal: 29.4s\tremaining: 20.9s\n",
      "2691:\tlearn: 1.9948181\ttotal: 29.5s\tremaining: 20.9s\n",
      "2692:\tlearn: 1.9943543\ttotal: 29.5s\tremaining: 20.8s\n",
      "2693:\tlearn: 1.9937409\ttotal: 29.5s\tremaining: 20.8s\n",
      "2694:\tlearn: 1.9933638\ttotal: 29.5s\tremaining: 20.8s\n",
      "2695:\tlearn: 1.9930461\ttotal: 29.5s\tremaining: 20.8s\n",
      "2696:\tlearn: 1.9926431\ttotal: 29.5s\tremaining: 20.8s\n",
      "2697:\tlearn: 1.9923325\ttotal: 29.5s\tremaining: 20.8s\n",
      "2698:\tlearn: 1.9918479\ttotal: 29.5s\tremaining: 20.8s\n",
      "2699:\tlearn: 1.9918084\ttotal: 29.5s\tremaining: 20.8s\n",
      "2700:\tlearn: 1.9915015\ttotal: 29.6s\tremaining: 20.8s\n",
      "2701:\tlearn: 1.9909096\ttotal: 29.6s\tremaining: 20.7s\n",
      "2702:\tlearn: 1.9903458\ttotal: 29.6s\tremaining: 20.7s\n",
      "2703:\tlearn: 1.9900709\ttotal: 29.6s\tremaining: 20.7s\n",
      "2704:\tlearn: 1.9897722\ttotal: 29.6s\tremaining: 20.7s\n",
      "2705:\tlearn: 1.9892839\ttotal: 29.6s\tremaining: 20.7s\n",
      "2706:\tlearn: 1.9886828\ttotal: 29.6s\tremaining: 20.7s\n",
      "2707:\tlearn: 1.9885677\ttotal: 29.6s\tremaining: 20.7s\n",
      "2708:\tlearn: 1.9884095\ttotal: 29.6s\tremaining: 20.7s\n",
      "2709:\tlearn: 1.9878063\ttotal: 29.7s\tremaining: 20.7s\n",
      "2710:\tlearn: 1.9874156\ttotal: 29.7s\tremaining: 20.6s\n",
      "2711:\tlearn: 1.9870805\ttotal: 29.7s\tremaining: 20.6s\n",
      "2712:\tlearn: 1.9868467\ttotal: 29.7s\tremaining: 20.6s\n",
      "2713:\tlearn: 1.9864586\ttotal: 29.7s\tremaining: 20.6s\n",
      "2714:\tlearn: 1.9860668\ttotal: 29.7s\tremaining: 20.6s\n",
      "2715:\tlearn: 1.9854430\ttotal: 29.7s\tremaining: 20.6s\n",
      "2716:\tlearn: 1.9850004\ttotal: 29.7s\tremaining: 20.6s\n",
      "2717:\tlearn: 1.9846701\ttotal: 29.7s\tremaining: 20.6s\n",
      "2718:\tlearn: 1.9844684\ttotal: 29.8s\tremaining: 20.6s\n",
      "2719:\tlearn: 1.9842072\ttotal: 29.8s\tremaining: 20.6s\n",
      "2720:\tlearn: 1.9838669\ttotal: 29.8s\tremaining: 20.5s\n",
      "2721:\tlearn: 1.9832810\ttotal: 29.8s\tremaining: 20.5s\n",
      "2722:\tlearn: 1.9828068\ttotal: 29.8s\tremaining: 20.5s\n",
      "2723:\tlearn: 1.9823074\ttotal: 29.8s\tremaining: 20.5s\n",
      "2724:\tlearn: 1.9819140\ttotal: 29.8s\tremaining: 20.5s\n",
      "2725:\tlearn: 1.9815177\ttotal: 29.8s\tremaining: 20.5s\n",
      "2726:\tlearn: 1.9814091\ttotal: 29.8s\tremaining: 20.5s\n",
      "2727:\tlearn: 1.9810182\ttotal: 29.9s\tremaining: 20.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2728:\tlearn: 1.9809166\ttotal: 29.9s\tremaining: 20.5s\n",
      "2729:\tlearn: 1.9806913\ttotal: 29.9s\tremaining: 20.4s\n",
      "2730:\tlearn: 1.9801739\ttotal: 29.9s\tremaining: 20.4s\n",
      "2731:\tlearn: 1.9798800\ttotal: 29.9s\tremaining: 20.4s\n",
      "2732:\tlearn: 1.9796458\ttotal: 29.9s\tremaining: 20.4s\n",
      "2733:\tlearn: 1.9793603\ttotal: 29.9s\tremaining: 20.4s\n",
      "2734:\tlearn: 1.9791919\ttotal: 29.9s\tremaining: 20.4s\n",
      "2735:\tlearn: 1.9788440\ttotal: 29.9s\tremaining: 20.4s\n",
      "2736:\tlearn: 1.9784223\ttotal: 30s\tremaining: 20.4s\n",
      "2737:\tlearn: 1.9781420\ttotal: 30s\tremaining: 20.4s\n",
      "2738:\tlearn: 1.9778397\ttotal: 30s\tremaining: 20.3s\n",
      "2739:\tlearn: 1.9773778\ttotal: 30s\tremaining: 20.3s\n",
      "2740:\tlearn: 1.9769288\ttotal: 30s\tremaining: 20.3s\n",
      "2741:\tlearn: 1.9765721\ttotal: 30s\tremaining: 20.3s\n",
      "2742:\tlearn: 1.9763217\ttotal: 30s\tremaining: 20.3s\n",
      "2743:\tlearn: 1.9760867\ttotal: 30s\tremaining: 20.3s\n",
      "2744:\tlearn: 1.9758369\ttotal: 30s\tremaining: 20.3s\n",
      "2745:\tlearn: 1.9754884\ttotal: 30s\tremaining: 20.3s\n",
      "2746:\tlearn: 1.9750666\ttotal: 30.1s\tremaining: 20.3s\n",
      "2747:\tlearn: 1.9746650\ttotal: 30.1s\tremaining: 20.2s\n",
      "2748:\tlearn: 1.9741410\ttotal: 30.1s\tremaining: 20.2s\n",
      "2749:\tlearn: 1.9738791\ttotal: 30.1s\tremaining: 20.2s\n",
      "2750:\tlearn: 1.9735343\ttotal: 30.1s\tremaining: 20.2s\n",
      "2751:\tlearn: 1.9731805\ttotal: 30.1s\tremaining: 20.2s\n",
      "2752:\tlearn: 1.9724034\ttotal: 30.1s\tremaining: 20.2s\n",
      "2753:\tlearn: 1.9721237\ttotal: 30.1s\tremaining: 20.2s\n",
      "2754:\tlearn: 1.9720140\ttotal: 30.1s\tremaining: 20.2s\n",
      "2755:\tlearn: 1.9715760\ttotal: 30.2s\tremaining: 20.2s\n",
      "2756:\tlearn: 1.9712216\ttotal: 30.2s\tremaining: 20.1s\n",
      "2757:\tlearn: 1.9708981\ttotal: 30.2s\tremaining: 20.1s\n",
      "2758:\tlearn: 1.9706256\ttotal: 30.2s\tremaining: 20.1s\n",
      "2759:\tlearn: 1.9701504\ttotal: 30.2s\tremaining: 20.1s\n",
      "2760:\tlearn: 1.9698635\ttotal: 30.2s\tremaining: 20.1s\n",
      "2761:\tlearn: 1.9696156\ttotal: 30.2s\tremaining: 20.1s\n",
      "2762:\tlearn: 1.9694482\ttotal: 30.2s\tremaining: 20.1s\n",
      "2763:\tlearn: 1.9692489\ttotal: 30.2s\tremaining: 20.1s\n",
      "2764:\tlearn: 1.9688425\ttotal: 30.3s\tremaining: 20.1s\n",
      "2765:\tlearn: 1.9683706\ttotal: 30.3s\tremaining: 20s\n",
      "2766:\tlearn: 1.9681419\ttotal: 30.3s\tremaining: 20s\n",
      "2767:\tlearn: 1.9677240\ttotal: 30.3s\tremaining: 20s\n",
      "2768:\tlearn: 1.9674584\ttotal: 30.3s\tremaining: 20s\n",
      "2769:\tlearn: 1.9671142\ttotal: 30.3s\tremaining: 20s\n",
      "2770:\tlearn: 1.9667565\ttotal: 30.3s\tremaining: 20s\n",
      "2771:\tlearn: 1.9666228\ttotal: 30.3s\tremaining: 20s\n",
      "2772:\tlearn: 1.9663219\ttotal: 30.3s\tremaining: 20s\n",
      "2773:\tlearn: 1.9661792\ttotal: 30.4s\tremaining: 20s\n",
      "2774:\tlearn: 1.9659945\ttotal: 30.4s\tremaining: 19.9s\n",
      "2775:\tlearn: 1.9658129\ttotal: 30.4s\tremaining: 19.9s\n",
      "2776:\tlearn: 1.9656241\ttotal: 30.4s\tremaining: 19.9s\n",
      "2777:\tlearn: 1.9653437\ttotal: 30.4s\tremaining: 19.9s\n",
      "2778:\tlearn: 1.9650934\ttotal: 30.4s\tremaining: 19.9s\n",
      "2779:\tlearn: 1.9646890\ttotal: 30.4s\tremaining: 19.9s\n",
      "2780:\tlearn: 1.9643295\ttotal: 30.4s\tremaining: 19.9s\n",
      "2781:\tlearn: 1.9639186\ttotal: 30.4s\tremaining: 19.9s\n",
      "2782:\tlearn: 1.9635484\ttotal: 30.4s\tremaining: 19.9s\n",
      "2783:\tlearn: 1.9631285\ttotal: 30.5s\tremaining: 19.8s\n",
      "2784:\tlearn: 1.9629584\ttotal: 30.5s\tremaining: 19.8s\n",
      "2785:\tlearn: 1.9626854\ttotal: 30.5s\tremaining: 19.8s\n",
      "2786:\tlearn: 1.9624349\ttotal: 30.5s\tremaining: 19.8s\n",
      "2787:\tlearn: 1.9621570\ttotal: 30.5s\tremaining: 19.8s\n",
      "2788:\tlearn: 1.9618630\ttotal: 30.5s\tremaining: 19.8s\n",
      "2789:\tlearn: 1.9612756\ttotal: 30.5s\tremaining: 19.8s\n",
      "2790:\tlearn: 1.9610214\ttotal: 30.5s\tremaining: 19.8s\n",
      "2791:\tlearn: 1.9605467\ttotal: 30.5s\tremaining: 19.8s\n",
      "2792:\tlearn: 1.9600530\ttotal: 30.6s\tremaining: 19.7s\n",
      "2793:\tlearn: 1.9598361\ttotal: 30.6s\tremaining: 19.7s\n",
      "2794:\tlearn: 1.9594493\ttotal: 30.6s\tremaining: 19.7s\n",
      "2795:\tlearn: 1.9593002\ttotal: 30.6s\tremaining: 19.7s\n",
      "2796:\tlearn: 1.9590087\ttotal: 30.6s\tremaining: 19.7s\n",
      "2797:\tlearn: 1.9585949\ttotal: 30.6s\tremaining: 19.7s\n",
      "2798:\tlearn: 1.9580469\ttotal: 30.6s\tremaining: 19.7s\n",
      "2799:\tlearn: 1.9579569\ttotal: 30.6s\tremaining: 19.7s\n",
      "2800:\tlearn: 1.9575866\ttotal: 30.6s\tremaining: 19.7s\n",
      "2801:\tlearn: 1.9573027\ttotal: 30.7s\tremaining: 19.7s\n",
      "2802:\tlearn: 1.9570637\ttotal: 30.7s\tremaining: 19.6s\n",
      "2803:\tlearn: 1.9567431\ttotal: 30.7s\tremaining: 19.6s\n",
      "2804:\tlearn: 1.9564137\ttotal: 30.7s\tremaining: 19.6s\n",
      "2805:\tlearn: 1.9561435\ttotal: 30.7s\tremaining: 19.6s\n",
      "2806:\tlearn: 1.9557926\ttotal: 30.7s\tremaining: 19.6s\n",
      "2807:\tlearn: 1.9555149\ttotal: 30.7s\tremaining: 19.6s\n",
      "2808:\tlearn: 1.9551587\ttotal: 30.7s\tremaining: 19.6s\n",
      "2809:\tlearn: 1.9546210\ttotal: 30.7s\tremaining: 19.6s\n",
      "2810:\tlearn: 1.9544940\ttotal: 30.8s\tremaining: 19.6s\n",
      "2811:\tlearn: 1.9541196\ttotal: 30.8s\tremaining: 19.5s\n",
      "2812:\tlearn: 1.9538263\ttotal: 30.8s\tremaining: 19.5s\n",
      "2813:\tlearn: 1.9536435\ttotal: 30.8s\tremaining: 19.5s\n",
      "2814:\tlearn: 1.9531133\ttotal: 30.8s\tremaining: 19.5s\n",
      "2815:\tlearn: 1.9528532\ttotal: 30.8s\tremaining: 19.5s\n",
      "2816:\tlearn: 1.9526115\ttotal: 30.8s\tremaining: 19.5s\n",
      "2817:\tlearn: 1.9522759\ttotal: 30.8s\tremaining: 19.5s\n",
      "2818:\tlearn: 1.9519390\ttotal: 30.8s\tremaining: 19.5s\n",
      "2819:\tlearn: 1.9517780\ttotal: 30.9s\tremaining: 19.5s\n",
      "2820:\tlearn: 1.9512792\ttotal: 30.9s\tremaining: 19.4s\n",
      "2821:\tlearn: 1.9508066\ttotal: 30.9s\tremaining: 19.4s\n",
      "2822:\tlearn: 1.9504727\ttotal: 30.9s\tremaining: 19.4s\n",
      "2823:\tlearn: 1.9502378\ttotal: 30.9s\tremaining: 19.4s\n",
      "2824:\tlearn: 1.9501248\ttotal: 30.9s\tremaining: 19.4s\n",
      "2825:\tlearn: 1.9496992\ttotal: 30.9s\tremaining: 19.4s\n",
      "2826:\tlearn: 1.9494023\ttotal: 30.9s\tremaining: 19.4s\n",
      "2827:\tlearn: 1.9491501\ttotal: 30.9s\tremaining: 19.4s\n",
      "2828:\tlearn: 1.9487522\ttotal: 30.9s\tremaining: 19.4s\n",
      "2829:\tlearn: 1.9484730\ttotal: 31s\tremaining: 19.3s\n",
      "2830:\tlearn: 1.9483408\ttotal: 31s\tremaining: 19.3s\n",
      "2831:\tlearn: 1.9481981\ttotal: 31s\tremaining: 19.3s\n",
      "2832:\tlearn: 1.9478142\ttotal: 31s\tremaining: 19.3s\n",
      "2833:\tlearn: 1.9475562\ttotal: 31s\tremaining: 19.3s\n",
      "2834:\tlearn: 1.9472939\ttotal: 31s\tremaining: 19.3s\n",
      "2835:\tlearn: 1.9470259\ttotal: 31s\tremaining: 19.3s\n",
      "2836:\tlearn: 1.9465932\ttotal: 31s\tremaining: 19.3s\n",
      "2837:\tlearn: 1.9463068\ttotal: 31s\tremaining: 19.3s\n",
      "2838:\tlearn: 1.9460044\ttotal: 31.1s\tremaining: 19.2s\n",
      "2839:\tlearn: 1.9458430\ttotal: 31.1s\tremaining: 19.2s\n",
      "2840:\tlearn: 1.9455588\ttotal: 31.1s\tremaining: 19.2s\n",
      "2841:\tlearn: 1.9453912\ttotal: 31.1s\tremaining: 19.2s\n",
      "2842:\tlearn: 1.9452258\ttotal: 31.1s\tremaining: 19.2s\n",
      "2843:\tlearn: 1.9449213\ttotal: 31.1s\tremaining: 19.2s\n",
      "2844:\tlearn: 1.9446008\ttotal: 31.1s\tremaining: 19.2s\n",
      "2845:\tlearn: 1.9442830\ttotal: 31.1s\tremaining: 19.2s\n",
      "2846:\tlearn: 1.9439840\ttotal: 31.1s\tremaining: 19.2s\n",
      "2847:\tlearn: 1.9437205\ttotal: 31.2s\tremaining: 19.1s\n",
      "2848:\tlearn: 1.9433827\ttotal: 31.2s\tremaining: 19.1s\n",
      "2849:\tlearn: 1.9432710\ttotal: 31.2s\tremaining: 19.1s\n",
      "2850:\tlearn: 1.9430446\ttotal: 31.2s\tremaining: 19.1s\n",
      "2851:\tlearn: 1.9427715\ttotal: 31.2s\tremaining: 19.1s\n",
      "2852:\tlearn: 1.9425816\ttotal: 31.2s\tremaining: 19.1s\n",
      "2853:\tlearn: 1.9422257\ttotal: 31.2s\tremaining: 19.1s\n",
      "2854:\tlearn: 1.9421137\ttotal: 31.2s\tremaining: 19.1s\n",
      "2855:\tlearn: 1.9418058\ttotal: 31.2s\tremaining: 19.1s\n",
      "2856:\tlearn: 1.9416245\ttotal: 31.3s\tremaining: 19s\n",
      "2857:\tlearn: 1.9412155\ttotal: 31.3s\tremaining: 19s\n",
      "2858:\tlearn: 1.9409292\ttotal: 31.3s\tremaining: 19s\n",
      "2859:\tlearn: 1.9406540\ttotal: 31.3s\tremaining: 19s\n",
      "2860:\tlearn: 1.9405406\ttotal: 31.3s\tremaining: 19s\n",
      "2861:\tlearn: 1.9400155\ttotal: 31.3s\tremaining: 19s\n",
      "2862:\tlearn: 1.9398404\ttotal: 31.3s\tremaining: 19s\n",
      "2863:\tlearn: 1.9395939\ttotal: 31.3s\tremaining: 19s\n",
      "2864:\tlearn: 1.9394701\ttotal: 31.3s\tremaining: 19s\n",
      "2865:\tlearn: 1.9392554\ttotal: 31.3s\tremaining: 18.9s\n",
      "2866:\tlearn: 1.9390434\ttotal: 31.4s\tremaining: 18.9s\n",
      "2867:\tlearn: 1.9386449\ttotal: 31.4s\tremaining: 18.9s\n",
      "2868:\tlearn: 1.9382397\ttotal: 31.4s\tremaining: 18.9s\n",
      "2869:\tlearn: 1.9381870\ttotal: 31.4s\tremaining: 18.9s\n",
      "2870:\tlearn: 1.9378801\ttotal: 31.4s\tremaining: 18.9s\n",
      "2871:\tlearn: 1.9377306\ttotal: 31.4s\tremaining: 18.9s\n",
      "2872:\tlearn: 1.9376053\ttotal: 31.4s\tremaining: 18.9s\n",
      "2873:\tlearn: 1.9371033\ttotal: 31.4s\tremaining: 18.9s\n",
      "2874:\tlearn: 1.9369170\ttotal: 31.4s\tremaining: 18.8s\n",
      "2875:\tlearn: 1.9365850\ttotal: 31.5s\tremaining: 18.8s\n",
      "2876:\tlearn: 1.9362263\ttotal: 31.5s\tremaining: 18.8s\n",
      "2877:\tlearn: 1.9358932\ttotal: 31.5s\tremaining: 18.8s\n",
      "2878:\tlearn: 1.9354056\ttotal: 31.5s\tremaining: 18.8s\n",
      "2879:\tlearn: 1.9348820\ttotal: 31.5s\tremaining: 18.8s\n",
      "2880:\tlearn: 1.9343237\ttotal: 31.5s\tremaining: 18.8s\n",
      "2881:\tlearn: 1.9340347\ttotal: 31.5s\tremaining: 18.8s\n",
      "2882:\tlearn: 1.9337636\ttotal: 31.5s\tremaining: 18.8s\n",
      "2883:\tlearn: 1.9333023\ttotal: 31.5s\tremaining: 18.7s\n",
      "2884:\tlearn: 1.9331885\ttotal: 31.6s\tremaining: 18.7s\n",
      "2885:\tlearn: 1.9329166\ttotal: 31.6s\tremaining: 18.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2886:\tlearn: 1.9325391\ttotal: 31.6s\tremaining: 18.7s\n",
      "2887:\tlearn: 1.9321692\ttotal: 31.6s\tremaining: 18.7s\n",
      "2888:\tlearn: 1.9320019\ttotal: 31.6s\tremaining: 18.7s\n",
      "2889:\tlearn: 1.9318252\ttotal: 31.6s\tremaining: 18.7s\n",
      "2890:\tlearn: 1.9315742\ttotal: 31.6s\tremaining: 18.7s\n",
      "2891:\tlearn: 1.9312375\ttotal: 31.6s\tremaining: 18.7s\n",
      "2892:\tlearn: 1.9309314\ttotal: 31.6s\tremaining: 18.6s\n",
      "2893:\tlearn: 1.9305190\ttotal: 31.7s\tremaining: 18.6s\n",
      "2894:\tlearn: 1.9301887\ttotal: 31.7s\tremaining: 18.6s\n",
      "2895:\tlearn: 1.9299016\ttotal: 31.7s\tremaining: 18.6s\n",
      "2896:\tlearn: 1.9296321\ttotal: 31.7s\tremaining: 18.6s\n",
      "2897:\tlearn: 1.9294466\ttotal: 31.7s\tremaining: 18.6s\n",
      "2898:\tlearn: 1.9290303\ttotal: 31.7s\tremaining: 18.6s\n",
      "2899:\tlearn: 1.9287987\ttotal: 31.7s\tremaining: 18.6s\n",
      "2900:\tlearn: 1.9285022\ttotal: 31.7s\tremaining: 18.6s\n",
      "2901:\tlearn: 1.9284511\ttotal: 31.7s\tremaining: 18.6s\n",
      "2902:\tlearn: 1.9280677\ttotal: 31.8s\tremaining: 18.5s\n",
      "2903:\tlearn: 1.9275684\ttotal: 31.8s\tremaining: 18.5s\n",
      "2904:\tlearn: 1.9272307\ttotal: 31.8s\tremaining: 18.5s\n",
      "2905:\tlearn: 1.9270332\ttotal: 31.8s\tremaining: 18.5s\n",
      "2906:\tlearn: 1.9269695\ttotal: 31.8s\tremaining: 18.5s\n",
      "2907:\tlearn: 1.9265775\ttotal: 31.8s\tremaining: 18.5s\n",
      "2908:\tlearn: 1.9264397\ttotal: 31.8s\tremaining: 18.5s\n",
      "2909:\tlearn: 1.9259513\ttotal: 31.8s\tremaining: 18.5s\n",
      "2910:\tlearn: 1.9256474\ttotal: 31.8s\tremaining: 18.5s\n",
      "2911:\tlearn: 1.9252009\ttotal: 31.9s\tremaining: 18.4s\n",
      "2912:\tlearn: 1.9249091\ttotal: 31.9s\tremaining: 18.4s\n",
      "2913:\tlearn: 1.9244915\ttotal: 31.9s\tremaining: 18.4s\n",
      "2914:\tlearn: 1.9239716\ttotal: 31.9s\tremaining: 18.4s\n",
      "2915:\tlearn: 1.9235159\ttotal: 31.9s\tremaining: 18.4s\n",
      "2916:\tlearn: 1.9233544\ttotal: 31.9s\tremaining: 18.4s\n",
      "2917:\tlearn: 1.9231594\ttotal: 31.9s\tremaining: 18.4s\n",
      "2918:\tlearn: 1.9230276\ttotal: 31.9s\tremaining: 18.4s\n",
      "2919:\tlearn: 1.9228225\ttotal: 31.9s\tremaining: 18.4s\n",
      "2920:\tlearn: 1.9225552\ttotal: 31.9s\tremaining: 18.3s\n",
      "2921:\tlearn: 1.9223059\ttotal: 32s\tremaining: 18.3s\n",
      "2922:\tlearn: 1.9217214\ttotal: 32s\tremaining: 18.3s\n",
      "2923:\tlearn: 1.9212305\ttotal: 32s\tremaining: 18.3s\n",
      "2924:\tlearn: 1.9208652\ttotal: 32s\tremaining: 18.3s\n",
      "2925:\tlearn: 1.9206691\ttotal: 32s\tremaining: 18.3s\n",
      "2926:\tlearn: 1.9203277\ttotal: 32s\tremaining: 18.3s\n",
      "2927:\tlearn: 1.9198595\ttotal: 32s\tremaining: 18.3s\n",
      "2928:\tlearn: 1.9195498\ttotal: 32s\tremaining: 18.3s\n",
      "2929:\tlearn: 1.9193476\ttotal: 32s\tremaining: 18.2s\n",
      "2930:\tlearn: 1.9188085\ttotal: 32.1s\tremaining: 18.2s\n",
      "2931:\tlearn: 1.9185526\ttotal: 32.1s\tremaining: 18.2s\n",
      "2932:\tlearn: 1.9182187\ttotal: 32.1s\tremaining: 18.2s\n",
      "2933:\tlearn: 1.9179011\ttotal: 32.1s\tremaining: 18.2s\n",
      "2934:\tlearn: 1.9176341\ttotal: 32.1s\tremaining: 18.2s\n",
      "2935:\tlearn: 1.9173235\ttotal: 32.1s\tremaining: 18.2s\n",
      "2936:\tlearn: 1.9170759\ttotal: 32.1s\tremaining: 18.2s\n",
      "2937:\tlearn: 1.9168912\ttotal: 32.1s\tremaining: 18.2s\n",
      "2938:\tlearn: 1.9164748\ttotal: 32.1s\tremaining: 18.1s\n",
      "2939:\tlearn: 1.9162452\ttotal: 32.2s\tremaining: 18.1s\n",
      "2940:\tlearn: 1.9157984\ttotal: 32.2s\tremaining: 18.1s\n",
      "2941:\tlearn: 1.9155334\ttotal: 32.2s\tremaining: 18.1s\n",
      "2942:\tlearn: 1.9152492\ttotal: 32.2s\tremaining: 18.1s\n",
      "2943:\tlearn: 1.9147946\ttotal: 32.2s\tremaining: 18.1s\n",
      "2944:\tlearn: 1.9146232\ttotal: 32.2s\tremaining: 18.1s\n",
      "2945:\tlearn: 1.9143488\ttotal: 32.2s\tremaining: 18.1s\n",
      "2946:\tlearn: 1.9140480\ttotal: 32.2s\tremaining: 18.1s\n",
      "2947:\tlearn: 1.9138365\ttotal: 32.2s\tremaining: 18s\n",
      "2948:\tlearn: 1.9135489\ttotal: 32.3s\tremaining: 18s\n",
      "2949:\tlearn: 1.9130521\ttotal: 32.3s\tremaining: 18s\n",
      "2950:\tlearn: 1.9128305\ttotal: 32.3s\tremaining: 18s\n",
      "2951:\tlearn: 1.9124445\ttotal: 32.3s\tremaining: 18s\n",
      "2952:\tlearn: 1.9123480\ttotal: 32.3s\tremaining: 18s\n",
      "2953:\tlearn: 1.9121958\ttotal: 32.3s\tremaining: 18s\n",
      "2954:\tlearn: 1.9118567\ttotal: 32.3s\tremaining: 18s\n",
      "2955:\tlearn: 1.9114229\ttotal: 32.3s\tremaining: 18s\n",
      "2956:\tlearn: 1.9110411\ttotal: 32.3s\tremaining: 17.9s\n",
      "2957:\tlearn: 1.9105302\ttotal: 32.4s\tremaining: 17.9s\n",
      "2958:\tlearn: 1.9104437\ttotal: 32.4s\tremaining: 17.9s\n",
      "2959:\tlearn: 1.9101863\ttotal: 32.4s\tremaining: 17.9s\n",
      "2960:\tlearn: 1.9098646\ttotal: 32.4s\tremaining: 17.9s\n",
      "2961:\tlearn: 1.9096274\ttotal: 32.4s\tremaining: 17.9s\n",
      "2962:\tlearn: 1.9093478\ttotal: 32.4s\tremaining: 17.9s\n",
      "2963:\tlearn: 1.9089665\ttotal: 32.4s\tremaining: 17.9s\n",
      "2964:\tlearn: 1.9087049\ttotal: 32.4s\tremaining: 17.9s\n",
      "2965:\tlearn: 1.9084497\ttotal: 32.4s\tremaining: 17.9s\n",
      "2966:\tlearn: 1.9082364\ttotal: 32.5s\tremaining: 17.8s\n",
      "2967:\tlearn: 1.9078211\ttotal: 32.5s\tremaining: 17.8s\n",
      "2968:\tlearn: 1.9076813\ttotal: 32.5s\tremaining: 17.8s\n",
      "2969:\tlearn: 1.9073197\ttotal: 32.5s\tremaining: 17.8s\n",
      "2970:\tlearn: 1.9071926\ttotal: 32.5s\tremaining: 17.8s\n",
      "2971:\tlearn: 1.9069035\ttotal: 32.5s\tremaining: 17.8s\n",
      "2972:\tlearn: 1.9062869\ttotal: 32.5s\tremaining: 17.8s\n",
      "2973:\tlearn: 1.9060033\ttotal: 32.5s\tremaining: 17.8s\n",
      "2974:\tlearn: 1.9056830\ttotal: 32.5s\tremaining: 17.8s\n",
      "2975:\tlearn: 1.9054386\ttotal: 32.6s\tremaining: 17.7s\n",
      "2976:\tlearn: 1.9053311\ttotal: 32.6s\tremaining: 17.7s\n",
      "2977:\tlearn: 1.9051339\ttotal: 32.6s\tremaining: 17.7s\n",
      "2978:\tlearn: 1.9048092\ttotal: 32.6s\tremaining: 17.7s\n",
      "2979:\tlearn: 1.9045202\ttotal: 32.6s\tremaining: 17.7s\n",
      "2980:\tlearn: 1.9041730\ttotal: 32.6s\tremaining: 17.7s\n",
      "2981:\tlearn: 1.9037567\ttotal: 32.6s\tremaining: 17.7s\n",
      "2982:\tlearn: 1.9034134\ttotal: 32.6s\tremaining: 17.7s\n",
      "2983:\tlearn: 1.9030885\ttotal: 32.6s\tremaining: 17.7s\n",
      "2984:\tlearn: 1.9027096\ttotal: 32.7s\tremaining: 17.6s\n",
      "2985:\tlearn: 1.9022477\ttotal: 32.7s\tremaining: 17.6s\n",
      "2986:\tlearn: 1.9019277\ttotal: 32.7s\tremaining: 17.6s\n",
      "2987:\tlearn: 1.9018012\ttotal: 32.7s\tremaining: 17.6s\n",
      "2988:\tlearn: 1.9013998\ttotal: 32.7s\tremaining: 17.6s\n",
      "2989:\tlearn: 1.9012721\ttotal: 32.7s\tremaining: 17.6s\n",
      "2990:\tlearn: 1.9009870\ttotal: 32.7s\tremaining: 17.6s\n",
      "2991:\tlearn: 1.9007424\ttotal: 32.7s\tremaining: 17.6s\n",
      "2992:\tlearn: 1.9005027\ttotal: 32.7s\tremaining: 17.6s\n",
      "2993:\tlearn: 1.8999841\ttotal: 32.8s\tremaining: 17.5s\n",
      "2994:\tlearn: 1.8997842\ttotal: 32.8s\tremaining: 17.5s\n",
      "2995:\tlearn: 1.8995017\ttotal: 32.8s\tremaining: 17.5s\n",
      "2996:\tlearn: 1.8991697\ttotal: 32.8s\tremaining: 17.5s\n",
      "2997:\tlearn: 1.8987617\ttotal: 32.8s\tremaining: 17.5s\n",
      "2998:\tlearn: 1.8985887\ttotal: 32.8s\tremaining: 17.5s\n",
      "2999:\tlearn: 1.8981644\ttotal: 32.8s\tremaining: 17.5s\n",
      "3000:\tlearn: 1.8977482\ttotal: 32.8s\tremaining: 17.5s\n",
      "3001:\tlearn: 1.8973987\ttotal: 32.8s\tremaining: 17.5s\n",
      "3002:\tlearn: 1.8971174\ttotal: 32.8s\tremaining: 17.4s\n",
      "3003:\tlearn: 1.8967580\ttotal: 32.9s\tremaining: 17.4s\n",
      "3004:\tlearn: 1.8964398\ttotal: 32.9s\tremaining: 17.4s\n",
      "3005:\tlearn: 1.8963499\ttotal: 32.9s\tremaining: 17.4s\n",
      "3006:\tlearn: 1.8960876\ttotal: 32.9s\tremaining: 17.4s\n",
      "3007:\tlearn: 1.8957598\ttotal: 32.9s\tremaining: 17.4s\n",
      "3008:\tlearn: 1.8953938\ttotal: 32.9s\tremaining: 17.4s\n",
      "3009:\tlearn: 1.8949054\ttotal: 32.9s\tremaining: 17.4s\n",
      "3010:\tlearn: 1.8948533\ttotal: 32.9s\tremaining: 17.4s\n",
      "3011:\tlearn: 1.8944228\ttotal: 33s\tremaining: 17.4s\n",
      "3012:\tlearn: 1.8938333\ttotal: 33s\tremaining: 17.3s\n",
      "3013:\tlearn: 1.8935909\ttotal: 33s\tremaining: 17.3s\n",
      "3014:\tlearn: 1.8933585\ttotal: 33s\tremaining: 17.3s\n",
      "3015:\tlearn: 1.8932320\ttotal: 33s\tremaining: 17.3s\n",
      "3016:\tlearn: 1.8930560\ttotal: 33s\tremaining: 17.3s\n",
      "3017:\tlearn: 1.8928221\ttotal: 33s\tremaining: 17.3s\n",
      "3018:\tlearn: 1.8924845\ttotal: 33s\tremaining: 17.3s\n",
      "3019:\tlearn: 1.8921122\ttotal: 33s\tremaining: 17.3s\n",
      "3020:\tlearn: 1.8918089\ttotal: 33s\tremaining: 17.3s\n",
      "3021:\tlearn: 1.8917593\ttotal: 33.1s\tremaining: 17.2s\n",
      "3022:\tlearn: 1.8913747\ttotal: 33.1s\tremaining: 17.2s\n",
      "3023:\tlearn: 1.8911473\ttotal: 33.1s\tremaining: 17.2s\n",
      "3024:\tlearn: 1.8908785\ttotal: 33.1s\tremaining: 17.2s\n",
      "3025:\tlearn: 1.8905594\ttotal: 33.1s\tremaining: 17.2s\n",
      "3026:\tlearn: 1.8901223\ttotal: 33.1s\tremaining: 17.2s\n",
      "3027:\tlearn: 1.8897954\ttotal: 33.1s\tremaining: 17.2s\n",
      "3028:\tlearn: 1.8894158\ttotal: 33.1s\tremaining: 17.2s\n",
      "3029:\tlearn: 1.8893061\ttotal: 33.1s\tremaining: 17.2s\n",
      "3030:\tlearn: 1.8889260\ttotal: 33.2s\tremaining: 17.1s\n",
      "3031:\tlearn: 1.8884877\ttotal: 33.2s\tremaining: 17.1s\n",
      "3032:\tlearn: 1.8882592\ttotal: 33.2s\tremaining: 17.1s\n",
      "3033:\tlearn: 1.8877770\ttotal: 33.2s\tremaining: 17.1s\n",
      "3034:\tlearn: 1.8874136\ttotal: 33.2s\tremaining: 17.1s\n",
      "3035:\tlearn: 1.8871922\ttotal: 33.2s\tremaining: 17.1s\n",
      "3036:\tlearn: 1.8869052\ttotal: 33.2s\tremaining: 17.1s\n",
      "3037:\tlearn: 1.8865472\ttotal: 33.2s\tremaining: 17.1s\n",
      "3038:\tlearn: 1.8862815\ttotal: 33.2s\tremaining: 17.1s\n",
      "3039:\tlearn: 1.8859709\ttotal: 33.3s\tremaining: 17s\n",
      "3040:\tlearn: 1.8858052\ttotal: 33.3s\tremaining: 17s\n",
      "3041:\tlearn: 1.8855041\ttotal: 33.3s\tremaining: 17s\n",
      "3042:\tlearn: 1.8853024\ttotal: 33.3s\tremaining: 17s\n",
      "3043:\tlearn: 1.8850035\ttotal: 33.3s\tremaining: 17s\n",
      "3044:\tlearn: 1.8846379\ttotal: 33.3s\tremaining: 17s\n",
      "3045:\tlearn: 1.8843481\ttotal: 33.3s\tremaining: 17s\n",
      "3046:\tlearn: 1.8841861\ttotal: 33.3s\tremaining: 17s\n",
      "3047:\tlearn: 1.8838442\ttotal: 33.3s\tremaining: 17s\n",
      "3048:\tlearn: 1.8837590\ttotal: 33.4s\tremaining: 16.9s\n",
      "3049:\tlearn: 1.8834555\ttotal: 33.4s\tremaining: 16.9s\n",
      "3050:\tlearn: 1.8829437\ttotal: 33.4s\tremaining: 16.9s\n",
      "3051:\tlearn: 1.8827448\ttotal: 33.4s\tremaining: 16.9s\n",
      "3052:\tlearn: 1.8823602\ttotal: 33.4s\tremaining: 16.9s\n",
      "3053:\tlearn: 1.8818683\ttotal: 33.4s\tremaining: 16.9s\n",
      "3054:\tlearn: 1.8815357\ttotal: 33.4s\tremaining: 16.9s\n",
      "3055:\tlearn: 1.8812043\ttotal: 33.4s\tremaining: 16.9s\n",
      "3056:\tlearn: 1.8811529\ttotal: 33.4s\tremaining: 16.9s\n",
      "3057:\tlearn: 1.8809589\ttotal: 33.5s\tremaining: 16.8s\n",
      "3058:\tlearn: 1.8807838\ttotal: 33.5s\tremaining: 16.8s\n",
      "3059:\tlearn: 1.8804594\ttotal: 33.5s\tremaining: 16.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3060:\tlearn: 1.8800986\ttotal: 33.5s\tremaining: 16.8s\n",
      "3061:\tlearn: 1.8798206\ttotal: 33.5s\tremaining: 16.8s\n",
      "3062:\tlearn: 1.8796043\ttotal: 33.5s\tremaining: 16.8s\n",
      "3063:\tlearn: 1.8795094\ttotal: 33.5s\tremaining: 16.8s\n",
      "3064:\tlearn: 1.8792135\ttotal: 33.5s\tremaining: 16.8s\n",
      "3065:\tlearn: 1.8789068\ttotal: 33.5s\tremaining: 16.8s\n",
      "3066:\tlearn: 1.8785710\ttotal: 33.6s\tremaining: 16.7s\n",
      "3067:\tlearn: 1.8781828\ttotal: 33.6s\tremaining: 16.7s\n",
      "3068:\tlearn: 1.8779245\ttotal: 33.6s\tremaining: 16.7s\n",
      "3069:\tlearn: 1.8777850\ttotal: 33.6s\tremaining: 16.7s\n",
      "3070:\tlearn: 1.8774823\ttotal: 33.6s\tremaining: 16.7s\n",
      "3071:\tlearn: 1.8770781\ttotal: 33.6s\tremaining: 16.7s\n",
      "3072:\tlearn: 1.8767715\ttotal: 33.6s\tremaining: 16.7s\n",
      "3073:\tlearn: 1.8764872\ttotal: 33.6s\tremaining: 16.7s\n",
      "3074:\tlearn: 1.8761195\ttotal: 33.6s\tremaining: 16.7s\n",
      "3075:\tlearn: 1.8755660\ttotal: 33.6s\tremaining: 16.6s\n",
      "3076:\tlearn: 1.8754295\ttotal: 33.7s\tremaining: 16.6s\n",
      "3077:\tlearn: 1.8751687\ttotal: 33.7s\tremaining: 16.6s\n",
      "3078:\tlearn: 1.8748714\ttotal: 33.7s\tremaining: 16.6s\n",
      "3079:\tlearn: 1.8747388\ttotal: 33.7s\tremaining: 16.6s\n",
      "3080:\tlearn: 1.8743681\ttotal: 33.7s\tremaining: 16.6s\n",
      "3081:\tlearn: 1.8738978\ttotal: 33.7s\tremaining: 16.6s\n",
      "3082:\tlearn: 1.8737451\ttotal: 33.7s\tremaining: 16.6s\n",
      "3083:\tlearn: 1.8734809\ttotal: 33.7s\tremaining: 16.6s\n",
      "3084:\tlearn: 1.8731102\ttotal: 33.8s\tremaining: 16.6s\n",
      "3085:\tlearn: 1.8727948\ttotal: 33.8s\tremaining: 16.5s\n",
      "3086:\tlearn: 1.8725410\ttotal: 33.8s\tremaining: 16.5s\n",
      "3087:\tlearn: 1.8722611\ttotal: 33.8s\tremaining: 16.5s\n",
      "3088:\tlearn: 1.8720728\ttotal: 33.8s\tremaining: 16.5s\n",
      "3089:\tlearn: 1.8716981\ttotal: 33.8s\tremaining: 16.5s\n",
      "3090:\tlearn: 1.8715106\ttotal: 33.8s\tremaining: 16.5s\n",
      "3091:\tlearn: 1.8711919\ttotal: 33.8s\tremaining: 16.5s\n",
      "3092:\tlearn: 1.8710201\ttotal: 33.8s\tremaining: 16.5s\n",
      "3093:\tlearn: 1.8708485\ttotal: 33.8s\tremaining: 16.5s\n",
      "3094:\tlearn: 1.8705829\ttotal: 33.9s\tremaining: 16.4s\n",
      "3095:\tlearn: 1.8702520\ttotal: 33.9s\tremaining: 16.4s\n",
      "3096:\tlearn: 1.8700249\ttotal: 33.9s\tremaining: 16.4s\n",
      "3097:\tlearn: 1.8697488\ttotal: 33.9s\tremaining: 16.4s\n",
      "3098:\tlearn: 1.8694701\ttotal: 33.9s\tremaining: 16.4s\n",
      "3099:\tlearn: 1.8690891\ttotal: 33.9s\tremaining: 16.4s\n",
      "3100:\tlearn: 1.8687931\ttotal: 33.9s\tremaining: 16.4s\n",
      "3101:\tlearn: 1.8686014\ttotal: 33.9s\tremaining: 16.4s\n",
      "3102:\tlearn: 1.8682077\ttotal: 33.9s\tremaining: 16.4s\n",
      "3103:\tlearn: 1.8682072\ttotal: 34s\tremaining: 16.3s\n",
      "3104:\tlearn: 1.8674367\ttotal: 34s\tremaining: 16.3s\n",
      "3105:\tlearn: 1.8670179\ttotal: 34s\tremaining: 16.3s\n",
      "3106:\tlearn: 1.8665949\ttotal: 34s\tremaining: 16.3s\n",
      "3107:\tlearn: 1.8664208\ttotal: 34s\tremaining: 16.3s\n",
      "3108:\tlearn: 1.8662826\ttotal: 34s\tremaining: 16.3s\n",
      "3109:\tlearn: 1.8659323\ttotal: 34s\tremaining: 16.3s\n",
      "3110:\tlearn: 1.8655733\ttotal: 34s\tremaining: 16.3s\n",
      "3111:\tlearn: 1.8654330\ttotal: 34s\tremaining: 16.3s\n",
      "3112:\tlearn: 1.8650764\ttotal: 34.1s\tremaining: 16.2s\n",
      "3113:\tlearn: 1.8647614\ttotal: 34.1s\tremaining: 16.2s\n",
      "3114:\tlearn: 1.8646262\ttotal: 34.1s\tremaining: 16.2s\n",
      "3115:\tlearn: 1.8642833\ttotal: 34.1s\tremaining: 16.2s\n",
      "3116:\tlearn: 1.8641548\ttotal: 34.1s\tremaining: 16.2s\n",
      "3117:\tlearn: 1.8638805\ttotal: 34.1s\tremaining: 16.2s\n",
      "3118:\tlearn: 1.8636493\ttotal: 34.1s\tremaining: 16.2s\n",
      "3119:\tlearn: 1.8631634\ttotal: 34.1s\tremaining: 16.2s\n",
      "3120:\tlearn: 1.8628751\ttotal: 34.1s\tremaining: 16.2s\n",
      "3121:\tlearn: 1.8625613\ttotal: 34.2s\tremaining: 16.1s\n",
      "3122:\tlearn: 1.8623109\ttotal: 34.2s\tremaining: 16.1s\n",
      "3123:\tlearn: 1.8620548\ttotal: 34.2s\tremaining: 16.1s\n",
      "3124:\tlearn: 1.8617669\ttotal: 34.2s\tremaining: 16.1s\n",
      "3125:\tlearn: 1.8614521\ttotal: 34.2s\tremaining: 16.1s\n",
      "3126:\tlearn: 1.8611036\ttotal: 34.2s\tremaining: 16.1s\n",
      "3127:\tlearn: 1.8607743\ttotal: 34.2s\tremaining: 16.1s\n",
      "3128:\tlearn: 1.8605078\ttotal: 34.2s\tremaining: 16.1s\n",
      "3129:\tlearn: 1.8599341\ttotal: 34.2s\tremaining: 16.1s\n",
      "3130:\tlearn: 1.8595198\ttotal: 34.3s\tremaining: 16s\n",
      "3131:\tlearn: 1.8591945\ttotal: 34.3s\tremaining: 16s\n",
      "3132:\tlearn: 1.8588678\ttotal: 34.3s\tremaining: 16s\n",
      "3133:\tlearn: 1.8584903\ttotal: 34.3s\tremaining: 16s\n",
      "3134:\tlearn: 1.8581538\ttotal: 34.3s\tremaining: 16s\n",
      "3135:\tlearn: 1.8579530\ttotal: 34.3s\tremaining: 16s\n",
      "3136:\tlearn: 1.8577472\ttotal: 34.3s\tremaining: 16s\n",
      "3137:\tlearn: 1.8574754\ttotal: 34.3s\tremaining: 16s\n",
      "3138:\tlearn: 1.8572584\ttotal: 34.3s\tremaining: 16s\n",
      "3139:\tlearn: 1.8568818\ttotal: 34.4s\tremaining: 16s\n",
      "3140:\tlearn: 1.8564737\ttotal: 34.4s\tremaining: 15.9s\n",
      "3141:\tlearn: 1.8563289\ttotal: 34.4s\tremaining: 15.9s\n",
      "3142:\tlearn: 1.8559740\ttotal: 34.4s\tremaining: 15.9s\n",
      "3143:\tlearn: 1.8556892\ttotal: 34.4s\tremaining: 15.9s\n",
      "3144:\tlearn: 1.8552234\ttotal: 34.4s\tremaining: 15.9s\n",
      "3145:\tlearn: 1.8547982\ttotal: 34.4s\tremaining: 15.9s\n",
      "3146:\tlearn: 1.8545495\ttotal: 34.4s\tremaining: 15.9s\n",
      "3147:\tlearn: 1.8541645\ttotal: 34.4s\tremaining: 15.9s\n",
      "3148:\tlearn: 1.8537268\ttotal: 34.5s\tremaining: 15.9s\n",
      "3149:\tlearn: 1.8534703\ttotal: 34.5s\tremaining: 15.8s\n",
      "3150:\tlearn: 1.8532889\ttotal: 34.5s\tremaining: 15.8s\n",
      "3151:\tlearn: 1.8529352\ttotal: 34.5s\tremaining: 15.8s\n",
      "3152:\tlearn: 1.8525545\ttotal: 34.5s\tremaining: 15.8s\n",
      "3153:\tlearn: 1.8520183\ttotal: 34.5s\tremaining: 15.8s\n",
      "3154:\tlearn: 1.8517004\ttotal: 34.5s\tremaining: 15.8s\n",
      "3155:\tlearn: 1.8512503\ttotal: 34.5s\tremaining: 15.8s\n",
      "3156:\tlearn: 1.8509418\ttotal: 34.5s\tremaining: 15.8s\n",
      "3157:\tlearn: 1.8506533\ttotal: 34.6s\tremaining: 15.8s\n",
      "3158:\tlearn: 1.8505012\ttotal: 34.6s\tremaining: 15.7s\n",
      "3159:\tlearn: 1.8502164\ttotal: 34.6s\tremaining: 15.7s\n",
      "3160:\tlearn: 1.8494700\ttotal: 34.6s\tremaining: 15.7s\n",
      "3161:\tlearn: 1.8493570\ttotal: 34.6s\tremaining: 15.7s\n",
      "3162:\tlearn: 1.8491106\ttotal: 34.6s\tremaining: 15.7s\n",
      "3163:\tlearn: 1.8488252\ttotal: 34.6s\tremaining: 15.7s\n",
      "3164:\tlearn: 1.8486171\ttotal: 34.6s\tremaining: 15.7s\n",
      "3165:\tlearn: 1.8486166\ttotal: 34.6s\tremaining: 15.7s\n",
      "3166:\tlearn: 1.8483560\ttotal: 34.6s\tremaining: 15.7s\n",
      "3167:\tlearn: 1.8480807\ttotal: 34.7s\tremaining: 15.6s\n",
      "3168:\tlearn: 1.8474595\ttotal: 34.7s\tremaining: 15.6s\n",
      "3169:\tlearn: 1.8472880\ttotal: 34.7s\tremaining: 15.6s\n",
      "3170:\tlearn: 1.8471137\ttotal: 34.7s\tremaining: 15.6s\n",
      "3171:\tlearn: 1.8464225\ttotal: 34.7s\tremaining: 15.6s\n",
      "3172:\tlearn: 1.8461828\ttotal: 34.7s\tremaining: 15.6s\n",
      "3173:\tlearn: 1.8456828\ttotal: 34.7s\tremaining: 15.6s\n",
      "3174:\tlearn: 1.8454499\ttotal: 34.7s\tremaining: 15.6s\n",
      "3175:\tlearn: 1.8451641\ttotal: 34.7s\tremaining: 15.6s\n",
      "3176:\tlearn: 1.8447965\ttotal: 34.8s\tremaining: 15.5s\n",
      "3177:\tlearn: 1.8445938\ttotal: 34.8s\tremaining: 15.5s\n",
      "3178:\tlearn: 1.8441973\ttotal: 34.8s\tremaining: 15.5s\n",
      "3179:\tlearn: 1.8438355\ttotal: 34.8s\tremaining: 15.5s\n",
      "3180:\tlearn: 1.8436568\ttotal: 34.8s\tremaining: 15.5s\n",
      "3181:\tlearn: 1.8434592\ttotal: 34.8s\tremaining: 15.5s\n",
      "3182:\tlearn: 1.8431071\ttotal: 34.8s\tremaining: 15.5s\n",
      "3183:\tlearn: 1.8428087\ttotal: 34.8s\tremaining: 15.5s\n",
      "3184:\tlearn: 1.8424000\ttotal: 34.8s\tremaining: 15.5s\n",
      "3185:\tlearn: 1.8419071\ttotal: 34.9s\tremaining: 15.4s\n",
      "3186:\tlearn: 1.8415253\ttotal: 34.9s\tremaining: 15.4s\n",
      "3187:\tlearn: 1.8412400\ttotal: 34.9s\tremaining: 15.4s\n",
      "3188:\tlearn: 1.8408061\ttotal: 34.9s\tremaining: 15.4s\n",
      "3189:\tlearn: 1.8400755\ttotal: 34.9s\tremaining: 15.4s\n",
      "3190:\tlearn: 1.8396612\ttotal: 34.9s\tremaining: 15.4s\n",
      "3191:\tlearn: 1.8392755\ttotal: 34.9s\tremaining: 15.4s\n",
      "3192:\tlearn: 1.8389101\ttotal: 34.9s\tremaining: 15.4s\n",
      "3193:\tlearn: 1.8388063\ttotal: 34.9s\tremaining: 15.4s\n",
      "3194:\tlearn: 1.8383879\ttotal: 35s\tremaining: 15.3s\n",
      "3195:\tlearn: 1.8381180\ttotal: 35s\tremaining: 15.3s\n",
      "3196:\tlearn: 1.8379181\ttotal: 35s\tremaining: 15.3s\n",
      "3197:\tlearn: 1.8374937\ttotal: 35s\tremaining: 15.3s\n",
      "3198:\tlearn: 1.8373857\ttotal: 35s\tremaining: 15.3s\n",
      "3199:\tlearn: 1.8367743\ttotal: 35s\tremaining: 15.3s\n",
      "3200:\tlearn: 1.8365879\ttotal: 35s\tremaining: 15.3s\n",
      "3201:\tlearn: 1.8363438\ttotal: 35s\tremaining: 15.3s\n",
      "3202:\tlearn: 1.8361457\ttotal: 35s\tremaining: 15.3s\n",
      "3203:\tlearn: 1.8357678\ttotal: 35.1s\tremaining: 15.3s\n",
      "3204:\tlearn: 1.8355682\ttotal: 35.1s\tremaining: 15.2s\n",
      "3205:\tlearn: 1.8351276\ttotal: 35.1s\tremaining: 15.2s\n",
      "3206:\tlearn: 1.8350397\ttotal: 35.1s\tremaining: 15.2s\n",
      "3207:\tlearn: 1.8344899\ttotal: 35.1s\tremaining: 15.2s\n",
      "3208:\tlearn: 1.8339949\ttotal: 35.1s\tremaining: 15.2s\n",
      "3209:\tlearn: 1.8336575\ttotal: 35.1s\tremaining: 15.2s\n",
      "3210:\tlearn: 1.8329403\ttotal: 35.1s\tremaining: 15.2s\n",
      "3211:\tlearn: 1.8327492\ttotal: 35.1s\tremaining: 15.2s\n",
      "3212:\tlearn: 1.8325965\ttotal: 35.2s\tremaining: 15.2s\n",
      "3213:\tlearn: 1.8324747\ttotal: 35.2s\tremaining: 15.1s\n",
      "3214:\tlearn: 1.8322997\ttotal: 35.2s\tremaining: 15.1s\n",
      "3215:\tlearn: 1.8319972\ttotal: 35.2s\tremaining: 15.1s\n",
      "3216:\tlearn: 1.8317379\ttotal: 35.2s\tremaining: 15.1s\n",
      "3217:\tlearn: 1.8311549\ttotal: 35.2s\tremaining: 15.1s\n",
      "3218:\tlearn: 1.8308614\ttotal: 35.2s\tremaining: 15.1s\n",
      "3219:\tlearn: 1.8305049\ttotal: 35.2s\tremaining: 15.1s\n",
      "3220:\tlearn: 1.8301469\ttotal: 35.2s\tremaining: 15.1s\n",
      "3221:\tlearn: 1.8299331\ttotal: 35.3s\tremaining: 15.1s\n",
      "3222:\tlearn: 1.8296544\ttotal: 35.3s\tremaining: 15s\n",
      "3223:\tlearn: 1.8293656\ttotal: 35.3s\tremaining: 15s\n",
      "3224:\tlearn: 1.8290690\ttotal: 35.3s\tremaining: 15s\n",
      "3225:\tlearn: 1.8288234\ttotal: 35.3s\tremaining: 15s\n",
      "3226:\tlearn: 1.8284951\ttotal: 35.3s\tremaining: 15s\n",
      "3227:\tlearn: 1.8280745\ttotal: 35.3s\tremaining: 15s\n",
      "3228:\tlearn: 1.8277610\ttotal: 35.3s\tremaining: 15s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3229:\tlearn: 1.8275713\ttotal: 35.3s\tremaining: 15s\n",
      "3230:\tlearn: 1.8272526\ttotal: 35.4s\tremaining: 15s\n",
      "3231:\tlearn: 1.8269973\ttotal: 35.4s\tremaining: 14.9s\n",
      "3232:\tlearn: 1.8266499\ttotal: 35.4s\tremaining: 14.9s\n",
      "3233:\tlearn: 1.8263623\ttotal: 35.4s\tremaining: 14.9s\n",
      "3234:\tlearn: 1.8260843\ttotal: 35.4s\tremaining: 14.9s\n",
      "3235:\tlearn: 1.8259522\ttotal: 35.4s\tremaining: 14.9s\n",
      "3236:\tlearn: 1.8255162\ttotal: 35.4s\tremaining: 14.9s\n",
      "3237:\tlearn: 1.8252502\ttotal: 35.4s\tremaining: 14.9s\n",
      "3238:\tlearn: 1.8249218\ttotal: 35.4s\tremaining: 14.9s\n",
      "3239:\tlearn: 1.8246177\ttotal: 35.5s\tremaining: 14.9s\n",
      "3240:\tlearn: 1.8244379\ttotal: 35.5s\tremaining: 14.8s\n",
      "3241:\tlearn: 1.8242395\ttotal: 35.5s\tremaining: 14.8s\n",
      "3242:\tlearn: 1.8241300\ttotal: 35.5s\tremaining: 14.8s\n",
      "3243:\tlearn: 1.8238433\ttotal: 35.5s\tremaining: 14.8s\n",
      "3244:\tlearn: 1.8238083\ttotal: 35.5s\tremaining: 14.8s\n",
      "3245:\tlearn: 1.8233965\ttotal: 35.5s\tremaining: 14.8s\n",
      "3246:\tlearn: 1.8232616\ttotal: 35.5s\tremaining: 14.8s\n",
      "3247:\tlearn: 1.8227967\ttotal: 35.5s\tremaining: 14.8s\n",
      "3248:\tlearn: 1.8225978\ttotal: 35.5s\tremaining: 14.8s\n",
      "3249:\tlearn: 1.8224433\ttotal: 35.6s\tremaining: 14.7s\n",
      "3250:\tlearn: 1.8221982\ttotal: 35.6s\tremaining: 14.7s\n",
      "3251:\tlearn: 1.8214545\ttotal: 35.6s\tremaining: 14.7s\n",
      "3252:\tlearn: 1.8213467\ttotal: 35.6s\tremaining: 14.7s\n",
      "3253:\tlearn: 1.8208272\ttotal: 35.6s\tremaining: 14.7s\n",
      "3254:\tlearn: 1.8205488\ttotal: 35.6s\tremaining: 14.7s\n",
      "3255:\tlearn: 1.8202181\ttotal: 35.6s\tremaining: 14.7s\n",
      "3256:\tlearn: 1.8199304\ttotal: 35.6s\tremaining: 14.7s\n",
      "3257:\tlearn: 1.8195492\ttotal: 35.7s\tremaining: 14.7s\n",
      "3258:\tlearn: 1.8191705\ttotal: 35.7s\tremaining: 14.7s\n",
      "3259:\tlearn: 1.8189123\ttotal: 35.7s\tremaining: 14.6s\n",
      "3260:\tlearn: 1.8187033\ttotal: 35.7s\tremaining: 14.6s\n",
      "3261:\tlearn: 1.8184450\ttotal: 35.7s\tremaining: 14.6s\n",
      "3262:\tlearn: 1.8181714\ttotal: 35.7s\tremaining: 14.6s\n",
      "3263:\tlearn: 1.8177191\ttotal: 35.7s\tremaining: 14.6s\n",
      "3264:\tlearn: 1.8175858\ttotal: 35.7s\tremaining: 14.6s\n",
      "3265:\tlearn: 1.8173607\ttotal: 35.7s\tremaining: 14.6s\n",
      "3266:\tlearn: 1.8170399\ttotal: 35.7s\tremaining: 14.6s\n",
      "3267:\tlearn: 1.8166723\ttotal: 35.8s\tremaining: 14.6s\n",
      "3268:\tlearn: 1.8164684\ttotal: 35.8s\tremaining: 14.5s\n",
      "3269:\tlearn: 1.8162149\ttotal: 35.8s\tremaining: 14.5s\n",
      "3270:\tlearn: 1.8158619\ttotal: 35.8s\tremaining: 14.5s\n",
      "3271:\tlearn: 1.8155712\ttotal: 35.8s\tremaining: 14.5s\n",
      "3272:\tlearn: 1.8152951\ttotal: 35.8s\tremaining: 14.5s\n",
      "3273:\tlearn: 1.8148740\ttotal: 35.8s\tremaining: 14.5s\n",
      "3274:\tlearn: 1.8145900\ttotal: 35.8s\tremaining: 14.5s\n",
      "3275:\tlearn: 1.8141053\ttotal: 35.9s\tremaining: 14.5s\n",
      "3276:\tlearn: 1.8138135\ttotal: 35.9s\tremaining: 14.5s\n",
      "3277:\tlearn: 1.8135124\ttotal: 35.9s\tremaining: 14.4s\n",
      "3278:\tlearn: 1.8131063\ttotal: 35.9s\tremaining: 14.4s\n",
      "3279:\tlearn: 1.8130060\ttotal: 35.9s\tremaining: 14.4s\n",
      "3280:\tlearn: 1.8127856\ttotal: 35.9s\tremaining: 14.4s\n",
      "3281:\tlearn: 1.8126461\ttotal: 35.9s\tremaining: 14.4s\n",
      "3282:\tlearn: 1.8125022\ttotal: 35.9s\tremaining: 14.4s\n",
      "3283:\tlearn: 1.8122824\ttotal: 35.9s\tremaining: 14.4s\n",
      "3284:\tlearn: 1.8121667\ttotal: 35.9s\tremaining: 14.4s\n",
      "3285:\tlearn: 1.8119655\ttotal: 36s\tremaining: 14.4s\n",
      "3286:\tlearn: 1.8117485\ttotal: 36s\tremaining: 14.3s\n",
      "3287:\tlearn: 1.8113296\ttotal: 36s\tremaining: 14.3s\n",
      "3288:\tlearn: 1.8111368\ttotal: 36s\tremaining: 14.3s\n",
      "3289:\tlearn: 1.8107304\ttotal: 36s\tremaining: 14.3s\n",
      "3290:\tlearn: 1.8105045\ttotal: 36s\tremaining: 14.3s\n",
      "3291:\tlearn: 1.8101760\ttotal: 36s\tremaining: 14.3s\n",
      "3292:\tlearn: 1.8099650\ttotal: 36s\tremaining: 14.3s\n",
      "3293:\tlearn: 1.8096586\ttotal: 36s\tremaining: 14.3s\n",
      "3294:\tlearn: 1.8094731\ttotal: 36.1s\tremaining: 14.3s\n",
      "3295:\tlearn: 1.8090809\ttotal: 36.1s\tremaining: 14.2s\n",
      "3296:\tlearn: 1.8087494\ttotal: 36.1s\tremaining: 14.2s\n",
      "3297:\tlearn: 1.8083878\ttotal: 36.1s\tremaining: 14.2s\n",
      "3298:\tlearn: 1.8083078\ttotal: 36.1s\tremaining: 14.2s\n",
      "3299:\tlearn: 1.8078699\ttotal: 36.1s\tremaining: 14.2s\n",
      "3300:\tlearn: 1.8075175\ttotal: 36.1s\tremaining: 14.2s\n",
      "3301:\tlearn: 1.8072135\ttotal: 36.1s\tremaining: 14.2s\n",
      "3302:\tlearn: 1.8066215\ttotal: 36.1s\tremaining: 14.2s\n",
      "3303:\tlearn: 1.8064557\ttotal: 36.2s\tremaining: 14.2s\n",
      "3304:\tlearn: 1.8057923\ttotal: 36.2s\tremaining: 14.1s\n",
      "3305:\tlearn: 1.8053300\ttotal: 36.2s\tremaining: 14.1s\n",
      "3306:\tlearn: 1.8048443\ttotal: 36.2s\tremaining: 14.1s\n",
      "3307:\tlearn: 1.8046171\ttotal: 36.2s\tremaining: 14.1s\n",
      "3308:\tlearn: 1.8043804\ttotal: 36.2s\tremaining: 14.1s\n",
      "3309:\tlearn: 1.8041050\ttotal: 36.2s\tremaining: 14.1s\n",
      "3310:\tlearn: 1.8038409\ttotal: 36.2s\tremaining: 14.1s\n",
      "3311:\tlearn: 1.8036071\ttotal: 36.2s\tremaining: 14.1s\n",
      "3312:\tlearn: 1.8032511\ttotal: 36.3s\tremaining: 14.1s\n",
      "3313:\tlearn: 1.8030699\ttotal: 36.3s\tremaining: 14.1s\n",
      "3314:\tlearn: 1.8028437\ttotal: 36.3s\tremaining: 14s\n",
      "3315:\tlearn: 1.8027157\ttotal: 36.3s\tremaining: 14s\n",
      "3316:\tlearn: 1.8020740\ttotal: 36.3s\tremaining: 14s\n",
      "3317:\tlearn: 1.8018507\ttotal: 36.3s\tremaining: 14s\n",
      "3318:\tlearn: 1.8015943\ttotal: 36.3s\tremaining: 14s\n",
      "3319:\tlearn: 1.8011937\ttotal: 36.3s\tremaining: 14s\n",
      "3320:\tlearn: 1.8009030\ttotal: 36.3s\tremaining: 14s\n",
      "3321:\tlearn: 1.8005182\ttotal: 36.4s\tremaining: 14s\n",
      "3322:\tlearn: 1.8002507\ttotal: 36.4s\tremaining: 14s\n",
      "3323:\tlearn: 1.7999450\ttotal: 36.4s\tremaining: 13.9s\n",
      "3324:\tlearn: 1.7997945\ttotal: 36.4s\tremaining: 13.9s\n",
      "3325:\tlearn: 1.7994665\ttotal: 36.4s\tremaining: 13.9s\n",
      "3326:\tlearn: 1.7990943\ttotal: 36.4s\tremaining: 13.9s\n",
      "3327:\tlearn: 1.7989418\ttotal: 36.4s\tremaining: 13.9s\n",
      "3328:\tlearn: 1.7985545\ttotal: 36.4s\tremaining: 13.9s\n",
      "3329:\tlearn: 1.7983193\ttotal: 36.5s\tremaining: 13.9s\n",
      "3330:\tlearn: 1.7980395\ttotal: 36.5s\tremaining: 13.9s\n",
      "3331:\tlearn: 1.7977381\ttotal: 36.5s\tremaining: 13.9s\n",
      "3332:\tlearn: 1.7974782\ttotal: 36.5s\tremaining: 13.8s\n",
      "3333:\tlearn: 1.7972010\ttotal: 36.5s\tremaining: 13.8s\n",
      "3334:\tlearn: 1.7967903\ttotal: 36.5s\tremaining: 13.8s\n",
      "3335:\tlearn: 1.7964513\ttotal: 36.5s\tremaining: 13.8s\n",
      "3336:\tlearn: 1.7963758\ttotal: 36.5s\tremaining: 13.8s\n",
      "3337:\tlearn: 1.7961202\ttotal: 36.5s\tremaining: 13.8s\n",
      "3338:\tlearn: 1.7959069\ttotal: 36.5s\tremaining: 13.8s\n",
      "3339:\tlearn: 1.7956184\ttotal: 36.6s\tremaining: 13.8s\n",
      "3340:\tlearn: 1.7950360\ttotal: 36.6s\tremaining: 13.8s\n",
      "3341:\tlearn: 1.7948590\ttotal: 36.6s\tremaining: 13.7s\n",
      "3342:\tlearn: 1.7946859\ttotal: 36.6s\tremaining: 13.7s\n",
      "3343:\tlearn: 1.7944162\ttotal: 36.6s\tremaining: 13.7s\n",
      "3344:\tlearn: 1.7941181\ttotal: 36.6s\tremaining: 13.7s\n",
      "3345:\tlearn: 1.7938898\ttotal: 36.6s\tremaining: 13.7s\n",
      "3346:\tlearn: 1.7937083\ttotal: 36.6s\tremaining: 13.7s\n",
      "3347:\tlearn: 1.7933852\ttotal: 36.6s\tremaining: 13.7s\n",
      "3348:\tlearn: 1.7930814\ttotal: 36.7s\tremaining: 13.7s\n",
      "3349:\tlearn: 1.7929491\ttotal: 36.7s\tremaining: 13.7s\n",
      "3350:\tlearn: 1.7926931\ttotal: 36.7s\tremaining: 13.6s\n",
      "3351:\tlearn: 1.7924585\ttotal: 36.7s\tremaining: 13.6s\n",
      "3352:\tlearn: 1.7921399\ttotal: 36.7s\tremaining: 13.6s\n",
      "3353:\tlearn: 1.7918957\ttotal: 36.7s\tremaining: 13.6s\n",
      "3354:\tlearn: 1.7915225\ttotal: 36.7s\tremaining: 13.6s\n",
      "3355:\tlearn: 1.7914051\ttotal: 36.7s\tremaining: 13.6s\n",
      "3356:\tlearn: 1.7910798\ttotal: 36.7s\tremaining: 13.6s\n",
      "3357:\tlearn: 1.7908870\ttotal: 36.8s\tremaining: 13.6s\n",
      "3358:\tlearn: 1.7906002\ttotal: 36.8s\tremaining: 13.6s\n",
      "3359:\tlearn: 1.7904085\ttotal: 36.8s\tremaining: 13.5s\n",
      "3360:\tlearn: 1.7901492\ttotal: 36.8s\tremaining: 13.5s\n",
      "3361:\tlearn: 1.7898355\ttotal: 36.8s\tremaining: 13.5s\n",
      "3362:\tlearn: 1.7895654\ttotal: 36.8s\tremaining: 13.5s\n",
      "3363:\tlearn: 1.7893502\ttotal: 36.8s\tremaining: 13.5s\n",
      "3364:\tlearn: 1.7891672\ttotal: 36.8s\tremaining: 13.5s\n",
      "3365:\tlearn: 1.7887875\ttotal: 36.8s\tremaining: 13.5s\n",
      "3366:\tlearn: 1.7886838\ttotal: 36.9s\tremaining: 13.5s\n",
      "3367:\tlearn: 1.7884073\ttotal: 36.9s\tremaining: 13.5s\n",
      "3368:\tlearn: 1.7882829\ttotal: 36.9s\tremaining: 13.4s\n",
      "3369:\tlearn: 1.7880084\ttotal: 36.9s\tremaining: 13.4s\n",
      "3370:\tlearn: 1.7877317\ttotal: 36.9s\tremaining: 13.4s\n",
      "3371:\tlearn: 1.7875404\ttotal: 36.9s\tremaining: 13.4s\n",
      "3372:\tlearn: 1.7873934\ttotal: 36.9s\tremaining: 13.4s\n",
      "3373:\tlearn: 1.7872831\ttotal: 36.9s\tremaining: 13.4s\n",
      "3374:\tlearn: 1.7869137\ttotal: 36.9s\tremaining: 13.4s\n",
      "3375:\tlearn: 1.7866350\ttotal: 36.9s\tremaining: 13.4s\n",
      "3376:\tlearn: 1.7864482\ttotal: 37s\tremaining: 13.4s\n",
      "3377:\tlearn: 1.7860670\ttotal: 37s\tremaining: 13.3s\n",
      "3378:\tlearn: 1.7860664\ttotal: 37s\tremaining: 13.3s\n",
      "3379:\tlearn: 1.7858192\ttotal: 37s\tremaining: 13.3s\n",
      "3380:\tlearn: 1.7855134\ttotal: 37s\tremaining: 13.3s\n",
      "3381:\tlearn: 1.7851884\ttotal: 37s\tremaining: 13.3s\n",
      "3382:\tlearn: 1.7849832\ttotal: 37s\tremaining: 13.3s\n",
      "3383:\tlearn: 1.7845311\ttotal: 37s\tremaining: 13.3s\n",
      "3384:\tlearn: 1.7841485\ttotal: 37s\tremaining: 13.3s\n",
      "3385:\tlearn: 1.7838719\ttotal: 37.1s\tremaining: 13.3s\n",
      "3386:\tlearn: 1.7834172\ttotal: 37.1s\tremaining: 13.3s\n",
      "3387:\tlearn: 1.7833156\ttotal: 37.1s\tremaining: 13.2s\n",
      "3388:\tlearn: 1.7830388\ttotal: 37.1s\tremaining: 13.2s\n",
      "3389:\tlearn: 1.7828227\ttotal: 37.1s\tremaining: 13.2s\n",
      "3390:\tlearn: 1.7824863\ttotal: 37.1s\tremaining: 13.2s\n",
      "3391:\tlearn: 1.7823124\ttotal: 37.1s\tremaining: 13.2s\n",
      "3392:\tlearn: 1.7820760\ttotal: 37.1s\tremaining: 13.2s\n",
      "3393:\tlearn: 1.7816245\ttotal: 37.1s\tremaining: 13.2s\n",
      "3394:\tlearn: 1.7813096\ttotal: 37.2s\tremaining: 13.2s\n",
      "3395:\tlearn: 1.7812533\ttotal: 37.2s\tremaining: 13.2s\n",
      "3396:\tlearn: 1.7810740\ttotal: 37.2s\tremaining: 13.1s\n",
      "3397:\tlearn: 1.7809284\ttotal: 37.2s\tremaining: 13.1s\n",
      "3398:\tlearn: 1.7805204\ttotal: 37.2s\tremaining: 13.1s\n",
      "3399:\tlearn: 1.7801788\ttotal: 37.2s\tremaining: 13.1s\n",
      "3400:\tlearn: 1.7800323\ttotal: 37.2s\tremaining: 13.1s\n",
      "3401:\tlearn: 1.7797453\ttotal: 37.2s\tremaining: 13.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3402:\tlearn: 1.7793934\ttotal: 37.2s\tremaining: 13.1s\n",
      "3403:\tlearn: 1.7790883\ttotal: 37.3s\tremaining: 13.1s\n",
      "3404:\tlearn: 1.7786249\ttotal: 37.3s\tremaining: 13.1s\n",
      "3405:\tlearn: 1.7783771\ttotal: 37.3s\tremaining: 13s\n",
      "3406:\tlearn: 1.7781637\ttotal: 37.3s\tremaining: 13s\n",
      "3407:\tlearn: 1.7777674\ttotal: 37.3s\tremaining: 13s\n",
      "3408:\tlearn: 1.7776520\ttotal: 37.3s\tremaining: 13s\n",
      "3409:\tlearn: 1.7770960\ttotal: 37.3s\tremaining: 13s\n",
      "3410:\tlearn: 1.7768301\ttotal: 37.3s\tremaining: 13s\n",
      "3411:\tlearn: 1.7765421\ttotal: 37.3s\tremaining: 13s\n",
      "3412:\tlearn: 1.7762083\ttotal: 37.4s\tremaining: 13s\n",
      "3413:\tlearn: 1.7759151\ttotal: 37.4s\tremaining: 13s\n",
      "3414:\tlearn: 1.7756252\ttotal: 37.4s\tremaining: 12.9s\n",
      "3415:\tlearn: 1.7752223\ttotal: 37.4s\tremaining: 12.9s\n",
      "3416:\tlearn: 1.7751671\ttotal: 37.4s\tremaining: 12.9s\n",
      "3417:\tlearn: 1.7749055\ttotal: 37.4s\tremaining: 12.9s\n",
      "3418:\tlearn: 1.7745602\ttotal: 37.4s\tremaining: 12.9s\n",
      "3419:\tlearn: 1.7744118\ttotal: 37.4s\tremaining: 12.9s\n",
      "3420:\tlearn: 1.7742372\ttotal: 37.4s\tremaining: 12.9s\n",
      "3421:\tlearn: 1.7740878\ttotal: 37.5s\tremaining: 12.9s\n",
      "3422:\tlearn: 1.7737988\ttotal: 37.5s\tremaining: 12.9s\n",
      "3423:\tlearn: 1.7734417\ttotal: 37.5s\tremaining: 12.8s\n",
      "3424:\tlearn: 1.7730964\ttotal: 37.5s\tremaining: 12.8s\n",
      "3425:\tlearn: 1.7729534\ttotal: 37.5s\tremaining: 12.8s\n",
      "3426:\tlearn: 1.7728857\ttotal: 37.5s\tremaining: 12.8s\n",
      "3427:\tlearn: 1.7726386\ttotal: 37.5s\tremaining: 12.8s\n",
      "3428:\tlearn: 1.7723806\ttotal: 37.5s\tremaining: 12.8s\n",
      "3429:\tlearn: 1.7721837\ttotal: 37.5s\tremaining: 12.8s\n",
      "3430:\tlearn: 1.7719720\ttotal: 37.5s\tremaining: 12.8s\n",
      "3431:\tlearn: 1.7718130\ttotal: 37.6s\tremaining: 12.8s\n",
      "3432:\tlearn: 1.7716758\ttotal: 37.6s\tremaining: 12.7s\n",
      "3433:\tlearn: 1.7715757\ttotal: 37.6s\tremaining: 12.7s\n",
      "3434:\tlearn: 1.7715381\ttotal: 37.6s\tremaining: 12.7s\n",
      "3435:\tlearn: 1.7713480\ttotal: 37.6s\tremaining: 12.7s\n",
      "3436:\tlearn: 1.7710113\ttotal: 37.6s\tremaining: 12.7s\n",
      "3437:\tlearn: 1.7708454\ttotal: 37.6s\tremaining: 12.7s\n",
      "3438:\tlearn: 1.7706168\ttotal: 37.6s\tremaining: 12.7s\n",
      "3439:\tlearn: 1.7702723\ttotal: 37.6s\tremaining: 12.7s\n",
      "3440:\tlearn: 1.7701909\ttotal: 37.7s\tremaining: 12.7s\n",
      "3441:\tlearn: 1.7701272\ttotal: 37.7s\tremaining: 12.6s\n",
      "3442:\tlearn: 1.7699538\ttotal: 37.7s\tremaining: 12.6s\n",
      "3443:\tlearn: 1.7696648\ttotal: 37.7s\tremaining: 12.6s\n",
      "3444:\tlearn: 1.7694118\ttotal: 37.7s\tremaining: 12.6s\n",
      "3445:\tlearn: 1.7691938\ttotal: 37.7s\tremaining: 12.6s\n",
      "3446:\tlearn: 1.7689250\ttotal: 37.7s\tremaining: 12.6s\n",
      "3447:\tlearn: 1.7687020\ttotal: 37.7s\tremaining: 12.6s\n",
      "3448:\tlearn: 1.7683815\ttotal: 37.7s\tremaining: 12.6s\n",
      "3449:\tlearn: 1.7679487\ttotal: 37.8s\tremaining: 12.6s\n",
      "3450:\tlearn: 1.7676893\ttotal: 37.8s\tremaining: 12.6s\n",
      "3451:\tlearn: 1.7674709\ttotal: 37.8s\tremaining: 12.5s\n",
      "3452:\tlearn: 1.7670800\ttotal: 37.8s\tremaining: 12.5s\n",
      "3453:\tlearn: 1.7667957\ttotal: 37.8s\tremaining: 12.5s\n",
      "3454:\tlearn: 1.7665220\ttotal: 37.8s\tremaining: 12.5s\n",
      "3455:\tlearn: 1.7660508\ttotal: 37.8s\tremaining: 12.5s\n",
      "3456:\tlearn: 1.7657791\ttotal: 37.8s\tremaining: 12.5s\n",
      "3457:\tlearn: 1.7655647\ttotal: 37.8s\tremaining: 12.5s\n",
      "3458:\tlearn: 1.7653975\ttotal: 37.9s\tremaining: 12.5s\n",
      "3459:\tlearn: 1.7652548\ttotal: 37.9s\tremaining: 12.5s\n",
      "3460:\tlearn: 1.7649799\ttotal: 37.9s\tremaining: 12.4s\n",
      "3461:\tlearn: 1.7648150\ttotal: 37.9s\tremaining: 12.4s\n",
      "3462:\tlearn: 1.7646890\ttotal: 37.9s\tremaining: 12.4s\n",
      "3463:\tlearn: 1.7644291\ttotal: 37.9s\tremaining: 12.4s\n",
      "3464:\tlearn: 1.7639507\ttotal: 37.9s\tremaining: 12.4s\n",
      "3465:\tlearn: 1.7637752\ttotal: 37.9s\tremaining: 12.4s\n",
      "3466:\tlearn: 1.7631940\ttotal: 37.9s\tremaining: 12.4s\n",
      "3467:\tlearn: 1.7629396\ttotal: 38s\tremaining: 12.4s\n",
      "3468:\tlearn: 1.7627034\ttotal: 38s\tremaining: 12.4s\n",
      "3469:\tlearn: 1.7625542\ttotal: 38s\tremaining: 12.3s\n",
      "3470:\tlearn: 1.7621665\ttotal: 38s\tremaining: 12.3s\n",
      "3471:\tlearn: 1.7619470\ttotal: 38s\tremaining: 12.3s\n",
      "3472:\tlearn: 1.7617438\ttotal: 38s\tremaining: 12.3s\n",
      "3473:\tlearn: 1.7616234\ttotal: 38s\tremaining: 12.3s\n",
      "3474:\tlearn: 1.7610618\ttotal: 38s\tremaining: 12.3s\n",
      "3475:\tlearn: 1.7607739\ttotal: 38s\tremaining: 12.3s\n",
      "3476:\tlearn: 1.7603240\ttotal: 38.1s\tremaining: 12.3s\n",
      "3477:\tlearn: 1.7602891\ttotal: 38.1s\tremaining: 12.3s\n",
      "3478:\tlearn: 1.7597775\ttotal: 38.1s\tremaining: 12.2s\n",
      "3479:\tlearn: 1.7595805\ttotal: 38.1s\tremaining: 12.2s\n",
      "3480:\tlearn: 1.7592820\ttotal: 38.1s\tremaining: 12.2s\n",
      "3481:\tlearn: 1.7589546\ttotal: 38.1s\tremaining: 12.2s\n",
      "3482:\tlearn: 1.7585863\ttotal: 38.1s\tremaining: 12.2s\n",
      "3483:\tlearn: 1.7583112\ttotal: 38.1s\tremaining: 12.2s\n",
      "3484:\tlearn: 1.7581513\ttotal: 38.1s\tremaining: 12.2s\n",
      "3485:\tlearn: 1.7579626\ttotal: 38.1s\tremaining: 12.2s\n",
      "3486:\tlearn: 1.7578067\ttotal: 38.2s\tremaining: 12.2s\n",
      "3487:\tlearn: 1.7574616\ttotal: 38.2s\tremaining: 12.1s\n",
      "3488:\tlearn: 1.7571770\ttotal: 38.2s\tremaining: 12.1s\n",
      "3489:\tlearn: 1.7570025\ttotal: 38.2s\tremaining: 12.1s\n",
      "3490:\tlearn: 1.7569547\ttotal: 38.2s\tremaining: 12.1s\n",
      "3491:\tlearn: 1.7567287\ttotal: 38.2s\tremaining: 12.1s\n",
      "3492:\tlearn: 1.7564349\ttotal: 38.2s\tremaining: 12.1s\n",
      "3493:\tlearn: 1.7563050\ttotal: 38.2s\tremaining: 12.1s\n",
      "3494:\tlearn: 1.7560849\ttotal: 38.2s\tremaining: 12.1s\n",
      "3495:\tlearn: 1.7559155\ttotal: 38.3s\tremaining: 12.1s\n",
      "3496:\tlearn: 1.7557395\ttotal: 38.3s\tremaining: 12s\n",
      "3497:\tlearn: 1.7554503\ttotal: 38.3s\tremaining: 12s\n",
      "3498:\tlearn: 1.7552289\ttotal: 38.3s\tremaining: 12s\n",
      "3499:\tlearn: 1.7552282\ttotal: 38.3s\tremaining: 12s\n",
      "3500:\tlearn: 1.7549734\ttotal: 38.3s\tremaining: 12s\n",
      "3501:\tlearn: 1.7547585\ttotal: 38.3s\tremaining: 12s\n",
      "3502:\tlearn: 1.7545545\ttotal: 38.3s\tremaining: 12s\n",
      "3503:\tlearn: 1.7545537\ttotal: 38.3s\tremaining: 12s\n",
      "3504:\tlearn: 1.7543215\ttotal: 38.4s\tremaining: 12s\n",
      "3505:\tlearn: 1.7539996\ttotal: 38.4s\tremaining: 11.9s\n",
      "3506:\tlearn: 1.7538012\ttotal: 38.4s\tremaining: 11.9s\n",
      "3507:\tlearn: 1.7535270\ttotal: 38.4s\tremaining: 11.9s\n",
      "3508:\tlearn: 1.7533376\ttotal: 38.4s\tremaining: 11.9s\n",
      "3509:\tlearn: 1.7531568\ttotal: 38.4s\tremaining: 11.9s\n",
      "3510:\tlearn: 1.7529512\ttotal: 38.4s\tremaining: 11.9s\n",
      "3511:\tlearn: 1.7528118\ttotal: 38.4s\tremaining: 11.9s\n",
      "3512:\tlearn: 1.7526411\ttotal: 38.4s\tremaining: 11.9s\n",
      "3513:\tlearn: 1.7523606\ttotal: 38.4s\tremaining: 11.9s\n",
      "3514:\tlearn: 1.7521070\ttotal: 38.5s\tremaining: 11.8s\n",
      "3515:\tlearn: 1.7518669\ttotal: 38.5s\tremaining: 11.8s\n",
      "3516:\tlearn: 1.7512591\ttotal: 38.5s\tremaining: 11.8s\n",
      "3517:\tlearn: 1.7509235\ttotal: 38.5s\tremaining: 11.8s\n",
      "3518:\tlearn: 1.7503999\ttotal: 38.5s\tremaining: 11.8s\n",
      "3519:\tlearn: 1.7498092\ttotal: 38.5s\tremaining: 11.8s\n",
      "3520:\tlearn: 1.7495465\ttotal: 38.5s\tremaining: 11.8s\n",
      "3521:\tlearn: 1.7492794\ttotal: 38.5s\tremaining: 11.8s\n",
      "3522:\tlearn: 1.7490590\ttotal: 38.5s\tremaining: 11.8s\n",
      "3523:\tlearn: 1.7486138\ttotal: 38.6s\tremaining: 11.8s\n",
      "3524:\tlearn: 1.7485213\ttotal: 38.6s\tremaining: 11.7s\n",
      "3525:\tlearn: 1.7482079\ttotal: 38.6s\tremaining: 11.7s\n",
      "3526:\tlearn: 1.7479592\ttotal: 38.6s\tremaining: 11.7s\n",
      "3527:\tlearn: 1.7477452\ttotal: 38.6s\tremaining: 11.7s\n",
      "3528:\tlearn: 1.7474207\ttotal: 38.6s\tremaining: 11.7s\n",
      "3529:\tlearn: 1.7472004\ttotal: 38.6s\tremaining: 11.7s\n",
      "3530:\tlearn: 1.7469156\ttotal: 38.6s\tremaining: 11.7s\n",
      "3531:\tlearn: 1.7465753\ttotal: 38.6s\tremaining: 11.7s\n",
      "3532:\tlearn: 1.7464800\ttotal: 38.7s\tremaining: 11.7s\n",
      "3533:\tlearn: 1.7462316\ttotal: 38.7s\tremaining: 11.6s\n",
      "3534:\tlearn: 1.7459627\ttotal: 38.7s\tremaining: 11.6s\n",
      "3535:\tlearn: 1.7456704\ttotal: 38.7s\tremaining: 11.6s\n",
      "3536:\tlearn: 1.7453144\ttotal: 38.7s\tremaining: 11.6s\n",
      "3537:\tlearn: 1.7449794\ttotal: 38.7s\tremaining: 11.6s\n",
      "3538:\tlearn: 1.7447832\ttotal: 38.7s\tremaining: 11.6s\n",
      "3539:\tlearn: 1.7445928\ttotal: 38.7s\tremaining: 11.6s\n",
      "3540:\tlearn: 1.7443736\ttotal: 38.7s\tremaining: 11.6s\n",
      "3541:\tlearn: 1.7442880\ttotal: 38.8s\tremaining: 11.6s\n",
      "3542:\tlearn: 1.7438484\ttotal: 38.8s\tremaining: 11.5s\n",
      "3543:\tlearn: 1.7436378\ttotal: 38.8s\tremaining: 11.5s\n",
      "3544:\tlearn: 1.7432820\ttotal: 38.8s\tremaining: 11.5s\n",
      "3545:\tlearn: 1.7431730\ttotal: 38.8s\tremaining: 11.5s\n",
      "3546:\tlearn: 1.7430685\ttotal: 38.8s\tremaining: 11.5s\n",
      "3547:\tlearn: 1.7426948\ttotal: 38.8s\tremaining: 11.5s\n",
      "3548:\tlearn: 1.7426311\ttotal: 38.8s\tremaining: 11.5s\n",
      "3549:\tlearn: 1.7424261\ttotal: 38.8s\tremaining: 11.5s\n",
      "3550:\tlearn: 1.7421666\ttotal: 38.9s\tremaining: 11.5s\n",
      "3551:\tlearn: 1.7419487\ttotal: 38.9s\tremaining: 11.4s\n",
      "3552:\tlearn: 1.7418304\ttotal: 38.9s\tremaining: 11.4s\n",
      "3553:\tlearn: 1.7412751\ttotal: 38.9s\tremaining: 11.4s\n",
      "3554:\tlearn: 1.7408890\ttotal: 38.9s\tremaining: 11.4s\n",
      "3555:\tlearn: 1.7406968\ttotal: 38.9s\tremaining: 11.4s\n",
      "3556:\tlearn: 1.7404261\ttotal: 38.9s\tremaining: 11.4s\n",
      "3557:\tlearn: 1.7402719\ttotal: 38.9s\tremaining: 11.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3558:\tlearn: 1.7400612\ttotal: 38.9s\tremaining: 11.4s\n",
      "3559:\tlearn: 1.7398944\ttotal: 39s\tremaining: 11.4s\n",
      "3560:\tlearn: 1.7395181\ttotal: 39s\tremaining: 11.3s\n",
      "3561:\tlearn: 1.7394105\ttotal: 39s\tremaining: 11.3s\n",
      "3562:\tlearn: 1.7392234\ttotal: 39s\tremaining: 11.3s\n",
      "3563:\tlearn: 1.7390684\ttotal: 39s\tremaining: 11.3s\n",
      "3564:\tlearn: 1.7389200\ttotal: 39s\tremaining: 11.3s\n",
      "3565:\tlearn: 1.7387139\ttotal: 39s\tremaining: 11.3s\n",
      "3566:\tlearn: 1.7385047\ttotal: 39s\tremaining: 11.3s\n",
      "3567:\tlearn: 1.7383786\ttotal: 39s\tremaining: 11.3s\n",
      "3568:\tlearn: 1.7382034\ttotal: 39s\tremaining: 11.3s\n",
      "3569:\tlearn: 1.7380110\ttotal: 39.1s\tremaining: 11.2s\n",
      "3570:\tlearn: 1.7375219\ttotal: 39.1s\tremaining: 11.2s\n",
      "3571:\tlearn: 1.7372118\ttotal: 39.1s\tremaining: 11.2s\n",
      "3572:\tlearn: 1.7371355\ttotal: 39.1s\tremaining: 11.2s\n",
      "3573:\tlearn: 1.7368112\ttotal: 39.1s\tremaining: 11.2s\n",
      "3574:\tlearn: 1.7364848\ttotal: 39.1s\tremaining: 11.2s\n",
      "3575:\tlearn: 1.7363250\ttotal: 39.1s\tremaining: 11.2s\n",
      "3576:\tlearn: 1.7362106\ttotal: 39.1s\tremaining: 11.2s\n",
      "3577:\tlearn: 1.7360202\ttotal: 39.1s\tremaining: 11.2s\n",
      "3578:\tlearn: 1.7357970\ttotal: 39.2s\tremaining: 11.1s\n",
      "3579:\tlearn: 1.7356205\ttotal: 39.2s\tremaining: 11.1s\n",
      "3580:\tlearn: 1.7354051\ttotal: 39.2s\tremaining: 11.1s\n",
      "3581:\tlearn: 1.7352279\ttotal: 39.2s\tremaining: 11.1s\n",
      "3582:\tlearn: 1.7348122\ttotal: 39.2s\tremaining: 11.1s\n",
      "3583:\tlearn: 1.7348110\ttotal: 39.2s\tremaining: 11.1s\n",
      "3584:\tlearn: 1.7346532\ttotal: 39.2s\tremaining: 11.1s\n",
      "3585:\tlearn: 1.7344820\ttotal: 39.2s\tremaining: 11.1s\n",
      "3586:\tlearn: 1.7343265\ttotal: 39.2s\tremaining: 11.1s\n",
      "3587:\tlearn: 1.7338669\ttotal: 39.3s\tremaining: 11s\n",
      "3588:\tlearn: 1.7336360\ttotal: 39.3s\tremaining: 11s\n",
      "3589:\tlearn: 1.7335355\ttotal: 39.3s\tremaining: 11s\n",
      "3590:\tlearn: 1.7332766\ttotal: 39.3s\tremaining: 11s\n",
      "3591:\tlearn: 1.7330978\ttotal: 39.3s\tremaining: 11s\n",
      "3592:\tlearn: 1.7328588\ttotal: 39.3s\tremaining: 11s\n",
      "3593:\tlearn: 1.7324940\ttotal: 39.3s\tremaining: 11s\n",
      "3594:\tlearn: 1.7321530\ttotal: 39.3s\tremaining: 11s\n",
      "3595:\tlearn: 1.7317885\ttotal: 39.3s\tremaining: 11s\n",
      "3596:\tlearn: 1.7315114\ttotal: 39.3s\tremaining: 10.9s\n",
      "3597:\tlearn: 1.7313803\ttotal: 39.4s\tremaining: 10.9s\n",
      "3598:\tlearn: 1.7311352\ttotal: 39.4s\tremaining: 10.9s\n",
      "3599:\tlearn: 1.7309185\ttotal: 39.4s\tremaining: 10.9s\n",
      "3600:\tlearn: 1.7306454\ttotal: 39.4s\tremaining: 10.9s\n",
      "3601:\tlearn: 1.7304841\ttotal: 39.4s\tremaining: 10.9s\n",
      "3602:\tlearn: 1.7303147\ttotal: 39.4s\tremaining: 10.9s\n",
      "3603:\tlearn: 1.7300865\ttotal: 39.4s\tremaining: 10.9s\n",
      "3604:\tlearn: 1.7298942\ttotal: 39.4s\tremaining: 10.9s\n",
      "3605:\tlearn: 1.7296855\ttotal: 39.4s\tremaining: 10.8s\n",
      "3606:\tlearn: 1.7294204\ttotal: 39.5s\tremaining: 10.8s\n",
      "3607:\tlearn: 1.7290168\ttotal: 39.5s\tremaining: 10.8s\n",
      "3608:\tlearn: 1.7286657\ttotal: 39.5s\tremaining: 10.8s\n",
      "3609:\tlearn: 1.7284200\ttotal: 39.5s\tremaining: 10.8s\n",
      "3610:\tlearn: 1.7280882\ttotal: 39.5s\tremaining: 10.8s\n",
      "3611:\tlearn: 1.7279845\ttotal: 39.5s\tremaining: 10.8s\n",
      "3612:\tlearn: 1.7276965\ttotal: 39.5s\tremaining: 10.8s\n",
      "3613:\tlearn: 1.7274576\ttotal: 39.5s\tremaining: 10.8s\n",
      "3614:\tlearn: 1.7269958\ttotal: 39.5s\tremaining: 10.8s\n",
      "3615:\tlearn: 1.7266926\ttotal: 39.6s\tremaining: 10.7s\n",
      "3616:\tlearn: 1.7264856\ttotal: 39.6s\tremaining: 10.7s\n",
      "3617:\tlearn: 1.7262674\ttotal: 39.6s\tremaining: 10.7s\n",
      "3618:\tlearn: 1.7258886\ttotal: 39.6s\tremaining: 10.7s\n",
      "3619:\tlearn: 1.7257149\ttotal: 39.6s\tremaining: 10.7s\n",
      "3620:\tlearn: 1.7255385\ttotal: 39.6s\tremaining: 10.7s\n",
      "3621:\tlearn: 1.7254100\ttotal: 39.6s\tremaining: 10.7s\n",
      "3622:\tlearn: 1.7252503\ttotal: 39.6s\tremaining: 10.7s\n",
      "3623:\tlearn: 1.7248881\ttotal: 39.6s\tremaining: 10.7s\n",
      "3624:\tlearn: 1.7245842\ttotal: 39.7s\tremaining: 10.6s\n",
      "3625:\tlearn: 1.7243237\ttotal: 39.7s\tremaining: 10.6s\n",
      "3626:\tlearn: 1.7241041\ttotal: 39.7s\tremaining: 10.6s\n",
      "3627:\tlearn: 1.7239463\ttotal: 39.7s\tremaining: 10.6s\n",
      "3628:\tlearn: 1.7237896\ttotal: 39.7s\tremaining: 10.6s\n",
      "3629:\tlearn: 1.7236241\ttotal: 39.7s\tremaining: 10.6s\n",
      "3630:\tlearn: 1.7233853\ttotal: 39.7s\tremaining: 10.6s\n",
      "3631:\tlearn: 1.7232799\ttotal: 39.7s\tremaining: 10.6s\n",
      "3632:\tlearn: 1.7231290\ttotal: 39.7s\tremaining: 10.6s\n",
      "3633:\tlearn: 1.7227080\ttotal: 39.7s\tremaining: 10.5s\n",
      "3634:\tlearn: 1.7224617\ttotal: 39.8s\tremaining: 10.5s\n",
      "3635:\tlearn: 1.7221816\ttotal: 39.8s\tremaining: 10.5s\n",
      "3636:\tlearn: 1.7219875\ttotal: 39.8s\tremaining: 10.5s\n",
      "3637:\tlearn: 1.7218382\ttotal: 39.8s\tremaining: 10.5s\n",
      "3638:\tlearn: 1.7216976\ttotal: 39.8s\tremaining: 10.5s\n",
      "3639:\tlearn: 1.7212818\ttotal: 39.8s\tremaining: 10.5s\n",
      "3640:\tlearn: 1.7209752\ttotal: 39.8s\tremaining: 10.5s\n",
      "3641:\tlearn: 1.7208562\ttotal: 39.8s\tremaining: 10.5s\n",
      "3642:\tlearn: 1.7206408\ttotal: 39.8s\tremaining: 10.4s\n",
      "3643:\tlearn: 1.7203338\ttotal: 39.9s\tremaining: 10.4s\n",
      "3644:\tlearn: 1.7202085\ttotal: 39.9s\tremaining: 10.4s\n",
      "3645:\tlearn: 1.7199017\ttotal: 39.9s\tremaining: 10.4s\n",
      "3646:\tlearn: 1.7196223\ttotal: 39.9s\tremaining: 10.4s\n",
      "3647:\tlearn: 1.7194433\ttotal: 39.9s\tremaining: 10.4s\n",
      "3648:\tlearn: 1.7193190\ttotal: 39.9s\tremaining: 10.4s\n",
      "3649:\tlearn: 1.7192478\ttotal: 39.9s\tremaining: 10.4s\n",
      "3650:\tlearn: 1.7189607\ttotal: 39.9s\tremaining: 10.4s\n",
      "3651:\tlearn: 1.7186545\ttotal: 39.9s\tremaining: 10.3s\n",
      "3652:\tlearn: 1.7185144\ttotal: 40s\tremaining: 10.3s\n",
      "3653:\tlearn: 1.7185133\ttotal: 40s\tremaining: 10.3s\n",
      "3654:\tlearn: 1.7180908\ttotal: 40s\tremaining: 10.3s\n",
      "3655:\tlearn: 1.7177794\ttotal: 40s\tremaining: 10.3s\n",
      "3656:\tlearn: 1.7177269\ttotal: 40s\tremaining: 10.3s\n",
      "3657:\tlearn: 1.7175623\ttotal: 40s\tremaining: 10.3s\n",
      "3658:\tlearn: 1.7172621\ttotal: 40s\tremaining: 10.3s\n",
      "3659:\tlearn: 1.7171238\ttotal: 40s\tremaining: 10.3s\n",
      "3660:\tlearn: 1.7166829\ttotal: 40s\tremaining: 10.2s\n",
      "3661:\tlearn: 1.7163200\ttotal: 40s\tremaining: 10.2s\n",
      "3662:\tlearn: 1.7160265\ttotal: 40.1s\tremaining: 10.2s\n",
      "3663:\tlearn: 1.7157872\ttotal: 40.1s\tremaining: 10.2s\n",
      "3664:\tlearn: 1.7154334\ttotal: 40.1s\tremaining: 10.2s\n",
      "3665:\tlearn: 1.7153656\ttotal: 40.1s\tremaining: 10.2s\n",
      "3666:\tlearn: 1.7151155\ttotal: 40.1s\tremaining: 10.2s\n",
      "3667:\tlearn: 1.7144724\ttotal: 40.1s\tremaining: 10.2s\n",
      "3668:\tlearn: 1.7142045\ttotal: 40.1s\tremaining: 10.2s\n",
      "3669:\tlearn: 1.7141280\ttotal: 40.1s\tremaining: 10.1s\n",
      "3670:\tlearn: 1.7138452\ttotal: 40.1s\tremaining: 10.1s\n",
      "3671:\tlearn: 1.7137173\ttotal: 40.2s\tremaining: 10.1s\n",
      "3672:\tlearn: 1.7135206\ttotal: 40.2s\tremaining: 10.1s\n",
      "3673:\tlearn: 1.7132117\ttotal: 40.2s\tremaining: 10.1s\n",
      "3674:\tlearn: 1.7129453\ttotal: 40.2s\tremaining: 10.1s\n",
      "3675:\tlearn: 1.7126450\ttotal: 40.2s\tremaining: 10.1s\n",
      "3676:\tlearn: 1.7124301\ttotal: 40.2s\tremaining: 10.1s\n",
      "3677:\tlearn: 1.7122443\ttotal: 40.2s\tremaining: 10.1s\n",
      "3678:\tlearn: 1.7120637\ttotal: 40.2s\tremaining: 10s\n",
      "3679:\tlearn: 1.7118332\ttotal: 40.2s\tremaining: 10s\n",
      "3680:\tlearn: 1.7115332\ttotal: 40.3s\tremaining: 10s\n",
      "3681:\tlearn: 1.7112499\ttotal: 40.3s\tremaining: 10s\n",
      "3682:\tlearn: 1.7109709\ttotal: 40.3s\tremaining: 10s\n",
      "3683:\tlearn: 1.7106681\ttotal: 40.3s\tremaining: 9.99s\n",
      "3684:\tlearn: 1.7104825\ttotal: 40.3s\tremaining: 9.98s\n",
      "3685:\tlearn: 1.7102320\ttotal: 40.3s\tremaining: 9.97s\n",
      "3686:\tlearn: 1.7100908\ttotal: 40.3s\tremaining: 9.96s\n",
      "3687:\tlearn: 1.7099375\ttotal: 40.3s\tremaining: 9.95s\n",
      "3688:\tlearn: 1.7096844\ttotal: 40.3s\tremaining: 9.94s\n",
      "3689:\tlearn: 1.7093984\ttotal: 40.3s\tremaining: 9.93s\n",
      "3690:\tlearn: 1.7092251\ttotal: 40.4s\tremaining: 9.92s\n",
      "3691:\tlearn: 1.7089195\ttotal: 40.4s\tremaining: 9.91s\n",
      "3692:\tlearn: 1.7086989\ttotal: 40.4s\tremaining: 9.89s\n",
      "3693:\tlearn: 1.7084838\ttotal: 40.4s\tremaining: 9.88s\n",
      "3694:\tlearn: 1.7084284\ttotal: 40.4s\tremaining: 9.87s\n",
      "3695:\tlearn: 1.7082087\ttotal: 40.4s\tremaining: 9.86s\n",
      "3696:\tlearn: 1.7079172\ttotal: 40.4s\tremaining: 9.85s\n",
      "3697:\tlearn: 1.7075682\ttotal: 40.4s\tremaining: 9.84s\n",
      "3698:\tlearn: 1.7070622\ttotal: 40.4s\tremaining: 9.83s\n",
      "3699:\tlearn: 1.7068138\ttotal: 40.5s\tremaining: 9.82s\n",
      "3700:\tlearn: 1.7064569\ttotal: 40.5s\tremaining: 9.81s\n",
      "3701:\tlearn: 1.7062498\ttotal: 40.5s\tremaining: 9.8s\n",
      "3702:\tlearn: 1.7060324\ttotal: 40.5s\tremaining: 9.79s\n",
      "3703:\tlearn: 1.7057109\ttotal: 40.5s\tremaining: 9.78s\n",
      "3704:\tlearn: 1.7054603\ttotal: 40.5s\tremaining: 9.76s\n",
      "3705:\tlearn: 1.7052710\ttotal: 40.5s\tremaining: 9.75s\n",
      "3706:\tlearn: 1.7050854\ttotal: 40.5s\tremaining: 9.74s\n",
      "3707:\tlearn: 1.7048494\ttotal: 40.5s\tremaining: 9.73s\n",
      "3708:\tlearn: 1.7045921\ttotal: 40.6s\tremaining: 9.72s\n",
      "3709:\tlearn: 1.7042130\ttotal: 40.6s\tremaining: 9.71s\n",
      "3710:\tlearn: 1.7039063\ttotal: 40.6s\tremaining: 9.7s\n",
      "3711:\tlearn: 1.7036124\ttotal: 40.6s\tremaining: 9.69s\n",
      "3712:\tlearn: 1.7032612\ttotal: 40.6s\tremaining: 9.68s\n",
      "3713:\tlearn: 1.7030959\ttotal: 40.6s\tremaining: 9.67s\n",
      "3714:\tlearn: 1.7029355\ttotal: 40.6s\tremaining: 9.65s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3715:\tlearn: 1.7028103\ttotal: 40.6s\tremaining: 9.64s\n",
      "3716:\tlearn: 1.7027413\ttotal: 40.6s\tremaining: 9.63s\n",
      "3717:\tlearn: 1.7025351\ttotal: 40.7s\tremaining: 9.62s\n",
      "3718:\tlearn: 1.7024277\ttotal: 40.7s\tremaining: 9.61s\n",
      "3719:\tlearn: 1.7023403\ttotal: 40.7s\tremaining: 9.6s\n",
      "3720:\tlearn: 1.7022032\ttotal: 40.7s\tremaining: 9.59s\n",
      "3721:\tlearn: 1.7021336\ttotal: 40.7s\tremaining: 9.58s\n",
      "3722:\tlearn: 1.7020695\ttotal: 40.7s\tremaining: 9.57s\n",
      "3723:\tlearn: 1.7018344\ttotal: 40.7s\tremaining: 9.56s\n",
      "3724:\tlearn: 1.7015348\ttotal: 40.7s\tremaining: 9.54s\n",
      "3725:\tlearn: 1.7013797\ttotal: 40.7s\tremaining: 9.54s\n",
      "3726:\tlearn: 1.7013069\ttotal: 40.8s\tremaining: 9.52s\n",
      "3727:\tlearn: 1.7009910\ttotal: 40.8s\tremaining: 9.51s\n",
      "3728:\tlearn: 1.7006956\ttotal: 40.8s\tremaining: 9.5s\n",
      "3729:\tlearn: 1.7003894\ttotal: 40.8s\tremaining: 9.49s\n",
      "3730:\tlearn: 1.7001778\ttotal: 40.8s\tremaining: 9.48s\n",
      "3731:\tlearn: 1.6999054\ttotal: 40.8s\tremaining: 9.47s\n",
      "3732:\tlearn: 1.6997471\ttotal: 40.8s\tremaining: 9.46s\n",
      "3733:\tlearn: 1.6996357\ttotal: 40.8s\tremaining: 9.45s\n",
      "3734:\tlearn: 1.6992356\ttotal: 40.8s\tremaining: 9.44s\n",
      "3735:\tlearn: 1.6989557\ttotal: 40.9s\tremaining: 9.43s\n",
      "3736:\tlearn: 1.6987951\ttotal: 40.9s\tremaining: 9.41s\n",
      "3737:\tlearn: 1.6985670\ttotal: 40.9s\tremaining: 9.4s\n",
      "3738:\tlearn: 1.6982053\ttotal: 40.9s\tremaining: 9.39s\n",
      "3739:\tlearn: 1.6978865\ttotal: 40.9s\tremaining: 9.38s\n",
      "3740:\tlearn: 1.6976623\ttotal: 40.9s\tremaining: 9.37s\n",
      "3741:\tlearn: 1.6974729\ttotal: 40.9s\tremaining: 9.36s\n",
      "3742:\tlearn: 1.6973402\ttotal: 40.9s\tremaining: 9.35s\n",
      "3743:\tlearn: 1.6968115\ttotal: 41s\tremaining: 9.34s\n",
      "3744:\tlearn: 1.6965522\ttotal: 41s\tremaining: 9.33s\n",
      "3745:\tlearn: 1.6962616\ttotal: 41s\tremaining: 9.32s\n",
      "3746:\tlearn: 1.6960176\ttotal: 41s\tremaining: 9.31s\n",
      "3747:\tlearn: 1.6957664\ttotal: 41s\tremaining: 9.3s\n",
      "3748:\tlearn: 1.6955768\ttotal: 41s\tremaining: 9.29s\n",
      "3749:\tlearn: 1.6954635\ttotal: 41s\tremaining: 9.28s\n",
      "3750:\tlearn: 1.6952860\ttotal: 41s\tremaining: 9.26s\n",
      "3751:\tlearn: 1.6951201\ttotal: 41s\tremaining: 9.25s\n",
      "3752:\tlearn: 1.6947363\ttotal: 41.1s\tremaining: 9.24s\n",
      "3753:\tlearn: 1.6944169\ttotal: 41.1s\tremaining: 9.23s\n",
      "3754:\tlearn: 1.6941665\ttotal: 41.1s\tremaining: 9.22s\n",
      "3755:\tlearn: 1.6938753\ttotal: 41.1s\tremaining: 9.21s\n",
      "3756:\tlearn: 1.6937594\ttotal: 41.1s\tremaining: 9.2s\n",
      "3757:\tlearn: 1.6935652\ttotal: 41.1s\tremaining: 9.19s\n",
      "3758:\tlearn: 1.6932840\ttotal: 41.1s\tremaining: 9.18s\n",
      "3759:\tlearn: 1.6930989\ttotal: 41.1s\tremaining: 9.17s\n",
      "3760:\tlearn: 1.6928960\ttotal: 41.1s\tremaining: 9.15s\n",
      "3761:\tlearn: 1.6925124\ttotal: 41.1s\tremaining: 9.14s\n",
      "3762:\tlearn: 1.6923958\ttotal: 41.2s\tremaining: 9.13s\n",
      "3763:\tlearn: 1.6922244\ttotal: 41.2s\tremaining: 9.12s\n",
      "3764:\tlearn: 1.6918040\ttotal: 41.2s\tremaining: 9.11s\n",
      "3765:\tlearn: 1.6915578\ttotal: 41.2s\tremaining: 9.1s\n",
      "3766:\tlearn: 1.6913176\ttotal: 41.2s\tremaining: 9.09s\n",
      "3767:\tlearn: 1.6912486\ttotal: 41.2s\tremaining: 9.08s\n",
      "3768:\tlearn: 1.6910208\ttotal: 41.2s\tremaining: 9.07s\n",
      "3769:\tlearn: 1.6908932\ttotal: 41.2s\tremaining: 9.06s\n",
      "3770:\tlearn: 1.6907713\ttotal: 41.2s\tremaining: 9.04s\n",
      "3771:\tlearn: 1.6904406\ttotal: 41.3s\tremaining: 9.03s\n",
      "3772:\tlearn: 1.6903461\ttotal: 41.3s\tremaining: 9.02s\n",
      "3773:\tlearn: 1.6899681\ttotal: 41.3s\tremaining: 9.01s\n",
      "3774:\tlearn: 1.6897232\ttotal: 41.3s\tremaining: 9s\n",
      "3775:\tlearn: 1.6894599\ttotal: 41.3s\tremaining: 8.99s\n",
      "3776:\tlearn: 1.6892670\ttotal: 41.3s\tremaining: 8.98s\n",
      "3777:\tlearn: 1.6891271\ttotal: 41.3s\tremaining: 8.97s\n",
      "3778:\tlearn: 1.6889786\ttotal: 41.3s\tremaining: 8.96s\n",
      "3779:\tlearn: 1.6888641\ttotal: 41.3s\tremaining: 8.95s\n",
      "3780:\tlearn: 1.6887247\ttotal: 41.4s\tremaining: 8.94s\n",
      "3781:\tlearn: 1.6885116\ttotal: 41.4s\tremaining: 8.92s\n",
      "3782:\tlearn: 1.6881735\ttotal: 41.4s\tremaining: 8.91s\n",
      "3783:\tlearn: 1.6879692\ttotal: 41.4s\tremaining: 8.9s\n",
      "3784:\tlearn: 1.6876953\ttotal: 41.4s\tremaining: 8.89s\n",
      "3785:\tlearn: 1.6874783\ttotal: 41.4s\tremaining: 8.88s\n",
      "3786:\tlearn: 1.6872208\ttotal: 41.4s\tremaining: 8.87s\n",
      "3787:\tlearn: 1.6869671\ttotal: 41.4s\tremaining: 8.86s\n",
      "3788:\tlearn: 1.6867988\ttotal: 41.4s\tremaining: 8.85s\n",
      "3789:\tlearn: 1.6866049\ttotal: 41.5s\tremaining: 8.84s\n",
      "3790:\tlearn: 1.6864235\ttotal: 41.5s\tremaining: 8.82s\n",
      "3791:\tlearn: 1.6858837\ttotal: 41.5s\tremaining: 8.81s\n",
      "3792:\tlearn: 1.6857505\ttotal: 41.5s\tremaining: 8.8s\n",
      "3793:\tlearn: 1.6855781\ttotal: 41.5s\tremaining: 8.79s\n",
      "3794:\tlearn: 1.6853686\ttotal: 41.5s\tremaining: 8.78s\n",
      "3795:\tlearn: 1.6852394\ttotal: 41.5s\tremaining: 8.77s\n",
      "3796:\tlearn: 1.6849321\ttotal: 41.5s\tremaining: 8.76s\n",
      "3797:\tlearn: 1.6846382\ttotal: 41.5s\tremaining: 8.75s\n",
      "3798:\tlearn: 1.6844587\ttotal: 41.5s\tremaining: 8.74s\n",
      "3799:\tlearn: 1.6840159\ttotal: 41.6s\tremaining: 8.73s\n",
      "3800:\tlearn: 1.6836267\ttotal: 41.6s\tremaining: 8.72s\n",
      "3801:\tlearn: 1.6834540\ttotal: 41.6s\tremaining: 8.71s\n",
      "3802:\tlearn: 1.6831490\ttotal: 41.6s\tremaining: 8.69s\n",
      "3803:\tlearn: 1.6828522\ttotal: 41.6s\tremaining: 8.68s\n",
      "3804:\tlearn: 1.6824135\ttotal: 41.6s\tremaining: 8.67s\n",
      "3805:\tlearn: 1.6820127\ttotal: 41.6s\tremaining: 8.66s\n",
      "3806:\tlearn: 1.6818399\ttotal: 41.6s\tremaining: 8.65s\n",
      "3807:\tlearn: 1.6816327\ttotal: 41.6s\tremaining: 8.64s\n",
      "3808:\tlearn: 1.6814699\ttotal: 41.7s\tremaining: 8.63s\n",
      "3809:\tlearn: 1.6812295\ttotal: 41.7s\tremaining: 8.62s\n",
      "3810:\tlearn: 1.6808753\ttotal: 41.7s\tremaining: 8.61s\n",
      "3811:\tlearn: 1.6805585\ttotal: 41.7s\tremaining: 8.6s\n",
      "3812:\tlearn: 1.6802322\ttotal: 41.7s\tremaining: 8.59s\n",
      "3813:\tlearn: 1.6799644\ttotal: 41.7s\tremaining: 8.57s\n",
      "3814:\tlearn: 1.6797489\ttotal: 41.7s\tremaining: 8.56s\n",
      "3815:\tlearn: 1.6796265\ttotal: 41.7s\tremaining: 8.55s\n",
      "3816:\tlearn: 1.6793701\ttotal: 41.7s\tremaining: 8.54s\n",
      "3817:\tlearn: 1.6790563\ttotal: 41.8s\tremaining: 8.53s\n",
      "3818:\tlearn: 1.6788126\ttotal: 41.8s\tremaining: 8.52s\n",
      "3819:\tlearn: 1.6787353\ttotal: 41.8s\tremaining: 8.51s\n",
      "3820:\tlearn: 1.6784671\ttotal: 41.8s\tremaining: 8.5s\n",
      "3821:\tlearn: 1.6782345\ttotal: 41.8s\tremaining: 8.49s\n",
      "3822:\tlearn: 1.6780106\ttotal: 41.8s\tremaining: 8.48s\n",
      "3823:\tlearn: 1.6776973\ttotal: 41.8s\tremaining: 8.46s\n",
      "3824:\tlearn: 1.6774234\ttotal: 41.8s\tremaining: 8.45s\n",
      "3825:\tlearn: 1.6771540\ttotal: 41.8s\tremaining: 8.44s\n",
      "3826:\tlearn: 1.6768467\ttotal: 41.9s\tremaining: 8.43s\n",
      "3827:\tlearn: 1.6766449\ttotal: 41.9s\tremaining: 8.42s\n",
      "3828:\tlearn: 1.6763727\ttotal: 41.9s\tremaining: 8.41s\n",
      "3829:\tlearn: 1.6761625\ttotal: 41.9s\tremaining: 8.4s\n",
      "3830:\tlearn: 1.6759154\ttotal: 41.9s\tremaining: 8.39s\n",
      "3831:\tlearn: 1.6757228\ttotal: 41.9s\tremaining: 8.38s\n",
      "3832:\tlearn: 1.6754520\ttotal: 41.9s\tremaining: 8.37s\n",
      "3833:\tlearn: 1.6751162\ttotal: 41.9s\tremaining: 8.36s\n",
      "3834:\tlearn: 1.6748450\ttotal: 42s\tremaining: 8.35s\n",
      "3835:\tlearn: 1.6746549\ttotal: 42s\tremaining: 8.34s\n",
      "3836:\tlearn: 1.6743249\ttotal: 42s\tremaining: 8.32s\n",
      "3837:\tlearn: 1.6740760\ttotal: 42s\tremaining: 8.31s\n",
      "3838:\tlearn: 1.6738805\ttotal: 42s\tremaining: 8.3s\n",
      "3839:\tlearn: 1.6735795\ttotal: 42s\tremaining: 8.29s\n",
      "3840:\tlearn: 1.6730575\ttotal: 42s\tremaining: 8.28s\n",
      "3841:\tlearn: 1.6727973\ttotal: 42s\tremaining: 8.27s\n",
      "3842:\tlearn: 1.6725907\ttotal: 42s\tremaining: 8.26s\n",
      "3843:\tlearn: 1.6723115\ttotal: 42s\tremaining: 8.25s\n",
      "3844:\tlearn: 1.6721768\ttotal: 42.1s\tremaining: 8.24s\n",
      "3845:\tlearn: 1.6718603\ttotal: 42.1s\tremaining: 8.22s\n",
      "3846:\tlearn: 1.6715594\ttotal: 42.1s\tremaining: 8.21s\n",
      "3847:\tlearn: 1.6712025\ttotal: 42.1s\tremaining: 8.2s\n",
      "3848:\tlearn: 1.6709572\ttotal: 42.1s\tremaining: 8.19s\n",
      "3849:\tlearn: 1.6707676\ttotal: 42.1s\tremaining: 8.18s\n",
      "3850:\tlearn: 1.6704471\ttotal: 42.1s\tremaining: 8.17s\n",
      "3851:\tlearn: 1.6701772\ttotal: 42.1s\tremaining: 8.16s\n",
      "3852:\tlearn: 1.6700184\ttotal: 42.2s\tremaining: 8.15s\n",
      "3853:\tlearn: 1.6696133\ttotal: 42.2s\tremaining: 8.14s\n",
      "3854:\tlearn: 1.6693379\ttotal: 42.2s\tremaining: 8.13s\n",
      "3855:\tlearn: 1.6691638\ttotal: 42.2s\tremaining: 8.12s\n",
      "3856:\tlearn: 1.6688970\ttotal: 42.2s\tremaining: 8.11s\n",
      "3857:\tlearn: 1.6686034\ttotal: 42.2s\tremaining: 8.1s\n",
      "3858:\tlearn: 1.6684243\ttotal: 42.2s\tremaining: 8.08s\n",
      "3859:\tlearn: 1.6680637\ttotal: 42.2s\tremaining: 8.07s\n",
      "3860:\tlearn: 1.6679196\ttotal: 42.2s\tremaining: 8.06s\n",
      "3861:\tlearn: 1.6677478\ttotal: 42.3s\tremaining: 8.05s\n",
      "3862:\tlearn: 1.6675590\ttotal: 42.3s\tremaining: 8.04s\n",
      "3863:\tlearn: 1.6672549\ttotal: 42.3s\tremaining: 8.03s\n",
      "3864:\tlearn: 1.6670187\ttotal: 42.3s\tremaining: 8.02s\n",
      "3865:\tlearn: 1.6668355\ttotal: 42.3s\tremaining: 8.01s\n",
      "3866:\tlearn: 1.6666021\ttotal: 42.3s\tremaining: 8s\n",
      "3867:\tlearn: 1.6663588\ttotal: 42.3s\tremaining: 7.99s\n",
      "3868:\tlearn: 1.6660903\ttotal: 42.3s\tremaining: 7.97s\n",
      "3869:\tlearn: 1.6657674\ttotal: 42.3s\tremaining: 7.96s\n",
      "3870:\tlearn: 1.6654411\ttotal: 42.4s\tremaining: 7.95s\n",
      "3871:\tlearn: 1.6653039\ttotal: 42.4s\tremaining: 7.94s\n",
      "3872:\tlearn: 1.6651377\ttotal: 42.4s\tremaining: 7.93s\n",
      "3873:\tlearn: 1.6649767\ttotal: 42.4s\tremaining: 7.92s\n",
      "3874:\tlearn: 1.6647792\ttotal: 42.4s\tremaining: 7.91s\n",
      "3875:\tlearn: 1.6643852\ttotal: 42.4s\tremaining: 7.9s\n",
      "3876:\tlearn: 1.6642170\ttotal: 42.4s\tremaining: 7.89s\n",
      "3877:\tlearn: 1.6640651\ttotal: 42.4s\tremaining: 7.88s\n",
      "3878:\tlearn: 1.6638786\ttotal: 42.4s\tremaining: 7.87s\n",
      "3879:\tlearn: 1.6636659\ttotal: 42.5s\tremaining: 7.86s\n",
      "3880:\tlearn: 1.6633801\ttotal: 42.5s\tremaining: 7.84s\n",
      "3881:\tlearn: 1.6632627\ttotal: 42.5s\tremaining: 7.83s\n",
      "3882:\tlearn: 1.6629064\ttotal: 42.5s\tremaining: 7.82s\n",
      "3883:\tlearn: 1.6626264\ttotal: 42.5s\tremaining: 7.81s\n",
      "3884:\tlearn: 1.6623838\ttotal: 42.5s\tremaining: 7.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3885:\tlearn: 1.6622577\ttotal: 42.5s\tremaining: 7.79s\n",
      "3886:\tlearn: 1.6621162\ttotal: 42.5s\tremaining: 7.78s\n",
      "3887:\tlearn: 1.6619575\ttotal: 42.5s\tremaining: 7.77s\n",
      "3888:\tlearn: 1.6617091\ttotal: 42.6s\tremaining: 7.76s\n",
      "3889:\tlearn: 1.6613773\ttotal: 42.6s\tremaining: 7.75s\n",
      "3890:\tlearn: 1.6610000\ttotal: 42.6s\tremaining: 7.74s\n",
      "3891:\tlearn: 1.6607826\ttotal: 42.6s\tremaining: 7.72s\n",
      "3892:\tlearn: 1.6605309\ttotal: 42.6s\tremaining: 7.71s\n",
      "3893:\tlearn: 1.6602491\ttotal: 42.6s\tremaining: 7.7s\n",
      "3894:\tlearn: 1.6597298\ttotal: 42.6s\tremaining: 7.69s\n",
      "3895:\tlearn: 1.6594609\ttotal: 42.6s\tremaining: 7.68s\n",
      "3896:\tlearn: 1.6591807\ttotal: 42.6s\tremaining: 7.67s\n",
      "3897:\tlearn: 1.6590017\ttotal: 42.6s\tremaining: 7.66s\n",
      "3898:\tlearn: 1.6586533\ttotal: 42.7s\tremaining: 7.65s\n",
      "3899:\tlearn: 1.6585056\ttotal: 42.7s\tremaining: 7.64s\n",
      "3900:\tlearn: 1.6581753\ttotal: 42.7s\tremaining: 7.63s\n",
      "3901:\tlearn: 1.6580271\ttotal: 42.7s\tremaining: 7.62s\n",
      "3902:\tlearn: 1.6578896\ttotal: 42.7s\tremaining: 7.6s\n",
      "3903:\tlearn: 1.6576197\ttotal: 42.7s\tremaining: 7.59s\n",
      "3904:\tlearn: 1.6574069\ttotal: 42.7s\tremaining: 7.58s\n",
      "3905:\tlearn: 1.6570715\ttotal: 42.7s\tremaining: 7.57s\n",
      "3906:\tlearn: 1.6568786\ttotal: 42.7s\tremaining: 7.56s\n",
      "3907:\tlearn: 1.6566776\ttotal: 42.8s\tremaining: 7.55s\n",
      "3908:\tlearn: 1.6563022\ttotal: 42.8s\tremaining: 7.54s\n",
      "3909:\tlearn: 1.6559662\ttotal: 42.8s\tremaining: 7.53s\n",
      "3910:\tlearn: 1.6558040\ttotal: 42.8s\tremaining: 7.52s\n",
      "3911:\tlearn: 1.6556051\ttotal: 42.8s\tremaining: 7.5s\n",
      "3912:\tlearn: 1.6554032\ttotal: 42.8s\tremaining: 7.49s\n",
      "3913:\tlearn: 1.6551811\ttotal: 42.8s\tremaining: 7.48s\n",
      "3914:\tlearn: 1.6549478\ttotal: 42.8s\tremaining: 7.47s\n",
      "3915:\tlearn: 1.6546680\ttotal: 42.8s\tremaining: 7.46s\n",
      "3916:\tlearn: 1.6545811\ttotal: 42.9s\tremaining: 7.45s\n",
      "3917:\tlearn: 1.6542409\ttotal: 42.9s\tremaining: 7.44s\n",
      "3918:\tlearn: 1.6539842\ttotal: 42.9s\tremaining: 7.43s\n",
      "3919:\tlearn: 1.6537679\ttotal: 42.9s\tremaining: 7.42s\n",
      "3920:\tlearn: 1.6534809\ttotal: 42.9s\tremaining: 7.41s\n",
      "3921:\tlearn: 1.6531862\ttotal: 42.9s\tremaining: 7.39s\n",
      "3922:\tlearn: 1.6529670\ttotal: 42.9s\tremaining: 7.38s\n",
      "3923:\tlearn: 1.6526619\ttotal: 42.9s\tremaining: 7.37s\n",
      "3924:\tlearn: 1.6525050\ttotal: 42.9s\tremaining: 7.36s\n",
      "3925:\tlearn: 1.6523378\ttotal: 43s\tremaining: 7.35s\n",
      "3926:\tlearn: 1.6521198\ttotal: 43s\tremaining: 7.34s\n",
      "3927:\tlearn: 1.6519283\ttotal: 43s\tremaining: 7.33s\n",
      "3928:\tlearn: 1.6517556\ttotal: 43s\tremaining: 7.32s\n",
      "3929:\tlearn: 1.6512732\ttotal: 43s\tremaining: 7.31s\n",
      "3930:\tlearn: 1.6510747\ttotal: 43s\tremaining: 7.3s\n",
      "3931:\tlearn: 1.6508477\ttotal: 43s\tremaining: 7.29s\n",
      "3932:\tlearn: 1.6505293\ttotal: 43s\tremaining: 7.28s\n",
      "3933:\tlearn: 1.6503406\ttotal: 43s\tremaining: 7.26s\n",
      "3934:\tlearn: 1.6499322\ttotal: 43.1s\tremaining: 7.25s\n",
      "3935:\tlearn: 1.6497889\ttotal: 43.1s\tremaining: 7.24s\n",
      "3936:\tlearn: 1.6493859\ttotal: 43.1s\tremaining: 7.23s\n",
      "3937:\tlearn: 1.6489782\ttotal: 43.1s\tremaining: 7.22s\n",
      "3938:\tlearn: 1.6487478\ttotal: 43.1s\tremaining: 7.21s\n",
      "3939:\tlearn: 1.6482693\ttotal: 43.1s\tremaining: 7.2s\n",
      "3940:\tlearn: 1.6480443\ttotal: 43.1s\tremaining: 7.19s\n",
      "3941:\tlearn: 1.6479302\ttotal: 43.1s\tremaining: 7.18s\n",
      "3942:\tlearn: 1.6477878\ttotal: 43.1s\tremaining: 7.17s\n",
      "3943:\tlearn: 1.6476114\ttotal: 43.2s\tremaining: 7.16s\n",
      "3944:\tlearn: 1.6473860\ttotal: 43.2s\tremaining: 7.14s\n",
      "3945:\tlearn: 1.6468761\ttotal: 43.2s\tremaining: 7.13s\n",
      "3946:\tlearn: 1.6464875\ttotal: 43.2s\tremaining: 7.12s\n",
      "3947:\tlearn: 1.6463204\ttotal: 43.2s\tremaining: 7.11s\n",
      "3948:\tlearn: 1.6458964\ttotal: 43.2s\tremaining: 7.1s\n",
      "3949:\tlearn: 1.6457401\ttotal: 43.2s\tremaining: 7.09s\n",
      "3950:\tlearn: 1.6454877\ttotal: 43.2s\tremaining: 7.08s\n",
      "3951:\tlearn: 1.6454413\ttotal: 43.2s\tremaining: 7.07s\n",
      "3952:\tlearn: 1.6453047\ttotal: 43.3s\tremaining: 7.06s\n",
      "3953:\tlearn: 1.6450306\ttotal: 43.3s\tremaining: 7.05s\n",
      "3954:\tlearn: 1.6445385\ttotal: 43.3s\tremaining: 7.04s\n",
      "3955:\tlearn: 1.6442818\ttotal: 43.3s\tremaining: 7.02s\n",
      "3956:\tlearn: 1.6441083\ttotal: 43.3s\tremaining: 7.01s\n",
      "3957:\tlearn: 1.6439359\ttotal: 43.3s\tremaining: 7s\n",
      "3958:\tlearn: 1.6435505\ttotal: 43.3s\tremaining: 6.99s\n",
      "3959:\tlearn: 1.6434475\ttotal: 43.3s\tremaining: 6.98s\n",
      "3960:\tlearn: 1.6432219\ttotal: 43.3s\tremaining: 6.97s\n",
      "3961:\tlearn: 1.6431800\ttotal: 43.3s\tremaining: 6.96s\n",
      "3962:\tlearn: 1.6429606\ttotal: 43.4s\tremaining: 6.95s\n",
      "3963:\tlearn: 1.6428242\ttotal: 43.4s\tremaining: 6.94s\n",
      "3964:\tlearn: 1.6425330\ttotal: 43.4s\tremaining: 6.92s\n",
      "3965:\tlearn: 1.6423516\ttotal: 43.4s\tremaining: 6.91s\n",
      "3966:\tlearn: 1.6422977\ttotal: 43.4s\tremaining: 6.9s\n",
      "3967:\tlearn: 1.6421409\ttotal: 43.4s\tremaining: 6.89s\n",
      "3968:\tlearn: 1.6419518\ttotal: 43.4s\tremaining: 6.88s\n",
      "3969:\tlearn: 1.6417962\ttotal: 43.4s\tremaining: 6.87s\n",
      "3970:\tlearn: 1.6416369\ttotal: 43.4s\tremaining: 6.86s\n",
      "3971:\tlearn: 1.6413736\ttotal: 43.5s\tremaining: 6.85s\n",
      "3972:\tlearn: 1.6412842\ttotal: 43.5s\tremaining: 6.84s\n",
      "3973:\tlearn: 1.6410720\ttotal: 43.5s\tremaining: 6.83s\n",
      "3974:\tlearn: 1.6408913\ttotal: 43.5s\tremaining: 6.82s\n",
      "3975:\tlearn: 1.6408013\ttotal: 43.5s\tremaining: 6.8s\n",
      "3976:\tlearn: 1.6405956\ttotal: 43.5s\tremaining: 6.79s\n",
      "3977:\tlearn: 1.6403399\ttotal: 43.5s\tremaining: 6.78s\n",
      "3978:\tlearn: 1.6400219\ttotal: 43.5s\tremaining: 6.77s\n",
      "3979:\tlearn: 1.6396513\ttotal: 43.5s\tremaining: 6.76s\n",
      "3980:\tlearn: 1.6394821\ttotal: 43.6s\tremaining: 6.75s\n",
      "3981:\tlearn: 1.6391586\ttotal: 43.6s\tremaining: 6.74s\n",
      "3982:\tlearn: 1.6388843\ttotal: 43.6s\tremaining: 6.73s\n",
      "3983:\tlearn: 1.6388345\ttotal: 43.6s\tremaining: 6.72s\n",
      "3984:\tlearn: 1.6386215\ttotal: 43.6s\tremaining: 6.71s\n",
      "3985:\tlearn: 1.6382884\ttotal: 43.6s\tremaining: 6.7s\n",
      "3986:\tlearn: 1.6380140\ttotal: 43.6s\tremaining: 6.68s\n",
      "3987:\tlearn: 1.6379743\ttotal: 43.6s\tremaining: 6.67s\n",
      "3988:\tlearn: 1.6378210\ttotal: 43.6s\tremaining: 6.66s\n",
      "3989:\tlearn: 1.6374656\ttotal: 43.7s\tremaining: 6.65s\n",
      "3990:\tlearn: 1.6372765\ttotal: 43.7s\tremaining: 6.64s\n",
      "3991:\tlearn: 1.6371714\ttotal: 43.7s\tremaining: 6.63s\n",
      "3992:\tlearn: 1.6369956\ttotal: 43.7s\tremaining: 6.62s\n",
      "3993:\tlearn: 1.6369186\ttotal: 43.7s\tremaining: 6.61s\n",
      "3994:\tlearn: 1.6365202\ttotal: 43.7s\tremaining: 6.6s\n",
      "3995:\tlearn: 1.6360870\ttotal: 43.7s\tremaining: 6.58s\n",
      "3996:\tlearn: 1.6359322\ttotal: 43.7s\tremaining: 6.58s\n",
      "3997:\tlearn: 1.6358896\ttotal: 43.7s\tremaining: 6.56s\n",
      "3998:\tlearn: 1.6356599\ttotal: 43.7s\tremaining: 6.55s\n",
      "3999:\tlearn: 1.6353411\ttotal: 43.8s\tremaining: 6.54s\n",
      "4000:\tlearn: 1.6351494\ttotal: 43.8s\tremaining: 6.53s\n",
      "4001:\tlearn: 1.6349607\ttotal: 43.8s\tremaining: 6.52s\n",
      "4002:\tlearn: 1.6347728\ttotal: 43.8s\tremaining: 6.51s\n",
      "4003:\tlearn: 1.6345978\ttotal: 43.8s\tremaining: 6.5s\n",
      "4004:\tlearn: 1.6342287\ttotal: 43.8s\tremaining: 6.49s\n",
      "4005:\tlearn: 1.6340006\ttotal: 43.8s\tremaining: 6.48s\n",
      "4006:\tlearn: 1.6335764\ttotal: 43.8s\tremaining: 6.46s\n",
      "4007:\tlearn: 1.6334466\ttotal: 43.9s\tremaining: 6.45s\n",
      "4008:\tlearn: 1.6333091\ttotal: 43.9s\tremaining: 6.44s\n",
      "4009:\tlearn: 1.6329980\ttotal: 43.9s\tremaining: 6.43s\n",
      "4010:\tlearn: 1.6326234\ttotal: 43.9s\tremaining: 6.42s\n",
      "4011:\tlearn: 1.6323815\ttotal: 43.9s\tremaining: 6.41s\n",
      "4012:\tlearn: 1.6321179\ttotal: 43.9s\tremaining: 6.4s\n",
      "4013:\tlearn: 1.6319399\ttotal: 43.9s\tremaining: 6.39s\n",
      "4014:\tlearn: 1.6318639\ttotal: 43.9s\tremaining: 6.38s\n",
      "4015:\tlearn: 1.6317242\ttotal: 43.9s\tremaining: 6.37s\n",
      "4016:\tlearn: 1.6314455\ttotal: 43.9s\tremaining: 6.36s\n",
      "4017:\tlearn: 1.6312246\ttotal: 44s\tremaining: 6.34s\n",
      "4018:\tlearn: 1.6310186\ttotal: 44s\tremaining: 6.33s\n",
      "4019:\tlearn: 1.6308742\ttotal: 44s\tremaining: 6.32s\n",
      "4020:\tlearn: 1.6306590\ttotal: 44s\tremaining: 6.31s\n",
      "4021:\tlearn: 1.6303981\ttotal: 44s\tremaining: 6.3s\n",
      "4022:\tlearn: 1.6301636\ttotal: 44s\tremaining: 6.29s\n",
      "4023:\tlearn: 1.6299957\ttotal: 44s\tremaining: 6.28s\n",
      "4024:\tlearn: 1.6298677\ttotal: 44s\tremaining: 6.27s\n",
      "4025:\tlearn: 1.6295151\ttotal: 44s\tremaining: 6.26s\n",
      "4026:\tlearn: 1.6292734\ttotal: 44.1s\tremaining: 6.25s\n",
      "4027:\tlearn: 1.6290361\ttotal: 44.1s\tremaining: 6.24s\n",
      "4028:\tlearn: 1.6288159\ttotal: 44.1s\tremaining: 6.22s\n",
      "4029:\tlearn: 1.6286317\ttotal: 44.1s\tremaining: 6.21s\n",
      "4030:\tlearn: 1.6283282\ttotal: 44.1s\tremaining: 6.2s\n",
      "4031:\tlearn: 1.6280776\ttotal: 44.1s\tremaining: 6.19s\n",
      "4032:\tlearn: 1.6279083\ttotal: 44.1s\tremaining: 6.18s\n",
      "4033:\tlearn: 1.6275342\ttotal: 44.1s\tremaining: 6.17s\n",
      "4034:\tlearn: 1.6274976\ttotal: 44.1s\tremaining: 6.16s\n",
      "4035:\tlearn: 1.6273665\ttotal: 44.2s\tremaining: 6.15s\n",
      "4036:\tlearn: 1.6271543\ttotal: 44.2s\tremaining: 6.14s\n",
      "4037:\tlearn: 1.6270611\ttotal: 44.2s\tremaining: 6.13s\n",
      "4038:\tlearn: 1.6268381\ttotal: 44.2s\tremaining: 6.12s\n",
      "4039:\tlearn: 1.6266091\ttotal: 44.2s\tremaining: 6.1s\n",
      "4040:\tlearn: 1.6263177\ttotal: 44.2s\tremaining: 6.09s\n",
      "4041:\tlearn: 1.6262340\ttotal: 44.2s\tremaining: 6.08s\n",
      "4042:\tlearn: 1.6261398\ttotal: 44.2s\tremaining: 6.07s\n",
      "4043:\tlearn: 1.6259922\ttotal: 44.2s\tremaining: 6.06s\n",
      "4044:\tlearn: 1.6258381\ttotal: 44.3s\tremaining: 6.05s\n",
      "4045:\tlearn: 1.6256002\ttotal: 44.3s\tremaining: 6.04s\n",
      "4046:\tlearn: 1.6254109\ttotal: 44.3s\tremaining: 6.03s\n",
      "4047:\tlearn: 1.6251625\ttotal: 44.3s\tremaining: 6.02s\n",
      "4048:\tlearn: 1.6249570\ttotal: 44.3s\tremaining: 6s\n",
      "4049:\tlearn: 1.6246795\ttotal: 44.3s\tremaining: 5.99s\n",
      "4050:\tlearn: 1.6244020\ttotal: 44.3s\tremaining: 5.98s\n",
      "4051:\tlearn: 1.6241590\ttotal: 44.3s\tremaining: 5.97s\n",
      "4052:\tlearn: 1.6241425\ttotal: 44.3s\tremaining: 5.96s\n",
      "4053:\tlearn: 1.6241174\ttotal: 44.3s\tremaining: 5.95s\n",
      "4054:\tlearn: 1.6238763\ttotal: 44.4s\tremaining: 5.94s\n",
      "4055:\tlearn: 1.6236523\ttotal: 44.4s\tremaining: 5.93s\n",
      "4056:\tlearn: 1.6233572\ttotal: 44.4s\tremaining: 5.92s\n",
      "4057:\tlearn: 1.6233013\ttotal: 44.4s\tremaining: 5.91s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4058:\tlearn: 1.6229232\ttotal: 44.4s\tremaining: 5.9s\n",
      "4059:\tlearn: 1.6226161\ttotal: 44.4s\tremaining: 5.88s\n",
      "4060:\tlearn: 1.6224988\ttotal: 44.4s\tremaining: 5.87s\n",
      "4061:\tlearn: 1.6223361\ttotal: 44.4s\tremaining: 5.86s\n",
      "4062:\tlearn: 1.6222231\ttotal: 44.4s\tremaining: 5.85s\n",
      "4063:\tlearn: 1.6219992\ttotal: 44.5s\tremaining: 5.84s\n",
      "4064:\tlearn: 1.6216758\ttotal: 44.5s\tremaining: 5.83s\n",
      "4065:\tlearn: 1.6213831\ttotal: 44.5s\tremaining: 5.82s\n",
      "4066:\tlearn: 1.6212454\ttotal: 44.5s\tremaining: 5.81s\n",
      "4067:\tlearn: 1.6209453\ttotal: 44.5s\tremaining: 5.8s\n",
      "4068:\tlearn: 1.6207164\ttotal: 44.5s\tremaining: 5.79s\n",
      "4069:\tlearn: 1.6205559\ttotal: 44.5s\tremaining: 5.78s\n",
      "4070:\tlearn: 1.6203341\ttotal: 44.5s\tremaining: 5.76s\n",
      "4071:\tlearn: 1.6199812\ttotal: 44.5s\tremaining: 5.75s\n",
      "4072:\tlearn: 1.6197803\ttotal: 44.6s\tremaining: 5.74s\n",
      "4073:\tlearn: 1.6196446\ttotal: 44.6s\tremaining: 5.73s\n",
      "4074:\tlearn: 1.6194801\ttotal: 44.6s\tremaining: 5.72s\n",
      "4075:\tlearn: 1.6191790\ttotal: 44.6s\tremaining: 5.71s\n",
      "4076:\tlearn: 1.6190075\ttotal: 44.6s\tremaining: 5.7s\n",
      "4077:\tlearn: 1.6188801\ttotal: 44.6s\tremaining: 5.69s\n",
      "4078:\tlearn: 1.6186377\ttotal: 44.6s\tremaining: 5.68s\n",
      "4079:\tlearn: 1.6185213\ttotal: 44.6s\tremaining: 5.67s\n",
      "4080:\tlearn: 1.6184095\ttotal: 44.6s\tremaining: 5.66s\n",
      "4081:\tlearn: 1.6180592\ttotal: 44.7s\tremaining: 5.64s\n",
      "4082:\tlearn: 1.6177641\ttotal: 44.7s\tremaining: 5.63s\n",
      "4083:\tlearn: 1.6176715\ttotal: 44.7s\tremaining: 5.62s\n",
      "4084:\tlearn: 1.6174951\ttotal: 44.7s\tremaining: 5.61s\n",
      "4085:\tlearn: 1.6172160\ttotal: 44.7s\tremaining: 5.6s\n",
      "4086:\tlearn: 1.6168079\ttotal: 44.7s\tremaining: 5.59s\n",
      "4087:\tlearn: 1.6167173\ttotal: 44.7s\tremaining: 5.58s\n",
      "4088:\tlearn: 1.6164694\ttotal: 44.7s\tremaining: 5.57s\n",
      "4089:\tlearn: 1.6163026\ttotal: 44.7s\tremaining: 5.56s\n",
      "4090:\tlearn: 1.6161079\ttotal: 44.8s\tremaining: 5.55s\n",
      "4091:\tlearn: 1.6159901\ttotal: 44.8s\tremaining: 5.54s\n",
      "4092:\tlearn: 1.6156566\ttotal: 44.8s\tremaining: 5.52s\n",
      "4093:\tlearn: 1.6153055\ttotal: 44.8s\tremaining: 5.51s\n",
      "4094:\tlearn: 1.6149914\ttotal: 44.8s\tremaining: 5.5s\n",
      "4095:\tlearn: 1.6149197\ttotal: 44.8s\tremaining: 5.49s\n",
      "4096:\tlearn: 1.6147140\ttotal: 44.8s\tremaining: 5.48s\n",
      "4097:\tlearn: 1.6143493\ttotal: 44.8s\tremaining: 5.47s\n",
      "4098:\tlearn: 1.6139484\ttotal: 44.8s\tremaining: 5.46s\n",
      "4099:\tlearn: 1.6135904\ttotal: 44.9s\tremaining: 5.45s\n",
      "4100:\tlearn: 1.6134132\ttotal: 44.9s\tremaining: 5.44s\n",
      "4101:\tlearn: 1.6132683\ttotal: 44.9s\tremaining: 5.43s\n",
      "4102:\tlearn: 1.6131101\ttotal: 44.9s\tremaining: 5.42s\n",
      "4103:\tlearn: 1.6127467\ttotal: 44.9s\tremaining: 5.4s\n",
      "4104:\tlearn: 1.6127045\ttotal: 44.9s\tremaining: 5.39s\n",
      "4105:\tlearn: 1.6124851\ttotal: 44.9s\tremaining: 5.38s\n",
      "4106:\tlearn: 1.6123732\ttotal: 44.9s\tremaining: 5.37s\n",
      "4107:\tlearn: 1.6122088\ttotal: 44.9s\tremaining: 5.36s\n",
      "4108:\tlearn: 1.6119628\ttotal: 45s\tremaining: 5.35s\n",
      "4109:\tlearn: 1.6118092\ttotal: 45s\tremaining: 5.34s\n",
      "4110:\tlearn: 1.6115102\ttotal: 45s\tremaining: 5.33s\n",
      "4111:\tlearn: 1.6112407\ttotal: 45s\tremaining: 5.32s\n",
      "4112:\tlearn: 1.6110300\ttotal: 45s\tremaining: 5.3s\n",
      "4113:\tlearn: 1.6108861\ttotal: 45s\tremaining: 5.29s\n",
      "4114:\tlearn: 1.6107070\ttotal: 45s\tremaining: 5.28s\n",
      "4115:\tlearn: 1.6105800\ttotal: 45s\tremaining: 5.27s\n",
      "4116:\tlearn: 1.6101021\ttotal: 45s\tremaining: 5.26s\n",
      "4117:\tlearn: 1.6098890\ttotal: 45s\tremaining: 5.25s\n",
      "4118:\tlearn: 1.6098865\ttotal: 45.1s\tremaining: 5.24s\n",
      "4119:\tlearn: 1.6097916\ttotal: 45.1s\tremaining: 5.23s\n",
      "4120:\tlearn: 1.6097006\ttotal: 45.1s\tremaining: 5.22s\n",
      "4121:\tlearn: 1.6093690\ttotal: 45.1s\tremaining: 5.21s\n",
      "4122:\tlearn: 1.6092323\ttotal: 45.1s\tremaining: 5.2s\n",
      "4123:\tlearn: 1.6088470\ttotal: 45.1s\tremaining: 5.18s\n",
      "4124:\tlearn: 1.6087351\ttotal: 45.1s\tremaining: 5.17s\n",
      "4125:\tlearn: 1.6086097\ttotal: 45.1s\tremaining: 5.16s\n",
      "4126:\tlearn: 1.6084721\ttotal: 45.1s\tremaining: 5.15s\n",
      "4127:\tlearn: 1.6082560\ttotal: 45.2s\tremaining: 5.14s\n",
      "4128:\tlearn: 1.6079102\ttotal: 45.2s\tremaining: 5.13s\n",
      "4129:\tlearn: 1.6077707\ttotal: 45.2s\tremaining: 5.12s\n",
      "4130:\tlearn: 1.6075959\ttotal: 45.2s\tremaining: 5.11s\n",
      "4131:\tlearn: 1.6072621\ttotal: 45.2s\tremaining: 5.1s\n",
      "4132:\tlearn: 1.6071506\ttotal: 45.2s\tremaining: 5.09s\n",
      "4133:\tlearn: 1.6070765\ttotal: 45.2s\tremaining: 5.08s\n",
      "4134:\tlearn: 1.6068267\ttotal: 45.2s\tremaining: 5.06s\n",
      "4135:\tlearn: 1.6065636\ttotal: 45.2s\tremaining: 5.05s\n",
      "4136:\tlearn: 1.6064466\ttotal: 45.3s\tremaining: 5.04s\n",
      "4137:\tlearn: 1.6061316\ttotal: 45.3s\tremaining: 5.03s\n",
      "4138:\tlearn: 1.6059150\ttotal: 45.3s\tremaining: 5.02s\n",
      "4139:\tlearn: 1.6058320\ttotal: 45.3s\tremaining: 5.01s\n",
      "4140:\tlearn: 1.6056893\ttotal: 45.3s\tremaining: 5s\n",
      "4141:\tlearn: 1.6054990\ttotal: 45.3s\tremaining: 4.99s\n",
      "4142:\tlearn: 1.6053443\ttotal: 45.3s\tremaining: 4.98s\n",
      "4143:\tlearn: 1.6051793\ttotal: 45.3s\tremaining: 4.97s\n",
      "4144:\tlearn: 1.6048813\ttotal: 45.3s\tremaining: 4.96s\n",
      "4145:\tlearn: 1.6047365\ttotal: 45.4s\tremaining: 4.94s\n",
      "4146:\tlearn: 1.6046868\ttotal: 45.4s\tremaining: 4.93s\n",
      "4147:\tlearn: 1.6044713\ttotal: 45.4s\tremaining: 4.92s\n",
      "4148:\tlearn: 1.6042636\ttotal: 45.4s\tremaining: 4.91s\n",
      "4149:\tlearn: 1.6040431\ttotal: 45.4s\tremaining: 4.9s\n",
      "4150:\tlearn: 1.6039163\ttotal: 45.4s\tremaining: 4.89s\n",
      "4151:\tlearn: 1.6038072\ttotal: 45.4s\tremaining: 4.88s\n",
      "4152:\tlearn: 1.6036090\ttotal: 45.4s\tremaining: 4.87s\n",
      "4153:\tlearn: 1.6033694\ttotal: 45.4s\tremaining: 4.86s\n",
      "4154:\tlearn: 1.6033683\ttotal: 45.4s\tremaining: 4.84s\n",
      "4155:\tlearn: 1.6031135\ttotal: 45.5s\tremaining: 4.83s\n",
      "4156:\tlearn: 1.6028885\ttotal: 45.5s\tremaining: 4.82s\n",
      "4157:\tlearn: 1.6026583\ttotal: 45.5s\tremaining: 4.81s\n",
      "4158:\tlearn: 1.6024222\ttotal: 45.5s\tremaining: 4.8s\n",
      "4159:\tlearn: 1.6023481\ttotal: 45.5s\tremaining: 4.79s\n",
      "4160:\tlearn: 1.6021697\ttotal: 45.5s\tremaining: 4.78s\n",
      "4161:\tlearn: 1.6020508\ttotal: 45.5s\tremaining: 4.77s\n",
      "4162:\tlearn: 1.6018426\ttotal: 45.5s\tremaining: 4.76s\n",
      "4163:\tlearn: 1.6016639\ttotal: 45.5s\tremaining: 4.75s\n",
      "4164:\tlearn: 1.6015287\ttotal: 45.5s\tremaining: 4.74s\n",
      "4165:\tlearn: 1.6012588\ttotal: 45.6s\tremaining: 4.72s\n",
      "4166:\tlearn: 1.6011640\ttotal: 45.6s\tremaining: 4.71s\n",
      "4167:\tlearn: 1.6009584\ttotal: 45.6s\tremaining: 4.7s\n",
      "4168:\tlearn: 1.6005721\ttotal: 45.6s\tremaining: 4.69s\n",
      "4169:\tlearn: 1.6003374\ttotal: 45.6s\tremaining: 4.68s\n",
      "4170:\tlearn: 1.6001819\ttotal: 45.6s\tremaining: 4.67s\n",
      "4171:\tlearn: 1.5998206\ttotal: 45.6s\tremaining: 4.66s\n",
      "4172:\tlearn: 1.5994465\ttotal: 45.6s\tremaining: 4.65s\n",
      "4173:\tlearn: 1.5992692\ttotal: 45.6s\tremaining: 4.64s\n",
      "4174:\tlearn: 1.5989318\ttotal: 45.7s\tremaining: 4.63s\n",
      "4175:\tlearn: 1.5988398\ttotal: 45.7s\tremaining: 4.62s\n",
      "4176:\tlearn: 1.5986232\ttotal: 45.7s\tremaining: 4.6s\n",
      "4177:\tlearn: 1.5983568\ttotal: 45.7s\tremaining: 4.59s\n",
      "4178:\tlearn: 1.5979981\ttotal: 45.7s\tremaining: 4.58s\n",
      "4179:\tlearn: 1.5978503\ttotal: 45.7s\tremaining: 4.57s\n",
      "4180:\tlearn: 1.5976405\ttotal: 45.7s\tremaining: 4.56s\n",
      "4181:\tlearn: 1.5974643\ttotal: 45.7s\tremaining: 4.55s\n",
      "4182:\tlearn: 1.5971133\ttotal: 45.7s\tremaining: 4.54s\n",
      "4183:\tlearn: 1.5969443\ttotal: 45.8s\tremaining: 4.53s\n",
      "4184:\tlearn: 1.5966920\ttotal: 45.8s\tremaining: 4.52s\n",
      "4185:\tlearn: 1.5965522\ttotal: 45.8s\tremaining: 4.51s\n",
      "4186:\tlearn: 1.5964326\ttotal: 45.8s\tremaining: 4.5s\n",
      "4187:\tlearn: 1.5963128\ttotal: 45.8s\tremaining: 4.48s\n",
      "4188:\tlearn: 1.5960744\ttotal: 45.8s\tremaining: 4.47s\n",
      "4189:\tlearn: 1.5959728\ttotal: 45.8s\tremaining: 4.46s\n",
      "4190:\tlearn: 1.5957040\ttotal: 45.8s\tremaining: 4.45s\n",
      "4191:\tlearn: 1.5955560\ttotal: 45.8s\tremaining: 4.44s\n",
      "4192:\tlearn: 1.5954214\ttotal: 45.9s\tremaining: 4.43s\n",
      "4193:\tlearn: 1.5952735\ttotal: 45.9s\tremaining: 4.42s\n",
      "4194:\tlearn: 1.5950613\ttotal: 45.9s\tremaining: 4.41s\n",
      "4195:\tlearn: 1.5948446\ttotal: 45.9s\tremaining: 4.4s\n",
      "4196:\tlearn: 1.5945758\ttotal: 45.9s\tremaining: 4.39s\n",
      "4197:\tlearn: 1.5945429\ttotal: 45.9s\tremaining: 4.38s\n",
      "4198:\tlearn: 1.5942515\ttotal: 45.9s\tremaining: 4.36s\n",
      "4199:\tlearn: 1.5940486\ttotal: 45.9s\tremaining: 4.35s\n",
      "4200:\tlearn: 1.5938419\ttotal: 45.9s\tremaining: 4.34s\n",
      "4201:\tlearn: 1.5936295\ttotal: 46s\tremaining: 4.33s\n",
      "4202:\tlearn: 1.5932378\ttotal: 46s\tremaining: 4.32s\n",
      "4203:\tlearn: 1.5928479\ttotal: 46s\tremaining: 4.31s\n",
      "4204:\tlearn: 1.5928180\ttotal: 46s\tremaining: 4.3s\n",
      "4205:\tlearn: 1.5925228\ttotal: 46s\tremaining: 4.29s\n",
      "4206:\tlearn: 1.5921185\ttotal: 46s\tremaining: 4.28s\n",
      "4207:\tlearn: 1.5918843\ttotal: 46s\tremaining: 4.26s\n",
      "4208:\tlearn: 1.5916833\ttotal: 46s\tremaining: 4.25s\n",
      "4209:\tlearn: 1.5914130\ttotal: 46s\tremaining: 4.24s\n",
      "4210:\tlearn: 1.5911859\ttotal: 46.1s\tremaining: 4.23s\n",
      "4211:\tlearn: 1.5909757\ttotal: 46.1s\tremaining: 4.22s\n",
      "4212:\tlearn: 1.5909505\ttotal: 46.1s\tremaining: 4.21s\n",
      "4213:\tlearn: 1.5905225\ttotal: 46.1s\tremaining: 4.2s\n",
      "4214:\tlearn: 1.5903457\ttotal: 46.1s\tremaining: 4.19s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4215:\tlearn: 1.5900889\ttotal: 46.1s\tremaining: 4.18s\n",
      "4216:\tlearn: 1.5895451\ttotal: 46.1s\tremaining: 4.17s\n",
      "4217:\tlearn: 1.5894611\ttotal: 46.1s\tremaining: 4.16s\n",
      "4218:\tlearn: 1.5890647\ttotal: 46.1s\tremaining: 4.14s\n",
      "4219:\tlearn: 1.5888550\ttotal: 46.2s\tremaining: 4.13s\n",
      "4220:\tlearn: 1.5886112\ttotal: 46.2s\tremaining: 4.12s\n",
      "4221:\tlearn: 1.5882828\ttotal: 46.2s\tremaining: 4.11s\n",
      "4222:\tlearn: 1.5880170\ttotal: 46.2s\tremaining: 4.1s\n",
      "4223:\tlearn: 1.5876345\ttotal: 46.2s\tremaining: 4.09s\n",
      "4224:\tlearn: 1.5874193\ttotal: 46.2s\tremaining: 4.08s\n",
      "4225:\tlearn: 1.5872490\ttotal: 46.2s\tremaining: 4.07s\n",
      "4226:\tlearn: 1.5871343\ttotal: 46.2s\tremaining: 4.06s\n",
      "4227:\tlearn: 1.5869324\ttotal: 46.2s\tremaining: 4.05s\n",
      "4228:\tlearn: 1.5866579\ttotal: 46.3s\tremaining: 4.04s\n",
      "4229:\tlearn: 1.5864473\ttotal: 46.3s\tremaining: 4.03s\n",
      "4230:\tlearn: 1.5863385\ttotal: 46.3s\tremaining: 4.01s\n",
      "4231:\tlearn: 1.5862178\ttotal: 46.3s\tremaining: 4s\n",
      "4232:\tlearn: 1.5859497\ttotal: 46.3s\tremaining: 3.99s\n",
      "4233:\tlearn: 1.5858296\ttotal: 46.3s\tremaining: 3.98s\n",
      "4234:\tlearn: 1.5857444\ttotal: 46.3s\tremaining: 3.97s\n",
      "4235:\tlearn: 1.5855816\ttotal: 46.3s\tremaining: 3.96s\n",
      "4236:\tlearn: 1.5851795\ttotal: 46.3s\tremaining: 3.95s\n",
      "4237:\tlearn: 1.5850697\ttotal: 46.4s\tremaining: 3.94s\n",
      "4238:\tlearn: 1.5848352\ttotal: 46.4s\tremaining: 3.93s\n",
      "4239:\tlearn: 1.5845311\ttotal: 46.4s\tremaining: 3.92s\n",
      "4240:\tlearn: 1.5844357\ttotal: 46.4s\tremaining: 3.9s\n",
      "4241:\tlearn: 1.5841099\ttotal: 46.4s\tremaining: 3.89s\n",
      "4242:\tlearn: 1.5838686\ttotal: 46.4s\tremaining: 3.88s\n",
      "4243:\tlearn: 1.5834758\ttotal: 46.4s\tremaining: 3.87s\n",
      "4244:\tlearn: 1.5830661\ttotal: 46.4s\tremaining: 3.86s\n",
      "4245:\tlearn: 1.5828410\ttotal: 46.5s\tremaining: 3.85s\n",
      "4246:\tlearn: 1.5827158\ttotal: 46.5s\tremaining: 3.84s\n",
      "4247:\tlearn: 1.5825333\ttotal: 46.5s\tremaining: 3.83s\n",
      "4248:\tlearn: 1.5823954\ttotal: 46.5s\tremaining: 3.82s\n",
      "4249:\tlearn: 1.5822975\ttotal: 46.5s\tremaining: 3.81s\n",
      "4250:\tlearn: 1.5820459\ttotal: 46.5s\tremaining: 3.8s\n",
      "4251:\tlearn: 1.5818271\ttotal: 46.5s\tremaining: 3.79s\n",
      "4252:\tlearn: 1.5814969\ttotal: 46.6s\tremaining: 3.78s\n",
      "4253:\tlearn: 1.5814057\ttotal: 46.6s\tremaining: 3.77s\n",
      "4254:\tlearn: 1.5813469\ttotal: 46.6s\tremaining: 3.75s\n",
      "4255:\tlearn: 1.5812317\ttotal: 46.6s\tremaining: 3.74s\n",
      "4256:\tlearn: 1.5810674\ttotal: 46.6s\tremaining: 3.73s\n",
      "4257:\tlearn: 1.5809047\ttotal: 46.6s\tremaining: 3.72s\n",
      "4258:\tlearn: 1.5807585\ttotal: 46.6s\tremaining: 3.71s\n",
      "4259:\tlearn: 1.5805039\ttotal: 46.6s\tremaining: 3.7s\n",
      "4260:\tlearn: 1.5801824\ttotal: 46.7s\tremaining: 3.69s\n",
      "4261:\tlearn: 1.5800935\ttotal: 46.7s\tremaining: 3.68s\n",
      "4262:\tlearn: 1.5797941\ttotal: 46.7s\tremaining: 3.67s\n",
      "4263:\tlearn: 1.5795929\ttotal: 46.7s\tremaining: 3.66s\n",
      "4264:\tlearn: 1.5794447\ttotal: 46.7s\tremaining: 3.65s\n",
      "4265:\tlearn: 1.5792981\ttotal: 46.7s\tremaining: 3.63s\n",
      "4266:\tlearn: 1.5790718\ttotal: 46.7s\tremaining: 3.62s\n",
      "4267:\tlearn: 1.5787058\ttotal: 46.7s\tremaining: 3.61s\n",
      "4268:\tlearn: 1.5784944\ttotal: 46.7s\tremaining: 3.6s\n",
      "4269:\tlearn: 1.5784009\ttotal: 46.8s\tremaining: 3.59s\n",
      "4270:\tlearn: 1.5782164\ttotal: 46.8s\tremaining: 3.58s\n",
      "4271:\tlearn: 1.5780104\ttotal: 46.8s\tremaining: 3.57s\n",
      "4272:\tlearn: 1.5776018\ttotal: 46.8s\tremaining: 3.56s\n",
      "4273:\tlearn: 1.5773706\ttotal: 46.8s\tremaining: 3.55s\n",
      "4274:\tlearn: 1.5772144\ttotal: 46.8s\tremaining: 3.54s\n",
      "4275:\tlearn: 1.5769785\ttotal: 46.8s\tremaining: 3.53s\n",
      "4276:\tlearn: 1.5767786\ttotal: 46.8s\tremaining: 3.52s\n",
      "4277:\tlearn: 1.5765239\ttotal: 46.8s\tremaining: 3.5s\n",
      "4278:\tlearn: 1.5762358\ttotal: 46.9s\tremaining: 3.49s\n",
      "4279:\tlearn: 1.5760199\ttotal: 46.9s\tremaining: 3.48s\n",
      "4280:\tlearn: 1.5758770\ttotal: 46.9s\tremaining: 3.47s\n",
      "4281:\tlearn: 1.5755204\ttotal: 46.9s\tremaining: 3.46s\n",
      "4282:\tlearn: 1.5754429\ttotal: 46.9s\tremaining: 3.45s\n",
      "4283:\tlearn: 1.5752576\ttotal: 46.9s\tremaining: 3.44s\n",
      "4284:\tlearn: 1.5745911\ttotal: 46.9s\tremaining: 3.43s\n",
      "4285:\tlearn: 1.5743652\ttotal: 46.9s\tremaining: 3.42s\n",
      "4286:\tlearn: 1.5741036\ttotal: 46.9s\tremaining: 3.4s\n",
      "4287:\tlearn: 1.5739097\ttotal: 47s\tremaining: 3.39s\n",
      "4288:\tlearn: 1.5736819\ttotal: 47s\tremaining: 3.38s\n",
      "4289:\tlearn: 1.5733982\ttotal: 47s\tremaining: 3.37s\n",
      "4290:\tlearn: 1.5730416\ttotal: 47s\tremaining: 3.36s\n",
      "4291:\tlearn: 1.5727523\ttotal: 47s\tremaining: 3.35s\n",
      "4292:\tlearn: 1.5724494\ttotal: 47s\tremaining: 3.34s\n",
      "4293:\tlearn: 1.5723168\ttotal: 47s\tremaining: 3.33s\n",
      "4294:\tlearn: 1.5722986\ttotal: 47s\tremaining: 3.32s\n",
      "4295:\tlearn: 1.5721674\ttotal: 47s\tremaining: 3.31s\n",
      "4296:\tlearn: 1.5720511\ttotal: 47s\tremaining: 3.29s\n",
      "4297:\tlearn: 1.5719373\ttotal: 47.1s\tremaining: 3.28s\n",
      "4298:\tlearn: 1.5717972\ttotal: 47.1s\tremaining: 3.27s\n",
      "4299:\tlearn: 1.5715915\ttotal: 47.1s\tremaining: 3.26s\n",
      "4300:\tlearn: 1.5714595\ttotal: 47.1s\tremaining: 3.25s\n",
      "4301:\tlearn: 1.5712132\ttotal: 47.1s\tremaining: 3.24s\n",
      "4302:\tlearn: 1.5710493\ttotal: 47.1s\tremaining: 3.23s\n",
      "4303:\tlearn: 1.5709413\ttotal: 47.1s\tremaining: 3.22s\n",
      "4304:\tlearn: 1.5706521\ttotal: 47.1s\tremaining: 3.21s\n",
      "4305:\tlearn: 1.5704219\ttotal: 47.1s\tremaining: 3.2s\n",
      "4306:\tlearn: 1.5697687\ttotal: 47.2s\tremaining: 3.19s\n",
      "4307:\tlearn: 1.5696523\ttotal: 47.2s\tremaining: 3.17s\n",
      "4308:\tlearn: 1.5694432\ttotal: 47.2s\tremaining: 3.16s\n",
      "4309:\tlearn: 1.5692914\ttotal: 47.2s\tremaining: 3.15s\n",
      "4310:\tlearn: 1.5691680\ttotal: 47.2s\tremaining: 3.14s\n",
      "4311:\tlearn: 1.5690509\ttotal: 47.2s\tremaining: 3.13s\n",
      "4312:\tlearn: 1.5688377\ttotal: 47.2s\tremaining: 3.12s\n",
      "4313:\tlearn: 1.5685715\ttotal: 47.2s\tremaining: 3.11s\n",
      "4314:\tlearn: 1.5683704\ttotal: 47.2s\tremaining: 3.1s\n",
      "4315:\tlearn: 1.5680939\ttotal: 47.3s\tremaining: 3.09s\n",
      "4316:\tlearn: 1.5677918\ttotal: 47.3s\tremaining: 3.08s\n",
      "4317:\tlearn: 1.5676050\ttotal: 47.3s\tremaining: 3.06s\n",
      "4318:\tlearn: 1.5674318\ttotal: 47.3s\tremaining: 3.05s\n",
      "4319:\tlearn: 1.5672357\ttotal: 47.3s\tremaining: 3.04s\n",
      "4320:\tlearn: 1.5670797\ttotal: 47.3s\tremaining: 3.03s\n",
      "4321:\tlearn: 1.5668281\ttotal: 47.3s\tremaining: 3.02s\n",
      "4322:\tlearn: 1.5666574\ttotal: 47.3s\tremaining: 3.01s\n",
      "4323:\tlearn: 1.5665029\ttotal: 47.3s\tremaining: 3s\n",
      "4324:\tlearn: 1.5663150\ttotal: 47.4s\tremaining: 2.99s\n",
      "4325:\tlearn: 1.5661925\ttotal: 47.4s\tremaining: 2.98s\n",
      "4326:\tlearn: 1.5660523\ttotal: 47.4s\tremaining: 2.97s\n",
      "4327:\tlearn: 1.5658117\ttotal: 47.4s\tremaining: 2.96s\n",
      "4328:\tlearn: 1.5657026\ttotal: 47.4s\tremaining: 2.94s\n",
      "4329:\tlearn: 1.5652920\ttotal: 47.4s\tremaining: 2.93s\n",
      "4330:\tlearn: 1.5650878\ttotal: 47.4s\tremaining: 2.92s\n",
      "4331:\tlearn: 1.5649398\ttotal: 47.4s\tremaining: 2.91s\n",
      "4332:\tlearn: 1.5648442\ttotal: 47.4s\tremaining: 2.9s\n",
      "4333:\tlearn: 1.5647150\ttotal: 47.5s\tremaining: 2.89s\n",
      "4334:\tlearn: 1.5645149\ttotal: 47.5s\tremaining: 2.88s\n",
      "4335:\tlearn: 1.5643723\ttotal: 47.5s\tremaining: 2.87s\n",
      "4336:\tlearn: 1.5641093\ttotal: 47.5s\tremaining: 2.86s\n",
      "4337:\tlearn: 1.5639610\ttotal: 47.5s\tremaining: 2.85s\n",
      "4338:\tlearn: 1.5636724\ttotal: 47.5s\tremaining: 2.83s\n",
      "4339:\tlearn: 1.5633952\ttotal: 47.5s\tremaining: 2.82s\n",
      "4340:\tlearn: 1.5631414\ttotal: 47.5s\tremaining: 2.81s\n",
      "4341:\tlearn: 1.5627866\ttotal: 47.5s\tremaining: 2.8s\n",
      "4342:\tlearn: 1.5626104\ttotal: 47.6s\tremaining: 2.79s\n",
      "4343:\tlearn: 1.5621664\ttotal: 47.6s\tremaining: 2.78s\n",
      "4344:\tlearn: 1.5619297\ttotal: 47.6s\tremaining: 2.77s\n",
      "4345:\tlearn: 1.5618345\ttotal: 47.6s\tremaining: 2.76s\n",
      "4346:\tlearn: 1.5616607\ttotal: 47.6s\tremaining: 2.75s\n",
      "4347:\tlearn: 1.5614700\ttotal: 47.6s\tremaining: 2.74s\n",
      "4348:\tlearn: 1.5612290\ttotal: 47.6s\tremaining: 2.73s\n",
      "4349:\tlearn: 1.5610996\ttotal: 47.6s\tremaining: 2.71s\n",
      "4350:\tlearn: 1.5608480\ttotal: 47.7s\tremaining: 2.71s\n",
      "4351:\tlearn: 1.5604903\ttotal: 47.7s\tremaining: 2.69s\n",
      "4352:\tlearn: 1.5602979\ttotal: 47.7s\tremaining: 2.68s\n",
      "4353:\tlearn: 1.5600310\ttotal: 47.7s\tremaining: 2.67s\n",
      "4354:\tlearn: 1.5596317\ttotal: 47.7s\tremaining: 2.66s\n",
      "4355:\tlearn: 1.5592852\ttotal: 47.7s\tremaining: 2.65s\n",
      "4356:\tlearn: 1.5588787\ttotal: 47.7s\tremaining: 2.64s\n",
      "4357:\tlearn: 1.5585630\ttotal: 47.7s\tremaining: 2.63s\n",
      "4358:\tlearn: 1.5583376\ttotal: 47.7s\tremaining: 2.62s\n",
      "4359:\tlearn: 1.5581331\ttotal: 47.8s\tremaining: 2.61s\n",
      "4360:\tlearn: 1.5580374\ttotal: 47.8s\tremaining: 2.6s\n",
      "4361:\tlearn: 1.5579368\ttotal: 47.8s\tremaining: 2.58s\n",
      "4362:\tlearn: 1.5577118\ttotal: 47.8s\tremaining: 2.57s\n",
      "4363:\tlearn: 1.5575441\ttotal: 47.8s\tremaining: 2.56s\n",
      "4364:\tlearn: 1.5572212\ttotal: 47.8s\tremaining: 2.55s\n",
      "4365:\tlearn: 1.5569468\ttotal: 47.8s\tremaining: 2.54s\n",
      "4366:\tlearn: 1.5566967\ttotal: 47.8s\tremaining: 2.53s\n",
      "4367:\tlearn: 1.5564377\ttotal: 47.9s\tremaining: 2.52s\n",
      "4368:\tlearn: 1.5563136\ttotal: 47.9s\tremaining: 2.51s\n",
      "4369:\tlearn: 1.5561811\ttotal: 47.9s\tremaining: 2.5s\n",
      "4370:\tlearn: 1.5559936\ttotal: 47.9s\tremaining: 2.49s\n",
      "4371:\tlearn: 1.5558685\ttotal: 47.9s\tremaining: 2.48s\n",
      "4372:\tlearn: 1.5557149\ttotal: 47.9s\tremaining: 2.46s\n",
      "4373:\tlearn: 1.5556279\ttotal: 47.9s\tremaining: 2.45s\n",
      "4374:\tlearn: 1.5554132\ttotal: 47.9s\tremaining: 2.44s\n",
      "4375:\tlearn: 1.5550809\ttotal: 47.9s\tremaining: 2.43s\n",
      "4376:\tlearn: 1.5549949\ttotal: 48s\tremaining: 2.42s\n",
      "4377:\tlearn: 1.5548726\ttotal: 48s\tremaining: 2.41s\n",
      "4378:\tlearn: 1.5546916\ttotal: 48s\tremaining: 2.4s\n",
      "4379:\tlearn: 1.5543905\ttotal: 48s\tremaining: 2.39s\n",
      "4380:\tlearn: 1.5542492\ttotal: 48s\tremaining: 2.38s\n",
      "4381:\tlearn: 1.5538265\ttotal: 48s\tremaining: 2.37s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4382:\tlearn: 1.5535905\ttotal: 48s\tremaining: 2.35s\n",
      "4383:\tlearn: 1.5533415\ttotal: 48s\tremaining: 2.34s\n",
      "4384:\tlearn: 1.5531224\ttotal: 48s\tremaining: 2.33s\n",
      "4385:\tlearn: 1.5529511\ttotal: 48.1s\tremaining: 2.32s\n",
      "4386:\tlearn: 1.5526159\ttotal: 48.1s\tremaining: 2.31s\n",
      "4387:\tlearn: 1.5523471\ttotal: 48.1s\tremaining: 2.3s\n",
      "4388:\tlearn: 1.5519584\ttotal: 48.1s\tremaining: 2.29s\n",
      "4389:\tlearn: 1.5518454\ttotal: 48.1s\tremaining: 2.28s\n",
      "4390:\tlearn: 1.5517431\ttotal: 48.1s\tremaining: 2.27s\n",
      "4391:\tlearn: 1.5516598\ttotal: 48.1s\tremaining: 2.26s\n",
      "4392:\tlearn: 1.5515087\ttotal: 48.1s\tremaining: 2.25s\n",
      "4393:\tlearn: 1.5513358\ttotal: 48.1s\tremaining: 2.23s\n",
      "4394:\tlearn: 1.5511913\ttotal: 48.1s\tremaining: 2.22s\n",
      "4395:\tlearn: 1.5508150\ttotal: 48.2s\tremaining: 2.21s\n",
      "4396:\tlearn: 1.5505969\ttotal: 48.2s\tremaining: 2.2s\n",
      "4397:\tlearn: 1.5504130\ttotal: 48.2s\tremaining: 2.19s\n",
      "4398:\tlearn: 1.5502921\ttotal: 48.2s\tremaining: 2.18s\n",
      "4399:\tlearn: 1.5500462\ttotal: 48.2s\tremaining: 2.17s\n",
      "4400:\tlearn: 1.5499033\ttotal: 48.2s\tremaining: 2.16s\n",
      "4401:\tlearn: 1.5496926\ttotal: 48.2s\tremaining: 2.15s\n",
      "4402:\tlearn: 1.5494589\ttotal: 48.2s\tremaining: 2.13s\n",
      "4403:\tlearn: 1.5492845\ttotal: 48.2s\tremaining: 2.13s\n",
      "4404:\tlearn: 1.5491459\ttotal: 48.3s\tremaining: 2.11s\n",
      "4405:\tlearn: 1.5489056\ttotal: 48.3s\tremaining: 2.1s\n",
      "4406:\tlearn: 1.5486758\ttotal: 48.3s\tremaining: 2.09s\n",
      "4407:\tlearn: 1.5484053\ttotal: 48.3s\tremaining: 2.08s\n",
      "4408:\tlearn: 1.5481618\ttotal: 48.3s\tremaining: 2.07s\n",
      "4409:\tlearn: 1.5480091\ttotal: 48.3s\tremaining: 2.06s\n",
      "4410:\tlearn: 1.5476983\ttotal: 48.3s\tremaining: 2.05s\n",
      "4411:\tlearn: 1.5473289\ttotal: 48.3s\tremaining: 2.04s\n",
      "4412:\tlearn: 1.5471956\ttotal: 48.3s\tremaining: 2.03s\n",
      "4413:\tlearn: 1.5467645\ttotal: 48.3s\tremaining: 2.02s\n",
      "4414:\tlearn: 1.5464877\ttotal: 48.4s\tremaining: 2s\n",
      "4415:\tlearn: 1.5461625\ttotal: 48.4s\tremaining: 1.99s\n",
      "4416:\tlearn: 1.5461234\ttotal: 48.4s\tremaining: 1.98s\n",
      "4417:\tlearn: 1.5458878\ttotal: 48.4s\tremaining: 1.97s\n",
      "4418:\tlearn: 1.5456431\ttotal: 48.4s\tremaining: 1.96s\n",
      "4419:\tlearn: 1.5455133\ttotal: 48.4s\tremaining: 1.95s\n",
      "4420:\tlearn: 1.5452910\ttotal: 48.4s\tremaining: 1.94s\n",
      "4421:\tlearn: 1.5450338\ttotal: 48.4s\tremaining: 1.93s\n",
      "4422:\tlearn: 1.5450043\ttotal: 48.4s\tremaining: 1.92s\n",
      "4423:\tlearn: 1.5448319\ttotal: 48.5s\tremaining: 1.91s\n",
      "4424:\tlearn: 1.5445970\ttotal: 48.5s\tremaining: 1.89s\n",
      "4425:\tlearn: 1.5442884\ttotal: 48.5s\tremaining: 1.88s\n",
      "4426:\tlearn: 1.5440501\ttotal: 48.5s\tremaining: 1.87s\n",
      "4427:\tlearn: 1.5438613\ttotal: 48.5s\tremaining: 1.86s\n",
      "4428:\tlearn: 1.5438316\ttotal: 48.5s\tremaining: 1.85s\n",
      "4429:\tlearn: 1.5435186\ttotal: 48.5s\tremaining: 1.84s\n",
      "4430:\tlearn: 1.5433863\ttotal: 48.5s\tremaining: 1.83s\n",
      "4431:\tlearn: 1.5432416\ttotal: 48.5s\tremaining: 1.82s\n",
      "4432:\tlearn: 1.5427250\ttotal: 48.5s\tremaining: 1.81s\n",
      "4433:\tlearn: 1.5423961\ttotal: 48.6s\tremaining: 1.8s\n",
      "4434:\tlearn: 1.5422891\ttotal: 48.6s\tremaining: 1.78s\n",
      "4435:\tlearn: 1.5421649\ttotal: 48.6s\tremaining: 1.77s\n",
      "4436:\tlearn: 1.5419998\ttotal: 48.6s\tremaining: 1.76s\n",
      "4437:\tlearn: 1.5417727\ttotal: 48.6s\tremaining: 1.75s\n",
      "4438:\tlearn: 1.5417170\ttotal: 48.6s\tremaining: 1.74s\n",
      "4439:\tlearn: 1.5415395\ttotal: 48.6s\tremaining: 1.73s\n",
      "4440:\tlearn: 1.5412923\ttotal: 48.6s\tremaining: 1.72s\n",
      "4441:\tlearn: 1.5411466\ttotal: 48.7s\tremaining: 1.71s\n",
      "4442:\tlearn: 1.5410032\ttotal: 48.7s\tremaining: 1.7s\n",
      "4443:\tlearn: 1.5408165\ttotal: 48.7s\tremaining: 1.69s\n",
      "4444:\tlearn: 1.5406768\ttotal: 48.7s\tremaining: 1.68s\n",
      "4445:\tlearn: 1.5404596\ttotal: 48.7s\tremaining: 1.67s\n",
      "4446:\tlearn: 1.5402918\ttotal: 48.7s\tremaining: 1.65s\n",
      "4447:\tlearn: 1.5401300\ttotal: 48.7s\tremaining: 1.64s\n",
      "4448:\tlearn: 1.5399171\ttotal: 48.7s\tremaining: 1.63s\n",
      "4449:\tlearn: 1.5396095\ttotal: 48.8s\tremaining: 1.62s\n",
      "4450:\tlearn: 1.5393860\ttotal: 48.8s\tremaining: 1.61s\n",
      "4451:\tlearn: 1.5392856\ttotal: 48.8s\tremaining: 1.6s\n",
      "4452:\tlearn: 1.5391727\ttotal: 48.8s\tremaining: 1.59s\n",
      "4453:\tlearn: 1.5389333\ttotal: 48.8s\tremaining: 1.58s\n",
      "4454:\tlearn: 1.5388269\ttotal: 48.8s\tremaining: 1.57s\n",
      "4455:\tlearn: 1.5386742\ttotal: 48.8s\tremaining: 1.55s\n",
      "4456:\tlearn: 1.5384746\ttotal: 48.8s\tremaining: 1.54s\n",
      "4457:\tlearn: 1.5382526\ttotal: 48.8s\tremaining: 1.53s\n",
      "4458:\tlearn: 1.5380383\ttotal: 48.9s\tremaining: 1.52s\n",
      "4459:\tlearn: 1.5378596\ttotal: 48.9s\tremaining: 1.51s\n",
      "4460:\tlearn: 1.5377313\ttotal: 48.9s\tremaining: 1.5s\n",
      "4461:\tlearn: 1.5375833\ttotal: 48.9s\tremaining: 1.49s\n",
      "4462:\tlearn: 1.5372649\ttotal: 48.9s\tremaining: 1.48s\n",
      "4463:\tlearn: 1.5370373\ttotal: 48.9s\tremaining: 1.47s\n",
      "4464:\tlearn: 1.5367580\ttotal: 48.9s\tremaining: 1.46s\n",
      "4465:\tlearn: 1.5365433\ttotal: 48.9s\tremaining: 1.45s\n",
      "4466:\tlearn: 1.5363662\ttotal: 48.9s\tremaining: 1.44s\n",
      "4467:\tlearn: 1.5363096\ttotal: 49s\tremaining: 1.42s\n",
      "4468:\tlearn: 1.5362542\ttotal: 49s\tremaining: 1.41s\n",
      "4469:\tlearn: 1.5361460\ttotal: 49s\tremaining: 1.4s\n",
      "4470:\tlearn: 1.5359583\ttotal: 49s\tremaining: 1.39s\n",
      "4471:\tlearn: 1.5357959\ttotal: 49s\tremaining: 1.38s\n",
      "4472:\tlearn: 1.5355959\ttotal: 49s\tremaining: 1.37s\n",
      "4473:\tlearn: 1.5353556\ttotal: 49s\tremaining: 1.36s\n",
      "4474:\tlearn: 1.5352226\ttotal: 49s\tremaining: 1.35s\n",
      "4475:\tlearn: 1.5351175\ttotal: 49s\tremaining: 1.34s\n",
      "4476:\tlearn: 1.5349056\ttotal: 49s\tremaining: 1.32s\n",
      "4477:\tlearn: 1.5348026\ttotal: 49.1s\tremaining: 1.31s\n",
      "4478:\tlearn: 1.5347385\ttotal: 49.1s\tremaining: 1.3s\n",
      "4479:\tlearn: 1.5345943\ttotal: 49.1s\tremaining: 1.29s\n",
      "4480:\tlearn: 1.5344277\ttotal: 49.1s\tremaining: 1.28s\n",
      "4481:\tlearn: 1.5341519\ttotal: 49.1s\tremaining: 1.27s\n",
      "4482:\tlearn: 1.5339789\ttotal: 49.1s\tremaining: 1.26s\n",
      "4483:\tlearn: 1.5339009\ttotal: 49.1s\tremaining: 1.25s\n",
      "4484:\tlearn: 1.5338298\ttotal: 49.1s\tremaining: 1.24s\n",
      "4485:\tlearn: 1.5337307\ttotal: 49.1s\tremaining: 1.23s\n",
      "4486:\tlearn: 1.5335834\ttotal: 49.2s\tremaining: 1.22s\n",
      "4487:\tlearn: 1.5333987\ttotal: 49.2s\tremaining: 1.2s\n",
      "4488:\tlearn: 1.5332644\ttotal: 49.2s\tremaining: 1.19s\n",
      "4489:\tlearn: 1.5330413\ttotal: 49.2s\tremaining: 1.18s\n",
      "4490:\tlearn: 1.5329461\ttotal: 49.2s\tremaining: 1.17s\n",
      "4491:\tlearn: 1.5325641\ttotal: 49.2s\tremaining: 1.16s\n",
      "4492:\tlearn: 1.5324738\ttotal: 49.2s\tremaining: 1.15s\n",
      "4493:\tlearn: 1.5323115\ttotal: 49.2s\tremaining: 1.14s\n",
      "4494:\tlearn: 1.5318611\ttotal: 49.2s\tremaining: 1.13s\n",
      "4495:\tlearn: 1.5315370\ttotal: 49.3s\tremaining: 1.12s\n",
      "4496:\tlearn: 1.5311787\ttotal: 49.3s\tremaining: 1.11s\n",
      "4497:\tlearn: 1.5308550\ttotal: 49.3s\tremaining: 1.09s\n",
      "4498:\tlearn: 1.5307310\ttotal: 49.3s\tremaining: 1.08s\n",
      "4499:\tlearn: 1.5305343\ttotal: 49.3s\tremaining: 1.07s\n",
      "4500:\tlearn: 1.5302568\ttotal: 49.3s\tremaining: 1.06s\n",
      "4501:\tlearn: 1.5299639\ttotal: 49.3s\tremaining: 1.05s\n",
      "4502:\tlearn: 1.5297248\ttotal: 49.4s\tremaining: 1.04s\n",
      "4503:\tlearn: 1.5296000\ttotal: 49.4s\tremaining: 1.03s\n",
      "4504:\tlearn: 1.5293693\ttotal: 49.4s\tremaining: 1.02s\n",
      "4505:\tlearn: 1.5291590\ttotal: 49.4s\tremaining: 1.01s\n",
      "4506:\tlearn: 1.5288426\ttotal: 49.4s\tremaining: 997ms\n",
      "4507:\tlearn: 1.5286969\ttotal: 49.4s\tremaining: 986ms\n",
      "4508:\tlearn: 1.5285173\ttotal: 49.4s\tremaining: 975ms\n",
      "4509:\tlearn: 1.5282534\ttotal: 49.4s\tremaining: 964ms\n",
      "4510:\tlearn: 1.5278724\ttotal: 49.4s\tremaining: 953ms\n",
      "4511:\tlearn: 1.5277038\ttotal: 49.4s\tremaining: 942ms\n",
      "4512:\tlearn: 1.5275372\ttotal: 49.5s\tremaining: 932ms\n",
      "4513:\tlearn: 1.5274399\ttotal: 49.5s\tremaining: 921ms\n",
      "4514:\tlearn: 1.5273677\ttotal: 49.5s\tremaining: 910ms\n",
      "4515:\tlearn: 1.5271537\ttotal: 49.5s\tremaining: 899ms\n",
      "4516:\tlearn: 1.5268817\ttotal: 49.5s\tremaining: 888ms\n",
      "4517:\tlearn: 1.5267581\ttotal: 49.5s\tremaining: 877ms\n",
      "4518:\tlearn: 1.5264370\ttotal: 49.5s\tremaining: 866ms\n",
      "4519:\tlearn: 1.5262368\ttotal: 49.5s\tremaining: 855ms\n",
      "4520:\tlearn: 1.5260650\ttotal: 49.5s\tremaining: 844ms\n",
      "4521:\tlearn: 1.5260228\ttotal: 49.6s\tremaining: 833ms\n",
      "4522:\tlearn: 1.5258816\ttotal: 49.6s\tremaining: 822ms\n",
      "4523:\tlearn: 1.5258337\ttotal: 49.6s\tremaining: 811ms\n",
      "4524:\tlearn: 1.5257019\ttotal: 49.6s\tremaining: 800ms\n",
      "4525:\tlearn: 1.5256284\ttotal: 49.6s\tremaining: 789ms\n",
      "4526:\tlearn: 1.5254328\ttotal: 49.6s\tremaining: 778ms\n",
      "4527:\tlearn: 1.5253373\ttotal: 49.6s\tremaining: 767ms\n",
      "4528:\tlearn: 1.5251865\ttotal: 49.6s\tremaining: 756ms\n",
      "4529:\tlearn: 1.5251272\ttotal: 49.6s\tremaining: 745ms\n",
      "4530:\tlearn: 1.5248519\ttotal: 49.6s\tremaining: 734ms\n",
      "4531:\tlearn: 1.5246932\ttotal: 49.7s\tremaining: 723ms\n",
      "4532:\tlearn: 1.5245709\ttotal: 49.7s\tremaining: 712ms\n",
      "4533:\tlearn: 1.5243962\ttotal: 49.7s\tremaining: 701ms\n",
      "4534:\tlearn: 1.5242046\ttotal: 49.7s\tremaining: 690ms\n",
      "4535:\tlearn: 1.5240800\ttotal: 49.7s\tremaining: 679ms\n",
      "4536:\tlearn: 1.5237982\ttotal: 49.7s\tremaining: 668ms\n",
      "4537:\tlearn: 1.5236414\ttotal: 49.7s\tremaining: 658ms\n",
      "4538:\tlearn: 1.5234624\ttotal: 49.7s\tremaining: 647ms\n",
      "4539:\tlearn: 1.5232978\ttotal: 49.8s\tremaining: 636ms\n",
      "4540:\tlearn: 1.5229962\ttotal: 49.8s\tremaining: 625ms\n",
      "4541:\tlearn: 1.5227779\ttotal: 49.8s\tremaining: 614ms\n",
      "4542:\tlearn: 1.5226446\ttotal: 49.8s\tremaining: 603ms\n",
      "4543:\tlearn: 1.5224776\ttotal: 49.8s\tremaining: 592ms\n",
      "4544:\tlearn: 1.5221567\ttotal: 49.8s\tremaining: 581ms\n",
      "4545:\tlearn: 1.5219649\ttotal: 49.8s\tremaining: 570ms\n",
      "4546:\tlearn: 1.5216614\ttotal: 49.8s\tremaining: 559ms\n",
      "4547:\tlearn: 1.5214872\ttotal: 49.8s\tremaining: 548ms\n",
      "4548:\tlearn: 1.5213616\ttotal: 49.9s\tremaining: 537ms\n",
      "4549:\tlearn: 1.5211206\ttotal: 49.9s\tremaining: 526ms\n",
      "4550:\tlearn: 1.5209779\ttotal: 49.9s\tremaining: 515ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4551:\tlearn: 1.5207589\ttotal: 49.9s\tremaining: 504ms\n",
      "4552:\tlearn: 1.5206487\ttotal: 49.9s\tremaining: 493ms\n",
      "4553:\tlearn: 1.5203637\ttotal: 49.9s\tremaining: 482ms\n",
      "4554:\tlearn: 1.5199987\ttotal: 49.9s\tremaining: 471ms\n",
      "4555:\tlearn: 1.5198553\ttotal: 49.9s\tremaining: 460ms\n",
      "4556:\tlearn: 1.5196810\ttotal: 49.9s\tremaining: 449ms\n",
      "4557:\tlearn: 1.5194596\ttotal: 50s\tremaining: 438ms\n",
      "4558:\tlearn: 1.5191488\ttotal: 50s\tremaining: 427ms\n",
      "4559:\tlearn: 1.5190243\ttotal: 50s\tremaining: 416ms\n",
      "4560:\tlearn: 1.5188639\ttotal: 50s\tremaining: 405ms\n",
      "4561:\tlearn: 1.5187277\ttotal: 50s\tremaining: 395ms\n",
      "4562:\tlearn: 1.5182968\ttotal: 50s\tremaining: 384ms\n",
      "4563:\tlearn: 1.5181487\ttotal: 50s\tremaining: 373ms\n",
      "4564:\tlearn: 1.5179707\ttotal: 50s\tremaining: 362ms\n",
      "4565:\tlearn: 1.5178148\ttotal: 50s\tremaining: 351ms\n",
      "4566:\tlearn: 1.5176832\ttotal: 50.1s\tremaining: 340ms\n",
      "4567:\tlearn: 1.5175402\ttotal: 50.1s\tremaining: 329ms\n",
      "4568:\tlearn: 1.5173323\ttotal: 50.1s\tremaining: 318ms\n",
      "4569:\tlearn: 1.5171993\ttotal: 50.1s\tremaining: 307ms\n",
      "4570:\tlearn: 1.5170808\ttotal: 50.1s\tremaining: 296ms\n",
      "4571:\tlearn: 1.5168026\ttotal: 50.1s\tremaining: 285ms\n",
      "4572:\tlearn: 1.5166727\ttotal: 50.1s\tremaining: 274ms\n",
      "4573:\tlearn: 1.5164395\ttotal: 50.1s\tremaining: 263ms\n",
      "4574:\tlearn: 1.5163733\ttotal: 50.1s\tremaining: 252ms\n",
      "4575:\tlearn: 1.5163081\ttotal: 50.1s\tremaining: 241ms\n",
      "4576:\tlearn: 1.5160690\ttotal: 50.2s\tremaining: 230ms\n",
      "4577:\tlearn: 1.5157968\ttotal: 50.2s\tremaining: 219ms\n",
      "4578:\tlearn: 1.5156746\ttotal: 50.2s\tremaining: 208ms\n",
      "4579:\tlearn: 1.5155206\ttotal: 50.2s\tremaining: 197ms\n",
      "4580:\tlearn: 1.5153861\ttotal: 50.2s\tremaining: 186ms\n",
      "4581:\tlearn: 1.5151331\ttotal: 50.2s\tremaining: 175ms\n",
      "4582:\tlearn: 1.5150047\ttotal: 50.2s\tremaining: 164ms\n",
      "4583:\tlearn: 1.5147568\ttotal: 50.2s\tremaining: 153ms\n",
      "4584:\tlearn: 1.5145935\ttotal: 50.2s\tremaining: 142ms\n",
      "4585:\tlearn: 1.5143091\ttotal: 50.3s\tremaining: 132ms\n",
      "4586:\tlearn: 1.5141981\ttotal: 50.3s\tremaining: 121ms\n",
      "4587:\tlearn: 1.5140182\ttotal: 50.3s\tremaining: 110ms\n",
      "4588:\tlearn: 1.5138918\ttotal: 50.3s\tremaining: 98.6ms\n",
      "4589:\tlearn: 1.5137397\ttotal: 50.3s\tremaining: 87.7ms\n",
      "4590:\tlearn: 1.5135103\ttotal: 50.3s\tremaining: 76.7ms\n",
      "4591:\tlearn: 1.5134561\ttotal: 50.3s\tremaining: 65.8ms\n",
      "4592:\tlearn: 1.5133081\ttotal: 50.3s\tremaining: 54.8ms\n",
      "4593:\tlearn: 1.5131112\ttotal: 50.3s\tremaining: 43.8ms\n",
      "4594:\tlearn: 1.5127614\ttotal: 50.4s\tremaining: 32.9ms\n",
      "4595:\tlearn: 1.5125280\ttotal: 50.4s\tremaining: 21.9ms\n",
      "4596:\tlearn: 1.5122425\ttotal: 50.4s\tremaining: 11ms\n",
      "4597:\tlearn: 1.5119836\ttotal: 50.4s\tremaining: 0us\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8244973703390805, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244973703390805\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.753170749901516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.753170749901516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "final_model_3, final_pred_3 = stacking_models(base_models_3,\n",
    "                                                X_train, y_train_transformed,\n",
    "                                                test=X_test, final_regressor='SVR', \n",
    "                                                final_params={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d21e1371",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_3_2 = pred_to_df(final_pred_3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bde0f9-2ccc-4788-8493-810d9e2a0674",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2e7fbfac-08db-4827-853c-966fa8132353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_with_slided(dataframe, merging_dataframe):\n",
    "    \n",
    "    new_dataframe = pd.DataFrame()\n",
    "    new_dataframe['val1'] = dataframe['values']\n",
    "    \n",
    "    new_dataframe['val2'] = merging_dataframe['values']\n",
    "    new_dataframe['max'] = new_dataframe[['val1','val2']].max(axis=1)\n",
    "    new_dataframe['values'] = np.where(new_dataframe['val1'] < 3000, new_dataframe['val1'], new_dataframe['max'])\n",
    "    only_A=new_dataframe.copy()[:720]\n",
    "    only_B_C=new_dataframe.copy()[720:]\n",
    "    only_B_C['values'] = np.where(only_B_C['val1'] < 550, only_B_C['val1'], only_B_C['max'])\n",
    "    new_dataframe = pd.concat([only_A, only_B_C])['values']\n",
    "    \n",
    "    return pred_to_df(new_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f6ee68b3-c62d-4ad9-958f-366cacdebd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_with_slided_A(dataframe, merging_dataframe):\n",
    "    \n",
    "    new_dataframe = pd.DataFrame()\n",
    "    new_dataframe['val1'] = dataframe['values']\n",
    "    \n",
    "    new_dataframe['val2'] = merging_dataframe['values']\n",
    "    new_dataframe['max'] = new_dataframe[['val1','val2']].max(axis=1)\n",
    "    new_dataframe['values'] = np.where(new_dataframe['val1'] < 3000, new_dataframe['val1'], new_dataframe['max'])\n",
    "    only_A=new_dataframe.copy()[:720]\n",
    "    only_B_C=new_dataframe.copy()[720:]\n",
    "    new_dataframe = pd.concat([only_A, only_B_C])['values']\n",
    "    \n",
    "    return pred_to_df(new_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c0844c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1 = merge_with_slided_A(result_lgbm, result_lgbm_slided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "09141ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge2 = merge_with_slided_A(merge1, result_lgbm_r_slided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f6a2006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge3 = merge_with_slided(final_pred_1_2, merge2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8ea9e073",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge3_1 = merge_with_slided(final_pred_2_2, merge2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c804df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AVG of two models\n",
    "result_column = (merge3['values'] + merge3_1['values']) / 2\n",
    "\n",
    "avg1 = pd.DataFrame({'Mean_Value': result_column})\n",
    "avg1 = pred_to_df(avg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "272c131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg2 = pd.DataFrame()\n",
    "avg2['val1'] = avg1['values'] \n",
    "avg2['val2'] = final_pred_3_2['values']\n",
    "avg2['avg'] = (avg2['val1'] + avg2['val2'] * 2)/3\n",
    "avg2['values'] = np.where(avg2['val1'] > 2000, avg2['val1'], avg2['avg'])\n",
    "avg2 = avg2.drop(columns=['val1','val2','avg'])\n",
    "avg2= pred_to_df(avg2)\n",
    "avg2.to_csv('short_notebook_1_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf710bc7-706d-4c77-a3ac-fb67a89d3224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "226162a7-ab0b-463a-b89c-699239c564f1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8c53b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a96543a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374826b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970031fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m112"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
